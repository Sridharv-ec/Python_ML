{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "base_data_pdf=glob.glob(\"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_1MB.pdf'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data_pdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "pdfFileObj1 = open(base_data_pdf[0],'rb')\n",
    "pdfReader1 = PyPDF2.PdfFileReader(pdfFileObj1)\n",
    "p = \" \"\n",
    "j = 0\n",
    "for i in range(0,pdfReader1.numPages):\n",
    "    pageObj1 = pdfReader1.getPage(i)\n",
    "    p = p + pageObj1.extractText()\n",
    "    j = j +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFileObj=open(\"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\LearningPython.pdf\",'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594\n"
     ]
    }
   ],
   "source": [
    "print(pdfReader.numPages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Strings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sequence Operations\n",
      "\n",
      "\n",
      "len\n",
      ">>>            >>> len(S)               4>>> S[0]                 >>> S[1]                 \n",
      "\n",
      "\n",
      "S\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ">>> S[-1]                >>> S[-2]                Strings|99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pageObj1 = pdfReader.getPage(150)\n",
    "print(pageObj1.extractText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "77\n",
      "93\n",
      "137\n",
      "138\n",
      "139\n",
      "141\n",
      "183\n",
      "225\n",
      "238\n",
      "239\n",
      "289\n",
      "324\n",
      "325\n",
      "363\n",
      "364\n",
      "365\n",
      "367\n",
      "388\n",
      "389\n",
      "422\n",
      "437\n",
      "438\n",
      "466\n",
      "493\n",
      "518\n",
      "519\n",
      "521\n",
      "535\n",
      "536\n",
      "571\n",
      "572\n",
      "573\n",
      "603\n",
      "604\n",
      "630\n",
      "631\n",
      "678\n",
      "679\n",
      "714\n",
      "715\n",
      "717\n",
      "737\n",
      "756\n",
      "757\n",
      "794\n",
      "795\n",
      "829\n",
      "830\n",
      "831\n",
      "847\n",
      "867\n",
      "907\n",
      "908\n",
      "909\n",
      "936\n",
      "937\n",
      "983\n",
      "1030\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1127\n",
      "1129\n",
      "1142\n",
      "1143\n",
      "1172\n",
      "1173\n",
      "1191\n",
      "1213\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1318\n",
      "1319\n",
      "1396\n",
      "1397\n",
      "1399\n",
      "1401\n",
      "1403\n",
      "1405\n",
      "1459\n",
      "1460\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,pdfReader.numPages):\n",
    "    pageObj = pdfReader.getPage(i)\n",
    "    if \"Test Your Knowledge\" in pageObj.extractText():\n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-sample_150kB.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pdf miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer in c:\\users\\srivutta\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (20191103)\n",
      "Requirement already satisfied: pycryptodome in c:\\users\\srivutta\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdfminer) (3.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsrcmgr = PDFResourceManager()\n",
    "retstr = StringIO()\n",
    "codec = 'uft-8'\n",
    "laparams = LAParams()\n",
    "device = TextConverter(rsrcmgr, retstr, laparams=LAParams())\n",
    "fp = open(\"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\LearningPython.pdf\",'rb')\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "password = \"\"\n",
    "maxpages = 0\n",
    "caching = True\n",
    "pagenos=set()\n",
    "\n",
    "for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching, check_extractable=True):\n",
    "    interpreter.process_page(page)\n",
    "    \n",
    "text = retstr.getvalue()\n",
    "fp.close()\n",
    "device.close()\n",
    "retstr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x0c\\x0cFIFTH EDITION\\n\\nLearning Python\\n\\nMark Lutz\\n\\nBeijing•Cambridge•Farnham•Köln•Sebastopol•Tokyo\\x0cLearning Python, Fifth Edition\\nby Mark Lutz\\n\\nCopyright © 2013 Mark Lutz. All rights reserved.\\nPrinted in the United States of America.\\n\\nPublished by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\\n\\nO’Reilly books may be purchased for educational, business, or sales promotional use. Online editions\\nare also available for most titles (http://my.safaribooksonline.com). For more information, contact our\\ncorporate/institutional sales department: 800-998-9938 or corporate@oreilly.com.\\n\\nEditor: Rachel Roumeliotis\\nProduction Editor: Christopher Hearse\\nCopyeditor: Rachel Monaghan\\nProofreader: Julie Van Keuren\\n\\nIndexer: Lucie Haskins\\nCover Designer: Randy Comer\\nInterior Designer: David Futato\\nIllustrator: Rebecca Demarest\\n\\nJune 2013:\\n\\nFifth Edition. \\n\\nRevision History for the Fifth Edition:\\n\\n2013-06-07\\n\\nFirst release\\n\\nSee http://oreilly.com/catalog/errata.csp?isbn=9781449355739 for release details.\\n\\nNutshell Handbook, the Nutshell Handbook logo, and the O’Reilly logo are registered trademarks of\\nO’Reilly Media, Inc. Learning Python, 5th Edition, the image of a wood rat, and related trade dress are\\ntrademarks of O’Reilly Media, Inc.\\n\\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed as\\ntrademarks. Where those designations appear in this book, and O’Reilly Media, Inc., was aware of a\\ntrademark claim, the designations have been printed in caps or initial caps.\\n\\nWhile every precaution has been taken in the preparation of this book, the publisher and authors assume\\nno responsibility for errors or omissions, or for damages resulting from the use of the information con-\\ntained herein.\\n\\nISBN: 978-1-449-35573-9\\n\\n[QG]\\n\\n1370970520\\n\\n\\x0cTo Vera.\\n\\nYou are my life.\\n\\n\\x0c\\x0cTable of Contents\\n\\nPreface  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xxxiii\\n\\nPart I.  Getting Started \\n\\nWhy Do People Use Python?\\n\\nSoftware Quality\\nDeveloper Productivity\\n\\nIs Python a “Scripting Language”?\\nOK, but What’s the Downside?\\nWho Uses Python Today?\\nWhat Can I Do with Python?\\n\\nSystems Programming\\nGUIs\\nInternet Scripting\\nComponent Integration\\nDatabase Programming\\nRapid Prototyping\\nNumeric and Scientific Programming\\nAnd More: Gaming, Images, Data Mining, Robots, Excel...\\n\\n1. A Python Q&A Session  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  3\\n3\\n4\\n5\\n5\\n7\\n9\\n10\\n11\\n11\\n11\\n12\\n12\\n13\\n13\\n14\\n15\\n15\\n16\\n16\\n17\\n17\\n18\\n19\\n19\\n20\\n20\\n\\nIt’s Object-Oriented and Functional\\nIt’s Free\\nIt’s Portable\\nIt’s Powerful\\nIt’s Mixable\\nIt’s Relatively Easy to Use\\nIt’s Relatively Easy to Learn\\nIt’s Named After Monty Python\\n\\nHow Is Python Developed and Supported?\\n\\nOpen Source Tradeoffs\\n\\nWhat Are Python’s Technical Strengths?\\n\\nv\\n\\n\\x0cHow Does Python Stack Up to Language X?\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n21\\n22\\n23\\n23\\n\\nExecution Model Variations\\n\\nThe Programmer’s View\\nPython’s View\\n\\nIntroducing the Python Interpreter\\nProgram Execution\\n\\n2. How Python Runs Programs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  27\\n27\\n28\\n28\\n30\\n33\\n33\\n37\\n39\\n40\\n40\\n41\\n41\\n\\nPython Implementation Alternatives\\nExecution Optimization Tools\\nFrozen Binaries\\nFuture Possibilities?\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nThe Interactive Prompt\\n\\nSystem Command Lines and Files\\n\\nStarting an Interactive Session\\nThe System Path\\nNew Windows Options in 3.3: PATH, Launcher\\nWhere to Run: Code Directories\\nWhat Not to Type: Prompts and Comments\\nRunning Code Interactively\\nWhy the Interactive Prompt?\\nUsage Notes: The Interactive Prompt\\n\\n3. How You Run Programs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  43\\n43\\n44\\n45\\n46\\n47\\n48\\n49\\n50\\n52\\n54\\n55\\n56\\n57\\n58\\n59\\n59\\n60\\n60\\n62\\n62\\n63\\n63\\n66\\n\\nUnix Script Basics\\nThe Unix env Lookup Trick\\nThe Python 3.3 Windows Launcher: #! Comes to Windows\\n\\nA First Script\\nRunning Files with Command Lines\\nCommand-Line Usage Variations\\nUsage Notes: Command Lines and Files\\n\\nIcon-Click Basics\\nClicking Icons on Windows\\nThe input Trick on Windows\\nOther Icon-Click Limitations\\n\\nUnix-Style Executable Scripts: #!\\n\\nClicking File Icons\\n\\nvi\\n\\n| Table of Contents\\n\\n\\x0cModule Imports and Reloads\\nImport and Reload Basics\\nThe Grander Module Story: Attributes\\nUsage Notes: import and reload\\n\\nUsing exec to Run Module Files\\nThe IDLE User Interface\\nIDLE Startup Details\\nIDLE Basic Usage\\nIDLE Usability Features\\nAdvanced IDLE Tools\\nUsage Notes: IDLE\\n\\nOther IDEs\\nOther Launch Options\\n\\nEmbedding Calls\\nFrozen Binary Executables\\nText Editor Launch Options\\nStill Other Launch Options\\nFuture Possibilities?\\n\\nWhich Option Should I Use?\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part I Exercises\\n\\nPart II.  Types and Operations \\n\\n66\\n66\\n68\\n71\\n72\\n73\\n74\\n75\\n76\\n77\\n78\\n79\\n81\\n81\\n82\\n82\\n82\\n83\\n83\\n85\\n85\\n86\\n87\\n\\n4.\\n\\nIntroducing Python Object Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  93\\nThe Python Conceptual Hierarchy\\n93\\n94\\nWhy Use Built-in Types?\\n95\\nPython’s Core Data Types\\n97\\nNumbers\\nStrings\\n99\\n99\\n101\\n102\\n104\\n105\\n106\\n108\\n109\\n109\\n109\\n\\nSequence Operations\\nImmutability\\nType-Specific Methods\\nGetting Help\\nOther Ways to Code Strings\\nUnicode Strings\\nPattern Matching\\n\\nLists\\n\\nSequence Operations\\nType-Specific Operations\\n\\nTable of Contents\\n\\n| vii\\n\\n\\x0cBounds Checking\\nNesting\\nComprehensions\\n\\nDictionaries\\n\\nMapping Operations\\nNesting Revisited\\nMissing Keys: if Tests\\nSorting Keys: for Loops\\nIteration and Optimization\\n\\nTuples\\n\\nWhy Tuples?\\n\\nFiles\\n\\nBinary Bytes Files\\nUnicode Text Files\\nOther File-Like Tools\\n\\nOther Core Types\\n\\nHow to Break Your Code’s Flexibility\\nUser-Defined Classes\\nAnd Everything Else\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n110\\n110\\n111\\n113\\n114\\n115\\n116\\n118\\n120\\n121\\n122\\n122\\n123\\n124\\n126\\n126\\n128\\n129\\n130\\n130\\n131\\n131\\n\\nNumeric Type Basics\\n\\nNumeric Literals\\nBuilt-in Numeric Tools\\nPython Expression Operators\\n\\nNumbers in Action\\n\\n5. Numeric Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  133\\n133\\n134\\n136\\n136\\n141\\n141\\n143\\n144\\n146\\n150\\n151\\n151\\n153\\n155\\n157\\n157\\n160\\n163\\n171\\n\\nVariables and Basic Expressions\\nNumeric Display Formats\\nComparisons: Normal and Chained\\nDivision: Classic, Floor, and True\\nInteger Precision\\nComplex Numbers\\nHex, Octal, Binary: Literals and Conversions\\nBitwise Operations\\nOther Built-in Numeric Tools\\n\\nDecimal Type\\nFraction Type\\nSets\\nBooleans\\n\\nOther Numeric Types\\n\\nviii\\n\\n| Table of Contents\\n\\n\\x0cNumeric Extensions\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n172\\n172\\n173\\n173\\n\\nShared References\\n\\nThe Case of the Missing Declaration Statements\\n\\nVariables, Objects, and References\\nTypes Live with Objects, Not Variables\\nObjects Are Garbage-Collected\\n\\n6. The Dynamic Typing Interlude  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  175\\n175\\n176\\n177\\n178\\n180\\n181\\n183\\n185\\n186\\n186\\n186\\n\\nDynamic Typing Is Everywhere\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nShared References and In-Place Changes\\nShared References and Equality\\n\\nStrings in Action\\n\\nString Methods\\n\\nThis Chapter’s Scope\\n\\nUnicode: The Short Story\\n\\nString Basics\\nString Literals\\n\\nBasic Operations\\nIndexing and Slicing\\nString Conversion Tools\\nChanging Strings I\\n\\nSingle- and Double-Quoted Strings Are the Same\\nEscape Sequences Represent Special Characters\\nRaw Strings Suppress Escapes\\nTriple Quotes Code Multiline Block Strings\\n\\n7. String Fundamentals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  189\\n189\\n189\\n190\\n192\\n193\\n193\\n196\\n198\\n200\\n200\\n201\\n205\\n208\\n209\\n209\\n210\\n211\\n213\\n214\\n215\\n216\\n217\\n218\\n220\\n\\nMethod Call Syntax\\nMethods of Strings\\nString Method Examples: Changing Strings II\\nString Method Examples: Parsing Text\\nOther Common String Methods in Action\\nThe Original string Module’s Functions (Gone in 3.X)\\n\\nFormatting Expression Basics\\nAdvanced Formatting Expression Syntax\\nAdvanced Formatting Expression Examples\\n\\nString Formatting Expressions\\n\\nTable of Contents\\n\\n|\\n\\nix\\n\\n\\x0cDictionary-Based Formatting Expressions\\n\\nString Formatting Method Calls\\n\\nFormatting Method Basics\\nAdding Keys, Attributes, and Offsets\\nAdvanced Formatting Method Syntax\\nAdvanced Formatting Method Examples\\nComparison to the % Formatting Expression\\nWhy the Format Method?\\n\\nGeneral Type Categories\\n\\nTypes Share Operation Sets by Categories\\nMutable Types Can Be Changed in Place\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n221\\n222\\n222\\n223\\n224\\n225\\n227\\n230\\n235\\n235\\n236\\n237\\n237\\n237\\n\\n8.\\n\\nDictionaries\\nDictionaries in Action\\n\\nBasic List Operations\\nList Iteration and Comprehensions\\nIndexing, Slicing, and Matrixes\\nChanging Lists in Place\\n\\nLists and Dictionaries  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  239\\n239\\nLists\\n242\\nLists in Action\\n242\\n242\\n243\\n244\\n250\\n252\\n253\\n254\\n254\\n256\\n258\\n262\\n264\\n271\\n272\\n272\\n\\nBasic Dictionary Operations\\nChanging Dictionaries in Place\\nMore Dictionary Methods\\nExample: Movie Database\\nDictionary Usage Notes\\nOther Ways to Make Dictionaries\\nDictionary Changes in Python 3.X and 2.7\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nTuples\\n\\nTuples in Action\\nWhy Lists and Tuples?\\nRecords Revisited: Named Tuples\\n\\n9. Tuples, Files, and Everything Else  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  275\\n276\\n277\\n279\\n280\\n282\\n283\\n284\\n\\nOpening Files\\nUsing Files\\n\\nFiles\\n\\nx | Table of Contents\\n\\n\\x0cFiles in Action\\nText and Binary Files: The Short Story\\nStoring Python Objects in Files: Conversions\\nStoring Native Python Objects: pickle\\nStoring Python Objects in JSON Format\\nStoring Packed Binary Data: struct\\nFile Context Managers\\nOther File Tools\\n\\nCore Types Review and Summary\\n\\nObject Flexibility\\nReferences Versus Copies\\nComparisons, Equality, and Truth\\nThe Meaning of True and False in Python\\nPython’s Type Hierarchies\\nType Objects\\nOther Types in Python\\n\\nBuilt-in Type Gotchas\\n\\nAssignment Creates References, Not Copies\\nRepetition Adds One Level Deep\\nBeware of Cyclic Data Structures\\nImmutable Types Can’t Be Changed in Place\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part II Exercises\\n\\nPart III.  Statements and Syntax \\n\\n285\\n287\\n288\\n290\\n291\\n293\\n294\\n294\\n295\\n297\\n297\\n300\\n304\\n306\\n306\\n308\\n308\\n308\\n309\\n310\\n311\\n311\\n311\\n312\\n313\\n\\n10.\\n\\nWhat Python Adds\\nWhat Python Removes\\nWhy Indentation Syntax?\\nA Few Special Cases\\n\\nA Quick Example: Interactive Loops\\n\\nIntroducing Python Statements  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  319\\n319\\nThe Python Conceptual Hierarchy Revisited\\n320\\nPython’s Statements\\nA Tale of Two ifs\\n322\\n322\\n323\\n324\\n327\\n329\\n329\\n331\\n332\\n333\\n335\\n\\nA Simple Interactive Loop\\nDoing Math on User Inputs\\nHandling Errors by Testing Inputs\\nHandling Errors with try Statements\\nNesting Code Three Levels Deep\\n\\nTable of Contents\\n\\n| xi\\n\\n\\x0cChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n336\\n336\\n336\\n\\nAssignment Statements\\n\\nAssignment Statement Forms\\nSequence Assignments\\nExtended Sequence Unpacking in Python 3.X\\nMultiple-Target Assignments\\nAugmented Assignments\\nVariable Name Rules\\nExpression Statements\\n\\n11. Assignments, Expressions, and Prints  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  339\\n339\\n340\\n341\\n344\\n348\\n350\\n352\\n356\\n357\\n358\\n359\\n361\\n363\\n366\\n369\\n370\\n370\\n\\nThe Python 3.X print Function\\nThe Python 2.X print Statement\\nPrint Stream Redirection\\nVersion-Neutral Printing\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nExpression Statements and In-Place Changes\\n\\nPrint Operations\\n\\n12.\\n\\nGeneral Format\\nBasic Examples\\nMultiway Branching\\nPython Syntax Revisited\\n\\nif Tests and Syntax Rules  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  371\\n371\\nif Statements\\n371\\n372\\n372\\n375\\n376\\n378\\n379\\n380\\n382\\n385\\n385\\n386\\n\\nTruth Values and Boolean Tests\\nThe if/else Ternary Expression\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nBlock Delimiters: Indentation Rules\\nStatement Delimiters: Lines and Continuations\\nA Few Special Cases\\n\\nwhile Loops\\n\\n13. while and for Loops  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  387\\n387\\n388\\n388\\n389\\n\\nbreak, continue, pass, and the Loop else\\n\\nGeneral Format\\nExamples\\n\\nxii\\n\\n| Table of Contents\\n\\n\\x0cGeneral Loop Format\\npass\\ncontinue\\nbreak\\nLoop else\\n\\nfor Loops\\n\\nGeneral Format\\nExamples\\n\\nLoop Coding Techniques\\nCounter Loops: range\\nSequence Scans: while and range Versus for\\nSequence Shufflers: range and len\\nNonexhaustive Traversals: range Versus Slices\\nChanging Lists: range Versus Comprehensions\\nParallel Traversals: zip and map\\nGenerating Both Offsets and Items: enumerate\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n389\\n390\\n391\\n391\\n392\\n395\\n395\\n395\\n402\\n402\\n403\\n404\\n405\\n406\\n407\\n410\\n413\\n414\\n414\\n\\nThe Iteration Protocol: File Iterators\\nManual Iteration: iter and next\\nOther Built-in Type Iterables\\n\\nList Comprehensions: A First Detailed Look\\n\\nList Comprehension Basics\\nUsing List Comprehensions on Files\\nExtended List Comprehension Syntax\\n\\nIterations and Comprehensions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  415\\n416\\nIterations: A First Look\\n416\\n419\\n422\\n424\\n425\\n426\\n427\\n429\\n434\\n434\\n435\\n436\\n438\\n439\\n440\\n441\\n441\\n441\\n\\nImpacts on 2.X Code: Pros and Cons\\nThe range Iterable\\nThe map, zip, and filter Iterables\\nMultiple Versus Single Pass Iterators\\nDictionary View Iterables\\n\\nOther Iteration Topics\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nOther Iteration Contexts\\nNew Iterables in Python 3.X\\n\\n14.\\n\\n15. The Documentation Interlude  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443\\n443\\n\\nPython Documentation Sources\\n\\nTable of Contents\\n\\n| xiii\\n\\n\\x0c# Comments\\nThe dir Function\\nDocstrings: __doc__\\nPyDoc: The help Function\\nPyDoc: HTML Reports\\nBeyond docstrings: Sphinx\\nThe Standard Manual Set\\nWeb Resources\\nPublished Books\\n\\nCommon Coding Gotchas\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part III Exercises\\n\\nPart IV.  Functions and Generators \\n\\n444\\n444\\n446\\n449\\n452\\n461\\n461\\n462\\n463\\n463\\n465\\n466\\n466\\n467\\n\\n16.\\n\\nA First Example: Definitions and Calls\\n\\nA Second Example: Intersecting Sequences\\n\\nDefinition\\nCalls\\nPolymorphism in Python\\n\\nFunction Basics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  473\\n474\\nWhy Use Functions?\\nCoding Functions\\n475\\n476\\ndef Statements\\n477\\ndef Executes at Runtime\\n478\\n478\\n478\\n479\\n480\\n481\\n481\\n482\\n483\\n483\\n483\\n484\\n\\nDefinition\\nCalls\\nPolymorphism Revisited\\nLocal Variables\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nPython Scope Basics\\n\\n17. Scopes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  485\\n485\\n486\\n488\\n490\\n491\\n494\\n\\nScope Details\\nName Resolution: The LEGB Rule\\nScope Example\\nThe Built-in Scope\\nThe global Statement\\n\\nxiv | Table of Contents\\n\\n\\x0cProgram Design: Minimize Global Variables\\nProgram Design: Minimize Cross-File Changes\\nOther Ways to Access Globals\\n\\nScopes and Nested Functions\\n\\nNested Scope Details\\nNested Scope Examples\\nFactory Functions: Closures\\nRetaining Enclosing Scope State with Defaults\\n\\nThe nonlocal Statement in 3.X\\n\\nnonlocal Basics\\nnonlocal in Action\\n\\nWhy nonlocal? State Retention Options\\n\\nState with nonlocal: 3.X only\\nState with Globals: A Single Copy Only\\nState with Classes: Explicit Attributes (Preview)\\nState with Function Attributes: 3.X and 2.X\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n495\\n497\\n498\\n499\\n500\\n500\\n501\\n504\\n508\\n508\\n509\\n512\\n512\\n513\\n513\\n515\\n519\\n519\\n520\\n\\nArgument-Passing Basics\\n\\nSpecial Argument-Matching Modes\\n\\nThe min Wakeup Call!\\n\\nFull Credit\\nBonus Points\\nThe Punch Line...\\n\\nArguments and Shared References\\nAvoiding Mutable Argument Changes\\nSimulating Output Parameters and Multiple Results\\n\\nArgument Matching Basics\\nArgument Matching Syntax\\nThe Gritty Details\\nKeyword and Default Examples\\nArbitrary Arguments Examples\\nPython 3.X Keyword-Only Arguments\\n\\n18. Arguments  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  523\\n523\\n524\\n526\\n527\\n528\\n529\\n530\\n531\\n532\\n534\\n539\\n542\\n542\\n544\\n544\\n545\\n547\\n548\\n550\\n551\\n552\\n\\nGeneralized Set Functions\\nEmulating the Python 3.X print Function\\n\\nUsing Keyword-Only Arguments\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nTable of Contents\\n\\n| xv\\n\\n\\x0cFunction Design Concepts\\nRecursive Functions\\n\\nFunction Objects: Attributes and Annotations\\n\\nSummation with Recursion\\nCoding Alternatives\\nLoop Statements Versus Recursion\\nHandling Arbitrary Structures\\n\\nIndirect Function Calls: “First Class” Objects\\nFunction Introspection\\nFunction Attributes\\nFunction Annotations in 3.X\\nAnonymous Functions: lambda\\n\\n19. Advanced Function Topics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  553\\n553\\n555\\n555\\n556\\n557\\n558\\n562\\n562\\n563\\n564\\n565\\n567\\n568\\n569\\n571\\n572\\n574\\n574\\n576\\n576\\n578\\n578\\n578\\n\\nlambda Basics\\nWhy Use lambda?\\nHow (Not) to Obfuscate Your Python Code\\nScopes: lambdas Can Be Nested Too\\n\\nMapping Functions over Iterables: map\\nSelecting Items in Iterables: filter\\nCombining Items in Iterables: reduce\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nFunctional Programming Tools\\n\\nGenerator Functions and Expressions\\n\\nList Comprehensions and Functional Tools\\n\\nList Comprehensions Versus map\\nAdding Tests and Nested Loops: filter\\nExample: List Comprehensions and Matrixes\\nDon’t Abuse List Comprehensions: KISS\\n\\n20. Comprehensions and Generations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  581\\n581\\n582\\n583\\n586\\n588\\n591\\n592\\n597\\n602\\n604\\n606\\n609\\n614\\n617\\n622\\n623\\n624\\n\\nGenerator Functions: yield Versus return\\nGenerator Expressions: Iterables Meet Comprehensions\\nGenerator Functions Versus Generator Expressions\\nGenerators Are Single-Iteration Objects\\nGeneration in Built-in Types, Tools, and Classes\\nExample: Generating Scrambled Sequences\\nDon’t Abuse Generators: EIBTI\\nExample: Emulating zip and map with Iteration Tools\\n\\nScopes and Comprehension Variables\\nComprehending Set and Dictionary Comprehensions\\n\\nComprehension Syntax Summary\\n\\nxvi\\n\\n| Table of Contents\\n\\n\\x0cExtended Comprehension Syntax for Sets and Dictionaries\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n625\\n626\\n626\\n626\\n\\nTiming Iteration Alternatives\\n\\nTiming Iterations and Pythons with timeit\\n\\nTiming Module: Homegrown\\nTiming Script\\nTiming Results\\nTiming Module Alternatives\\nOther Suggestions\\n\\nBasic timeit Usage\\nBenchmark Module and Script: timeit\\nBenchmark Script Results\\nMore Fun with Benchmarks\\n\\n21. The Benchmarking Interlude  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  629\\n629\\n630\\n634\\n635\\n638\\n642\\n642\\n643\\n647\\n649\\n651\\n656\\n656\\n657\\n658\\n660\\n661\\n661\\n662\\n662\\n663\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part IV Exercises\\n\\nLocal Names Are Detected Statically\\nDefaults and Mutable Objects\\nFunctions Without returns\\nMiscellaneous Function Gotchas\\n\\nOther Benchmarking Topics: pystones\\nFunction Gotchas\\n\\nPart V.  Modules and Packages \\n\\nWhy Use Modules?\\nPython Program Architecture\\n\\nHow to Structure a Program\\nImports and Attributes\\nStandard Library Modules\\n\\n22. Modules: The Big Picture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  669\\n669\\n670\\n671\\n671\\n673\\n674\\n674\\n675\\n675\\n676\\n677\\n\\n1. Find It\\n2. Compile It (Maybe)\\n3. Run It\\n\\nByte Code Files: __pycache__ in Python 3.2+\\n\\nByte Code File Models in Action\\n\\nHow Imports Work\\n\\nTable of Contents\\n\\n| xvii\\n\\n\\x0cThe Module Search Path\\n\\nConfiguring the Search Path\\nSearch Path Variations\\nThe sys.path List\\nModule File Selection\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n678\\n681\\n681\\n681\\n682\\n685\\n685\\n685\\n\\nModule Creation\\n\\nModule Usage\\n\\nModule Filenames\\nOther Kinds of Modules\\n\\nThe import Statement\\nThe from Statement\\nThe from * Statement\\nImports Happen Only Once\\nimport and from Are Assignments\\nimport and from Equivalence\\nPotential Pitfalls of the from Statement\\n\\n23. Module Coding Basics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 687\\n687\\n687\\n688\\n688\\n689\\n689\\n689\\n690\\n691\\n692\\n693\\n694\\n695\\n696\\n697\\n698\\n699\\n700\\n701\\n702\\n703\\n704\\n704\\n\\nFiles Generate Namespaces\\nNamespace Dictionaries: __dict__\\nAttribute Name Qualification\\nImports Versus Scopes\\nNamespace Nesting\\n\\nreload Basics\\nreload Example\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nModule Namespaces\\n\\nReloading Modules\\n\\nPackage Import Basics\\n\\nPackages and Search Path Settings\\nPackage __init__.py Files\\n\\n24. Module Packages  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  707\\n708\\n708\\n709\\n711\\n713\\n713\\n714\\n717\\n\\nWhy Use Package Imports?\\nA Tale of Three Systems\\n\\nfrom Versus import with Packages\\n\\nPackage Relative Imports\\n\\nPackage Import Example\\n\\nxviii\\n\\n| Table of Contents\\n\\n\\x0cChanges in Python 3.X\\nRelative Import Basics\\nWhy Relative Imports?\\nThe Scope of Relative Imports\\nModule Lookup Rules Summary\\nRelative Imports in Action\\nPitfalls of Package-Relative Imports: Mixed Use\\n\\nPython 3.3 Namespace Packages\\nNamespace Package Semantics\\nImpacts on Regular Packages: Optional __init__.py\\nNamespace Packages in Action\\nNamespace Package Nesting\\nFiles Still Have Precedence over Directories\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n718\\n718\\n720\\n722\\n723\\n723\\n729\\n734\\n735\\n736\\n737\\n738\\n740\\n742\\n742\\n742\\n\\nModule Design Concepts\\nData Hiding in Modules\\n\\nUnit Tests with __name__\\n\\nExample: Dual Mode Code\\n\\nCurrency Symbols: Unicode in Action\\nDocstrings: Module Documentation at Work\\n\\nMinimizing from * Damage: _X and __all__\\nEnabling Future Language Features: __future__\\nMixed Usage Modes: __name__ and __main__\\n\\nChanging the Module Search Path\\nThe as Extension for import and from\\nExample: Modules Are Objects\\nImporting Modules by Name String\\n\\n25. Advanced Module Topics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  745\\n745\\n747\\n747\\n748\\n749\\n750\\n751\\n754\\n756\\n756\\n758\\n759\\n761\\n762\\n762\\n763\\n764\\n767\\n770\\n771\\n771\\n772\\n773\\n773\\n774\\n\\nModule Name Clashes: Package and Package-Relative Imports\\nStatement Order Matters in Top-Level Code\\nfrom Copies Names but Doesn’t Link\\nfrom * Can Obscure the Meaning of Variables\\nreload May Not Impact from Imports\\nreload, from, and Interactive Testing\\n\\nRunning Code Strings\\nDirect Calls: Two Options\\n\\nExample: Transitive Module Reloads\\n\\nA Recursive Reloader\\nAlternative Codings\\n\\nModule Gotchas\\n\\nTable of Contents\\n\\n| xix\\n\\n\\x0cRecursive from Imports May Not Work\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part V Exercises\\n\\nPart VI.  Classes and OOP \\n\\n775\\n776\\n777\\n777\\n778\\n\\nWhy Use Classes?\\nOOP from 30,000 Feet\\n\\n26. OOP: The Big Picture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 783\\n784\\n785\\n785\\n788\\n788\\n789\\n791\\n792\\n795\\n795\\n795\\n\\nAttribute Inheritance Search\\nClasses and Instances\\nMethod Calls\\nCoding Class Trees\\nOperator Overloading\\nOOP Is About Code Reuse\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nClasses Are Customized by Inheritance\\n\\nA Second Example\\nClasses Are Attributes in Modules\\n\\nClasses Can Intercept Python Operators\\n\\nClasses Generate Multiple Instance Objects\\nClass Objects Provide Default Behavior\\nInstance Objects Are Concrete Items\\nA First Example\\n\\n27. Class Coding Basics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  797\\n797\\n798\\n798\\n799\\n801\\n802\\n804\\n805\\n806\\n808\\n809\\n812\\n814\\n815\\n815\\n\\nA Third Example\\nWhy Use Operator Overloading?\\nThe World’s Simplest Python Class\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nRecords Revisited: Classes Versus Dictionaries\\n\\n28. A More Realistic Example  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 817\\n818\\n818\\n819\\n\\nStep 1: Making Instances\\nCoding Constructors\\nTesting As You Go\\n\\nxx | Table of Contents\\n\\n\\x0cUsing Code Two Ways\\n\\nStep 2: Adding Behavior Methods\\n\\nCoding Methods\\n\\nStep 3: Operator Overloading\\n\\nProviding Print Displays\\n\\nStep 4: Customizing Behavior by Subclassing\\n\\nCoding Subclasses\\nAugmenting Methods: The Bad Way\\nAugmenting Methods: The Good Way\\nPolymorphism in Action\\nInherit, Customize, and Extend\\nOOP: The Big Idea\\n\\nStep 5: Customizing Constructors, Too\\n\\nOOP Is Simpler Than You May Think\\nOther Ways to Combine Classes\\n\\nStep 6: Using Introspection Tools\\n\\nSpecial Class Attributes\\nA Generic Display Tool\\nInstance Versus Class Attributes\\nName Considerations in Tool Classes\\nOur Classes’ Final Form\\n\\nStep 7 (Final): Storing Objects in a Database\\n\\nPickles and Shelves\\nStoring Objects on a Shelve Database\\nExploring Shelves Interactively\\nUpdating Objects on a Shelve\\n\\nFuture Directions\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n820\\n822\\n824\\n826\\n826\\n828\\n828\\n829\\n829\\n832\\n833\\n833\\n834\\n836\\n836\\n840\\n840\\n842\\n843\\n844\\n845\\n847\\n847\\n848\\n849\\n851\\n853\\n855\\n855\\n856\\n\\nThe class Statement\\n\\nGeneral Form\\nExample\\n\\nMethods\\n\\n29. Class Coding Details  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  859\\n859\\n860\\n860\\n862\\n863\\n864\\n864\\n865\\n865\\n866\\n867\\n\\nMethod Example\\nCalling Superclass Constructors\\nOther Method Call Possibilities\\n\\nAttribute Tree Construction\\nSpecializing Inherited Methods\\nClass Interface Techniques\\n\\nInheritance\\n\\nTable of Contents\\n\\n| xxi\\n\\n\\x0cAbstract Superclasses\\n\\nNamespaces: The Conclusion\\n\\nSimple Names: Global Unless Assigned\\nAttribute Names: Object Namespaces\\nThe “Zen” of Namespaces: Assignments Classify Names\\nNested Classes: The LEGB Scopes Rule Revisited\\nNamespace Dictionaries: Review\\nNamespace Links: A Tree Climber\\n\\nDocumentation Strings Revisited\\nClasses Versus Modules\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n869\\n872\\n872\\n872\\n873\\n875\\n878\\n880\\n882\\n884\\n884\\n884\\n885\\n\\nThe Basics\\n\\nConstructors and Expressions: __init__ and __sub__\\nCommon Operator Overloading Methods\\n\\nIndexing and Slicing: __getitem__ and __setitem__\\n\\nIntercepting Slices\\nSlicing and Indexing in Python 2.X\\nBut 3.X’s __index__ Is Not Indexing!\\n\\nIndex Iteration: __getitem__\\nIterable Objects: __iter__ and __next__\\n\\nMembership: __contains__, __iter__, and __getitem__\\nAttribute Access: __getattr__ and __setattr__\\n\\nUser-Defined Iterables\\nMultiple Iterators on One Object\\nCoding Alternative: __iter__ plus yield\\n\\n30. Operator Overloading  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  887\\n887\\n888\\n888\\n890\\n891\\n893\\n894\\n894\\n895\\n896\\n899\\n902\\n906\\n909\\n909\\n910\\n912\\n912\\n913\\n914\\n916\\n917\\n917\\n920\\n921\\n923\\n925\\n926\\n\\nAttribute Reference\\nAttribute Assignment and Deletion\\nOther Attribute Management Tools\\nEmulating Privacy for Instance Attributes: Part 1\\n\\nRight-Side Addition\\nIn-Place Addition\\n\\nCall Expressions: __call__\\n\\nFunction Interfaces and Callback-Based Code\\n\\nComparisons: __lt__, __gt__, and Others\\n\\nThe __cmp__ Method in Python 2.X\\n\\nString Representation: __repr__ and __str__\\n\\nWhy Two Display Methods?\\nDisplay Usage Notes\\n\\nRight-Side and In-Place Uses: __radd__ and __iadd__\\n\\nxxii\\n\\n| Table of Contents\\n\\n\\x0cBoolean Tests: __bool__ and __len__\\n\\nBoolean Methods in Python 2.X\\n\\nObject Destruction: __del__\\n\\nDestructor Usage Notes\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n927\\n928\\n929\\n930\\n931\\n931\\n931\\n\\nPython and OOP\\n\\nStream Processors Revisited\\n\\nPolymorphism Means Interfaces, Not Call Signatures\\n\\nName Mangling Overview\\nWhy Use Pseudoprivate Attributes?\\n\\nOOP and Inheritance: “Is-a” Relationships\\nOOP and Composition: “Has-a” Relationships\\n\\nOOP and Delegation: “Wrapper” Proxy Objects\\nPseudoprivate Class Attributes\\n\\n31. Designing with Classes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 933\\n933\\n934\\n935\\n937\\n938\\n942\\n944\\n945\\n945\\n948\\n950\\n951\\n954\\n955\\n956\\n957\\n977\\n977\\n978\\n978\\n\\nMethods Are Objects: Bound or Unbound\\nUnbound Methods Are Functions in 3.X\\nBound Methods and Other Callable Objects\\nClasses Are Objects: Generic Object Factories\\n\\nOther Design-Related Topics\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nWhy Factories?\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\nCoding Mix-in Display Classes\\n\\nExtending Built-in Types\\n\\nJust How New Is New-Style?\\n\\nThe “New Style” Class Model\\n\\nExtending Types by Embedding\\nExtending Types by Subclassing\\n\\n32. Advanced Class Topics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  979\\n980\\n980\\n981\\n983\\n984\\n985\\n987\\n992\\n995\\n997\\n1001\\n1004\\n\\nAttribute Fetch for Built-ins Skips Instances\\nType Model Changes\\nAll Classes Derive from “object”\\nDiamond Inheritance Change\\nMore on the MRO: Method Resolution Order\\nExample: Mapping Attributes to Inheritance Sources\\n\\nNew-Style Class Changes\\n\\nTable of Contents\\n\\n| xxiii\\n\\n\\x0cNew-Style Class Extensions\\n\\nSlots: Attribute Declarations\\nProperties: Attribute Accessors\\n__getattribute__ and Descriptors: Attribute Tools\\nOther Class Changes and Extensions\\n\\nStatic and Class Methods\\n\\nWhy the Special Methods?\\nStatic Methods in 2.X and 3.X\\nStatic Method Alternatives\\nUsing Static and Class Methods\\nCounting Instances with Static Methods\\nCounting Instances with Class Methods\\n\\nDecorators and Metaclasses: Part 1\\n\\nFunction Decorator Basics\\nA First Look at User-Defined Function Decorators\\nA First Look at Class Decorators and Metaclasses\\nFor More Details\\n\\nThe super Built-in Function: For Better or Worse?\\n\\nThe Great super Debate\\nTraditional Superclass Call Form: Portable, General\\nBasic super Usage and Its Tradeoffs\\nThe super Upsides: Tree Changes and Dispatch\\nRuntime Class Changes and super\\nCooperative Multiple Inheritance Method Dispatch\\nThe super Summary\\n\\nClass Gotchas\\n\\nChanging Class Attributes Can Have Side Effects\\nChanging Mutable Class Attributes Can Have Side Effects, Too\\nMultiple Inheritance: Order Matters\\nScopes in Methods and Classes\\nMiscellaneous Class Gotchas\\nKISS Revisited: “Overwrapping-itis”\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part VI Exercises\\n\\nPart VII.  Exceptions and Tools \\n\\n1010\\n1010\\n1020\\n1023\\n1023\\n1024\\n1024\\n1025\\n1027\\n1028\\n1030\\n1031\\n1034\\n1035\\n1037\\n1038\\n1040\\n1041\\n1041\\n1042\\n1043\\n1049\\n1049\\n1050\\n1062\\n1064\\n1064\\n1065\\n1066\\n1068\\n1069\\n1070\\n1070\\n1071\\n1071\\n1072\\n\\n33. Exception Basics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1081\\n1081\\n1082\\n\\nWhy Use Exceptions?\\n\\nException Roles\\n\\nxxiv | Table of Contents\\n\\n\\x0cExceptions: The Short Story\\n\\nDefault Exception Handler\\nCatching Exceptions\\nRaising Exceptions\\nUser-Defined Exceptions\\nTermination Actions\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n1083\\n1083\\n1084\\n1085\\n1086\\n1087\\n1089\\n1090\\n1090\\n\\nThe try/finally Statement\\n\\nUnified try/except/finally\\n\\nExample: Coding Termination Actions with try/finally\\n\\nThe raise Statement\\n\\nUnified try Statement Syntax\\nCombining finally and except by Nesting\\nUnified try Example\\n\\nThe try/except/else Statement\\nHow try Statements Work\\ntry Statement Clauses\\nThe try else Clause\\nExample: Default Behavior\\nExample: Catching Built-in Exceptions\\n\\n34. Exception Coding Details  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1093\\n1093\\n1094\\n1095\\n1098\\n1098\\n1100\\n1100\\n1101\\n1102\\n1104\\n1104\\n1105\\n1106\\n1107\\n1108\\n1110\\n1110\\n1112\\n1113\\n1114\\n1114\\n1116\\n1118\\n1119\\n1120\\n1120\\n\\nRaising Exceptions\\nScopes and try except Variables\\nPropagating Exceptions with raise\\nPython 3.X Exception Chaining: raise from\\n\\nBasic Usage\\nThe Context Management Protocol\\nMultiple Context Managers in 3.1, 2.7, and Later\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\nThe assert Statement\\n\\nExample: Trapping Constraints (but Not Errors!)\\n\\nwith/as Context Managers\\n\\nExceptions: Back to the Future\\n\\n35. Exception Objects  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1123\\n1124\\n1124\\n1125\\n1126\\n\\nString Exceptions Are Right Out!\\nClass-Based Exceptions\\nCoding Exceptions Classes\\n\\nTable of Contents\\n\\n| xxv\\n\\n\\x0cWhy Exception Hierarchies?\\nBuilt-in Exception Classes\\n\\nBuilt-in Exception Categories\\nDefault Printing and State\\n\\nCustom Print Displays\\nCustom Data and Behavior\\n\\nProviding Exception Details\\nProviding Exception Methods\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n1128\\n1131\\n1132\\n1133\\n1135\\n1136\\n1136\\n1137\\n1139\\n1139\\n1139\\n\\nNesting Exception Handlers\\n\\nExample: Control-Flow Nesting\\nExample: Syntactic Nesting\\n\\nException Idioms\\n\\nBreaking Out of Multiple Nested Loops: “go to”\\nExceptions Aren’t Always Errors\\nFunctions Can Signal Conditions with raise\\nClosing Files and Server Connections\\nDebugging with Outer try Statements\\nRunning In-Process Tests\\nMore on sys.exc_info\\nDisplaying Errors and Tracebacks\\nException Design Tips and Gotchas\\n\\n36. Designing with Exceptions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1141\\n1141\\n1143\\n1143\\n1145\\n1145\\n1146\\n1147\\n1148\\n1149\\n1149\\n1150\\n1151\\n1152\\n1152\\n1153\\n1155\\n1155\\n1156\\n1157\\n1160\\n1161\\n1161\\n1161\\n\\nWhat Should Be Wrapped\\nCatching Too Much: Avoid Empty except and Exception\\nCatching Too Little: Use Class-Based Categories\\n\\nThe Python Toolset\\nDevelopment Tools for Larger Projects\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\nTest Your Knowledge: Part VII Exercises\\n\\nCore Language Summary\\n\\nPart VIII.  Advanced Topics \\n\\n37. Unicode and Byte Strings  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1165\\n1166\\n1167\\n\\nString Changes in 3.X\\nString Basics\\n\\nxxvi\\n\\n| Table of Contents\\n\\n\\x0cCharacter Encoding Schemes\\nHow Python Stores Strings in Memory\\nPython’s String Types\\nText and Binary Files\\n\\nCoding Basic Strings\\n\\nPython 3.X String Literals\\nPython 2.X String Literals\\nString Type Conversions\\n\\nCoding Unicode Strings\\n\\nCoding ASCII Text\\nCoding Non-ASCII Text\\nEncoding and Decoding Non-ASCII text\\nOther Encoding Schemes\\nByte String Literals: Encoded Text\\nConverting Encodings\\nCoding Unicode Strings in Python 2.X\\nSource File Character Set Encoding Declarations\\n\\nUsing 3.X bytes Objects\\n\\nMethod Calls\\nSequence Operations\\nOther Ways to Make bytes Objects\\nMixing String Types\\n\\nUsing 3.X/2.6+ bytearray Objects\\n\\nbytearrays in Action\\nPython 3.X String Types Summary\\n\\nUsing Text and Binary Files\\n\\nText File Basics\\nText and Binary Modes in 2.X and 3.X\\nType and Content Mismatches in 3.X\\n\\nUsing Unicode Files\\n\\nReading and Writing Unicode in 3.X\\nHandling the BOM in 3.X\\nUnicode Files in 2.X\\nUnicode Filenames and Streams\\nOther String Tool Changes in 3.X\\n\\nThe re Pattern-Matching Module\\nThe struct Binary Data Module\\nThe pickle Object Serialization Module\\nXML Parsing Tools\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n1167\\n1170\\n1171\\n1173\\n1174\\n1175\\n1176\\n1177\\n1178\\n1178\\n1179\\n1180\\n1181\\n1183\\n1184\\n1185\\n1187\\n1189\\n1189\\n1190\\n1191\\n1192\\n1192\\n1193\\n1195\\n1195\\n1196\\n1197\\n1198\\n1199\\n1199\\n1201\\n1204\\n1205\\n1206\\n1206\\n1207\\n1209\\n1211\\n1215\\n1215\\n1216\\n\\nTable of Contents\\n\\n| xxvii\\n\\n\\x0cWhy Manage Attributes?\\n\\nInserting Code to Run on Attribute Access\\n\\nProperties\\n\\nDescriptors\\n\\nThe Basics\\nA First Example\\nComputed Attributes\\nCoding Properties with Decorators\\n\\nThe Basics\\nA First Example\\nComputed Attributes\\nUsing State Information in Descriptors\\nHow Properties and Descriptors Relate\\n\\n38. Managed Attributes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1219\\n1219\\n1220\\n1221\\n1222\\n1222\\n1224\\n1224\\n1226\\n1227\\n1229\\n1231\\n1232\\n1236\\n1237\\n1238\\n1241\\n1243\\n1245\\n1246\\n1249\\n1256\\n1256\\n1259\\n1263\\n1265\\n1266\\n1266\\n1267\\n\\nThe Basics\\nA First Example\\nComputed Attributes\\n__getattr__ and __getattribute__ Compared\\nManagement Techniques Compared\\nIntercepting Built-in Operation Attributes\\n\\nExample: Attribute Validations\\nUsing Properties to Validate\\nUsing Descriptors to Validate\\nUsing __getattr__ to Validate\\nUsing __getattribute__ to Validate\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\n\\n__getattr__ and __getattribute__\\n\\nTest Your Knowledge: Answers\\n\\nWhat’s a Decorator?\\n\\nManaging Calls and Instances\\nManaging Functions and Classes\\nUsing and Defining Decorators\\nWhy Decorators?\\n\\n39. Decorators  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1269\\n1269\\n1270\\n1270\\n1271\\n1271\\n1273\\n1273\\n1277\\n1279\\n1281\\n1282\\n1283\\n\\nFunction Decorators\\nClass Decorators\\nDecorator Nesting\\nDecorator Arguments\\nDecorators Manage Functions and Classes, Too\\n\\nCoding Function Decorators\\n\\nThe Basics\\n\\nxxviii\\n\\n| Table of Contents\\n\\n\\x0cTracing Calls\\nDecorator State Retention Options\\nClass Blunders I: Decorating Methods\\nTiming Calls\\nAdding Decorator Arguments\\n\\nCoding Class Decorators\\n\\nSingleton Classes\\nTracing Object Interfaces\\nClass Blunders II: Retaining Multiple Instances\\nDecorators Versus Manager Functions\\nWhy Decorators? (Revisited)\\n\\nManaging Functions and Classes Directly\\nExample: “Private” and “Public” Attributes\\n\\nImplementing Private Attributes\\nImplementation Details I\\nGeneralizing for Public Declarations, Too\\nImplementation Details II\\nOpen Issues\\nPython Isn’t About Control\\n\\nExample: Validating Function Arguments\\n\\nThe Goal\\nA Basic Range-Testing Decorator for Positional Arguments\\nGeneralizing for Keywords and Defaults, Too\\nImplementation Details\\nOpen Issues\\nDecorator Arguments Versus Function Annotations\\nOther Applications: Type Testing (If You Insist!)\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n1283\\n1285\\n1289\\n1295\\n1298\\n1301\\n1301\\n1303\\n1308\\n1309\\n1310\\n1312\\n1314\\n1314\\n1317\\n1318\\n1320\\n1321\\n1329\\n1330\\n1330\\n1331\\n1333\\n1336\\n1338\\n1340\\n1342\\n1343\\n1344\\n1345\\n\\nTo Metaclass or Not to Metaclass\\n\\nThe Metaclass Model\\n\\nClasses Are Instances of type\\nMetaclasses Are Subclasses of Type\\nClass Statement Protocol\\n\\nIncreasing Levels of “Magic”\\nA Language of Hooks\\nThe Downside of “Helper” Functions\\nMetaclasses Versus Class Decorators: Round 1\\n\\n40. Metaclasses  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1355\\n1356\\n1357\\n1358\\n1359\\n1361\\n1364\\n1364\\n1366\\n1367\\n1368\\n1369\\n\\nDeclaring Metaclasses\\nDeclaration in 3.X\\n\\nTable of Contents\\n\\n| xxix\\n\\n\\x0cDeclaration in 2.X\\nMetaclass Dispatch in Both 3.X and 2.X\\n\\nCoding Metaclasses\\nA Basic Metaclass\\nCustomizing Construction and Initialization\\nOther Metaclass Coding Techniques\\n\\nInheritance and Instance\\n\\nMetaclass Versus Superclass\\nInheritance: The Full Story\\n\\nMetaclass Methods\\n\\nMetaclass Methods Versus Class Methods\\nOperator Overloading in Metaclass Methods\\n\\nExample: Adding Methods to Classes\\n\\nManual Augmentation\\nMetaclass-Based Augmentation\\nMetaclasses Versus Class Decorators: Round 2\\n\\nExample: Applying Decorators to Methods\\n\\nTracing with Decoration Manually\\nTracing with Metaclasses and Decorators\\nApplying Any Decorator to Methods\\nMetaclasses Versus Class Decorators: Round 3 (and Last)\\n\\nChapter Summary\\nTest Your Knowledge: Quiz\\nTest Your Knowledge: Answers\\n\\n1369\\n1370\\n1370\\n1371\\n1372\\n1373\\n1378\\n1381\\n1382\\n1388\\n1389\\n1390\\n1391\\n1391\\n1393\\n1394\\n1400\\n1400\\n1401\\n1403\\n1404\\n1407\\n1407\\n1408\\n\\nThe Python Paradox\\n\\n41. All Good Things  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1409\\n1409\\n1410\\n1411\\n1412\\n1412\\n1413\\n1414\\n1414\\n\\nOn “Optional” Language Features\\nAgainst Disquieting Improvements\\nComplexity Versus Power\\nSimplicity Versus Elitism\\nClosing Thoughts\\n\\nWhere to Go From Here\\nEncore: Print Your Own Completion Certificate!\\n\\nPart IX.  Appendixes \\n\\nA.\\n\\nInstallation and Configuration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1421\\n1421\\nInstalling the Python Interpreter\\n1421\\n1422\\n1423\\n\\nIs Python Already Present?\\nWhere to Get Python\\nInstallation Steps\\n\\nxxx | Table of Contents\\n\\n\\x0cConfiguring Python\\n\\nPython Environment Variables\\nHow to Set Configuration Options\\nPython Command-Line Arguments\\nPython 3.3 Windows Launcher Command Lines\\n\\nFor More Help\\n\\n1427\\n1427\\n1429\\n1432\\n1435\\n1436\\n\\nThe Unix Legacy\\nThe Windows Legacy\\nIntroducing the New Windows Launcher\\nA Windows Launcher Tutorial\\n\\nB. The Python 3.3 Windows Launcher  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1437\\n1437\\n1438\\n1439\\n1441\\n1441\\n1444\\n1445\\n1447\\n1447\\n1448\\n1449\\n1450\\n\\nStep 1: Using Version Directives in Files\\nStep 2: Using Command-Line Version Switches\\nStep 3: Using and Changing Defaults\\nPitfalls of the New Windows Launcher\\n\\nPitfall 1: Unrecognized Unix !# Lines Fail\\nPitfall 2: The Launcher Defaults to 2.X\\nPitfall 3: The New PATH Extension Option\\n\\nConclusions: A Net Win for Windows\\n\\nMajor 2.X/3.X Differences\\n\\n3.X Differences\\n3.X-Only Extensions\\n\\nFifth Edition Python Changes: 2.7, 3.2, 3.3\\n\\nGeneral Remarks: 3.X Changes\\n\\nChanges in Libraries and Tools\\nMigrating to 3.X\\n\\nC. Python Changes and This Book  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1451\\n1451\\n1452\\n1453\\n1454\\n1454\\n1455\\n1456\\n1456\\n1457\\n1458\\n1458\\n1458\\n1459\\n1460\\n1462\\n1463\\n\\nChanges in Python 3.1\\nChanges in Python 3.0 and 2.6\\nSpecific Language Removals in 3.0\\n\\nThird Edition Python Changes: 2.3, 2.4, 2.5\\nEarlier and Later Python Changes\\n\\nChanges in Python 2.7\\nChanges in Python 3.3\\nChanges in Python 3.2\\n\\nFourth Edition Python Changes: 2.6, 3.0, 3.1\\n\\nD. Solutions to End-of-Part Exercises  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1465\\n1465\\n1467\\n1473\\n\\nPart I, Getting Started\\nPart II, Types and Operations\\nPart III, Statements and Syntax\\n\\nTable of Contents\\n\\n| xxxi\\n\\n\\x0cPart IV, Functions and Generators\\nPart V, Modules and Packages\\nPart VI, Classes and OOP\\nPart VII, Exceptions and Tools\\n\\n1475\\n1485\\n1489\\n1497\\n\\nIndex  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1507\\n\\nxxxii\\n\\n| Table of Contents\\n\\n\\x0cPreface\\n\\nIf you’re standing in a bookstore looking for the short story on this book, try this:\\n\\n• Python is a powerful multiparadigm computer programming language, optimized\\n\\nfor programmer productivity, code readability, and software quality.\\n\\n• This book provides a comprehensive and in-depth introduction to the Python lan-\\nguage itself. Its goal is to help you master Python fundamentals before moving on\\nto apply them in your work. Like all its prior editions, this book is designed to serve\\nas a single, all-inclusive learning resource for all Python newcomers, whether they\\nwill be using Python 2.X, Python 3.X, or both.\\n\\n• This edition has been brought up to date with Python releases 3.3 and 2.7, and has\\n\\nbeen expanded substantially to reflect current practice in the Python world.\\n\\nThis preface describes this book’s goals, scope, and structure in more detail. It’s optional\\nreading, but is designed to provide some orientation before you get started with the\\nbook at large.\\n\\nThis Book’s “Ecosystem”\\nPython is a popular open source programming language used for both standalone pro-\\ngrams and scripting applications in a wide variety of domains. It is free, portable, pow-\\nerful, and is both relatively easy and remarkably fun to use. Programmers from every\\ncorner of the software industry have found Python’s focus on developer productivity\\nand software quality to be a strategic advantage in projects both large and small.\\nWhether you are new to programming or are a professional developer, this book is\\ndesigned to bring you up to speed on the Python language in ways that more limited\\napproaches cannot. After reading this book, you should know enough about Python\\nto apply it in whatever application domains you choose to explore.\\nBy design, this book is a tutorial that emphasizes the core Python language itself, rather\\nthan specific applications of it. As such, this book is intended to serve as the first in a\\ntwo-volume set:\\n\\nxxxiii\\n\\n\\x0c• Learning Python, this book, teaches Python itself, focusing on language funda-\\n\\nmentals that span domains.\\n\\n• Programming Python, among others, moves on to show what you can do with\\n\\nPython after you’ve learned it.\\n\\nThis division of labor is deliberate. While application goals can vary per reader, the\\nneed for useful language fundamentals coverage does not. Applications-focused books\\nsuch as Programming Python pick up where this book leaves off, using realistically\\nscaled examples to explore Python’s role in common domains such as the Web, GUIs,\\nsystems, databases, and text. In addition, the book Python Pocket Reference provides\\nreference materials not included here, and it is designed to supplement this book.\\nBecause of this book’s focus on foundations, though, it is able to present Python lan-\\nguage fundamentals with more depth than many programmers see when first learning\\nthe language. Its bottom-up approach and self-contained didactic examples are de-\\nsigned to teach readers the entire language one step at a time.\\nThe core language skills you’ll gain in the process will apply to every Python software\\nsystem you’ll encounter—be it today’s popular tools such as Django, NumPy, and App\\nEngine, or others that may be a part of both Python’s future and your programming\\ncareer.\\nBecause it’s based upon a three-day Python training class with quizzes and exercises\\nthroughout, this book also serves as a self-paced introduction to the language. Although\\nits format lacks the live interaction of a class, it compensates in the extra depth and\\nflexibility that only a book can provide. Though there are many ways to use this book,\\nlinear readers will find it roughly equivalent to a semester-long Python class.\\n\\nAbout This Fifth Edition\\nThe prior fourth edition of this book published in 2009 covered Python versions 2.6\\nand 3.0.1 It addressed the many and sometimes incompatible changes introduced in\\nthe Python 3.X line in general. It also introduced a new OOP tutorial, and new chapters\\non advanced topics such as Unicode text, decorators, and metaclasses, derived from\\nboth the live classes I teach and evolution in Python “best practice.”\\nThis fifth edition completed in 2013 is a revision of the prior, updated to cover both\\nPython 3.3 and 2.7, the current latest releases in the 3.X and 2.X lines. It incorporates\\n\\n1. And 2007’s short-lived third edition covered Python 2.5, and its simpler—and shorter—single-line Python\\nworld. See http://www.rmi.net/~lutz for more on this book’s history. Over the years, this book has grown\\nin size and complexity in direct proportion to Python’s own growth. Per Appendix C, Python 3.0 alone\\nintroduced 27 additions and 57 changes in the language that found their way into this book, and Python\\n3.3  continues  this  trend.  Today’s  Python  programmer  faces  two  incompatible  lines,  three  major\\nparadigms, a plethora of advanced tools, and a blizzard of feature redundancy—most of which do not\\ndivide neatly between the 2.X and 3.X lines. That’s not as daunting as it may sound (many tools are\\nvariations on a theme), but all are fair game in an inclusive, comprehensive Python text.\\n\\nxxxiv | Preface\\n\\n\\x0call language changes introduced in each line since the prior edition was published, and\\nhas been polished throughout to update and sharpen its presentation. Specifically:\\n\\n• Python 2.X coverage here has been updated to include features such as dictionary\\nand set comprehensions that were formerly for 3.X only, but have been back-ported\\nfor use in 2.7.\\n\\n• Python  3.X  coverage  has  been  augmented  for  new  yield  and  raise  syntax;  the\\n__pycache__  bytecode  model;  3.3  namespace  packages;  PyDoc’s  all-browser\\nmode;  Unicode  literal  and  storage  changes;  and  the  new  Windows  launcher\\nshipped with 3.3.\\n\\n• Assorted new or expanded coverage for JSON, timeit, PyPy, os.popen, generators,\\nrecursion, weak references, __mro__, __iter__, super, __slots__, metaclasses, de-\\nscriptors, random, Sphinx, and more has been added, along with a general increase\\nin 2.X compatibility in both examples and narrative.\\n\\nThis edition also adds a new conclusion as Chapter 41 (on Python’s evolution), two\\nnew appendixes (on recent Python changes and the new Windows launcher), and one\\nnew chapter (on benchmarking: an expanded version of the former code timing exam-\\nple). See Appendix C for a concise summary of Python changes between the prior edition\\nand this one, as well as links to their coverage in the book. This appendix also sum-\\nmarizes initial differences between 2.X and 3.X in general that were first addressed in\\nthe prior edition, though some, such as new-style classes, span versions and simply\\nbecome mandated in 3.X (more on what the X’s mean in a moment).\\nPer the last bullet in the preceding list, this edition has also experienced some growth\\nbecause it gives fuller coverage to more advanced language features—which many of us\\nhave tried very hard to ignore as optional for the last decade, but which have now grown\\nmore common in Python code. As we’ll see, these tools make Python more powerful,\\nbut also raise the bar for newcomers, and may shift Python’s scope and definition.\\nBecause you might encounter any of these, this book covers them head-on, instead of\\npretending they do not exist.\\nDespite the updates, this edition retains most of the structure and content of the prior\\nedition, and is still designed to be a comprehensive learning resource for both the 2.X\\nand 3.X Python lines. While it is primarily focused on users of Python 3.3 and 2.7—\\nthe latest in the 3.X line and the likely last in the 2.X line—its historical perspective\\nalso makes it relevant to older Pythons that still see regular use today.\\nThough it’s impossible to predict the future, this book stresses fundamentals that have\\nbeen valid for nearly two decades, and will likely apply to future Pythons too. As usual,\\nI’ll be posting Python updates that impact this book at the book’s website described\\nahead. The “What’s New” documents in Python’s manuals set can also serve to fill in\\nthe gaps as Python surely evolves after this book is published.\\n\\nPreface | xxxv\\n\\n\\x0cThe Python 2.X and 3.X Lines\\nBecause it bears heavily on this book’s content, I need to say a few more words about\\nthe Python 2.X/3.X story up front. When the fourth edition of this book was written in\\n2009, Python had just become available in two flavors:\\n\\n• Version 3.0 was the first in the line of an emerging and incompatible mutation of\\n\\nthe language known generically as 3.X.\\n\\n• Version 2.6 retained backward compatibility with the vast body of existing Python\\n\\ncode, and was the latest in the line known collectively as 2.X.\\n\\nWhile 3.X was largely the same language, it ran almost no code written for prior re-\\nleases. It:\\n\\n• Imposed a Unicode model with broad consequences for strings, files, and libraries\\n• Elevated iterators and generators to a more pervasive role, as part of fuller func-\\n\\ntional paradigm\\n\\n• Mandated new-style classes, which merge with types, but grow more powerful and\\n\\ncomplex\\n\\n• Changed many fundamental tools and libraries, and replaced or removed others\\n\\nentirely\\n\\nThe mutation of print from statement to function alone, aesthetically sound as it may\\nbe, broke nearly every Python program ever written. And strategic potential aside, 3.X’s\\nmandatory Unicode and class models and ubiquitous generators made for a different\\nprogramming experience.\\nAlthough many viewed Python 3.X as both an improvement and the future of Python,\\nPython 2.X was still very widely used and was to be supported in parallel with Python\\n3.X for years to come. The majority of Python code in use was 2.X, and migration to\\n3.X seemed to be shaping up to be a slow process.\\n\\nThe 2.X/3.X Story Today\\nAs this fifth edition is being written in 2013, Python has moved on to versions 3.3 and\\n2.7, but this 2.X/3.X story is still largely unchanged. In fact, Python is now a dual-version\\nworld, with many users running both 2.X and 3.X according to their software goals and\\ndependencies. And for many newcomers, the choice between 2.X and 3.X remains one\\nof existing software versus the language’s cutting edge. Although many major Python\\npackages have been ported to 3.X, many others are still 2.X-only today.\\nTo some observers, Python 3.X is now seen as a sandbox for exploring new ideas, while\\n2.X is viewed as the tried-and-true Python, which doesn’t have all of 3.X’s features but\\nis  still  more  pervasive.  Others  still  see  Python  3.X  as  the  future,  a  view  that  seems\\nsupported by current core developer plans: Python 2.7 will continue to be supported\\nbut is to be the last 2.X, while 3.3 is the latest in the 3.X line’s continuing evolution.\\n\\nxxxvi\\n\\n| Preface\\n\\n\\x0cOn the other hand, initiatives such as PyPy—today a still 2.X-only implementation of\\nPython that offers stunning performance improvements—represent a 2.X future, if not\\nan outright faction.\\nAll opinions aside, almost five years after its release, 3.X has yet to supersede 2.X, or\\neven match its user base. As one metric, 2.X is still downloaded more often than 3.X\\nfor Windows at python.org today, despite the fact that this measure would be naturally\\nskewed to new users and the most recent release. Such statistics are prone to change,\\nof course, but after five years are indicative of 3.X uptake nonetheless. The existing 2.X\\nsoftware base still trumps 3.X’s language extensions for many. Moreover, being last in\\nthe 2.X line makes 2.7 a sort of de facto standard, immune to the constant pace of change\\nin the 3.X line—a positive to those who seek a stable base, and a negative to those who\\nseek growth and ongoing relevance.\\nPersonally, I think today’s Python world is large enough to accommodate both 3.X and\\n2.X; they seem to satisfy different goals and appeal to different camps, and there is\\nprecedence for this in other language families (C and C++, for example, have a long-\\nstanding coexistence, though they may differ more than Python 2.X and 3.X). More-\\nover, because they are so similar, the skills gained by learning either Python line transfer\\nalmost entirely to the other, especially if you’re aided by dual-version resources like\\nthis book. In fact, as long as you understand how they diverge, it’s often possible to\\nwrite code that runs on both.\\nAt the same time, this split presents a substantial dilemma for both programmers and\\nbook authors, which shows no signs of abating. While it would be easier for a book to\\npretend that Python 2.X never existed and cover 3.X only, this would not address the\\nneeds of the large Python user base that exists today. A vast amount of existing code\\nwas written for Python 2.X, and it won’t be going away anytime soon. And while some\\nnewcomers to the language can and should focus on Python 3.X, anyone who must use\\ncode written in the past needs to keep one foot in the Python 2.X world today. Since it\\nmay still be years before many third-party libraries and extensions are ported to Python\\n3.X, this fork might not be entirely temporary.\\n\\nCoverage for Both 3.X and 2.X\\nTo address this dichotomy and to meet the needs of all potential readers, this book has\\nbeen updated to cover both Python 3.3 and Python 2.7, and should apply to later re-\\nleases in both the 3.X and 2.X lines. It’s intended for programmers using Python 2.X,\\nprogrammers using Python 3.X, and programmers stuck somewhere between the two.\\nThat is, you can use this book to learn either Python line. Although 3.X is often em-\\nphasized, 2.X differences and tools are also noted along the way for programmers using\\nolder code. While the two versions are largely similar, they diverge in some important\\nways, and I’ll point these out as they crop up.\\n\\nPreface | xxxvii\\n\\n\\x0cFor instance, I’ll use 3.X print calls in most examples, but will also describe the 2.X\\nprint statement so you can make sense of earlier code, and will often use portable\\nprinting techniques that run on both lines. I’ll also freely introduce new features, such\\nas the nonlocal statement in 3.X and the string format method available as of 2.6 and\\n3.0, and will point out when such extensions are not present in older Pythons.\\nBy proxy, this edition addresses other Python version 2.X and 3.X releases as well,\\nthough some older version 2.X code may not be able to run all the examples here.\\nAlthough class decorators are available as of both Python 2.6 and 3.0, for example, you\\ncannot use them in an older Python 2.X that did not yet have this feature. Again, see\\nthe change tables in Appendix C for summaries of recent 2.X and 3.X changes.\\n\\nWhich Python Should I Use?\\nVersion choice may be mandated by your organization, but if you’re new to Python\\nand learning on your own, you may be wondering which version to install. The answer\\nhere depends on your goals. Here are a few suggestions on the choice.\\n\\nWhen to choose 3.X: new features, evolution\\n\\nIf you are learning Python for the first time and don’t need to use any existing 2.X\\ncode, I encourage you to begin with Python 3.X. It cleans up some longstanding\\nwarts in the language and trims some dated cruft, while retaining all the original\\ncore ideas and adding some nice new tools. For example, 3.X’s seamless Unicode\\nmodel and broader use of generators and functional techniques are seen by many\\nusers as assets. Many popular Python libraries and tools are already available for\\nPython 3.X, or will be by the time you read these words, especially given the con-\\ntinual improvements in the 3.X line. All new language evolution occurs in 3.X only,\\nwhich adds features and keeps Python relevant, but also makes language definition\\na constantly moving target—a tradeoff inherent on the leading edge.\\n\\nWhen to choose 2.X: existing code, stability\\n\\nIf you’ll be using a system based on Python 2.X, the 3.X line may not be an option\\nfor you today. However, you’ll find that this book addresses your concerns, too,\\nand will help if you migrate to 3.X in the future. You’ll also find that you’re in large\\ncompany. Every group I taught in 2012 was using 2.X only, and I still regularly see\\nuseful Python software in 2.X-only form. Moreover, unlike 3.X, 2.X is no longer\\nbeing changed—which is either an asset or liability, depending on whom you ask.\\nThere’s nothing wrong with using and writing 2.X code, but you may wish to keep\\ntabs on 3.X and its ongoing evolution as you do. Python’s future remains to be\\nwritten, and is largely up to its users, including you.\\n\\nWhen to choose both: version-neutral code\\n\\nProbably the best news here is that Python’s fundamentals are the same in both its\\nlines—2.X and 3.X differ in ways that many users will find minor, and this book\\nis designed to help you learn both. In fact, as long as you understand their differ-\\nences, it’s often straightforward to write version-neutral code that runs on both\\n\\nxxxviii\\n\\n| Preface\\n\\n\\x0cPythons, as we regularly will in this book. See Appendix C for pointers on 2.X/3.X\\nmigration and tips on writing code for both Python lines and audiences.\\n\\nRegardless of which version or versions you choose to focus on first, your skills will\\ntransfer directly to wherever your Python work leads you.\\n\\nAbout the Xs: Throughout this book, “3.X” and “2.X” are used to refer\\ncollectively to all releases in these two lines. For instance, 3.X includes\\n3.0 through 3.3, and future 3.X releases; 2.X means all from 2.0 through\\n2.7 (and presumably no others). More specific releases are mentioned\\nwhen a topic applies to it only (e.g., 2.7’s set literals and 3.3’s launcher\\nand namespace packages). This notation may occasionally be too broad\\n—some features labeled 2.X here may not be present in early 2.X releases\\nrarely  used  today—but  it  accommodates  a  2.X  line  that  has  already\\nspanned 13 years. The 3.X label is more easily and accurately applied\\nto this younger five-year-old line.\\n\\nThis Book’s Prerequisites and Effort\\nIt’s impossible to give absolute prerequisites for this book, because its utility and value\\ncan depend as much on reader motivation as on reader background. Both true beginners\\nand crusty programming veterans have used this book successfully in the past. If you\\nare motivated to learn Python, and willing to invest the time and focus it requires, this\\ntext will probably work for you.\\nJust how much time is required to learn Python? Although this will vary per learner,\\nthis book tends to work best when read. Some readers may use this book as an on-\\ndemand reference resource, but most people seeking Python mastery should expect to\\nspend at least weeks and probably months going through the material here, depending\\non how closely they follow along with its examples. As mentioned, it’s roughly equiv-\\nalent to a full-semester course on the Python language itself.\\nThat’s the estimate for learning just Python itself and the software skills required to use\\nit well. Though this book may suffice for basic scripting goals, readers hoping to pursue\\nsoftware development at large as a career should expect to devote additional time after\\nthis book to large-scale project experience, and possibly to follow-up texts such as\\nProgramming Python.2\\n\\n2. The standard disclaimer: I wrote this and another book mentioned earlier, which work together as a set:\\nLearning Python for language fundamentals, Programming Python for applications basics, and Python\\nPocket  Reference  as  a  companion  to  the  other  two.  All  three  derive  from  1995’s  original  and  broad\\nProgramming Python. I encourage you to explore the many Python books available today (I stopped\\ncounting at 200 at Amazon.com just now because there was no end in sight, and this didn’t include related\\nsubjects  like  Django).  My  own  publisher  has  recently  produced  Python-focused  books  on\\ninstrumentation, data mining, App Engine, numeric analysis, natural language processing, MongoDB,\\nAWS, and more—specific domains you may wish to explore once you’ve mastered Python language\\nfundamentals here. The Python story today is far too rich for any one book to address alone.\\n\\nPreface | xxxix\\n\\n\\x0cThat may not be welcome news to people looking for instant proficiency, but pro-\\ngramming is not a trivial skill (despite what you may have heard!). Today’s Python,\\nand software in general, are both challenging and rewarding enough to merit the effort\\nimplied by comprehensive books such as this. Here are a few pointers on using this\\nbook for readers on both sides of the experience spectrum:\\n\\nTo experienced programmers\\n\\nYou have an initial advantage and can move quickly through some earlier chapters;\\nbut you shouldn’t skip the core ideas, and may need to work at letting go of some\\nbaggage. In general terms, exposure to any programming or scripting before this\\nbook might be helpful because of the analogies it may provide. On the other hand,\\nI’ve also found that prior programming experience can be a handicap due to ex-\\npectations  rooted  in  other  languages  (it’s  far  too  easy  to  spot  the  Java  or  C++\\nprogrammers in classes by the first Python code they write!). Using Python well\\nrequires adopting its mindset. By focusing on key core concepts, this book is de-\\nsigned to help you learn to code Python in Python.\\n\\nTo true beginners\\n\\nYou can learn Python here too, as well as programming itself; but you may need\\nto work a bit harder, and may wish to supplement this text with gentler introduc-\\ntions. If you don’t consider yourself a programmer already, you will probably find\\nthis book useful too, but you’ll want to be sure to proceed slowly and work through\\nthe examples and exercises along the way. Also keep in mind that this book will\\nspend more time teaching Python itself than programming basics. If you find your-\\nself lost here, I encourage you to explore an introduction to programming in general\\nbefore tackling this book. Python’s website has links to many helpful resources for\\nbeginners.\\n\\nFormally,  this  book  is  designed  to  serve  as  a  first  Python  text  for  newcomers  of  all\\nkinds. It may not be an ideal resource for someone who has never touched a computer\\nbefore (for instance, we’re not going to spend any time exploring what a computer is),\\nbut I haven’t made many assumptions about your programming background or edu-\\ncation.\\nOn the other hand, I won’t insult readers by assuming they are “dummies,” either,\\nwhatever that means—it’s easy to do useful things in Python, and this book will show\\nyou how. The text occasionally contrasts Python with languages such as C, C++, Java,\\nand others, but you can safely ignore these comparisons if you haven’t used such lan-\\nguages in the past.\\n\\nThis Book’s Structure\\nTo help orient you, this section provides a quick rundown of the content and goals of\\nthe major parts of this book. If you’re anxious to get to it, you should feel free to skip\\n\\nxl\\n\\n| Preface\\n\\n\\x0cthis section (or browse the table of contents instead). To some readers, though, a book\\nthis large probably merits a brief roadmap up front.\\nBy design, each part covers a major functional area of the language, and each part is\\ncomposed of chapters focusing on a specific topic or aspect of the part’s area. In addi-\\ntion, each chapter ends with quizzes and their answers, and each part ends with larger\\nexercises, whose solutions show up in Appendix D.\\n\\nPractice matters: I strongly recommend that readers work through the\\nquizzes and exercises in this book, and work along with its examples in\\ngeneral if you can. In programming, there’s no substitute for practicing\\nwhat you’ve read. Whether you do it with this book or a project of your\\nown, actual coding is crucial if you want the ideas presented here to\\nstick.\\n\\nOverall, this book’s presentation is bottom-up because Python is too. The examples\\nand topics grow more challenging as we move along. For instance, Python’s classes are\\nlargely just packages of functions that process built-in types. Once you’ve mastered\\nbuilt-in types and functions, classes become a relatively minor intellectual leap. Because\\neach part builds on those preceding it this way, most readers will find a linear reading\\nmakes the most sense. Here’s a preview of the book’s main parts you’ll find along the\\nway:\\n\\nPart I\\n\\nWe begin with a general overview of Python that answers commonly asked initial\\nquestions—why people use the language, what it’s useful for, and so on. The first\\nchapter introduces the major ideas underlying the technology to give you some\\nbackground context. The rest of this part moves on to explore the ways that both\\nPython and programmers run programs. The main goal here is to give you just\\nenough information to be able to follow along with later examples and exercises.\\n\\nPart II\\n\\nNext, we begin our tour of the Python language, studying Python’s major built-in\\nobject types and what you can do with them in depth: numbers, lists, dictionaries,\\nand so on. You can get a lot done with these tools alone, and they are at the heart\\nof every Python script. This is the most substantial part of the book because we lay\\ngroundwork  here  for  later  chapters.  We’ll  also  explore  dynamic  typing  and  its\\nreferences—keys to using Python well—in this part.\\n\\nPart III\\n\\nThe next part moves on to introduce Python’s statements—the code you type to\\ncreate  and  process  objects  in  Python.  It  also  presents  Python’s  general  syntax\\nmodel. Although this part focuses on syntax, it also introduces some related tools\\n(such as the PyDoc system), takes a first look at iteration concepts, and explores\\ncoding alternatives.\\n\\nPreface | xli\\n\\n\\x0cPart IV\\n\\nThis part begins our look at Python’s higher-level program structure tools. Func-\\ntions turn out to be a simple way to package code for reuse and avoid code redun-\\ndancy. In this part, we will explore Python’s scoping rules, argument-passing tech-\\nniques,  the  sometimes-notorious  lambda,  and  more.  We’ll  also  revisit  iterators\\nfrom a functional programming perspective, introduce user-defined generators,\\nand learn how to time Python code to measure performance here.\\n\\nPart V\\n\\nPython modules let you organize statements and functions into larger components,\\nand this part illustrates how to create, use, and reload modules. We’ll also look at\\nsome more advanced topics here, such as module packages, module reloading,\\npackage-relative imports, 3.3’s new namespace packages, and the __name__ vari-\\nable.\\n\\nPart VI\\n\\nHere, we explore Python’s object-oriented programming tool, the class—an op-\\ntional but powerful way to structure code for customization and reuse, which al-\\nmost naturally minimizes redundancy. As you’ll see, classes mostly reuse ideas we\\nwill have covered by this point in the book, and OOP in Python is mostly about\\nlooking up names in linked objects with a special first argument in functions. As\\nyou’ll also see, OOP is optional in Python, but most find Python’s OOP to be much\\nsimpler than others, and it can shave development time substantially, especially\\nfor long-term strategic project development.\\n\\nPart VII\\n\\nWe  conclude  the  language  fundamentals  coverage  in  this  text  with  a  look  at\\nPython’s exception handling model and statements, plus a brief overview of de-\\nvelopment tools that will become more useful when you start writing larger pro-\\ngrams (debugging and testing tools, for instance). Although exceptions are a fairly\\nlightweight tool, this part appears after the discussion of classes because user-de-\\nfined exceptions should now all be classes. We also cover some more advanced\\ntopics, such as context managers, here.\\n\\nPart VIII\\n\\nIn  the  final  part,  we  explore  some  advanced  topics:  Unicode  and  byte  strings,\\nmanaged attribute tools like properties and descriptors, function and class deco-\\nrators, and metaclasses. These chapters are all optional reading, because not all\\nprogrammers need to understand the subjects they address. On the other hand,\\nreaders who must process internationalized text or binary data, or are responsible\\nfor developing APIs for other programmers to use, should find something of in-\\nterest in this part. The examples here are also larger than most of those in this book,\\nand can serve as self-study material.\\n\\nPart IX\\n\\nThe book wraps up with a set of four appendixes that give platform-specific tips\\nfor installing and using Python on various computers; present the new Windows\\n\\nxlii\\n\\n| Preface\\n\\n\\x0clauncher that ships with Python 3.3; summarize changes in Python addressed by\\nrecent editions and give links to their coverage here; and provide solutions to the\\nend-of-part exercises. Solutions to end-of-chapter quizzes appear in the chapters\\nthemselves.\\n\\nSee the table of contents for a finer-grained look at this book’s components.\\n\\nWhat This Book Is Not\\nGiven its relatively large audience over the years, some have inevitably expected this\\nbook to serve a role outside its scope. So now that I’ve told you what this book is, I also\\nwant to be clear on what it isn’t:\\n\\n• This book is a tutorial, not a reference.\\n• This book covers the language itself, not applications, standard libraries, or third-\\n\\nparty tools.\\n\\n• This  book  is  a  comprehensive  look  at  a  substantial  topic,  not  a  watered-down\\n\\noverview.\\n\\nBecause these points are key to this book’s content, I want to say a few more words\\nabout them up front.\\n\\nIt’s Not a Reference or a Guide to Specific Applications\\nThis book is a language tutorial, not a reference, and not an applications book. This is\\nby design: today’s Python—with its built-in types, generators, closures, comprehen-\\nsions, Unicode, decorators, and blend of procedural, object-oriented, and functional\\nprogramming paradigms—makes the core language a substantial topic all by itself, and\\na prerequisite to all your future Python work, in whatever domains you pursue. When\\nyou are ready for other resources, though, here are a few suggestions and reminders:\\n\\nReference resources\\n\\nAs implied by the preceding structural description, you can use the index and table\\nof contents to hunt for details, but there are no reference appendixes in this book.\\nIf you are looking for Python reference resources (and most readers probably will\\nbe very soon in their Python careers), I suggest the previously mentioned book that\\nI also wrote as a companion to this one—Python Pocket Reference—as well as other\\nreference books you’ll find with a quick search, and the standard Python reference\\nmanuals maintained at http://www.python.org. The latter of these are free, always\\nup to date, and available both on the Web and on your computer after a Windows\\ninstall.\\n\\nApplications and libraries\\n\\nAs also discussed earlier, this book is not a guide to specific applications such as\\nthe Web, GUIs, or systems programming. By proxy, this includes the libraries and\\n\\nPreface | xliii\\n\\n\\x0ctools used in applications work; although some standard libraries and tools are\\nintroduced here—including timeit, shelve, pickle, struct, json, pdb, os, urllib,\\nre, xml, random, PyDoc and IDLE—they are not officially in this book’s primary\\nscope. If you’re looking for more coverage on such topics and are already proficient\\nwith Python, I recommend the follow-up book Programming Python, among oth-\\ners. That book assumes this one as its prerequisite, though, so be sure you have a\\nfirm grasp of the core language first. Especially in an engineering domain like soft-\\nware, one must walk before one runs.\\n\\nIt’s Not the Short Story for People in a Hurry\\nAs you can tell from its size, this book also doesn’t skimp on the details: it presents the\\nfull Python language, not a brief look at a simplified subset. Along the way it also covers\\nsoftware principles that are essential to writing good Python code. As mentioned, this\\nis a multiple-week or -month book, designed to impart the skill level you’d acquire\\nfrom a full-term class on Python.\\nThis is also deliberate. Many of this book’s readers don’t need to acquire full-scale\\nsoftware development skills, of course, and some can absorb Python in a piecemeal\\nfashion. At the same time, because any part of the language may be used in code you\\nwill encounter, no part is truly optional for most programmers. Moreover, even casual\\nscripters and hobbyists need to know basic principles of software development in order\\nto code well, and even to use precoded tools properly.\\nThis book aims to address both of these needs—language and principles—in enough\\ndepth to be useful. In the end, though, you’ll find that Python’s more advanced tools,\\nsuch as its object-oriented and functional programming support, are relatively easy to\\nlearn once you’ve mastered their prerequisites—and you will, if you work through this\\nbook one chapter at a time.\\n\\nIt’s as Linear as Python Allows\\nSpeaking of reading order, this edition also tries hard to minimize forward references,\\nbut Python 3.X’s changes make this impossible in some cases (in fact, 3.X sometimes\\nseems to assume you already know Python while you’re learning it!). As a handful of\\nrepresentative examples:\\n\\n• Printing,  sorts,  the  string  format  method,  and  some  dict  calls  rely  on  function\\n\\nkeyword arguments.\\n\\n• Dictionary key lists and tests, and the list calls used around many tools, imply\\n\\niteration concepts.\\n\\n• Using exec to run code now assumes knowledge of file objects and interfaces.\\n• Coding new exceptions requires classes and OOP fundamentals.\\n\\nxliv | Preface\\n\\n\\x0c• And so on—even basic inheritance broaches advanced topics such as metaclasses\\n\\nand descriptors.\\n\\nPython  is  still  best  learned  as  a  progression  from  simple  to  advanced,  and  a  linear\\nreading here still makes the most sense. Still, some topics may require nonlinear jumps\\nand random lookups. To minimize these, this book will point out forward dependencies\\nwhen they occur, and will ease their impacts as much as possible.\\n\\nBut if your time is tight: Though depth is crucial to mastering Python,\\nsome readers may have limited time. If you are interested in starting out\\nwith a quick Python tour, I suggest Chapter 1, Chapter 4, Chapter 10,\\nand Chapter 28 (and perhaps 26)—a short survey that will hopefully\\npique your interest in the more complete story told in the rest of the\\nbook,  and  which  most  readers  will  need  in  today’s  Python  software\\nworld. In general, this book is intentionally layered this way to make its\\nmaterial easier to absorb—with introductions followed by details, so\\nyou can start with overviews, and dig deeper over time. You don’t need\\nto read this book all at once, but its gradual approach is designed to help\\nyou tackle its material eventually.\\n\\nThis Book’s Programs\\nIn general, this book has always strived to be agnostic about both Python versions and\\nplatforms. It’s designed to be useful to all Python users. Nevertheless, because Python\\nchanges over time and platforms tend to differ in pragmatic ways, I need to describe\\nthe specific systems you’ll see in action in most examples here.\\n\\nPython Versions\\nThis fifth edition of this book, and all the program examples in it, are based on Python\\nversions 3.3 and 2.7. In addition, many of its examples run under prior 3.X and 2.X\\nreleases, and notes about the history of language changes in earlier versions are mixed\\nin along the way for users of older Pythons.\\nBecause this text focuses on the core language, however, you can be fairly sure that\\nmost of what it has to say won’t change very much in future releases of Python, as noted\\nearlier. Most of this book applies to earlier Python versions, too, except when it does\\nnot; naturally, if you try using extensions added after a release you’re using, all bets are\\noff. As a rule of thumb, the latest Python is the best Python if you are able to upgrade.\\nBecause this book focuses on the core language, most of it also applies to both Jython\\nand IronPython, the Java- and .NET-based Python language implementations, as well\\nas other Python implementations such as Stackless and PyPy (described in Chapter 2).\\nSuch alternatives differ mostly in usage details, not language.\\n\\nPreface | xlv\\n\\n\\x0cPlatforms\\nThe examples in this book were run on a Windows 7 and 8 ultrabook,3 though Python’s\\nportability makes this mostly a moot point, especially in this fundamentals-focused\\nbook. You’ll notice a few Windows-isms—including command-line prompts, a hand-\\nful of screenshots, install pointers, and an appendix on the new Windows launcher in\\n3.3—but this reflects the fact that most Python newcomers will probably get started\\non this platform, and these can be safely ignored by users of other operating systems.\\nI also give a few launching details for other platforms like Linux, such as “#!” line use,\\nbut as we’ll see in Chapter 3 and Appendix B, the 3.3 Windows launcher makes even\\nthis a more portable technique.\\n\\nFetching This Book’s Code\\nSource code for the book’s examples, as well as exercise solutions, can be fetched as a\\nzip file from the book’s website at the following address:\\n\\nhttp://oreil.ly/LearningPython-5E\\n\\nThis site includes both all the code in this book as well as package usage instructions,\\nso I’ll defer to it for more details. Of course, the examples work best in the context of\\ntheir appearance in this book, and you’ll need some background knowledge on running\\nPython programs in general to make use of them. We’ll study startup details in Chap-\\nter 3, so please stay tuned for information on this front.\\n\\nUsing This Book’s Code\\nThe code in my Python books is designed to teach, and I’m glad when it assists readers\\nin that capacity. O’Reilly itself has an official policy regarding reusing the book’s ex-\\namples in general, which I’ve pasted into the rest of this section for reference:\\n\\nThis book is here to help you get your job done. In general, you may use the code in this\\nbook in your programs and documentation. You do not need to contact us for permission\\nunless you’re reproducing a significant portion of the code. For example, writing a pro-\\ngram that uses several chunks of code from this book does not require permission. Selling\\nor distributing a CD-ROM of examples from O’Reilly books does require permission.\\nAnswering a question by citing this book and quoting example code does not require\\npermission. Incorporating a significant amount of example code from this book into your\\nproduct’s documentation does require permission.\\n\\n3. Mostly under Windows 7, but it’s irrelevant to this book. At this writing, Python installs on Windows 8\\nand runs in its desktop mode, which is essentially the same as Windows 7 without a Start button as I\\nwrite this (you may need to create shortcuts for former Start button menu items). Support for WinRT/\\nMetro “apps” is still pending. See Appendix A for more details. Frankly, the future of Windows 8 is\\nunclear as I type these words, so this book will be as version-neutral as possible.\\n\\nxlvi\\n\\n| Preface\\n\\n\\x0cWe appreciate, but do not require, attribution. An attribution usually includes the title,\\nauthor, publisher, and ISBN. For example: “Learning Python, Fifth Edition, by Mark\\nLutz. Copyright 2013 Mark Lutz, 978-1-4493-5573-9.”\\n\\nIf you feel your use of code examples falls outside fair use or the permission given above,\\nfeel free to contact us at permissions@oreilly.com.\\n\\nFont Conventions\\nThis book’s mechanics will make more sense once you start reading it, of course, but\\nas a reference, this book uses the following typographical conventions:\\n\\nItalic\\n\\nUsed  for  email  addresses,  URLs,  filenames,  pathnames,  and  emphasizing  new\\nterms when they are first introduced\\n\\nConstant width\\n\\nUsed for program code, the contents of files and the output from commands, and\\nto designate modules, methods, statements, and system commands\\n\\nConstant width bold\\n\\nUsed in code sections to show commands or text that would be typed by the user,\\nand, occasionally, to highlight portions of code\\n\\nConstant width italic\\n\\nUsed for replaceables and some comments in code sections\\n\\nIndicates a tip, suggestion, or general note relating to the nearby text.\\n\\nIndicates a warning or caution relating to the nearby text.\\n\\nYou’ll also find occasional sidebars (delimited by boxes) and footnotes (at page end)\\nthroughout, which are often optional reading, but provide additional context on the\\ntopics being presented. The sidebars in “Why You Will Care: Slices” on page 204,\\nfor example, often give example use cases for the subjects being explored.\\n\\nBook Updates and Resources\\nImprovements happen (and so do mis^H^H^H typos). Updates, supplements, and cor-\\nrections (a.k.a. errata) for this book will be maintained on the Web, and may be sug-\\ngested at either the publisher’s website or by email. Here are the main coordinates:\\n\\nPreface | xlvii\\n\\n\\x0cPublisher’s site: http://oreil.ly/LearningPython-5E\\n\\nThis site will maintain this edition’s official list of book errata, and chronicle spe-\\ncific patches applied to the text in reprints. It’s also the official site for the book’s\\nexamples as described earlier.\\n\\nAuthor’s site: http://www.rmi.net/~lutz/about-lp5e.html\\n\\nThis site will be used to post more general updates related to this text or Python\\nitself—a hedge against future changes, which should be considered a sort of virtual\\nappendix to this book.\\n\\nMy publisher also has an email address for comments and technical questions about\\nthis book:\\n\\nbookquestions@oreilly.com\\n\\nFor more information about my publisher’s books, conferences, Resource Centers, and\\nthe O’Reilly Network, see its general website:\\n\\nhttp://www.oreilly.com\\n\\nFor more on my books, see my own book support site:\\n\\nhttp://rmi.net/~lutz\\n\\nAlso be sure to search the Web if any of the preceding links become invalid over time;\\nif I could become more clairvoyant, I would, but the Web changes faster than published\\nbooks.\\n\\nAcknowledgments\\nAs I write this fifth edition of this book in 2013, it’s difficult to not be somewhat ret-\\nrospective. I have now been using and promoting Python for 21 years, writing books\\nabout it for 18, and teaching live classes on it for 16. Despite the passage of time, I’m\\nstill regularly amazed at how successful Python has been—in ways that most of us could\\nnot possibly have imagined in the early 1990s. So at the risk of sounding like a hopelessly\\nself-absorbed author, I hope you’ll pardon a few closing words of history and gratitude\\nhere.\\n\\nThe Backstory\\nMy own Python history predates both Python 1.0 and the Web (and goes back to a\\ntime  when  an  install  meant  fetching  email  messages,  concatenating,  decoding,  and\\nhoping it all somehow worked). When I first discovered Python as a frustrated C++\\nsoftware developer in 1992, I had no idea what an impact it would have on the next\\ntwo  decades  of  my  life.  Two  years  after  writing  the  first  edition  of  Programming\\nPython in 1995 for Python 1.3, I began traveling around the country and world teaching\\nPython to beginners and experts. Since finishing the first edition of Learning Python in\\n\\nxlviii\\n\\n| Preface\\n\\n\\x0c1999, I’ve been an independent Python trainer and writer, thanks in part to Python’s\\nphenomenal growth in popularity.\\nHere’s the damage so far. I’ve now written 13 Python books (5 of this, and 4 of two\\nothers), which have together sold some 400,000 units by my data. I’ve also been teach-\\ning Python for over a decade and a half; have taught some 260 Python training sessions\\nin the U.S., Europe, Canada, and Mexico; and have met roughly 4,000 students along\\nthe way. Besides propelling me toward frequent flyer utopia, these classes helped me\\nrefine this text and my other Python books. Teaching honed the books, and vice versa,\\nwith the net result that my books closely parallel what happens in my classes, and can\\nserve as a viable alternative to them.\\nAs for Python itself, in recent years it has grown to become one of the top 5 to 10 most\\nwidely used programming languages in the world (depending on which source you cite\\nand when you cite it). Because we’ll be exploring Python’s status in the first chapter of\\nthis book, I’ll defer the rest of this story until then.\\n\\nPython Thanks\\nBecause teaching teaches teachers to teach, this book owes much to my live classes. I’d\\nlike to thank all the students who have participated in my courses during the last 16\\nyears. Along with changes in Python itself, your feedback played a major role in shaping\\nthis text; there’s nothing quite as instructive as watching 4,000 people repeat the same\\nbeginner mistakes live and in person! This book’s recent editions owe their training-\\nbased changes primarily to recent classes, though every class held since 1997 has in\\nsome way helped refine this book. I’d like to thank clients who hosted classes in Dublin,\\nMexico City, Barcelona, London, Edmonton, and Puerto Rico; such experiences have\\nbeen one of my career’s most lasting rewards.\\nBecause writing teaches writers to write, this book also owes much to its audience. I\\nwant to thank the countless readers who took time to offer suggestions over the last 18\\nyears, both online and in person. Your feedback has also been vital to this book’s evo-\\nlution and a substantial factor in its success, a benefit that seems inherent in the open\\nsource world. Reader comments have run the gamut from “You should be banned from\\nwriting books” to “God bless you for writing this book”; if consensus is possible in\\nsuch matters it probably lies somewhere between these two, though to borrow a line\\nfrom Tolkien: the book is still too short.\\nI’d  also  like  to  express  my  gratitude  to  everyone  who  played  a  part  in  this  book’s\\nproduction. To all those who have helped make this book a solid product over the years\\n—including its editors, formatters, marketers, technical reviewers, and more. And to\\nO’Reilly for giving me a chance to work on 13 book projects; it’s been net fun (and only\\nfeels a little like the movie Groundhog Day).\\nAdditional thanks is due to the entire Python community; like most open source sys-\\ntems, Python is the product of many unsung efforts. It’s been my privilege to watch\\n\\nPreface | xlix\\n\\n\\x0cPython grow from a new kid on the scripting languages block to a widely used tool,\\ndeployed in some fashion by almost every organization writing software. Technical\\ndisagreements aside, that’s been an exciting endeavor to be a part of.\\nI also want to thank my original editor at O’Reilly, the late Frank Willison. This book\\nwas largely Frank’s idea. He had a profound impact on both my career and the success\\nof Python when it was new, a legacy that I remember each time I’m tempted to misuse\\nthe word “only.”\\n\\nPersonal Thanks\\nFinally, a few more personal notes of thanks. To the late Carl Sagan, for inspiring an\\n18-year-old kid from Wisconsin. To my Mother, for courage. To my siblings, for the\\ntruths to be found in museum peanuts. To the book The Shallows, for a much-needed\\nwakeup call.\\nTo my son Michael and daughters Samantha and Roxanne, for who you are. I’m not\\nquite sure when you grew up, but I’m proud of how you did, and look forward to seeing\\nwhere life takes you next.\\nAnd to my wife Vera, for patience, proofing, Diet Cokes, and pretzels. I’m glad I finally\\nfound you. I don’t know what the next 50 years hold, but I do know that I hope to\\nspend all of them holding you.\\n\\n—Mark Lutz, Amongst the Larch, Spring 2013\\n\\nl\\n\\n| Preface\\n\\n\\x0cPART I\\nGetting Started\\n\\n\\x0c\\x0cCHAPTER 1\\nA Python Q&A Session\\n\\nIf you’ve bought this book, you may already know what Python is and why it’s an\\nimportant tool to learn. If you don’t, you probably won’t be sold on Python until you’ve\\nlearned the language by reading the rest of this book and have done a project or two.\\nBut before we jump into details, this first chapter of this book will briefly introduce\\nsome of the main reasons behind Python’s popularity. To begin sculpting a definition\\nof Python, this chapter takes the form of a question-and-answer session, which poses\\nsome of the most common questions asked by beginners.\\n\\nWhy Do People Use Python?\\nBecause there are many programming languages available today, this is the usual first\\nquestion of newcomers. Given that there are roughly 1 million Python users out there\\nat the moment, there really is no way to answer this question with complete accuracy;\\nthe choice of development tools is sometimes based on unique constraints or personal\\npreference.\\nBut after teaching Python to roughly 260 groups and over 4,000 students during the\\nlast 16 years, I have seen some common themes emerge. The primary factors cited by\\nPython users seem to be these:\\n\\nSoftware quality\\n\\nFor many, Python’s focus on readability, coherence, and software quality in general\\nsets it apart from other tools in the scripting world. Python code is designed to be\\nreadable, and hence reusable and maintainable—much more so than traditional\\nscripting languages. The uniformity of Python code makes it easy to understand,\\neven if you did not write it. In addition, Python has deep support for more advanced\\nsoftware reuse mechanisms, such as object-oriented (OO) and function program-\\nming.\\n\\nDeveloper productivity\\n\\nPython boosts developer productivity many times beyond compiled or statically\\ntyped languages such as C, C++, and Java. Python code is typically one-third to\\n\\n3\\n\\n\\x0cone-fifth the size of equivalent C++ or Java code. That means there is less to type,\\nless to debug, and less to maintain after the fact. Python programs also run imme-\\ndiately, without the lengthy compile and link steps required by some other tools,\\nfurther boosting programmer speed.\\n\\nProgram portability\\n\\nMost Python programs run unchanged on all major computer platforms. Porting\\nPython code between Linux and Windows, for example, is usually just a matter of\\ncopying a script’s code between machines. Moreover, Python offers multiple op-\\ntions for coding portable graphical user interfaces, database access programs, web-\\nbased systems, and more. Even operating system interfaces, including program\\nlaunches and directory processing, are as portable in Python as they can possibly\\nbe.\\n\\nSupport libraries\\n\\nPython comes with a large collection of prebuilt and portable functionality, known\\nas  the  standard  library.  This  library  supports  an  array  of  application-level  pro-\\ngramming  tasks,  from  text  pattern  matching  to  network  scripting.  In  addition,\\nPython can be extended with both homegrown libraries and a vast collection of\\nthird-party application support software. Python’s third-party domain offers tools\\nfor website construction, numeric programming, serial port access, game devel-\\nopment, and much more (see ahead for a sampling). The NumPy extension, for\\ninstance, has been described as a free and more powerful equivalent to the Matlab\\nnumeric programming system.\\n\\nComponent integration\\n\\nPython scripts can easily communicate with other parts of an application, using a\\nvariety of integration mechanisms. Such integrations allow Python to be used as a\\nproduct customization and extension tool. Today, Python code can invoke C and\\nC++ libraries, can be called from C and C++ programs, can integrate with Java\\nand .NET components, can communicate over frameworks such as COM and Sil-\\nverlight, can interface with devices over serial ports, and can interact over networks\\nwith interfaces like SOAP, XML-RPC, and CORBA. It is not a standalone tool.\\n\\nEnjoyment\\n\\nBecause of Python’s ease of use and built-in toolset, it can make the act of pro-\\ngramming more pleasure than chore. Although this may be an intangible benefit,\\nits effect on productivity is an important asset.\\n\\nOf these factors, the first two (quality and productivity) are probably the most com-\\npelling benefits to most Python users, and merit a fuller description.\\n\\nSoftware Quality\\nBy design, Python implements a deliberately simple and readable syntax and a highly\\ncoherent programming model. As a slogan at a past Python conference attests, the net\\nresult is that Python seems to “fit your brain”—that is, features of the language interact\\n\\n4 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cin consistent and limited ways and follow naturally from a small set of core concepts.\\nThis makes the language easier to learn, understand, and remember. In practice, Python\\nprogrammers do not need to constantly refer to manuals when reading or writing code;\\nit’s a consistently designed system that many find yields surprisingly uniform code.\\nBy philosophy, Python adopts a somewhat minimalist approach. This means that al-\\nthough there are usually multiple ways to accomplish a coding task, there is usually\\njust one obvious way, a few less obvious alternatives, and a small set of coherent in-\\nteractions everywhere in the language. Moreover, Python doesn’t make arbitrary deci-\\nsions for you; when interactions are ambiguous, explicit intervention is preferred over\\n“magic.” In the Python way of thinking, explicit is better than implicit, and simple is\\nbetter than complex.1\\nBeyond such design themes, Python includes tools such as modules and OOP that\\nnaturally promote code reusability. And because Python is focused on quality, so too,\\nnaturally, are Python programmers.\\n\\nDeveloper Productivity\\nDuring the great Internet boom of the mid-to-late 1990s, it was difficult to find enough\\nprogrammers to implement software projects; developers were asked to implement\\nsystems as fast as the Internet evolved. In later eras of layoffs and economic recession,\\nthe picture shifted. Programming staffs were often asked to accomplish the same tasks\\nwith even fewer people.\\nIn both of these scenarios, Python has shined as a tool that allows programmers to get\\nmore done with less effort. It is deliberately optimized for speed of development—its\\nsimple syntax, dynamic typing, lack of compile steps, and built-in toolset allow pro-\\ngrammers to develop programs in a fraction of the time needed when using some other\\ntools. The net effect is that Python typically boosts developer productivity many times\\nbeyond the levels supported by traditional languages. That’s good news in both boom\\nand bust times, and everywhere the software industry goes in between.\\n\\nIs Python a “Scripting Language”?\\nPython is a general-purpose programming language that is often applied in scripting\\nroles. It is commonly defined as an object-oriented scripting language—a definition that\\nblends support for OOP with an overall orientation toward scripting roles. If pressed\\nfor a one-liner, I’d say that Python is probably better known as a general-purpose pro-\\n\\n1. For  a  more  complete  look  at  the  Python  philosophy,  type  the  command  import  this  at  any  Python\\ninteractive prompt (you’ll see how in Chapter 3). This invokes an “Easter egg” hidden in Python—a\\ncollection  of  design  principles  underlying  Python  that  permeate  both  the  language  and  its  user\\ncommunity. Among them, the acronym EIBTI is now fashionable jargon for the “explicit is better than\\nimplicit” rule. These principles are not religion, but are close enough to qualify as a Python motto and\\ncreed, which we’ll be quoting from often in this book.\\n\\nIs Python a “Scripting Language”?\\n\\n| 5\\n\\n\\x0cgramming language that blends procedural, functional, and object-oriented paradigms—\\na statement that captures the richness and scope of today’s Python.\\nStill, the term “scripting” seems to have stuck to Python like glue, perhaps as a contrast\\nwith larger programming effort required by some other tools. For example, people often\\nuse the word “script” instead of “program” to describe a Python code file. In keeping\\nwith this tradition, this book uses the terms “script” and “program” interchangeably,\\nwith a slight preference for “script” to describe a simpler top-level file and “program”\\nto refer to a more sophisticated multifile application.\\nBecause  the  term  “scripting  language”  has  so  many  different  meanings  to  different\\nobservers, though, some would prefer that it not be applied to Python at all. In fact,\\npeople tend to make three very different associations, some of which are more useful\\nthan others, when they hear Python labeled as such:\\n\\nShell tools\\n\\nSometimes when people hear Python described as a scripting language, they think\\nit means that Python is a tool for coding operating-system-oriented scripts. Such\\nprograms are often launched from console command lines and perform tasks such\\nas processing text files and launching other programs.\\nPython programs can and do serve such roles, but this is just one of dozens of\\ncommon Python application domains. It is not just a better shell-script language.\\n\\nControl language\\n\\nTo others, scripting refers to a “glue” layer used to control and direct (i.e., script)\\nother application components. Python programs are indeed often deployed in the\\ncontext of larger applications. For instance, to test hardware devices, Python pro-\\ngrams may call out to components that give low-level access to a device. Similarly,\\nprograms  may  run  bits  of  Python  code  at  strategic  points  to  support  end-user\\nproduct customization without the need to ship and recompile the entire system’s\\nsource code.\\nPython’s simplicity makes it a naturally flexible control tool. Technically, though,\\nthis is also just a common Python role; many (perhaps most) Python programmers\\ncode standalone scripts without ever using or knowing about any integrated com-\\nponents. It is not just a control language.\\n\\nEase of use\\n\\nProbably the best way to think of the term “scripting language” is that it refers to\\na simple language used for quickly coding tasks. This is especially true when the\\nterm is applied to Python, which allows much faster program development than\\ncompiled languages like C++. Its rapid development cycle fosters an exploratory,\\nincremental mode of programming that has to be experienced to be appreciated.\\nDon’t be fooled, though—Python is not just for simple tasks. Rather, it makes tasks\\nsimple by its ease of use and flexibility. Python has a simple feature set, but it allows\\nprograms to scale up in sophistication as needed. Because of that, it is commonly\\nused for quick tactical tasks and longer-term strategic development.\\n\\n6 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cSo, is Python a scripting language or not? It depends on whom you ask. In general, the\\nterm “scripting” is probably best used to describe the rapid and flexible mode of de-\\nvelopment that Python supports, rather than a particular application domain.\\n\\nOK, but What’s the Downside?\\nAfter using it for 21 years, writing about it for 18, and teaching it for 16, I’ve found that\\nthe only significant universal downside to Python is that, as currently implemented, its\\nexecution speed may not always be as fast as that of fully compiled and lower-level\\nlanguages such as C and C++. Though relatively rare today, for some tasks you may\\nstill occasionally need to get “closer to the iron” by using lower-level languages such\\nas these that are more directly mapped to the underlying hardware architecture.\\nWe’ll talk about implementation concepts in detail later in this book. In short, the\\nstandard implementations of Python today compile (i.e., translate) source code state-\\nments to an intermediate format known as byte code and then interpret the byte code.\\nByte code provides portability, as it is a platform-independent format. However, be-\\ncause Python is not normally compiled all the way down to binary machine code (e.g.,\\ninstructions for an Intel chip), some programs will run more slowly in Python than in\\na fully compiled language like C. The PyPy system discussed in the next chapter can\\nachieve a 10X to 100X speedup on some code by compiling further as your program\\nruns, but it’s a separate, alternative implementation.\\nWhether you will ever care about the execution speed difference depends on what kinds\\nof programs you write. Python has been optimized numerous times, and Python code\\nruns fast enough by itself in most application domains. Furthermore, whenever you do\\nsomething “real” in a Python script, like processing a file or constructing a graphical\\nuser interface (GUI), your program will actually run at C speed, since such tasks are\\nimmediately dispatched to compiled C code inside the Python interpreter. More fun-\\ndamentally, Python’s speed-of-development gain is often far more important than any\\nspeed-of-execution loss, especially given modern computer speeds.\\nEven at today’s CPU speeds, though, there still are some domains that do require op-\\ntimal execution speeds. Numeric programming and animation, for example, often need\\nat least their core number-crunching components to run at C speed (or better). If you\\nwork  in  such  a  domain,  you  can  still  use  Python—simply  split  off  the  parts  of  the\\napplication that require optimal speed into compiled extensions, and link those into\\nyour system for use in Python scripts.\\nWe won’t talk about extensions much in this text, but this is really just an instance of \\nthe Python-as-control-language role we discussed earlier. A prime example of this dual\\nlanguage strategy is the NumPy numeric programming extension for Python; by com-\\nbining compiled and optimized numeric extension libraries with the Python language,\\nNumPy turns Python into a numeric programming tool that is simultaneously efficient\\nand easy to use. When needed, such extensions provide a powerful optimization tool.\\n\\nOK, but What’s the Downside?\\n\\n| 7\\n\\n\\x0cOther Python Tradeoffs: The Intangible Bits\\n\\nI mentioned that execution speed is the only major downside to Python. That’s indeed\\nthe case for most Python users, and especially for newcomers. Most people find Python\\nto be easy to learn and fun to use, especially when compared with its contemporaries\\nlike Java, C#, and C++. In the interest of full disclosure, though, I should also note up\\nfront some more abstract tradeoffs I’ve observed in my two decades in the Python world\\n—both as an educator and developer.\\n\\nAs an educator, I’ve sometimes found the rate of change in Python and its libraries to\\nbe a negative, and have on occasion lamented its growth over the years. This is partly\\nbecause trainers and book authors live on the front lines of such things—it’s been my\\njob to teach the language despite its constant change, a task at times akin to chronicling\\nthe herding of cats! Still, it’s a broadly shared concern. As we’ll see in this book, Python’s\\noriginal “keep it simple” motif is today often subsumed by a trend toward more so-\\nphisticated solutions at the expense of the learning curve of newcomers. This book’s\\nsize is indirect evidence of this trend.\\n\\nOn the other hand, by most measures Python is still much simpler than its alternatives,\\nand perhaps only as complex as it needs to be given the many roles it serves today. Its\\noverall coherence and open nature remain compelling features to most. Moreover, not\\neveryone  needs  to  stay  up  to  date  with  the  cutting  edge—as  Python  2.X’s  ongoing\\npopularity clearly shows.\\n\\nAs a developer, I also at times question the tradeoffs inherent in Python’s “batteries\\nincluded” approach to development. Its emphasis on prebuilt tools can add dependen-\\ncies  (what  if  a  battery  you  use  is  changed,  broken,  or  deprecated?),  and  encourage\\nspecial-case solutions over general principles that may serve users better in the long run\\n(how can you evaluate or use a tool well if you don’t understand its purpose?). We’ll\\nsee examples of both of these concerns in this book.\\n\\nFor typical users, and especially for hobbyists and beginners, Python’s toolset approach\\nis a major asset. But you shouldn’t be surprised when you outgrow precoded tools, and\\ncan benefit from the sorts of skills this book aims to impart. Or, to paraphrase a proverb:\\ngive people a tool, and they’ll code for a day; teach them how to build tools, and they’ll\\ncode for a lifetime. This book’s job is more the latter than the former.\\n\\nAs mentioned elsewhere in this chapter, both Python and its toolbox model are also\\nsusceptible to downsides common to open source projects in general—the potential\\ntriumph of the personal preference of the few over common usage of the many, and the\\noccasional  appearance  of  anarchy  and  even  elitism—though  these  tend  to  be  most\\ngrievous on the leading edge of new releases.\\n\\nWe’ll return to some of these tradeoffs at the end of the book, after you’ve learned\\nPython well enough to draw your own conclusions. As an open source system, what\\nPython “is” is up to its users to define. In the end, Python is more popular today than\\never, and its growth shows no signs of abating. To some, that may be a more telling\\nmetric than individual opinions, both pro and con.\\n\\n8 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cWho Uses Python Today?\\nAt this writing, the best estimate anyone can seem to make of the size of the Python\\nuser base is that there are roughly 1 million Python users around the world today (plus\\nor minus a few). This estimate is based on various statistics, like download rates, web\\nstatistics, and developer surveys. Because Python is open source, a more exact count is\\ndifficult—there are no license registrations to tally. Moreover, Python is automatically\\nincluded with Linux distributions, Macintosh computers, and a wide range of products\\nand hardware, further clouding the user-base picture.\\nIn general, though, Python enjoys a large user base and a very active developer com-\\nmunity. It is generally considered to be in the top 5 or top 10 most widely used pro-\\ngramming languages in the world today (its exact ranking varies per source and date).\\nBecause Python has been around for over two decades and has been widely used, it is\\nalso very stable and robust.\\nBesides being leveraged by individual users, Python is also being applied in real revenue-\\ngenerating  products  by  real  companies.  For  instance,  among  the  generally  known\\nPython user base:\\n\\n• Google makes extensive use of Python in its web search systems.\\n• The popular YouTube video sharing service is largely written in Python.\\n• The Dropbox storage service codes both its server and desktop client software pri-\\n\\nmarily in Python.\\n\\n• The Raspberry Pi single-board computer promotes Python as its educational lan-\\n\\nguage.\\n\\n• EVE Online, a massively multiplayer online game (MMOG) by CCP Games, uses\\n\\nPython broadly.\\n\\n• The  widespread  BitTorrent  peer-to-peer  file  sharing  system  began  its  life  as  a\\n\\nPython program.\\n\\n• Industrial Light & Magic, Pixar, and others use Python in the production of ani-\\n\\nmated movies.\\n\\n• ESRI uses Python as an end-user customization tool for its popular GIS mapping\\n\\nproducts.\\n\\n• Google’s App Engine web development framework uses Python as an application\\n\\nlanguage.\\n\\n• The IronPort email server product uses more than 1 million lines of Python code\\n\\nto do its job.\\n\\n• Maya,  a  powerful  integrated  3D  modeling  and  animation  system,  provides  a\\n\\nPython scripting API.\\n\\n• The NSA uses Python for cryptography and intelligence analysis.\\n• iRobot uses Python to develop commercial and military robotic devices.\\n\\nWho Uses Python Today?\\n\\n| 9\\n\\n\\x0c• The  Civilization  IV  game’s  customizable  scripted  events  are  written  entirely  in\\n\\nPython.\\n\\n• The One Laptop Per Child (OLPC) project built its user interface and activity model\\n\\nin Python.\\n\\n• Netflix and Yelp have both documented the role of Python in their software infra-\\n\\nstructures.\\n\\n• Intel, Cisco, Hewlett-Packard, Seagate, Qualcomm, and IBM use Python for hard-\\n\\nware testing.\\n\\n• JPMorgan Chase, UBS, Getco, and Citadel apply Python to financial market fore-\\n\\ncasting.\\n\\n• NASA, Los Alamos, Fermilab, JPL, and others use Python for scientific program-\\n\\nming tasks.\\n\\nAnd so on—though this list is representative, a full accounting is beyond this book’s\\nscope, and is almost guaranteed to change over time. For an up-to-date sampling of\\nadditional Python users, applications, and software, try the following pages currently\\nat Python’s site and Wikipedia, as well as a search in your favorite web browser:\\n\\n• Success stories: http://www.python.org/about/success\\n• Application domains: http://www.python.org/about/apps\\n• User quotes: http://www.python.org/about/quotes\\n• Wikipedia page: http://en.wikipedia.org/wiki/List_of_Python_software\\n\\nProbably the only common thread among the companies using Python today is that\\nPython is used all over the map, in terms of application domains. Its general-purpose\\nnature makes it applicable to almost all fields, not just one. In fact, it’s safe to say that\\nvirtually every substantial organization writing software is using Python, whether for\\nshort-term tactical tasks, such as testing and administration, or for long-term strategic\\nproduct development. Python has proven to work well in both modes.\\n\\nWhat Can I Do with Python?\\nIn addition to being a well-designed programming language, Python is useful for ac-\\ncomplishing real-world tasks—the sorts of things developers do day in and day out.\\nIt’s commonly used in a variety of domains, as a tool for scripting other components\\nand  implementing  standalone  programs.  In  fact,  as  a  general-purpose  language,\\nPython’s roles are virtually unlimited: you can use it for everything from website de-\\nvelopment and gaming to robotics and spacecraft control.\\nHowever, the most common Python roles currently seem to fall into a few broad cat-\\negories. The next few sections describe some of Python’s most common applications\\ntoday, as well as tools used in each domain. We won’t be able to explore the tools\\n\\n10 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cmentioned here in any depth—if you are interested in any of these topics, see the Python\\nwebsite or other resources for more details.\\n\\nSystems Programming\\nPython’s  built-in  interfaces  to  operating-system  services  make  it  ideal  for  writing\\nportable, maintainable system-administration tools and utilities (sometimes called shell\\ntools). Python programs can search files and directory trees, launch other programs, do\\nparallel processing with processes and threads, and so on.\\nPython’s standard library comes with POSIX bindings and support for all the usual OS\\ntools: environment variables, files, sockets, pipes, processes, multiple threads, regular\\nexpression pattern matching, command-line arguments, standard stream interfaces,\\nshell-command launchers, filename expansion, zip file utilities, XML and JSON pars-\\ners, CSV file handlers, and more. In addition, the bulk of Python’s system interfaces\\nare designed to be portable; for example, a script that copies directory trees typically\\nruns unchanged on all major Python platforms. The Stackless Python implementation,\\ndescribed  in  Chapter  2  and  used  by  EVE  Online,  also  offers  advanced  solutions  to\\nmultiprocessing requirements.\\n\\nGUIs\\nPython’s simplicity and rapid turnaround also make it a good match for graphical user\\ninterface programming on the desktop. Python comes with a standard object-oriented\\ninterface to the Tk GUI API called tkinter (Tkinter in 2.X) that allows Python programs\\nto implement portable GUIs with a native look and feel. Python/tkinter GUIs run un-\\nchanged on Microsoft Windows, X Windows (on Unix and Linux), and the Mac OS\\n(both Classic and OS X). A free extension package, PMW, adds advanced widgets to\\nthe tkinter toolkit. In addition, the wxPython GUI API, based on a C++ library, offers\\nan alternative toolkit for constructing portable GUIs in Python.\\nHigher-level toolkits such as Dabo are built on top of base APIs such as wxPython and\\ntkinter. With the proper library, you can also use GUI support in other toolkits in\\nPython, such as Qt with PyQt, GTK with PyGTK, MFC with PyWin32, .NET with\\nIronPython, and Swing with Jython (the Java version of Python, described in Chap-\\nter 2) or JPype. For applications that run in web browsers or have simple interface\\nrequirements, both Jython and Python web frameworks and server-side CGI scripts,\\ndescribed in the next section, provide additional user interface options.\\n\\nInternet Scripting\\nPython comes with standard Internet modules that allow Python programs to perform\\na wide variety of networking tasks, in client and server modes. Scripts can communicate\\nover sockets; extract form information sent to server-side CGI scripts; transfer files by\\nFTP; parse and generate XML and JSON documents; send, receive, compose, and parse\\n\\nWhat Can I Do with Python?\\n\\n| 11\\n\\n\\x0cemail; fetch web pages by URLs; parse the HTML of fetched web pages; communicate\\nover XML-RPC, SOAP, and Telnet; and more. Python’s libraries make these tasks re-\\nmarkably simple.\\nIn addition, a large collection of third-party tools are available on the Web for doing\\nInternet programming in Python. For instance, the HTMLGen system generates HTML\\nfiles from Python class-based descriptions, the mod_python package runs Python effi-\\nciently  within  the  Apache  web  server  and  supports  server-side  templating  with  its\\nPython Server Pages, and the Jython system provides for seamless Python/Java inte-\\ngration and supports coding of server-side applets that run on clients.\\nIn  addition,  full-blown  web  development  framework  packages  for  Python,  such  as\\nDjango, TurboGears, web2py, Pylons, Zope, and WebWare, support quick construction\\nof full-featured and production-quality websites with Python. Many of these include\\nfeatures  such  as  object-relational  mappers,  a  Model/View/Controller  architecture,\\nserver-side scripting and templating, and AJAX support, to provide complete and en-\\nterprise-level web development solutions.\\nMore recently, Python has expanded into rich Internet applications (RIAs), with tools\\nsuch as Silverlight in IronPython, and pyjs (a.k.a. pyjamas) and its Python-to-JavaScript\\ncompiler, AJAX framework, and widget set. Python also has moved into cloud com-\\nputing, with App Engine, and others described in the database section ahead. Where\\nthe Web leads, Python quickly follows.\\n\\nComponent Integration\\nWe discussed the component integration role earlier when describing Python as a con-\\ntrol language. Python’s ability to be extended by and embedded in C and C++ systems\\nmakes it useful as a flexible glue language for scripting the behavior of other systems\\nand components. For instance, integrating a C library into Python enables Python to\\ntest and launch the library’s components, and embedding Python in a product enables\\nonsite customizations to be coded without having to recompile the entire product (or\\nship its source code at all).\\nTools  such  as  the  SWIG  and  SIP  code  generators  can  automate  much  of  the  work\\nneeded to link compiled components into Python for use in scripts, and the Cython\\nsystem  allows  coders  to  mix  Python  and  C-like  code.  Larger  frameworks,  such  as\\nPython’s COM support on Windows, the Jython Java-based implementation, and the\\nIronPython  .NET-based  implementation  provide  alternative  ways  to  script  compo-\\nnents. On Windows, for example, Python scripts can use frameworks to script Word\\nand Excel, access Silverlight, and much more.\\n\\nDatabase Programming\\nFor traditional database demands, there are Python interfaces to all commonly used\\nrelational database systems—Sybase, Oracle, Informix, ODBC, MySQL, PostgreSQL,\\n\\n12 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cSQLite, and more. The Python world has also defined a portable database API for ac-\\ncessing SQL database systems from Python scripts, which looks the same on a variety\\nof underlying database systems. For instance, because the vendor interfaces implement\\nthe portable API, a script written to work with the free MySQL system will work largely\\nunchanged on other systems (such as Oracle); all you generally have to do is replace\\nthe underlying vendor interface. The in-process SQLite embedded SQL database engine\\nis a standard part of Python itself since 2.5, supporting both prototyping and basic\\nprogram storage needs.\\nIn the non-SQL department, Python’s standard pickle module provides a simple object\\npersistence system—it allows programs to easily save and restore entire Python objects\\nto files and file-like objects. On the Web, you’ll also find third-party open source sys-\\ntems named ZODB and Durus that provide complete object-oriented database systems\\nfor Python scripts; others, such as SQLObject and SQLAlchemy, that implement object\\nrelational mappers (ORMs), which graft Python’s class model onto relational tables;\\nand PyMongo, an interface to MongoDB, a high-performance, non-SQL, open source\\nJSON-style document database, which stores data in structures very similar to Python’s\\nown lists and dictionaries, and whose text may be parsed and created with Python’s\\nown standard library json module.\\nStill other systems offer more specialized ways to store data, including the datastore in\\nGoogle’s App Engine, which models data with Python classes and provides extensive\\nscalability,  as  well  as  additional  emerging  cloud  storage  options  such  as  Azure,  Pi-\\nCloud, OpenStack, and Stackato.\\n\\nRapid Prototyping\\nTo Python programs, components written in Python and C look the same. Because of\\nthis, it’s possible to prototype systems in Python initially, and then move selected com-\\nponents to a compiled language such as C or C++ for delivery. Unlike some prototyping\\ntools, Python doesn’t require a complete rewrite once the prototype has solidified. Parts\\nof the system that don’t require the efficiency of a language such as C++ can remain\\ncoded in Python for ease of maintenance and use.\\n\\nNumeric and Scientific Programming\\nPython is also heavily used in numeric programming—a domain that would not tra-\\nditionally have been considered to be in the scope of scripting languages, but has grown\\nto become one of Python’s most compelling use cases. Prominent here, the NumPy\\nhigh-performance numeric programming extension for Python mentioned earlier in-\\ncludes such advanced tools as an array object, interfaces to standard mathematical\\nlibraries,  and  much  more.  By  integrating  Python  with  numeric  routines  coded  in  a\\ncompiled language for speed, NumPy turns Python into a sophisticated yet easy-to-use\\nnumeric programming tool that can often replace existing code written in traditional\\ncompiled languages such as FORTRAN or C++.\\n\\nWhat Can I Do with Python?\\n\\n| 13\\n\\n\\x0cAdditional numeric tools for Python support animation, 3D visualization, parallel pro-\\ncessing, and so on. The popular SciPy and ScientificPython extensions, for example,\\nprovide additional libraries of scientific programming tools and use NumPy as a core\\ncomponent. The PyPy implementation of Python (discussed in Chapter 2) has also\\ngained traction in the numeric domain, in part because heavily algorithmic code of the\\nsort that’s common in this domain can run dramatically faster in PyPy—often 10X to\\n100X quicker.\\n\\nAnd More: Gaming, Images, Data Mining, Robots, Excel...\\nPython is commonly applied in more domains than can be covered here. For example,\\nyou’ll find tools that allow you to use Python to do:\\n\\n• Game  programming  and  multimedia  with  pygame,  cgkit,  pyglet,  PySoy,\\n\\nPanda3D, and others\\n\\n• Serial port communication on Windows, Linux, and more with the PySerial ex-\\n\\ntension\\n\\n• Image processing with PIL and its newer Pillow fork, PyOpenGL, Blender, Maya,\\n\\nand more\\n\\n• Robot control programming with the PyRo toolkit\\n• Natural language analysis with the NLTK package\\n• Instrumentation on the Raspberry Pi and Arduino boards\\n• Mobile computing with ports of Python to the Google Android and Apple iOS\\n\\nplatforms\\n\\n• Excel spreadsheet function and macro programming with the PyXLL or DataNi-\\n\\ntro add-ins\\n\\n• Media file content and metadata tag processing with PyMedia, ID3, PIL/Pillow,\\n\\nand more\\n\\n• Artificial intelligence with the PyBrain neural net library and the Milk machine\\n\\nlearning toolkit\\n\\n• Expert system programming with PyCLIPS, Pyke, Pyrolog, and pyDatalog\\n• Network monitoring with zenoss, written in and customized with Python\\n• Python-scripted design and modeling with PythonCAD, PythonOCC, FreeCAD,\\n\\nand others\\n\\n• Document processing and generation with ReportLab, Sphinx, Cheetah, PyPDF,\\n\\nand so on\\n\\n• Data visualization with Mayavi, matplotlib, VTK, VPython, and more\\n• XML parsing with the xml library package, the xmlrpclib module, and third-party\\n\\nextensions\\n\\n• JSON and CSV file processing with the json and csv modules\\n\\n14 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0c• Data mining with the Orange framework, the Pattern bundle, Scrapy, and custom\\n\\ncode\\n\\nYou can even play solitaire with the PySolFC program. And of course, you can always\\ncode custom Python scripts in less buzzword-laden domains to perform day-to-day\\nsystem administration, process your email, manage your document and media libraries,\\nand so on. You’ll find links to the support in many fields at the PyPI website, and via\\nweb searches (search Google or http://www.python.org for links).\\nThough of broad practical use, many of these specific domains are largely just instances\\nof  Python’s  component  integration  role  in  action  again.  Adding  it  as  a  frontend  to\\nlibraries of components written in a compiled language such as C makes Python useful\\nfor scripting in a wide variety of domains. As a general-purpose language that supports\\nintegration, Python is widely applicable.\\n\\nHow Is Python Developed and Supported?\\nAs a popular open source system, Python enjoys a large and active development com-\\nmunity that responds to issues and develops enhancements with a speed that many\\ncommercial software developers might find remarkable. Python developers coordinate\\nwork online with a source-control system. Changes are developed per a formal proto-\\ncol, which includes writing a PEP (Python Enhancement Proposal) or other document,\\nand extensions to Python’s regression testing system. In fact, modifying Python today\\nis roughly as involved as changing commercial software—a far cry from Python’s early\\ndays, when an email to its creator would suffice, but a good thing given its large user\\nbase today.\\nThe PSF (Python Software Foundation), a formal nonprofit group, organizes confer-\\nences and deals with intellectual property issues. Numerous Python conferences are\\nheld around the world; O’Reilly’s OSCON and the PSF’s PyCon are the largest. The\\nformer of these addresses multiple open source projects, and the latter is a Python-only\\nevent that has experienced strong growth in recent years. PyCon 2012 and 2013 reached\\n2,500 attendees each; in fact, PyCon 2013 had to cap its limit at this level after a surprise\\nsell-out in 2012 (and managed to grab wide attention on both technical and nontech-\\nnical grounds that I won’t chronicle here). Earlier years often saw attendance double\\n—from  586  attendees  in  2007  to  over  1,000  in  2008,  for  example—indicative  of\\nPython’s growth in general, and impressive to those who remember early conferences\\nwhose attendees could largely be served around a single restaurant table.\\n\\nOpen Source Tradeoffs\\nHaving said that, it’s important to note that while Python enjoys a vigorous develop-\\nment community, this comes with inherent tradeoffs. Open source software can also\\nappear chaotic and even resemble anarchy at times, and may not always be as smoothly\\nimplemented as the prior paragraphs might imply. Some changes may still manage to\\n\\nHow Is Python Developed and Supported?\\n\\n| 15\\n\\n\\x0cdefy official protocols, and as in all human endeavors, mistakes still happen despite the\\nprocess controls (Python 3.2.0, for instance, came with a broken console input function\\non Windows).\\nMoreover, open source projects exchange commercial interests for the personal pref-\\nerences of a current set of developers, which may or may not be the same as yours—\\nyou are not held hostage by a company, but you are at the mercy of those with spare\\ntime to change the system. The net effect is that open source software evolution is often\\ndriven by the few, but imposed on the many.\\nIn practice, though, these tradeoffs impact those on the “bleeding” edge of new releases\\nmuch more than those using established versions of the system, including prior releases\\nin both Python 3.X and 2.X. If you kept using classic classes in Python 2.X, for example,\\nyou were largely immune to the explosion of class functionality and change in new-style\\nclasses that occurred in the early-to-mid 2000s. Though these become mandatory in\\n3.X (along with much more), many 2.X users today still happily skirt the issue.\\n\\nWhat Are Python’s Technical Strengths?\\nNaturally,  this  is  a  developer’s  question.  If  you  don’t  already  have  a  programming\\nbackground, the language in the next few sections may be a bit baffling—don’t worry,\\nwe’ll explore all of these terms in more detail as we proceed through this book. For\\ndevelopers, though, here is a quick introduction to some of Python’s top technical\\nfeatures.\\n\\nIt’s Object-Oriented and Functional\\nPython is an object-oriented language, from the ground up. Its class model supports\\nadvanced notions such as polymorphism, operator overloading, and multiple inheri-\\ntance; yet, in the context of Python’s simple syntax and typing, OOP is remarkably easy\\nto apply. In fact, if you don’t understand these terms, you’ll find they are much easier\\nto learn with Python than with just about any other OOP language available.\\nBesides serving as a powerful code structuring and reuse device, Python’s OOP nature\\nmakes it ideal as a scripting tool for other object-oriented systems languages. For ex-\\nample,  with  the  appropriate  glue  code,  Python  programs  can  subclass  (specialize)\\nclasses implemented in C++, Java, and C#.\\nOf equal significance, OOP is an option in Python; you can go far without having to\\nbecome an object guru all at once. Much like C++, Python supports both procedural\\nand object-oriented programming modes. Its object-oriented tools can be applied if\\nand when constraints allow. This is especially useful in tactical development modes,\\nwhich preclude design phases.\\nIn  addition  to  its  original  procedural  (statement-based)  and  object-oriented  (class-\\nbased) paradigms, Python in recent years has acquired built-in support for functional\\n\\n16 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cprogramming—a set that by most measures includes generators, comprehensions, clo-\\nsures, maps, decorators, anonymous function lambdas, and first-class function objects.\\nThese can serve as both complement and alternative to its OOP tools.\\n\\nIt’s Free\\nPython is completely free to use and distribute. As with other open source software,\\nsuch as Tcl, Perl, Linux, and Apache, you can fetch the entire Python system’s source\\ncode for free on the Internet. There are no restrictions on copying it, embedding it in\\nyour systems, or shipping it with your products. In fact, you can even sell Python’s\\nsource code, if you are so inclined.\\nBut don’t get the wrong idea: “free” doesn’t mean “unsupported.” On the contrary,\\nthe Python online community responds to user queries with a speed that most com-\\nmercial software help desks would do well to try to emulate. Moreover, because Python\\ncomes with complete source code, it empowers developers, leading to the creation of\\na large team of implementation experts. Although studying or changing a programming\\nlanguage’s implementation isn’t everyone’s idea of fun, it’s comforting to know that\\nyou can do so if you need to. You’re not dependent on the whims of a commercial\\nvendor, because the ultimate documentation—source code—is at your disposal as a\\nlast resort.\\nAs mentioned earlier, Python development is performed by a community that largely\\ncoordinates its efforts over the Internet. It consists of Python’s original creator—Guido\\nvan Rossum, the officially anointed Benevolent Dictator for Life (BDFL) of Python—\\nplus a supporting cast of thousands. Language changes must follow a formal enhance-\\nment procedure and be scrutinized by both other developers and the BDFL. This tends\\nto make Python more conservative with changes than some other languages and sys-\\ntems. While the Python 3.X/2.X split broke with this tradition soundly and deliberately,\\nit still holds generally true within each Python line.\\n\\nIt’s Portable\\nThe standard implementation of Python is written in portable ANSI C, and it compiles\\nand runs on virtually every major platform currently in use. For example, Python pro-\\ngrams run today on everything from PDAs to supercomputers. As a partial list, Python\\nis available on:\\n\\n• Linux and Unix systems\\n• Microsoft Windows (all modern flavors)\\n• Mac OS (both OS X and Classic)\\n• BeOS, OS/2, VMS, and QNX\\n• Real-time systems such as VxWorks\\n• Cray supercomputers and IBM mainframes\\n\\nWhat Are Python’s Technical Strengths?\\n\\n| 17\\n\\n\\x0c• PDAs running Palm OS, PocketPC, and Linux\\n• Cell phones running Symbian OS, and Windows Mobile\\n• Gaming consoles and iPods\\n• Tablets and smartphones running Google’s Android and Apple’s iOS\\n• And more\\n\\nLike the language interpreter itself, the standard library modules that ship with Python\\nare implemented to be as portable across platform boundaries as possible. Further,\\nPython programs are automatically compiled to portable byte code, which runs the\\nsame on any platform with a compatible version of Python installed (more on this in\\nthe next chapter).\\nWhat that means is that Python programs using the core language and standard libraries\\nrun the same on Linux, Windows, and most other systems with a Python interpreter.\\nMost Python ports also contain platform-specific extensions (e.g., COM support on\\nWindows), but the core Python language and libraries work the same everywhere. As\\nmentioned earlier, Python also includes an interface to the Tk GUI toolkit called tkinter\\n(Tkinter in 2.X), which allows Python programs to implement full-featured graphical\\nuser interfaces that run on all major GUI desktop platforms without program changes.\\n\\nIt’s Powerful\\nFrom a features perspective, Python is something of a hybrid. Its toolset places it be-\\ntween traditional scripting languages (such as Tcl, Scheme, and Perl) and systems de-\\nvelopment languages (such as C, C++, and Java). Python provides all the simplicity\\nand ease of use of a scripting language, along with more advanced software-engineering\\ntools  typically  found  in  compiled  languages.  Unlike  some  scripting  languages,  this\\ncombination makes Python useful for large-scale development projects. As a preview,\\nhere are some of the main things you’ll find in Python’s toolbox:\\n\\nDynamic typing\\n\\nPython  keeps  track  of  the  kinds  of  objects  your  program  uses  when  it  runs;  it\\ndoesn’t require complicated type and size declarations in your code. In fact, as\\nyou’ll see in Chapter 6, there is no such thing as a type or variable declaration\\nanywhere in Python. Because Python code does not constrain data types, it is also\\nusually automatically applicable to a whole range of objects.\\n\\nAutomatic memory management\\n\\nPython  automatically  allocates  objects  and  reclaims  (“garbage  collects”)  them\\nwhen they are no longer used, and most can grow and shrink on demand. As you’ll\\nlearn, Python keeps track of low-level memory details so you don’t have to.\\n\\nProgramming-in-the-large support\\n\\nFor building larger systems, Python includes tools such as modules, classes, and\\nexceptions. These tools allow you to organize systems into components, use OOP\\n\\n18 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cto reuse and customize code, and handle events and errors gracefully. Python’s\\nfunctional programming tools, described earlier, provide additional ways to meet\\nmany of the same goals.\\n\\nBuilt-in object types\\n\\nPython provides commonly used data structures such as lists, dictionaries, and\\nstrings as intrinsic parts of the language; as you’ll see, they’re both flexible and easy\\nto use. For instance, built-in objects can grow and shrink on demand, can be ar-\\nbitrarily nested to represent complex information, and more.\\n\\nBuilt-in tools\\n\\nTo process all those object types, Python comes with powerful and standard op-\\nerations,  including  concatenation  (joining  collections),  slicing  (extracting  sec-\\ntions), sorting, mapping, and more.\\n\\nLibrary utilities\\n\\nFor more specific tasks, Python also comes with a large collection of precoded\\nlibrary  tools  that  support  everything  from  regular  expression  matching  to  net-\\nworking. Once you learn the language itself, Python’s library tools are where much\\nof the application-level action occurs.\\n\\nThird-party utilities\\n\\nBecause Python is open source, developers are encouraged to contribute precoded\\ntools that support tasks beyond those supported by its built-ins; on the Web, you’ll\\nfind free support for COM, imaging, numeric programming, XML, database ac-\\ncess, and much more.\\n\\nDespite the array of tools in Python, it retains a remarkably simple syntax and design.\\nThe result is a powerful programming tool with all the usability of a scripting language.\\n\\nIt’s Mixable\\nPython programs can easily be “glued” to components written in other languages in a\\nvariety of ways. For example, Python’s C API lets C programs call and be called by\\nPython programs flexibly. That means you can add functionality to the Python system\\nas needed, and use Python programs within other environments or systems.\\nMixing Python with libraries coded in languages such as C or C++, for instance, makes\\nit an easy-to-use frontend language and customization tool. As mentioned earlier, this\\nalso makes Python good at rapid prototyping—systems may be implemented in Python\\nfirst, to leverage its speed of development, and later moved to C for delivery, one piece\\nat a time, according to performance demands.\\n\\nIt’s Relatively Easy to Use\\nCompared to alternatives like C++, Java, and C#, Python programming seems aston-\\nishingly simple to most observers. To run a Python program, you simply type it and\\nrun it. There are no intermediate compile and link steps, like there are for languages\\n\\nWhat Are Python’s Technical Strengths?\\n\\n| 19\\n\\n\\x0csuch as C or C++. Python executes programs immediately, which makes for an inter-\\nactive programming experience and rapid turnaround after program changes—in many\\ncases, you can witness the effect of a program change nearly as fast as you can type it.\\nOf course, development cycle turnaround is only one aspect of Python’s ease of use. It\\nalso provides a deliberately simple syntax and powerful built-in tools. In fact, some\\nhave gone so far as to call Python executable pseudocode. Because it eliminates much\\nof the complexity in other tools, Python programs are simpler, smaller, and more flex-\\nible than equivalent programs in other popular languages.\\n\\nIt’s Relatively Easy to Learn\\nThis brings us to the point of this book: especially when compared to other widely used\\nprogramming languages, the core Python language is remarkably easy to learn. In fact,\\nif you’re an experienced programmer, you can expect to be coding small-scale Python\\nprograms in a matter of days, and may be able to pick up some limited portions of the\\nlanguage in just hours—though you shouldn’t expect to become an expert quite that\\nfast (despite what you may have heard from marketing departments!).\\nNaturally, mastering any topic as substantial as today’s Python is not trivial, and we’ll\\ndevote the rest of this book to this task. But the true investment required to master\\nPython is worthwhile—in the end, you’ll gain programming skills that apply to nearly\\nevery computer application domain. Moreover, most find Python’s learning curve to\\nbe much gentler than that of other programming tools.\\nThat’s good news for professional developers seeking to learn the language to use on\\nthe job, as well as for end users of systems that expose a Python layer for customization\\nor control. Today, many systems rely on the fact that end users can learn enough Python\\nto tailor their Python customization code onsite, with little or no support. Moreover,\\nPython has spawned a large group of users who program for fun instead of career, and\\nmay  never  need  full-scale  software  development  skills.  Although  Python  does  have\\nadvanced programming tools, its core language essentials will still seem relatively sim-\\nple to beginners and gurus alike.\\n\\nIt’s Named After Monty Python\\nOK, this isn’t quite a technical strength, but it does seem to be a surprisingly well-kept\\nsecret in the Python world that I wish to expose up front. Despite all the reptiles on\\nPython books and icons, the truth is that Python is named after the British comedy\\ngroup Monty Python—makers of the 1970s BBC comedy series Monty Python’s Flying\\nCircus and a handful of later full-length films, including Monty Python and the Holy\\nGrail, that are still widely popular today. Python’s original creator was a fan of Monty\\nPython, as are many software developers (indeed, there seems to be a sort of symmetry\\nbetween the two fields...).\\n\\n20 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cThis legacy inevitably adds a humorous quality to Python code examples. For instance,\\nthe traditional “foo” and “bar” for generic variable names become “spam” and “eggs”\\nin the Python world. The occasional “Brian,” “ni,” and “shrubbery” likewise owe their\\nappearances to this namesake. It even impacts the Python community at large: some\\nevents at Python conferences are regularly billed as “The Spanish Inquisition.”\\nAll of this is, of course, very funny if you are familiar with the shows, but less so other-\\nwise. You don’t need to be familiar with Monty Python’s work to make sense of ex-\\namples that borrow references from it, including many you will see in this book, but at\\nleast you now know their root. (Hey—I’ve warned you.)\\n\\nHow Does Python Stack Up to Language X?\\nFinally, to place it in the context of what you may already know, people sometimes\\ncompare Python to languages such as Perl, Tcl, and Java. This section summarizes\\ncommon consensus in this department.\\nI want to note up front that I’m not a fan of winning by disparaging the competition—\\nit doesn’t work in the long run, and that’s not the goal here. Moreover, this is not a\\nzero sum game—most programmers will use many languages over their careers. Nev-\\nertheless, programming tools present choices and tradeoffs that merit consideration.\\nAfter all, if Python didn’t offer something over its alternatives, it would never have been\\nused in the first place.\\nWe talked about performance tradeoffs earlier, so here we’ll focus on functionality.\\nWhile other languages are also useful tools to know and use, many people find that\\nPython:\\n\\n• Is more powerful than Tcl. Python’s strong support for “programming in the large”\\nmakes it applicable to the development of larger systems, and its library of appli-\\ncation tools is broader.\\n\\n• Is more readable than Perl. Python has a clear syntax and a simple, coherent design.\\nThis in turn makes Python more reusable and maintainable, and helps reduce pro-\\ngram bugs.\\n\\n• Is simpler and easier to use than Java and C#. Python is a scripting language, but\\nJava and C# both inherit much of the complexity and syntax of larger OOP systems\\nlanguages like C++.\\n\\n• Is simpler and easier to use than C++. Python code is simpler than the equivalent\\nC++  and  often  one-third  to  one-fifth  as  large,  though  as  a  scripting  language,\\nPython sometimes serves different roles.\\n\\n• Is simpler and higher-level than C. Python’s detachment from underlying hardware\\narchitecture makes code less complex, better structured, and more approachable\\nthan C, C++’s progenitor.\\n\\nHow Does Python Stack Up to Language X?\\n\\n| 21\\n\\n\\x0c• Is more powerful, general-purpose, and cross-platform than Visual Basic. Python\\nis a richer language that is used more widely, and its open source nature means it\\nis not controlled by a single company.\\n\\n• Is more readable and general-purpose than PHP. Python is used to construct web-\\nsites too, but it is also applied to nearly every other computer domain, from robotics\\nto movie animation and gaming.\\n\\n• Is more powerful and general-purpose than JavaScript. Python has a larger toolset,\\nand is not as tightly bound to web development. It’s also used for scientific mod-\\neling, instrumentation, and more.\\n\\n• Is more readable and established than Ruby. Python syntax is less cluttered, espe-\\ncially in nontrivial code, and its OOP is fully optional for users and projects to\\nwhich it may not apply.\\n\\n• Is more mature and broadly focused than Lua. Python’s larger feature set and more\\nextensive library support give it a wider scope than Lua, an embedded “glue” lan-\\nguage like Tcl.\\n\\n• Is less esoteric than Smalltalk, Lisp, and Prolog. Python has the dynamic flavor of\\nlanguages like these, but also has a traditional syntax accessible to both developers\\nand end users of customizable systems.\\n\\nEspecially for programs that do more than scan text files, and that might have to be\\nread in the future by others (or by you!), many people find that Python fits the bill better\\nthan any other scripting or programming language available today. Furthermore, unless\\nyour  application  requires  peak  performance,  Python  is  often  a  viable  alternative  to\\nsystems development languages such as C, C++, and Java: Python code can often ach-\\nieve the same goals, but will be much less difficult to write, debug, and maintain.\\nOf course, your author has been a card-carrying Python evangelist since 1992, so take\\nthese comments as you may (and other languages’ advocates’ mileage may vary arbi-\\ntrarily). They do, however, reflect the common experience of many developers who\\nhave taken time to explore what Python has to offer.\\n\\nChapter Summary\\nAnd that concludes the “hype” portion of this book. In this chapter, we’ve explored\\nsome of the reasons that people pick Python for their programming tasks. We’ve also\\nseen how it is applied and looked at a representative sample of who is using it today.\\nMy goal is to teach Python, though, not to sell it. The best way to judge a language is\\nto see it in action, so the rest of this book focuses entirely on the language details we’ve\\nglossed over here.\\nThe next two chapters begin our technical introduction to the language. In them, we’ll\\nexplore ways to run Python programs, peek at Python’s byte code execution model,\\nand introduce the basics of module files for saving code. The goal will be to give you\\n\\n22 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cjust enough information to run the examples and exercises in the rest of the book. You\\nwon’t really start programming per se until Chapter 4, but make sure you have a handle\\non the startup details before moving on.\\n\\nTest Your Knowledge: Quiz\\nIn this edition of the book, we will be closing each chapter with a quick open-book\\nquiz about the material presented herein to help you review the key concepts. The\\nanswers for these quizzes appear immediately after the questions, and you are encour-\\naged to read the answers once you’ve taken a crack at the questions yourself, as they\\nsometimes give useful context.\\nIn addition to these end-of-chapter quizzes, you’ll find lab exercises at the end of each\\npart of the book, designed to help you start coding Python on your own. For now,\\nhere’s your first quiz. Good luck, and be sure to refer back to this chapter’s material as\\nneeded.\\n\\n1. What are the six main reasons that people choose to use Python?\\n2. Name four notable companies or organizations using Python today.\\n3. Why might you not want to use Python in an application?\\n4. What can you do with Python?\\n5. What’s the significance of the Python import this statement?\\n6. Why does “spam” show up in so many Python examples in books and on the Web?\\n7. What is your favorite color?\\n\\nTest Your Knowledge: Answers\\nHow did you do? Here are the answers I came up with, though there may be multiple\\nsolutions to some quiz questions. Again, even if you’re sure of your answer, I encourage\\nyou to look at mine for additional context. See the chapter’s text for more details if any\\nof these responses don’t make sense to you.\\n\\n1. Software quality, developer productivity, program portability, support libraries,\\ncomponent integration, and simple enjoyment. Of these, the quality and produc-\\ntivity themes seem to be the main reasons that people choose to use Python.\\n\\n2. Google, Industrial Light & Magic, CCP Games, Jet Propulsion Labs, Maya, ESRI,\\nand  many  more.  Almost  every  organization  doing  software  development  uses\\nPython in some fashion, whether for long-term strategic product development or\\nfor short-term tactical tasks such as testing and system administration.\\n\\n3. Python’s main downside is performance: it won’t run as quickly as fully compiled\\nlanguages like C and C++. On the other hand, it’s quick enough for most appli-\\ncations, and typical Python code runs at close to C speed anyhow because it invokes\\n\\nTest Your Knowledge: Answers\\n\\n| 23\\n\\n\\x0clinked-in C code in the interpreter. If speed is critical, compiled extensions are\\navailable for number-crunching parts of an application.\\n\\n4. You can use Python for nearly anything you can do with a computer, from website\\n\\ndevelopment and gaming to robotics and spacecraft control.\\n\\n5. This was mentioned in a footnote: import this triggers an Easter egg inside Python\\nthat displays some of the design philosophies underlying the language. You’ll learn\\nhow to run this statement in the next chapter.\\n\\n6. “Spam” is a reference from a famous Monty Python skit in which people trying to\\norder food in a cafeteria are drowned out by a chorus of Vikings singing about\\nspam. Oh, and it’s also a common variable name in Python scripts...\\n\\n7. Blue. No, yellow! (See the prior answer.)\\n\\nPython Is Engineering, Not Art\\n\\nWhen Python first emerged on the software scene in the early 1990s, it spawned what\\nis now something of a classic conflict between its proponents and those of another\\npopular scripting language, Perl. Personally, I think the debate is tired and unwarranted\\ntoday—developers are smart enough to draw their own conclusions. Still, this is one\\nof the most common topics I’m asked about on the training road, and underscores one\\nof the main reasons people choose to use Python; it seems fitting to say a few brief\\nwords about it here.\\n\\nThe short story is this: you can do everything in Python that you can in Perl, but you can\\nread your code after you do it. That’s it—their domains largely overlap, but Python is\\nmore  focused  on  producing  readable  code.  For  many,  the  enhanced  readability  of\\nPython translates to better code reusability and maintainability, making Python a better\\nchoice for programs that will not be written once and thrown away. Perl code is easy\\nto write, but can be difficult to read. Given that most software has a lifespan much\\nlonger than its initial creation, many see Python as the more effective tool.\\n\\nThe somewhat longer story reflects the backgrounds of the designers of the two lan-\\nguages. Python originated with a mathematician by training, who seems to have natu-\\nrally produced an orthogonal language with a high degree of uniformity and coherence.\\nPerl  was  spawned  by  a  linguist,  who  created  a  programming  tool  closer  to  natural\\nlanguage, with its context sensitivities and wide variability. As a well-known Perl motto\\nstates, there’s more than one way to do it. Given this mindset, both the Perl language\\nand its user community have historically encouraged untethered freedom of expression\\nwhen writing code. One person’s Perl code can be radically different from another’s.\\nIn fact, writing unique, tricky code is often a source of pride among Perl users.\\n\\nBut as anyone who has done any substantial code maintenance should be able to attest,\\nfreedom of expression is great for art, but lousy for engineering. In engineering, we need\\na minimal feature set and predictability. In engineering, freedom of expression can lead\\nto maintenance nightmares. As more than one Perl user has confided to me, the result\\nof too much freedom is often code that is much easier to rewrite from scratch than to\\nmodify. This is clearly less than ideal.\\n\\n24 | Chapter 1:\\u2002A Python Q&A Session\\n\\n\\x0cConsider  this:  when  people  create  a  painting  or  a  sculpture,  they  do  so  largely  for\\nthemselves; the prospect of someone else changing their work later doesn’t enter into\\nit. This is a critical difference between art and engineering. When people write soft-\\nware, they are not writing it for themselves. In fact, they are not even writing primarily\\nfor the computer. Rather, good programmers know that code is written for the next\\nhuman being who has to read it in order to maintain or reuse it. If that person cannot\\nunderstand the code, it’s all but useless in a realistic development scenario. In other\\nwords, programming is not about being clever and obscure—it’s about how clearly your\\nprogram communicates its purpose.\\n\\nThis readability focus is where many people find that Python most clearly differentiates\\nitself from other scripting languages. Because Python’s syntax model almost forces the\\ncreation of readable code, Python programs lend themselves more directly to the full\\nsoftware development cycle. And because Python emphasizes ideas such as limited\\ninteractions, code uniformity, and feature consistency, it more directly fosters code that\\ncan be used long after it is first written.\\n\\nIn the long run, Python’s focus on code quality in itself boosts programmer productivity,\\nas well as programmer satisfaction. Python programmers can be wildly creative, too,\\nof course, and as we’ll see, the language does offer multiple solutions for some tasks—\\nsometimes even more than it should today, an issue we’ll confront head-on in this book\\ntoo. In fact, this sidebar can also be read as a cautionary tale: quality turns out to be a\\nfragile state, one that depends as much on people as on technology. Python has histor-\\nically encouraged good engineering in ways that other scripting languages often did\\nnot, but the rest of the quality story is up to you.\\n\\nAt least, that’s some of the common consensus among many people who have adopted\\nPython. You should judge such claims for yourself, of course, by learning what Python\\nhas to offer. To help you get started, let’s move on to the next chapter.\\n\\nTest Your Knowledge: Answers\\n\\n| 25\\n\\n\\x0c\\x0cCHAPTER 2\\nHow Python Runs Programs\\n\\nThis chapter and the next take a quick look at program execution—how you launch\\ncode, and how Python runs it. In this chapter, we’ll study how the Python interpreter\\nexecutes  programs  in  general.  Chapter  3  will  then  show  you  how  to  get  your  own\\nprograms up and running.\\nStartup details are inherently platform-specific, and some of the material in these two\\nchapters may not apply to the platform you work on, so more advanced readers should\\nfeel free to skip parts not relevant to their intended use. Likewise, readers who have\\nused similar tools in the past and prefer to get to the meat of the language quickly may\\nwant to file some of these chapters away as “for future reference.” For the rest of us,\\nlet’s take a brief look at the way that Python will run our code, before we learn how to\\nwrite it.\\n\\nIntroducing the Python Interpreter\\nSo far, I’ve mostly been talking about Python as a programming language. But, as cur-\\nrently implemented, it’s also a software package called an interpreter. An interpreter is\\na kind of program that executes other programs. When you write a Python program,\\nthe Python interpreter reads your program and carries out the instructions it contains.\\nIn effect, the interpreter is a layer of software logic between your code and the computer\\nhardware on your machine.\\nWhen the Python package is installed on your machine, it generates a number of com-\\nponents—minimally, an interpreter and a support library. Depending on how you use\\nit,  the  Python  interpreter  may  take  the  form  of  an  executable  program,  or  a  set  of\\nlibraries linked into another program. Depending on which flavor of Python you run,\\nthe  interpreter  itself  may  be  implemented  as  a  C  program,  a  set  of  Java  classes,  or\\nsomething else. Whatever form it takes, the Python code you write must always be run\\nby this interpreter. And to enable that, you must install a Python interpreter on your\\ncomputer.\\n\\n27\\n\\n\\x0cPython installation details vary by platform and are covered in more depth in Appen-\\ndix A. In short:\\n\\n• Windows users fetch and run a self-installing executable file that puts Python on\\n\\ntheir machines. Simply double-click and say Yes or Next at all prompts.\\n\\n• Linux and Mac OS X users probably already have a usable Python preinstalled on\\n\\ntheir computers—it’s a standard component on these platforms today.\\n\\n• Some Linux and Mac OS X users (and most Unix users) compile Python from its\\n\\nfull source code distribution package.\\n\\n• Linux users can also find RPM files, and Mac OS X users can find various Mac-\\n\\nspecific installation packages.\\n\\n• Other platforms have installation techniques relevant to those platforms. For in-\\nstance, Python is available on cell phones, tablets, game consoles, and iPods, but\\ninstallation details vary widely.\\n\\nPython itself may be fetched from the downloads page on its main website, http://www\\n.python.org. It may also be found through various other distribution channels. Keep in\\nmind that you should always check to see whether Python is already present before\\ninstalling it. If you’re working on Windows 7 and earlier, you’ll usually find Python in\\nthe Start menu, as captured in Figure 2-1; we’ll discuss the menu options shown here\\nin the next chapter. On Unix and Linux, Python probably lives in your /usr directory\\ntree.\\n\\nBecause installation details are so platform-specific, we’ll postpone the rest of this story\\nhere. For more details on the installation process, consult Appendix A. For the purposes\\nof this chapter and the next, I’ll assume that you’ve got Python ready to go.\\n\\nProgram Execution\\nWhat it means to write and run a Python script depends on whether you look at these\\ntasks as a programmer, or as a Python interpreter. Both views offer important perspec-\\ntives on Python programming.\\n\\nThe Programmer’s View\\nIn its simplest form, a Python program is just a text file containing Python statements.\\nFor example, the following file, named script0.py, is one of the simplest Python scripts\\nI could dream up, but it passes for a fully functional Python program:\\n\\nprint(\\'hello world\\')\\nprint(2 ** 100)\\n\\nThis file contains two Python print statements, which simply print a string (the text in\\nquotes) and a numeric expression result (2 to the power 100) to the output stream.\\nDon’t worry about the syntax of this code yet—for this chapter, we’re interested only\\n\\n28 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0cFigure 2-1. When installed on Windows 7 and earlier, this is how Python shows up in your Start\\nbutton menu. This can vary across releases, but IDLE starts a development GUI, and Python starts\\na simple interactive session. Also here are the standard manuals and the PyDoc documentation engine\\n(Module Docs). See Chapter 3 and Appendix A for pointers on Windows 8 and other platforms.\\n\\nin getting it to run. I’ll explain the print statement, and why you can raise 2 to the\\npower 100 in Python without overflowing, in the next parts of this book.\\nYou can create such a file of statements with any text editor you like. By convention,\\nPython program files are given names that end in .py; technically, this naming scheme\\nis required only for files that are “imported”—a term clarified in the next chapter—but\\nmost Python files have .py names for consistency.\\nAfter you’ve typed these statements into a text file, you must tell Python to execute the\\nfile—which simply means to run all the statements in the file from top to bottom, one\\nafter another. As you’ll see in the next chapter, you can launch Python program files\\nby  shell  command  lines,  by  clicking  their  icons,  from  within  IDEs,  and  with  other\\nstandard techniques. If all goes well, when you execute the file, you’ll see the results of\\nthe two print statements show up somewhere on your computer—by default, usually\\nin the same window you were in when you ran the program:\\n\\nProgram Execution | 29\\n\\n\\x0chello world\\n1267650600228229401496703205376\\n\\nFor example, here’s what happened when I ran this script from a Command Prompt\\nwindow’s command line on a Windows laptop, to make sure it didn’t have any silly\\ntypos:\\n\\nC:\\\\code> python script0.py\\nhello world\\n1267650600228229401496703205376\\n\\nSee Chapter 3 for the full story on this process, especially if you’re new to programming;\\nwe’ll get into all the gory details of writing and launching programs there. For our\\npurposes here, we’ve just run a Python script that prints a string and a number. We\\nprobably won’t win any programming awards with this code, but it’s enough to capture\\nthe basics of program execution.\\n\\nPython’s View\\nThe brief description in the prior section is fairly standard for scripting languages, and\\nit’s usually all that most Python programmers need to know. You type code into text\\nfiles, and you run those files through the interpreter. Under the hood, though, a bit\\nmore happens when you tell Python to “go.” Although knowledge of Python internals\\nis not strictly required for Python programming, a basic understanding of the runtime\\nstructure of Python can help you grasp the bigger picture of program execution.\\nWhen you instruct Python to run your script, there are a few steps that Python carries\\nout before your code actually starts crunching away. Specifically, it’s first compiled to\\nsomething called “byte code” and then routed to something called a “virtual machine.”\\n\\nByte code compilation\\nInternally,  and  almost  completely  hidden  from  you,  when  you  execute  a  program\\nPython first compiles your source code (the statements in your file) into a format known\\nas byte code. Compilation is simply a translation step, and byte code is a lower-level,\\nplatform-independent representation of your source code. Roughly, Python translates\\neach of your source statements into a group of byte code instructions by decomposing\\nthem into individual steps. This byte code translation is performed to speed execution\\n—byte code can be run much more quickly than the original source code statements\\nin your text file.\\nYou’ll notice that the prior paragraph said that this is almost completely hidden from\\nyou. If the Python process has write access on your machine, it will store the byte code\\nof your programs in files that end with a .pyc extension (“.pyc” means compiled “.py”\\nsource). Prior to Python 3.2, you will see these files show up on your computer after\\nyou’ve run a few programs alongside the corresponding source code files—that is, in\\nthe same directories. For instance, you’ll notice a script.pyc after importing a script.py.\\n\\n30 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0cIn 3.2 and later, Python instead saves its .pyc byte code files in a subdirectory named\\n__pycache__ located in the directory where your source files reside, and in files whose\\nnames identify the Python version that created them (e.g., script.cpython-33.pyc). The\\nnew __pycache__ subdirectory helps to avoid clutter, and the new naming convention\\nfor byte code files prevents different Python versions installed on the same computer\\nfrom overwriting each other’s saved byte code. We’ll study these byte code file models\\nin more detail in Chapter 22, though they are automatic and irrelevant to most Python\\nprograms, and are free to vary among the alternative Python implementations described\\nahead.\\nIn both models, Python saves byte code like this as a startup speed optimization. The\\nnext time you run your program, Python will load the .pyc files and skip the compilation\\nstep, as long as you haven’t changed your source code since the byte code was last\\nsaved, and aren’t running with a different Python than the one that created the byte\\ncode. It works like this:\\n\\n• Source  changes:  Python  automatically  checks  the  last-modified  timestamps  of \\nsource and byte code files to know when it must recompile—if you edit and resave\\nyour source code, byte code is automatically re-created the next time your program\\nis run.\\n\\n• Python versions: Imports also check to see if the file must be recompiled because\\nit was created by a different Python version, using either a “magic” version number\\nin the byte code file itself in 3.2 and earlier, or the information present in byte code\\nfilenames in 3.2 and later.\\n\\nThe result is that both source code changes and differing Python version numbers will\\ntrigger a new byte code file. If Python cannot write the byte code files to your machine,\\nyour program still works—the byte code is generated in memory and simply discarded\\non program exit. However, because .pyc files speed startup time, you’ll want to make\\nsure they are written for larger programs. Byte code files are also one way to ship Python\\nprograms—Python is happy to run a program if all it can find are .pyc files, even if the\\noriginal  .py  source  files  are  absent.  (See  “Frozen  Binaries”  on  page  39  for  another\\nshipping option.)\\nFinally, keep in mind that byte code is saved in files only for files that are imported, not\\nfor the top-level files of a program that are only run as scripts (strictly speaking, it’s an\\nimport optimization). We’ll explore import basics in Chapter 3, and take a deeper look\\nat imports in Part V. Moreover, a given file is only imported (and possibly compiled)\\nonce per program run, and byte code is also never saved for code typed at the interactive\\nprompt—a programming mode we’ll learn about in Chapter 3.\\n\\nThe Python Virtual Machine (PVM)\\nOnce your program has been compiled to byte code (or the byte code has been loaded\\nfrom existing .pyc files), it is shipped off for execution to something generally known\\nas the Python Virtual Machine (PVM, for the more acronym-inclined among you). The\\n\\nProgram Execution | 31\\n\\n\\x0cFigure 2-2. Python’s traditional runtime execution model: source code you type is translated to byte\\ncode, which is then run by the Python Virtual Machine. Your code is automatically compiled, but then\\nit is interpreted.\\n\\nPVM sounds more impressive than it is; really, it’s not a separate program, and it need\\nnot be installed by itself. In fact, the PVM is just a big code loop that iterates through\\nyour byte code instructions, one by one, to carry out their operations. The PVM is the\\nruntime engine of Python; it’s always present as part of the Python system, and it’s the\\ncomponent that truly runs your scripts. Technically, it’s just the last step of what is\\ncalled the “Python interpreter.”\\nFigure 2-2 illustrates the runtime structure described here. Keep in mind that all of this\\ncomplexity is deliberately hidden from Python programmers. Byte code compilation is\\nautomatic, and the PVM is just part of the Python system that you have installed on\\nyour machine. Again, programmers simply code and run files of statements, and Python\\nhandles the logistics of running them.\\n\\nPerformance implications\\nReaders with a background in fully compiled languages such as C and C++ might notice\\na few differences in the Python model. For one thing, there is usually no build or “make”\\nstep in Python work: code runs immediately after it is written. For another, Python byte\\ncode is not binary machine code (e.g., instructions for an Intel or ARM chip). Byte code\\nis a Python-specific representation.\\nThis is why some Python code may not run as fast as C or C++ code, as described in\\nChapter 1—the PVM loop, not the CPU chip, still must interpret the byte code, and\\nbyte code instructions require more work than CPU instructions. On the other hand,\\nunlike in classic interpreters, there is still an internal compile step—Python does not\\nneed to reanalyze and reparse each source statement’s text repeatedly. The net effect\\nis  that  pure  Python  code  runs  at  speeds  somewhere  between  those  of  a  traditional\\ncompiled language and a traditional interpreted language. See Chapter 1 for more on\\nPython performance tradeoffs.\\n\\nDevelopment implications\\nAnother ramification of Python’s execution model is that there is really no distinction\\nbetween the development and execution environments. That is, the systems that com-\\npile and execute your source code are really one and the same. This similarity may have\\n\\n32 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0ca bit more significance to readers with a background in traditional compiled languages,\\nbut in Python, the compiler is always present at runtime and is part of the system that\\nruns programs.\\nThis makes for a much more rapid development cycle. There is no need to precompile\\nand link before execution may begin; simply type and run the code. This also adds a\\nmuch more dynamic flavor to the language—it is possible, and often very convenient,\\nfor Python programs to construct and execute other Python programs at runtime. The\\neval and exec built-ins, for instance, accept and run strings containing Python program\\ncode. This structure is also why Python lends itself to product customization—because\\nPython code can be changed on the fly, users can modify the Python parts of a system\\nonsite without needing to have or compile the entire system’s code.\\nAt a more fundamental level, keep in mind that all we really have in Python is runtime—\\nthere is no initial compile-time phase at all, and everything happens as the program is\\nrunning. This even includes operations such as the creation of functions and classes\\nand the linkage of modules. Such events occur before execution in more static lan-\\nguages, but happen as programs execute in Python. As we’ll see, this makes for a much\\nmore dynamic programming experience than that to which some readers may be ac-\\ncustomed.\\n\\nExecution Model Variations\\nNow that we’ve studied the internal execution flow described in the prior section, I\\nshould note that it reflects the standard implementation of Python today but is not\\nreally a requirement of the Python language itself. Because of that, the execution model\\nis prone to changing with time. In fact, there are already a few systems that modify the\\npicture in Figure 2-2 somewhat. Before moving on, let’s briefly explore the most prom-\\ninent of these variations.\\n\\nPython Implementation Alternatives\\nStrictly speaking, as this book edition is being written, there are at least five imple-\\nmentations  of  the  Python  language—CPython,  Jython,  IronPython,  Stackless,  and\\nPyPy. Although there is much cross-fertilization of ideas and work between these Py-\\nthons, each is a separately installed software system, with its own developers and user\\nbase. Other potential candidates here include the Cython and Shed Skin systems, but\\nthey are discussed later as optimization tools because they do not implement the stan-\\ndard Python language (the former is a Python/C mix, and the latter is implicitly stati-\\ncally typed).\\nIn brief, CPython is the standard implementation, and the system that most readers\\nwill wish to use (if you’re not sure, this probably includes you). This is also the version\\nused in this book, though the core Python language presented here is almost entirely\\nthe same in the alternatives. All the other Python implementations have specific pur-\\n\\nExecution Model Variations\\n\\n| 33\\n\\n\\x0cposes and roles, though they can often serve in most of CPython’s capacities too. All\\nimplement the same Python language but execute programs in different ways.\\nFor example, PyPy is a drop-in replacement for CPython, which can run most programs\\nmuch quicker. Similarly, Jython and IronPython are completely independent imple-\\nmentations of Python that compile Python source for different runtime architectures,\\nto provide direct access to Java and .NET components. It is also possible to access Java\\nand .NET software from standard CPython programs—JPype and Python for .NET\\nsystems, for instance, allow standard CPython code to call out to Java and .NET com-\\nponents. Jython and IronPython offer more complete solutions, by providing full im-\\nplementations of the Python language.\\nHere’s  a  quick  rundown  on  the  most  prominent  Python  implementations  available\\ntoday.\\n\\nCPython: The standard\\nThe original, and standard, implementation of Python is usually called CPython when\\nyou want to contrast it with the other options (and just plain “Python” otherwise). This\\nname comes from the fact that it is coded in portable ANSI C language code. This is\\nthe Python that you fetch from http://www.python.org, get with the ActivePython and\\nEnthought distributions, and have automatically on most Linux and Mac OS X ma-\\nchines. If you’ve found a preinstalled version of Python on your machine, it’s probably\\nCPython, unless your company or organization is using Python in more specialized\\nways.\\nUnless you want to script Java or .NET applications with Python or find the benefits\\nof Stackless or PyPy compelling, you probably want to use the standard CPython sys-\\ntem. Because it is the reference implementation of the language, it tends to run the\\nfastest, be the most complete, and be more up-to-date and robust than the alternative\\nsystems. Figure 2-2 reflects CPython’s runtime architecture.\\n\\nJython: Python for Java\\nThe Jython system (originally known as JPython) is an alternative implementation of\\nthe Python language, targeted for integration with the Java programming language.\\nJython consists of Java classes that compile Python source code to Java byte code and\\nthen route the resulting byte code to the Java Virtual Machine (JVM). Programmers\\nstill code Python statements in .py text files as usual; the Jython system essentially just\\nreplaces the rightmost two bubbles in Figure 2-2 with Java-based equivalents.\\nJython’s goal is to allow Python code to script Java applications, much as CPython\\nallows Python to script C and C++ components. Its integration with Java is remarkably\\nseamless. Because Python code is translated to Java byte code, it looks and feels like a\\ntrue Java program at runtime. Jython scripts can serve as web applets and servlets, build\\nJava-based GUIs, and so on. Moreover, Jython includes integration support that allows\\nPython code to import and use Java classes as though they were coded in Python, and\\n\\n34 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0cJava code to run Python code as an embedded language. Because Jython is slower and\\nless robust than CPython, though, it is usually seen as a tool of interest primarily to\\nJava developers looking for a scripting language to serve as a frontend to Java code. See\\nJython’s website http://jython.org for more details.\\n\\nIronPython: Python for .NET\\nA third implementation of Python, and newer than both CPython and Jython, IronPy-\\nthon is designed to allow Python programs to integrate with applications coded to work\\nwith Microsoft’s .NET Framework for Windows, as well as the Mono open source\\nequivalent for Linux. .NET and its C# programming language runtime system are de-\\nsigned to be a language-neutral object communication layer, in the spirit of Microsoft’s\\nearlier COM model. IronPython allows Python programs to act as both client and server\\ncomponents,  gain  accessibility  both  to  and  from  other  .NET  languages,  and  lever-\\nage .NET technologies such as the Silverlight framework from their Python code.\\nBy implementation, IronPython is very much like Jython (and, in fact, was developed\\nby the same creator)—it replaces the last two bubbles in Figure 2-2 with equivalents\\nfor execution in the .NET environment. Also like Jython, IronPython has a special focus\\n—it is primarily of interest to developers integrating Python with .NET components.\\nFormerly developed by Microsoft and now an open source project, IronPython might\\nalso be able to take advantage of some important optimization tools for better perfor-\\nmance. For more details, consult http://ironpython.net and other resources to be had\\nwith a web search.\\n\\nStackless: Python for concurrency\\nStill other schemes for running Python programs have more focused goals. For example,\\nthe Stackless Python system is an enhanced version and reimplementation of the stan-\\ndard CPython language oriented toward concurrency. Because it does not save state on\\nthe C language call stack, Stackless Python can make Python easier to port to small\\nstack architectures, provides efficient multiprocessing options, and fosters novel pro-\\ngramming structures such as coroutines.\\nAmong other things, the microthreads that Stackless adds to Python are an efficient and\\nlightweight alternative to Python’s standard multitasking tools such as threads and\\nprocesses, and promise better program structure, more readable code, and increased\\nprogrammer productivity. CCP Games, the creator of EVE Online, is a well-known\\nStackless Python user, and a compelling Python user success story in general. Try http:\\n//stackless.com for more information.\\n\\nPyPy: Python for speed\\nThe PyPy system is another standard CPython reimplementation, focused on perfor-\\nmance. It provides a fast Python implementation with a JIT (just-in-time) compiler,\\nprovides tools for a “sandbox” model that can run untrusted code in a secure environ-\\n\\nExecution Model Variations\\n\\n| 35\\n\\n\\x0cment, and by default includes support for the prior section’s Stackless Python systems\\nand its microthreads to support massive concurrency.\\nPyPy is the successor to the original Psyco JIT, described ahead, and subsumes it with\\na complete Python implementation built for speed. A JIT is really just an extension to\\nthe PVM—the rightmost bubble in Figure 2-2—that translates portions of your byte\\ncode all the way to binary machine code for faster execution. It does this as your pro-\\ngram is running, not in a prerun compile step, and is able to created type-specific ma-\\nchine code for the dynamic Python language by keeping track of the data types of the\\nobjects your program processes. By replacing portions of your byte code this way, your\\nprogram runs faster and faster as it is executing. In addition, some Python programs\\nmay also take up less memory under PyPy.\\nAt this writing, PyPy supports Python 2.7 code (not yet 3.X) and runs on Intel x86\\n(IA-32) and x86_64 platforms (including Windows, Linux, and recent Macs), with\\nARM and PPC support under development. It runs most CPython code, though C\\nextension modules must generally be recompiled, and PyPy has some minor but subtle\\nlanguage differences, including garbage collection semantics that obviate some com-\\nmon coding patterns. For instance, its non-reference-count scheme means that tem-\\nporary files may not close and flush output buffers immediately, and may require man-\\nual close calls in some cases.\\nIn return, your code may run much quicker. PyPy currently claims a 5.7X speedup over\\nCPython across a range of benchmark programs (per http://speed.pypy.org/). In some\\ncases, its ability to take advantage of dynamic optimization opportunities can make\\nPython code as quick as C code, and occasionally faster. This is especially true for\\nheavily algorithmic or numeric programs, which might otherwise be recoded in C.\\nFor instance, in one simple benchmark we’ll see in Chapter 21, PyPy today clocks in\\nat 10X faster than CPython 2.7, and 100X faster than CPython 3.X. Though other\\nbenchmarks will vary, such speedups may be a compelling advantage in many domains,\\nperhaps even more so than leading-edge language features. Just as important, memory\\nspace is also optimized in PyPy—in the case of one posted benchmark, requiring 247\\nMB and completing in 10.3 seconds, compared to CPython’s 684 MB and 89 seconds.\\nPyPy’s tool chain is also general enough to support additional languages, including\\nPyrolog, a Prolog interpreter written in Python using the PyPy translator. Search for\\nPyPy’s website for more. PyPy currently lives at http://pypy.org, though the usual web\\nsearch may also prove fruitful over time. For an overview of its current performance, \\nalso see http://www.pypy.org/performance.html.\\n\\n36 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0cJust after I wrote this, PyPy 2.0 was released in beta form, adding support\\nfor the ARM processor, and still a Python 2.X-only implementation. Per\\nits 2.0 beta release notes:\\n\\n“PyPy is a very compliant Python interpreter, almost a drop-in replace-\\nment for CPython 2.7.3. It’s fast due to its integrated tracing JIT com-\\npiler. This release supports x86 machines running Linux 32/64, Mac OS\\nX 64 or Windows 32. It also supports ARM machines running Linux.”\\n\\nThe claims seem accurate. Using the timing tools we’ll study in Chap-\\nter 21, PyPy is often an order of magnitude (factor of 10) faster than\\nCPython 2.X and 3.X on tests I’ve run, and sometimes even better. This\\nis despite the fact that PyPy is a 32-bit build on my Windows test ma-\\nchine, while CPython is a faster 64-bit compile.\\n\\nNaturally the only benchmark that truly matters is your own code, and\\nthere are cases where CPython wins the race; PyPy’s file iterators, for\\ninstance, may clock in slower today. Still, given PyPy’s focus on perfor-\\nmance over language mutation, and especially its support for the nu-\\nmeric domain, many today see PyPy as an important path for Python.\\nIf you write CPU-intensive code, PyPy deserves your attention.\\n\\nExecution Optimization Tools\\nCPython and most of the alternatives of the prior section all implement the Python\\nlanguage in similar ways: by compiling source code to byte code and executing the byte\\ncode on an appropriate virtual machine. Some systems, such as the Cython hybrid, the\\nShed Skin C++ translator, and the just-in-time compilers in PyPy and Psyco instead\\nattempt to optimize the basic execution model. These systems are not required knowl-\\nedge at this point in your Python career, but a quick look at their place in the execution\\nmodel might help demystify the model in general.\\n\\nCython: A Python/C hybrid\\nThe Cython system (based on work done by the Pyrex project) is a hybrid language that\\ncombines Python code with the ability to call C functions and use C type declarations\\nfor variables, parameters, and class attributes. Cython code can be compiled to C code\\nthat uses the Python/C API, which may then be compiled completely. Though not\\ncompletely compatible with standard Python, Cython can be useful both for wrapping\\nexternal C libraries and for coding efficient C extensions for Python. See http://cython\\n.org for current status and details.\\n\\nShed Skin: A Python-to-C++ translator\\nShed Skin is an emerging system that takes a different approach to Python program\\nexecution—it attempts to translate Python source code to C++ code, which your com-\\nputer’s C++ compiler then compiles to machine code. As such, it represents a platform-\\nneutral approach to running Python code.\\n\\nExecution Model Variations\\n\\n| 37\\n\\n\\x0cShed Skin is still being actively developed as I write these words. It currently supports\\nPython 2.4 to 2.6 code, and it limits Python programs to an implicit statically typed\\nconstraint that is typical of most programs but is technically not normal Python, so we\\nwon’t go into further detail here. Initial results, though, show that it has the potential\\nto outperform both standard Python and Psyco-like extensions in terms of execution\\nspeed. Search the Web for details on the project’s current status.\\n\\nPsyco: The original just-in-time compiler\\nThe Psyco system is not another Python implementation, but rather a component that\\nextends the byte code execution model to make programs run faster. Today, Psyco is\\nsomething of an ex-project: it is still available for separate download, but has fallen out\\nof date with Python’s evolution, and is no longer actively maintained. Instead, its ideas\\nhave been incorporated into the more complete PyPy system described earlier. Still, the\\nongoing importance of the ideas Psyco explored makes them worth a quick look.\\nIn terms of Figure 2-2, Psyco is an enhancement to the PVM that collects and uses type\\ninformation while the program runs to translate portions of the program’s byte code\\nall the way down to true binary machine code for faster execution. Psyco accomplishes\\nthis translation without requiring changes to the code or a separate compilation step\\nduring development.\\nRoughly, while your program runs, Psyco collects information about the kinds of ob-\\njects being passed around; that information can be used to generate highly efficient\\nmachine code tailored for those object types. Once generated, the machine code then\\nreplaces the corresponding part of the original byte code to speed your program’s over-\\nall execution. The result is that with Psyco, your program becomes quicker over time\\nas it runs. In ideal cases, some Python code may become as fast as compiled C code\\nunder Psyco.\\nBecause this translation from byte code happens at program runtime, Psyco is known \\nas a just-in-time compiler. Psyco is different from the JIT compilers some readers may\\nhave seen for the Java language, though. Really, Psyco is a specializing JIT compiler—\\nit generates machine code tailored to the data types that your program actually uses.\\nFor example, if a part of your program uses different data types at different times, Psyco\\nmay generate a different version of machine code to support each different type com-\\nbination.\\nPsyco was shown to speed some Python code dramatically. According to its web page,\\nPsyco provides “2X to 100X speed-ups, typically 4X, with an unmodified Python in-\\nterpreter and unmodified source code, just a dynamically loadable C extension mod-\\nule.” Of equal significance, the largest speedups are realized for algorithmic code writ-\\nten in pure Python—exactly the sort of code you might normally migrate to C to op-\\ntimize. For more on Psyco, search the Web or see its successor—the PyPy project de-\\nscribed previously.\\n\\n38 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0cFrozen Binaries\\nSometimes when people ask for a “real” Python compiler, what they’re really seeking\\nis simply a way to generate standalone binary executables from their Python programs.\\nThis is more a packaging and shipping idea than an execution-flow concept, but it’s\\nsomewhat related. With the help of third-party tools that you can fetch off the Web, it\\nis possible to turn your Python programs into true executables, known as frozen bi-\\nnaries in the Python world. These programs can be run without requiring a Python\\ninstallation.\\nFrozen binaries bundle together the byte code of your program files, along with the\\nPVM  (interpreter)  and  any  Python  support  files  your  program  needs,  into  a  single\\npackage. There are some variations on this theme, but the end result can be a single\\nbinary executable program (e.g., an .exe file on Windows) that can easily be shipped\\nto customers. In Figure 2-2, it is as though the two rightmost bubbles—byte code and\\nPVM—are merged into a single component: a frozen binary file.\\nToday, a variety of systems are capable of generating frozen binaries, which vary in\\nplatforms and features: py2exe for Windows only, but with broad Windows support;\\nPyInstaller, which is similar to py2exe but also works on Linux and Mac OS X and is\\ncapable of generating self-installing binaries; py2app for creating Mac OS X applica-\\ntions; freeze, the original; and cx_freeze, which offers both Python 3.X and cross-plat-\\nform support. You may have to fetch these tools separately from Python itself, but they\\nare freely available.\\nThese tools are also constantly evolving, so consult http://www.python.org or your fa-\\nvorite web search engine for more details and status. To give you an idea of the scope\\nof these systems, py2exe can freeze standalone programs that use the tkinter, PMW,\\nwxPython, and PyGTK GUI libraries; programs that use the pygame game program-\\nming toolkit; win32com client programs; and more.\\nFrozen binaries are not the same as the output of a true compiler—they run byte code\\nthrough a virtual machine. Hence, apart from a possible startup improvement, frozen\\nbinaries run at the same speed as the original source files. Frozen binaries are also not\\ngenerally small (they contain a PVM), but by current standards they are not unusually\\nlarge either. Because Python is embedded in the frozen binary, though, it does not have\\nto be installed on the receiving end to run your program. Moreover, because your code\\nis embedded in the frozen binary, it is more effectively hidden from recipients.\\nThis single file-packaging scheme is especially appealing to developers of commercial\\nsoftware. For instance, a Python-coded user interface program based on the tkinter\\ntoolkit can be frozen into an executable file and shipped as a self-contained program\\non a CD or on the Web. End users do not need to install (or even have to know about)\\nPython to run the shipped program.\\n\\nExecution Model Variations\\n\\n| 39\\n\\n\\x0cFuture Possibilities?\\nFinally, note that the runtime execution model sketched here is really an artifact of the\\ncurrent  implementation  of  Python,  not  of  the  language  itself.  For  instance,  it’s  not\\nimpossible that a full, traditional compiler for translating Python source code to ma-\\nchine code may appear during the shelf life of this book (although the fact that one has\\nnot in over two decades makes this seem unlikely!).\\nNew byte code formats and implementation variants may also be adopted in the future.\\nFor instance:\\n\\n• The ongoing Parrot project aims to provide a common byte code format, virtual\\nmachine, and optimization techniques for a variety of programming languages,\\nincluding Python. Python’s own PVM runs Python code more efficiently than Par-\\nrot (as famously demonstrated by a pie challenge at a software conference—search\\nthe Web for details), but it’s unclear how Parrot will evolve in relation to Python\\nspecifically. See http://parrot.org or the Web at large for details.\\n\\n• The former Unladen Swallow project—an open source project developed by Goo-\\ngle engineers—sought to make standard Python faster by a factor of at least 5, and\\nfast enough to replace the C language in many contexts. This was an optimization\\nbranch of CPython (specifically Python 2.6), intended to be compatible yet faster\\nby virtue of adding a JIT to standard Python. As I write this in 2012, this project\\nseems to have drawn to a close (per its withdrawn Python PEP, it was “going the\\nway of the Norwegian Blue”). Still, its lessons gained may be leveraged in other\\nforms; search the Web for breaking developments.\\n\\nAlthough future implementation schemes may alter the runtime structure of Python\\nsomewhat, it seems likely that the byte code compiler will still be the standard for some\\ntime to come. The portability and runtime flexibility of byte code are important features\\nof many Python systems. Moreover, adding type constraint declarations to support\\nstatic compilation would likely break much of the flexibility, conciseness, simplicity,\\nand overall spirit of Python coding. Due to Python’s highly dynamic nature, any future\\nimplementation will likely retain many artifacts of the current PVM.\\n\\nChapter Summary\\nThis chapter introduced the execution model of Python—how Python runs your pro-\\ngrams—and explored some common variations on that model: just-in-time compilers\\nand the like. Although you don’t really need to come to grips with Python internals to\\nwrite Python scripts, a passing acquaintance with this chapter’s topics will help you\\ntruly  understand  how  your  programs  run  once  you  start  coding  them.  In  the  next\\nchapter, you’ll start actually running some code of your own. First, though, here’s the\\nusual chapter quiz.\\n\\n40 | Chapter 2:\\u2002How Python Runs Programs\\n\\n\\x0cTest Your Knowledge: Quiz\\n1. What is the Python interpreter?\\n2. What is source code?\\n3. What is byte code?\\n4. What is the PVM?\\n5. Name two or more variations on Python’s standard execution model.\\n6. How are CPython, Jython, and IronPython different?\\n7. What are Stackless and PyPy?\\n\\nTest Your Knowledge: Answers\\n1. The Python interpreter is a program that runs the Python programs you write.\\n2. Source code is the statements you write for your program—it consists of text in\\n\\ntext files that normally end with a .py extension.\\n\\n3. Byte code is the lower-level form of your program after Python compiles it. Python\\n\\nautomatically stores byte code in files with a .pyc extension.\\n\\n4. The PVM is the Python Virtual Machine—the runtime engine of Python that in-\\n\\nterprets your compiled byte code.\\n\\n5. Psyco, Shed Skin, and frozen binaries are all variations on the execution model. In\\naddition, the alternative implementations of Python named in the next two answers\\nmodify the model in some fashion as well—by replacing byte code and VMs, or by\\nadding tools and JITs.\\n\\n6. CPython is the standard implementation of the language. Jython and IronPython\\nimplement Python programs for use in Java and .NET environments, respectively;\\nthey are alternative compilers for Python.\\n\\n7. Stackless is an enhanced version of Python aimed at concurrency, and PyPy is a\\nreimplementation of Python targeted at speed. PyPy is also the successor to Psyco,\\nand incorporates the JIT concepts that Psyco pioneered.\\n\\nTest Your Knowledge: Answers\\n\\n| 41\\n\\n\\x0c\\x0cCHAPTER 3\\nHow You Run Programs\\n\\nOK, it’s time to start running some code. Now that you have a handle on the program\\nexecution model, you’re finally ready to start some real Python programming. At this\\npoint, I’ll assume that you have Python installed on your computer; if you don’t, see\\nthe start of the prior chapter and Appendix A for installation and configuration hints\\non various platforms. Our goal here is to learn how to run Python program code.\\nThere  are  multiple  ways  to  tell  Python  to  execute  the  code  you  type.  This  chapter\\ndiscusses all the program launching techniques in common use today. Along the way,\\nyou’ll learn how to both type code interactively, and how to save it in files to be run as\\noften as you like in a variety of ways: with system command lines, icon clicks, module\\nimports, exec calls, menu options in the IDLE GUI, and more.\\nAs for the previous chapter, if you have prior programming experience and are anxious\\nto start digging into Python itself, you may want to skim this chapter and move on to\\nChapter 4. But don’t skip this chapter’s early coverage of preliminaries and conven-\\ntions, its overview of debugging techniques, or its first look at module imports—a topic\\nessential to understanding Python’s program architecture, which we won’t revisit until\\na later part. I also encourage you to see the sections on IDLE and other IDEs, so you’ll\\nknow what tools are available when you start developing more sophisticated Python\\nprograms.\\n\\nThe Interactive Prompt\\nThis section gets us started with interactive coding basics. Because it’s our first look at\\nrunning code, we also cover some preliminaries here, such as setting up a working\\ndirectory and the system path, so be sure to read this section first if you’re relatively\\nnew to programming. This section also explains some conventions used throughout\\nthe book, so most readers should probably take at least a quick look here.\\n\\n43\\n\\n\\x0cStarting an Interactive Session\\nPerhaps the simplest way to run Python programs is to type them at Python’s interactive\\ncommand line, sometimes called the interactive prompt. There are a variety of ways to\\nstart this command line: in an IDE, from a system console, and so on. Assuming the\\ninterpreter is installed as an executable program on your system, the most platform-\\nneutral way to start an interactive interpreter session is usually just to type python at\\nyour operating system’s prompt, without any arguments. For example:\\n\\n% python\\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> ^Z\\n\\nTyping the word “python” at your system shell prompt like this begins an interactive\\nPython session; the “%” character at the start of this listing stands for a generic system\\nprompt in this book—it’s not input that you type yourself. On Windows, a Ctrl-Z gets\\nyou out of this session; on Unix, try Ctrl-D instead.\\nThe notion of a system shell prompt is generic, but exactly how you access it varies by\\nplatform:\\n\\n• On Windows, you can type python in a DOS console window—a program named\\ncmd.exe and usually known as Command Prompt. For more details on starting this\\nprogram,  see  this  chapter’s  sidebar  “Where  Is  Command  Prompt  on  Win-\\ndows?” on page 45.\\n\\n• On Mac OS X, you can start a Python interactive interpreter by double-clicking on\\nApplications→Utilities→Terminal,  and  then  typing  python  in  the  window  that\\nopens up.\\n\\n• On Linux (and other Unixes), you might type this command in a shell or terminal\\nwindow (for instance, in an xterm or console running a shell such as ksh or csh).\\n• Other systems may use similar or platform-specific devices. On handheld devices,\\nfor example, you might click the Python icon in the home or application window\\nto launch an interactive session.\\n\\nOn most platforms, you can start the interactive prompt in additional ways that don’t\\nrequire typing a command, but they vary per platform even more widely:\\n\\n• On Windows 7 and earlier, besides typing python in a shell window, you can also\\nbegin similar interactive sessions by starting the IDLE GUI (discussed later), or by\\nselecting the “Python (command line)” menu option from the Start button menu\\nfor Python, as shown in Figure 2-1 in Chapter 2. Both spawn a Python interactive\\nprompt with the same functionality obtained with a “python” command.\\n\\n• On Windows 8, you don’t have a Start button (at least as I write this), but there are\\nother ways to get to the tools described in the prior bullet, including tiles, Search,\\nFile Explorer, and the “All apps” interface on the Start screen. See Appendix A for\\nmore pointers on this platform.\\n\\n44 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c• Other platforms have similar ways to start a Python interactive session without\\ntyping commands, but they’re too specific to get into here; see your system’s doc-\\numentation for details.\\n\\nAnytime you see the >>> prompt, you’re in an interactive Python interpreter session—\\nyou can type any Python statement or expression here and run it immediately. We will\\nin a moment, but first we need to get a few startup details sorted out to make sure all\\nreaders are set to go.\\n\\nWhere Is Command Prompt on Windows?\\n\\nSo how do you start the command-line interface on Windows? Some Windows readers\\nalready know, but Unix developers and beginners may not; it’s not as prominent as\\nterminal or console windows on Unix systems. Here are some pointers on finding your\\nCommand Prompt, which vary slightly per Windows version.\\n\\nOn  Windows  7  and  earlier,  this  is  usually  found  in  the  Accessories  section  of  the\\nStart→All Programs menu, or you can run it by typing cmd in the Start→Run... dialog\\nbox or the Start menu’s search entry field. You can drag out a desktop shortcut to get\\nto it quicker if desired.\\n\\nOn Windows 8, you can access Command Prompt in the menu opened by right-clicking\\non the preview in the screen’s lower-left corner; in the Windows System section of the\\n“All  apps”  display  reached  by  right-clicking  your  Start  screen;  or  by  typing  cmd  or\\ncommand prompt in the input field of the Search charm pulled down from the screen’s\\nupper-right corner. There are probably additional routes, and touch screens offer sim-\\nilar access. And if you want to forget all that, pin it to your desktop taskbar for easy\\naccess next time around.\\n\\nThese procedures are prone to vary over time, and possibly even per computer and\\nuser. I’m trying to avoid making this a book on Windows, though, so I’ll cut this topic\\nshort here. When in doubt, try the system Help interface (whose usage may differ as\\nmuch as the tools it provides help for!).\\n\\nA note to any Unix users reading this sidebar who may be starting to feel like a fish out\\nof water: you may also be interested in the Cygwin system, which brings a full Unix\\ncommand prompt to Windows. See Appendix A for more pointers.\\n\\nThe System Path\\nWhen we typed python in the last section to start an interactive session, we relied on\\nthe fact that the system located the Python program for us on its program search path.\\nDepending on your Python version and platform, if you have not set your system’s\\nPATH environment variable to include Python’s install directory, you may need to replace\\nthe word “python” with the full path to the Python executable on your machine. On\\nUnix, Linux, and similar, something like /usr/local/bin/python or /usr/bin/python3\\nwill often suffice. On Windows, try typing C:\\\\Python33\\\\python (for version 3.3):\\n\\nThe Interactive Prompt\\n\\n| 45\\n\\n\\x0cc:\\\\code> c:\\\\python33\\\\python\\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> ^Z\\n\\nAlternatively, you can run a “cd” change-directory command to go to Python’s install\\ndirectory before typing python—try the cd c:\\\\python33 command on Windows, for\\nexample:\\n\\nc:\\\\code> cd c:\\\\python33\\nc:\\\\Python33> python\\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> ^Z\\n\\nBut you’ll probably want to set your PATH eventually, so a simple “python” suffices. If\\nyou don’t know what PATH is or how to set it, see Appendix A—it covers environment\\nvariables like this whose usage varies per platform, as well as Python command-line\\narguments we won’t be using much in this book. The short story for Windows users:\\nsee the Advanced settings in the System entry of your Control Panel. If you’re using\\nPython 3.3 and later, this is now automatic on Windows, as the next section explains.\\n\\nNew Windows Options in 3.3: PATH, Launcher\\nThe foregoing section and much of this chapter at large describe the generic state of\\nplay for all 2.X and 3.X Pythons prior to version 3.3. Starting with Python 3.3, the\\nWindows installer has an option to automatically add Python 3.3’s directory to your\\nsystem PATH, if enabled in the installer’s windows. If you use this option, you won’t\\nneed to type a directory path or issue a “cd” to run python commands as in the prior\\nsection. Be sure to select this option during the install if you want it, as it’s currently\\ndisabled by default.\\nMore dramatically, Python 3.3 for Windows ships with and automatically installs the \\nnew Windows launcher—a system that comes with new executable programs, py with\\na console and pyw without, that are placed in directories on your system path, and so\\nmay be run out of the box without any PATH configurations, change-directory com-\\nmands, or directory path prefixes:\\n\\nc:\\\\code> py\\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> ^Z\\n\\nc:\\\\code> py −2\\nPython 2.7.3 (default, Apr 10 2012, 23:24:47) [MSC v.1500 64 bit (AMD64)] ...\\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> ^Z\\n\\nc:\\\\code> py −3.1\\nPython 3.1.4 (default, Jun 12 2011, 14:16:16) [MSC v.1500 64 bit (AMD64)] ...\\n\\n46 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\\n>>> ^Z\\n\\nAs shown in the last two commands here, these executables also accept Python version\\nnumbers on the command line (and in Unix-style #! lines at the top of scripts, as dis-\\ncussed later), and are associated to open Python files when clicked just like the original\\npython executable—which is still available and works as before, but is somewhat su-\\nperseded by the launcher’s new programs.\\nThe launcher is a standard part of Python 3.3, and is available standalone for use with\\nother versions. We’ll see more on this new launcher in this and later chapters, including\\na brief look at its #! line support here. However, because it is of interest only to Windows\\nusers, and even for this group is present only in 3.3 or where installed separately, I’ve\\ncollected almost all of the details about the launcher in Appendix B.\\nIf you’ll be working on Windows under Python 3.3 or later, I suggest taking a brief\\ndetour to that appendix now, as it provides an alternative, and in some ways better,\\nway to run Python command lines and scripts. At a base level, launcher users can type\\npy instead of python in most of the system commands shown in this book, and may\\navoid some configuration steps. Especially on computers with multiple Python ver-\\nsions, though, the new launcher gives you more explicit control over which Python\\nruns your code.\\n\\nWhere to Run: Code Directories\\nNow that I’ve started showing you how to run code, I want to say a few words up front\\nabout where to run code. To keep things simple, in this chapter and book at large I’m\\ngoing to be running code from a working directory (a.k.a. folder) I’ve created on my\\nWindows computer called C:\\\\code—a subdirectory at the top of my main drive. That’s\\nwhere I’ll start most interactive sessions, and where I’ll be both saving and running\\nmost script files. This also means the files that examples will create will mostly show\\nup in this directory.\\nIf you’ll be working along, you should probably do something similar before we get\\nstarted. Here are some pointers if you need help getting set up with a working directory\\non your computer:\\n\\n• On Windows, you can make your working code directory in File Explorer or a\\nCommand Prompt window. In File Explorer, look for New Folder, see the File\\nmenu, or try a right-click. In Command Prompt, type and run a mkdir command,\\nusually after you cd to your desired parent directory (e.g., cd c\\\\: and mkdir code).\\nYour working directory can be located wherever you like and called whatever you\\nwish,  and  doesn’t  have  to  be  C:\\\\code  (I  chose  this  name  because  it’s  short  in\\nprompts). But running out of one directory will help you keep track of your work\\nand simplify some tasks. For more Windows hints, see this chapter’s sidebar on\\nCommand Prompt, as well as Appendix A.\\n\\nThe Interactive Prompt\\n\\n| 47\\n\\n\\x0c• On Unix-based systems (including Mac OS X and Linux), your working directory\\nmight be in /usr/home and be created by a mkdir command in a shell window or\\nfile explorer GUI specific to your platform, but the same concepts apply. The Cyg-\\nwin Unix-like system for Windows is similar too, though your directory names\\nmay vary (/home and /cygdrive/c are candidates).\\n\\nYou can store your code in Python’s install directory too (e.g., C:\\\\Python33 on Win-\\ndows) to simplify some command lines before setting PATH, but you probably shouldn’t\\n—this is for Python itself, and your files may not survive a move or uninstall.\\nOnce you’ve made your working directory, always start there to work along with the\\nexamples  in  this  book.  The  prompts  in  this  book  that  show  the  directory  that  I’m\\nrunning code in will reflect my Windows laptop’s working directory; when you see C:\\n\\\\code> or %, think the location and name of your own directory.\\n\\nWhat Not to Type: Prompts and Comments\\nSpeaking of prompts, this book sometimes shows system prompts as a generic %, and\\nsometimes in full C:\\\\code> Windows form. The former is meant to be platform agnostic\\n(and derives from earlier editions’ use of Linux), and the latter is used in Windows-\\nspecific contexts. I also add a space after system prompts just for readability in this\\nbook. When used, the % character at the start of a system command line stands for the\\nsystem’s prompt, whatever that may be on your machine. For instance, on my machine\\n% stands for C:\\\\code> in Windows Command Prompt, and just $ in my Cygwn install.\\nTo beginners: don’t type the % character (or the C:\\\\code system prompt it sometimes\\nstands for) you see in this book’s interaction listings yourself—this is text the system\\nprints. Type just the text after these system prompts. Similarly, do not type the >>>\\nand ... characters shown at the start of lines in interpreter interaction listings—these\\nare prompts that Python displays automatically as visual guides for interactive code\\nentry. Type just the text after these Python prompts. For instance, the ... prompt is\\nused for continuation lines in some shells, but doesn’t appear in IDLE, and shows up\\nin some but not all of this book’s listings; don’t type it yourself if it’s absent in your\\ninterface.\\nTo help you remember this, user inputs are shown in bold in this book, and prompts\\nare not. In some systems these prompts may differ (for instance, the PyPy performance-\\nfocused implementation described in Chapter 2 uses four-character >>>> and ....), but\\nthe same rules apply. Also keep in mind that commands typed after these system and\\nPython prompts are meant to be run immediately, and are not generally to be saved in\\nthe source files we will be creating; we’ll see why this distinction matters ahead.\\nIn the same vein, you normally don’t need to type text that starts with a # character in\\nlistings in this book—as you’ll learn, these are comments, not executable code. Except\\nwhen # is used to introduce a directive at the top of a script for Unix or the Python 3.3\\n\\n48 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cWindows launcher, you can safely ignore the text that follows it (more on Unix and\\nthe launcher later in this chapter and in Appendix B).\\n\\nIf you’re working along, interactive listings will drop most “...” contin-\\nuation prompts as of Chapter 17 to aid cut-and-paste of larger code such\\nas functions and classes from ebooks or other; until then, paste or type\\none line at a time and omit the prompts. At least initially, it’s important\\nto type code manually, to get a feel for syntax details and errors. Some\\nexamples will be listed either by themselves or in named files available\\nin the book’s examples package (per the preface), and we’ll switch be-\\ntween listing formats often; when in doubt, if you see “>>>”, it means\\nthe code is being typed interactively.\\n\\nRunning Code Interactively\\nWith those preliminaries out of the way, let’s move on to typing some actual code.\\nHowever it’s started, the Python interactive session begins by printing two lines of\\ninformational text giving the Python version number and a few hints shown earlier\\n(which I’ll omit from most of this book’s examples to save space), then prompts for\\ninput with >>> when it’s waiting for you to type a new Python statement or expression.\\nWhen working interactively, the results of your code are displayed below the >>> input\\nlines after you press the Enter key. For instance, here are the results of two Python\\nprint statements (print is really a function call in Python 3.X, but not in 2.X, so the\\nparentheses here are required in 3.X only):\\n\\n% python\\n>>> print(\\'Hello world!\\')\\nHello world!\\n>>> print(2 ** 8)\\n256\\n\\nThere it is—we’ve just run some Python code (were you expecting the Spanish Inqui-\\nsition?). Don’t worry about the details of the print statements shown here yet; we’ll\\nstart digging into syntax in the next chapter. In short, they print a Python string and\\nan integer, as shown by the output lines that appear after each >>> input line (2 ** 8\\nmeans 2 raised to the power 8 in Python).\\nWhen coding interactively like this, you can type as many Python commands as you\\nlike; each is run immediately after it’s entered. Moreover, because the interactive ses-\\nsion automatically prints the results of expressions you type, you don’t usually need to\\nsay “print” explicitly at this prompt:\\n\\n>>> lumberjack = \\'okay\\'\\n>>> lumberjack\\n\\'okay\\'\\n>>> 2 ** 8\\n256\\n\\nThe Interactive Prompt\\n\\n| 49\\n\\n\\x0c>>> ^Z                     # Use Ctrl-D (on Unix) or Ctrl-Z (on Windows) to exit\\n%\\n\\nHere, the first line saves a value by assigning it to a variable (lumberjack), which is\\ncreated by the assignment; and the last two lines typed are expressions (lumberjack and\\n2 ** 8), whose results are displayed automatically. Again, to exit an interactive session\\nlike this and return to your system shell prompt, type Ctrl-D on Unix-like machines,\\nand Ctrl-Z on Windows. In the IDLE GUI discussed later, either type Ctrl-D or simply\\nclose the window.\\nNotice the italicized note about this on the right side of this listing (staring with “#”\\nhere). I’ll use these throughout to add remarks about what is being illustrated, but you\\ndon’t need to type this text yourself. In fact, just like system and Python prompts, you\\nshouldn’t type this when it’s on a system command line; the “#” part is taken as a\\ncomment by Python but may be an error at a system prompt.\\nNow, we didn’t do much in this session’s code—just typed some Python print and\\nassignment statements, along with a few expressions, which we’ll study in detail later.\\nThe main thing to notice is that the interpreter executes the code entered on each line\\nimmediately, when the Enter key is pressed.\\nFor example, when we typed the first print statement at the >>> prompt, the output (a\\nPython string) was echoed back right away. There was no need to create a source code\\nfile, and no need to run the code through a compiler and linker first, as you’d normally\\ndo when using a language such as C or C++. As you’ll see in later chapters, you can\\nalso run multiline statements at the interactive prompt; such a statement runs imme-\\ndiately after you’ve entered all of its lines and pressed Enter twice to add a blank line.\\n\\nWhy the Interactive Prompt?\\nThe interactive prompt runs code and echoes results as you go, but it doesn’t save your\\ncode in a file. Although this means you won’t do the bulk of your coding in interactive\\nsessions, the interactive prompt turns out to be a great place to both experiment with\\nthe language and test program files on the fly.\\n\\nExperimenting\\nBecause code is executed immediately, the interactive prompt is a perfect place to ex-\\nperiment with the language and will be used often in this book to demonstrate smaller\\nexamples. In fact, this is the first rule of thumb to remember: if you’re ever in doubt\\nabout how a piece of Python code works, fire up the interactive command line and try\\nit out to see what happens.\\nFor instance, suppose you’re reading a Python program’s code and you come across\\nan expression like \\'Spam!\\' * 8 whose meaning you don’t understand. At this point,\\nyou can spend 10 minutes wading through manuals, books, and the Web to try to figure\\nout what the code does, or you can simply run it interactively:\\n\\n50 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c% python\\n>>> \\'Spam!\\' * 8                                  # Learning by trying\\n\\'Spam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\'\\n\\nThe immediate feedback you receive at the interactive prompt is often the quickest way\\nto deduce what a piece of code does. Here, it’s clear that it does string repetition: in\\nPython * means multiply for numbers, but repeat for strings—it’s like concatenating a\\nstring to itself repeatedly (more on strings in Chapter 4).\\nChances are good that you won’t break anything by experimenting this way—at least,\\nnot yet. To do real damage, like deleting files and running shell commands, you must\\nreally try, by importing modules explicitly (you also need to know more about Python’s\\nsystem interfaces in general before you will become that dangerous!). Straight Python\\ncode is almost always safe to run.\\nFor instance, watch what happens when you make a mistake at the interactive prompt:\\n\\n>>> X                                            # Making mistakes\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nNameError: name \\'X\\' is not defined\\n\\nIn Python, using a variable before it has been assigned a value is always an error—\\notherwise, if names were filled in with defaults, some errors might go undetected. This\\nmeans you must initial counters to zero before you can add to them, must initial lists\\nbefore extending them, and so on; you don’t declare variables, but they must be as-\\nsigned before you can fetch their values.\\nWe’ll learn more about that later; the important point here is that you don’t crash\\nPython or your computer when you make a mistake this way. Instead, you get a mean-\\ningful error message pointing out the mistake and the line of code that made it, and\\nyou can continue on in your session or script. In fact, once you get comfortable with\\nPython, its error messages may often provide as much debugging support as you’ll need\\n(you’ll  learn  more  about  debugging  options  in  the  sidebar  “Debugging  Python\\nCode” on page 83).\\n\\nTesting\\nBesides  serving  as  a  tool  for  experimenting  while  you’re  learning  the  language,  the\\ninteractive interpreter is also an ideal place to test code you’ve written in files. You can\\nimport your module files interactively and run tests on the tools they define by typing\\ncalls at the interactive prompt on the fly.\\nFor instance, the following tests a function in a precoded module that ships with Python\\nin its standard library (it prints the name of the directory you’re currently working in,\\nwith a doubled-up backslash that stands for just one), but you can do the same once\\nyou start writing module files of your own:\\n\\n>>> import os\\n>>> os.getcwd()                                  # Testing on the fly\\n\\'c:\\\\\\\\code\\'\\n\\nThe Interactive Prompt\\n\\n| 51\\n\\n\\x0cMore generally, the interactive prompt is a place to test program components, regard-\\nless of their source—you can import and test functions and classes in your Python files,\\ntype calls to linked-in C functions, exercise Java classes under Jython, and more. Partly\\nbecause of its interactive nature, Python supports an experimental and exploratory\\nprogramming style you’ll find convenient when getting started. Although Python pro-\\ngrammers also test with in-file code (and we’ll learn ways to make this simple later in\\nthe book), for many, the interactive prompt is still their first line of testing defense.\\n\\nUsage Notes: The Interactive Prompt\\nAlthough the interactive prompt is simple to use, there are a few tips that beginners\\nshould keep in mind. I’m including lists of common mistakes like the following in this\\nchapter for reference, but they might also spare you from a few headaches if you read\\nthem up front:\\n\\n• Type  Python  commands  only.  First  of  all,  remember  that  you  can  only  type\\nPython code at Python’s >>> prompt, not system commands. There are ways to\\nrun system commands from within Python code (e.g., with os.system), but they\\nare not as direct as simply typing the commands themselves.\\n\\n• print statements are required only in files. Because the interactive interpreter\\nautomatically prints the results of expressions, you do not need to type complete\\nprint statements interactively. This is a nice feature, but it tends to confuse users\\nwhen  they  move  on  to  writing  code  in  files:  within  a  code  file,  you  must  use\\nprint statements to see your output because expression results are not automati-\\ncally echoed. Remember, you must say print in files, but it’s optional interactively.\\n• Don’t indent at the interactive prompt (yet). When typing Python programs,\\neither interactively or into a text file, be sure to start all your unnested statements\\nin  column  1  (that  is,  all  the  way  to  the  left).  If  you  don’t,  Python  may  print  a\\n“SyntaxError” message, because blank space to the left of your code is taken to be\\nindentation that groups nested statements. Until Chapter 10, all statements you\\nwrite will be unnested, so this includes everything for now. Remember, a leading\\nspace generates an error message, so don’t start with a space or tab at the interactive\\nprompt unless it’s nested code.\\n\\n• Watch out for prompt changes for compound statements.  We  won’t  meet\\ncompound (multiline) statements until Chapter 4 and not in earnest until Chap-\\nter 10, but as a preview, you should know that when typing lines 2 and beyond of\\na compound statement interactively, the prompt may change. In the simple shell\\nwindow interface, the interactive prompt changes to ... instead of >>> for lines 2\\nand beyond; in the IDLE GUI interface, lines after the first are instead automatically\\nindented.\\nYou’ll see why this matters in Chapter 10. For now, if you happen to come across\\na ... prompt or a blank line when entering your code, it probably means that you’ve\\nsomehow  confused  interactive  Python  into  thinking  you’re  typing  a  multiline\\n\\n52 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cstatement. Try hitting the Enter key or a Ctrl-C combination to get back to the\\nmain prompt. The >>> and ... prompt strings can also be changed (they are avail-\\nable in the built-in module sys), but I’ll assume they have not been in the book’s\\nexample listings.\\n\\n• Terminate  compound  statements  at  the  interactive  prompt  with  a  blank\\nline. At the interactive prompt, inserting a blank line (by hitting the Enter key at\\nthe start of a line) is necessary to tell interactive Python that you’re done typing the\\nmultiline statement. That is, you must press Enter twice to make a compound\\nstatement run. By contrast, blank lines are not required in files and are simply\\nignored if present. If you don’t press Enter twice at the end of a compound state-\\nment when working interactively, you’ll appear to be stuck in a limbo state, because\\nthe interactive interpreter will do nothing at all—it’s waiting for you to press Enter\\nagain!\\n\\n• The interactive prompt runs one statement at a time. At the interactive prompt, \\nyou must run one statement to completion before typing another. This is natural\\nfor simple statements, because pressing the Enter key runs the statement entered.\\nFor compound statements, though, remember that you must submit a blank line\\nto terminate the statement and make it run before you can type the next statement.\\n\\nEntering multiline statements\\nAt the risk of repeating myself, I’ve received multiple emails from readers who’d gotten\\nburned by the last two points, so they probably merit emphasis. I’ll introduce multiline\\n(a.k.a. compound) statements in the next chapter, and we’ll explore their syntax more\\nformally later in this book. Because their behavior differs slightly in files and at the\\ninteractive prompt, though, two cautions are in order here.\\nFirst, be sure to terminate multiline compound statements like for loops and if tests\\nat the interactive prompt with a blank line. In other words, you must press the Enter\\nkey twice, to terminate the whole multiline statement and then make it run. For example\\n(pun not intended):\\n\\n>>> for x in \\'spam\\':\\n...     print(x)              # Press Enter twice here to make this loop run\\n...\\n\\nYou don’t need the blank line after compound statements in a script file, though; this\\nis required only at the interactive prompt. In a file, blank lines are not required and are\\nsimply ignored when present; at the interactive prompt, they terminate multiline state-\\nments.  Reminder:  the  ...  continuation  line  prompt  in  the  preceding  is  printed  by\\nPython automatically as a visual guide; it may not appear in your interface (e.g., IDLE),\\nand is sometimes omitted by this book, but do not type it yourself if it’s absent.\\nAlso bear in mind that the interactive prompt runs just one statement at a time: you\\nmust press Enter twice to run a loop or other multiline statement before you can type\\nthe next statement:\\n\\nThe Interactive Prompt\\n\\n| 53\\n\\n\\x0c>>> for x in \\'spam\\':\\n...     print(x)              # Press Enter twice before a new statement\\n... print(\\'done\\')\\n  File \"<stdin>\", line 3\\n    print(\\'done\\')\\n        ^\\nSyntaxError: invalid syntax\\n\\nThis means you can’t cut and paste multiple lines of code into the interactive prompt,\\nunless the code includes blank lines after each compound statement. Such code is better\\nrun in a file—which brings us to the next section’s topic.\\n\\nSystem Command Lines and Files\\nAlthough the interactive prompt is great for experimenting and testing, it has one big\\ndisadvantage: programs you type there go away as soon as the Python interpreter ex-\\necutes them. Because the code you type interactively is never stored in a file, you can’t\\nrun it again without retyping it from scratch. Cut-and-paste and command recall can\\nhelp some here, but not much, especially when you start writing larger programs. To\\ncut and paste code from an interactive session, you would have to edit out Python\\nprompts, program outputs, and so on—not exactly a modern software development\\nmethodology!\\nTo save programs permanently, you need to write your code in files, which are usually\\nknown as modules. Modules are simply text files containing Python statements. Once\\nthey are coded, you can ask the Python interpreter to execute the statements in such a\\nfile any number of times, and in a variety of ways—by system command lines, by file\\nicon clicks, by options in the IDLE user interface, and more. Regardless of how it is\\nrun, Python executes all the code in a module file from top to bottom each time you\\nrun the file.\\nTerminology in this domain can vary somewhat. For instance, module files are often\\nreferred to as programs in Python—that is, a program is considered to be a series of\\nprecoded statements stored in a file for repeated execution. Module files that are run\\ndirectly are also sometimes called scripts—an informal term usually meaning a top-level\\nprogram file. Some reserve the term “module” for a file imported from another file, and\\n“script” for the main file of a program; we generally will here, too (though you’ll have\\nto stay tuned for more on the meaning of “top-level,” imports, and main files later in\\nthis chapter).\\nWhatever you call them, the next few sections explore ways to run code typed into\\nmodule files. In this section, you’ll learn how to run files in the most basic way: by\\nlisting  their  names  in  a  python  command  line  entered  at  your  computer’s  system\\nprompt. Though it might seem primitive to some—and can often be avoided altogether\\nby using a GUI like IDLE, discussed later—for many programmers a system shell com-\\nmand-line  window,  together  with  a  text  editor  window,  constitutes  as  much  of  an\\n\\n54 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cintegrated development environment as they will ever need, and provides more direct\\ncontrol over programs.\\n\\nA First Script\\nLet’s get started. Open your favorite text editor (e.g., vi, Notepad, or the IDLE editor),\\ntype the following statements into a new text file named script1.py, and save it in your\\nworking code directory that you set up earlier:\\n\\n# A first Python script\\nimport sys                  # Load a library module\\nprint(sys.platform)\\nprint(2 ** 100)             # Raise 2 to a power\\nx = \\'Spam!\\'\\nprint(x * 8)                # String repetition\\n\\nThis file is our first official Python script (not counting the two-liner in Chapter 2). You\\nshouldn’t worry too much about this file’s code, but as a brief description, this file:\\n\\n• Imports a Python module (libraries of additional tools), to fetch the name of the\\n\\nplatform\\n\\n• Runs three print function calls, to display the script’s results\\n• Uses a variable named x, created when it’s assigned, to hold onto a string object\\n• Applies various object operations that we’ll begin studying in the next chapter\\n\\nThe sys.platform here is just a string that identifies the kind of computer you’re work-\\ning on; it lives in a standard Python module called sys, which you must import to load\\n(again, more on imports later).\\nFor color, I’ve also added some formal Python comments here—the text after the #\\ncharacters.  I  mentioned  these  earlier,  but  should  be  more  formal  now  that  they’re\\nshowing up in scripts. Comments can show up on lines by themselves, or to the right\\nof code on a line. The text after a # is simply ignored as a human-readable comment\\nand is not considered part of the statement’s syntax. If you’re copying this code, you\\ncan ignore the comments; they are just informative. In this book, we usually use a\\ndifferent formatting style to make comments more visually distinctive, but they’ll ap-\\npear as normal text in your code.\\nAgain, don’t focus on the syntax of the code in this file for now; we’ll learn about all\\nof it later. The main point to notice is that you’ve typed this code into a file, rather than\\nat the interactive prompt. In the process, you’ve coded a fully functional Python script.\\nNotice that the module file is called script1.py. As for all top-level files, it could also be\\ncalled simply script, but files of code you want to import into a client have to end with\\na .py suffix. We’ll study imports later in this chapter. Because you may want to import\\nthem in the future, it’s a good idea to use .py suffixes for most Python files that you\\ncode. Also, some text editors detect Python files by their .py suffix; if the suffix is not\\npresent, you may not get features like syntax colorization and automatic indentation.\\n\\nSystem Command Lines and Files\\n\\n| 55\\n\\n\\x0cRunning Files with Command Lines\\nOnce you’ve saved this text file, you can ask Python to run it by listing its full filename\\nas the first argument to a python command like the following typed at the system shell\\nprompt (don’t type this at Python’s interactive prompt, and read on to the next para-\\ngraph if this doesn’t work right away for you):\\n\\n% python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nAgain, you can type such a system shell command in whatever your system provides\\nfor command-line entry—a Windows Command Prompt window, an xterm window,\\nor similar. But be sure to run this in the same working directory where you’ve saved\\nyour script file (“cd” there first if needed), and be sure to run this at the system prompt,\\nnot Python’s “>>>” prompt. Also remember to replace the command’s word “python”\\nwith a full directory path as we did before if your PATH setting is not configured, though\\nthis isn’t required for the “py” Windows launcher program, and may not be required\\nin 3.3 and later.\\nAnother note to beginners: do not type any of the preceding text in the script1.py source\\nfile you created in the prior section. This text is a system command and program output,\\nnot program code. The first line here is the shell command used to run the source file,\\nand the lines following it are the results produced by the source file’s print statements.\\nAnd again, remember that the % stands for the system prompt—don’t type it yourself\\n(not to nag, but it’s a remarkably common early mistake).\\nIf all works as planned, this shell command makes Python run the code in this file line\\nby line, and you will see the output of the script’s three print statements—the name\\nof the underlying platform as known Python, 2 raised to the power 100, and the result\\nof the same string repetition expression we saw earlier (again, more on the meaning of\\nthe last two of these in Chapter 4).\\nIf all didn’t work as planned, you’ll get an error message—make sure you’ve entered\\nthe code in your file exactly as shown, and try again. The next section has additional\\noptions and pointers on this process, and we’ll talk about debugging options in the\\nsidebar “Debugging Python Code” on page 83, but at this point in the book your best\\nbet is probably rote imitation. And if all else fails, you might also try running under the\\nIDLE GUI discussed ahead—a tool that sugarcoats some launching details, though\\nsometimes at the expense of the more explicit control you have when using command\\nlines.\\nYou can also fetch the code examples off the Web if copying grows too tedious or error-\\nprone, though typing some code initially will help you learn to avoid syntax errors. See\\nthe preface for details on how to obtain the book’s example files.\\n\\n56 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cCommand-Line Usage Variations\\nBecause this scheme uses shell command lines to start Python programs, all the usual\\nshell syntax applies. For instance, you can route the printed output of a Python script\\nto a file to save it for later use or inspection by using special shell syntax:\\n\\n% python script1.py > saveit.txt\\n\\nIn this case, the three output lines shown in the prior run are stored in the file sa-\\nveit.txt instead of being printed. This is generally known as stream redirection; it works\\nfor input and output text and is available on Windows and Unix-like systems. This is\\nnice for testing, as you can write programs that watch for changes in other programs’\\noutputs. It also has little to do with Python, though (Python simply supports it), so we\\nwill skip further details on shell redirection syntax here.\\nIf you are working on a Windows platform, this example works the same, but the system\\nprompt is normally different as described earlier:\\n\\nC:\\\\code> python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nAs usual, if you haven’t set your PATH environment variable to include the full directory\\npath to python, be sure to include this in your command, or run a change-directory\\ncommand to go to the path first:\\n\\nC:\\\\code> C:\\\\python33\\\\python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nAlternatively, if you’re using the Windows launcher new in Python 3.3 (described ear-\\nlier), a py command will have the same effect, but does not require a directory path or\\nPATH settings, and allows you to specify Python version numbers on the command line\\ntoo:\\n\\nc:\\\\code> py −3 script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nOn all recent versions of Windows, you can also type just the name of your script, and\\nomit the name of Python itself. Because newer Windows systems use the Windows\\nRegistry (a.k.a. filename associations) to find a program with which to run a file, you\\ndon’t need to name “python” or “py” on the command line explicitly to run a .py file.\\nThe prior command, for example, could be simplified to the following on most Win-\\ndows machines, and will automatically be run by python prior to 3.3, and by py in 3.3\\nand later—just as though you had clicked on the file’s icon in Explorer (more on this\\noption ahead):\\n\\nC:\\\\code> script1.py\\n\\nSystem Command Lines and Files\\n\\n| 57\\n\\n\\x0cFinally, remember to give the full path to your script file if it lives in a different directory\\nfrom the one in which you are working. For example, the following system command\\nline, run from D:\\\\other, assumes Python is in your system path but runs a file located\\nelsewhere:\\n\\nC:\\\\code>  cd D:\\\\other\\nD:\\\\other> python c:\\\\code\\\\script1.py\\n\\nIf  your  PATH  doesn’t  include  Python’s  directory,  you’re  not  using  the  Windows\\nlauncher’s py program, and neither Python nor your script file is in the directory you’re\\nworking in, use full paths for both:\\n\\nD:\\\\other> C:\\\\Python33\\\\python c:\\\\code\\\\script1.py\\n\\nUsage Notes: Command Lines and Files\\nRunning program files from system command lines is a fairly straightforward launch\\noption, especially if you are familiar with command lines in general from prior work.\\nIt’s also perhaps the most portable way to run Python programs since nearly every\\ncomputer has some notion of a command line and directory structure. For newcomers,\\nthough, here are a few pointers about common beginner traps that might help you\\navoid some frustration:\\n\\n• Beware of automatic extensions on Windows and IDLE. If you use the Note-\\npad program to code program files on Windows, be careful to pick the type All\\nFiles when it comes time to save your file, and give the file a .py suffix explicitly.\\nOtherwise,  Notepad  will  save  your  file  with  a  .txt  extension  (e.g.,  as\\nscript1.py.txt), making it difficult to use in some schemes; it won’t be importable,\\nfor example.\\nWorse, Windows hides file extensions by default, so unless you have changed your\\nview options you may not even notice that you’ve coded a text file and not a Python\\nfile. The file’s icon may give this away—if it doesn’t have a snake of some sort on\\nit, you may have trouble. Uncolored code in IDLE and files that open to edit instead\\nof run when clicked are other symptoms of this problem.\\nMicrosoft Word similarly adds a .doc extension by default; much worse, it adds\\nformatting characters that are not legal Python syntax. As a rule of thumb, always\\npick All Files when saving under Windows, or use a more programmer-friendly\\ntext editor such as IDLE. IDLE does not even add a .py suffix automatically—a\\nfeature some programmers tend to like, but some users do not.\\n\\n• Use file extensions and directory paths at system prompts, but not for im-\\nports. Don’t forget to type the full name of your file in system command lines—\\nthat is, use python script1.py rather than python script1. By contrast, Python’s\\nimport statements, which we’ll meet later in this chapter, omit both the .py file\\nsuffix and the directory path (e.g.,  import script1). This may seem trivial, but\\nconfusing these two is a common mistake.\\n\\n58 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cAt the system prompt, you are in a system shell, not Python, so Python’s module\\nfile search rules do not apply. Because of that, you must include both the .py ex-\\ntension and, if necessary, the full directory path leading to the file you wish to run.\\nFor instance, to run a file that resides in a different directory from the one in which\\nyou  are  working,  you  would  typically  list  its  full  path  (e.g.,  python  d:\\\\tests\\n\\\\spam.py). Within Python code, however, you can just say import spam and rely on\\nthe Python module search path to locate your file, as described later.\\n\\n• Use print statements in files. Yes, we’ve already been over this, but it is such a\\ncommon mistake that it’s worth repeating at least once here. Unlike in interactive\\ncoding, you generally must use print statements to see output from program files.\\nIf you don’t see any output, make sure you’ve said “print” in your file. print state-\\nments are not required in an interactive session, since Python automatically echoes\\nexpression results; prints don’t hurt here, but are superfluous typing.\\n\\nUnix-Style Executable Scripts: #!\\nOur next launching technique is really a specialized form of the prior, which, despite\\nthis section’s title, can apply to program files run on both Unix and Windows today.\\nSince it has its roots on Unix, let’s begin this story there.\\n\\nUnix Script Basics\\nIf you are going to use Python on a Unix, Linux, or Unix-like system, you can also turn\\nfiles of Python code into executable programs, much as you would for programs coded\\nin a shell language such as csh or ksh. Such files are usually called executable scripts. In\\nsimple terms, Unix-style executable scripts are just normal text files containing Python\\nstatements, but with two special properties:\\n\\n• Their first line is special. Scripts usually start with a line that begins with the \\ncharacters #! (often called “hash bang” or “shebang”), followed by the path to the\\nPython interpreter on your machine.\\n\\n• They usually have executable privileges. Script files are usually marked as ex-\\necutable to tell the operating system that they may be run as top-level programs.\\nOn Unix systems, a command such as chmod +x file.py usually does the trick.\\n\\nLet’s look at an example for Unix-like systems. Use your text editor again to create a\\nfile of Python code called brian:\\n\\n#!/usr/local/bin/python\\nprint(\\'The Bright Side \\' + \\'of Life...\\')        # + means concatenate for strings\\n\\nThe special line at the top of the file tells the system where the Python interpreter lives.\\nTechnically, the first line is a Python comment. As mentioned earlier, all comments in\\nPython programs start with a # and span to the end of the line; they are a place to insert\\nextra information for human readers of your code. But when a comment such as the\\n\\nUnix-Style Executable Scripts: #!\\n\\n| 59\\n\\n\\x0cfirst line in this file appears, it’s special on Unix because the operating system shell uses\\nit to find an interpreter for running the program code in the rest of the file.\\nAlso, note that this file is called simply brian, without the .py suffix used for the module\\nfile earlier. Adding a .py to the name wouldn’t hurt (and might help you remember that\\nthis is a Python program file), but because you don’t plan on letting other modules\\nimport the code in this file, the name of the file is irrelevant. If you give the file executable\\nprivileges with a chmod +x brian shell command, you can run it from the operating\\nsystem  shell  as  though  it  were  a  binary  program  (for  the  following,  either  make\\nsure ., the current directory, is in your system PATH setting, or run this with ./brian):\\n\\n% brian\\nThe Bright Side of Life...\\n\\nThe Unix env Lookup Trick\\nOn some Unix systems, you can avoid hardcoding the path to the Python interpreter\\nin your script file by writing the special first-line comment like this:\\n\\n#!/usr/bin/env python\\n...script goes here...\\n\\nWhen coded this way, the env program locates the Python interpreter according to your\\nsystem search path settings (in most Unix shells, by looking in all the directories listed\\nin your PATH environment variable). This scheme can be more portable, as you don’t\\nneed to hardcode a Python install path in the first line of all your scripts. That way, if\\nyour scripts ever move to a new machine, or your Python ever moves to a new location,\\nyou must update just PATH, not all your scripts.\\nProvided you have access to env everywhere, your scripts will run no matter where\\nPython lives on your system. In fact, this env form is generally recommended today over\\neven  something  as  generic  as  /usr/bin/python,  because  some  platforms  may  install\\nPython elsewhere. Of course, this assumes that env lives in the same place everywhere\\n(on some machines, it may be in /sbin, /bin, or elsewhere); if not, all portability bets are\\noff!\\n\\nThe Python 3.3 Windows Launcher: #! Comes to Windows\\nA note for Windows users running Python 3.2 and earlier: the method described here\\nis a Unix trick, and it may not work on your platform. Not to worry; just use the basic\\ncommand-line technique explored earlier. List the file’s name on an explicit python\\ncommand line:1\\n\\nC:\\\\code> python brian\\nThe Bright Side of Life...\\n\\nIn this case, you don’t need the special #! comment at the top (although Python just\\nignores it if it’s present), and the file doesn’t need to be given executable privileges. In\\nfact, if you want to run files portably between Unix and Microsoft Windows, your life\\n\\n60 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cwill probably be simpler if you always use the basic command-line approach, not Unix-\\nstyle scripts, to launch programs.\\nIf you’re using Python 3.3 or later, though, or have its Windows launcher installed\\nseparately, it turns out that Unix-style #! lines do mean something on Windows too.\\nBesides offering the py executable described earlier, the new Windows launcher men-\\ntioned earlier attempts to parse #! lines to determine which Python version to launch\\nto run your script’s code. Moreover, it allows you to give the version number in full or\\npartial  forms,  and  recognizes  most  common  Unix  patterns  for  this  line,  including\\nthe /usr/bin/env form.\\nThe launcher’s #! parsing mechanism is applied when you run scripts from command\\nlines with the py program, and when you click Python file icons (in which case py is run\\nimplicitly by filename associations). Unlike Unix, you do not need to mark files with\\nexecutable privileges for this to work on Windows, because filename associations ach-\\nieve similar results.\\nFor example, the first of the following is run by Python 3.X and the second by 2.X\\n(without an explicit number, the launcher defaults to 2.X unless you set a PY_PYTHON\\nenvironment variable):\\n\\nc:\\\\code> type robin3.py\\n#!/usr/bin/python3\\nprint(\\'Run\\', \\'away!...\\')            # 3.X function\\n\\nc:\\\\code> py robin3.py               # Run file per #! line version\\nRun away!...\\n\\nc:\\\\code> type robin2.py\\n#!python2\\nprint \\'Run\\', \\'away more!...\\'        # 2.X statement\\n\\nc:\\\\code> py robin2.py               # Run file per #! line version\\nRun away more!...\\n\\nThis works in addition to passing versions on command lines—we saw this briefly\\nearlier for starting the interactive prompt, but it works the same when launching a script\\nfile:\\n\\nc:\\\\code> py −3.1 robin3.py          # Run per command-line argument\\nRun away!...\\n\\nThe net effect is that the launcher allows Python versions to be specified on both a per-\\nfile and per-command basis, by using #! lines and command-line arguments, respec-\\n\\n1. As we discussed when exploring command lines, all recent Windows versions also let you type just the\\nname of a .py file at the system command line—they use the Registry to determine that the file should be\\nopened with Python (e.g., typing brian.py is equivalent to typing python brian.py). This command-line\\nmode is similar in spirit to the Unix #!, though it is system-wide on Windows, not per-file. It also requires\\nan  explicit  .py  extension:  filename  associations  won’t  work  without  it.  Some  programs  may  actually\\ninterpret  and  use  a  first  #!  line  on  Windows  much  like  on  Unix  (including  Python  3.3’s  Windows\\nlauncher), but the system shell on Windows itself simply ignores it.\\n\\nUnix-Style Executable Scripts: #!\\n\\n| 61\\n\\n\\x0ctively. At least that’s the very short version of the launcher’s story. If you’re using Python\\n3.3  or  later  on  Windows  or  may  in  the  future,  I  recommend  a  side  trip  to  the  full\\nlauncher story in Appendix B if you haven’t made one already.\\n\\nClicking File Icons\\nIf you’re not a fan of command lines, you can generally avoid them by launching Python\\nscripts with file icon clicks, development GUIs, and other schemes that vary per plat-\\nform. Let’s take a quick look at the first of these alternatives here.\\n\\nIcon-Click Basics\\nIcon clicks are supported on most platforms in one form or another. Here’s a rundown\\nof how these might be structured on your computer:\\n\\nWindows icon clicks\\n\\nOn Windows, the Registry makes opening files with icon clicks easy. When in-\\nstalled, Python uses Windows filename associations to automatically register itself\\nto be the program that opens Python program files when they are clicked. Because\\nof that, it is possible to launch the Python programs you write by simply clicking\\n(or double-clicking) on their file icons with your mouse cursor.\\nSpecifically, a clicked file will be run by one of two Python programs, depending\\non its extension and the Python you’re running. In Pythons 3.2 and earlier, .py files\\nare run by python.exe with a console (Command Prompt) window, and .pyw files\\nare run by pythonw.exe files without a console. Byte code files are also run by these\\nprograms if clicked. Per Appendix B, in Python 3.3 and later (and where it’s in-\\nstalled separately), the new Window’s launchers’s py.exe and pyw.exe programs\\nserve the same roles, opening .py and .pyw files, respectively.\\n\\nNon-Windows icon clicks\\n\\nOn non-Windows systems, you will probably be able to perform a similar feat, but\\nthe icons, file explorer navigation schemes, and more may differ slightly. On Mac\\nOS X, for instance, you might use PythonLauncher in the MacPython (or Python\\nN.M) folder of your Applications folder to run by clicking in Finder.\\nOn some Linux and other Unix systems, you may need to register the .py extension\\nwith your file explorer GUI, make your script executable using the #! line scheme\\nof the preceding section, or associate the file MIME type with an application or\\ncommand by editing files, installing programs, or using other tools. See your file\\nexplorer’s documentation for more details.\\n\\nIn other words, icon clicks generally work as you’d expect for your platform, but be\\nsure to see the platform usage documentation “Python Setup and Usage” in Python’s\\nstandard manual set for more details as needed.\\n\\n62 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cClicking Icons on Windows\\nTo illustrate, let’s keep using the script we wrote earlier, script1.py, repeated here to\\nminimize page flipping:\\n\\n# A first Python script\\nimport sys                  # Load a library module\\nprint(sys.platform)\\nprint(2 ** 100)             # Raise 2 to a power\\nx = \\'Spam!\\'\\nprint(x * 8)                # String repetition\\n\\nAs we’ve seen, you can always run this file from a system command line:\\n\\nC:\\\\code> python script1.py\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nHowever, icon clicks allow you to run the file without any typing at all. To do so, you\\nhave to find this file’s icon on your computer. On Windows 8, you might right-click\\nthe screen’s lower-left corner to open a File Explorer. On earlier Windows, you can\\nselect Computer (or My Computer in XP) in your Start button’s menu. There are ad-\\nditional ways to open a file explorer; once you do, work your way down on the C drive\\nto your working directory.\\nAt this point, you should have a file explorer window similar to that captured in Fig-\\nure 3-1 (Windows 8 is being used here). Notice how the icons for Python files show up:\\n\\n• Source files have white backgrounds on Windows.\\n• Byte code files show with black backgrounds.\\n\\nPer the prior chapter, I created the byte code file in this figure by importing in Python\\n3.1; 3.2 and later instead store byte code files in the __pycache__ subdirectory also\\nshown here, which I created by importing in 3.3 too. You will normally want to click\\n(or otherwise run) the white source code files in order to pick up your most recent\\nchanges, not the byte code files—Python won’t check the source code file for changes\\nif you launch byte code directly. To launch the file here, simply click on the icon for\\nscript1.py.\\n\\nThe input Trick on Windows\\nUnfortunately, on Windows, the result of clicking on a file icon may not be incredibly\\nsatisfying. In fact, as it is, this example script might generate a perplexing “flash” when\\nclicked—not exactly the sort of feedback that budding Python programmers usually\\nhope for! This is not a bug, but has to do with the way the Windows version of Python\\nhandles printed output.\\nBy default, Python generates a pop-up black DOS console window (Command Prompt)\\nto serve as a clicked file’s input and output. If a script just prints and exits, well, it just\\n\\nClicking File Icons\\n\\n| 63\\n\\n\\x0cFigure 3-1. On Windows, Python program files show up as icons in file explorer windows and can\\nautomatically be run with a double-click of the mouse (though you might not see printed output or\\nerror messages this way).\\n\\nprints and exits—the console window appears, and text is printed there, but the console\\nwindow closes and disappears on program exit. Unless you are very fast, or your ma-\\nchine is very slow, you won’t get to see your output at all. Although this is normal\\nbehavior, it’s probably not what you had in mind.\\nLuckily, it’s easy to work around this. If you need your script’s output to stick around\\nwhen you launch it with an icon click, simply put a call to the built-in input function \\nat the very bottom of the script in 3.X (in 2.X use the name raw_input instead: see the\\nnote ahead). For example:\\n\\n# A first Python script\\nimport sys                  # Load a library module\\nprint(sys.platform)\\nprint(2 ** 100)             # Raise 2 to a power\\nx = \\'Spam!\\'\\nprint(x * 8)                # String repetition\\ninput()                     # <== ADDED\\n\\nIn general, input reads and returns the next line of standard input, waiting if there is\\nnone yet available. The net effect in this context will be to pause the script, thereby\\nkeeping the output window shown in Figure 3-2 open until you press the Enter key.\\nNow that I’ve shown you this trick, keep in mind that it is usually only required for\\nWindows, and then only if your script prints text and exits and only if you will launch\\nthe script by clicking its file icon. You should add this call to the bottom of your top-\\nlevel files if and only if all of these three conditions apply. There is no reason to add\\nthis call in any other contexts, such as scripts you’ll run in command lines or the IDLE\\nGUI (unless you’re unreasonably fond of pressing your computer’s Enter key!).2 That\\nmay sound obvious, but it’s been another common mistake in live classes.\\n\\n64 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cFigure 3-2. When you click a program’s icon on Windows, you will be able to see its printed output\\nif you include an input call at the very end of the script. But you only need to do so in this one context!\\n\\nBefore we move ahead, note that the input call applied here is the input counterpart of\\nusing the print function (and 2.X statement) for outputs. It is the simplest way to read\\nuser input, and it is more general than this example implies. For instance, input:\\n\\n• Optionally accepts a string that will be printed as a prompt (e.g., input(\\'Press\\n\\nEnter to exit\\'))\\n\\n• Returns to your script a line of text read as a string (e.g., nextinput = input())\\n• Supports input stream redirections at the system shell level (e.g., python spam.py\\n\\n< input.txt), just as the print statement does for output\\n\\nWe’ll use input in more advanced ways later in this text; for instance, Chapter 10 will\\napply it in an interactive loop. For now, it will help you see the output of simple scripts\\nthat you click to launch.\\n\\nVersion skew note: If you are working in Python 2.X, use raw_input()\\ninstead of input() in this code. The former was renamed to the latter in\\nPython 3.X. Technically, 2.X has an input function too, but it also eval-\\nuates strings as though they are program code typed into a script, and\\nso will not work in this context (an empty string is an error). Python\\n3.X’s input (and 2.X’s raw_input) simply returns the entered text as a\\ncharacter  string,  unevaluated.  To  simulate  2.X’s  input  in  3.X,  use\\neval(input()).\\n\\nBe aware, though, that because this runs the entered text as though it\\nwere program code, this may have security implications that we’ll largely\\n\\n2. Conversely,  it  is  also  possible  to  completely  suppress  the  pop-up  console  window  (a.k.a.  Command\\nPrompt) for clicked files on Windows when you don’t want to see printed text. Files whose names end in\\na  .pyw  extension  will  display  only  windows  constructed  by  your  script,  not  the  default  console\\nwindow. .pyw files are simply .py source files that have this special operational behavior on Windows.\\nThey  are  mostly  used  for  Python-coded  user  interfaces  that  build  windows  of  their  own,  often  in\\nconjunction with various techniques for saving printed output and errors to files. As implied earlier,\\nPython achieves this when it is installed by associating a special executable (pythonw.exe in 3.2 and earlier\\nand pyw.exe as of 3.3) to open .pyw files when clicked.\\n\\nClicking File Icons\\n\\n| 65\\n\\n\\x0cignore here, except to say that you should trust the source of the entered\\ntext; if you don’t, stick to just plain input in 3.X and raw_input in 2.X.\\n\\nOther Icon-Click Limitations\\nEven with the prior section’s input trick, clicking file icons is not without its perils. You\\nalso may not get to see Python error messages. If your script generates an error, the\\nerror message text is written to the pop-up console window—which then immediately\\ndisappears! Worse, adding an input call to your file will not help this time because your\\nscript will likely abort long before it reaches this call. In other words, you won’t be able\\nto tell what went wrong.\\nWhen we discuss exceptions later in this book, you’ll learn that it is possible to write\\ncode to intercept, process, and recover from errors so that they do not terminate your\\nprograms. Watch for the discussion of the try statement later in this book for an al-\\nternative way to keep the console window from closing on errors. We’ll also learn how\\nto redirect printed text to files for later inspection when we study print operations.\\nBarring  such  support  in  your  code,  though,  errors  and  prints  disappear  for  clicked\\nprograms.\\nBecause of these limitations, it is probably best to view icon clicks as a way to launch\\nprograms after they have been debugged, or have been instrumented to write their\\noutput to a file and catch and process any important errors. Especially when you’re\\nstarting out, I recommend using other techniques—such as system command lines and\\nIDLE (discussed further in the section “The IDLE User Interface” on page 73)—so\\nthat you can see generated error messages and view your normal output without re-\\nsorting to extra coding.\\n\\nModule Imports and Reloads\\nSo far, I’ve been talking about “importing modules” without really explaining what this\\nterm means. We’ll study modules and larger program architecture in depth in Part V,\\nbut because imports are also a way to launch programs, this section will introduce\\nenough module basics to get you started.\\n\\nImport and Reload Basics\\nIn simple terms, every file of Python source code whose name ends in a .py extension\\nis a module. No special code or syntax is required to make a file a module: any such\\nfile will do. Other files can access the items a module defines by importing that module\\n—import operations essentially load another file and grant access to that file’s contents.\\nThe contents of a module are made available to the outside world through its attributes\\n(a term I’ll define in the next section).\\n\\n66 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cThis module-based services model turns out to be the core idea behind program archi-\\ntecture in Python. Larger programs usually take the form of multiple module files, which\\nimport tools from other module files. One of the modules is designated as the main or\\ntop-level file, or “script”—the file launched to start the entire program, which runs line\\nby line as usual. Below this level, it’s all modules importing modules.\\nWe’ll delve into such architectural issues in more detail later in this book. This chapter\\nis mostly interested in the fact that import operations run the code in a file that is being\\nloaded as a final step. Because of this, importing a file is yet another way to launch it.\\nFor instance, if you start an interactive session (from a system command line or other-\\nwise), you can run the script1.py file you created earlier with a simple import (be sure\\nto delete the input line you added in the prior section first, or you’ll need to press Enter\\nfor no reason):\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> import script1\\nwin32\\n1267650600228229401496703205376\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nThis works, but only once per session (really, process—a program run) by default. After\\nthe first import, later imports do nothing, even if you change and save the module’s\\nsource file again in another window:\\n\\n...Change script1.py in a text edit window to print 2 ** 16...\\n\\n>>> import script1\\n>>> import script1\\n\\nThis is by design; imports are too expensive an operation to repeat more than once per\\nfile, per program run. As you’ll learn in Chapter 22, imports must find files, compile\\nthem to byte code, and run the code.\\nIf you really want to force Python to run the file again in the same session without\\nstopping and restarting the session, you need to instead call the reload function avail-\\nable in the imp standard library module (this function is also a simple built-in in Python\\n2.X, but not in 3.X):\\n\\n>>> from imp import reload           # Must load from module in 3.X (only)\\n>>> reload(script1)\\nwin32\\n65536\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n<module \\'script1\\' from \\'.\\\\\\\\script1.py\\'>\\n>>>\\n\\nThe from statement here simply copies a name out of a module (more on this soon).\\nThe reload function itself loads and runs the current version of your file’s code, picking\\nup changes if you’ve modified and saved it in another window.\\n\\nModule Imports and Reloads\\n\\n| 67\\n\\n\\x0cThis allows you to edit and pick up new code on the fly within the current Python\\ninteractive  session.  In  this  session,  for  example,  the  second  print  statement  in\\nscript1.py was changed in another window to print 2 ** 16 between the time of the\\nfirst import and the reload call—hence the different result.\\nThe reload function expects the name of an already loaded module object, so you have\\nto have successfully imported a module once before you reload it (if the import reported\\nan error, you can’t yet reload and must import again). Notice that reload also expects\\nparentheses  around  the  module  object  name,  whereas  import  does  not.  reload  is  a\\nfunction that is called, and import is a statement.\\nThat’s why you must pass the module name to reload as an argument in parentheses,\\nand that’s why you get back an extra output line when reloading—the last output line\\nis just the display representation of the reload call’s return value, a Python module\\nobject. We’ll learn more about using functions in general in Chapter 16; for now, when\\nyou hear “function,” remember that parentheses are required to run a call.\\n\\nVersion skew note: Python 3.X moved the reload built-in function to the\\nimp standard library module. It still reloads files as before, but you must\\nimport  it  in  order  to  use  it.  In  3.X,  run  an  import  imp  and  use\\nimp.reload(M), or run a from imp import reload and use reload(M), as\\nshown here. We’ll discuss import and from statements in the next sec-\\ntion, and more formally later in this book.\\n\\nIf you are working in Python 2.X, reload is available as a built-in func-\\ntion, so no import is required. In Python 2.6 and 2.7, reload is available\\nin both forms—built-in and module function—to aid the transition to\\n3.X. In other words, reloading is still available in 3.X, but an extra line\\nof code is required to fetch the reload call.\\n\\nThe move in 3.X was likely motivated in part by some well-known issues\\ninvolving reload and from statements that we’ll encounter in the next\\nsection. In short, names loaded with a from are not directly updated by\\na  reload,  but  names  accessed  with  an  import  statement  are.  If  your\\nnames don’t seem to change after a reload, try using import and mod\\nule.attribute name references instead.\\n\\nThe Grander Module Story: Attributes\\nImports and reloads provide a natural program launch option because import opera-\\ntions execute files as a last step. In the broader scheme of things, though, modules serve\\nthe role of libraries of tools, as you’ll learn in detail in Part V. The basic idea is straight-\\nforward, though: a module is mostly just a package of variable names, known as a\\nnamespace, and the names within that package are called attributes. An attribute is\\nsimply a variable name that is attached to a specific object (like a module).\\nIn more concrete terms, importers gain access to all the names assigned at the top level\\nof a module’s file. These names are usually assigned to tools exported by the module\\n\\n68 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c—functions, classes, variables, and so on—that are intended to be used in other files\\nand other programs. Externally, a module file’s names can be fetched with two Python \\nstatements, import and from, as well as the reload call.\\nTo illustrate, use a text editor to create a one-line Python module file called myfile.py\\nin your working directory, with the following contents:\\n\\ntitle = \"The Meaning of Life\"\\n\\nThis may be one of the world’s simplest Python modules (it contains a single assignment\\nstatement), but it’s enough to illustrate the point. When this file is imported, its code\\nis run to generate the module’s attribute. That is, the assignment statement creates a\\nvariable and module attribute named title.\\nYou can access this module’s title attribute in other components in two different ways.\\nFirst, you can load the module as a whole with an import statement, and then qualify\\nthe module name with the attribute name to fetch it (note that we’re letting the inter-\\npreter print automatically here):\\n\\n% python                           # Start Python\\n>>> import myfile                  # Run file; load module as a whole\\n>>> myfile.title                   # Use its attribute names: \\'.\\' to qualify\\n\\'The Meaning of Life\\'\\n\\nIn  general,  the  dot  expression  syntax  object.attribute  lets  you  fetch  any  attribute\\nattached to any object, and is one of the most common operations in Python code.\\nHere, we’ve used it to access the string variable title inside the module myfile—in\\nother words, myfile.title.\\nAlternatively, you can fetch (really, copy) names out of a module with from statements:\\n\\n% python                           # Start Python\\n>>> from myfile import title       # Run file; copy its names\\n>>> title                          # Use name directly: no need to qualify\\n\\'The Meaning of Life\\'\\n\\nAs you’ll see in more detail later, from is just like an import, with an extra assignment\\nto names in the importing component. Technically, from copies a module’s attributes,\\nsuch that they become simple variables in the recipient—thus, you can simply refer to\\nthe imported string this time as title (a variable) instead of myfile.title (an attribute\\nreference).3\\nWhether you use import or from to invoke an import operation, the statements in the\\nmodule file myfile.py are executed, and the importing component (here, the interactive\\nprompt) gains access to names assigned at the top level of the file. There’s only one\\nsuch name in this simple example—the variable title, assigned to a string—but the\\n\\n3. Notice that import and from both list the name of the module file as simply myfile without its .py extension\\nsuffix. As you’ll learn in Part V, when Python looks for the actual file, it knows to include the suffix in its\\nsearch  procedure.  Again,  you  must  include  the  .py suffix in system shell command lines, but not in\\nimport statements.\\n\\nModule Imports and Reloads\\n\\n| 69\\n\\n\\x0cconcept will be more useful when you start defining objects such as functions and\\nclasses in your modules: such objects become reusable software components that can\\nbe accessed by name from one or more client modules.\\nIn practice, module files usually define more than one name to be used in and outside\\nthe files. Here’s an example that defines three:\\n\\na = \\'dead\\'                      # Define three attributes\\nb = \\'parrot\\'                    # Exported to other files\\nc = \\'sketch\\'\\nprint(a, b, c)                  # Also used in this file (in 2.X: print a, b, c)\\n\\nThis file, threenames.py, assigns three variables, and so generates three attributes for\\nthe outside world. It also uses its own three variables in a 3.X print statement, as we\\nsee when we run this as a top-level file (in Python 2.X print differs slightly, so omit its\\nouter parenthesis to match the output here exactly; watch for a more complete ex-\\nplanation of this in Chapter 11):\\n\\n% python threenames.py\\ndead parrot sketch\\n\\nAll of this file’s code runs as usual the first time it is imported elsewhere, by either an\\nimport or from. Clients of this file that use import get a module with attributes, while\\nclients that use from get copies of the file’s names:\\n\\n% python\\n>>> import threenames                    # Grab the whole module: it runs here\\ndead parrot sketch\\n>>>\\n>>> threenames.b, threenames.c           # Access its attributes\\n(\\'parrot\\', \\'sketch\\')\\n>>>\\n>>> from threenames import a, b, c       # Copy multiple names out\\n>>> b, c\\n(\\'parrot\\', \\'sketch\\')\\n\\nThe results here are printed in parentheses because they are really tuples—a kind of\\nobject created by the comma in the inputs (and covered in the next part of this book)\\n—that you can safely ignore for now.\\nOnce you start coding modules with multiple names like this, the built-in dir function\\nstarts to come in handy—you can use it to fetch a list of all the names available inside\\na module. The following returns a Python list of strings in square brackets (we’ll start\\nstudying lists in the next chapter):\\n\\n>>> dir(threenames)\\n[\\'__builtins__\\', \\'__doc__\\', \\'__file__\\', \\'__name__\\', \\'__package__\\', \\'a\\', \\'b\\', \\'c\\']\\n\\nThe contents of this list have been edited here because they vary per Python version.\\nThe point to notice here is that when the dir function is called with the name of an\\nimported module in parentheses like this, it returns all the attributes inside that module.\\nSome of the names it returns are names you get “for free”: names with leading and\\ntrailing double underscores (__X__) are built-in names that are always predefined by\\n\\n70 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cPython and have special meaning to the interpreter, but they aren’t important at this\\npoint in this book. The variables our code defined by assignment—a, b, and c—show\\nup last in the dir result.\\n\\nModules and namespaces\\nModule imports are a way to run files of code, but, as we’ll expand on later in the book,\\nmodules are also the largest program structure in Python programs, and one of the first\\nkey concepts in the language.\\nAs we’ve seen, Python programs are composed of multiple module files linked together\\nby import statements, and each module file is a package of variables—that is, a name-\\nspace. Just as importantly, each module is a self-contained namespace: one module file\\ncannot see the names defined in another file unless it explicitly imports that other file.\\nBecause of this, modules serve to minimize name collisions in your code—because each\\nfile is a self-contained namespace, the names in one file cannot clash with those in\\nanother, even if they are spelled the same way.\\nIn fact, as you’ll see, modules are one of a handful of ways that Python goes to great\\nlengths  to  package  your  variables  into  compartments  to  avoid  name  clashes.  We’ll\\ndiscuss modules and other namespace constructs—including local scopes defined by\\nclasses and functions—further later in the book. For now, modules will come in handy\\nas a way to run your code many times without having to retype it, and will prevent your\\nfile’s names from accidentally replacing each other.\\n\\nimport versus from: I should point out that the from statement in a sense\\ndefeats the namespace partitioning purpose of modules—because the\\nfrom copies variables from one file to another, it can cause same-named\\nvariables in the importing file to be overwritten, and won’t warn you if\\nit does. This essentially collapses namespaces together, at least in terms\\nof the copied variables.\\n\\nBecause of this, some recommend always using import instead of from.\\nI won’t go that far, though; not only does from involve less typing (an\\nasset at the interactive prompt), but its purported problem is relatively\\nrare  in  practice.  Besides,  this  is  something  you  control  by  listing  the\\nvariables you want in the from; as long as you understand that they’ll be\\nassigned to values in the target module, this is no more dangerous than\\ncoding assignment statements—another feature you’ll probably want\\nto use!\\n\\nUsage Notes: import and reload\\nFor some reason, once people find out about running files using import and reload,\\nmany tend to focus on this alone and forget about other launch options that always\\nrun the current version of the code (e.g., icon clicks, IDLE menu options, and system\\ncommand lines). This approach can quickly lead to confusion, though—you need to\\n\\nModule Imports and Reloads\\n\\n| 71\\n\\n\\x0cremember when you’ve imported to know if you can reload, you need to remember to\\nuse  parentheses  when  you  call  reload  (only),  and  you  need  to  remember  to  use\\nreload in the first place to get the current version of your code to run. Moreover, reloads\\naren’t transitive—reloading a module reloads that module only, not any modules it\\nmay import—so you sometimes have to reload multiple files.\\nBecause of these complications (and others we’ll explore later, including the reload/\\nfrom issue mentioned briefly in a prior note in this chapter), it’s generally a good idea\\nto  avoid  the  temptation  to  launch  by  imports  and  reloads  for  now.  The  IDLE\\nRun→Run Module menu option described in the next section, for example, provides a\\nsimpler and less error-prone way to run your files, and always runs the current version\\nof your code. System shell command lines offer similar benefits. You don’t need to use\\nreload if you use any of these other techniques.\\nIn addition, you may run into trouble if you use modules in unusual ways at this point\\nin the book. For instance, if you want to import a module file that is stored in a directory\\nother than the one you’re working in, you’ll have to skip ahead to Chapter 22 and learn\\nabout the module search path. For now, if you must import, try to keep all your files in\\nthe directory you are working in to avoid complications.4\\nThat said, imports and reloads have proven to be a popular testing technique in Python\\nclasses,  and  you  may  prefer  using  this  approach  too.  As  usual,  though,  if  you  find\\nyourself running into a wall, stop running into a wall!\\n\\nUsing exec to Run Module Files\\nStrictly speaking, there are more ways to run code stored in module files than have yet\\nbeen presented here. For instance, the exec(open(\\'module.py\\').read()) built-in func-\\ntion call is another way to launch files from the interactive prompt without having to\\nimport and later reload. Each such exec runs the current version of the code read from\\na file, without requiring later reloads (script1.py is as we left it after a reload in the prior\\nsection):\\n\\n% python\\n>>> exec(open(\\'script1.py\\').read())\\nwin32\\n65536\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\n...Change script1.py in a text edit window to print 2 ** 32...\\n\\n>>> exec(open(\\'script1.py\\').read())\\n\\n4. If you’re too curious to wait, the short story is that Python searches for imported modules in every directory\\nlisted in sys.path—a Python list of directory name strings in the sys module, which is initialized from a\\nPYTHONPATH environment variable, plus a set of standard directories. If you want to import from a directory\\nother than the one you are working in, that directory must generally be listed in your PYTHONPATH setting.\\nFor more details, see Chapter 22 and Appendix A.\\n\\n72 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cwin32\\n4294967296\\nSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n\\nThe exec call has an effect similar to an import, but it doesn’t actually import the module\\n—by default, each time you call exec this way it runs the file’s code anew, as though\\nyou had pasted it in at the place where exec is called. Because of that, exec does not\\nrequire module reloads after file changes—it skips the normal module import logic.\\nOn the downside, because it works as if you’ve pasted code into the place where it is \\ncalled,  exec, like the  from statement mentioned earlier, has the potential to silently\\noverwrite variables you may currently be using. For example, our script1.py assigns to\\na variable named x. If that name is also being used in the place where exec is called, the\\nname’s value is replaced:\\n\\n>>> x = 999\\n>>> exec(open(\\'script1.py\\').read())     # Code run in this namespace by default\\n...same output...\\n>>> x                                   # Its assignments can overwrite names here\\n\\'Spam!\\'\\n\\nBy contrast, the basic import statement runs the file only once per process, and it makes\\nthe file a separate module namespace so that its assignments will not change variables\\nin your scope. The price you pay for the namespace partitioning of modules is the need\\nto reload after changes.\\n\\nVersion skew note: Python 2.X also includes an execfile(\\'module.py\\')\\nbuilt-in  function,  in  addition  to  allowing  the  form  exec(open(\\'mod\\nule.py\\')),  which  both  automatically  read  the  file’s  content.  Both  of\\nthese  are  equivalent  to  the  exec(open(\\'module.py\\').read())  form,\\nwhich is more complex but runs in both 2.X and 3.X.\\n\\nUnfortunately, neither of these two simpler 2.X forms is available in 3.X,\\nwhich means you must understand both files and their read methods to\\nfully understand this technique today (this seems to be a case of aes-\\nthetics trouncing practicality in 3.X). In fact, the exec form in 3.X in-\\nvolves so much typing that the best advice may simply be not to do it—\\nit’s usually easier to launch files by typing system shell command lines\\nor by using the IDLE menu options described in the next section.\\n\\nFor more on the file interfaces used by the 3.X exec form, see Chap-\\nter 9. For more on exec and its cohorts, eval and compile, see Chap-\\nter 10 and Chapter 25.\\n\\nThe IDLE User Interface\\nSo far, we’ve seen how to run Python code with the interactive prompt, system com-\\nmand lines, Unix-style scripts, icon clicks, module imports, and exec calls. If you’re\\nlooking for something a bit more visual, IDLE provides a graphical user interface for\\n\\nThe IDLE User Interface | 73\\n\\n\\x0cdoing Python development, and it’s a standard and free part of the Python system. IDLE\\nis usually referred to as an integrated development environment (IDE), because it binds\\ntogether various development tasks into a single view.5\\nIn short, IDLE is a desktop GUI that lets you edit, run, browse, and debug Python\\nprograms, all from a single interface. It runs portably on most Python platforms, in-\\ncluding Microsoft Windows, X Windows (for Linux, Unix, and Unix-like platforms),\\nand the Mac OS (both Classic and OS X). For many, IDLE represents an easy-to-use\\nalternative to typing command lines, a less problem-prone alternative to clicking on\\nicons, and a great way for newcomers to get started editing and running code. You’ll\\nsacrifice some control in the bargain, but this typically becomes important later in your\\nPython career.\\n\\nIDLE Startup Details\\nMost readers should be able to use IDLE immediately, as it is a standard component\\non Mac OS X and most Linux installations today, and is installed automatically with\\nstandard Python on Windows. Because platforms specifics vary, though, I need to give\\na few pointers before we open the GUI.\\nTechnically, IDLE is a Python program that uses the standard library’s tkinter GUI\\ntoolkit (named Tkinter in Python 2.X) to build its windows. This makes IDLE portable\\n—it works the same on all major desktop platforms—but it also means that you’ll need\\nto have tkinter support in your Python to use IDLE. This support is standard on Win-\\ndows, Macs, and Linux, but it comes with a few caveats on some systems, and startup\\ncan vary per platform. Here are a few platform-specific tips:\\n\\n• On Windows 7 and earlier, IDLE is easy to start—it’s always present after a Python\\ninstall, and has an entry in the Start button menu for Python in Windows 7 and\\nearlier (see Figure 2-1, shown previously). You can also select it by right-clicking\\non  a  Python  program  icon,  and  launch  it  by  clicking  on  the  icon  for  the  files\\nidle.pyw or idle.py located in the idlelib subdirectory of Python’s Lib directory. In\\nthis mode, IDLE is a clickable Python script that lives in C:\\\\Python33\\\\Lib\\\\idlelib,\\nC:\\\\Python27\\\\Lib\\\\idlelib, or similar, which you can drag out to a shortcut for one-\\nclick access if desired.\\n\\n• On Windows 8, look for IDLE in your Start tiles, by a search for “idle,” by browsing\\nyour “All apps” Start screen display, or by using File Explorer to find the idle.py\\nfile mentioned earlier. You may want a shortcut here, as you have no Start button\\nmenu in desktop mode (at least today; see Appendix A for more pointers).\\n\\n• On Mac OS X everything required for IDLE is present as standard components in\\nyour operating system. IDLE should be available to launch in Applications under\\nthe MacPython (or Python N.M) program folder. One note here: some OS X ver-\\n\\n5. IDLE is officially a corruption of IDE, but it’s really named in honor of Monty Python member Eric Idle.\\n\\nSee Chapter 1 if you’re not sure why.\\n\\n74 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0csions may require installing updated tkinter support due to subtle version depen-\\ndencies I’ll spare readers from here; see python.org’s Download page for details.\\n• On Linux IDLE is also usually present as a standard component today. It might\\ntake the form of an idle executable or script in your path; type this in a shell to\\ncheck. On some machines, it may require an install (see Appendix A for pointers),\\nand on others you may need to launch IDLE’s top-level script from a command\\nline  or  icon  click:  run  the  file  idle.py  located  in  the  idlelib  subdirectory  of\\nPython’s /usr/lib directory (run a find for the exact location).\\n\\nBecause IDLE is just a Python script on the module search path in the standard library,\\nyou can also generally run it on any platform and from any directory by typing the\\nfollowing in a system command shell window (e.g., in a Command Prompt on Win-\\ndows),  though  you’ll  have  to  see  Appendix  A  for  more  on  Python’s  –m  flag,  and\\nPart V for more on the “.” package syntax required here (blind trust will suffice at this\\npoint in the book):\\n\\nc:\\\\code> python -m idlelib.idle           # Run idle.py in a package on module path\\n\\nFor more on install issues and usage notes for Windows and other platforms, be sure\\nto see both Appendix A as well as the notes for your platform in “Python Setup and\\nUsage” in Python’s standard manuals.\\n\\nIDLE Basic Usage\\nLet’s jump into an example. Figure 3-3 shows the scene after you start IDLE on Win-\\ndows. The Python shell window that opens initially is the main window, which runs\\nan interactive session (notice the >>> prompt). This works like all interactive sessions\\n—code you type here is run immediately after you type it—and serves as a testing and\\nexperimenting tool.\\nIDLE uses familiar menus with keyboard shortcuts for most of its operations. To make\\na new script file under IDLE, use File→New: in the main shell window, select the File\\npull-down menu, and pick New to open a new text edit window where you can type,\\nsave, and run your file’s code. Use File→Open... instead to open a new text edit window\\ndisplaying an existing file’s code to edit and run.\\nAlthough it may not show up fully in this book’s graphics, IDLE uses syntax-directed\\ncolorization for the code typed in both the main window and all text edit windows—\\nkeywords are one color, literals are another, and so on. This helps give you a better\\npicture of the components in your code (and can even help you spot mistakes—run-\\non strings are all one color, for example).\\nTo run a file of code that you are editing in IDLE, use Run→Run Module in that file’s\\ntext edit window. That is, select the file’s text edit window, open that window’s Run\\npull-down menu, and choose the Run Module option listed there (or use the equivalent\\nkeyboard shortcut, given in the menu). Python will let you know that you need to save\\n\\nThe IDLE User Interface | 75\\n\\n\\x0cFigure 3-3. The main Python shell window of the IDLE development GUI, shown here running on\\nWindows. Use the File menu to begin (New Window) or change (Open...) a source file; use the text\\nedit window’s Run menu to run the code in that window (Run Module).\\n\\nyour file first if you’ve changed it since it was opened or last saved and forgot to save\\nyour changes—a common mistake when you’re knee-deep in coding.\\nWhen run this way, the output of your script and any error messages it may generate\\nshow  up  back  in  the  main  interactive  window  (the  Python  shell  window).  In  Fig-\\nure 3-3, for example, the three lines after the “RESTART” line near the middle of the\\nwindow reflect an execution of our script1.py file opened in a separate edit window.\\nThe “RESTART” message tells us that the user-code process was restarted to run the\\nedited script and serves to separate script output (it does not appear if IDLE is started\\nwithout a user-code subprocess—more on this mode in a moment).\\n\\nIDLE Usability Features\\nLike most GUIs, the best way to learn IDLE may be to test-drive it for yourself, but\\nsome key usage points seem to be less than obvious. For example, if you want to repeat\\nprior commands in IDLE’s main interactive window, you can use the Alt-P key combi-\\nnation to scroll backward through the command history, and Alt-N to scroll forward\\n(on some Macs, try Ctrl-P and Ctrl-N instead). Your prior commands will be recalled\\nand displayed, and may be edited and rerun.\\n\\n76 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cYou can also recall commands by positioning the cursor on them and clicking and\\npressing Enter to insert their text at the input prompt, or using standard cut-and-paste\\noperations, though these techniques tend to involve more steps (and can sometimes be\\ntriggered accidentally). Outside IDLE, you may be able to recall commands in an in-\\nteractive session with the arrow keys on Windows.\\nBesides command history and syntax colorization, IDLE has additional usability fea-\\ntures such as:\\n\\n• Auto-indent and unindent for Python code in the editor (Backspace goes back one\\n\\nlevel)\\n\\n• Word auto-completion while typing, invoked by a Tab press\\n• Balloon help pop ups for a function call when you type its opening “(”\\n• Pop-up selection lists of object attributes when you type a “.” after an object’s name\\n\\nand either pause or press Tab\\n\\nSome of these may not work on every platform, and some can be configured or disabled\\nif you find that their defaults get in the way of your personal coding style.\\n\\nAdvanced IDLE Tools\\nBesides the basic edit and run functions and the prior section’s usability tools, IDLE\\nprovides more advanced features, including a point-and-click program graphical de-\\nbugger and an object browser. The IDLE debugger is enabled via the Debug menu and\\nthe object browser via the File menu. The browser allows you to navigate through the\\nmodule search path to files and objects in files; clicking on a file or object opens the\\ncorresponding source in a text edit window.\\nYou initiate IDLE debugging by selecting the Debug→Debugger menu option in the\\nmain window and then starting your script by selecting the Run→Run Module option\\nin the text edit window; once the debugger is enabled, you can set breakpoints in your\\ncode that stop its execution by right-clicking on lines in the text edit windows, show\\nvariable values, and so on. You can also watch program execution when debugging—\\nthe current line of code is noted as you step through your code.\\nFor simpler debugging operations, you can also right-click with your mouse on the text\\nof an error message to quickly jump to the line of code where the error occurred—a\\ntrick that makes it simple and fast to repair and run again. In addition, IDLE’s text\\neditor offers a large collection of programmer-friendly tools, including advanced text\\nand file search operations we won’t cover here. Because IDLE uses intuitive GUI in-\\nteractions, you should experiment with the system live to get a feel for its other tools.\\n\\nThe IDLE User Interface | 77\\n\\n\\x0cUsage Notes: IDLE\\nIDLE is free, easy to use, portable, and automatically available on most platforms. I\\ngenerally recommend it to Python newcomers because it simplifies some startup details\\nand  does  not  assume  prior  experience  with  system  command  lines.  However,  it  is\\nsomewhat limited compared to more advanced commercial IDEs, and may seem heav-\\nier than a command line to some. To help you avoid some common pitfalls, here is a\\nlist of issues that IDLE beginners should bear in mind:\\n\\n• You must add “.py” explicitly when saving your files. I mentioned this when\\ntalking about files in general, but it’s a common IDLE stumbling block, especially\\nfor Windows users. IDLE does not automatically add a .py extension to filenames\\nwhen files are saved. Be careful to type the .py extension yourself when saving a\\nfile for the first time. If you don’t, while you will be able to run your file from IDLE\\n(and system command lines), you will not be able to import it either interactively\\nor from other modules.\\n\\n• Run scripts by selecting Run→Run Module in text edit windows, not by in-\\nteractive imports and reloads. Earlier in this chapter, we saw that it’s possible\\nto run a file by importing it interactively. However, this scheme can grow complex\\nbecause it requires you to manually reload files after changes. By contrast, using\\nthe Run→Run Module menu option in IDLE always runs the most current version\\nof  your  file,  just  like  running  it  using  a  system  shell  command  line.  IDLE  also\\nprompts you to save your file first, if needed (another common mistake outside\\nIDLE).\\n\\n• You need to reload only modules being tested interactively. Like system shell\\ncommand lines, IDLE’s Run→Run Module menu option always runs the current\\nversion  of  both  the  top-level  file  and  any  modules  it  imports.  Because  of  this,\\nRun→Run Module eliminates common confusions surrounding imports. You need\\nto reload only modules that you are importing and testing interactively in IDLE. If\\nyou choose to use the import and reload technique instead of Run→Run Module,\\nremember that you can use the Alt-P/Alt-N key combinations to recall prior com-\\nmands.\\n\\n• You can customize IDLE. To change the text fonts and colors in IDLE, select the\\nConfigure option in the Options menu of any IDLE window. You can also cus-\\ntomize key combination actions, indentation settings, autocompletions, and more;\\nsee IDLE’s Help pull-down menu for more hints.\\n\\n• There is currently no clear-screen option in IDLE. This seems to be a frequent\\nrequest (perhaps because it’s an option available in similar IDEs), and it might be\\nadded eventually. Today, though, there is no way to clear the interactive window’s\\ntext. If you want the window’s text to go away, you can either press and hold the\\nEnter key, or type a Python loop to print a series of blank lines (nobody really uses\\nthe latter technique, of course, but it sounds more high-tech than pressing the Enter\\nkey!).\\n\\n78 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c• tkinter GUI and threaded programs may not work well with IDLE. Because \\nIDLE is a Python/tkinter program, it can hang if you use it to run certain types of\\nadvanced Python/tkinter programs. This has become less of an issue in more recent\\nversions of IDLE that run user code in one process and the IDLE GUI itself in\\nanother, but some programs (especially those that use multithreading) might still\\nhang the GUI. Even just calling the tkinter quit function in your code, the normal\\nway to exit a GUI program, may be enough to cause your program’s GUI to hang\\nif run in IDLE (destroy may be better here only). Your code may not exhibit such\\nproblems, but as a rule of thumb, it’s always safe to use IDLE to edit GUI programs\\nbut launch them using other options, such as icon clicks or system command lines.\\nWhen in doubt, if your code fails in IDLE, try it outside the GUI.\\n\\n• If connection errors arise, try starting IDLE in single-process mode.  This\\nissue appears to have gone away in recent Pythons, but may still impact readers\\nusing older versions. Because IDLE requires communication between its separate\\nuser and GUI processes, it can sometimes have trouble starting up on certain plat-\\nforms (notably, it fails to start occasionally on some Windows machines, due to\\nfirewall software that blocks connections). If you run into such connection errors,\\nit’s always possible to start IDLE with a system command line that forces it to run\\nin single-process mode without a user-code subprocess and therefore avoids com-\\nmunication issues: its -n command-line flag forces this mode. On Windows, for\\nexample, start a Command Prompt window and run the system command line\\nidle.py  -n  from  within  the  directory  C:\\\\Python33\\\\Lib\\\\idlelib  (cd  there  first  if\\nneeded). A python -m idlelib.idle –n command works from anywhere (see Ap-\\npendix A for –m).\\n\\n• Beware of some IDLE usability features. IDLE does much to make life easier\\nfor beginners, but some of its tricks won’t apply outside the IDLE GUI. For in-\\nstance, IDLE runs your scripts in its own interactive namespace, so variables in\\nyour code show up automatically in the IDLE interactive session—you don’t al-\\nways need to run import commands to access names at the top level of files you’ve\\nalready run. This can be handy, but it can also be confusing, because outside the\\nIDLE environment names must always be imported from files explicitly to be used.\\nWhen you run a file of code, IDLE also automatically changes to that file’s direc-\\ntory and adds it to the module import search path—a handy feature that allows\\nyou to use files and import modules there without search path settings, but also\\nsomething that won’t work the same when you run files outside IDLE. It’s OK to\\nuse such features, but don’t forget that they are IDLE behavior, not Python be-\\nhavior.\\n\\nOther IDEs\\nBecause IDLE is free, portable, and a standard part of Python, it’s a nice first develop-\\nment tool to become familiar with if you want to use an IDE at all. Again, I recommend\\n\\nOther IDEs\\n\\n| 79\\n\\n\\x0cthat you use IDLE for this book’s exercises if you’re just starting out, unless you are\\nalready familiar with and prefer a command-line-based development mode. There are,\\nhowever, a handful of alternative IDEs for Python developers, some of which are sub-\\nstantially more powerful and robust than IDLE. Apart from IDLE, here are some of\\nPython’s most commonly used IDEs:\\n\\nEclipse and PyDev\\n\\nEclipse is an advanced open source IDE GUI. Originally developed as a Java IDE,\\nEclipse also supports Python development when you install the PyDev (or a similar)\\nplug-in. Eclipse is a popular and powerful option for Python development, and it\\ngoes well beyond IDLE’s feature set. It includes support for code completion, syn-\\ntax highlighting, syntax analysis, refactoring, debugging, and more. Its downsides\\nare that it is a large system to install and may require shareware extensions for some\\nfeatures (this may vary over time). Still, when you are ready to graduate from IDLE,\\nthe Eclipse/PyDev combination is worth your attention.\\n\\nKomodo\\n\\nA full-featured development environment GUI for Python (and other languages),\\nKomodo  includes  standard  syntax  coloring,  text  editing,  debugging,  and  other\\nfeatures. In addition, Komodo offers many advanced features that IDLE does not,\\nincluding project files, source-control integration, and regular-expression debug-\\nging. At this writing, Komodo is not free, but see the Web for its current status—\\nit is available at http://www.activestate.com from ActiveState, which also offers the\\nActivePython distribution package mentioned in Appendix A.\\n\\nNetBeans IDE for Python\\n\\nNetBeans is a powerful open source development environment GUI with support\\nfor many advanced features for Python developers: code completion, automatic\\nindentation and code colorization, editor hints, code folding, refactoring, debug-\\nging, code coverage and testing, projects, and more. It may be used to develop both\\nCPython and Jython code. Like Eclipse, NetBeans requires installation steps be-\\nyond those of the included IDLE GUI, but it is seen by many as more than worth\\nthe effort. Search the Web for the latest information and links.\\n\\nPythonWin\\n\\nPythonWin is a free Windows-only IDE for Python that ships as part of Active-\\nState’s ActivePython distribution (and may also be fetched separately from http://\\nwww.python.org resources). It is roughly like IDLE, with a handful of useful Win-\\ndows-specific extensions added; for example, PythonWin has support for COM\\nobjects. Today, IDLE is probably more advanced than PythonWin (for instance,\\nIDLE’s dual-process architecture often prevents it from hanging). However, Py-\\nthonWin still offers tools for Windows developers that IDLE does not. See http://\\nwww.activestate.com for more information.\\n\\nWing, Visual Studio, and others\\n\\nOther IDEs are popular among Python developers too, including the mostly com-\\nmercial Wing IDE, Microsoft Visual Studio via a plug-in, and PyCharm, PyScrip-\\n\\n80 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cter, Pyshield, and Spyder—but I do not have space to do justice to them here, and\\nmore will undoubtedly appear over time. In fact, almost every programmer-friendly\\ntext editor has some sort of support for Python development these days, whether\\nit be preinstalled or fetched separately. Emacs and Vim, for instance, have sub-\\nstantial Python support.\\nIDE choices are often subjective, so I encourage you to browse to find tools that\\nfit  your  development  style  and  goals.  For  more  information,  see  the  resources\\navailable at http://www.python.org or search the Web for “Python IDE” or similar.\\nA search for “Python editors” today leads you to a wiki page that maintains infor-\\nmation about dozens of IDE and text-editor options for Python programming.\\n\\nOther Launch Options\\nAt this point, we’ve seen how to run code typed interactively, and how to launch code\\nsaved in files in a variety of ways—system command lines, icon clicks, imports and\\nexecs, GUIs like IDLE, and more. That covers most of the techniques in common use,\\nand enough to run the code you’ll see in this book. There are additional ways to run\\nPython code, though, most of which have special or narrow roles. For completeness\\nand reference, the next few sections take a quick look at some of these.\\n\\nEmbedding Calls\\nIn some specialized domains, Python code may be run automatically by an enclosing\\nsystem. In such cases, we say that the Python programs are embedded in (i.e., run by)\\nanother program. The Python code itself may be entered into a text file, stored in a\\ndatabase, fetched from an HTML page, parsed from an XML document, and so on.\\nBut from an operational perspective, another system—not you—may tell Python to\\nrun the code you’ve created.\\nSuch an embedded execution mode is commonly used to support end-user customi-\\nzation—a game program, for instance, might allow for play modifications by running\\nuser-accessible embedded Python code at strategic points in time. Users can modify\\nthis type of system by providing or changing Python code. Because Python code is\\ninterpreted, there is no need to recompile the entire system to incorporate the change\\n(see Chapter 2 for more on how Python code is run).\\nIn this mode, the enclosing system that runs your code might be written in C, C++, or\\neven Java when the Jython system is used. As an example, it’s possible to create and\\nrun strings of Python code from a C program by calling functions in the Python runtime\\nAPI (a set of services exported by the libraries created when Python is compiled on your\\nmachine):\\n\\n#include <Python.h>\\n...\\n\\nOther Launch Options\\n\\n| 81\\n\\n\\x0cPy_Initialize();                                     // This is C, not Python\\nPyRun_SimpleString(\"x = \\'brave \\' + \\'sir robin\\'\");    // But it runs Python code\\n\\nIn this C code snippet, a program coded in the C language embeds the Python inter-\\npreter by linking in its libraries, and passes it a Python assignment statement string to\\nrun. C programs may also gain access to Python modules and objects and process or\\nexecute them using other Python API tools.\\nThis book isn’t about Python/C integration, but you should be aware that, depending\\non how your organization plans to use Python, you may or may not be the one who\\nactually starts the Python programs you create. Regardless, you can usually still use the\\ninteractive and file-based launching techniques described here to test code in isolation\\nfrom those enclosing systems that may eventually use it.6\\n\\nFrozen Binary Executables\\nFrozen binary executables, described in Chapter 2, are packages that combine your\\nprogram’s byte code and the Python interpreter into a single executable program. This\\napproach enables Python programs to be launched in the same ways that you would\\nlaunch any other executable program (icon clicks, command lines, etc.). While this\\noption works well for delivery of products, it is not really intended for use during pro-\\ngram development; you normally freeze just before shipping (after development is fin-\\nished). See the prior chapter for more on this option.\\n\\nText Editor Launch Options\\nAs mentioned previously, although they’re not full-blown IDE GUIs, most program-\\nmer-friendly text editors have support for editing, and possibly running, Python pro-\\ngrams. Such support may be built in or fetchable on the Web. For instance, if you are\\nfamiliar with the Emacs text editor, you can do all your Python editing and launching\\nfrom inside that text editor. See the text editor resources page at http://www.python\\n.org/editors for more details, or search the Web for the phrase “Python editors.”\\n\\nStill Other Launch Options\\nDepending on your platform, there may be additional ways that you can start Python\\nprograms. For instance, on some Macintosh systems you may be able to drag Python\\nprogram file icons onto the Python interpreter icon to make them execute, and on some\\nWindows systems you can always start Python scripts with the Run... option in the\\nStart menu. Additionally, the Python standard library has utilities that allow Python\\nprograms to be started by other Python programs in separate processes (e.g., os.popen,\\n\\n6. See Programming Python (O’Reilly) for more details on embedding Python in C/C++. The embedding\\nAPI can call Python functions directly, load modules, and more. Also, note that the Jython system allows\\nJava programs to invoke Python code using a Java-based API (a Python interpreter class).\\n\\n82 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0cos.system), and Python scripts might also be spawned in larger contexts like the Web\\n(for instance, a web page might invoke a script on a server); however, these are beyond\\nthe scope of the present chapter.\\n\\nFuture Possibilities?\\nThis chapter reflects current practice, but much of the material is both platform- and\\ntime-specific. Indeed, many of the execution and launch details presented arose during\\nthe shelf life of this book’s various editions. As with program execution options, it’s\\nnot impossible that new program launch options may arise over time.\\nNew operating systems, and new versions of existing systems, may also provide exe-\\ncution techniques beyond those outlined here. In general, because Python keeps pace\\nwith such changes, you should be able to launch Python programs in whatever way\\nmakes sense for the machines you use, both now and in the future—be that by swiping\\non tablet PCs and smartphones, grabbing icons in a virtual reality, or shouting a script’s\\nname over your coworkers’ conversations.\\nImplementation changes may also impact launch schemes somewhat (e.g., a full com-\\npiler could produce normal executables that are launched much like frozen binaries\\ntoday). If I knew what the future truly held, though, I would probably be talking to a\\nstockbroker instead of writing these words!\\n\\nWhich Option Should I Use?\\nWith all these options, true beginners might naturally ask: which one is best for me?\\nIn general, you should give the IDLE interface a try if you are just getting started with\\nPython. It provides a user-friendly GUI environment and hides some of the underlying\\nconfiguration details. It also comes with a platform-neutral text editor for coding your\\nscripts, and it’s a standard and free part of the Python system.\\nIf, on the other hand, you are an experienced programmer, you might be more com-\\nfortable with simply the text editor of your choice in one window, and another window\\nfor launching the programs you edit via system command lines and icon clicks (in fact,\\nthis is how I develop Python programs, but I have a Unix-biased distant past). Because\\nthe choice of development environments is very subjective, I can’t offer much more in\\nthe way of universal guidelines. In general, whatever environment you like to use will\\nbe the best for you to use.\\n\\nDebugging Python Code\\n\\nNaturally, none of my readers or students ever have bugs in their code (insert smiley\\nhere), but for less fortunate friends of yours who may, here’s a quick review of the\\nstrategies commonly used by real-world Python programmers to debug code, for you\\nto refer to as you start coding in earnest:\\n\\nWhich Option Should I Use?\\n\\n| 83\\n\\n\\x0c• Do nothing. By this, I don’t mean that Python programmers don’t debug their\\ncode—but when you make a mistake in a Python program, you get a very useful\\nand readable error message (you’ll get to see some soon, if you haven’t already).\\nIf you already know Python, and especially for your own code, this is often enough\\n—read the error message, and go fix the tagged line and file. For many, this is\\ndebugging in Python. It may not always be ideal for larger systems you didn’t write,\\nthough.\\n\\n• Insert print statements. Probably the main way that Python programmers debug\\ntheir code (and the way that I debug Python code) is to insert print statements and\\nrun  again.  Because  Python  runs  immediately  after  changes,  this  is  usually  the\\nquickest  way  to  get  more  information  than  error  messages  provide.  The  print\\nstatements don’t have to be sophisticated—a simple “I am here” or display of\\nvariable values is usually enough to provide the context you need. Just remember\\nto delete or comment out (i.e., add a # before) the debugging prints before you\\nship your code!\\n\\n• Use IDE GUI debuggers. For larger systems you didn’t write, and for beginners\\nwho want to trace code in more detail, most Python development GUIs have some\\nsort of point-and-click debugging support. IDLE has a debugger too, but it doesn’t\\nappear to be used very often in practice—perhaps because it has no command line,\\nor perhaps because adding print statements is usually quicker than setting up a\\nGUI debugging session. To learn more, see IDLE’s Help, or simply try it on your\\nown; \\nin  the  section  “Advanced  IDLE\\nTools” on page 77. Other IDEs, such as Eclipse, NetBeans, Komodo, and Wing\\nIDE, offer advanced point-and-click debuggers as well; see their documentation if\\nyou use them.\\n\\nis  described \\n\\nits  basic \\n\\ninterface \\n\\n• Use the pdb command-line debugger. For ultimate control, Python comes with\\na source code debugger named pdb, available as a module in Python’s standard\\nlibrary. In pdb, you type commands to step line by line, display variables, set and\\nclear breakpoints, continue to a breakpoint or error, and so on. You can launch\\npdb interactively by importing it, or as a top-level script. Either way, because you\\ncan type commands to control the session, it provides a powerful debugging tool.\\npdb  also  includes  a  postmortem  function  (pdb.pm())  that  you  can  run  after  an\\nexception occurs, to get information from the time of the error. See the Python\\nlibrary manual and Chapter 36 for more details on pdb, and Appendix A for an\\nexample or running pdb as a script with Python’s –m command argument.\\n\\n• Use Python’s –i command-line argument. Short of adding prints or running\\nunder pdb, you can still see what went wrong on errors. If you run your script from\\na command line and pass a -i argument between python and the name of your\\nscript (e.g., python –i m.py), Python will enter into its interactive interpreter mode\\n(the >>> prompt) when your script exits, whether it ends successfully or runs into\\nan error. At this point, you can print the final values of variables to get more details\\nabout what happened in your code because they are in the top-level namespace.\\nYou can also then import and run the pdb debugger for even more context; its\\npostmortem mode will let you inspect the latest error if your script failed. Appen-\\ndix A also shows -i in action.\\n\\n84 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c• Other options. For more specific debugging requirements, you can find additional\\ntools in the open source domain, including support for multithreaded programs,\\nembedded code, and process attachment. The Winpdb system, for example, is a\\nstandalone debugger with advanced debugging support and cross-platform GUI\\nand console interfaces.\\n\\nThese options will become more important as we start writing larger scripts. Probably\\nthe best news on the debugging front, though, is that errors are detected and reported\\nin Python, rather than passing silently or crashing the system altogether. In fact, errors\\nthemselves are a well-defined mechanism known as exceptions, which you can catch\\nand process (more on exceptions in Part VII). Making mistakes is never fun, of course,\\nbut take it from someone who recalls when debugging meant getting out a hex calcu-\\nlator and poring over piles of memory dump printouts: Python’s debugging support\\nmakes errors much less painful than they might otherwise be.\\n\\nChapter Summary\\nIn this chapter, we’ve looked at common ways to launch Python programs: by running\\ncode typed interactively, and by running code stored in files with system command\\nlines, file icon clicks, module imports, exec calls, and IDE GUIs such as IDLE. We’ve\\ncovered a lot of pragmatic startup territory here. This chapter’s goal was to equip you\\nwith enough information to enable you to start writing some code, which you’ll do in\\nthe next part of the book. There, we will start exploring the Python language itself,\\nbeginning with its core data types—the objects that are the subjects of your programs.\\nFirst, though, take the usual chapter quiz to exercise what you’ve learned here. Because\\nthis is the last chapter in this part of the book, it’s followed with a set of more complete\\nexercises that test your mastery of this entire part’s topics. For help with the latter set\\nof problems, or just for a refresher, be sure to turn to Appendix D after you’ve given\\nthe exercises a try.\\n\\nTest Your Knowledge: Quiz\\n1. How can you start an interactive interpreter session?\\n2. Where do you type a system command line to launch a script file?\\n3. Name four or more ways to run the code saved in a script file.\\n4. Name two pitfalls related to clicking file icons on Windows.\\n5. Why might you need to reload a module?\\n6. How do you run a script from within IDLE?\\n7. Name two pitfalls related to using IDLE.\\n8. What is a namespace, and how does it relate to module files?\\n\\nTest Your Knowledge: Quiz | 85\\n\\n\\x0cTest Your Knowledge: Answers\\n1. You can start an interactive session on Windows 7 and earlier by clicking your Start\\nbutton, picking the All Programs option, clicking the Python entry, and selecting\\nthe “Python (command line)” menu option. You can also achieve the same effect\\non Windows and other platforms by typing python as a system command line in\\nyour system’s console window (a Command Prompt window on Windows). An-\\nother alternative is to launch IDLE, as its main Python shell window is an interactive\\nsession. Depending on your platform and Python, if you have not set your system’s\\nPATH variable to find Python, you may need to cd to where Python is installed, or\\ntype its full directory path instead of just python (e.g., C:\\\\Python33\\\\python on Win-\\ndows, unless you’re using the 3.3 launcher).\\n\\n2. You type system command lines in whatever your platform provides as a system\\nconsole: a Command Prompt window on Windows; an xterm or terminal window\\non Unix, Linux, and Mac OS X; and so on. You type this at the system’s prompt,\\nnot at the Python interactive interpreter’s “>>>” prompt—be careful not to con-\\nfuse these prompts.\\n\\n3. Code in a script (really, module) file can be run with system command lines, file\\nicon clicks, imports and reloads, the exec built-in function, and IDE GUI selections\\nsuch as IDLE’s Run→Run Module menu option. On Unix, they can also be run as\\nexecutables with the #! trick, and some platforms support more specialized launch-\\ning techniques (e.g., drag and drop). In addition, some text editors have unique\\nways to run Python code, some Python programs are provided as standalone “fro-\\nzen binary” executables, and some systems use Python code in embedded mode,\\nwhere it is run automatically by an enclosing program written in a language like\\nC, C++, or Java. The latter technique is usually done to provide a user customi-\\nzation layer.\\n\\n4. Scripts that print and then exit cause the output file to disappear immediately,\\nbefore you can view the output (which is why the input trick comes in handy);\\nerror messages generated by your script also appear in an output window that\\ncloses before you can examine its contents (which is one reason that system com-\\nmand lines and IDEs such as IDLE are better for most development).\\n\\n5. Python imports (loads) a module only once per process, by default, so if you’ve\\nchanged its source code and want to run the new version without stopping and\\nrestarting Python, you’ll have to reload it. You must import a module at least once\\nbefore you can reload it. Running files of code from a system shell command line,\\nvia an icon click, or via an IDE such as IDLE generally makes this a nonissue, as\\nthose launch schemes usually run the current version of the source code file each\\ntime.\\n\\n6. Within  the  text  edit  window  of  the  file  you  wish  to  run,  select  the  window’s\\nRun→Run Module menu option. This runs the window’s source code as a top-level\\nscript file and displays its output back in the interactive Python shell window.\\n\\n86 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c7. IDLE can still be hung by some types of programs—especially GUI programs that\\nperform multithreading (an advanced technique beyond this book’s scope). Also,\\nIDLE has some usability features that can burn you once you leave the IDLE GUI:\\na script’s variables are automatically imported to the interactive scope in IDLE and\\nworking directories are changed when you run a file, for instance, but Python itself\\ndoes not take such steps in general.\\n\\n8. A namespace is just a package of variables (i.e., names). It takes the form of an\\nobject with attributes in Python. Each module file is automatically a namespace—\\nthat is, a package of variables reflecting the assignments made at the top level of\\nthe file. Namespaces help avoid name collisions in Python programs: because each\\nmodule file is a self-contained namespace, files must explicitly import other files\\nin order to use their names.\\n\\nTest Your Knowledge: Part I Exercises\\nIt’s time to start doing a little coding on your own. This first exercise session is fairly\\nsimple, but it’s designed to make sure you’re ready to work along with the rest of the\\nbook, and a few of its questions hint at topics to come in later chapters. Be sure to check\\nPart I in Appendix D for the answers; the exercises and their solutions sometimes con-\\ntain supplemental information not discussed in the main text, so you should take a\\npeek at the solutions even if you manage to answer all the questions on your own.\\n\\n1. Interaction. Using a system command line, IDLE, or any other method that works\\non your platform, start the Python interactive command line (>>> prompt), and\\ntype the expression \"Hello World!\" (including the quotes). The string should be\\nechoed back to you. The purpose of this exercise is to get your environment con-\\nfigured  to  run  Python.  In  some  scenarios,  you  may  need  to  first  run  a  cd  shell\\ncommand, type the full path to the Python executable, or add its path to your\\nPATH environment variable. If desired, you can set PATH in your .cshrc or .kshrc file\\nto make Python permanently available on Unix systems; on Windows, the envi-\\nronment variable GUI is usually what you want for this. See Appendix A for help\\nwith environment variable settings.\\n\\n2. Programs. With the text editor of your choice, write a simple module file containing\\nthe  single  statement  print(\\'Hello  module  world!\\')  and  store  it  as  module1.py.\\nNow, run this file by using any launch option you like: running it in IDLE, clicking\\non its file icon, passing it to the Python interpreter on the system shell’s command\\nline (e.g., python module1.py), built-in exec calls, imports and reloads, and so on.\\nIn fact, experiment by running your file with as many of the launch techniques\\ndiscussed in this chapter as you can. Which technique seems easiest? (There is no\\nright answer to this, of course.)\\n\\n3. Modules. Start the Python interactive command line (>>> prompt) and import the\\nmodule you wrote in exercise 2. Try moving the file to a different directory and\\nimporting it again from its original directory (i.e., run Python in the original di-\\n\\nTest Your Knowledge: Part I Exercises\\n\\n| 87\\n\\n\\x0crectory when you import). What happens? (Hint: is there still a module1.pyc byte\\ncode file in the original directory, or something similar in a __pycache__ subdir-\\nectory there?)\\n\\n4. Scripts.  If  your  platform  supports  it,  add  the  #!  line  to  the  top  of  your  mod-\\nule1.py module file, give the file executable privileges, and run it directly as an\\nexecutable. What does the first line need to contain? #! usually only has meaning\\non Unix, Linux, and Unix-like platforms such as Mac OS X; if you’re working on\\nWindows, instead try running your file by listing just its name in a Command\\nPrompt window without the word “python” before it (this works on recent versions\\nof Windows), via the Start→Run... dialog box, or similar. If you are using Python\\n3.3 or the Windows launcher that installs with it, experiment with changing your\\nscript’s #! line to launch different Python versions you may have installed on your\\ncomputer (or equivalently, work through the tutorial in Appendix B).\\n\\n5. Errors and debugging. Experiment with typing mathematical expressions and as-\\nsignments at the Python interactive command line. Along the way, type the ex-\\npressions 2 ** 500 and 1 / 0, and reference an undefined variable name as we did\\nearly on in this chapter. What happens?\\nYou may not know it yet, but when you make a mistake, you’re doing exception\\nprocessing: a topic we’ll explore in depth in Part VII. As you’ll learn there, you are\\ntechnically triggering what’s known as the default exception handler—logic that\\nprints a standard error message. If you do not catch an error, the default handler\\ndoes and prints the standard error message in response.\\nExceptions are also bound up with the notion of debugging in Python. When you’re\\nfirst starting out, Python’s default error messages on exceptions will probably pro-\\nvide as much error-handling support as you need—they give the cause of the error,\\nas well as showing the lines in your code that were active when the error occurred.\\nFor  more  about  debugging,  see  the  sidebar  “Debugging  Python  Code”\\non page 83.\\n\\n6. Breaks and cycles. At the Python command line, type:\\n\\nL = [1, 2]              # Make a 2-item list\\nL.append(L)             # Append L as a single item to itself\\nL                       # Print L: a cyclic/circular object\\n\\nWhat happens? In all recent versions of Python, you’ll see a strange output that\\nwe’ll describe in the solutions appendix, and which will make more sense when\\nwe study references in the next part of the book. If you’re using a Python version\\nolder than 1.5.1, a Ctrl-C key combination will probably help on most platforms.\\nWhy do you think your version of Python responds the way it does for this code?\\n\\nIf you do have a Python older than Release 1.5.1 (a hopefully rare\\nscenario today!), make sure your machine can stop a program with\\na Ctrl-C key combination of some sort before running this test, or\\nyou may be waiting a long time.\\n\\n88 | Chapter 3:\\u2002How You Run Programs\\n\\n\\x0c7. Documentation. Spend at least 15 minutes browsing the Python library and lan-\\nguage manuals before moving on to get a feel for the available tools in the standard\\nlibrary and the structure of the documentation set. It takes at least this long to\\nbecome familiar with the locations of major topics in the manual set; once you’ve\\ndone this, it’s easy to find what you need. You can find this manual via the Python\\nStart button entry on some Windows, in the Python Docs option on the Help pull-\\ndown menu in IDLE, or online at http://www.python.org/doc. I’ll also have a few\\nmore words to say about the manuals and other documentation sources available\\n(including PyDoc and the help function) in Chapter 15. If you still have time, go\\nexplore the Python website, as well as its PyPI third-party extension repository.\\nEspecially check out the Python.org (http://www.python.org) documentation and\\nsearch pages; they can be crucial resources.\\n\\nTest Your Knowledge: Part I Exercises\\n\\n| 89\\n\\n\\x0c\\x0cPART II\\nTypes and Operations\\n\\n\\x0c\\x0cCHAPTER 4\\nIntroducing Python Object Types\\n\\nThis chapter begins our tour of the Python language. In an informal sense, in Python\\nwe do things with stuff.1 “Things” take the form of operations like addition and con-\\ncatenation, and “stuff” refers to the objects on which we perform those operations. In\\nthis part of the book, our focus is on that stuff, and the things our programs can do with\\nit.\\nSomewhat more formally, in Python, data takes the form of objects—either built-in\\nobjects that Python provides, or objects we create using Python classes or external\\nlanguage tools such as C extension libraries. Although we’ll firm up this definition later,\\nobjects are essentially just pieces of memory, with values and sets of associated oper-\\nations. As we’ll see, everything is an object in a Python script. Even simple numbers\\nqualify, with values (e.g., 99), and supported operations (addition, subtraction, and so\\non).\\nBecause objects are also the most fundamental notion in Python programming, we’ll\\nstart this chapter with a survey of Python’s built-in object types. Later chapters provide\\na second pass that fills in details we’ll gloss over in this survey. Here, our goal is a brief\\ntour to introduce the basics.\\n\\nThe Python Conceptual Hierarchy\\nBefore we get to the code, let’s first establish a clear picture of how this chapter fits into\\nthe overall Python picture. From a more concrete perspective, Python programs can be\\ndecomposed into modules, statements, expressions, and objects, as follows:\\n\\n1. Programs are composed of modules.\\n2. Modules contain statements.\\n3. Statements contain expressions.\\n4. Expressions create and process objects.\\n\\n1. Pardon my formality. I’m a computer scientist.\\n\\n93\\n\\n\\x0cThe discussion of modules in Chapter 3 introduced the highest level of this hierarchy.\\nThis part’s chapters begin at the bottom—exploring both built-in objects and the ex-\\npressions you can code to use them.\\nWe’ll move on to study statements in the next part of the book, though we will find\\nthat they largely exist to manage the objects we’ll meet here. Moreover, by the time we\\nreach classes in the OOP part of this book, we’ll discover that they allow us to define\\nnew object types of our own, by both using and emulating the object types we will\\nexplore here. Because of all this, built-in objects are a mandatory point of embarkation\\nfor all Python journeys.\\n\\nTraditional introductions to programming often stress its three pillars\\nof sequence (“Do this, then that”), selection (“Do this if that is true”),\\nand repetition (“Do this many times”). Python has tools in all three cat-\\negories, along with some for definition—of functions and classes. These\\nthemes may help you organize your thinking early on, but they are a bit\\nartificial and simplistic. Expressions such as comprehensions, for ex-\\nample, are both repetition and selection; some of these terms have other\\nmeanings in Python; and many later concepts won’t seem to fit this mold\\nat all. In Python, the more strongly unifying principle is objects, and\\nwhat we can do with them. To see why, read on.\\n\\nWhy Use Built-in Types?\\nIf you’ve used lower-level languages such as C or C++, you know that much of your\\nwork centers on implementing objects—also known as data structures—to represent\\nthe components in your application’s domain. You need to lay out memory structures,\\nmanage memory allocation, implement search and access routines, and so on. These\\nchores are about as tedious (and error-prone) as they sound, and they usually distract\\nfrom your program’s real goals.\\nIn typical Python programs, most of this grunt work goes away. Because Python pro-\\nvides powerful object types as an intrinsic part of the language, there’s usually no need\\nto code object implementations before you start solving problems. In fact, unless you\\nhave a need for special processing that built-in types don’t provide, you’re almost al-\\nways better off using a built-in object instead of implementing your own. Here are some\\nreasons why:\\n\\n• Built-in objects make programs easy to write. For simple tasks, built-in types\\nare often all you need to represent the structure of problem domains. Because you\\nget powerful tools such as collections (lists) and search tables (dictionaries) for free,\\nyou can use them immediately. You can get a lot of work done with Python’s built-\\nin object types alone.\\n\\n• Built-in objects are components of extensions. For more complex tasks, you\\nmay need to provide your own objects using Python classes or C language inter-\\n\\n94 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cfaces. But as you’ll see in later parts of this book, objects implemented manually\\nare often built on top of built-in types such as lists and dictionaries. For instance,\\na stack data structure may be implemented as a class that manages or customizes\\na built-in list.\\n\\n• Built-in  objects  are  often  more  efficient  than  custom  data  structures.\\nPython’s built-in types employ already optimized data structure algorithms that\\nare implemented in C for speed. Although you can write similar object types on\\nyour own, you’ll usually be hard-pressed to get the level of performance built-in\\nobject types provide.\\n\\n• Built-in objects are a standard part of the language. In some ways, Python\\nborrows both from languages that rely on built-in tools (e.g., LISP) and languages\\nthat rely on the programmer to provide tool implementations or frameworks of\\ntheir own (e.g., C++). Although you can implement unique object types in Python,\\nyou don’t need to do so just to get started. Moreover, because Python’s built-ins\\nare standard, they’re always the same; proprietary frameworks, on the other hand,\\ntend to differ from site to site.\\n\\nIn other words, not only do built-in object types make programming easier, but they’re\\nalso more powerful and efficient than most of what can be created from scratch. Re-\\ngardless of whether you implement new object types, built-in objects form the core of\\nevery Python program.\\n\\nPython’s Core Data Types\\nTable 4-1 previews Python’s built-in object types and some of the syntax used to code\\ntheir literals—that is, the expressions that generate these objects.2 Some of these types\\nwill probably seem familiar if you’ve used other languages; for instance, numbers and\\nstrings represent numeric and textual values, respectively, and file objects provide an\\ninterface for processing real files stored on your computer.\\nTo some readers, though, the object types in Table 4-1 may be more general and pow-\\nerful than what you are accustomed to. For instance, you’ll find that lists and diction-\\naries alone are powerful data representation tools that obviate most of the work you\\ndo to support collections and searching in lower-level languages. In short, lists provide\\nordered collections of other objects, while dictionaries store objects by key; both lists\\nand dictionaries may be nested, can grow and shrink on demand, and may contain\\nobjects of any type.\\n\\n2. In this book, the term literal simply means an expression whose syntax generates an object—sometimes\\nalso called a constant. Note that the term “constant” does not imply objects or variables that can never\\nbe changed (i.e., this term is unrelated to C++’s const or Python’s “immutable”—a topic explored in the\\nsection “Immutability” on page 101).\\n\\nPython’s Core Data Types\\n\\n| 95\\n\\n\\x0cTable 4-1. Built-in objects preview\\n\\nObject type\\nNumbers\\nStrings\\nLists\\nDictionaries\\nTuples\\nFiles\\nSets\\nOther core types\\nProgram unit types\\nImplementation-related types\\n\\nExample literals/creation\\n1234, 3.1415, 3+4j, 0b111, Decimal(), Fraction()\\n\\'spam\\', \"Bob\\'s\", b\\'a\\\\x01c\\', u\\'sp\\\\xc4m\\'\\n[1, [2, \\'three\\'], 4.5], list(range(10))\\n{\\'food\\': \\'spam\\', \\'taste\\': \\'yum\\'}, dict(hours=10)\\n(1, \\'spam\\', 4, \\'U\\'), tuple(\\'spam\\'), namedtuple\\nopen(\\'eggs.txt\\'), open(r\\'C:\\\\ham.bin\\', \\'wb\\')\\nset(\\'abc\\'), {\\'a\\', \\'b\\', \\'c\\'}\\nBooleans, types, None\\nFunctions, modules, classes (Part IV, Part V, Part VI)\\nCompiled code, stack tracebacks (Part IV, Part VII)\\n\\nAlso shown in Table 4-1, program units such as functions, modules, and classes—which\\nwe’ll meet in later parts of this book—are objects in Python too; they are created with\\nstatements and expressions such as def, class, import, and lambda and may be passed\\naround scripts freely, stored within other objects, and so on. Python also provides a \\nset of implementation-related types such as compiled code objects, which are generally\\nof interest to tool builders more than application developers; we’ll explore these in later\\nparts too, though in less depth due to their specialized roles.\\nDespite its title, Table 4-1 isn’t really complete, because everything we process in Python\\nprograms is a kind of object. For instance, when we perform text pattern matching in\\nPython, we create pattern objects, and when we perform network scripting, we use\\nsocket objects. These other kinds of objects are generally created by importing and\\nusing functions in library modules—for example, in the re and socket modules for\\npatterns and sockets—and have behavior all their own.\\nWe usually call the other object types in Table 4-1 core data types, though, because\\nthey are effectively built into the Python language—that is, there is specific expression\\nsyntax for generating most of them. For instance, when you run the following code\\nwith characters surrounded by quotes:\\n\\n>>> \\'spam\\'\\n\\nyou are, technically speaking, running a literal expression that generates and returns a \\nnew string object. There is specific Python language syntax to make this object. Simi-\\nlarly, an expression wrapped in square brackets makes a list, one in curly braces makes\\na dictionary, and so on. Even though, as we’ll see, there are no type declarations in\\nPython, the syntax of the expressions you run determines the types of objects you create\\nand use. In fact, object-generation expressions like those in Table 4-1 are generally\\nwhere types originate in the Python language.\\n\\n96 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cJust as importantly, once you create an object, you bind its operation set for all time—\\nyou can perform only string operations on a string and list operations on a list. In formal\\nterms, this means that Python is dynamically typed, a model that keeps track of types\\nfor you automatically instead of requiring declaration code, but it is also strongly ty-\\nped, a constraint that means you can perform on an object only operations that are\\nvalid for its type.\\nWe’ll study each of the object types in Table 4-1 in detail in upcoming chapters. Before\\ndigging into the details, though, let’s begin by taking a quick look at Python’s core\\nobjects in action. The rest of this chapter provides a preview of the operations we’ll\\nexplore in more depth in the chapters that follow. Don’t expect to find the full story\\nhere—the goal of this chapter is just to whet your appetite and introduce some key\\nideas. Still, the best way to get started is to get started, so let’s jump right into some\\nreal code.\\n\\nNumbers\\nIf you’ve done any programming or scripting in the past, some of the object types in\\nTable 4-1 will probably seem familiar. Even if you haven’t, numbers are fairly straight-\\nforward. Python’s core objects set includes the usual suspects: integers that have no\\nfractional part, floating-point numbers that do, and more exotic types—complex num-\\nbers with imaginary parts, decimals with fixed precision, rationals with numerator and\\ndenominator, and full-featured sets. Built-in numbers are enough to represent most\\nnumeric quantities—from your age to your bank balance—but more types are available\\nas third-party add-ons.\\nAlthough it offers some fancier options, Python’s basic number types are, well, basic.\\nNumbers in Python support the normal mathematical operations. For instance, the \\nplus sign (+) performs addition, a star (*) is used for multiplication, and two stars (**)\\nare used for exponentiation:\\n\\n>>> 123 + 222                    # Integer addition\\n345\\n>>> 1.5 * 4                      # Floating-point multiplication\\n6.0\\n>>> 2 ** 100                     # 2 to the power 100, again\\n1267650600228229401496703205376\\n\\nNotice the last result here: Python 3.X’s integer type automatically provides extra pre-\\ncision for large numbers like this when needed (in 2.X, a separate long integer type\\nhandles numbers too large for the normal integer type in similar ways). You can, for\\ninstance, compute 2 to the power 1,000,000 as an integer in Python, but you probably\\nshouldn’t try to print the result—with more than 300,000 digits, you may be waiting\\nawhile!\\n\\n>>> len(str(2 ** 1000000))       # How many digits in a really BIG number?\\n301030\\n\\nNumbers\\n\\n| 97\\n\\n\\x0cThis nested-call form works from inside out—first converting the ** result’s number\\nto a string of digits with the built-in str function, and then getting the length of the\\nresulting string with len. The end result is the number of digits. str and len work on\\nmany object types; more on both as we move along.\\nOn  Pythons  prior  to  2.7  and  3.1,  once  you  start  experimenting  with  floating-point\\nnumbers, you’re likely to stumble across something that may look a bit odd at first\\nglance:\\n\\n>>> 3.1415 * 2                   # repr: as code (Pythons < 2.7 and 3.1)\\n6.2830000000000004\\n>>> print(3.1415 * 2)            # str: user-friendly\\n6.283\\n\\nThe first result isn’t a bug; it’s a display issue. It turns out that there are two ways to\\nprint every object in Python—with full precision (as in the first result shown here), and\\nin a user-friendly form (as in the second). Formally, the first form is known as an object’s\\nas-code repr, and the second is its user-friendly str. In older Pythons, the floating-point\\nrepr sometimes displays more precision than you might expect. The difference can also\\nmatter when we step up to using classes. For now, if something looks odd, try showing\\nit with a print built-in function call statement.\\nBetter yet, upgrade to Python 2.7 and the latest 3.X, where floating-point numbers\\ndisplay themselves more intelligently, usually with fewer extraneous digits—since this\\nbook is based on Pythons 2.7 and 3.3, this is the display form I’ll be showing throughout\\nthis book for floating-point numbers:\\n\\n>>> 3.1415 * 2                   # repr: as code (Pythons >= 2.7 and 3.1)\\n6.283\\n\\nBesides  expressions,  there  are  a  handful  of  useful  numeric  modules  that  ship  with\\nPython—modules are just packages of additional tools that we import to use:\\n\\n>>> import math\\n>>> math.pi\\n3.141592653589793\\n>>> math.sqrt(85)\\n9.219544457292887\\n\\nThe math module contains more advanced numeric tools as functions, while the ran\\ndom module performs random-number generation and random selections (here, from a\\nPython list coded in square brackets—an ordered collection of other objects to be in-\\ntroduced later in this chapter):\\n\\n>>> import random\\n>>> random.random()\\n0.7082048489415967\\n>>> random.choice([1, 2, 3, 4])\\n1\\n\\nPython also includes more exotic numeric objects—such as complex, fixed-precision,\\nand rational numbers, as well as sets and Booleans—and the third-party open source\\n\\n98 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cextension domain has even more (e.g., matrixes and vectors, and extended precision\\nnumbers). We’ll defer discussion of these types until later in this chapter and book.\\nSo far, we’ve been using Python much like a simple calculator; to do better justice to\\nits built-in types, let’s move on to explore strings.\\n\\nStrings\\nStrings are used to record both textual information (your name, for instance) as well\\nas arbitrary collections of bytes (such as an image file’s contents). They are our first\\nexample of what in Python we call a sequence—a positionally ordered collection of\\nother objects. Sequences maintain a left-to-right order among the items they contain:\\ntheir items are stored and fetched by their relative positions. Strictly speaking, strings\\nare  sequences  of  one-character  strings;  other,  more  general  sequence  types  include\\nlists and tuples, covered later.\\n\\nSequence Operations\\nAs  sequences,  strings  support  operations  that  assume  a  positional  ordering  among\\nitems. For example, if we have a four-character string coded inside quotes (usually of\\nthe single variety), we can verify its length with the built-in len function and fetch its\\ncomponents with indexing expressions:\\n\\n>>> S = \\'Spam\\'           # Make a 4-character string, and assign it to a name\\n>>> len(S)               # Length\\n4\\n>>> S[0]                 # The first item in S, indexing by zero-based position\\n\\'S\\'\\n>>> S[1]                 # The second item from the left\\n\\'p\\'\\n\\nIn Python, indexes are coded as offsets from the front, and so start from 0: the first item\\nis at index 0, the second is at index 1, and so on.\\nNotice how we assign the string to a variable named S here. We’ll go into detail on how\\nthis works later (especially in Chapter 6), but Python variables never need to be declared\\nahead of time. A variable is created when you assign it a value, may be assigned any\\ntype of object, and is replaced with its value when it shows up in an expression. It must\\nalso have been previously assigned by the time you use its value. For the purposes of\\nthis chapter, it’s enough to know that we need to assign an object to a variable in order\\nto save it for later use.\\nIn Python, we can also index backward, from the end—positive indexes count from\\nthe left, and negative indexes count back from the right:\\n\\n>>> S[-1]                # The last item from the end in S\\n\\'m\\'\\n>>> S[-2]                # The second-to-last item from the end\\n\\'a\\'\\n\\nStrings\\n\\n| 99\\n\\n\\x0cFormally, a negative index is simply added to the string’s length, so the following two\\noperations are equivalent (though the first is easier to code and less easy to get wrong):\\n\\n>>> S[-1]                # The last item in S\\n\\'m\\'\\n>>> S[len(S)-1]          # Negative indexing, the hard way\\n\\'m\\'\\n\\nNotice that we can use an arbitrary expression in the square brackets, not just a hard-\\ncoded number literal—anywhere that Python expects a value, we can use a literal, a\\nvariable, or any expression we wish. Python’s syntax is completely general this way.\\nIn addition to simple positional indexing, sequences also support a more general form\\nof indexing known as slicing, which is a way to extract an entire section (slice) in a single\\nstep. For example:\\n\\n>>> S                     # A 4-character string\\n\\'Spam\\'\\n>>> S[1:3]                # Slice of S from offsets 1 through 2 (not 3)\\n\\'pa\\'\\n\\nProbably the easiest way to think of slices is that they are a way to extract an entire\\ncolumn from a string in a single step. Their general form, X[I:J], means “give me ev-\\nerything in X from offset I up to but not including offset J.” The result is returned in a\\nnew object. The second of the preceding operations, for instance, gives us all the char-\\nacters in string S from offsets 1 through 2 (that is, 1 through 3 – 1) as a new string. The\\neffect is to slice or “parse out” the two characters in the middle.\\nIn a slice, the left bound defaults to zero, and the right bound defaults to the length of\\nthe sequence being sliced. This leads to some common usage variations:\\n\\n>>> S[1:]                 # Everything past the first (1:len(S))\\n\\'pam\\'\\n>>> S                     # S itself hasn\\'t changed\\n\\'Spam\\'\\n>>> S[0:3]                # Everything but the last\\n\\'Spa\\'\\n>>> S[:3]                 # Same as S[0:3]\\n\\'Spa\\'\\n>>> S[:-1]                # Everything but the last again, but simpler (0:-1)\\n\\'Spa\\'\\n>>> S[:]                  # All of S as a top-level copy (0:len(S))\\n\\'Spam\\'\\n\\nNote in the second-to-last command how negative offsets can be used to give bounds\\nfor slices, too, and how the last operation effectively copies the entire string. As you’ll\\nlearn later, there is no reason to copy a string, but this form can be useful for sequences\\nlike lists.\\nFinally, as sequences, strings also support concatenation with the plus sign (joining two\\nstrings into a new string) and repetition (making a new string by repeating another):\\n\\n>>> S\\n\\'Spam\\'\\n\\n100 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c>>> S + \\'xyz\\'             # Concatenation\\n\\'Spamxyz\\'\\n>>> S                     # S is unchanged\\n\\'Spam\\'\\n>>> S * 8                 # Repetition\\n\\'SpamSpamSpamSpamSpamSpamSpamSpam\\'\\n\\nNotice that the plus sign (+) means different things for different objects: addition for\\nnumbers, and concatenation for strings. This is a general property of Python that we’ll\\ncall polymorphism later in the book—in sum, the meaning of an operation depends on\\nthe objects being operated on. As you’ll see when we study dynamic typing, this poly-\\nmorphism property accounts for much of the conciseness and flexibility of Python code.\\nBecause  types  aren’t  constrained,  a  Python-coded  operation  can  normally  work  on\\nmany different types of objects automatically, as long as they support a compatible\\ninterface (like the + operation here). This turns out to be a huge idea in Python; you’ll\\nlearn more about it later on our tour.\\n\\nImmutability\\nAlso notice in the prior examples that we were not changing the original string with\\nany of the operations we ran on it. Every string operation is defined to produce a new\\nstring as its result, because strings are immutable in Python—they cannot be changed\\nin place after they are created. In other words, you can never overwrite the values of\\nimmutable objects. For example, you can’t change a string by assigning to one of its\\npositions, but you can always build a new one and assign it to the same name. Because\\nPython cleans up old objects as you go (as you’ll see later), this isn’t as inefficient as it\\nmay sound:\\n\\n>>> S\\n\\'Spam\\'\\n\\n>>> S[0] = \\'z\\'             # Immutable objects cannot be changed\\n...error text omitted...\\nTypeError: \\'str\\' object does not support item assignment\\n\\n>>> S = \\'z\\' + S[1:]        # But we can run expressions to make new objects\\n>>> S\\n\\'zpam\\'\\n\\nEvery object in Python is classified as either immutable (unchangeable) or not. In terms\\nof the core types, numbers, strings, and tuples are immutable; lists, dictionaries, and\\nsets are not—they can be changed in place freely, as can most new objects you’ll code\\nwith classes. This distinction turns out to be crucial in Python work, in ways that we\\ncan’t yet fully explore. Among other things, immutability can be used to guarantee that\\nan object remains constant throughout your program; mutable objects’ values can be\\nchanged at any time and place (and whether you expect it or not).\\n\\nStrings\\n\\n| 101\\n\\n\\x0cStrictly speaking, you can change text-based data in place if you either expand it into a\\nlist of individual characters and join it back together with nothing between, or use the \\nnewer bytearray type available in Pythons 2.6, 3.0, and later:\\n\\n>>> S = \\'shrubbery\\'\\n>>> L = list(S)                                     # Expand to a list: [...]\\n>>> L\\n[\\'s\\', \\'h\\', \\'r\\', \\'u\\', \\'b\\', \\'b\\', \\'e\\', \\'r\\', \\'y\\']\\n>>> L[1] = \\'c\\'                                      # Change it in place\\n>>> \\'\\'.join(L)                                      # Join with empty delimiter\\n\\'scrubbery\\'\\n\\n>>> B = bytearray(b\\'spam\\')                          # A bytes/list hybrid (ahead)\\n>>> B.extend(b\\'eggs\\')                               # \\'b\\' needed in 3.X, not 2.X\\n>>> B                                               # B[i] = ord(c) works here too\\nbytearray(b\\'spameggs\\')\\n>>> B.decode()                                      # Translate to normal string\\n\\'spameggs\\'\\n\\nThe bytearray supports in-place changes for text, but only for text whose characters\\nare all at most 8-bits wide (e.g., ASCII). All other strings are still immutable—bytear\\nray is a distinct hybrid of immutable bytes strings (whose b\\'...\\' syntax is required in\\n3.X and optional in 2.X) and mutable lists (coded and displayed in []), and we have to\\nlearn more about both these and Unicode text to fully grasp this code.\\n\\nType-Specific Methods\\nEvery string operation we’ve studied so far is really a sequence operation—that is, these\\noperations will work on other sequences in Python as well, including lists and tuples.\\nIn addition to generic sequence operations, though, strings also have operations all\\ntheir own, available as methods—functions that are attached to and act upon a specific\\nobject, which are triggered with a call expression.\\nFor example, the string find method is the basic substring search operation (it returns\\nthe offset of the passed-in substring, or −1 if it is not present), and the string replace\\nmethod performs global searches and replacements; both act on the subject that they\\nare attached to and called from:\\n\\n>>> S = \\'Spam\\'\\n>>> S.find(\\'pa\\')                 # Find the offset of a substring in S\\n1\\n>>> S\\n\\'Spam\\'\\n>>> S.replace(\\'pa\\', \\'XYZ\\')       # Replace occurrences of a string in S with another\\n\\'SXYZm\\'\\n>>> S\\n\\'Spam\\'\\n\\nAgain, despite the names of these string methods, we are not changing the original\\nstrings here, but creating new strings as the results—because strings are immutable,\\nthis is the only way this can work. String methods are the first line of text-processing\\n\\n102 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0ctools in Python. Other methods split a string into substrings on a delimiter (handy as\\na simple form of parsing), perform case conversions, test the content of the string (digits,\\nletters, and so on), and strip whitespace characters off the ends of the string:\\n\\n>>> line = \\'aaa,bbb,ccccc,dd\\'\\n>>> line.split(\\',\\')              # Split on a delimiter into a list of substrings\\n[\\'aaa\\', \\'bbb\\', \\'ccccc\\', \\'dd\\']\\n\\n>>> S = \\'spam\\'\\n>>> S.upper()                    # Upper- and lowercase conversions\\n\\'SPAM\\'\\n>>> S.isalpha()                  # Content tests: isalpha, isdigit, etc.\\nTrue\\n\\n>>> line = \\'aaa,bbb,ccccc,dd\\\\n\\'\\n>>> line.rstrip()                # Remove whitespace characters on the right side\\n\\'aaa,bbb,ccccc,dd\\'\\n>>> line.rstrip().split(\\',\\')     # Combine two operations\\n[\\'aaa\\', \\'bbb\\', \\'ccccc\\', \\'dd\\']\\n\\nNotice the last command here—it strips before it splits because Python runs from left\\nto right, making a temporary result along the way. Strings also support an advanced\\nsubstitution operation known as formatting, available as both an expression (the orig-\\ninal) and a string method call (new as of 2.6 and 3.0); the second of these allows you\\nto omit relative argument value numbers as of 2.7 and 3.1:\\n\\n>>> \\'%s, eggs, and %s\\' % (\\'spam\\', \\'SPAM!\\')          # Formatting expression (all)\\n\\'spam, eggs, and SPAM!\\'\\n\\n>>> \\'{0}, eggs, and {1}\\'.format(\\'spam\\', \\'SPAM!\\')    # Formatting method (2.6+, 3.0+)\\n\\'spam, eggs, and SPAM!\\'\\n\\n>>> \\'{}, eggs, and {}\\'.format(\\'spam\\', \\'SPAM!\\')      # Numbers optional (2.7+, 3.1+)\\n\\'spam, eggs, and SPAM!\\'\\n\\nFormatting is rich with features, which we’ll postpone discussing until later in this\\nbook, and which tend to matter most when you must generate numeric reports:\\n\\n>>> \\'{:,.2f}\\'.format(296999.2567)                   # Separators, decimal digits\\n\\'296,999.26\\'\\n>>> \\'%.2f | %+05d\\' % (3.14159, −42)                 # Digits, padding, signs\\n\\'3.14 | −0042\\'\\n\\nOne note here: although sequence operations are generic, methods are not—although\\nsome types share some method names, string method operations generally work only\\non strings, and nothing else. As a rule of thumb, Python’s toolset is layered: generic\\noperations that span multiple types show up as built-in functions or expressions (e.g.,\\nlen(X),  X[0]), but type-specific operations are method calls (e.g.,  aString.upper()).\\nFinding the tools you need among all these categories will become more natural as you\\nuse Python more, but the next section gives a few tips you can use right now.\\n\\nStrings\\n\\n| 103\\n\\n\\x0cGetting Help\\nThe methods introduced in the prior section are a representative, but small, sample of\\nwhat is available for string objects. In general, this book is not exhaustive in its look at\\nobject methods. For more details, you can always call the built-in dir function. This\\nfunction lists variables assigned in the caller’s scope when called with no argument;\\nmore usefully, it returns a list of all the attributes available for any object passed to it.\\nBecause methods are function attributes, they will show up in this list. Assuming S is\\nstill the string, here are its attributes on Python 3.3 (Python 2.X varies slightly):\\n\\n>>> dir(S)\\n[\\'__add__\\', \\'__class__\\', \\'__contains__\\', \\'__delattr__\\', \\'__dir__\\', \\'__doc__\\',\\n\\'__eq__\\', \\'__format__\\', \\'__ge__\\', \\'__getattribute__\\', \\'__getitem__\\',\\n\\'__getnewargs__\\', \\'__gt__\\', \\'__hash__\\', \\'__init__\\', \\'__iter__\\', \\'__le__\\',\\n\\'__len__\\', \\'__lt__\\', \\'__mod__\\', \\'__mul__\\', \\'__ne__\\', \\'__new__\\', \\'__reduce__\\',\\n\\'__reduce_ex__\\', \\'__repr__\\', \\'__rmod__\\', \\'__rmul__\\', \\'__setattr__\\', \\'__sizeof__\\',\\n\\'__str__\\', \\'__subclasshook__\\', \\'capitalize\\', \\'casefold\\', \\'center\\', \\'count\\',\\n\\'encode\\', \\'endswith\\', \\'expandtabs\\', \\'find\\', \\'format\\', \\'format_map\\', \\'index\\',\\n\\'isalnum\\', \\'isalpha\\', \\'isdecimal\\', \\'isdigit\\', \\'isidentifier\\', \\'islower\\',\\n\\'isnumeric\\', \\'isprintable\\', \\'isspace\\', \\'istitle\\', \\'isupper\\', \\'join\\', \\'ljust\\',\\n\\'lower\\', \\'lstrip\\', \\'maketrans\\', \\'partition\\', \\'replace\\', \\'rfind\\', \\'rindex\\',\\n\\'rjust\\', \\'rpartition\\', \\'rsplit\\', \\'rstrip\\', \\'split\\', \\'splitlines\\', \\'startswith\\',\\n\\'strip\\', \\'swapcase\\', \\'title\\', \\'translate\\', \\'upper\\', \\'zfill\\']\\n\\nYou probably won’t care about the names with double underscores in this list until later\\nin the book, when we study operator overloading in classes—they represent the im-\\nplementation  of  the  string  object  and  are  available  to  support  customization.  The\\n__add__ method of strings, for example, is what really performs concatenation; Python\\nmaps the first of the following to the second internally, though you shouldn’t usually\\nuse the second form yourself (it’s less intuitive, and might even run slower):\\n\\n>>> S + \\'NI!\\'\\n\\'spamNI!\\'\\n>>> S.__add__(\\'NI!\\')\\n\\'spamNI!\\'\\n\\nIn general, leading and trailing double underscores is the naming pattern Python uses\\nfor implementation details. The names without the underscores in this list are the call-\\nable methods on string objects.\\nThe dir function simply gives the methods’ names. To ask what they do, you can pass\\nthem to the help function:\\n\\n>>> help(S.replace)\\nHelp on built-in function replace:\\n\\nreplace(...)\\n    S.replace(old, new[, count]) -> str\\n\\n    Return a copy of S with all occurrences of substring\\n    old replaced by new.  If the optional argument count is\\n    given, only the first count occurrences are replaced.\\n\\n104 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0chelp is one of a handful of interfaces to a system of code that ships with Python known\\nas PyDoc—a tool for extracting documentation from objects. Later in the book, you’ll\\nsee that PyDoc can also render its reports in HTML format for display on a web browser.\\nYou can also ask for help on an entire string (e.g., help(S)), but you may get more or\\nless help than you want to see—information about every string method in older Py-\\nthons, and probably no help at all in newer versions because strings are treated specially.\\nIt’s generally better to ask about a specific method.\\nBoth dir and help also accept as arguments either a real object (like our string S), or\\nthe name of a data type (like str, list, and dict). The latter form returns the same list\\nfor dir but shows full type details for help, and allows you to ask about a specific method\\nvia type name (e.g., help on str.replace).\\nFor more details, you can also consult Python’s standard library reference manual or\\ncommercially published reference books, but dir and help are the first level of docu-\\nmentation in Python.\\n\\nOther Ways to Code Strings\\nSo far, we’ve looked at the string object’s sequence operations and type-specific meth-\\nods. Python also provides a variety of ways for us to code strings, which we’ll explore\\nin greater depth later. For instance, special characters can be represented as backslash\\nescape sequences, which Python displays in \\\\xNN hexadecimal escape notation, unless\\nthey represent printable characters:\\n\\n>>> S = \\'A\\\\nB\\\\tC\\'            # \\\\n is end-of-line, \\\\t is tab\\n>>> len(S)                   # Each stands for just one character\\n5\\n\\n>>> ord(\\'\\\\n\\')                # \\\\n is a byte with the binary value 10 in ASCII\\n10\\n\\n>>> S = \\'A\\\\0B\\\\0C\\'            # \\\\0, a binary zero byte, does not terminate string\\n>>> len(S)\\n5\\n>>> S                        # Non-printables are displayed as \\\\xNN hex escapes\\n\\'a\\\\x00B\\\\x00C\\'\\n\\nPython allows strings to be enclosed in single or double quote characters—they mean\\nthe same thing but allow the other type of quote to be embedded with an escape (most\\nprogrammers prefer single quotes). It also allows multiline string literals enclosed in\\ntriple quotes (single or double)—when this form is used, all the lines are concatenated\\ntogether, and end-of-line characters are added where line breaks appear. This is a minor\\nsyntactic convenience, but it’s useful for embedding things like multiline HTML, XML,\\nor JSON code in a Python script, and stubbing out lines of code temporarily—just add\\nthree quotes above and below:\\n\\n>>> msg = \"\"\"\\naaaaaaaaaaaaa\\n\\nStrings\\n\\n| 105\\n\\n\\x0cbbb\\'\\'\\'bbbbbbbbbb\"\"bbbbbbb\\'bbbb\\ncccccccccccccc\\n\"\"\"\\n>>> msg\\n\\'\\\\naaaaaaaaaaaaa\\\\nbbb\\\\\\'\\\\\\'\\\\\\'bbbbbbbbbb\"\"bbbbbbb\\\\\\'bbbb\\\\ncccccccccccccc\\\\n\\'\\n\\nPython also supports a raw string literal that turns off the backslash escape mechanism.\\nSuch literals start with the letter r and are useful for strings like directory paths on\\nWindows (e.g., r\\'C:\\\\text\\\\new\\').\\n\\nUnicode Strings\\nPython’s strings also come with full Unicode support required for processing text in\\ninternationalized character sets. Characters in the Japanese and Russian alphabets, for\\nexample, are outside the ASCII set. Such non-ASCII text can show up in web pages,\\nemails, GUIs, JSON, XML, or elsewhere. When it does, handling it well requires Uni-\\ncode support. Python has such support built in, but the form of its Unicode support\\nvaries per Python line, and is one of their most prominent differences.\\nIn Python 3.X, the normal str string handles Unicode text (including ASCII, which is\\njust a simple kind of Unicode); a distinct bytes string type represents raw byte values\\n(including media and encoded text); and 2.X Unicode literals are supported in 3.3 and\\nlater for 2.X compatibility (they are treated the same as normal 3.X str strings):\\n\\n>>> \\'sp\\\\xc4m\\'                     # 3.X: normal str strings are Unicode text\\n\\'spÄm\\'\\n>>> b\\'a\\\\x01c\\'                     # bytes strings are byte-based data\\nb\\'a\\\\x01c\\'\\n>>> u\\'sp\\\\u00c4m\\'                  # The 2.X Unicode literal works in 3.3+: just str\\n\\'spÄm\\'\\n\\nIn Python 2.X, the normal str string handles both 8-bit character strings (including\\nASCII text) and raw byte values; a distinct unicode string type represents Unicode text;\\nand 3.X bytes literals are supported in 2.6 and later for 3.X compatibility (they are\\ntreated the same as normal 2.X str strings):\\n\\n>>> print u\\'sp\\\\xc4m\\'              # 2.X: Unicode strings are a distinct type\\nspÄm\\n>>> \\'a\\\\x01c\\'                      # Normal str strings contain byte-based text/data\\n\\'a\\\\x01c\\'\\n>>> b\\'a\\\\x01c\\'                     # The 3.X bytes literal works in 2.6+: just str\\n\\'a\\\\x01c\\'\\n\\nFormally, in both 2.X and 3.X, non-Unicode strings are sequences of 8-bit bytes that\\nprint with ASCII characters when possible, and Unicode strings are sequences of Uni-\\ncode code points—identifying numbers for characters, which do not necessarily map to\\nsingle bytes when encoded to files or stored in memory. In fact, the notion of bytes\\ndoesn’t apply to Unicode: some encodings include character code points too large for\\na byte, and even simple 7-bit ASCII text is not stored one byte per character under some\\nencodings and memory storage schemes:\\n\\n106 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c>>> \\'spam\\'                        # Characters may be 1, 2, or 4 bytes in memory\\n\\'spam\\'\\n>>> \\'spam\\'.encode(\\'utf8\\')         # Encoded to 4 bytes in UTF-8 in files\\nb\\'spam\\'\\n>>> \\'spam\\'.encode(\\'utf16\\')        # But encoded to 10 bytes in UTF-16\\nb\\'\\\\xff\\\\xfes\\\\x00p\\\\x00a\\\\x00m\\\\x00\\'\\n\\nBoth 3.X and 2.X also support the bytearray string type we met earlier, which is es-\\nsentially a bytes string (a str in 2.X) that supports most of the list object’s in-place\\nmutable change operations.\\nBoth 3.X and 2.X also support coding non-ASCII characters with \\\\x hexadecimal and\\nshort \\\\u and long \\\\U Unicode escapes, as well as file-wide encodings declared in program\\nsource files. Here’s our non-ASCII character coded three ways in 3.X (add a leading\\n“u” and say “print” to see the same in 2.X):\\n\\n>>> \\'sp\\\\xc4\\\\u00c4\\\\U000000c4m\\'\\n\\'spÄÄÄm\\'\\n\\nWhat these values mean and how they are used differs between text strings, which are\\nthe normal string in 3.X and Unicode in 2.X, and byte strings, which are bytes in 3.X\\nand the normal string in 2.X. All these escapes can be used to embed actual Unicode\\ncode-point ordinal-value integers in text strings. By contrast, byte strings use only \\\\x\\nhexadecimal escapes to embed the encoded form of text, not its decoded code point\\nvalues—encoded bytes are the same as code points, only for some encodings and char-\\nacters:\\n\\n>>> \\'\\\\u00A3\\', \\'\\\\u00A3\\'.encode(\\'latin1\\'), b\\'\\\\xA3\\'.decode(\\'latin1\\')\\n(\\'£\\', b\\'\\\\xa3\\', \\'£\\')\\n\\nAs a notable difference, Python 2.X allows its normal and Unicode strings to be mixed\\nin expressions as long as the normal string is all ASCII; in contrast, Python 3.X has a\\ntighter model that  never allows its normal and byte strings to mix without explicit\\nconversion:\\n\\nu\\'x\\' + b\\'y\\'            # Works in 2.X (where b is optional and ignored)\\nu\\'x\\' + \\'y\\'             # Works in 2.X: u\\'xy\\'\\n\\nu\\'x\\' + b\\'y\\'            # Fails in 3.3 (where u is optional and ignored)\\nu\\'x\\' + \\'y\\'             # Works in 3.3: \\'xy\\'\\n\\n\\'x\\' + b\\'y\\'.decode()    # Works in 3.X if decode bytes to str: \\'xy\\'\\n\\'x\\'.encode() + b\\'y\\'    # Works in 3.X if encode str to bytes: b\\'xy\\'\\n\\nApart from these string types, Unicode processing mostly reduces to transferring text\\ndata to and from files—text is encoded to bytes when stored in a file, and decoded into\\ncharacters (a.k.a. code points) when read back into memory. Once it is loaded, we\\nusually process text as strings in decoded form only.\\nBecause of this model, though, files are also content-specific in 3.X: text files implement \\nnamed encodings and accept and return str strings, but binary files instead deal in\\n\\nStrings\\n\\n| 107\\n\\n\\x0cbytes strings for raw binary data. In Python 2.X, normal files’ content is str bytes, and\\na special codecs module handles Unicode and represents content with the unicode type.\\nWe’ll meet Unicode again in the files coverage later in this chapter, but save the rest of\\nthe Unicode story for later in this book. It crops up briefly in a Chapter 25 example in\\nconjunction with currency symbols, but for the most part is postponed until this book’s\\nadvanced topics part. Unicode is crucial in some domains, but many programmers can\\nget by with just a passing acquaintance. If your data is all ASCII text, the string and file\\nstories are largely the same in 2.X and 3.X. And if you’re new to programming, you can\\nsafely defer most Unicode details until you’ve mastered string basics.\\n\\nPattern Matching\\nOne point worth noting before we move on is that none of the string object’s own\\nmethods support pattern-based text processing. Text pattern matching is an advanced\\ntool outside this book’s scope, but readers with backgrounds in other scripting lan-\\nguages may be interested to know that to do pattern matching in Python, we import a \\nmodule  called  re.  This  module  has  analogous  calls  for  searching,  splitting,  and  re-\\nplacement, but because we can use patterns to specify substrings, we can be much more\\ngeneral:\\n\\n>>> import re\\n>>> match = re.match(\\'Hello[ \\\\t]*(.*)world\\', \\'Hello    Python world\\')\\n>>> match.group(1)\\n\\'Python \\'\\n\\nThis example searches for a substring that begins with the word “Hello,” followed by\\nzero or more tabs or spaces, followed by arbitrary characters to be saved as a matched\\ngroup, terminated by the word “world.” If such a substring is found, portions of the\\nsubstring  matched  by  parts  of  the  pattern  enclosed  in  parentheses  are  available  as\\ngroups. The following pattern, for example, picks out three groups separated by slashes,\\nand is similar to splitting by an alternatives pattern:\\n\\n>>> match = re.match(\\'[/:](.*)[/:](.*)[/:](.*)\\', \\'/usr/home:lumberjack\\')\\n>>> match.groups()\\n(\\'usr\\', \\'home\\', \\'lumberjack\\')\\n\\n>>> re.split(\\'[/:]\\', \\'/usr/home/lumberjack\\')\\n[\\'\\', \\'usr\\', \\'home\\', \\'lumberjack\\']\\n\\nPattern matching is an advanced text-processing tool by itself, but there is also support\\nin Python for even more advanced text and language processing, including XML and\\nHTML parsing and natural language analysis. We’ll see additional brief examples of\\npatterns and XML parsing at the end of Chapter 37, but I’ve already said enough about\\nstrings for this tutorial, so let’s move on to the next type.\\n\\n108 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cLists\\nThe Python list object is the most general sequence provided by the language. Lists are\\npositionally ordered collections of arbitrarily typed objects, and they have no fixed size.\\nThey are also mutable—unlike strings, lists can be modified in place by assignment to\\noffsets as well as a variety of list method calls. Accordingly, they provide a very flexible\\ntool  for  representing  arbitrary  collections—lists  of  files  in  a  folder,  employees  in  a\\ncompany, emails in your inbox, and so on.\\n\\nSequence Operations\\nBecause they are sequences, lists support all the sequence operations we discussed for\\nstrings; the only difference is that the results are usually lists instead of strings. For\\ninstance, given a three-item list:\\n\\n>>> L = [123, \\'spam\\', 1.23]            # A list of three different-type objects\\n>>> len(L)                             # Number of items in the list\\n3\\n\\nwe can index, slice, and so on, just as for strings:\\n\\n>>> L[0]                               # Indexing by position\\n123\\n>>> L[:-1]                             # Slicing a list returns a new list\\n[123, \\'spam\\']\\n\\n>>> L + [4, 5, 6]                      # Concat/repeat make new lists too\\n[123, \\'spam\\', 1.23, 4, 5, 6]\\n>>> L * 2\\n[123, \\'spam\\', 1.23, 123, \\'spam\\', 1.23]\\n\\n>>> L                                  # We\\'re not changing the original list\\n[123, \\'spam\\', 1.23]\\n\\nType-Specific Operations\\nPython’s lists may be reminiscent of arrays in other languages, but they tend to be more\\npowerful. For one thing, they have no fixed type constraint—the list we just looked at,\\nfor example, contains three objects of completely different types (an integer, a string,\\nand a floating-point number). Further, lists have no fixed size. That is, they can grow\\nand shrink on demand, in response to list-specific operations:\\n\\n>>> L.append(\\'NI\\')                     # Growing: add object at end of list\\n>>> L\\n[123, \\'spam\\', 1.23, \\'NI\\']\\n\\n>>> L.pop(2)                           # Shrinking: delete an item in the middle\\n1.23\\n>>> L                                  # \"del L[2]\" deletes from a list too\\n[123, \\'spam\\', \\'NI\\']\\n\\nLists\\n\\n| 109\\n\\n\\x0cHere, the list append method expands the list’s size and inserts an item at the end; the\\npop method (or an equivalent del statement) then removes an item at a given offset,\\ncausing the list to shrink. Other list methods insert an item at an arbitrary position\\n(insert),  remove  a  given  item  by  value  (remove),  add  multiple  items  at  the  end\\n(extend), and so on. Because lists are mutable, most list methods also change the list\\nobject in place, instead of creating a new one:\\n\\n>>> M = [\\'bb\\', \\'aa\\', \\'cc\\']\\n>>> M.sort()\\n>>> M\\n[\\'aa\\', \\'bb\\', \\'cc\\']\\n>>> M.reverse()\\n>>> M\\n[\\'cc\\', \\'bb\\', \\'aa\\']\\n\\nThe list sort method here, for example, orders the list in ascending fashion by default,\\nand reverse reverses it—in both cases, the methods modify the list directly.\\n\\nBounds Checking\\nAlthough lists have no fixed size, Python still doesn’t allow us to reference items that\\nare not present. Indexing off the end of a list is always a mistake, but so is assigning off\\nthe end:\\n>>> L\\n[123, \\'spam\\', \\'NI\\']\\n\\n>>> L[99]\\n...error text omitted...\\nIndexError: list index out of range\\n\\n>>> L[99] = 1\\n...error text omitted...\\nIndexError: list assignment index out of range\\n\\nThis is intentional, as it’s usually an error to try to assign off the end of a list (and a\\nparticularly nasty one in the C language, which doesn’t do as much error checking as\\nPython). Rather than silently growing the list in response, Python reports an error. To\\ngrow a list, we call list methods such as append instead.\\n\\nNesting\\nOne nice feature of Python’s core data types is that they support arbitrary nesting—we\\ncan nest them in any combination, and as deeply as we like. For example, we can have\\na list that contains a dictionary, which contains another list, and so on. One immediate\\napplication of this feature is to represent matrixes, or “multidimensional arrays” in\\nPython. A list with nested lists will do the job for basic applications (you’ll get “...”\\ncontinuation-line prompts on lines 2 and 3 of the following in some interfaces, but not\\nin IDLE):\\n\\n110 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c>>> M = [[1, 2, 3],               # A 3 × 3 matrix, as nested lists\\n         [4, 5, 6],               # Code can span lines if bracketed\\n         [7, 8, 9]]\\n>>> M\\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\n\\nHere, we’ve coded a list that contains three other lists. The effect is to represent a\\n3 × 3 matrix of numbers. Such a structure can be accessed in a variety of ways:\\n\\n>>> M[1]                          # Get row 2\\n[4, 5, 6]\\n\\n>>> M[1][2]                       # Get row 2, then get item 3 within the row\\n6\\n\\nThe first operation here fetches the entire second row, and the second grabs the third\\nitem within that row (it runs left to right, like the earlier string strip and split). Stringing\\ntogether index operations takes us deeper and deeper into our nested-object structure.3\\n\\nComprehensions\\nIn addition to sequence operations and list methods, Python includes a more advanced\\noperation known as a list comprehension expression, which turns out to be a powerful\\nway to process structures like our matrix. Suppose, for instance, that we need to extract\\nthe second column of our sample matrix. It’s easy to grab rows by simple indexing\\nbecause the matrix is stored by rows, but it’s almost as easy to get a column with a list\\ncomprehension:\\n\\n>>> col2 = [row[1] for row in M]             # Collect the items in column 2\\n>>> col2\\n[2, 5, 8]\\n\\n>>> M                                        # The matrix is unchanged\\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\n\\nList comprehensions derive from set notation; they are a way to build a new list by\\nrunning an expression on each item in a sequence, one at a time, from left to right. List\\ncomprehensions are coded in square brackets (to tip you off to the fact that they make\\na list) and are composed of an expression and a looping construct that share a variable\\nname (row, here). The preceding list comprehension means basically what it says: “Give\\nme row[1] for each row in matrix M, in a new list.” The result is a new list containing\\ncolumn 2 of the matrix.\\nList comprehensions can be more complex in practice:\\n\\n3. This  matrix  structure  works  for  small-scale  tasks,  but  for  more  serious  number  crunching  you  will\\nprobably want to use one of the numeric extensions to Python, such as the open source NumPy and\\nSciPy systems. Such tools can store and process large matrixes much more efficiently than our nested list\\nstructure. NumPy has been said to turn Python into the equivalent of a free and more powerful version\\nof the Matlab system, and organizations such as NASA, Los Alamos, JPL, and many others use this tool\\nfor scientific and financial tasks. Search the Web for more details.\\n\\nLists\\n\\n| 111\\n\\n\\x0c>>> [row[1] + 1 for row in M]                 # Add 1 to each item in column 2\\n[3, 6, 9]\\n\\n>>> [row[1] for row in M if row[1] % 2 == 0]  # Filter out odd items\\n[2, 8]\\n\\nThe first operation here, for instance, adds 1 to each item as it is collected, and the\\nsecond uses an if clause to filter odd numbers out of the result using the % modulus\\nexpression (remainder of division). List comprehensions make new lists of results, but\\nthey can be used to iterate over any iterable object—a term we’ll flesh out later in this\\npreview. Here, for instance, we use list comprehensions to step over a hardcoded list\\nof coordinates and a string:\\n\\n>>> diag = [M[i][i] for i in [0, 1, 2]]      # Collect a diagonal from matrix\\n>>> diag\\n[1, 5, 9]\\n\\n>>> doubles = [c * 2 for c in \\'spam\\']        # Repeat characters in a string\\n>>> doubles\\n[\\'ss\\', \\'pp\\', \\'aa\\', \\'mm\\']\\n\\nThese expressions can also be used to collect multiple values, as long as we wrap those\\nvalues in a nested collection. The following illustrates using range—a built-in that gen-\\nerates successive integers, and requires a surrounding list to display all its values in\\n3.X only (2.X makes a physical list all at once):\\n\\n>>> list(range(4))                           # 0..3 (list() required in 3.X)\\n[0, 1, 2, 3]\\n>>> list(range(−6, 7, 2))                    # −6 to +6 by 2 (need list() in 3.X)\\n[−6, −4, −2, 0, 2, 4, 6]\\n\\n>>> [[x ** 2, x ** 3] for x in range(4)]     # Multiple values, \"if\" filters\\n[[0, 0], [1, 1], [4, 8], [9, 27]]\\n>>> [[x, x / 2, x * 2] for x in range(−6, 7, 2) if x > 0]\\n[[2, 1, 4], [4, 2, 8], [6, 3, 12]]\\n\\nAs you can probably tell, list comprehensions, and relatives like the map and filter\\nbuilt-in functions, are too involved to cover more formally in this preview chapter. The\\nmain point of this brief introduction is to illustrate that Python includes both simple\\nand advanced tools in its arsenal. List comprehensions are an optional feature, but they\\ntend  to  be  very  useful  in  practice  and  often  provide  a  substantial  processing  speed\\nadvantage. They also work on any type that is a sequence in Python, as well as some\\ntypes that are not. You’ll hear much more about them later in this book.\\nAs a preview, though, you’ll find that in recent Pythons, comprehension syntax has\\nbeen generalized for other roles: it’s not just for making lists today. For example, en-\\nclosing a comprehension in parentheses can also be used to create generators that pro-\\nduce results on demand. To illustrate, the sum built-in sums items in a sequence—in\\nthis example, summing all items in our matrix’s rows on request:\\n\\n>>> G = (sum(row) for row in M)              # Create a generator of row sums\\n>>> next(G)                                  # iter(G) not required here\\n\\n112 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c6\\n>>> next(G)                                  # Run the iteration protocol next()\\n15\\n>>> next(G)\\n24\\n\\nThe map built-in can do similar work, by generating the results of running items through\\na function, one at a time and on request. Like range, wrapping it in list forces it to\\nreturn all its values in Python 3.X; this isn’t needed in 2.X where map makes a list of\\nresults all at once instead, and is not needed in other contexts that iterate automatically,\\nunless multiple scans or list-like behavior is also required:\\n\\n>>> list(map(sum, M))                        # Map sum over items in M\\n[6, 15, 24]\\n\\nIn  Python  2.7  and  3.X,  comprehension  syntax  can  also  be  used  to  create  sets  and\\ndictionaries:\\n\\n>>> {sum(row) for row in M}                  # Create a set of row sums\\n{24, 6, 15}\\n\\n>>> {i : sum(M[i]) for i in range(3)}        # Creates key/value table of row sums\\n{0: 6, 1: 15, 2: 24}\\n\\nIn fact, lists, sets, dictionaries, and generators can all be built with comprehensions in\\n3.X and 2.7:\\n\\n>>> [ord(x) for x in \\'spaam\\']                # List of character ordinals\\n[115, 112, 97, 97, 109]\\n>>> {ord(x) for x in \\'spaam\\'}                # Sets remove duplicates\\n{112, 97, 115, 109}\\n>>> {x: ord(x) for x in \\'spaam\\'}             # Dictionary keys are unique\\n{\\'p\\': 112, \\'a\\': 97, \\'s\\': 115, \\'m\\': 109}\\n>>> (ord(x) for x in \\'spaam\\')                # Generator of values\\n<generator object <genexpr> at 0x000000000254DAB0>\\n\\nTo understand objects like generators, sets, and dictionaries, though, we must move \\nahead.\\n\\nDictionaries\\nPython dictionaries are something completely different (Monty Python reference in-\\ntended)—they are not sequences at all, but are instead known as mappings. Mappings\\nare also collections of other objects, but they store objects by key instead of by relative\\nposition. In fact, mappings don’t maintain any reliable left-to-right order; they simply\\nmap keys to associated values. Dictionaries, the only mapping type in Python’s core\\nobjects set, are also mutable: like lists, they may be changed in place and can grow and\\nshrink on demand. Also like lists, they are a flexible tool for representing collections,\\nbut their more mnemonic keys are better suited when a collection’s items are named or\\nlabeled—fields of a database record, for example.\\n\\nDictionaries\\n\\n| 113\\n\\n\\x0cMapping Operations\\nWhen written as literals, dictionaries are coded in curly braces and consist of a series\\nof “key: value” pairs. Dictionaries are useful anytime we need to associate a set of values\\nwith keys—to describe the properties of something, for instance. As an example, con-\\nsider the following three-item dictionary (with keys “food,” “quantity,” and “color,”\\nperhaps the details of a hypothetical menu item?):\\n\\n>>> D = {\\'food\\': \\'Spam\\', \\'quantity\\': 4, \\'color\\': \\'pink\\'}\\n\\nWe can index this dictionary by key to fetch and change the keys’ associated values.\\nThe dictionary index operation uses the same syntax as that used for sequences, but\\nthe item in the square brackets is a key, not a relative position:\\n\\n>>> D[\\'food\\']              # Fetch value of key \\'food\\'\\n\\'Spam\\'\\n\\n>>> D[\\'quantity\\'] += 1     # Add 1 to \\'quantity\\' value\\n>>> D\\n{\\'color\\': \\'pink\\', \\'food\\': \\'Spam\\', \\'quantity\\': 5}\\n\\nAlthough the curly-braces literal form does see use, it is perhaps more common to see\\ndictionaries built up in different ways (it’s rare to know all your program’s data before\\nyour program runs). The following code, for example, starts with an empty dictionary\\nand fills it out one key at a time. Unlike out-of-bounds assignments in lists, which are\\nforbidden, assignments to new dictionary keys create those keys:\\n\\n>>> D = {}\\n>>> D[\\'name\\'] = \\'Bob\\'      # Create keys by assignment\\n>>> D[\\'job\\']  = \\'dev\\'\\n>>> D[\\'age\\']  = 40\\n\\n>>> D\\n{\\'age\\': 40, \\'job\\': \\'dev\\', \\'name\\': \\'Bob\\'}\\n\\n>>> print(D[\\'name\\'])\\nBob\\n\\nHere, we’re effectively using dictionary keys as field names in a record that describes\\nsomeone. In other applications, dictionaries can also be used to replace searching op-\\nerations—indexing  a  dictionary  by  key  is  often  the  fastest  way  to  code  a  search  in\\nPython.\\nAs we’ll learn later, we can also make dictionaries by passing to the dict type name \\neither keyword arguments (a special name=value syntax in function calls), or the result\\nof zipping together sequences of keys and values obtained at runtime (e.g., from files).\\nBoth the following make the same dictionary as the prior example and its equivalent\\n{} literal form, though the first tends to make for less typing:\\n\\n>>> bob1 = dict(name=\\'Bob\\', job=\\'dev\\', age=40)                      # Keywords\\n>>> bob1\\n{\\'age\\': 40, \\'name\\': \\'Bob\\', \\'job\\': \\'dev\\'}\\n\\n114 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c>>> bob2 = dict(zip([\\'name\\', \\'job\\', \\'age\\'], [\\'Bob\\', \\'dev\\', 40]))    # Zipping\\n>>> bob2\\n{\\'job\\': \\'dev\\', \\'name\\': \\'Bob\\', \\'age\\': 40}\\n\\nNotice how the left-to-right order of dictionary keys is scrambled. Mappings are not\\npositionally ordered, so unless you’re lucky, they’ll come back in a different order than\\nyou typed them. The exact order may vary per Python, but you shouldn’t depend on\\nit, and shouldn’t expect yours to match that in this book.\\n\\nNesting Revisited\\nIn the prior example, we used a dictionary to describe a hypothetical person, with three\\nkeys.  Suppose,  though,  that  the  information  is  more  complex.  Perhaps  we  need  to\\nrecord a first name and a last name, along with multiple job titles. This leads to another\\napplication of Python’s object nesting in action. The following dictionary, coded all at\\nonce as a literal, captures more structured information:\\n>>> rec = {\\'name\\': {\\'first\\': \\'Bob\\', \\'last\\': \\'Smith\\'},\\n           \\'jobs\\': [\\'dev\\', \\'mgr\\'],\\n           \\'age\\':  40.5}\\n\\nHere, we again have a three-key dictionary at the top (keys “name,” “jobs,” and “age”),\\nbut the values have become more complex: a nested dictionary for the name to support\\nmultiple parts, and a nested list for the jobs to support multiple roles and future ex-\\npansion. We can access the components of this structure much as we did for our list-\\nbased matrix earlier, but this time most indexes are dictionary keys, not list offsets:\\n\\n>>> rec[\\'name\\']                         # \\'name\\' is a nested dictionary\\n{\\'last\\': \\'Smith\\', \\'first\\': \\'Bob\\'}\\n\\n>>> rec[\\'name\\'][\\'last\\']                 # Index the nested dictionary\\n\\'Smith\\'\\n\\n>>> rec[\\'jobs\\']                         # \\'jobs\\' is a nested list\\n[\\'dev\\', \\'mgr\\']\\n>>> rec[\\'jobs\\'][-1]                     # Index the nested list\\n\\'mgr\\'\\n\\n>>> rec[\\'jobs\\'].append(\\'janitor\\')       # Expand Bob\\'s job description in place\\n>>> rec\\n{\\'age\\': 40.5, \\'jobs\\': [\\'dev\\', \\'mgr\\', \\'janitor\\'], \\'name\\': {\\'last\\': \\'Smith\\',\\n\\'first\\': \\'Bob\\'}}\\n\\nNotice how the last operation here expands the nested jobs list—because the jobs list\\nis a separate piece of memory from the dictionary that contains it, it can grow and shrink\\nfreely (object memory layout will be discussed further later in this book).\\nThe  real  reason  for  showing  you  this  example  is  to  demonstrate  the  flexibility  of\\nPython’s core data types. As you can see, nesting allows us to build up complex infor-\\nmation structures directly and easily. Building a similar structure in a low-level language\\nlike C would be tedious and require much more code: we would have to lay out and\\n\\nDictionaries\\n\\n| 115\\n\\n\\x0cdeclare structures and arrays, fill out values, link everything together, and so on. In\\nPython, this is all automatic—running the expression creates the entire nested object\\nstructure for us. In fact, this is one of the main benefits of scripting languages like\\nPython.\\nJust as importantly, in a lower-level language we would have to be careful to clean up\\nall of the object’s space when we no longer need it. In Python, when we lose the last\\nreference to the object—by assigning its variable to something else, for example—all\\nof the memory space occupied by that object’s structure is automatically cleaned up\\nfor us:\\n\\n>>> rec = 0                             # Now the object\\'s space is reclaimed\\n\\nTechnically speaking, Python has a feature known as garbage collection that cleans up\\nunused memory as your program runs and frees you from having to manage such details\\nin your code. In standard Python (a.k.a. CPython), the space is reclaimed immediately,\\nas soon as the last reference to an object is removed. We’ll study how this works later\\nin Chapter 6; for now, it’s enough to know that you can use objects freely, without\\nworrying about creating their space or cleaning up as you go.\\nAlso watch for a record structure similar to the one we just coded in Chapter 8, Chap-\\nter 9, and Chapter 27, where we’ll use it to compare and contrast lists, dictionaries,\\ntuples, named tuples, and classes—an array of data structure options with tradeoffs\\nwe’ll cover in full later.4\\n\\nMissing Keys: if Tests\\nAs mappings, dictionaries support accessing items by key only, with the sorts of oper-\\nations we’ve just seen. In addition, though, they also support type-specific operations\\nwith method calls that are useful in a variety of common use cases. For example, al-\\nthough we can assign to a new key to expand a dictionary, fetching a nonexistent key\\nis still a mistake:\\n\\n>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> D\\n\\n4. Two application notes here. First, as a preview, the rec record we just created really could be an actual\\ndatabase record, when we employ Python’s object persistence system—an easy way to store native Python\\nobjects in simple files or access-by-key databases, which translates objects to and from serial byte streams\\nautomatically.  We  won’t  go  into  details  here,  but  watch  for  coverage  of  Python’s  pickle  and  shelve\\npersistence modules in Chapter 9, Chapter 28, Chapter 31, and Chapter 37, where we’ll explore them in\\nthe context of files, an OOP use case, classes, and 3.X changes, respectively.\\n\\nSecond,  if  you  are  familiar  with  JSON  (JavaScript  Object  Notation)—an  emerging  data-interchange\\nformat used for databases and network transfers—this example may also look curiously similar, though\\nPython’s support for variables, arbitrary expressions, and changes can make its data structures more\\ngeneral. Python’s json library module supports creating and parsing JSON text, but the translation to\\nPython objects is often trivial. Watch for a JSON example that uses this record in Chapter 9 when we\\nstudy files. For a larger use case, see MongoDB, which stores data using a language-neutral binary-encoded\\nserialization of JSON-like documents, and its PyMongo interface.\\n\\n116 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c{\\'a\\': 1, \\'c\\': 3, \\'b\\': 2}\\n\\n>>> D[\\'e\\'] = 99                      # Assigning new keys grows dictionaries\\n>>> D\\n{\\'a\\': 1, \\'c\\': 3, \\'b\\': 2, \\'e\\': 99}\\n\\n>>> D[\\'f\\']                           # Referencing a nonexistent key is an error\\n...error text omitted...\\nKeyError: \\'f\\'\\n\\nThis is what we want—it’s usually a programming error to fetch something that isn’t\\nreally there. But in some generic programs, we can’t always know what keys will be\\npresent when we write our code. How do we handle such cases and avoid errors? One\\nsolution is to test ahead of time. The dictionary in membership expression allows us\\nto query the existence of a key and branch on the result with a Python if statement. In\\nthe following, be sure to press Enter twice to run the if interactively after typing its\\ncode (as explained in Chapter 3, an empty line means “go” at the interactive prompt),\\nand just as for the earlier multiline dictionaries and lists, the prompt changes to “...”\\non some interfaces for lines two and beyond:\\n\\n>>> \\'f\\' in D\\nFalse\\n\\n>>> if not \\'f\\' in D:                           # Python\\'s sole selection statement\\n       print(\\'missing\\')\\n\\nmissing\\n\\nThis book has more to say about the if statement in later chapters, but the form we’re\\nusing here is straightforward: it consists of the word if, followed by an expression that\\nis interpreted as a true or false result, followed by a block of code to run if the test is\\ntrue. In its full form, the if statement can also have an else clause for a default case,\\nand one or more elif (“else if”) clauses for other tests. It’s the main selection statement\\ntool in Python; along with both its ternary if/else expression cousin (which we’ll meet\\nin a moment) and the if comprehension filter lookalike we saw earlier, it’s the way we\\ncode the logic of choices and decisions in our scripts.\\nIf you’ve used some other programming languages in the past, you might be wondering\\nhow Python knows when the if statement ends. I’ll explain Python’s syntax rules in\\ndepth in later chapters, but in short, if you have more than one action to run in a\\nstatement block, you simply indent all their statements the same way—this both pro-\\nmotes readable code and reduces the number of characters you have to type:\\n\\n>>> if not \\'f\\' in D:\\n        print(\\'missing\\')\\n        print(\\'no, really...\\')                 # Statement blocks are indented\\n\\nmissing\\nno, really...\\n\\nDictionaries\\n\\n| 117\\n\\n\\x0cBesides the in test, there are a variety of ways to avoid accessing nonexistent keys in\\nthe dictionaries we create: the get method, a conditional index with a default; the \\nPython 2.X has_key method, an in work-alike that is no longer available in 3.X; the\\ntry statement, a tool we’ll first meet in Chapter 10 that catches and recovers from\\nexceptions altogether; and the if/else ternary (three-part) expression, which is essen-\\ntially an if statement squeezed onto a single line. Here are a few examples:\\n\\n>>> value = D.get(\\'x\\', 0)                      # Index but with a default\\n>>> value\\n0\\n>>> value = D[\\'x\\'] if \\'x\\' in D else 0          # if/else expression form\\n>>> value\\n0\\n\\nWe’ll save the details on such alternatives until a later chapter. For now, let’s turn to\\nanother dictionary method’s role in a common use case.\\n\\nSorting Keys: for Loops\\nAs mentioned earlier, because dictionaries are not sequences, they don’t maintain any\\ndependable left-to-right order. If we make a dictionary and print it back, its keys may\\ncome back in a different order than that in which we typed them, and may vary per\\nPython version and other variables:\\n>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> D\\n{\\'a\\': 1, \\'c\\': 3, \\'b\\': 2}\\n\\nWhat do we do, though, if we do need to impose an ordering on a dictionary’s items?\\nOne common solution is to grab a list of keys with the dictionary keys method, sort\\nthat with the list sort method, and then step through the result with a Python for loop\\n(as for if, be sure to press the Enter key twice after coding the following for loop, and\\nomit the outer parenthesis in the print in Python 2.X):\\n\\n>>> Ks = list(D.keys())                # Unordered keys list\\n>>> Ks                                 # A list in 2.X, \"view\" in 3.X: use list()\\n[\\'a\\', \\'c\\', \\'b\\']\\n\\n>>> Ks.sort()                          # Sorted keys list\\n>>> Ks\\n[\\'a\\', \\'b\\', \\'c\\']\\n\\n>>> for key in Ks:                     # Iterate though sorted keys\\n        print(key, \\'=>\\', D[key])       # <== press Enter twice here (3.X print)\\n\\na => 1\\nb => 2\\nc => 3\\n\\nThis is a three-step process, although, as we’ll see in later chapters, in recent versions\\nof  Python  it  can  be  done  in  one  step  with  the  newer  sorted  built-in  function.  The\\n\\n118 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0csorted call returns the result and sorts a variety of object types, in this case sorting\\ndictionary keys automatically:\\n\\n>>> D\\n{\\'a\\': 1, \\'c\\': 3, \\'b\\': 2}\\n\\n>>> for key in sorted(D):\\n        print(key, \\'=>\\', D[key])\\n\\na => 1\\nb => 2\\nc => 3\\n\\nBesides showcasing dictionaries, this use case serves to introduce the Python for loop.\\nThe for loop is a simple and efficient way to step through all the items in a sequence\\nand run a block of code for each item in turn. A user-defined loop variable (key, here)\\nis used to reference the current item each time through. The net effect in our example\\nis to print the unordered dictionary’s keys and values, in sorted-key order.\\nThe for loop, and its more general colleague the while loop, are the main ways we code\\nrepetitive tasks as statements in our scripts. Really, though, the for loop, like its relative\\nthe list comprehension introduced earlier, is a sequence operation. It works on any\\nobject that is a sequence and, like the list comprehension, even on some things that are\\nnot. Here, for example, it is stepping across the characters in a string, printing the\\nuppercase version of each as it goes:\\n\\n>>> for c in \\'spam\\':\\n        print(c.upper())\\n\\nS\\nP\\nA\\nM\\n\\nPython’s while loop is a more general sort of looping tool; it’s not limited to stepping\\nacross sequences, but generally requires more code to do so:\\n\\n>>> x = 4\\n>>> while x > 0:\\n        print(\\'spam!\\' * x)\\n        x -= 1\\n\\nspam!spam!spam!spam!\\nspam!spam!spam!\\nspam!spam!\\nspam!\\n\\nWe’ll discuss looping statements, syntax, and tools in depth later in the book. First,\\nthough, I need to confess that this section has not been as forthcoming as it might have\\nbeen. Really, the for loop, and all its cohorts that step through objects from left to right,\\nare not just sequence operations, they are iterable operations—as the next section de-\\nscribes.\\n\\nDictionaries\\n\\n| 119\\n\\n\\x0cIteration and Optimization\\nIf the last section’s for loop looks like the list comprehension expression introduced\\nearlier, it should: both are really general iteration tools. In fact, both will work on any\\niterable object that follows the iteration protocol—pervasive ideas in Python that un-\\nderlie all its iteration tools.\\nIn a nutshell, an object is iterable if it is either a physically stored sequence in memory,\\nor an object that generates one item at a time in the context of an iteration operation\\n—a sort of “virtual” sequence. More formally, both types of objects are considered\\niterable because they support the iteration protocol—they respond to the iter call with\\nan object that advances in response to next calls and raises an exception when finished\\nproducing values.\\nThe generator comprehension expression we saw earlier is such an object: its values\\naren’t stored in memory all at once, but are produced as requested, usually by iteration\\ntools. Python file objects similarly iterate line by line when used by an iteration tool:\\nfile content isn’t in a list, it’s fetched on demand. Both are iterable objects in Python—\\na category that expands in 3.X to include core tools like range and map.\\nI’ll have more to say about the iteration protocol later in this book. For now, keep in\\nmind that every Python tool that scans an object from left to right uses the iteration\\nprotocol. This is why the sorted call used in the prior section works on the dictionary\\ndirectly—we don’t have to call the keys method to get a sequence because dictionaries\\nare iterable objects, with a next that returns successive keys.\\nIt may also help you to see that any list comprehension expression, such as this one,\\nwhich computes the squares of a list of numbers:\\n>>> squares = [x ** 2 for x in [1, 2, 3, 4, 5]]\\n>>> squares\\n[1, 4, 9, 16, 25]\\n\\ncan always be coded as an equivalent for loop that builds the result list manually by\\nappending as it goes:\\n\\n>>> squares = []\\n>>> for x in [1, 2, 3, 4, 5]:          # This is what a list comprehension does\\n        squares.append(x ** 2)         # Both run the iteration protocol internally\\n\\n>>> squares\\n[1, 4, 9, 16, 25]\\n\\nBoth tools leverage the iteration protocol internally and produce the same result. The\\nlist comprehension, though, and related functional programming tools like map and\\nfilter, will often run faster than a for loop today on some types of code (perhaps even\\ntwice as fast)—a property that could matter in your programs for large data sets. Having\\nsaid that, though, I should point out that performance measures are tricky business in\\nPython because it optimizes so much, and they may vary from release to release.\\n\\n120 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cA major rule of thumb in Python is to code for simplicity and readability first and worry\\nabout performance later, after your program is working, and after you’ve proved that\\nthere is a genuine performance concern. More often than not, your code will be quick\\nenough as it is. If you do need to tweak code for performance, though, Python includes\\ntools to help you out, including the time and timeit modules for timing the speed of\\nalternatives, and the profile module for isolating bottlenecks.\\nYou’ll find more on these later in this book (see especially Chapter 21’s benchmarking\\ncase study) and in the Python manuals. For the sake of this preview, let’s move ahead\\nto the next core data type.\\n\\nTuples\\nThe tuple object (pronounced “toople” or “tuhple,” depending on whom you ask) is\\nroughly like a list that cannot be changed—tuples are sequences, like lists, but they are\\nimmutable,  like  strings.  Functionally,  they’re  used  to  represent  fixed  collections  of\\nitems: the components of a specific calendar date, for instance. Syntactically, they are\\nnormally coded in parentheses instead of square brackets, and they support arbitrary\\ntypes, arbitrary nesting, and the usual sequence operations:\\n\\n>>> T = (1, 2, 3, 4)            # A 4-item tuple\\n>>> len(T)                      # Length\\n4\\n\\n>> T + (5, 6)                   # Concatenation\\n(1, 2, 3, 4, 5, 6)\\n\\n>>> T[0]                        # Indexing, slicing, and more\\n1\\n\\nTuples also have type-specific callable methods as of Python 2.6 and 3.0, but not nearly\\nas many as lists:\\n\\n>>> T.index(4)                  # Tuple methods: 4 appears at offset 3\\n3\\n>>> T.count(4)                  # 4 appears once\\n1\\n\\nThe primary distinction for tuples is that they cannot be changed once created. That\\nis, they are immutable sequences (one-item tuples like the one here require a trailing\\ncomma):\\n\\n>>> T[0] = 2                    # Tuples are immutable\\n...error text omitted...\\nTypeError: \\'tuple\\' object does not support item assignment\\n\\n>>> T = (2,) + T[1:]            # Make a new tuple for a new value\\n>>> T\\n(2, 2, 3, 4)\\n\\nTuples\\n\\n| 121\\n\\n\\x0cLike lists and dictionaries, tuples support mixed types and nesting, but they don’t grow\\nand shrink because they are immutable (the parentheses enclosing a tuple’s items can\\nusually be omitted, as done here):\\n\\n>>> T = \\'spam\\', 3.0, [11, 22, 33]\\n>>> T[1]\\n3.0\\n>>> T[2][1]\\n22\\n>>> T.append(4)\\nAttributeError: \\'tuple\\' object has no attribute \\'append\\'\\n\\nWhy Tuples?\\nSo, why have a type that is like a list, but supports fewer operations? Frankly, tuples\\nare not generally used as often as lists in practice, but their immutability is the whole\\npoint. If you pass a collection of objects around your program as a list, it can be changed\\nanywhere; if you use a tuple, it cannot. That is, tuples provide a sort of integrity con-\\nstraint that is convenient in programs larger than those we’ll write here. We’ll talk more\\nabout tuples later in the book, including an extension that builds upon them called\\nnamed tuples. For now, though, let’s jump ahead to our last major core type: the file.\\n\\nFiles\\nFile objects are Python code’s main interface to external files on your computer. They\\ncan be used to read and write text memos, audio clips, Excel documents, saved email\\nmessages, and whatever else you happen to have stored on your machine. Files are a\\ncore type, but they’re something of an oddball—there is no specific literal syntax for\\ncreating them. Rather, to create a file object, you call the built-in open function, passing\\nin an external filename and an optional processing mode as strings.\\nFor example, to create a text output file, you would pass in its name and the \\'w\\' pro-\\ncessing mode string to write data:\\n\\n>>> f = open(\\'data.txt\\', \\'w\\')      # Make a new file in output mode (\\'w\\' is write)\\n>>> f.write(\\'Hello\\\\n\\')             # Write strings of characters to it\\n6\\n>>> f.write(\\'world\\\\n\\')             # Return number of items written in Python 3.X\\n6\\n>>> f.close()                      # Close to flush output buffers to disk\\n\\nThis creates a file in the current directory and writes text to it (the filename can be a\\nfull directory path if you need to access a file elsewhere on your computer). To read\\nback what you just wrote, reopen the file in \\'r\\' processing mode, for reading text input\\n—this is the default if you omit the mode in the call. Then read the file’s content into\\na string, and display it. A file’s contents are always a string in your script, regardless of\\nthe type of data the file contains:\\n\\n122 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c>>> f = open(\\'data.txt\\')           # \\'r\\' (read) is the default processing mode\\n>>> text = f.read()                # Read entire file into a string\\n>>> text\\n\\'Hello\\\\nworld\\\\n\\'\\n\\n>>> print(text)                    # print interprets control characters\\nHello\\nworld\\n\\n>>> text.split()                   # File content is always a string\\n[\\'Hello\\', \\'world\\']\\n\\nOther file object methods support additional features we don’t have time to cover here.\\nFor instance, file objects provide more ways of reading and writing (read accepts an\\noptional maximum byte/character size, readline reads one line at a time, and so on),\\nas well as other tools (seek moves to a new file position). As we’ll see later, though, the\\nbest way to read a file today is to not read it at all—files provide an iterator that auto-\\nmatically reads line by line in for loops and other contexts:\\n\\n>>> for line in open(\\'data.txt\\'): print(line)\\n\\nWe’ll meet the full set of file methods later in this book, but if you want a quick preview\\nnow, run a dir call on any open file and a help on any of the method names that come\\nback:\\n\\n>>> dir(f)\\n[ ...many names omitted...\\n\\'buffer\\', \\'close\\', \\'closed\\', \\'detach\\', \\'encoding\\', \\'errors\\', \\'fileno\\', \\'flush\\',\\n\\'isatty\\', \\'line_buffering\\', \\'mode\\', \\'name\\', \\'newlines\\', \\'read\\', \\'readable\\',\\n\\'readline\\', \\'readlines\\', \\'seek\\', \\'seekable\\', \\'tell\\', \\'truncate\\', \\'writable\\',\\n\\'write\\', \\'writelines\\']\\n\\n>>>help(f.seek)\\n...try it and see...\\n\\nBinary Bytes Files\\nThe prior section’s examples illustrate file basics that suffice for many roles. Techni-\\ncally, though, they rely on either the platform’s Unicode encoding default in Python\\n3.X, or the 8-bit byte nature of files in Python 2.X. Text files always encode strings in\\n3.X, and blindly write string content in 2.X. This is irrelevant for the simple ASCII data\\nused previously, which maps to and from file bytes unchanged. But for richer types of\\ndata, file interfaces can vary depending on both content and the Python line you use.\\nAs hinted when we met strings earlier, Python 3.X draws a sharp distinction between\\ntext and binary data in files: text files represent content as normal str strings and per-\\nform Unicode encoding and decoding automatically when writing and reading data,\\nwhile binary files represent content as a special bytes string and allow you to access file\\ncontent unaltered. Python 2.X supports the same dichotomy, but doesn’t impose it as\\nrigidly, and its tools differ.\\n\\nFiles\\n\\n| 123\\n\\n\\x0cFor example, binary files are useful for processing media, accessing data created by C\\nprograms, and so on. To illustrate, Python’s struct module can both create and unpack\\npacked binary data—raw bytes that record values that are not Python objects—to be\\nwritten to a file in binary mode. We’ll study this technique in detail later in the book,\\nbut the concept is simple: the following creates a binary file in Python 3.X (binary files\\nwork the same in 2.X, but the “b” string literal prefix isn’t required and won’t be dis-\\nplayed):\\n\\n>>> import struct\\n>>> packed = struct.pack(\\'>i4sh\\', 7, b\\'spam\\', 8)     # Create packed binary data\\n>>> packed                                           # 10 bytes, not objects or text\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>>\\n>>> file = open(\\'data.bin\\', \\'wb\\')                    # Open binary output file\\n>>> file.write(packed)                               # Write packed binary data\\n10\\n>>> file.close()\\n\\nReading binary data back is essentially symmetric; not all programs need to tread so\\ndeeply into the low-level realm of bytes, but binary files make this easy in Python:\\n\\n>>> data = open(\\'data.bin\\', \\'rb\\').read()              # Open/read binary data file\\n>>> data                                              # 10 bytes, unaltered\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>> data[4:8]                                         # Slice bytes in the middle\\nb\\'spam\\'\\n>>> list(data)                                        # A sequence of 8-bit bytes\\n[0, 0, 0, 7, 115, 112, 97, 109, 0, 8]\\n>>> struct.unpack(\\'>i4sh\\', data)                      # Unpack into objects again\\n(7, b\\'spam\\', 8)\\n\\nUnicode Text Files\\nText files are used to process all sorts of text-based data, from memos to email content\\nto JSON and XML documents. In today’s broader interconnected world, though, we\\ncan’t really talk about text without also asking “what kind?”—you must also know the\\ntext’s Unicode encoding type if either it differs from your platform’s default, or you\\ncan’t rely on that default for data portability reasons.\\nLuckily, this is easier than it may sound. To access files containing non-ASCII Unicode\\ntext of the sort introduced earlier in this chapter, we simply pass in an encoding name\\nif the text in the file doesn’t match the default encoding for our platform. In this mode,\\nPython text files automatically encode on writes and decode on reads per the encoding\\nscheme name you provide. In Python 3.X:\\n\\n>>> S = \\'sp\\\\xc4m\\'                                          # Non-ASCII Unicode text\\n>>> S\\n\\'spÄm\\'\\n>>> S[2]                                                   # Sequence of characters\\n\\'Ä\\'\\n\\n>>> file = open(\\'unidata.txt\\', \\'w\\', encoding=\\'utf-8\\')      # Write/encode UTF-8 text\\n\\n124 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c>>> file.write(S)                                          # 4 characters written\\n4\\n>>> file.close()\\n\\n>>> text = open(\\'unidata.txt\\', encoding=\\'utf-8\\').read()    # Read/decode UTF-8 text\\n>>> text\\n\\'spÄm\\'\\n>>> len(text)                                              # 4 chars (code points)\\n4\\n\\nThis automatic encoding and decoding is what you normally want. Because files handle\\nthis  on  transfers,  you  may  process  text  in  memory  as  a  simple  string  of  characters\\nwithout concern for its Unicode-encoded origins. If needed, though, you can also see\\nwhat’s truly stored in your file by stepping into binary mode:\\n\\n>>> raw = open(\\'unidata.txt\\', \\'rb\\').read()                 # Read raw encoded bytes\\n>>> raw\\nb\\'sp\\\\xc3\\\\x84m\\'\\n>>> len(raw)                                               # Really 5 bytes in UTF-8\\n5\\n\\nYou can also encode and decode manually if you get Unicode data from a source other\\nthan a file—parsed from an email message or fetched over a network connection, for\\nexample:\\n\\n>>> text.encode(\\'utf-8\\')                                   # Manual encode to bytes\\nb\\'sp\\\\xc3\\\\x84m\\'\\n>>> raw.decode(\\'utf-8\\')                                    # Manual decode to str\\n\\'spÄm\\'\\n\\nThis is also useful to see how text files would automatically encode the same string\\ndifferently under different encoding names, and provides a way to translate data to\\ndifferent  encodings—it’s  different  bytes  in  files,  but  decodes  to  the  same  string  in\\nmemory if you provide the proper encoding name:\\n\\n>>> text.encode(\\'latin-1\\')                                 # Bytes differ in others\\nb\\'sp\\\\xc4m\\'\\n>>> text.encode(\\'utf-16\\')\\nb\\'\\\\xff\\\\xfes\\\\x00p\\\\x00\\\\xc4\\\\x00m\\\\x00\\'\\n\\n>>> len(text.encode(\\'latin-1\\')), len(text.encode(\\'utf-16\\'))\\n(4, 10)\\n\\n>>> b\\'\\\\xff\\\\xfes\\\\x00p\\\\x00\\\\xc4\\\\x00m\\\\x00\\'.decode(\\'utf-16\\')    # But same string decoded\\n\\'spÄm\\'\\n\\nThis all works more or less the same in Python 2.X, but Unicode strings are coded and\\ndisplay with a leading “u,” byte strings don’t require or show a leading “b,” and Unicode\\ntext files must be opened with codecs.open, which accepts an encoding name just like\\n3.X’s open, and uses the special unicode string to represent content in memory. Binary\\nfile mode may seem optional in 2.X since normal files are just byte-based data, but it’s\\nrequired to avoid changing line ends if present (more on this later in the book):\\n\\nFiles\\n\\n| 125\\n\\n\\x0c>>> import codecs\\n>>> codecs.open(\\'unidata.txt\\', encoding=\\'utf8\\').read()     # 2.X: read/decode text\\nu\\'sp\\\\xc4m\\'\\n>>> open(\\'unidata.txt\\', \\'rb\\').read()                       # 2.X: read raw bytes\\n\\'sp\\\\xc3\\\\x84m\\'\\n>>> open(\\'unidata.txt\\').read()                             # 2.X: raw/undecoded too\\n\\'sp\\\\xc3\\\\x84m\\'\\n\\nAlthough you won’t generally need to care about this distinction if you deal only with\\nASCII text, Python’s strings and files are an asset if you deal with either binary data\\n(which includes most types of media) or text in internationalized character sets (which\\nincludes most content on the Web and Internet at large today). Python also supports\\nnon-ASCII file names (not just content), but it’s largely automatic; tools such as walkers\\nand listers offer more control when needed, though we’ll defer further details until\\nChapter 37.\\n\\nOther File-Like Tools\\nThe open function is the workhorse for most file processing you will do in Python. For\\nmore  advanced  tasks,  though,  Python  comes  with  additional  file-like  tools:  pipes,\\nFIFOs, sockets, keyed-access files, persistent object shelves, descriptor-based files, re-\\nlational  and  object-oriented  database  interfaces,  and  more.  Descriptor  files,  for  in-\\nstance, support file locking and other low-level tools, and sockets provide an interface\\nfor networking and interprocess communication. We won’t cover many of these topics\\nin this book, but you’ll find them useful once you start programming Python in earnest.\\n\\nOther Core Types\\nBeyond the core types we’ve seen so far, there are others that may or may not qualify\\nfor membership in the category, depending on how broadly it is defined. Sets, for ex-\\nample, are a recent addition to the language that are neither mappings nor sequences;\\nrather, they are unordered collections of unique and immutable objects. You create sets\\nby calling the built-in set function or using new set literals and expressions in 3.X and\\n2.7, and they support the usual mathematical set operations (the choice of new {...}\\nsyntax for set literals makes sense, since sets are much like the keys of a valueless dic-\\ntionary):\\n\\n>>> X = set(\\'spam\\')                 # Make a set out of a sequence in 2.X and 3.X\\n>>> Y = {\\'h\\', \\'a\\', \\'m\\'}             # Make a set with set literals in 3.X and 2.7\\n\\n>>> X, Y                            # A tuple of two sets without parentheses\\n({\\'m\\', \\'a\\', \\'p\\', \\'s\\'}, {\\'m\\', \\'a\\', \\'h\\'})\\n\\n>>> X & Y                           # Intersection\\n{\\'m\\', \\'a\\'}\\n>>> X | Y                           # Union\\n{\\'m\\', \\'h\\', \\'a\\', \\'p\\', \\'s\\'}\\n>>> X - Y                           # Difference\\n\\n126 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0c{\\'p\\', \\'s\\'}\\n>>> X > Y                           # Superset\\nFalse\\n\\n>>> {n ** 2 for n in [1, 2, 3, 4]}  # Set comprehensions in 3.X and 2.7\\n{16, 1, 4, 9}\\n\\nEven less mathematically inclined programmers often find sets useful for common tasks\\nsuch  as  filtering  out  duplicates,  isolating  differences,  and  performing  order-neutral\\nequality tests without sorting—in lists, strings, and all other iterable objects:\\n\\n>>> list(set([1, 2, 1, 3, 1]))      # Filtering out duplicates (possibly reordered)\\n[1, 2, 3]\\n>>> set(\\'spam\\') - set(\\'ham\\')        # Finding differences in collections\\n{\\'p\\', \\'s\\'}\\n>>> set(\\'spam\\') == set(\\'asmp\\')      # Order-neutral equality tests (== is False)\\nTrue\\n\\nSets also support in membership tests, though all other collection types in Python do\\ntoo:\\n\\n>>> \\'p\\' in set(\\'spam\\'), \\'p\\' in \\'spam\\', \\'ham\\' in [\\'eggs\\', \\'spam\\', \\'ham\\']\\n(True, True, True)\\n\\nIn addition, Python recently grew a few new numeric types: decimal numbers, which\\nare fixed-precision floating-point numbers, and fraction numbers, which are rational\\nnumbers with both a numerator and a denominator. Both can be used to work around\\nthe limitations and inherent inaccuracies of floating-point math:\\n\\n>>> 1 / 3                           # Floating-point (add a .0 in Python 2.X)\\n0.3333333333333333\\n>>> (2/3) + (1/2)\\n1.1666666666666665\\n\\n>>> import decimal                  # Decimals: fixed precision\\n>>> d = decimal.Decimal(\\'3.141\\')\\n>>> d + 1\\nDecimal(\\'4.141\\')\\n\\n>>> decimal.getcontext().prec = 2\\n>>> decimal.Decimal(\\'1.00\\') / decimal.Decimal(\\'3.00\\')\\nDecimal(\\'0.33\\')\\n\\n>>> from fractions import Fraction  # Fractions: numerator+denominator\\n>>> f = Fraction(2, 3)\\n>>> f + 1\\nFraction(5, 3)\\n>>> f + Fraction(1, 2)\\nFraction(7, 6)\\n\\nPython also comes with Booleans (with predefined True and False objects that are es-\\nsentially just the integers 1 and 0 with custom display logic), and it has long supported\\na special placeholder object called None commonly used to initialize names and objects:\\n\\nOther Core Types\\n\\n| 127\\n\\n\\x0c>>> 1 > 2, 1 < 2                    # Booleans\\n(False, True)\\n>>> bool(\\'spam\\')                    # Object\\'s Boolean value\\nTrue\\n\\n>>> X = None                        # None placeholder\\n>>> print(X)\\nNone\\n>>> L = [None] * 100                # Initialize a list of 100 Nones\\n>>> L\\n[None, None, None, None, None, None, None, None, None, None, None, None,\\nNone, None, None, None, None, None, None, None, ...a list of 100 Nones...]\\n\\nHow to Break Your Code’s Flexibility\\nI’ll have more to say about all of Python’s object types later, but one merits special\\ntreatment here. The type object, returned by the type built-in function, is an object that\\ngives the type of another object; its result differs slightly in 3.X, because types have\\nmerged with classes completely (something we’ll explore in the context of “new-style”\\nclasses in Part VI). Assuming L is still the list of the prior section:\\n\\n# In Python 2.X:\\n>>> type(L)                         # Types: type of L is list type object\\n<type \\'list\\'>\\n>>> type(type(L))                   # Even types are objects\\n<type \\'type\\'>\\n\\n# In Python 3.X:\\n>>> type(L)                         # 3.X: types are classes, and vice versa\\n<class \\'list\\'>\\n>>> type(type(L))                   # See Chapter 32 for more on class types\\n<class \\'type\\'>\\n\\nBesides allowing you to explore your objects interactively, the type object in its most\\npractical application allows code to check the types of the objects it processes. In fact,\\nthere are at least three ways to do so in a Python script:\\n\\n>>> if type(L) == type([]):         # Type testing, if you must...\\n        print(\\'yes\\')\\n\\nyes\\n>>> if type(L) == list:             # Using the type name\\n        print(\\'yes\\')\\n\\nyes\\n>>> if isinstance(L, list):         # Object-oriented tests\\n        print(\\'yes\\')\\n\\nyes\\n\\nNow that I’ve shown you all these ways to do type testing, however, I am required by\\nlaw to tell you that doing so is almost always the wrong thing to do in a Python program\\n(and often a sign of an ex-C programmer first starting to use Python!). The reason why\\n\\n128 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cwon’t become completely clear until later in the book, when we start writing larger\\ncode units such as functions, but it’s a (perhaps the) core Python concept. By checking\\nfor  specific  types  in  your  code,  you  effectively  break  its  flexibility—you  limit  it  to\\nworking on just one type. Without such tests, your code may be able to work on a\\nwhole range of types.\\nThis  is  related  to  the  idea  of  polymorphism  mentioned  earlier,  and  it  stems  from\\nPython’s lack of type declarations. As you’ll learn, in Python, we code to object inter-\\nfaces (operations supported), not to types. That is, we care what an object does, not\\nwhat it is. Not caring about specific types means that code is automatically applicable\\nto many of them—any object with a compatible interface will work, regardless of its\\nspecific type. Although type checking is supported—and even required in some rare\\ncases—you’ll see that it’s not usually the “Pythonic” way of thinking. In fact, you’ll\\nfind that polymorphism is probably the key idea behind using Python well.\\n\\nUser-Defined Classes\\nWe’ll study object-oriented programming in Python—an optional but powerful feature\\nof the language that cuts development time by supporting programming by customi-\\nzation—in depth later in this book. In abstract terms, though, classes define new types\\nof objects that extend the core set, so they merit a passing glance here. Say, for example,\\nthat you wish to have a type of object that models employees. Although there is no such\\nspecific core type in Python, the following user-defined class might fit the bill:\\n\\n>>> class Worker:\\n         def __init__(self, name, pay):          # Initialize when created\\n             self.name = name                    # self is the new object\\n             self.pay  = pay\\n         def lastName(self):\\n             return self.name.split()[-1]        # Split string on blanks\\n         def giveRaise(self, percent):\\n             self.pay *= (1.0 + percent)         # Update pay in place\\n\\nThis class defines a new kind of object that will have name and pay attributes (sometimes \\ncalled state information), as well as two bits of behavior coded as functions (normally\\ncalled methods). Calling the class like a function generates instances of our new type,\\nand the class’s methods automatically receive the instance being processed by a given\\nmethod call (in the self argument):\\n\\n>>> bob = Worker(\\'Bob Smith\\', 50000)             # Make two instances\\n>>> sue = Worker(\\'Sue Jones\\', 60000)             # Each has name and pay attrs\\n>>> bob.lastName()                               # Call method: bob is self\\n\\'Smith\\'\\n>>> sue.lastName()                               # sue is the self subject\\n\\'Jones\\'\\n>>> sue.giveRaise(.10)                           # Updates sue\\'s pay\\n>>> sue.pay\\n66000.0\\n\\nOther Core Types\\n\\n| 129\\n\\n\\x0cThe implied “self” object is why we call this an object-oriented model: there is always\\nan implied subject in functions within a class. In a sense, though, the class-based type\\nsimply builds on and uses core types—a user-defined Worker object here, for example,\\nis just a collection of a string and a number (name and pay, respectively), plus functions\\nfor processing those two built-in objects.\\nThe larger story of classes is that their inheritance mechanism supports software hier-\\narchies that lend themselves to customization by extension. We extend software by\\nwriting new classes, not by changing what already works. You should also know that\\nclasses are an optional feature of Python, and simpler built-in types such as lists and\\ndictionaries are often better tools than user-coded classes. This is all well beyond the\\nbounds of our introductory object-type tutorial, though, so consider this just a preview;\\nfor full disclosure on user-defined types coded with classes, you’ll have to read on.\\nBecause classes build upon other tools in Python, they are one of the major goals of\\nthis book’s journey.\\n\\nAnd Everything Else\\nAs mentioned earlier, everything you can process in a Python script is a type of object,\\nso our object type tour is necessarily incomplete. However, even though everything in\\nPython is an “object,” only those types of objects we’ve met so far are considered part\\nof Python’s core type set. Other types in Python either are objects related to program\\nexecution (like functions, modules, classes, and compiled code), which we will study\\nlater, or are implemented by imported module functions, not language syntax. The\\nlatter of these also tend to have application-specific roles—text patterns, database in-\\nterfaces, network connections, and so on.\\nMoreover, keep in mind that the objects we’ve met here are objects, but not necessarily\\nobject-oriented—a  concept  that  usually  requires  inheritance  and  the  Python  class\\nstatement, which we’ll meet again later in this book. Still, Python’s core objects are the\\nworkhorses of almost every Python script you’re likely to meet, and they usually are\\nthe basis of larger noncore types.\\n\\nChapter Summary\\nAnd that’s a wrap for our initial data type tour. This chapter has offered a brief intro-\\nduction to Python’s core object types and the sorts of operations we can apply to them.\\nWe’ve studied generic operations that work on many object types (sequence operations\\nsuch as indexing and slicing, for example), as well as type-specific operations available\\nas method calls (for instance, string splits and list appends). We’ve also defined some\\nkey terms, such as immutability, sequences, and polymorphism.\\nAlong the way, we’ve seen that Python’s core object types are more flexible and pow-\\nerful than what is available in lower-level languages such as C. For instance, Python’s\\nlists  and  dictionaries  obviate  most  of  the  work  you  do  to  support  collections  and\\n\\n130 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0csearching in lower-level languages. Lists are ordered collections of other objects, and\\ndictionaries are collections of other objects that are indexed by key instead of by posi-\\ntion. Both dictionaries and lists may be nested, can grow and shrink on demand, and\\nmay contain objects of any type. Moreover, their space is automatically cleaned up as\\nyou go. We’ve also seen that strings and files work hand in hand to support a rich\\nvariety of binary and text data.\\nI’ve skipped most of the details here in order to provide a quick tour, so you shouldn’t\\nexpect all of this chapter to have made sense yet. In the next few chapters we’ll start to\\ndig deeper, taking a second pass over Python’s core object types that will fill in details\\nomitted here, and give you a deeper understanding. We’ll start off the next chapter\\nwith an in-depth look at Python numbers. First, though, here is another quiz to review.\\n\\nTest Your Knowledge: Quiz\\nWe’ll  explore  the  concepts  introduced  in  this  chapter  in  more  detail  in  upcoming\\nchapters, so we’ll just cover the big ideas here:\\n\\n1. Name four of Python’s core data types.\\n2. Why are they called “core” data types?\\n3. What does “immutable” mean, and which three of Python’s core types are con-\\n\\nsidered immutable?\\n\\n4. What does “sequence” mean, and which three types fall into that category?\\n5. What does “mapping” mean, and which core type is a mapping?\\n6. What is “polymorphism,” and why should you care?\\n\\nTest Your Knowledge: Answers\\n1. Numbers, strings, lists, dictionaries, tuples, files, and sets are generally considered\\nto be the core object (data) types. Types, None, and Booleans are sometimes clas-\\nsified this way as well. There are multiple number types (integer, floating point,\\ncomplex, fraction, and decimal) and multiple string types (simple strings and Uni-\\ncode strings in Python 2.X, and text strings and byte strings in Python 3.X).\\n\\n2. They are known as “core” types because they are part of the Python language itself\\nand are always available; to create other objects, you generally must call functions\\nin imported modules. Most of the core types have specific syntax for generating\\nthe objects: \\'spam\\', for example, is an expression that makes a string and deter-\\nmines the set of operations that can be applied to it. Because of this, core types are\\nhardwired into Python’s syntax. In contrast, you must call the built-in open function\\nto create a file object (even though this is usually considered a core type too).\\n\\n3. An  “immutable”  object  is  an  object  that  cannot  be  changed  after  it  is  created.\\nNumbers, strings, and tuples in Python fall into this category. While you cannot\\n\\nTest Your Knowledge: Answers\\n\\n| 131\\n\\n\\x0cchange an immutable object in place, you can always make a new one by running\\nan expression. Bytearrays in recent Pythons offer mutability for text, but they are\\nnot normal strings, and only apply directly to text if it’s a simple 8-bit kind (e.g.,\\nASCII).\\n\\n4. A “sequence” is a positionally ordered collection of objects. Strings, lists, and tuples\\nare all sequences in Python. They share common sequence operations, such as\\nindexing, concatenation, and slicing, but also have type-specific method calls. A\\nrelated term, “iterable,” means either a physical sequence, or a virtual one that\\nproduces its items on request.\\n\\n5. The  term  “mapping”  denotes  an  object  that  maps  keys  to  associated  values.\\nPython’s dictionary is the only mapping type in the core type set. Mappings do not\\nmaintain any left-to-right positional ordering; they support access to data stored\\nby key, plus type-specific method calls.\\n\\n6. “Polymorphism” means that the meaning of an operation (like a +) depends on the\\nobjects being operated on. This turns out to be a key idea (perhaps the key idea)\\nbehind using Python well—not constraining code to specific types makes that code\\nautomatically applicable to many types.\\n\\n132 | Chapter 4:\\u2002Introducing Python Object Types\\n\\n\\x0cCHAPTER 5\\nNumeric Types\\n\\nThis chapter begins our in-depth tour of the Python language. In Python, data takes\\nthe form of objects—either built-in objects that Python provides, or objects we create\\nusing Python tools and other languages such as C. In fact, objects are the basis of every\\nPython program you will ever write. Because they are the most fundamental notion in\\nPython programming, objects are also our first focus in this book.\\nIn the preceding chapter, we took a quick pass over Python’s core object types. Al-\\nthough essential terms were introduced in that chapter, we avoided covering too many\\nspecifics in the interest of space. Here, we’ll begin a more careful second look at data\\ntype concepts, to fill in details we glossed over earlier. Let’s get started by exploring\\nour first data type category: Python’s numeric types and operations.\\n\\nNumeric Type Basics\\nMost of Python’s number types are fairly typical and will probably seem familiar if\\nyou’ve used almost any other programming language in the past. They can be used to\\nkeep track of your bank balance, the distance to Mars, the number of visitors to your\\nwebsite, and just about any other numeric quantity.\\nIn Python, numbers are not really a single object type, but a category of similar types.\\nPython supports the usual numeric types (integers and floating points), as well as literals\\nfor creating numbers and expressions for processing them. In addition, Python provides\\nmore advanced numeric programming support and objects for more advanced work.\\nA complete inventory of Python’s numeric toolbox includes:\\n\\n• Integer and floating-point objects\\n• Complex number objects\\n• Decimal: fixed-precision objects\\n• Fraction: rational number objects\\n• Sets: collections with numeric operations\\n\\n133\\n\\n\\x0c• Booleans: true and false\\n• Built-in functions and modules: round, math, random, etc.\\n• Expressions; unlimited integer precision; bitwise operations; hex, octal, and binary\\n\\nformats\\n\\n• Third-party extensions: vectors, libraries, visualization, plotting, etc.\\n\\nBecause the types in this list’s first bullet item tend to see the most action in Python\\ncode, this chapter starts with basic numbers and fundamentals, then moves on to ex-\\nplore the other types on this list, which serve specialized roles. We’ll also study sets\\nhere, which have both numeric and collection qualities, but are generally considered\\nmore the former than the latter. Before we jump into code, though, the next few sections\\nget us started with a brief overview of how we write and process numbers in our scripts.\\n\\nNumeric Literals\\nAmong its basic types, Python provides integers, which are positive and negative whole\\nnumbers, and floating-point numbers, which are numbers with a fractional part (some-\\ntimes called “floats” for verbal economy). Python also allows us to write integers using\\nhexadecimal, octal, and binary literals; offers a complex number type; and allows in-\\ntegers to have unlimited precision—they can grow to have as many digits as your mem-\\nory space allows. Table 5-1 shows what Python’s numeric types look like when written\\nout in a program as literals or constructor function calls.\\n\\nTable 5-1. Numeric literals and constructors\\n\\nLiteral\\n1234, −24, 0, 99999999999999\\n1.23, 1., 3.14e-10, 4E210, 4.0e+210\\n0o177, 0x9ff, 0b101010\\n0177, 0o177, 0x9ff, 0b101010\\n3+4j, 3.0+4.0j, 3J\\nset(\\'spam\\'), {1, 2, 3, 4}\\n\\nDecimal(\\'1.0\\'), Fraction(1, 3)\\n\\nbool(X), True, False\\n\\nInterpretation\\nIntegers (unlimited size)\\nFloating-point numbers\\nOctal, hex, and binary literals in 3.X\\nOctal, octal, hex, and binary literals in 2.X\\nComplex number literals\\nSets: 2.X and 3.X construction forms\\nDecimal and fraction extension types\\nBoolean type and constants\\n\\nIn general, Python’s numeric type literals are straightforward to write, but a few coding\\nconcepts are worth highlighting here:\\n\\nInteger and floating-point literals\\n\\nIntegers are written as strings of decimal digits. Floating-point numbers have a\\ndecimal point and/or an optional signed exponent introduced by an e or E and\\nfollowed by an optional sign. If you write a number with a decimal point or expo-\\nnent, Python makes it a floating-point object and uses floating-point (not integer)\\n\\n134 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cmath when the object is used in an expression. Floating-point numbers are imple-\\nmented as C “doubles” in standard CPython, and therefore get as much precision\\nas the C compiler used to build the Python interpreter gives to doubles.\\n\\nIntegers in Python 2.X: normal and long\\n\\nIn Python 2.X there are two integer types, normal (often 32 bits) and long (un-\\nlimited precision), and an integer may end in an l or L to force it to become a long\\ninteger. Because integers are automatically converted to long integers when their\\nvalues overflow their allocated bits, you never need to type the letter L yourself—\\nPython automatically converts up to long integer when extra precision is needed.\\n\\nIntegers in Python 3.X: a single type\\n\\nIn Python 3.X, the normal and long integer types have been merged—there is only\\ninteger, which automatically supports the unlimited precision of Python 2.X’s sep-\\narate long integer type. Because of this, integers can no longer be coded with a\\ntrailing l or L, and integers never print with this character either. Apart from this,\\nmost  programs  are  unaffected  by  this  change,  unless  they  do  type  testing  that\\nchecks for 2.X long integers.\\n\\nHexadecimal, octal, and binary literals\\n\\nIntegers may be coded in decimal (base 10), hexadecimal (base 16), octal (base 8),\\nor binary (base 2), the last three of which are common in some programming do-\\nmains. Hexadecimals start with a leading 0x or 0X, followed by a string of hexa-\\ndecimal digits (0–9 and A–F). Hex digits may be coded in lower- or uppercase. Octal\\nliterals start with a leading 0o or 0O (zero and lower- or uppercase letter o), followed\\nby a string of digits (0–7). In 2.X, octal literals can also be coded with just a leading\\n0, but not in 3.X—this original octal form is too easily confused with decimal, and\\nis replaced by the new 0o format, which can also be used in 2.X as of 2.6. Binary\\nliterals, new as of 2.6 and 3.0, begin with a leading 0b or 0B, followed by binary\\ndigits (0–1).\\nNote that all of these literals produce integer objects in program code; they are just\\nalternative syntaxes for specifying values. The built-in calls hex(I), oct(I), and\\nbin(I)  convert  an  integer  to  its  representation  string  in  these  three  bases,  and\\nint(str, base) converts a runtime string to an integer per a given base.\\n\\nComplex numbers\\n\\nPython complex literals are written as realpart+imaginarypart, where the imagi\\nnarypart is terminated with a j or J. The realpart is technically optional, so the\\nimaginarypart may appear on its own. Internally, complex numbers are imple-\\nmented as pairs of floating-point numbers, but all numeric operations perform\\ncomplex math when applied to complex numbers. Complex numbers may also be\\ncreated with the complex(real, imag) built-in call.\\n\\nCoding other numeric types\\n\\nAs we’ll see later in this chapter, there are additional numeric types at the end of\\nTable 5-1 that serve more advanced or specialized roles. You create some of these\\n\\nNumeric Type Basics\\n\\n| 135\\n\\n\\x0cby calling functions in imported modules (e.g., decimals and fractions), and others\\nhave literal syntax all their own (e.g., sets).\\n\\nBuilt-in Numeric Tools\\nBesides the built-in number literals and construction calls shown in Table 5-1, Python\\nprovides a set of tools for processing number objects:\\n\\nExpression operators\\n\\n+, -, *, /, >>, **, &, etc.\\n\\nBuilt-in mathematical functions\\n\\npow, abs, round, int, hex, bin, etc.\\n\\nUtility modules\\n\\nrandom, math, etc.\\n\\nWe’ll meet all of these as we go along.\\nAlthough numbers are primarily processed with expressions, built-ins, and modules,\\nthey also have a handful of type-specific methods today, which we’ll meet in this chapter\\nas well. Floating-point numbers, for example, have an as_integer_ratio method that\\nis useful for the fraction number type, and an is_integer method to test if the number\\nis an integer. Integers have various attributes, including a new bit_length method in-\\ntroduced in Python 3.1 that gives the number of bits necessary to represent the object’s\\nvalue. Moreover, as part collection and part number, sets also support both methods\\nand expressions.\\nSince expressions are the most essential tool for most number types, though, let’s turn\\nto them next.\\n\\nPython Expression Operators\\nPerhaps the most fundamental tool that processes numbers is the expression: a com-\\nbination of numbers (or other objects) and operators that computes a value when ex-\\necuted by Python. In Python, you write expressions using the usual mathematical no-\\ntation and operator symbols. For instance, to add two numbers X and Y you would say\\nX + Y, which tells Python to apply the + operator to the values named by X and Y. The\\nresult of the expression is the sum of X and Y, another number object.\\nTable 5-2 lists all the operator expressions available in Python. Many are self-explana-\\ntory; for instance, the usual mathematical operators (+, −, *, /, and so on) are supported.\\nA few will be familiar if you’ve used other languages in the past: % computes a division\\nremainder, << performs a bitwise left-shift, & computes a bitwise AND result, and so\\non. Others are more Python-specific, and not all are numeric in nature: for example,\\nthe is operator tests object identity (i.e., address in memory, a strict form of equality),\\nand lambda creates unnamed functions.\\n\\n136 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cTable 5-2. Python expression operators and precedence\\n\\nOperators\\nyield x\\n\\nlambda args: expression\\n\\nx if y else z\\n\\nx or y\\n\\nx and y\\n\\nnot x\\nx in y, x not in y\\nx is y, x is not y\\nx < y, x <= y, x > y, x >= y\\nx == y, x != y\\nx | y\\n\\nx ^ y\\n\\nx & y\\nx << y, x >> y\\nx + y\\n\\nx – y\\n\\nx * y\\n\\nx % y\\nx / y, x // y\\n−x, +x\\n˜x\\n\\nx ** y\\n\\nx[i]\\n\\nx[i:j:k]\\n\\nx(...)\\n\\nx.attr\\n\\n(...)\\n\\n[...]\\n\\n{...}\\n\\nDescription\\nGenerator function send protocol\\nAnonymous function generation\\nTernary selection (x is evaluated only if y is true)\\nLogical OR (y is evaluated only if x is false)\\nLogical AND (y is evaluated only if x is true)\\nLogical negation\\nMembership (iterables, sets)\\nObject identity tests\\nMagnitude comparison, set subset and superset;\\nValue equality operators\\nBitwise OR, set union\\nBitwise XOR, set symmetric difference\\nBitwise AND, set intersection\\nShift x left or right by y bits\\nAddition, concatenation;\\nSubtraction, set difference\\nMultiplication, repetition;\\nRemainder, format;\\nDivision: true and floor\\nNegation, identity\\nBitwise NOT (inversion)\\nPower (exponentiation)\\nIndexing (sequence, mapping, others)\\nSlicing\\nCall (function, method, class, other callable)\\nAttribute reference\\nTuple, expression, generator expression\\nList, list comprehension\\nDictionary, set, set and dictionary comprehensions\\n\\nSince this book addresses both Python 2.X and 3.X, here are some notes about version\\ndifferences and recent additions related to the operators in Table 5-2:\\n\\nNumeric Type Basics\\n\\n| 137\\n\\n\\x0c• In Python 2.X, value inequality can be written as either X != Y or X <> Y. In Python\\n3.X, the latter of these options is removed because it is redundant. In either version,\\nbest practice is to use X != Y for all value inequality tests.\\n\\n• In Python 2.X, a backquotes expression `X` works the same as repr(X) and converts\\nobjects to display strings. Due to its obscurity, this expression is removed in Python\\n3.X; use the more readable str and repr built-in functions, described in “Numeric\\nDisplay Formats.”\\n\\n• The X // Y floor division expression always truncates fractional remainders in both\\nPython 2.X and 3.X. The X / Y expression performs true division in 3.X (retaining\\nremainders) and classic division in 2.X (truncating for integers). See  “Division:\\nClassic, Floor, and True” on page 146.\\n\\n• The syntax [...] is used for both list literals and list comprehension expressions.\\nThe latter of these performs an implied loop and collects expression results in a\\nnew list. See Chapter 4, Chapter 14, and Chapter 20 for examples.\\n\\n• The syntax (...) is used for tuples and expression grouping, as well as generator\\nexpressions—a form of list comprehension that produces results on demand, in-\\nstead of building a result list. See Chapter 4 and Chapter 20 for examples. The\\nparentheses may sometimes be omitted in all three contexts.\\n\\n• The syntax {...} is used for dictionary literals, and in Python 3.X and 2.7 for set\\nliterals and both dictionary and set comprehensions. See the set coverage in this\\nchapter as well as Chapter 4, Chapter 8, Chapter 14, and Chapter 20 for examples.\\n• The yield and ternary if/else selection expressions are available in Python 2.5 and\\nlater. The former returns send(...) arguments in generators; the latter is shorthand\\nfor a multiline if statement. yield requires parentheses if not alone on the right\\nside of an assignment statement.\\n\\n• Comparison operators may be chained: X < Y < Z produces the same result as X <\\n\\nY and Y < Z. See “Comparisons: Normal and Chained” on page 144 for details.\\n\\n• In recent Pythons, the slice expression X[I:J:K] is equivalent to indexing with a\\n\\nslice object: X[slice(I, J, K)].\\n\\n• In Python 2.X, magnitude comparisons of mixed types are allowed, and convert\\nnumbers to a common type, and order other mixed types according to type names.\\nIn Python 3.X, nonnumeric mixed-type magnitude comparisons are not allowed\\nand raise exceptions; this includes sorts by proxy.\\n\\n• Magnitude comparisons for dictionaries are also no longer supported in Python\\n3.X (though equality tests are); comparing sorted(aDict.items()) is one possible\\nreplacement.\\n\\nWe’ll see most of the operators in Table 5-2 in action later; first, though, we need to\\ntake a quick look at the ways these operators may be combined in expressions.\\n\\n138 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cMixed operators follow operator precedence\\nAs in most languages, in Python, you code more complex expressions by stringing\\ntogether the operator expressions in Table 5-2. For instance, the sum of two multipli-\\ncations might be written as a mix of variables and operators:\\n\\nA * B + C * D\\n\\nSo, how does Python know which operation to perform first? The answer to this ques-\\ntion lies in operator precedence. When you write an expression with more than one\\noperator, Python groups its parts according to what are called precedence rules, and\\nthis  grouping  determines  the  order  in  which  the  expression’s  parts  are  computed.\\nTable 5-2 is ordered by operator precedence:\\n\\n• Operators lower in the table have higher precedence, and so bind more tightly in\\n\\nmixed expressions.\\n\\n• Operators in the same row in Table 5-2 generally group from left to right when\\ncombined (except for exponentiation, which groups right to left, and comparisons,\\nwhich chain left to right).\\n\\nFor example, if you write X + Y * Z, Python evaluates the multiplication first (Y *\\nZ), then adds that result to X because * has higher precedence (is lower in the table)\\nthan +. Similarly, in this section’s original example, both multiplications (A * B and C\\n* D) will happen before their results are added.\\n\\nParentheses group subexpressions\\nYou can forget about precedence completely if you’re careful to group parts of expres-\\nsions with parentheses. When you enclose subexpressions in parentheses, you override\\nPython’s precedence rules; Python always evaluates expressions in parentheses first\\nbefore using their results in the enclosing expressions.\\nFor instance, instead of coding X + Y * Z, you could write one of the following to force\\nPython to evaluate the expression in the desired order:\\n\\n(X + Y) * Z\\nX + (Y * Z)\\n\\nIn the first case, + is applied to X and Y first, because this subexpression is wrapped in\\nparentheses. In the second case, the * is performed first (just as if there were no paren-\\ntheses at all). Generally speaking, adding parentheses in large expressions is a good\\nidea—it not only forces the evaluation order you want, but also aids readability.\\n\\nMixed types are converted up\\nBesides mixing operators in expressions, you can also mix numeric types. For instance,\\nyou can add an integer to a floating-point number:\\n\\n40 + 3.14\\n\\nNumeric Type Basics\\n\\n| 139\\n\\n\\x0cBut this leads to another question: what type is the result—integer or floating point?\\nThe answer is simple, especially if you’ve used almost any other language before: in\\nmixed-type numeric expressions, Python first converts operands up to the type of the\\nmost complicated operand, and then performs the math on same-type operands. This\\nbehavior is similar to type conversions in the C language.\\nPython ranks the complexity of numeric types like so: integers are simpler than floating-\\npoint numbers, which are simpler than complex numbers. So, when an integer is mixed\\nwith a floating point, as in the preceding example, the integer is converted up to a\\nfloating-point value first, and floating-point math yields the floating-point result:\\n\\n>>> 40 + 3.14       # Integer to float, float math/result\\n43.14\\n\\nSimilarly, any mixed-type expression where one operand is a complex number results\\nin the other operand being converted up to a complex number, and the expression\\nyields a complex result. In Python 2.X, normal integers are also converted to long in-\\ntegers whenever their values are too large to fit in a normal integer; in 3.X, integers\\nsubsume longs entirely.\\nYou can force the issue by calling built-in functions to convert types manually:\\n\\n>>> int(3.1415)     # Truncates float to integer\\n3\\n>>> float(3)        # Converts integer to float\\n3.0\\n\\nHowever, you won’t usually need to do this: because Python automatically converts\\nup to the more complex type within an expression, the results are normally what you\\nwant.\\nAlso,  keep  in  mind  that  all  these  mixed-type  conversions  apply  only  when  mixing\\nnumeric types (e.g., an integer and a floating point) in an expression, including those\\nusing numeric and comparison operators. In general, Python does not convert across\\nany other type boundaries automatically. Adding a string to an integer, for example,\\nresults in an error, unless you manually convert one or the other; watch for an example\\nwhen we meet strings in Chapter 7.\\n\\nIn Python 2.X, nonnumeric mixed types can be compared, but no con-\\nversions are performed—mixed types compare according to a rule that\\nseems deterministic but not aesthetically pleasing: it compares the string\\nnames of the objects’ types. In 3.X, nonnumeric mixed-type magnitude\\ncomparisons are never allowed and raise exceptions. Note that this ap-\\nplies to comparison operators such as > only; other operators like + do\\nnot allow mixed nonnumeric types in either 3.X or 2.X.\\n\\n140 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cPreview: Operator overloading and polymorphism\\nAlthough we’re focusing on built-in numbers right now, all Python operators may be\\noverloaded (i.e., implemented) by Python classes and C extension types to work on\\nobjects you create. For instance, you’ll see later that objects coded with classes may be\\nadded or concatenated with x+y expressions, indexed with x[i] expressions, and so on.\\nFurthermore,  Python  itself  automatically  overloads  some  operators,  such  that  they\\nperform different actions depending on the type of built-in objects being processed.\\nFor example, the + operator performs addition when applied to numbers but performs\\nconcatenation when applied to sequence objects such as strings and lists. In fact, + can\\nmean anything at all when applied to objects you define with classes.\\nAs we saw in the prior chapter, this property is usually called polymorphism—a term\\nindicating that the meaning of an operation depends on the type of the objects being\\noperated on. We’ll revisit this concept when we explore functions in Chapter 16, be-\\ncause it becomes a much more obvious feature in that context.\\n\\nNumbers in Action\\nOn to the code! Probably the best way to understand numeric objects and expressions\\nis to see them in action, so with those basics in hand let’s start up the interactive com-\\nmand line and try some simple but illustrative operations (be sure to see Chapter 3 for\\npointers if you need help starting an interactive session).\\n\\nVariables and Basic Expressions\\nFirst of all, let’s exercise some basic math. In the following interaction, we first assign\\ntwo variables (a and  b) to integers so we can use them later in a larger expression.\\nVariables are simply names—created by you or Python—that are used to keep track of\\ninformation in your program. We’ll say more about this in the next chapter, but in\\nPython:\\n\\n• Variables are created when they are first assigned values.\\n• Variables are replaced with their values when used in expressions.\\n• Variables must be assigned before they can be used in expressions.\\n• Variables refer to objects and are never declared ahead of time.\\n\\nIn other words, these assignments cause the variables a and b to spring into existence\\nautomatically:\\n\\n% python\\n>>> a = 3                  # Name created: not declared ahead of time\\n>>> b = 4\\n\\nI’ve also used a comment here. Recall that in Python code, text after a  # mark and\\ncontinuing to the end of the line is considered to be a comment and is ignored by\\n\\nNumbers in Action | 141\\n\\n\\x0cPython. Comments are a way to write human-readable documentation for your code,\\nand an important part of programming. I’ve added them to most of this book’s exam-\\nples to help explain the code. In the next part of the book, we’ll meet a related but more\\nfunctional feature—documentation strings—that attaches the text of your comments\\nto objects so it’s available after your code is loaded.\\nBecause code you type interactively is temporary, though, you won’t normally write\\ncomments in this context. If you’re working along, this means you don’t need to type\\nany of the comment text from the # through to the end of the line; it’s not a required\\npart of the statements we’re running this way.\\nNow, let’s use our new integer objects in some expressions. At this point, the values of\\na and b are still 3 and 4, respectively. Variables like these are replaced with their values\\nwhenever they’re used inside an expression, and the expression results are echoed back\\nimmediately when we’re working interactively:\\n\\n>>> a + 1, a − 1           # Addition (3 + 1), subtraction (3 − 1)\\n(4, 2)\\n>>> b * 3, b / 2           # Multiplication (4 * 3), division (4 / 2)\\n(12, 2.0)\\n>>> a % 2, b ** 2          # Modulus (remainder), power (4 ** 2)\\n(1, 16)\\n>>> 2 + 4.0, 2.0 ** b      # Mixed-type conversions\\n(6.0, 16.0)\\n\\nTechnically, the results being echoed back here are tuples of two values because the\\nlines typed at the prompt contain two expressions separated by commas; that’s why\\nthe results are displayed in parentheses (more on tuples later). Note that the expressions\\nwork because the variables a and b within them have been assigned values. If you use\\na different variable that has not yet been assigned, Python reports an error rather than\\nfilling in some default value:\\n\\n>>> c * 2\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nNameError: name \\'c\\' is not defined\\n\\nYou don’t need to predeclare variables in Python, but they must have been assigned at\\nleast once before you can use them. In practice, this means you have to initialize coun-\\nters to zero before you can add to them, initialize lists to an empty list before you can\\nappend to them, and so on.\\nHere are two slightly larger expressions to illustrate operator grouping and more about\\nconversions, and preview a difference in the division operator in Python 3.X and 2.X:\\n\\n>>> b / 2 + a               # Same as ((4 / 2) + 3)   [use 2.0 in 2.X]\\n5.0\\n>>> b / (2.0 + a)           # Same as (4 / (2.0 + 3)) [use print before 2.7]\\n0.8\\n\\nIn the first expression, there are no parentheses, so Python automatically groups the\\ncomponents according to its precedence rules—because / is lower in Table 5-2 than\\n\\n142 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c+, it binds more tightly and so is evaluated first. The result is as if the expression had\\nbeen organized with parentheses as shown in the comment to the right of the code.\\nAlso, notice that all the numbers are integers in the first expression. Because of that,\\nPython 2.X’s / performs integer division and addition and will give a result of 5, whereas\\nPython 3.X’s / performs true division, which always retains fractional remainders and\\ngives the result 5.0 shown. If you want 2.X’s integer division in 3.X, code this as b //\\n2 + a; if you want 3.X’s true division in 2.X, code this as b / 2.0 + a (more on division\\nin a moment).\\nIn the second expression, parentheses are added around the + part to force Python to\\nevaluate it first (i.e., before the /). We also made one of the operands floating point by\\nadding a decimal point: 2.0. Because of the mixed types, Python converts the integer\\nreferenced by a to a floating-point value (3.0) before performing the +. If instead all the\\nnumbers in this expression were integers, integer division (4 / 5) would yield the trun-\\ncated integer 0 in Python 2.X but the floating point 0.8 shown in Python 3.X. Again,\\nstay tuned for formal division details.\\n\\nNumeric Display Formats\\nIf you’re using Python 2.6, Python 3.0, or earlier, the result of the last of the preceding\\nexamples may look a bit odd the first time you see it:\\n\\n>>> b / (2.0 + a)           # Pythons <= 2.6: echoes give more (or fewer) digits\\n0.80000000000000004\\n\\n>>> print(b / (2.0 + a))    # But print rounds off digits\\n0.8\\n\\nWe met this phenomenon briefly in the prior chapter, and it’s not present in Pythons\\n2.7, 3.1, and later. The full story behind this odd result has to do with the limitations\\nof floating-point hardware and its inability to exactly represent some values in a limited\\nnumber  of  bits.  Because  computer  architecture  is  well  beyond  this  book’s  scope,\\nthough, we’ll finesse this by saying that your computer’s floating-point hardware is\\ndoing the best it can, and neither it nor Python is in error here.\\nIn fact, this is really just a display issue—the interactive prompt’s automatic result echo\\nshows more digits than the print statement here only because it uses a different algo-\\nrithm. It’s the same number in memory. If you don’t want to see all the digits, use\\nprint; as this chapter’s sidebar “str and repr Display Formats” on page 144 will explain,\\nyou’ll get a user-friendly display. As of 2.7 and 3.1, Python’s floating-point display logic\\ntries  to  be  more  intelligent,  usually  showing  fewer  decimal  digits,  but  occasionally\\nmore.\\nNote, however, that not all values have so many digits to display:\\n\\n>>> 1 / 2.0\\n0.5\\n\\nNumbers in Action | 143\\n\\n\\x0cand that there are more ways to display the bits of a number inside your computer than\\nusing print and automatic echoes (the following are all run in Python 3.3, and may\\nvary slightly in older versions):\\n\\n>>> num = 1 / 3.0\\n>>> num                      # Auto-echoes\\n0.3333333333333333\\n>>> print(num)               # Print explicitly\\n0.3333333333333333\\n\\n>>> \\'%e\\' % num               # String formatting expression\\n\\'3.333333e-01\\'\\n>>> \\'%4.2f\\' % num            # Alternative floating-point format\\n\\'0.33\\'\\n>>> \\'{0:4.2f}\\'.format(num)   # String formatting method: Python 2.6, 3.0, and later\\n\\'0.33\\'\\n\\nThe last three of these expressions employ string formatting, a tool that allows for for-\\nmat flexibility, which we will explore in the upcoming chapter on strings (Chapter 7).\\nIts results are strings that are typically printed to displays or reports.\\n\\nstr and repr Display Formats\\n\\nTechnically, the difference between default interactive echoes and print corresponds\\nto the difference between the built-in repr and str functions:\\n\\n>>> repr(\\'spam\\')           # Used by echoes: as-code form\\n\"\\'spam\\'\"\\n>>> str(\\'spam\\')            # Used by print: user-friendly form\\n\\'spam\\'\\n\\nBoth of these convert arbitrary objects to their string representations: repr (and the\\ndefault interactive echo) produces results that look as though they were code; str (and\\nthe print operation) converts to a typically more user-friendly format if available. Some\\nobjects have both—a str for general use, and a repr with extra details. This notion will\\nresurface when we study both strings and operator overloading in classes, and you’ll\\nfind more on these built-ins in general later in the book.\\nBesides providing print strings for arbitrary objects, the str built-in is also the name of\\nthe string data type, and in 3.X may be called with an encoding name to decode a\\nUnicode string from a byte string (e.g., str(b\\'xy\\', \\'utf8\\')), and serves as an alternative\\nto the bytes.decode method we met in Chapter 4. We’ll study the latter advanced role\\nin Chapter 37 of this book.\\n\\nComparisons: Normal and Chained\\nSo far, we’ve been dealing with standard numeric operations (addition and multipli-\\ncation), but numbers, like all Python objects, can also be compared. Normal compar-\\nisons work for numbers exactly as you’d expect—they compare the relative magnitudes\\n\\n144 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cof their operands and return a Boolean result, which we would normally test and take\\naction on in a larger statement and program:\\n\\n>>> 1 < 2                  # Less than\\nTrue\\n>>> 2.0 >= 1               # Greater than or equal: mixed-type 1 converted to 1.0\\nTrue\\n>>> 2.0 == 2.0             # Equal value\\nTrue\\n>>> 2.0 != 2.0             # Not equal value\\nFalse\\n\\nNotice again how mixed types are allowed in numeric expressions (only); in the second\\ntest here, Python compares values in terms of the more complex type, float.\\nInterestingly, Python also allows us to chain multiple comparisons together to perform\\nrange tests. Chained comparisons are a sort of shorthand for larger Boolean expres-\\nsions.  In  short,  Python  lets  us  string  together  magnitude  comparison  tests  to  code\\nchained comparisons such as range tests. The expression (A < B < C), for instance,\\ntests whether B is between A and C; it is equivalent to the Boolean test (A < B and B <\\nC) but is easier on the eyes (and the keyboard). For example, assume the following\\nassignments:\\n>>> X = 2\\n>>> Y = 4\\n>>> Z = 6\\n\\nThe following two expressions have identical effects, but the first is shorter to type, and\\nit may run slightly faster since Python needs to evaluate Y only once:\\n\\n>>> X < Y < Z              # Chained comparisons: range tests\\nTrue\\n>>> X < Y and Y < Z\\nTrue\\n\\nThe same equivalence holds for false results, and arbitrary chain lengths are allowed:\\n\\n>>> X < Y > Z\\nFalse\\n>>> X < Y and Y > Z\\nFalse\\n\\n>>> 1 < 2 < 3.0 < 4\\nTrue\\n>>> 1 > 2 > 3.0 > 4\\nFalse\\n\\nYou can use other comparisons in chained tests, but the resulting expressions can be-\\ncome nonintuitive unless you evaluate them the way Python does. The following, for\\ninstance, is false just because 1 is not equal to 2:\\n>>> 1 == 2 < 3        # Same as: 1 == 2 and 2 < 3\\nFalse                 # Not same as: False < 3 (which means 0 < 3, which is true!)\\n\\nNumbers in Action | 145\\n\\n\\x0cPython does not compare the 1 == 2 expression’s False result to 3—this would tech-\\nnically mean the same as 0 < 3, which would be True (as we’ll see later in this chapter,\\nTrue and False are just customized 1 and 0).\\nOne last note here before we move on: chaining aside, numeric comparisons are based\\non magnitudes, which are generally simple—though floating-point numbers may not\\nalways work as you’d expect, and may require conversions or other massaging to be\\ncompared meaningfully:\\n\\n>>> 1.1 + 2.2 == 3.3             # Shouldn\\'t this be True?...\\nFalse\\n>>> 1.1 + 2.2                    # Close to 3.3, but not exactly: limited precision\\n3.3000000000000003\\n>>> int(1.1 + 2.2) == int(3.3)   # OK if convert: see also round, floor, trunc ahead\\nTrue                             # Decimals and fractions (ahead) may help here too\\n\\nThis stems from the fact that floating-point numbers cannot represent some values\\nexactly due to their limited number of bits—a fundamental issue in numeric program-\\nming not unique to Python, which we’ll learn more about later when we meet deci-\\nmals and fractions, tools that can address such limitations. First, though, let’s continue\\nour tour of Python’s core numeric operations, with a deeper look at division.\\n\\nDivision: Classic, Floor, and True\\nYou’ve seen how division works in the previous sections, so you should know that it\\nbehaves slightly differently in Python 3.X and 2.X. In fact, there are actually three flavors\\nof division, and two different division operators, one of which changes in 3.X. This\\nstory gets a bit detailed, but it’s another major change in 3.X and can break 2.X code,\\nso let’s get the division operator facts straight:\\n\\nX / Y\\n\\nClassic and true division. In Python 2.X, this operator performs classic division,\\ntruncating results for integers, and keeping remainders (i.e., fractional parts) for\\nfloating-point numbers. In Python 3.X, it performs true division, always keeping\\nremainders in floating-point results, regardless of types.\\n\\nX // Y\\n\\nFloor division. Added in Python 2.2 and available in both Python 2.X and 3.X, this\\noperator always truncates fractional remainders down to their floor, regardless of\\ntypes. Its result type depends on the types of its operands.\\n\\nTrue division was added to address the fact that the results of the original classic division\\nmodel are dependent on operand types, and so can be difficult to anticipate in a dy-\\nnamically typed language like Python. Classic division was removed in 3.X because of\\nthis constraint—the / and // operators implement true and floor division in 3.X. Python\\n2.X defaults to classic and floor division, but you can enable true division as an option.\\nIn sum:\\n\\n146 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c• In 3.X, the / now always performs true division, returning a float result that includes\\nany remainder, regardless of operand types. The // performs floor division, which\\ntruncates the remainder and returns an integer for integer operands or a float if any\\noperand is a float.\\n\\n• In 2.X, the / does classic division, performing truncating integer division if both\\noperands are integers and float division (keeping remainders) otherwise. The //\\ndoes floor division and works as it does in 3.X, performing truncating division for\\nintegers and floor division for floats.\\n\\nHere are the two operators at work in 3.X and 2.X—the first operation in each set is\\nthe crucial difference between the lines that may impact code:\\n\\nC:\\\\code> C:\\\\Python33\\\\python\\n>>>\\n>>> 10 / 4            # Differs in 3.X: keeps remainder\\n2.5\\n>>> 10 / 4.0          # Same in 3.X: keeps remainder\\n2.5\\n>>> 10 // 4           # Same in 3.X: truncates remainder\\n2\\n>>> 10 // 4.0         # Same in 3.X: truncates to floor\\n2.0\\n\\nC:\\\\code> C:\\\\Python27\\\\python\\n>>>\\n>>> 10 / 4            # This might break on porting to 3.X!\\n2\\n>>> 10 / 4.0\\n2.5\\n>>> 10 // 4           # Use this in 2.X if truncation needed\\n2\\n>>> 10 // 4.0\\n2.0\\n\\nNotice that the data type of the result for // is still dependent on the operand types in\\n3.X: if either is a float, the result is a float; otherwise, it is an integer. Although this may\\nseem similar to the type-dependent behavior of / in 2.X that motivated its change in\\n3.X, the type of the return value is much less critical than differences in the return value\\nitself.\\nMoreover, because // was provided in part as a compatibility tool for programs that\\nrely on truncating integer division (and this is more common than you might expect),\\nit must return integers for integers. Using // instead of / in 2.X when integer truncation\\nis required helps make code 3.X-compatible.\\n\\nSupporting either Python\\nAlthough / behavior differs in 2.X and 3.X, you can still support both versions in your\\ncode. If your programs depend on truncating integer division, use // in both 2.X and\\n3.X as just mentioned. If your programs require floating-point results with remainders\\n\\nNumbers in Action | 147\\n\\n\\x0cfor integers, use float to guarantee that one operand is a float around a / when run in\\n2.X:\\n\\nX = Y // Z        # Always truncates, always an int result for ints in 2.X and 3.X\\n\\nX = Y / float(Z)  # Guarantees float division with remainder in either 2.X or 3.X\\n\\nAlternatively, you can enable 3.X / division in 2.X with a __future__ import, rather\\nthan forcing it with float conversions:\\n\\nC:\\\\code> C:\\\\Python27\\\\python\\n>>> from __future__ import division         # Enable 3.X \"/\" behavior\\n>>> 10 / 4\\n2.5\\n>>> 10 // 4                                 # Integer // is the same in both\\n2\\n\\nThis special from statement applies to the rest of your session when typed interactively\\nlike this, and must appear as the first executable line when used in a script file (and\\nalas, we can import from the future in Python, but not the past; insert something about \\ntalking to “the Doc” here...).\\n\\nFloor versus truncation\\nOne subtlety: the  // operator is informally called truncating division, but it’s more\\naccurate to refer to it as floor division—it truncates the result down to its floor, which\\nmeans the closest whole number below the true result. The net effect is to round down,\\nnot  strictly  truncate,  and  this  matters  for  negatives.  You  can  see  the  difference  for\\nyourself with the Python math module (modules must be imported before you can use\\ntheir contents; more on this later):\\n\\n>>> import math\\n>>> math.floor(2.5)           # Closest number below value\\n2\\n>>> math.floor(-2.5)\\n-3\\n>>> math.trunc(2.5)           # Truncate fractional part (toward zero)\\n2\\n>>> math.trunc(-2.5)\\n-2\\n\\nWhen running division operators, you only really truncate for positive results, since\\ntruncation is the same as floor; for negatives, it’s a floor result (really, they are both\\nfloor, but floor is the same as truncation for positives). Here’s the case for 3.X:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> 5 / 2, 5 / −2\\n(2.5, −2.5)\\n\\n>>> 5 // 2, 5 // −2           # Truncates to floor: rounds to first lower integer\\n(2, −3)                       # 2.5 becomes 2, −2.5 becomes −3\\n\\n>>> 5 / 2.0, 5 / −2.0\\n(2.5, −2.5)\\n\\n148 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c>>> 5 // 2.0, 5 // −2.0       # Ditto for floats, though result is float too\\n(2.0, −3.0)\\n\\nThe 2.X case is similar, but / results differ again:\\n\\nC:code> c:\\\\python27\\\\python\\n>>> 5 / 2, 5 / −2             # Differs in 3.X\\n(2, −3)\\n\\n>>> 5 // 2, 5 // −2           # This and the rest are the same in 2.X and 3.X\\n(2, −3)\\n\\n>>> 5 / 2.0, 5 / −2.0\\n(2.5, −2.5)\\n\\n>>> 5 // 2.0, 5 // −2.0\\n(2.0, −3.0)\\n\\nIf you really want truncation toward zero regardless of sign, you can always run a float\\ndivision result through  math.trunc, regardless of Python version (also see the  round\\nbuilt-in for related functionality, and the int built-in, which has the same effect here\\nbut requires no import):\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> import math\\n>>> 5 / −2                      # Keep remainder\\n−2.5\\n>>> 5 // −2                     # Floor below result\\n-3\\n>>> math.trunc(5 / −2)          # Truncate instead of floor (same as int())\\n−2\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> import math\\n>>> 5 / float(−2)               # Remainder in 2.X\\n−2.5\\n>>> 5 / −2, 5 // −2             # Floor in 2.X\\n(−3, −3)\\n>>> math.trunc(5 / float(−2))   # Truncate in 2.X\\n−2\\n\\nWhy does truncation matter?\\nAs a wrap-up, if you are using 3.X, here is the short story on division operators for\\nreference:\\n\\n>>> (5 / 2), (5 / 2.0), (5 / −2.0), (5 / −2)        # 3.X true division\\n(2.5, 2.5, −2.5, −2.5)\\n\\n>>> (5 // 2), (5 // 2.0), (5 // −2.0), (5 // −2)    # 3.X floor division\\n(2, 2.0, −3.0, −3)\\n\\n>>> (9 / 3), (9.0 / 3), (9 // 3), (9 // 3.0)        # Both\\n(3.0, 3.0, 3, 3.0)\\n\\nNumbers in Action | 149\\n\\n\\x0cFor 2.X readers, division works as follows (the three bold outputs of integer division\\ndiffer from 3.X):\\n\\n>>> (5 / 2), (5 / 2.0), (5 / −2.0), (5 / −2)        # 2.X classic division (differs)\\n(2, 2.5, −2.5, −3)\\n\\n>>> (5 // 2), (5 // 2.0), (5 // −2.0), (5 // −2)    # 2.X floor division (same)\\n(2, 2.0, −3.0, −3)\\n\\n>>> (9 / 3), (9.0 / 3), (9 // 3), (9 // 3.0)        # Both\\n(3, 3.0, 3, 3.0)\\n\\nIt’s possible that the nontruncating behavior of / in 3.X may break a significant number\\nof 2.X programs. Perhaps because of a C language legacy, many programmers rely on\\ndivision truncation for integers and will have to learn to use // in such contexts instead.\\nYou should do so in all new 2.X and 3.X code you write today—in the former for 3.X\\ncompatibility, and in the latter because / does not truncate in 3.X. Watch for a simple\\nprime number while loop example in Chapter 13, and a corresponding exercise at the\\nend of Part IV that illustrates the sort of code that may be impacted by this / change.\\nAlso stay tuned for more on the special from command used in this section; it’s discussed\\nfurther in Chapter 25.\\n\\nInteger Precision\\nDivision may differ slightly across Python releases, but it’s still fairly standard. Here’s\\nsomething a bit more exotic. As mentioned earlier, Python 3.X integers support un-\\nlimited size:\\n\\n>>> 999999999999999999999999999999 + 1         # 3.X\\n1000000000000000000000000000000\\n\\nPython  2.X  has  a  separate  type  for  long  integers,  but  it  automatically  converts  any\\nnumber too large to store in a normal integer to this type. Hence, you don’t need to\\ncode any special syntax to use longs, and the only way you can tell that you’re using\\n2.X longs is that they print with a trailing “L”:\\n\\n>>> 999999999999999999999999999999 + 1         # 2.X\\n1000000000000000000000000000000L\\n\\nUnlimited-precision integers are a convenient built-in tool. For instance, you can use\\nthem to count the U.S. national debt in pennies in Python directly (if you are so inclined,\\nand have enough memory on your computer for this year’s budget). They are also why\\nwe were able to raise 2 to such large powers in the examples in Chapter 3. Here are the\\n3.X and 2.X cases:\\n\\n>>> 2 ** 200\\n1606938044258990275541962092341162602522202993782792835301376\\n\\n>>> 2 ** 200\\n1606938044258990275541962092341162602522202993782792835301376L\\n\\n150 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cBecause Python must do extra work to support their extended precision, integer math\\nis usually substantially slower than normal when numbers grow large. However, if you\\nneed  the  precision,  the  fact  that  it’s  built  in  for  you  to  use  will  likely  outweigh  its\\nperformance penalty.\\n\\nComplex Numbers\\nAlthough less commonly used than the types we’ve been exploring thus far, complex\\nnumbers are a distinct core object type in Python. They are typically used in engineering\\nand science applications. If you know what they are, you know why they are useful; if\\nnot, consider this section optional reading.\\nComplex numbers are represented as two floating-point numbers—the real and imag-\\ninary parts—and you code them by adding a j or J suffix to the imaginary part. We\\ncan also write complex numbers with a nonzero real part by adding the two parts with\\na +. For example, the complex number with a real part of 2 and an imaginary part of\\n−3 is written 2 + −3j. Here are some examples of complex math at work:\\n\\n>>> 1j * 1J\\n(-1+0j)\\n>>> 2 + 1j * 3\\n(2+3j)\\n>>> (2 + 1j) * 3\\n(6+3j)\\n\\nComplex numbers also allow us to extract their parts as attributes, support all the usual\\nmathematical  expressions,  and  may  be  processed  with  tools  in  the  standard  cmath\\nmodule (the complex version of the standard math module). Because complex numbers\\nare rare in most programming domains, though, we’ll skip the rest of this story here.\\nCheck Python’s language reference manual for additional details.\\n\\nHex, Octal, Binary: Literals and Conversions\\nPython integers can be coded in hexadecimal, octal, and binary notation, in addition\\nto the normal base-10 decimal coding we’ve been using so far. The first three of these\\nmay at first seem foreign to 10-fingered beings, but some programmers find them con-\\nvenient alternatives for specifying values, especially when their mapping to bytes and\\nbits is important. The coding rules were introduced briefly at the start of this chapter;\\nlet’s look at some live examples here.\\nKeep in mind that these literals are simply an alternative syntax for specifying the value\\nof an integer object. For example, the following literals coded in Python 3.X or 2.X\\nproduce normal integers with the specified values in all three bases. In memory, an\\ninteger’s value is the same, regardless of the base we use to specify it:\\n>>> 0o1, 0o20, 0o377           # Octal literals: base 8, digits 0-7 (3.X, 2.6+)\\n(1, 16, 255)\\n>>> 0x01, 0x10, 0xFF           # Hex literals: base 16, digits 0-9/A-F (3.X, 2.X)\\n\\nNumbers in Action | 151\\n\\n\\x0c(1, 16, 255)\\n>>> 0b1, 0b10000, 0b11111111   # Binary literals: base 2, digits 0-1 (3.X, 2.6+)\\n(1, 16, 255)\\n\\nHere, the octal value 0o377, the hex value 0xFF, and the binary value 0b11111111 are all\\ndecimal 255. The F digits in the hex value, for example, each mean 15 in decimal and a\\n4-bit 1111 in binary, and reflect powers of 16. Thus, the hex value  0xFF and others\\nconvert to decimal values as follows:\\n\\n>>> 0xFF, (15 * (16 ** 1)) + (15 * (16 ** 0))     # How hex/binary map to decimal\\n(255, 255)\\n>>> 0x2F, (2  * (16 ** 1)) + (15 * (16 ** 0))\\n(47, 47)\\n>>> 0xF, 0b1111, (1*(2**3) + 1*(2**2) + 1*(2**1) + 1*(2**0))\\n(15, 15, 15)\\n\\nPython prints integer values in decimal (base 10) by default but provides built-in func-\\ntions that allow you to convert integers to other bases’ digit strings, in Python-literal\\nform—useful when programs or users expect to see values in a given base:\\n\\n>>> oct(64), hex(64), bin(64)               # Numbers=>digit strings\\n(\\'0o100\\', \\'0x40\\', \\'0b1000000\\')\\n\\nThe oct function converts decimal to octal, hex to hexadecimal, and bin to binary. To\\ngo the other way, the built-in int function converts a string of digits to an integer, and\\nan optional second argument lets you specify the numeric base—useful for numbers\\nread from files as strings instead of coded in scripts:\\n\\n>>> 64, 0o100, 0x40, 0b1000000              # Digits=>numbers in scripts and strings\\n(64, 64, 64, 64)\\n\\n>>> int(\\'64\\'), int(\\'100\\', 8), int(\\'40\\', 16), int(\\'1000000\\', 2)\\n(64, 64, 64, 64)\\n\\n>>> int(\\'0x40\\', 16), int(\\'0b1000000\\', 2)    # Literal forms supported too\\n(64, 64)\\n\\nThe eval function, which you’ll meet later in this book, treats strings as though they\\nwere Python code. Therefore, it has a similar effect, but usually runs more slowly—it\\nactually compiles and runs the string as a piece of a program, and it assumes the string\\nbeing run comes from a trusted source—a clever user might be able to submit a string\\nthat deletes files on your machine, so be careful with this call:\\n\\n>>> eval(\\'64\\'), eval(\\'0o100\\'), eval(\\'0x40\\'), eval(\\'0b1000000\\')\\n(64, 64, 64, 64)\\n\\nFinally, you can also convert integers to base-specific strings with string formatting\\nmethod calls and expressions, which return just digits, not Python literal strings:\\n\\n>>> \\'{0:o}, {1:x}, {2:b}\\'.format(64, 64, 64)     # Numbers=>digits, 2.6+\\n\\'100, 40, 1000000\\'\\n\\n>>> \\'%o, %x, %x, %X\\' % (64, 64, 255, 255)        # Similar, in all Pythons\\n\\'100, 40, ff, FF\\'\\n\\n152 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cString formatting is covered in more detail in Chapter 7.\\nTwo notes before moving on. First, per the start of this chapter, Python 2.X users should\\nremember that you can code octals with simply a leading zero, the original octal format\\nin Python:\\n\\n>>> 0o1, 0o20, 0o377     # New octal format in 2.6+ (same as 3.X)\\n(1, 16, 255)\\n>>> 01, 020, 0377        # Old octal literals in all 2.X (error in 3.X)\\n(1, 16, 255)\\n\\nIn 3.X, the syntax in the second of these examples generates an error. Even though it’s\\nnot an error in 2.X, be careful not to begin a string of digits with a leading zero unless\\nyou really mean to code an octal value. Python 2.X will treat it as base 8, which may\\nnot work as you’d expect—010 is always decimal 8 in 2.X, not decimal 10 (despite what\\nyou may or may not think!). This, along with symmetry with the hex and binary forms,\\nis why the octal format was changed in 3.X—you must use 0o010 in 3.X, and probably\\nshould in 2.6 and 2.7 both for clarity and forward-compatibility with 3.X.\\nSecondly, note that these literals can produce arbitrarily long integers. The following,\\nfor instance, creates an integer with hex notation and then displays it first in decimal\\nand then in octal and binary with converters (run in 3.X here: in 2.X the decimal and\\noctal  displays  have  a  trailing  L  to  denote  its  separate  long  type,  and  octals  display\\nwithout the letter o):\\n\\n>>> X = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFF\\n>>> X\\n5192296858534827628530496329220095\\n>>> oct(X)\\n\\'0o17777777777777777777777777777777777777\\'\\n>>> bin(X)\\n\\'0b111111111111111111111111111111111111111111111111111111111 ...and so on... 11111\\'\\n\\nSpeaking of binary digits, the next section shows tools for processing individual bits.\\n\\nBitwise Operations\\nBesides the normal numeric operations (addition, subtraction, and so on), Python sup-\\nports most of the numeric expressions available in the C language. This includes oper-\\nators that treat integers as strings of binary bits, and can come in handy if your Python\\ncode must deal with things like network packets, serial ports, or packed binary data\\nproduced by a C program.\\nWe can’t dwell on the fundamentals of Boolean math here—again, those who must\\nuse it probably already know how it works, and others can often postpone the topic\\naltogether—but the basics are straightforward. For instance, here are some of Python’s\\nbitwise expression operators at work performing bitwise shift and Boolean operations\\non integers:\\n\\n>>> x = 1               # 1 decimal is 0001 in bits\\n>>> x << 2              # Shift left 2 bits: 0100\\n\\nNumbers in Action | 153\\n\\n\\x0c4\\n>>> x | 2               # Bitwise OR (either bit=1): 0011\\n3\\n>>> x & 1               # Bitwise AND (both bits=1): 0001\\n1\\n\\nIn the first expression, a binary 1 (in base 2, 0001) is shifted left two slots to create a\\nbinary 4 (0100). The last two operations perform a binary OR to combine bits (0001|\\n0010 = 0011) and a binary AND to select common bits (0001&0001 = 0001). Such bit-\\nmasking operations allow us to encode and extract multiple flags and other values\\nwithin a single integer.\\nThis is one area where the binary and hexadecimal number support in Python as of 3.0\\nand 2.6 become especially useful—they allow us to code and inspect numbers by bit-\\nstrings:\\n\\n>>> X = 0b0001          # Binary literals\\n>>> X << 2              # Shift left\\n4\\n>>> bin(X << 2)         # Binary digits string\\n\\'0b100\\'\\n\\n>>> bin(X | 0b010)      # Bitwise OR: either\\n\\'0b11\\'\\n>>> bin(X & 0b1)        # Bitwise AND: both\\n\\'0b1\\'\\n\\nThis is also true for values that begin life as hex literals, or undergo base conversions:\\n\\n>>> X = 0xFF            # Hex literals\\n>>> bin(X)\\n\\'0b11111111\\'\\n>>> X ^ 0b10101010      # Bitwise XOR: either but not both\\n85\\n>>> bin(X ^ 0b10101010)\\n\\'0b1010101\\'\\n\\n>>> int(\\'01010101\\', 2)  # Digits=>number: string to int per base\\n85\\n>>> hex(85)             # Number=>digits: Hex digit string\\n\\'0x55\\'\\n\\nAlso  in  this  department,  Python  3.1  and  2.7  introduced  a  new  integer  bit_length\\nmethod, which allows you to query the number of bits required to represent a number’s\\nvalue in binary. You can often achieve the same effect by subtracting 2 from the length\\nof the bin string using the len built-in function we met in Chapter 4 (to account for the\\nleading “0b”), though it may be less efficient:\\n\\n>>> X = 99\\n>>> bin(X), X.bit_length(), len(bin(X)) - 2\\n(\\'0b1100011\\', 7, 7)\\n>>> bin(256), (256).bit_length(), len(bin(256)) - 2\\n(\\'0b100000000\\', 9, 9)\\n\\n154 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cWe won’t go into much more detail on such “bit twiddling” here. It’s supported if you\\nneed it, but bitwise operations are often not as important in a high-level language such\\nas Python as they are in a low-level language such as C. As a rule of thumb, if you find\\nyourself wanting to flip bits in Python, you should think about which language you’re\\nreally coding. As we’ll see in upcoming chapters, Python’s lists, dictionaries, and the\\nlike provide richer—and usually better—ways to encode information than bit strings,\\nespecially when your data’s audience includes readers of the human variety.\\n\\nOther Built-in Numeric Tools\\nIn addition to its core object types, Python also provides both built-in functions and\\nstandard library modules for numeric processing. The pow and abs built-in functions,\\nfor instance, compute powers and absolute values, respectively. Here are some exam-\\nples of the built-in math module (which contains most of the tools in the C language’s\\nmath library) and a few built-in functions at work in 3.3; as described earlier, some\\nfloating-point displays may show more or fewer digits in Pythons before 2.7 and 3.1:\\n\\n>>> import math\\n>>> math.pi, math.e                               # Common constants\\n(3.141592653589793, 2.718281828459045)\\n\\n>>> math.sin(2 * math.pi / 180)                   # Sine, tangent, cosine\\n0.03489949670250097\\n\\n>>> math.sqrt(144), math.sqrt(2)                  # Square root\\n(12.0, 1.4142135623730951)\\n\\n>>> pow(2, 4), 2 ** 4, 2.0 ** 4.0                 # Exponentiation (power)\\n(16, 16, 16.0)\\n\\n>>> abs(-42.0), sum((1, 2, 3, 4))                 # Absolute value, summation\\n(42.0, 10)\\n\\n>>> min(3, 1, 2, 4), max(3, 1, 2, 4)              # Minimum, maximum\\n(1, 4)\\n\\nThe sum function shown here works on a sequence of numbers, and min and max accept\\neither a sequence or individual arguments. There are a variety of ways to drop the\\ndecimal digits of floating-point numbers. We met truncation and floor earlier; we can\\nalso round, both numerically and for display purposes:\\n\\n>>> math.floor(2.567), math.floor(-2.567)         # Floor (next-lower integer)\\n(2, −3)\\n\\n>>> math.trunc(2.567), math.trunc(−2.567)         # Truncate (drop decimal digits)\\n(2, −2)\\n\\n>>> int(2.567), int(−2.567)                       # Truncate (integer conversion)\\n(2, −2)\\n\\n>>> round(2.567), round(2.467), round(2.567, 2)   # Round (Python 3.X version)\\n\\nNumbers in Action | 155\\n\\n\\x0c(3, 2, 2.57)\\n\\n>>> \\'%.1f\\' % 2.567, \\'{0:.2f}\\'.format(2.567)       # Round for display (Chapter 7)\\n(\\'2.6\\', \\'2.57\\')\\n\\nAs we saw earlier, the last of these produces strings that we would usually print and\\nsupports a variety of formatting options. As also described earlier, the second-to-last\\ntest here will also output (3, 2, 2.57) prior to 2.7 and 3.1 if we wrap it in a print call\\nto request a more user-friendly display. String formatting is still subtly different, though,\\neven in 3.X; round rounds and drops decimal digits but still produces a floating-point\\nnumber in memory, whereas string formatting produces a string, not a number:\\n\\n>>> (1 / 3.0), round(1 / 3.0, 2), (\\'%.2f\\' % (1 / 3.0))\\n(0.3333333333333333, 0.33, \\'0.33\\')\\n\\nInterestingly, there are three ways to compute square roots in Python: using a module\\nfunction, an expression, or a built-in function (if you’re interested in performance, we\\nwill revisit these in an exercise and its solution at the end of Part IV, to see which runs\\nquicker):\\n\\n>>> import math\\n>>> math.sqrt(144)              # Module\\n12.0\\n>>> 144 ** .5                   # Expression\\n12.0\\n>>> pow(144, .5)                # Built-in\\n12.0\\n\\n>>> math.sqrt(1234567890)       # Larger numbers\\n35136.41828644462\\n>>> 1234567890 ** .5\\n35136.41828644462\\n>>> pow(1234567890, .5)\\n35136.41828644462\\n\\nNotice that standard library modules such as math must be imported, but built-in func-\\ntions such as abs and round are always available without imports. In other words, mod-\\nules are external components, but built-in functions live in an implied namespace that\\nPython automatically searches to find names used in your program. This namespace\\nsimply corresponds to the standard library module called builtins in Python 3.X (and\\n__builtin__ in 2.X). There is much more about name resolution in the function and\\nmodule parts of this book; for now, when you hear “module,” think “import.”\\nThe standard library random module must be imported as well. This module provides\\nan array of tools, for tasks such as picking a random floating-point number between 0\\nand 1, and selecting a random integer between two numbers:\\n\\n>>> import random\\n>>> random.random()\\n0.5566014960423105\\n>>> random.random()              # Random floats, integers, choices, shuffles\\n0.051308506597373515\\n\\n156 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c>>> random.randint(1, 10)\\n5\\n>>> random.randint(1, 10)\\n9\\n\\nThis module can also choose an item at random from a sequence, and shuffle a list of\\nitems randomly:\\n\\n>>> random.choice([\\'Life of Brian\\', \\'Holy Grail\\', \\'Meaning of Life\\'])\\n\\'Holy Grail\\'\\n>>> random.choice([\\'Life of Brian\\', \\'Holy Grail\\', \\'Meaning of Life\\'])\\n\\'Life of Brian\\'\\n\\n>>> suits = [\\'hearts\\', \\'clubs\\', \\'diamonds\\', \\'spades\\']\\n>>> random.shuffle(suits)\\n>>> suits\\n[\\'spades\\', \\'hearts\\', \\'diamonds\\', \\'clubs\\']\\n>>> random.shuffle(suits)\\n>>> suits\\n[\\'clubs\\', \\'diamonds\\', \\'hearts\\', \\'spades\\']\\n\\nThough we’d need additional code to make this more tangible here, the random module\\ncan be useful for shuffling cards in games, picking images at random in a slideshow\\nGUI, performing statistical simulations, and much more. We’ll deploy it again later in\\nthis book (e.g., in Chapter 20’s permutations case study), but for more details, see\\nPython’s library manual.\\n\\nOther Numeric Types\\nSo far in this chapter, we’ve been using Python’s core numeric types—integer, floating\\npoint, and complex. These will suffice for most of the number crunching that most\\nprogrammers will ever need to do. Python comes with a handful of more exotic numeric\\ntypes, though, that merit a brief look here.\\n\\nDecimal Type\\nPython 2.4 introduced a new core numeric type: the decimal object, formally known\\nas Decimal. Syntactically, you create decimals by calling a function within an imported\\nmodule, rather than running a literal expression. Functionally, decimals are like float-\\ning-point numbers, but they have a fixed number of decimal points. Hence, decimals\\nare fixed-precision floating-point values.\\nFor example, with decimals, we can have a floating-point value that always retains just\\ntwo decimal digits. Furthermore, we can specify how to round or truncate the extra\\ndecimal digits beyond the object’s cutoff. Although it generally incurs a performance\\npenalty compared to the normal floating-point type, the decimal type is well suited to\\nrepresenting fixed-precision quantities like sums of money and can help you achieve\\nbetter numeric accuracy.\\n\\nOther Numeric Types\\n\\n| 157\\n\\n\\x0cDecimal basics\\nThe last point merits elaboration. As previewed briefly when we explored comparisons,\\nfloating-point math is less than exact because of the limited space used to store values.\\nFor example, the following should yield zero, but it does not. The result is close to zero,\\nbut there are not enough bits to be precise here:\\n\\n>>> 0.1 + 0.1 + 0.1 - 0.3                         # Python 3.3\\n5.551115123125783e-17\\n\\nOn Pythons prior to 3.1 and 2.7, printing the result to produce the user-friendly display\\nformat doesn’t completely help either, because the hardware related to floating-point\\nmath is inherently limited in terms of accuracy (a.k.a. precision). The following in 3.3\\ngives the same result as the previous output:\\n\\n>>> print(0.1 + 0.1 + 0.1 - 0.3)                  # Pythons < 2.7, 3.1\\n5.55111512313e-17\\n\\nHowever, with decimals, the result can be dead-on:\\n\\n>>> from decimal import Decimal\\n>>> Decimal(\\'0.1\\') + Decimal(\\'0.1\\') + Decimal(\\'0.1\\') - Decimal(\\'0.3\\')\\nDecimal(\\'0.0\\')\\n\\nAs shown here, we can make decimal objects by calling the Decimal constructor function\\nin the decimal module and passing in strings that have the desired number of decimal\\ndigits for the resulting object (using the str function to convert floating-point values\\nto strings if needed). When decimals of different precision are mixed in expressions,\\nPython converts up to the largest number of decimal digits automatically:\\n>>> Decimal(\\'0.1\\') + Decimal(\\'0.10\\') + Decimal(\\'0.10\\') - Decimal(\\'0.30\\')\\nDecimal(\\'0.00\\')\\n\\nIn Pythons 2.7, 3.1, and later, it’s also possible to create a decimal object from a floating-\\npoint object, with a call of the form  decimal.Decimal.from_float(1.25), and recent\\nPythons allow floating-point numbers to be used directly. The conversion is exact but\\ncan sometimes yield a large default number of digits, unless they are fixed per the next\\nsection:\\n\\n>>> Decimal(0.1) + Decimal(0.1) + Decimal(0.1) - Decimal(0.3)\\nDecimal(\\'2.775557561565156540423631668E-17\\')\\n\\nIn Python 3.3 and later, the decimal module was also optimized to improve its perfor-\\nmance radically: the reported speedup for the new version is 10X to 100X, depending\\non the type of program benchmarked.\\n\\nSetting decimal precision globally\\nOther tools in the decimal module can be used to set the precision of all decimal num-\\nbers, arrange error handling, and more. For instance, a context object in this module\\nallows for specifying precision (number of decimal digits) and rounding modes (down,\\n\\n158 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cceiling, etc.). The precision is applied globally for all decimals created in the calling\\nthread:\\n\\n>>> import decimal\\n>>> decimal.Decimal(1) / decimal.Decimal(7)                     # Default: 28 digits\\nDecimal(\\'0.1428571428571428571428571429\\')\\n\\n>>> decimal.getcontext().prec = 4                               # Fixed precision\\n>>> decimal.Decimal(1) / decimal.Decimal(7)\\nDecimal(\\'0.1429\\')\\n\\n>>> Decimal(0.1) + Decimal(0.1) + Decimal(0.1) - Decimal(0.3)   # Closer to 0\\nDecimal(\\'1.110E-17\\')\\n\\nThis is especially useful for monetary applications, where cents are represented as two\\ndecimal digits. Decimals are essentially an alternative to manual rounding and string\\nformatting in this context:\\n\\n>>> 1999 + 1.33      # This has more digits in memory than displayed in 3.3\\n2000.33\\n>>>\\n>>> decimal.getcontext().prec = 2\\n>>> pay = decimal.Decimal(str(1999 + 1.33))\\n>>> pay\\nDecimal(\\'2000.33\\')\\n\\nDecimal context manager\\nIn Python 2.6 and 3.0 and later, it’s also possible to reset precision temporarily by using\\nthe  with  context  manager  statement.  The  precision  is  reset  to  its  original  value  on\\nstatement exit; in a new Python 3.3 session (per Chapter 3 the “...” here is Python’s\\ninteractive prompt for continuation lines in some interfaces and requires manual in-\\ndentation; IDLE omits this prompt and indents for you):\\n\\nC:\\\\code> C:\\\\Python33\\\\python\\n>>> import decimal\\n>>> decimal.Decimal(\\'1.00\\') / decimal.Decimal(\\'3.00\\')\\nDecimal(\\'0.3333333333333333333333333333\\')\\n>>>\\n>>> with decimal.localcontext() as ctx:\\n...     ctx.prec = 2\\n...     decimal.Decimal(\\'1.00\\') / decimal.Decimal(\\'3.00\\')\\n...\\nDecimal(\\'0.33\\')\\n>>>\\n>>> decimal.Decimal(\\'1.00\\') / decimal.Decimal(\\'3.00\\')\\nDecimal(\\'0.3333333333333333333333333333\\')\\n\\nThough useful, this statement requires much more background knowledge than you’ve\\nobtained at this point; watch for coverage of the with statement in Chapter 34.\\nBecause use of the decimal type is still relatively rare in practice, I’ll defer to Python’s\\nstandard library manuals and interactive help for more details. And because decimals\\n\\nOther Numeric Types\\n\\n| 159\\n\\n\\x0caddress some of the same floating-point accuracy issues as the fraction type, let’s move\\non to the next section to see how the two compare.\\n\\nFraction Type\\nPython 2.6 and 3.0 debuted a new numeric type, Fraction, which implements a rational\\nnumber object. It essentially keeps both a numerator and a denominator explicitly, so\\nas to avoid some of the inaccuracies and limitations of floating-point math. Like deci-\\nmals, fractions do not map as closely to computer hardware as floating-point numbers.\\nThis means their performance may not be as good, but it also allows them to provide\\nextra utility in a standard tool where required or useful.\\n\\nFraction basics\\nFraction is a functional cousin to the Decimal fixed-precision type described in the prior\\nsection, as both can be used to address the floating-point type’s numerical inaccura-\\ncies. It’s also used in similar ways—like Decimal, Fraction resides in a module; import\\nits constructor and pass in a numerator and a denominator to make one (among other\\nschemes). The following interaction shows how:\\n\\n>>> from fractions import Fraction\\n>>> x = Fraction(1, 3)                    # Numerator, denominator\\n>>> y = Fraction(4, 6)                    # Simplified to 2, 3 by gcd\\n\\n>>> x\\nFraction(1, 3)\\n>>> y\\nFraction(2, 3)\\n>>> print(y)\\n2/3\\n\\nOnce created, Fractions can be used in mathematical expressions as usual:\\n\\n>>> x + y\\nFraction(1, 1)\\n>>> x − y                           # Results are exact: numerator, denominator\\nFraction(−1, 3)\\n>>> x * y\\nFraction(2, 9)\\n\\nFraction objects can also be created from floating-point number strings, much like\\ndecimals:\\n\\n>>> Fraction(\\'.25\\')\\nFraction(1, 4)\\n>>> Fraction(\\'1.25\\')\\nFraction(5, 4)\\n>>>\\n>>> Fraction(\\'.25\\') + Fraction(\\'1.25\\')\\nFraction(3, 2)\\n\\n160 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cNumeric accuracy in fractions and decimals\\nNotice that this is different from floating-point-type math, which is constrained by the\\nunderlying limitations of floating-point hardware. To compare, here are the same op-\\nerations run with floating-point objects, and notes on their limited accuracy—they may\\ndisplay fewer digits in recent Pythons than they used to, but they still aren’t exact values\\nin memory:\\n\\n>>> a = 1 / 3.0                     # Only as accurate as floating-point hardware\\n>>> b = 4 / 6.0                     # Can lose precision over many calculations\\n>>> a\\n0.3333333333333333\\n>>> b\\n0.6666666666666666\\n\\n>>> a + b\\n1.0\\n>>> a - b\\n-0.3333333333333333\\n>>> a * b\\n0.2222222222222222\\n\\nThis floating-point limitation is especially apparent for values that cannot be repre-\\nsented accurately given their limited number of bits in memory. Both Fraction and\\nDecimal provide ways to get exact results, albeit at the cost of some speed and code\\nverbosity. For instance, in the following example (repeated from the prior section),\\nfloating-point numbers do not accurately give the zero answer expected, but both of\\nthe other types do:\\n\\n>>> 0.1 + 0.1 + 0.1 - 0.3           # This should be zero (close, but not exact)\\n5.551115123125783e-17\\n\\n>>> from fractions import Fraction\\n>>> Fraction(1, 10) + Fraction(1, 10) + Fraction(1, 10) - Fraction(3, 10)\\nFraction(0, 1)\\n\\n>>> from decimal import Decimal\\n>>> Decimal(\\'0.1\\') + Decimal(\\'0.1\\') + Decimal(\\'0.1\\') - Decimal(\\'0.3\\')\\nDecimal(\\'0.0\\')\\n\\nMoreover, fractions and decimals both allow more intuitive and accurate results than\\nfloating points sometimes can, in different ways—by using rational representation and\\nby limiting precision:\\n\\n>>> 1 / 3                           # Use a \".0\" in Python 2.X for true \"/\"\\n0.3333333333333333\\n\\n>>> Fraction(1, 3)                  # Numeric accuracy, two ways\\nFraction(1, 3)\\n\\n>>> import decimal\\n>>> decimal.getcontext().prec = 2\\n>>> Decimal(1) / Decimal(3)\\nDecimal(\\'0.33\\')\\n\\nOther Numeric Types\\n\\n| 161\\n\\n\\x0cIn fact, fractions both retain accuracy and automatically simplify results. Continuing\\nthe preceding interaction:\\n\\n>>> (1 / 3) + (6 / 12)              # Use a \".0\" in Python 2.X for true \"/\"\\n0.8333333333333333\\n\\n>>> Fraction(6, 12)                 # Automatically simplified\\nFraction(1, 2)\\n\\n>>> Fraction(1, 3) + Fraction(6, 12)\\nFraction(5, 6)\\n\\n>>> decimal.Decimal(str(1/3)) + decimal.Decimal(str(6/12))\\nDecimal(\\'0.83\\')\\n\\n>>> 1000.0 / 1234567890\\n8.100000073710001e-07\\n>>> Fraction(1000, 1234567890)      # Substantially simpler!\\nFraction(100, 123456789)\\n\\nFraction conversions and mixed types\\nTo support fraction conversions, floating-point objects now have a method that yields\\ntheir  numerator  and  denominator  ratio,  fractions  have  a  from_float  method,  and\\nfloat accepts a Fraction as an argument. Trace through the following interaction to\\nsee how this pans out (the * in the second test is special syntax that expands a tuple\\ninto individual arguments; more on this when we study function argument passing in\\nChapter 18):\\n\\n>>> (2.5).as_integer_ratio()               # float object method\\n(5, 2)\\n\\n>>> f = 2.5\\n>>> z = Fraction(*f.as_integer_ratio())    # Convert float -> fraction: two args\\n>>> z                                      # Same as Fraction(5, 2)\\nFraction(5, 2)\\n\\n>>> x                                      # x from prior interaction\\nFraction(1, 3)\\n>>> x + z\\nFraction(17, 6)                            # 5/2 + 1/3 = 15/6 + 2/6\\n\\n>>> float(x)                               # Convert fraction -> float\\n0.3333333333333333\\n>>> float(z)\\n2.5\\n>>> float(x + z)\\n2.8333333333333335\\n>>> 17 / 6\\n2.8333333333333335\\n\\n>>> Fraction.from_float(1.75)              # Convert float -> fraction: other way\\nFraction(7, 4)\\n\\n162 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c>>> Fraction(*(1.75).as_integer_ratio())\\nFraction(7, 4)\\n\\nFinally, some type mixing is allowed in expressions, though Fraction must sometimes\\nbe manually propagated to retain accuracy. Study the following interaction to see how\\nthis works:\\n\\n>>> x\\nFraction(1, 3)\\n>>> x + 2                                  # Fraction + int -> Fraction\\nFraction(7, 3)\\n>>> x + 2.0                                # Fraction + float -> float\\n2.3333333333333335\\n>>> x + (1./3)                             # Fraction + float -> float\\n0.6666666666666666\\n>>> x + (4./3)\\n1.6666666666666665\\n>>> x + Fraction(4, 3)                     # Fraction + Fraction -> Fraction\\nFraction(5, 3)\\n\\nCaveat: although you can convert from floating point to fraction, in some cases there\\nis an unavoidable precision loss when you do so, because the number is inaccurate in\\nits original floating-point form. When needed, you can simplify such results by limiting\\nthe maximum denominator value:\\n\\n>>> 4.0 / 3\\n1.3333333333333333\\n>>> (4.0 / 3).as_integer_ratio()                # Precision loss from float\\n(6004799503160661, 4503599627370496)\\n\\n>>> x\\nFraction(1, 3)\\n>>> a = x + Fraction(*(4.0 / 3).as_integer_ratio())\\n>>> a\\nFraction(22517998136852479, 13510798882111488)\\n\\n>>> 22517998136852479 / 13510798882111488.      # 5 / 3 (or close to it!)\\n1.6666666666666667\\n\\n>>> a.limit_denominator(10)                     # Simplify to closest fraction\\nFraction(5, 3)\\n\\nFor more details on the Fraction type, experiment further on your own and consult the\\nPython 2.6, 2.7, and 3.X library manuals and other documentation.\\n\\nSets\\nBesides decimals, Python 2.4 also introduced a new collection type, the set—an unor-\\ndered  collection  of  unique  and  immutable  objects  that  supports  operations  corre-\\nsponding to mathematical set theory. By definition, an item appears only once in a set,\\nno matter how many times it is added. Accordingly, sets have a variety of applications,\\nespecially in numeric and database-focused work.\\n\\nOther Numeric Types\\n\\n| 163\\n\\n\\x0cBecause sets are collections of other objects, they share some behavior with objects\\nsuch as lists and dictionaries that are outside the scope of this chapter. For example,\\nsets are iterable, can grow and shrink on demand, and may contain a variety of object\\ntypes. As we’ll see, a set acts much like the keys of a valueless dictionary, but it supports\\nextra operations.\\nHowever, because sets are unordered and do not map keys to values, they are neither\\nsequence nor mapping types; they are a type category unto themselves. Moreover, be-\\ncause sets are fundamentally mathematical in nature (and for many readers, may seem\\nmore academic and be used much less often than more pervasive objects like diction-\\naries), we’ll explore the basic utility of Python’s set objects here.\\n\\nSet basics in Python 2.6 and earlier\\nThere are a few ways to make sets today, depending on which Python you use. Since\\nthis book covers all, let’s begin with the case for 2.6 and earlier, which also is available\\n(and sometimes still required) in later Pythons; we’ll refine this for 2.7 and 3.X exten-\\nsions in a moment. To make a set object, pass in a sequence or other iterable object to\\nthe built-in set function:\\n\\n>>> x = set(\\'abcde\\')\\n>>> y = set(\\'bdxyz\\')\\n\\nYou get back a set object, which contains all the items in the object passed in (notice\\nthat sets do not have a positional ordering, and so are not sequences—their order is\\narbitrary and may vary per Python release):\\n\\n>>> x\\nset([\\'a\\', \\'c\\', \\'b\\', \\'e\\', \\'d\\'])                    # Pythons <= 2.6 display format\\n\\nSets  made  this  way  support  the  common  mathematical  set  operations  with  expres-\\nsion operators. Note that we can’t perform the following operations on plain sequences\\nlike strings, lists, and tuples—we must create sets from them by passing them to set in\\norder to apply these tools:\\n\\n>>> x − y                                         # Difference\\nset([\\'a\\', \\'c\\', \\'e\\'])\\n\\n>>> x | y                                         # Union\\nset([\\'a\\', \\'c\\', \\'b\\', \\'e\\', \\'d\\', \\'y\\', \\'x\\', \\'z\\'])\\n\\n>>> x & y                                         # Intersection\\nset([\\'b\\', \\'d\\'])\\n\\n>>> x ^ y                                         # Symmetric difference (XOR)\\nset([\\'a\\', \\'c\\', \\'e\\', \\'y\\', \\'x\\', \\'z\\'])\\n\\n>>> x > y, x < y                                  # Superset, subset\\n(False, False)\\n\\nThe notable exception to this rule is the in set membership test—this expression is also\\ndefined to work on all other collection types, where it also performs membership (or a\\n\\n164 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0csearch, if you prefer to think in procedural terms). Hence, we do not need to convert\\nthings like strings and lists to sets to run this test:\\n\\n>>> \\'e\\' in x                                      # Membership (sets)\\nTrue\\n\\n>>> \\'e\\' in \\'Camelot\\', 22 in [11, 22, 33]          # But works on other types too\\n(True, True)\\n\\nIn addition to expressions, the set object provides methods that correspond to these\\noperations and more, and that support set changes—the set add method inserts one\\nitem, update is an in-place union, and remove deletes an item by value (run a dir call on\\nany set instance or the set type name to see all the available methods). Assuming x and\\ny are still as they were in the prior interaction:\\n\\n>>> z = x.intersection(y)                         # Same as x & y\\n>>> z\\nset([\\'b\\', \\'d\\'])\\n>>> z.add(\\'SPAM\\')                                 # Insert one item\\n>>> z\\nset([\\'b\\', \\'d\\', \\'SPAM\\'])\\n>>> z.update(set([\\'X\\', \\'Y\\']))                     # Merge: in-place union\\n>>> z\\nset([\\'Y\\', \\'X\\', \\'b\\', \\'d\\', \\'SPAM\\'])\\n>>> z.remove(\\'b\\')                                 # Delete one item\\n>>> z\\nset([\\'Y\\', \\'X\\', \\'d\\', \\'SPAM\\'])\\n\\nAs iterable containers, sets can also be used in operations such as len, for loops, and\\nlist comprehensions. Because they are unordered, though, they don’t support sequence\\noperations like indexing and slicing:\\n\\n>>> for item in set(\\'abc\\'): print(item * 3)\\n\\naaa\\nccc\\nbbb\\n\\nFinally, although the set expressions shown earlier generally require two sets, their\\nmethod-based counterparts can often work with any iterable type as well:\\n\\n>>> S = set([1, 2, 3])\\n\\n>>> S | set([3, 4])          # Expressions require both to be sets\\nset([1, 2, 3, 4])\\n>>> S | [3, 4]\\nTypeError: unsupported operand type(s) for |: \\'set\\' and \\'list\\'\\n\\n>>> S.union([3, 4])          # But their methods allow any iterable\\nset([1, 2, 3, 4])\\n>>> S.intersection((1, 3, 5))\\nset([1, 3])\\n>>> S.issubset(range(-5, 5))\\nTrue\\n\\nOther Numeric Types\\n\\n| 165\\n\\n\\x0cFor more details on set operations, see Python’s library reference manual or a reference\\nbook. Although set operations can be coded manually in Python with other types, like\\nlists and dictionaries (and often were in the past), Python’s built-in sets use efficient\\nalgorithms and implementation techniques to provide quick and standard operation.\\n\\nSet literals in Python 3.X and 2.7\\nIf you think sets are “cool,” they eventually became noticeably cooler, with new syntax\\nfor set literals and comprehensions initially added in the Python 3.X line only, but back-\\nported to Python 2.7 by popular demand. In these Pythons we can still use the set built-\\nin to make set objects, but also a new set literal form, using the curly braces formerly\\nreserved for dictionaries. In 3.X and 2.7, the following are equivalent:\\n\\nset([1, 2, 3, 4])                # Built-in call (all)\\n{1, 2, 3, 4}                     # Newer set literals (2.7, 3.X)\\n\\nThis  syntax  makes  sense,  given  that  sets  are  essentially  like  valueless  dictionaries—\\nbecause a set’s items are unordered, unique, and immutable, the items behave much\\nlike a dictionary’s keys. This operational similarity is even more striking given that\\ndictionary key lists in 3.X are view objects, which support set-like behavior such as\\nintersections and unions (see Chapter 8 for more on dictionary view objects).\\nRegardless of how a set is made, 3.X displays it using the new literal format. Python\\n2.7 accepts the new literal syntax, but still displays sets using the 2.6 display form of\\nthe prior section. In all Pythons, the set built-in is still required to create empty sets\\nand to build sets from existing iterable objects (short of using set comprehensions,\\ndiscussed later in this chapter), but the new literal is convenient for initializing sets of\\nknown structure.\\nHere’s what sets look like in 3.X; it’s the same in 2.7, except that set results display\\nwith 2.X’s set([...]) notation, and item order may vary per version (which by defini-\\ntion is irrelevant in sets anyhow):\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> set([1, 2, 3, 4])            # Built-in: same as in 2.6\\n{1, 2, 3, 4}\\n>>> set(\\'spam\\')                  # Add all items in an iterable\\n{\\'s\\', \\'a\\', \\'p\\', \\'m\\'}\\n\\n>>> {1, 2, 3, 4}                 # Set literals: new in 3.X (and 2.7)\\n{1, 2, 3, 4}\\n>>> S = {\\'s\\', \\'p\\', \\'a\\', \\'m\\'}\\n>>> S\\n{\\'s\\', \\'a\\', \\'p\\', \\'m\\'}\\n\\n>>> S.add(\\'alot\\')                # Methods work as before\\n>>> S\\n{\\'s\\', \\'a\\', \\'p\\', \\'alot\\', \\'m\\'}\\n\\nAll the set processing operations discussed in the prior section work the same in 3.X,\\nbut the result sets print differently:\\n\\n166 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c>>> S1 = {1, 2, 3, 4}\\n>>> S1 & {1, 3}                  # Intersection\\n{1, 3}\\n>>> {1, 5, 3, 6} | S1            # Union\\n{1, 2, 3, 4, 5, 6}\\n>>> S1 - {1, 3, 4}               # Difference\\n{2}\\n>>> S1 > {1, 3}                  # Superset\\nTrue\\n\\nNote that {} is still a dictionary in all Pythons. Empty sets must be created with the\\nset built-in, and print the same way:\\n\\n>>> S1 - {1, 2, 3, 4}            # Empty sets print differently\\nset()\\n>>> type({})                     # Because {} is an empty dictionary\\n<class \\'dict\\'>\\n\\n>>> S = set()                    # Initialize an empty set\\n>>> S.add(1.23)\\n>>> S\\n{1.23}\\n\\nAs in Python 2.6 and earlier, sets created with 3.X/2.7 literals support the same meth-\\nods, some of which allow general iterable operands that expressions do not:\\n\\n>>> {1, 2, 3} | {3, 4}\\n{1, 2, 3, 4}\\n>>> {1, 2, 3} | [3, 4]\\nTypeError: unsupported operand type(s) for |: \\'set\\' and \\'list\\'\\n\\n>>> {1, 2, 3}.union([3, 4])\\n{1, 2, 3, 4}\\n>>> {1, 2, 3}.union({3, 4})\\n{1, 2, 3, 4}\\n>>> {1, 2, 3}.union(set([3, 4]))\\n{1, 2, 3, 4}\\n\\n>>> {1, 2, 3}.intersection((1, 3, 5))\\n{1, 3}\\n>>> {1, 2, 3}.issubset(range(-5, 5))\\nTrue\\n\\nImmutable constraints and frozen sets\\nSets are powerful and flexible objects, but they do have one constraint in both 3.X and\\n2.X that you should keep in mind—largely because of their implementation, sets can\\nonly contain immutable (a.k.a. “hashable”) object types. Hence, lists and dictionaries\\ncannot be embedded in sets, but tuples can if you need to store compound values.\\nTuples compare by their full values when used in set operations:\\n\\n>>> S\\n{1.23}\\n>>> S.add([1, 2, 3])                   # Only immutable objects work in a set\\nTypeError: unhashable type: \\'list\\'\\n\\nOther Numeric Types\\n\\n| 167\\n\\n\\x0c>>> S.add({\\'a\\':1})\\nTypeError: unhashable type: \\'dict\\'\\n>>> S.add((1, 2, 3))\\n>>> S                                  # No list or dict, but tuple OK\\n{1.23, (1, 2, 3)}\\n\\n>>> S | {(4, 5, 6), (1, 2, 3)}         # Union: same as S.union(...)\\n{1.23, (4, 5, 6), (1, 2, 3)}\\n>>> (1, 2, 3) in S                     # Membership: by complete values\\nTrue\\n>>> (1, 4, 3) in S\\nFalse\\n\\nTuples in a set, for instance, might be used to represent dates, records, IP addresses,\\nand so on (more on tuples later in this part of the book). Sets may also contain modules,\\ntype objects, and more. Sets themselves are mutable too, and so cannot be nested in\\nother sets directly; if you need to store a set inside another set, the frozenset built-in\\ncall works just like set but creates an immutable set that cannot change and thus can\\nbe embedded in other sets.\\n\\nSet comprehensions in Python 3.X and 2.7\\nIn addition to literals, Python 3.X grew a set comprehension construct that was back-\\nported for use to Python 2.7 too. Like the 3.X set literal, 2.7 accepts its syntax, but\\ndisplays its results in 2.X set notation. The set comprehension expression is similar in\\nform to the list comprehension we previewed in Chapter 4, but is coded in curly braces\\ninstead of square brackets and run to make a set instead of a list. Set comprehensions\\nrun a loop and collect the result of an expression on each iteration; a loop variable gives\\naccess to the current iteration value for use in the collection expression. The result is a\\nnew set you create by running the code, with all the normal set behavior. Here is a set\\ncomprehension in 3.3 (again, result display and order differs in 2.7):\\n>>> {x ** 2 for x in [1, 2, 3, 4]}         # 3.X/2.7 set comprehension\\n{16, 1, 4, 9}\\n\\nIn this expression, the loop is coded on the right, and the collection expression is coded\\non the left (x ** 2). As for list comprehensions, we get back pretty much what this\\nexpression says: “Give me a new set containing X squared, for every X in a list.” Com-\\nprehensions can also iterate across other kinds of objects, such as strings (the first of\\nthe following examples illustrates the comprehension-based way to make a set from an\\nexisting iterable):\\n\\n>>> {x for x in \\'spam\\'}                    # Same as: set(\\'spam\\')\\n{\\'m\\', \\'s\\', \\'p\\', \\'a\\'}\\n\\n>>> {c * 4 for c in \\'spam\\'}                # Set of collected expression results\\n{\\'pppp\\', \\'aaaa\\', \\'ssss\\', \\'mmmm\\'}\\n>>> {c * 4 for c in \\'spamham\\'}\\n{\\'pppp\\', \\'aaaa\\', \\'hhhh\\', \\'ssss\\', \\'mmmm\\'}\\n\\n>>> S = {c * 4 for c in \\'spam\\'}\\n\\n168 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c>>> S | {\\'mmmm\\', \\'xxxx\\'}\\n{\\'pppp\\', \\'xxxx\\', \\'mmmm\\', \\'aaaa\\', \\'ssss\\'}\\n>>> S & {\\'mmmm\\', \\'xxxx\\'}\\n{\\'mmmm\\'}\\n\\nBecause the rest of the comprehensions story relies upon underlying concepts we’re\\nnot yet prepared to address, we’ll postpone further details until later in this book. In\\nChapter 8, we’ll meet a first cousin in 3.X and 2.7, the dictionary comprehension, and\\nI’ll have much more to say about all comprehensions—list, set, dictionary, and gener-\\nator—later on, especially in Chapter 14 and Chapter 20. As we’ll learn there, all com-\\nprehensions support additional syntax not shown here, including nested loops and\\nif tests, which can be challenging to understand until you’ve had a chance to study\\nlarger statements.\\n\\nWhy sets?\\nSet operations have a variety of common uses, some more practical than mathematical.\\nFor example, because items are stored only once in a set, sets can be used to filter\\nduplicates out of other collections, though items may be reordered in the process be-\\ncause sets are unordered in general. Simply convert the collection to a set, and then\\nconvert it back again (sets work in the list call here because they are iterable, another\\ntechnical artifact that we’ll unearth later):\\n\\n>>> L = [1, 2, 1, 3, 2, 4, 5]\\n>>> set(L)\\n{1, 2, 3, 4, 5}\\n>>> L = list(set(L))                                  # Remove duplicates\\n>>> L\\n[1, 2, 3, 4, 5]\\n\\n>>> list(set([\\'yy\\', \\'cc\\', \\'aa\\', \\'xx\\', \\'dd\\', \\'aa\\']))   # But order may change\\n[\\'cc\\', \\'xx\\', \\'yy\\', \\'dd\\', \\'aa\\']\\n\\nSets can be used to isolate differences in lists, strings, and other iterable objects too—\\nsimply convert to sets and take the difference—though again the unordered nature of\\nsets means that the results may not match that of the originals. The last two of the\\nfollowing compare attribute lists of string object types in 3.X (results vary in 2.7):\\n\\n>>> set([1, 3, 5, 7]) - set([1, 2, 4, 5, 6])          # Find list differences\\n{3, 7}\\n>>> set(\\'abcdefg\\') - set(\\'abdghij\\')                   # Find string differences\\n{\\'c\\', \\'e\\', \\'f\\'}\\n>>> set(\\'spam\\') - set([\\'h\\', \\'a\\', \\'m\\'])                # Find differences, mixed\\n{\\'p\\', \\'s\\'}\\n\\n>>> set(dir(bytes)) - set(dir(bytearray))             # In bytes but not bytearray\\n{\\'__getnewargs__\\'}\\n>>> set(dir(bytearray)) - set(dir(bytes))\\n{\\'append\\', \\'copy\\', \\'__alloc__\\', \\'__imul__\\', \\'remove\\', \\'pop\\', \\'insert\\', ...more...]\\n\\nYou can also use sets to perform order-neutral equality tests by converting to a set before\\nthe test, because order doesn’t matter in a set. More formally, two sets are equal if and\\n\\nOther Numeric Types\\n\\n| 169\\n\\n\\x0conly if every element of each set is contained in the other—that is, each is a subset of\\nthe other, regardless of order. For instance, you might use this to compare the outputs\\nof programs that should work the same but may generate results in different order.\\nSorting before testing has the same effect for equality, but sets don’t rely on an expensive\\nsort, and sorts order their results to support additional magnitude tests that sets do not\\n(greater, less, and so on):\\n\\n>>> L1, L2 = [1, 3, 5, 2, 4], [2, 5, 3, 4, 1]\\n>>> L1 == L2                                          # Order matters in sequences\\nFalse\\n>>> set(L1) == set(L2)                                # Order-neutral equality\\nTrue\\n>>> sorted(L1) == sorted(L2)                          # Similar but results ordered\\nTrue\\n>>> \\'spam\\' == \\'asmp\\', set(\\'spam\\') == set(\\'asmp\\'), sorted(\\'spam\\') == sorted(\\'asmp\\')\\n(False, True, True)\\n\\nSets can also be used to keep track of where you’ve already been when traversing a\\ngraph or other cyclic structure. For example, the transitive module reloader and inher-\\nitance tree lister examples we’ll study in Chapter 25 and Chapter 31, respectively, must\\nkeep track of items visited to avoid loops, as Chapter 19 discusses in the abstract. Using\\na list in this context is inefficient because searches require linear scans. Although re-\\ncording states visited as keys in a dictionary is efficient, sets offer an alternative that’s\\nessentially equivalent (and may be more or less intuitive, depending on whom you ask).\\nFinally, sets are also convenient when you’re dealing with large data sets (database\\nquery results, for example)—the intersection of two sets contains objects common to\\nboth categories, and the union contains all items in either set. To illustrate, here’s a\\nsomewhat more realistic example of set operations at work, applied to lists of people\\nin a hypothetical company, using 3.X/2.7 set literals and 3.X result displays (use set in\\n2.6 and earlier):\\n\\n>>> engineers = {\\'bob\\', \\'sue\\', \\'ann\\', \\'vic\\'}\\n>>> managers  = {\\'tom\\', \\'sue\\'}\\n\\n>>> \\'bob\\' in engineers                   # Is bob an engineer?\\nTrue\\n\\n>>> engineers & managers                 # Who is both engineer and manager?\\n{\\'sue\\'}\\n\\n>>> engineers | managers                 # All people in either category\\n{\\'bob\\', \\'tom\\', \\'sue\\', \\'vic\\', \\'ann\\'}\\n\\n>>> engineers - managers                 # Engineers who are not managers\\n{\\'vic\\', \\'ann\\', \\'bob\\'}\\n\\n>>> managers - engineers                 # Managers who are not engineers\\n{\\'tom\\'}\\n\\n>>> engineers > managers                 # Are all managers engineers? (superset)\\nFalse\\n\\n170 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0c>>> {\\'bob\\', \\'sue\\'} < engineers           # Are both engineers? (subset)\\nTrue\\n\\n>>> (managers | engineers) > managers    # All people is a superset of managers\\nTrue\\n\\n>>> managers ^ engineers                 # Who is in one but not both?\\n{\\'tom\\', \\'vic\\', \\'ann\\', \\'bob\\'}\\n\\n>>> (managers | engineers) - (managers ^ engineers)     # Intersection!\\n{\\'sue\\'}\\n\\nYou can find more details on set operations in the Python library manual and some\\nmathematical  and  relational  database  theory  texts.  Also  stay  tuned  for  Chapter  8’s\\nrevival of some of the set operations we’ve seen here, in the context of dictionary view\\nobjects in Python 3.X.\\n\\nBooleans\\nSome may argue that the Python Boolean type, bool, is numeric in nature because its\\ntwo values, True and False, are just customized versions of the integers 1 and 0 that\\nprint themselves differently. Although that’s all most programmers need to know, let’s\\nexplore this type in a bit more detail.\\nMore formally, Python today has an explicit Boolean data type called bool, with the\\nvalues True and False available as preassigned built-in names. Internally, the names\\nTrue and False are instances of bool, which is in turn just a subclass (in the object-\\noriented sense) of the built-in integer type int. True and False behave exactly like the\\nintegers 1 and 0, except that they have customized printing logic—they print them-\\nselves as the words True and False, instead of the digits 1 and 0. bool accomplishes this\\nby redefining str and repr string formats for its two objects.\\nBecause of this customization, the output of Boolean expressions typed at the interac-\\ntive prompt prints as the words True and False instead of the older and less obvious 1\\nand 0. In addition, Booleans make truth values more explicit in your code. For instance,\\nan infinite loop can now be coded as while True: instead of the less intuitive while\\n1:. Similarly, flags can be initialized more clearly with flag = False. We’ll discuss these\\nstatements further in Part III.\\nAgain, though, for most practical purposes, you can treat True and False as though\\nthey are predefined variables set to integers 1 and 0. Most programmers had been pre-\\nassigning True and False to 1 and 0 anyway; the bool type simply makes this standard.\\nIts implementation can lead to curious results, though. Because True is just the integer\\n1 with a custom display format, True + 4 yields integer 5 in Python!\\n\\n>>> type(True)\\n<class \\'bool\\'>\\n>>> isinstance(True, int)\\nTrue\\n\\nOther Numeric Types\\n\\n| 171\\n\\n\\x0c>>> True == 1                # Same value\\nTrue\\n>>> True is 1                # But a different object: see the next chapter\\nFalse\\n>>> True or False            # Same as: 1 or 0\\nTrue\\n>>> True + 4                 # (Hmmm)\\n5\\n\\nSince you probably won’t come across an expression like the last of these in real Python\\ncode, you can safely ignore any of its deeper metaphysical implications.\\nWe’ll revisit Booleans in Chapter 9 to define Python’s notion of truth, and again in\\nChapter 12 to see how Boolean operators like and and or work.\\n\\nNumeric Extensions\\nFinally, although Python core numeric types offer plenty of power for most applica-\\ntions, there is a large library of third-party open source extensions available to address\\nmore focused needs. Because numeric programming is a popular domain for Python,\\nyou’ll find a wealth of advanced tools.\\nFor example, if you need to do serious number crunching, an optional extension for\\nPython  called  NumPy  (Numeric  Python)  provides  advanced  numeric  programming\\ntools, such as a matrix data type, vector processing, and sophisticated computation\\nlibraries. Hardcore scientific programming groups at places like Los Alamos and NASA\\nuse  Python  with  NumPy  to  implement  the  sorts  of  tasks  they  previously  coded  in\\nC++, FORTRAN, or Matlab. The combination of Python and NumPy is often com-\\npared to a free, more flexible version of Matlab—you get NumPy’s performance, plus\\nthe Python language and its libraries.\\nBecause it’s so advanced, we won’t talk further about NumPy in this book. You can\\nfind  additional  support  for  advanced  numeric  programming  in  Python,  including\\ngraphics and plotting tools, extended precision floats, statistics libraries, and the pop-\\nular SciPy package by searching the Web. Also note that NumPy is currently an optional\\nextension; it doesn’t come with Python and must be installed separately, though you’ll\\nprobably want to do so if you care enough about this domain to look it up on the Web.\\n\\nChapter Summary\\nThis chapter has taken a tour of Python’s numeric object types and the operations we\\ncan apply to them. Along the way, we met the standard integer and floating-point types,\\nas well as some more exotic and less commonly used types such as complex numbers,\\ndecimals, fractions, and sets. We also explored Python’s expression syntax, type con-\\nversions, bitwise operations, and various literal forms for coding numbers in scripts.\\n\\n172 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cLater in this part of the book, we’ll continue our in-depth type tour by filling in some\\ndetails about the next object type—the string. In the next chapter, however, we’ll take\\nsome time to explore the mechanics of variable assignment in more detail than we have\\nhere. This turns out to be perhaps the most fundamental idea in Python, so make sure\\nyou check out the next chapter before moving on. First, though, it’s time to take the\\nusual chapter quiz.\\n\\nTest Your Knowledge: Quiz\\n1. What is the value of the expression 2 * (3 + 4) in Python?\\n2. What is the value of the expression 2 * 3 + 4 in Python?\\n3. What is the value of the expression 2 + 3 * 4 in Python?\\n4. What tools can you use to find a number’s square root, as well as its square?\\n5. What is the type of the result of the expression 1 + 2.0 + 3?\\n6. How can you truncate and round a floating-point number?\\n7. How can you convert an integer to a floating-point number?\\n8. How would you display an integer in octal, hexadecimal, or binary notation?\\n9. How might you convert an octal, hexadecimal, or binary string to a plain integer?\\n\\nTest Your Knowledge: Answers\\n1. The value will be 14, the result of 2 * 7, because the parentheses force the addition\\n\\nto happen before the multiplication.\\n\\n2. The value will be 10, the result of 6 + 4. Python’s operator precedence rules are\\napplied in the absence of parentheses, and multiplication has higher precedence\\nthan (i.e., happens before) addition, per Table 5-2.\\n\\n3. This expression yields 14, the result of 2 + 12, for the same precedence reasons as\\n\\nin the prior question.\\n\\n4. Functions  for  obtaining  the  square  root,  as  well  as  pi,  tangents,  and  more,  are\\navailable in the imported math module. To find a number’s square root, import\\nmath and call  math.sqrt(N). To get a number’s square, use either the exponent\\nexpression X ** 2 or the built-in function pow(X, 2). Either of these last two can\\nalso compute the square root when given a power of 0.5 (e.g., X ** .5).\\n\\n5. The result will be a floating-point number: the integers are converted up to floating\\npoint, the most complex type in the expression, and floating-point math is used to\\nevaluate it.\\n\\n6. The int(N) and math.trunc(N) functions truncate, and the round(N, digits) func-\\ntion rounds. We can also compute the floor with math.floor(N) and round for\\ndisplay with string formatting operations.\\n\\nTest Your Knowledge: Answers\\n\\n| 173\\n\\n\\x0c7. The float(I) function converts an integer to a floating point; mixing an integer\\nwith a floating point within an expression will result in a conversion as well. In\\nsome sense, Python 3.X / division converts too—it always returns a floating-point\\nresult that includes the remainder, even if both operands are integers.\\n\\n8. The oct(I) and hex(I) built-in functions return the octal and hexadecimal string\\nforms for an integer. The bin(I) call also returns a number’s binary digits string in\\nPythons 2.6, 3.0, and later. The % string formatting expression and format string\\nmethod also provide targets for some such conversions.\\n\\n9. The  int(S,  base)  function  can  be  used  to  convert  from  octal  and  hexadecimal\\nstrings to normal integers (pass in 8, 16, or 2 for the base). The eval(S) function\\ncan be used for this purpose too, but it’s more expensive to run and can have\\nsecurity issues. Note that integers are always stored in binary form in computer\\nmemory; these are just display string format conversions.\\n\\n174 | Chapter 5:\\u2002Numeric Types\\n\\n\\x0cCHAPTER 6\\nThe Dynamic Typing Interlude\\n\\nIn the prior chapter, we began exploring Python’s core object types in depth by studying\\nPython numeric types and operations. We’ll resume our object type tour in the next\\nchapter, but before we move on, it’s important that you get a handle on what may be\\nthe most fundamental idea in Python programming and is certainly the basis of much\\nof both the conciseness and flexibility of the Python language—dynamic typing, and\\nthe polymorphism it implies.\\nAs you’ll see here and throughout this book, in Python, we do not declare the specific\\ntypes of the objects our scripts use. In fact, most programs should not even care about\\nspecific types; in exchange, they are naturally applicable in more contexts than we can\\nsometimes even plan ahead for. Because dynamic typing is the root of this flexibility,\\nand is also a potential stumbling block for newcomers, let’s take a brief side trip to\\nexplore the model here.\\n\\nThe Case of the Missing Declaration Statements\\nIf you have a background in compiled or statically typed languages like C, C++, or Java,\\nyou might find yourself a bit perplexed at this point in the book. So far, we’ve been\\nusing variables without declaring their existence or their types, and it somehow works.\\nWhen we type a = 3 in an interactive session or program file, for instance, how does\\nPython know that a should stand for an integer? For that matter, how does Python\\nknow what a is at all?\\nOnce you start asking such questions, you’ve crossed over into the domain of Python’s\\ndynamic typing model. In Python, types are determined automatically at runtime, not\\nin response to declarations in your code. This means that you never declare variables\\nahead of time (a concept that is perhaps simpler to grasp if you keep in mind that it all\\nboils down to variables, objects, and the links between them).\\n\\n175\\n\\n\\x0cVariables, Objects, and References\\nAs you’ve seen in many of the examples used so far in this book, when you run an\\nassignment statement such as a = 3 in Python, it works even if you’ve never told Python\\nto use the name a as a variable, or that a should stand for an integer-type object. In the\\nPython language, this all pans out in a very natural way, as follows:\\n\\nVariable creation\\n\\nA variable (i.e., name), like a, is created when your code first assigns it a value.\\nFuture assignments change the value of the already created name. Technically,\\nPython detects some names before your code runs, but you can think of it as though\\ninitial assignments make variables.\\n\\nVariable types\\n\\nA variable never has any type information or constraints associated with it. The\\nnotion of type lives with objects, not names. Variables are generic in nature; they\\nalways simply refer to a particular object at a particular point in time.\\n\\nVariable use\\n\\nWhen a variable appears in an expression, it is immediately replaced with the object\\nthat it currently refers to, whatever that may be. Further, all variables must be\\nexplicitly assigned before they can be used; referencing unassigned variables results\\nin errors.\\n\\nIn sum, variables are created when assigned, can reference any type of object, and must\\nbe assigned before they are referenced. This means that you never need to declare names\\nused by your script, but you must initialize names before you can update them; coun-\\nters, for example, must be initialized to zero before you can add to them.\\nThis dynamic typing model is strikingly different from the typing model of traditional\\nlanguages. When you are first starting out, the model is usually easier to understand if\\nyou keep clear the distinction between names and objects. For example, when we say\\nthis to assign a variable a value:\\n\\n>>> a = 3                # Assign a name to an object\\n\\nat least conceptually, Python will perform three distinct steps to carry out the request.\\nThese steps reflect the operation of all assignments in the Python language:\\n\\n1. Create an object to represent the value 3.\\n2. Create the variable a, if it does not yet exist.\\n3. Link the variable a to the new object 3.\\n\\nThe net result will be a structure inside Python that resembles Figure 6-1. As sketched, \\nvariables and objects are stored in different parts of memory and are associated by links\\n(the link is shown as a pointer in the figure). Variables always link to objects and never\\nto other variables, but larger objects may link to other objects (for instance, a list object\\nhas links to the objects it contains).\\n\\n176 | Chapter 6:\\u2002The Dynamic Typing Interlude\\n\\n\\x0cFigure 6-1. Names and objects after running the assignment a = 3. Variable a becomes a reference to\\nthe object 3. Internally, the variable is really a pointer to the object’s memory space created by running\\nthe literal expression 3.\\n\\nThese links from variables to objects are called references in Python—that is, a reference\\nis a kind of association, implemented as a pointer in memory.1 Whenever the variables\\nare  later  used  (i.e.,  referenced),  Python  automatically  follows  the  variable-to-object\\nlinks. This is all simpler than the terminology may imply. In concrete terms:\\n\\n• Variables are entries in a system table, with spaces for links to objects.\\n• Objects are pieces of allocated memory, with enough space to represent the values\\n\\nfor which they stand.\\n\\n• References are automatically followed pointers from variables to objects.\\n\\nAt least conceptually, each time you generate a new value in your script by running an\\nexpression, Python creates a new object (i.e., a chunk of memory) to represent that\\nvalue. As an optimization, Python internally caches and reuses certain kinds of un-\\nchangeable objects, such as small integers and strings (each 0 is not really a new piece\\nof memory—more on this caching behavior later). But from a logical perspective, it\\nworks as though each expression’s result value is a distinct object and each object is a\\ndistinct piece of memory.\\nTechnically speaking, objects have more structure than just enough space to represent\\ntheir values. Each object also has two standard header fields: a type designator used to \\nmark the type of the object, and a reference counter used to determine when it’s OK to\\nreclaim the object. To understand how these two header fields factor into the model,\\nwe need to move on.\\n\\nTypes Live with Objects, Not Variables\\nTo see how object types come into play, watch what happens if we assign a variable\\nmultiple times:\\n\\n1. Readers with a background in C may find Python references similar to C pointers (memory addresses).\\nIn fact, references are implemented as pointers, and they often serve the same roles, especially with objects\\nthat can be changed in place (more on this later). However, because references are always automatically\\ndereferenced when used, you can never actually do anything useful with a reference itself; this is a feature\\nthat eliminates a vast category of C bugs. But you can think of Python references as C “void*” pointers,\\nwhich are automatically followed whenever used.\\n\\nThe Case of the Missing Declaration Statements\\n\\n| 177\\n\\n\\x0c>>> a = 3             # It\\'s an integer\\n>>> a = \\'spam\\'        # Now it\\'s a string\\n>>> a = 1.23          # Now it\\'s a floating point\\n\\nThis isn’t typical Python code, but it does work—a starts out as an integer, then be-\\ncomes a string, and finally becomes a floating-point number. This example tends to\\nlook especially odd to ex-C programmers, as it appears as though the type of a changes\\nfrom integer to string when we say a = \\'spam\\'.\\nHowever, that’s not really what’s happening. In Python, things work more simply.\\nNames have no types; as stated earlier, types live with objects, not names. In the pre-\\nceding listing, we’ve simply changed a to reference different objects. Because variables\\nhave no type, we haven’t actually changed the type of the variable a; we’ve simply made\\nthe variable reference a different type of object. In fact, again, all we can ever say about\\na variable in Python is that it references a particular object at a particular point in time.\\nObjects, on the other hand, know what type they are—each object contains a header\\nfield that tags the object with its type. The integer object 3, for example, will contain\\nthe value 3, plus a designator that tells Python that the object is an integer (strictly\\nspeaking, a pointer to an object called int, the name of the integer type). The type\\ndesignator of the  \\'spam\\' string object points to the string type (called  str) instead.\\nBecause objects know their types, variables don’t have to.\\nTo recap, types are associated with objects in Python, not with variables. In typical\\ncode, a given variable usually will reference just one kind of object. Because this isn’t\\na requirement, though, you’ll find that Python code tends to be much more flexible\\nthan you may be accustomed to—if you use Python well, your code might work on\\nmany types automatically.\\nI  mentioned  that  objects  have  two  header  fields,  a  type  designator  and  a  reference\\ncounter. To understand the latter of these, we need to move on and take a brief look\\nat what happens at the end of an object’s life.\\n\\nObjects Are Garbage-Collected\\nIn the prior section’s listings, we assigned the variable a to different types of objects in\\neach assignment. But when we reassign a variable, what happens to the value it was\\npreviously referencing? For example, after the following statements, what happens to\\nthe object 3?\\n>>> a = 3\\n>>> a = \\'spam\\'\\n\\nThe answer is that in Python, whenever a name is assigned to a new object, the space\\nheld by the prior object is reclaimed if it is not referenced by any other name or object.\\nThis automatic reclamation of objects’ space is known as garbage collection, and makes\\nlife much simpler for programmers of languages like Python that support it.\\n\\n178 | Chapter 6:\\u2002The Dynamic Typing Interlude\\n\\n\\x0cTo illustrate, consider the following example, which sets the name x to a different object\\non each assignment:\\n\\n>>> x = 42\\n>>> x = \\'shrubbery\\'          # Reclaim 42 now (unless referenced elsewhere)\\n>>> x = 3.1415               # Reclaim \\'shrubbery\\' now\\n>>> x = [1, 2, 3]            # Reclaim 3.1415 now\\n\\nFirst, notice that x is set to a different type of object each time. Again, though this is\\nnot really the case, the effect is as though the type of x is changing over time. Remember,\\nin Python types live with objects, not names. Because names are just generic references\\nto objects, this sort of code works naturally.\\nSecond, notice that references to objects are discarded along the way. Each time x is\\nassigned to a new object, Python reclaims the prior object’s space. For instance, when\\nit is assigned the string \\'shrubbery\\', the object 42 is immediately reclaimed (assuming\\nit is not referenced anywhere else)—that is, the object’s space is automatically thrown\\nback into the free space pool, to be reused for a future object.\\nInternally, Python accomplishes this feat by keeping a counter in every object that keeps\\ntrack of the number of references currently pointing to that object. As soon as (and\\nexactly when) this counter drops to zero, the object’s memory space is automatically\\nreclaimed. In the preceding listing, we’re assuming that each time x is assigned to a new\\nobject, the prior object’s reference counter drops to zero, causing it to be reclaimed.\\nThe most immediately tangible benefit of garbage collection is that it means you can\\nuse objects liberally without ever needing to allocate or free up space in your script.\\nPython  will  clean  up  unused  space  for  you  as  your  program  runs.  In  practice,  this\\neliminates a substantial amount of bookkeeping code required in lower-level languages\\nsuch as C and C++.\\n\\nMore on Python Garbage Collection\\n\\nTechnically speaking, Python’s garbage collection is based mainly upon reference coun-\\nters, as described here; however, it also has a component that detects and reclaims\\nobjects with cyclic references in time. This component can be disabled if you’re sure\\nthat your code doesn’t create cycles, but it is enabled by default.\\n\\nCircular references are a classic issue in reference count garbage collectors. Because\\nreferences are implemented as pointers, it’s possible for an object to reference itself, or\\nreference another object that does. For example, exercise 3 at the end of Part I and its\\nsolution in Appendix D show how to create a cycle easily by embedding a reference to\\na list within itself (e.g., L.append(L)). The same phenomenon can occur for assignments\\nto attributes of objects created from user-defined classes. Though relatively rare, be-\\ncause the reference counts for such objects never drop to zero, they must be treated\\nspecially.\\nFor more details on Python’s cycle detector, see the documentation for the gc module\\nin Python’s library manual. The best news here is that garbage-collection-based mem-\\nory management is implemented for you in Python, by people highly skilled at the task.\\n\\nThe Case of the Missing Declaration Statements\\n\\n| 179\\n\\n\\x0cAlso note that this chapter’s description of Python’s garbage collector applies to the\\nstandard Python (a.k.a. CPython) only; Chapter 2’s alternative implementations such\\nas Jython, IronPython, and PyPy may use different schemes, though the net effect in\\nall is similar—unused space is reclaimed for you automatically, if not always as imme-\\ndiately.\\n\\nShared References\\nSo far, we’ve seen what happens as a single variable is assigned references to objects.\\nNow let’s introduce another variable into our interaction and watch what happens to\\nits names and objects:\\n\\n>>> a = 3\\n>>> b = a\\n\\nTyping these two statements generates the scene captured in Figure 6-2. The second\\ncommand causes Python to create the variable b; the variable a is being used and not\\nassigned here, so it is replaced with the object it references (3), and b is made to reference\\nthat object. The net effect is that the variables a and b wind up referencing the same\\nobject (that is, pointing to the same chunk of memory).\\n\\nFigure 6-2. Names and objects after next running the assignment b = a. Variable b becomes a reference\\nto the object 3. Internally, the variable is really a pointer to the object’s memory space created by\\nrunning the literal expression 3.\\n\\nThis scenario in Python—with multiple names referencing the same object—is usually\\ncalled a shared reference (and sometimes just a shared object). Note that the names a\\nand b are not linked to each other directly when this happens; in fact, there is no way\\nto ever link a variable to another variable in Python. Rather, both variables point to the\\nsame object via their references.\\nNext, suppose we extend the session with one more statement:\\n\\n>>> a = 3\\n>>> b = a\\n>>> a = \\'spam\\'\\n\\nAs with all Python assignments, this statement simply makes a new object to represent\\nthe string value \\'spam\\' and sets a to reference this new object. It does not, however,\\n\\n180 | Chapter 6:\\u2002The Dynamic Typing Interlude\\n\\n\\x0cFigure 6-3. Names and objects after finally running the assignment a = ‘spam’. Variable a references\\nthe new object (i.e., piece of memory) created by running the literal expression ‘spam’, but variable b\\nstill refers to the original object 3. Because this assignment is not an in-place change to the object 3,\\nit changes only variable a, not b.\\n\\nchange the value of b; b still references the original object, the integer 3. The resulting\\nreference structure is shown in Figure 6-3.\\nThe same sort of thing would happen if we changed b to \\'spam\\' instead—the assignment\\nwould change only b, not a. This behavior also occurs if there are no type differences\\nat all. For example, consider these three statements:\\n\\n>>> a = 3\\n>>> b = a\\n>>> a = a + 2\\n\\nIn this sequence, the same events transpire. Python makes the variable a reference the\\nobject 3 and makes b reference the same object as a, as in Figure 6-2; as before, the last\\nassignment then sets a to a completely different object (in this case, the integer 5, which\\nis the result of the + expression). It does not change b as a side effect. In fact, there is\\nno way to ever overwrite the value of the object 3—as introduced in Chapter 4, integers\\nare immutable and thus can never be changed in place.\\nOne way to think of this is that, unlike in some languages, in Python variables are always\\npointers to objects, not labels of changeable memory areas: setting a variable to a new\\nvalue does not alter the original object, but rather causes the variable to reference an\\nentirely different object. The net effect is that assignment to a variable itself can impact\\nonly the single variable being assigned. When mutable objects and in-place changes\\nenter the equation, though, the picture changes somewhat; to see how, let’s move on.\\n\\nShared References and In-Place Changes\\nAs you’ll see later in this part’s chapters, there are objects and operations that perform\\nin-place object changes—Python’s mutable types, including lists, dictionaries, and sets.\\nFor instance, an assignment to an offset in a list actually changes the list object itself in\\nplace, rather than generating a brand-new list object.\\n\\nShared References\\n\\n| 181\\n\\n\\x0cThough you must take it somewhat on faith at this point in the book, this distinction\\ncan matter much in your programs. For objects that support such in-place changes,\\nyou need to be more aware of shared references, since a change from one name may\\nimpact others. Otherwise, your objects may seem to change for no apparent reason.\\nGiven that all assignments are based on references (including function argument pass-\\ning), it’s a pervasive potential.\\nTo illustrate, let’s take another look at the list objects introduced in Chapter 4. Recall\\nthat lists, which do support in-place assignments to positions, are simply collections\\nof other objects, coded in square brackets:\\n\\n>>> L1 = [2, 3, 4]\\n>>> L2 = L1\\n\\nL1 here is a list containing the objects 2, 3, and 4. Items inside a list are accessed by their\\npositions, so L1[0] refers to object 2, the first item in the list L1. Of course, lists are also\\nobjects in their own right, just like integers and strings. After running the two prior\\nassignments, L1 and L2 reference the same shared object, just like a and b in the prior\\nexample (see Figure 6-2). Now say that, as before, we extend this interaction to say the\\nfollowing:\\n\\n>>> L1 = 24\\n\\nThis assignment simply sets L1 to a different object; L2 still references the original list.\\nIf we change this statement’s syntax slightly, however, it has a radically different effect:\\n\\n>>> L1 = [2, 3, 4]        # A mutable object\\n>>> L2 = L1               # Make a reference to the same object\\n>>> L1[0] = 24            # An in-place change\\n\\n>>> L1                    # L1 is different\\n[24, 3, 4]\\n>>> L2                    # But so is L2!\\n[24, 3, 4]\\n\\nReally, we haven’t changed L1 itself here; we’ve changed a component of the object that\\nL1 references. This sort of change overwrites part of the list object’s value in place.\\nBecause the list object is shared by (referenced from) other variables, though, an in-\\nplace change like this doesn’t affect only L1—that is, you must be aware that when you\\nmake such changes, they can impact other parts of your program. In this example, the\\neffect shows up in L2 as well because it references the same object as L1. Again, we\\nhaven’t actually changed L2, either, but its value will appear different because it refers\\nto an object that has been overwritten in place.\\nThis behavior only occurs for mutable objects that support in-place changes, and is\\nusually what you want, but you should be aware of how it works, so that it’s expected.\\nIt’s also just the default: if you don’t want such behavior, you can request that Python\\ncopy objects instead of making references. There are a variety of ways to copy a list,\\nincluding using the built-in list function and the standard library copy module. Perhaps\\n\\n182 | Chapter 6:\\u2002The Dynamic Typing Interlude\\n\\n\\x0cthe most common way is to slice from start to finish (see Chapter 4 and Chapter 7 for\\nmore on slicing):\\n\\n>>> L1 = [2, 3, 4]\\n>>> L2 = L1[:]            # Make a copy of L1 (or list(L1), copy.copy(L1), etc.)\\n>>> L1[0] = 24\\n\\n>>> L1\\n[24, 3, 4]\\n>>> L2                    # L2 is not changed\\n[2, 3, 4]\\n\\nHere, the change made through L1 is not reflected in L2 because L2 references a copy\\nof the object L1 references, not the original; that is, the two variables point to different\\npieces of memory.\\nNote that this slicing technique won’t work on the other major mutable core types,\\ndictionaries  and  sets,  because  they  are  not  sequences—to  copy  a  dictionary  or  set,\\ninstead use their X.copy() method call (lists have one as of Python 3.3 as well), or pass\\nthe original object to their type names, dict and set. Also, note that the standard library\\ncopy module has a call for copying any object type generically, as well as a call for\\ncopying nested object structures—a dictionary with nested lists, for example:\\n\\nimport copy\\nX = copy.copy(Y)          # Make top-level \"shallow\" copy of any object Y\\nX = copy.deepcopy(Y)      # Make deep copy of any object Y: copy all nested parts\\n\\nWe’ll explore lists and dictionaries in more depth, and revisit the concept of shared\\nreferences and copies, in Chapter 8 and Chapter 9. For now, keep in mind that objects\\nthat can be changed in place (that is, mutable objects) are always open to these kinds\\nof effects in any code they pass through. In Python, this includes lists, dictionaries, sets,\\nand some objects defined with class statements. If this is not the desired behavior, you\\ncan simply copy your objects as needed.\\n\\nShared References and Equality\\nIn the interest of full disclosure, I should point out that the garbage-collection behavior\\ndescribed earlier in this chapter may be more conceptual than literal for certain types.\\nConsider these statements:\\n\\n>>> x = 42\\n>>> x = \\'shrubbery\\'       # Reclaim 42 now?\\n\\nBecause Python caches and reuses small integers and small strings, as mentioned earlier,\\nthe object 42 here is probably not literally reclaimed; instead, it will likely remain in a\\nsystem table to be reused the next time you generate a 42 in your code. Most kinds of\\nobjects, though, are reclaimed immediately when they are no longer referenced; for\\nthose that are not, the caching mechanism is irrelevant to your code.\\nFor instance, because of Python’s reference model, there are two different ways to check\\nfor equality in a Python program. Let’s create a shared reference to demonstrate:\\n\\nShared References\\n\\n| 183\\n\\n\\x0c>>> L = [1, 2, 3]\\n>>> M = L                 # M and L reference the same object\\n>>> L == M                # Same values\\nTrue\\n>>> L is M                # Same objects\\nTrue\\n\\nThe first technique here, the == operator, tests whether the two referenced objects have\\nthe same values; this is the method almost always used for equality checks in Python.\\nThe second method, the is operator, instead tests for object identity—it returns True\\nonly if both names point to the exact same object, so it is a much stronger form of\\nequality testing and is rarely applied in most programs.\\nReally, is simply compares the pointers that implement references, and it serves as a\\nway to detect shared references in your code if needed. It returns False if the names\\npoint to equivalent but different objects, as is the case when we run two different literal\\nexpressions:\\n\\n>>> L = [1, 2, 3]\\n>>> M = [1, 2, 3]         # M and L reference different objects\\n>>> L == M                # Same values\\nTrue\\n>>> L is M                # Different objects\\nFalse\\n\\nNow, watch what happens when we perform the same operations on small numbers:\\n\\n>>> X = 42\\n>>> Y = 42                # Should be two different objects\\n>>> X == Y\\nTrue\\n>>> X is Y                # Same object anyhow: caching at work!\\nTrue\\n\\nIn this interaction, X and Y should be == (same value), but not is (same object) because\\nwe  ran  two  different  literal  expressions  (42).  Because  small  integers  and  strings  are\\ncached and reused, though, is tells us they reference the same single object.\\nIn fact, if you really want to look under the hood, you can always ask Python how many\\nreferences there are to an object: the getrefcount function in the standard sys module\\nreturns the object’s reference count. When I ask about the integer object 1 in the IDLE\\nGUI, for instance, it reports 647 reuses of this same object (most of which are in IDLE’s\\nsystem  code,  not  mine,  though  this  returns  173  outside  IDLE  so  Python  must  be\\nhoarding 1s as well):\\n\\n>>> import sys\\n>>> sys.getrefcount(1)    # 647 pointers to this shared piece of memory\\n647\\n\\nThis object caching and reuse is irrelevant to your code (unless you run the is check!).\\nBecause you cannot change immutable numbers or strings in place, it doesn’t matter\\nhow many references there are to the same object—every reference will always see the\\n\\n184 | Chapter 6:\\u2002The Dynamic Typing Interlude\\n\\n\\x0csame, unchanging value. Still, this behavior reflects one of the many ways Python op-\\ntimizes its model for execution speed.\\n\\nDynamic Typing Is Everywhere\\nOf course, you don’t really need to draw name/object diagrams with circles and arrows\\nto use Python. When you’re starting out, though, it sometimes helps you understand\\nunusual cases if you can trace their reference structures as we’ve done here. If a mutable\\nobject changes out from under you when passed around your program, for example,\\nchances are you are witnessing some of this chapter’s subject matter firsthand.\\nMoreover, even if dynamic typing seems a little abstract at this point, you probably will\\ncare about it eventually. Because everything seems to work by assignment and refer-\\nences in Python, a basic understanding of this model is useful in many different con-\\ntexts. As you’ll see, it works the same in assignment statements, function arguments,\\nfor loop variables, module imports, class attributes, and more. The good news is that\\nthere is just one assignment model in Python; once you get a handle on dynamic typing,\\nyou’ll find that it works the same everywhere in the language.\\nAt the most practical level, dynamic typing means there is less code for you to write.\\nJust  as  importantly,  though,  dynamic  typing  is  also  the  root  of  Python’s  polymor-\\nphism, a concept we introduced in Chapter 4 and will revisit again later in this book.\\nBecause we do not constrain types in Python code, it is both concise and highly flexible.\\nAs you’ll see, when used well, dynamic typing—and the polymorphism it implies—\\nproduces code that automatically adapts to new requirements as your systems evolve.\\n\\n“Weak” References\\n\\nYou may occasionally see the term “weak reference” in the Python world. This is a\\nsomewhat advanced tool, but is related to the reference model we’ve explored here,\\nand like the is operator, can’t really be understood without it.\\nIn short, a weak reference, implemented by the weakref standard library module, is a\\nreference to an object that does not by itself prevent the referenced object from being\\ngarbage-collected. If the last remaining references to an object are weak references, the\\nobject is reclaimed and the weak references to it are automatically deleted (or otherwise\\nnotified).\\n\\nThis can be useful in dictionary-based caches of large objects, for example; otherwise,\\nthe cache’s reference alone would keep the object in memory indefinitely. Still, this is\\nreally just a special-case extension to the reference model. For more details, see Python’s\\nlibrary manual.\\n\\nDynamic Typing Is Everywhere | 185\\n\\n\\x0cChapter Summary\\nThis chapter took a deeper look at Python’s dynamic typing model—that is, the way\\nthat Python keeps track of object types for us automatically, rather than requiring us\\nto code declaration statements in our scripts. Along the way, we learned how variables\\nand objects are associated by references in Python; we also explored the idea of garbage\\ncollection, learned how shared references to objects can affect multiple variables, and\\nsaw how references impact the notion of equality in Python.\\nBecause there is just one assignment model in Python, and because assignment pops\\nup everywhere in the language, it’s important that you have a handle on the model\\nbefore moving on. The following quiz should help you review some of this chapter’s\\nideas. After that, we’ll resume our core object tour in the next chapter, with strings.\\n\\nTest Your Knowledge: Quiz\\n1. Consider the following three statements. Do they change the value printed for A?\\n\\nA = \"spam\"\\nB = A\\nB = \"shrubbery\"\\n\\n2. Consider these three statements. Do they change the printed value of A?\\n\\nA = [\"spam\"]\\nB = A\\nB[0] = \"shrubbery\"\\n\\n3. How about these—is A changed now?\\n\\nA = [\"spam\"]\\nB = A[:]\\nB[0] = \"shrubbery\"\\n\\nTest Your Knowledge: Answers\\n1. No: A still prints as \"spam\". When B is assigned to the string \"shrubbery\", all that\\nhappens is that the variable B is reset to point to the new string object. A and B\\ninitially share (i.e., reference/point to) the same single string object \"spam\", but two\\nnames are never linked together in Python. Thus, setting B to a different object has\\nno effect on A. The same would be true if the last statement here were B = B +\\n\\'shrubbery\\', by the way—the concatenation would make a new object for its result,\\nwhich would then be assigned to B only. We can never overwrite a string (or num-\\nber, or tuple) in place, because strings are immutable.\\n\\n2. Yes: A now prints as [\"shrubbery\"]. Technically, we haven’t really changed either\\nA or B; instead, we’ve changed part of the object they both reference (point to) by\\noverwriting that object in place through the variable B. Because A references the\\nsame object as B, the update is reflected in A as well.\\n\\n186 | Chapter 6:\\u2002The Dynamic Typing Interlude\\n\\n\\x0c3. No: A still prints as [\"spam\"]. The in-place assignment through B has no effect this\\ntime because the slice expression made a copy of the list object before it was as-\\nsigned to  B. After the second assignment statement, there are two different list\\nobjects that have the same value (in Python, we say they are ==, but not is). The\\nthird statement changes the value of the list object pointed to by B, but not that\\npointed to by A.\\n\\nTest Your Knowledge: Answers\\n\\n| 187\\n\\n\\x0c\\x0cCHAPTER 7\\nString Fundamentals\\n\\nSo far, we’ve studied numbers and explored Python’s dynamic typing model. The next\\nmajor type on our in-depth core object tour is the Python string—an ordered collection\\nof characters used to store and represent text- and bytes-based information. We looked\\nbriefly at strings in Chapter 4. Here, we will revisit them in more depth, filling in some\\nof the details we skipped earlier.\\n\\nThis Chapter’s Scope\\nBefore we get started, I also want to clarify what we won’t be covering here. Chap-\\nter 4 briefly previewed Unicode strings and files—tools for dealing with non-ASCII text.\\nUnicode is a key tool for some programmers, especially those who work in the Internet\\ndomain. It can pop up, for example, in web pages, email content and headers, FTP\\ntransfers, GUI APIs, directory tools, and HTML, XML and JSON text.\\nAt the same time, Unicode can be a heavy topic for programmers just starting out, and\\nmany (or most) of the Python programmers I meet today still do their jobs in blissful\\nignorance of the entire topic. In light of that, this book relegates most of the Unicode\\nstory to Chapter 37 of its Advanced Topics part as optional reading, and focuses on\\nstring basics here.\\nThat is, this chapter tells only part of the string story in Python—the part that most\\nscripts use and most programmers need to know. It explores the fundamental str string\\ntype, which handles ASCII text, and works the same regardless of which version of\\nPython you use. Despite this intentionally limited scope, because str also handles Uni-\\ncode in Python 3.X, and the separate unicode type works almost identically to str in\\n2.X, everything we learn here will apply directly to Unicode processing too.\\n\\nUnicode: The Short Story\\nFor readers who do care about Unicode, I’d like to also provide a quick summary of its\\nimpacts and pointers for further study. From a formal perspective, ASCII is a simple\\n\\n189\\n\\n\\x0cform of Unicode text, but just one of many possible encodings and alphabets. Text\\nfrom non-English-speaking sources may use very different letters, and may be encoded\\nvery differently when stored in files.\\nAs we saw in Chapter 4, Python addresses this by distinguishing between text and\\nbinary data, with distinct string object types and file interfaces for each. This support\\nvaries per Python line:\\n\\n• In Python 3.X there are three string types: str is used for Unicode text (including\\nASCII), bytes is used for binary data (including encoded text), and bytearray is a\\nmutable variant of bytes. Files work in two modes: text, which represents content \\nas str and implements Unicode encodings, and binary, which deals in raw bytes\\nand does no data translation.\\n\\n• In Python 2.X, unicode strings represent Unicode text, str strings handle both 8-\\nbit text and binary data, and bytearray is available in 2.6 and later as a back-port\\nfrom 3.X. Normal files’ content is simply bytes represented as str, but a codecs\\nmodule opens Unicode text files, handles encodings, and represents content as\\nunicode objects.\\n\\nDespite such version differences, if and when you do need to care about Unicode you’ll\\nfind that it is a relatively minor extension—once text is in memory, it’s a Python string\\nof characters that supports all the basics we’ll study in this chapter. In fact, the primary\\ndistinction of Unicode often lies in the translation (a.k.a. encoding) step required to\\nmove it to and from files. Beyond that, it’s largely just string processing.\\nAgain, though, because most programmers don’t need to come to grips with Unicode\\ndetails up front, I’ve moved most of them to Chapter 37. When you’re ready to learn\\nabout these more advanced string concepts, I encourage you to see both their preview\\nin Chapter 4 and the full Unicode and bytes disclosure in Chapter 37 after reading the\\nstring fundamentals material here.\\nFor this chapter, we’ll focus on the basic string type and its operations. As you’ll find,\\nthe techniques we’ll study here also apply directly to the more advanced string types\\nin Python’s toolset.\\n\\nString Basics\\nFrom a functional perspective, strings can be used to represent just about anything that\\ncan be encoded as text or bytes. In the text department, this includes symbols and\\nwords (e.g., your name), contents of text files loaded into memory, Internet addresses,\\nPython source code, and so on. Strings can also be used to hold the raw bytes used for\\nmedia files and network transfers, and both the encoded and decoded forms of non-\\nASCII Unicode text used in internationalized programs.\\nYou may have used strings in other languages, too. Python’s strings serve the same role\\nas character arrays in languages such as C, but they are a somewhat higher-level tool\\n\\n190 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cthan arrays. Unlike in C, in Python, strings come with a powerful set of processing\\ntools. Also unlike languages such as C, Python has no distinct type for individual char-\\nacters; instead, you just use one-character strings.\\nStrictly speaking, Python strings are categorized as immutable sequences, meaning that\\nthe characters they contain have a left-to-right positional order and that they cannot\\nbe changed in place. In fact, strings are the first representative of the larger class of\\nobjects called sequences that we will study here. Pay special attention to the sequence\\noperations introduced in this chapter, because they will work the same on other se-\\nquence types we’ll explore later, such as lists and tuples.\\nTable 7-1 previews common string literals and operations we will discuss in this chap-\\nter.  Empty  strings  are  written  as  a  pair  of  quotation  marks  (single  or  double)  with\\nnothing in between, and there are a variety of ways to code strings. For processing,\\nstrings support expression operations such as concatenation (combining strings), slic-\\ning (extracting sections), indexing (fetching by offset), and so on. Besides expressions,\\nPython also provides a set of string methods that implement common string-specific\\ntasks,  as  well  as  modules  for  more  advanced  text-processing  tasks  such  as  pattern\\nmatching. We’ll explore all of these later in the chapter.\\n\\nTable 7-1. Common string literals and operations\\n\\nOperation\\nS = \\'\\'\\n\\nS = \"spam\\'s\"\\n\\nS = \\'s\\\\np\\\\ta\\\\x00m\\'\\n\\nS = \"\"\"...multiline...\"\"\"\\n\\nS = r\\'\\\\temp\\\\spam\\'\\n\\nB = b\\'sp\\\\xc4m\\'\\n\\nU = u\\'sp\\\\u00c4m\\'\\n\\nS1 + S2\\n\\nS * 3\\n\\nS[i]\\n\\nS[i:j]\\n\\nlen(S)\\n\\nInterpretation\\nEmpty string\\nDouble quotes, same as single\\nEscape sequences\\nTriple-quoted block strings\\nRaw strings (no escapes)\\nByte strings in 2.6, 2.7, and 3.X (Chapter 4, Chapter 37)\\nUnicode strings in 2.X and 3.3+ (Chapter 4, Chapter 37)\\nConcatenate, repeat\\n\\nIndex, slice, length\\n\\n\"a %s parrot\" % kind\\n\\n\"a {0} parrot\".format(kind)\\n\\nS.find(\\'pa\\')\\n\\nS.rstrip()\\n\\nS.replace(\\'pa\\', \\'xx\\')\\n\\nS.split(\\',\\')\\n\\nString formatting expression\\nString formatting method in 2.6, 2.7, and 3.X\\nString methods (see ahead for all 43): search,\\nremove whitespace,\\nreplacement,\\nsplit on delimiter,\\n\\nString Basics\\n\\n| 191\\n\\n\\x0cInterpretation\\ncontent test,\\ncase conversion,\\nend test,\\ndelimiter join,\\nUnicode encoding,\\nUnicode decoding, etc. (see Table 7-3)\\nIteration, membership\\n\\nOperation\\nS.isdigit()\\n\\nS.lower()\\n\\nS.endswith(\\'spam\\')\\n\\n\\'spam\\'.join(strlist)\\n\\nS.encode(\\'latin-1\\')\\n\\nB.decode(\\'utf8\\')\\n\\nfor x in S: print(x)\\n\\n\\'spam\\' in S\\n\\n[c * 2 for c in S]\\n\\nmap(ord, S)\\n\\nre.match(\\'sp(.*)am\\', line)\\n\\nPattern matching: library module\\n\\nBeyond the core set of string tools in Table 7-1, Python also supports more advanced\\npattern-based string processing with the standard library’s re (for “regular expression”)\\nmodule, introduced in Chapter 4 and Chapter 36, and even higher-level text processing\\ntools such as XML parsers (discussed briefly in Chapter 37). This book’s scope, though,\\nis focused on the fundamentals represented by Table 7-1.\\nTo cover the basics, this chapter begins with an overview of string literal forms and\\nstring expressions, then moves on to look at more advanced tools such as string meth-\\nods and formatting. Python comes with many string tools, and we won’t look at them\\nall here; the complete story is chronicled in the Python library manual and reference\\nbooks. Our goal here is to explore enough commonly used tools to give you a repre-\\nsentative sample; methods we won’t see in action here, for example, are largely anal-\\nogous to those we will.\\n\\nString Literals\\nBy and large, strings are fairly easy to use in Python. Perhaps the most complicated\\nthing about them is that there are so many ways to write them in your code:\\n\\n• Single quotes: \\'spa\"m\\'\\n• Double quotes: \"spa\\'m\"\\n• Triple quotes: \\'\\'\\'... spam ...\\'\\'\\', \"\"\"... spam ...\"\"\"\\n• Escape sequences: \"s\\\\tp\\\\na\\\\0m\"\\n• Raw strings: r\"C:\\\\new\\\\test.spm\"\\n• Bytes literals in 3.X and 2.6+ (see Chapter 4, Chapter 37): b\\'sp\\\\x01am\\'\\n• Unicode literals in 2.X and 3.3+ (see Chapter 4, Chapter 37): u\\'eggs\\\\u0020spam\\'\\n\\n192 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cThe single- and double-quoted forms are by far the most common; the others serve\\nspecialized roles, and we’re postponing further discussion of the last two advanced\\nforms until Chapter 37. Let’s take a quick look at all the other options in turn.\\n\\nSingle- and Double-Quoted Strings Are the Same\\nAround Python strings, single- and double-quote characters are interchangeable. That\\nis, string literals can be written enclosed in either two single or two double quotes—\\nthe two forms work the same and return the same type of object. For example, the\\nfollowing two strings are identical, once coded:\\n\\n>>> \\'shrubbery\\', \"shrubbery\"\\n(\\'shrubbery\\', \\'shrubbery\\')\\n\\nThe reason for supporting both is that it allows you to embed a quote character of the\\nother variety inside a string without escaping it with a backslash. You may embed a\\nsingle-quote character in a string enclosed in double-quote characters, and vice versa:\\n\\n>>> \\'knight\"s\\', \"knight\\'s\"\\n(\\'knight\"s\\', \"knight\\'s\")\\n\\nThis book generally prefers to use single quotes around strings just because they are\\nmarginally easier to read, except in cases where a single quote is embedded in the string.\\nThis is a purely subjective style choice, but Python displays strings this way too and\\nmost Python programmers do the same today, so you probably should too.\\nNote  that  the  comma  is  important  here.  Without  it,  Python  automatically  concate-\\nnates adjacent string literals in any expression, although it is almost as simple to add a\\n+  operator  between  them  to  invoke  concatenation  explicitly  (as  we’ll  see  in  Chap-\\nter 12, wrapping this form in parentheses also allows it to span multiple lines):\\n\\n>>> title = \"Meaning \" \\'of\\' \" Life\"        # Implicit concatenation\\n>>> title\\n\\'Meaning of Life\\'\\n\\nAdding commas between these strings would result in a tuple, not a string. Also notice\\nin all of these outputs that Python prints strings in single quotes unless they embed\\none. If needed, you can also embed quote characters by escaping them with backslashes:\\n\\n>>> \\'knight\\\\\\'s\\', \"knight\\\\\"s\"\\n(\"knight\\'s\", \\'knight\"s\\')\\n\\nTo understand why, you need to know how escapes work in general.\\n\\nEscape Sequences Represent Special Characters\\nThe last example embedded a quote inside a string by preceding it with a backslash.\\nThis is representative of a general pattern in strings: backslashes are used to introduce\\nspecial character codings known as escape sequences.\\n\\nString Literals\\n\\n| 193\\n\\n\\x0cEscape sequences let us embed characters in strings that cannot easily be typed on a\\nkeyboard. The character \\\\, and one or more characters following it in the string literal,\\nare replaced with a single character in the resulting string object, which has the binary\\nvalue specified by the escape sequence. For example, here is a five-character string that\\nembeds a newline and a tab:\\n\\n>>> s = \\'a\\\\nb\\\\tc\\'\\n\\nThe two characters \\\\n stand for a single character—the binary value of the newline\\ncharacter in your character set (in ASCII, character code 10). Similarly, the sequence\\n\\\\t is replaced with the tab character. The way this string looks when printed depends\\non how you print it. The interactive echo shows the special characters as escapes, but\\nprint interprets them instead:\\n\\n>>> s\\n\\'a\\\\nb\\\\tc\\'\\n>>> print(s)\\na\\nb       c\\n\\nTo be completely sure how many actual characters are in this string, use the built-in\\nlen function—it returns the actual number of characters in a string, regardless of how\\nit is coded or displayed:\\n\\n>>> len(s)\\n5\\n\\nThis string is five characters long: it contains an ASCII a, a newline character, an ASCII\\nb, and so on.\\n\\nIf  you’re  accustomed  to  all-ASCII  text,  it’s  tempting  to  think  of  this\\nresult  as  meaning  5  bytes  too,  but  you  probably  shouldn’t.  Really,\\n“bytes” has no meaning in the Unicode world. For one thing, the string\\nobject is probably larger in memory in Python.\\n\\nMore critically, string content and length both reflect code points (iden-\\ntifying numbers) in Unicode-speak, where a single character does not\\nnecessarily map directly to a single byte, either when encoded in files or\\nwhen stored in memory. This mapping might hold true for simple 7-bit\\nASCII text, but even this depends on both the external encoding type\\nand the internal storage scheme used. Under UTF-16, for example, AS-\\nCII characters are multiple bytes in files, and they may be 1, 2, or 4 bytes\\nin memory depending on how Python allocates their space. For other,\\nnon-ASCII text, whose characters’ values might be too large to fit in an\\n8-bit byte, the character-to-byte mapping doesn’t apply at all.\\n\\nIn fact, 3.X defines str strings formally as sequences of Unicode code\\npoints, not bytes, to make this clear. There’s more on how strings are\\nstored internally in Chapter 37 if you care to know. For now, to be safest,\\nthink characters instead of bytes in strings. Trust me on this; as an ex-\\nC programmer, I had to break the habit too!\\n\\n194 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cNote that the original backslash characters in the preceding result are not really stored\\nwith the string in memory; they are used only to describe special character values to be\\nstored in the string. For coding such special characters, Python recognizes a full set of\\nescape code sequences, listed in Table 7-2.\\n\\nTable 7-2. String backslash characters\\n\\nEscape\\n\\\\newline\\n\\n\\\\\\\\\\n\\n\\\\\\'\\n\\n\\\\\"\\n\\n\\\\a\\n\\n\\\\b\\n\\n\\\\f\\n\\n\\\\n\\n\\n\\\\r\\n\\n\\\\t\\n\\n\\\\v\\n\\n\\\\xhh\\n\\n\\\\ooo\\n\\n\\\\0\\n\\n\\\\N{ id }\\n\\n\\\\uhhhh\\n\\n\\\\Uhhhhhhhh\\n\\n\\\\other\\n\\nMeaning\\nIgnored (continuation line)\\nBackslash (stores one \\\\)\\nSingle quote (stores \\')\\nDouble quote (stores \")\\nBell\\nBackspace\\nFormfeed\\nNewline (linefeed)\\nCarriage return\\nHorizontal tab\\nVertical tab\\nCharacter with hex value hh (exactly 2 digits)\\nCharacter with octal value ooo (up to 3 digits)\\nNull: binary 0 character (doesn’t end string)\\nUnicode database ID\\nUnicode character with 16-bit hex value\\nUnicode character with 32-bit hex valuea\\nNot an escape (keeps both \\\\ and other)\\n\\na The \\\\Uhhhh... escape sequence takes exactly eight hexadecimal digits (h); both \\\\u and \\\\U are recognized only in Unicode string literals\\nin 2.X, but can be used in normal strings (which are Unicode) in 3.X. In a 3.X bytes literal, hexadecimal and octal escapes denote the byte\\nwith the given value; in a string literal, these escapes denote a Unicode character with the given code-point value. There is more on Unicode\\nescapes in Chapter 37.\\n\\nSome escape sequences allow you to embed absolute binary values into the characters\\nof a string. For instance, here’s a five-character string that embeds two characters with\\nbinary zero values (coded as octal escapes of one digit):\\n\\n>>> s = \\'a\\\\0b\\\\0c\\'\\n>>> s\\n\\'a\\\\x00b\\\\x00c\\'\\n>>> len(s)\\n5\\n\\nIn Python, a zero (null) character like this does not terminate a string the way a “null\\nbyte” typically does in C. Instead, Python keeps both the string’s length and text in\\nmemory. In fact, no character terminates a string in Python. Here’s a string that is all\\n\\nString Literals\\n\\n| 195\\n\\n\\x0cabsolute binary escape codes—a binary 1 and 2 (coded in octal), followed by a binary\\n3 (coded in hexadecimal):\\n>>> s = \\'\\\\001\\\\002\\\\x03\\'\\n>>> s\\n\\'\\\\x01\\\\x02\\\\x03\\'\\n>>> len(s)\\n3\\n\\nNotice that Python displays nonprintable characters in hex, regardless of how they were\\nspecified. You can freely combine absolute value escapes and the more symbolic escape\\ntypes in Table 7-2. The following string contains the characters “spam”, a tab and\\nnewline, and an absolute zero value character coded in hex:\\n\\n>>> S = \"s\\\\tp\\\\na\\\\x00m\"\\n>>> S\\n\\'s\\\\tp\\\\na\\\\x00m\\'\\n>>> len(S)\\n7\\n>>> print(S)\\ns       p\\na m\\n\\nThis becomes more important to know when you process binary data files in Python.\\nBecause their contents are represented as strings in your scripts, it’s OK to process\\nbinary files that contain any sorts of binary byte values—when opened in binary modes,\\nfiles return strings of raw bytes from the external file (there’s much more on files in\\nChapter 4, Chapter 9, and Chapter 37).\\nFinally, as the last entry in Table 7-2 implies, if Python does not recognize the character\\nafter a \\\\ as being a valid escape code, it simply keeps the backslash in the resulting string:\\n\\n>>> x = \"C:\\\\py\\\\code\"           # Keeps \\\\ literally (and displays it as \\\\\\\\)\\n>>> x\\n\\'C:\\\\\\\\py\\\\\\\\code\\'\\n>>> len(x)\\n10\\n\\nHowever, unless you’re able to commit all of Table 7-2 to memory (and there are ar-\\nguably better uses for your neurons!), you probably shouldn’t rely on this behavior. To\\ncode literal backslashes explicitly such that they are retained in your strings, double\\nthem up (\\\\\\\\ is an escape for one \\\\) or use raw strings; the next section shows how.\\n\\nRaw Strings Suppress Escapes\\nAs  we’ve  seen,  escape  sequences  are  handy  for  embedding  special  character  codes\\nwithin strings. Sometimes, though, the special treatment of backslashes for introducing\\nescapes can lead to trouble. It’s surprisingly common, for instance, to see Python new-\\ncomers in classes trying to open a file with a filename argument that looks something\\nlike this:\\n\\nmyfile = open(\\'C:\\\\new\\\\text.dat\\', \\'w\\')\\n\\n196 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cthinking that they will open a file called text.dat in the directory C:\\\\new. The problem\\nhere is that \\\\n is taken to stand for a newline character, and \\\\t is replaced with a tab.\\nIn effect, the call tries to open a file named C:(newline)ew(tab)ext.dat, with usually less-\\nthan-stellar results.\\nThis is just the sort of thing that raw strings are useful for. If the letter r (uppercase or\\nlowercase) appears just before the opening quote of a string, it turns off the escape\\nmechanism. The result is that Python retains your backslashes literally, exactly as you\\ntype them. Therefore, to fix the filename problem, just remember to add the letter r on\\nWindows:\\n\\nmyfile = open(r\\'C:\\\\new\\\\text.dat\\', \\'w\\')\\n\\nAlternatively, because two backslashes are really an escape sequence for one backslash,\\nyou can keep your backslashes by simply doubling them up:\\n\\nmyfile = open(\\'C:\\\\\\\\new\\\\\\\\text.dat\\', \\'w\\')\\n\\nIn fact, Python itself sometimes uses this doubling scheme when it prints strings with\\nembedded backslashes:\\n\\n>>> path = r\\'C:\\\\new\\\\text.dat\\'\\n>>> path                          # Show as Python code\\n\\'C:\\\\\\\\new\\\\\\\\text.dat\\'\\n>>> print(path)                   # User-friendly format\\nC:\\\\new\\\\text.dat\\n>>> len(path)                     # String length\\n15\\n\\nAs with numeric representation, the default format at the interactive prompt prints\\nresults  as  if  they  were  code,  and  therefore  escapes  backslashes  in  the  output.  The\\nprint statement provides a more user-friendly format that shows that there is actually\\nonly one backslash in each spot. To verify this is the case, you can check the result of\\nthe built-in len function, which returns the number of characters in the string, inde-\\npendent of display formats. If you count the characters in the print(path) output, you’ll\\nsee that there really is just 1 character per backslash, for a total of 15.\\nBesides directory paths on Windows, raw strings are also commonly used for regular\\nexpressions (text pattern matching, supported with the re module introduced in Chap-\\nter 4 and Chapter 37). Also note that Python scripts can usually use forward slashes in\\ndirectory paths on Windows and Unix because Python tries to interpret paths portably\\n(i.e., \\'C:/new/text.dat\\' works when opening files, too). Raw strings are useful if you\\ncode paths using native Windows backslashes, though.\\n\\nString Literals\\n\\n| 197\\n\\n\\x0cDespite its role, even a raw string cannot end in a single backslash, be-\\ncause the backslash escapes the following quote character—you still\\nmust escape the surrounding quote character to embed it in the string.\\nThat is, r\"...\\\\\" is not a valid string literal—a raw string cannot end in\\nan odd number of backslashes. If you need to end a raw string with a\\nsingle backslash, you can use two and slice off the second (r\\'1\\\\nb\\\\tc\\\\\\n\\\\\\'[:-1]), tack one on manually (r\\'1\\\\nb\\\\tc\\' + \\'\\\\\\\\\\'), or skip the raw\\nstring syntax and just double up the backslashes in a normal string (\\'1\\\\\\n\\\\nb\\\\\\\\tc\\\\\\\\\\').  All  three  of  these  forms  create  the  same  eight-character\\nstring containing three backslashes.\\n\\nTriple Quotes Code Multiline Block Strings\\nSo far, you’ve seen single quotes, double quotes, escapes, and raw strings in action.\\nPython also has a triple-quoted string literal format, sometimes called a block string,\\nthat is a syntactic convenience for coding multiline text data. This form begins with\\nthree quotes (of either the single or double variety), is followed by any number of lines\\nof text, and is closed with the same triple-quote sequence that opened it. Single and\\ndouble quotes embedded in the string’s text may be, but do not have to be, escaped—\\nthe string does not end until Python sees three unescaped quotes of the same kind used\\nto start the literal. For example (the “...” here is Python’s prompt for continuation lines\\noutside IDLE: don’t type it yourself):\\n\\n>>> mantra = \"\"\"Always look\\n...   on the bright\\n... side of life.\"\"\"\\n>>>\\n>>> mantra\\n\\'Always look\\\\n  on the bright\\\\nside of life.\\'\\n\\nThis string spans three lines. As we learned in Chapter 3, in some interfaces, the inter-\\nactive prompt changes to ... on continuation lines like this, but IDLE simply drops\\ndown one line; this book shows listings in both forms, so extrapolate as needed. Either\\nway, Python collects all the triple-quoted text into a single multiline string, with em-\\nbedded newline characters (\\\\n) at the places where your code has line breaks. Notice\\nthat, as in the literal, the second line in the result has leading spaces, but the third does\\nnot—what you type is truly what you get. To see the string with the newlines inter-\\npreted, print it instead of echoing:\\n\\n>>> print(mantra)\\nAlways look\\n  on the bright\\nside of life.\\n\\nIn fact, triple-quoted strings will retain all the enclosed text, including any to the right\\nof your code that you might intend as comments. So don’t do this—put your comments\\nabove or below the quoted text, or use the automatic concatenation of adjacent strings\\nmentioned earlier, with explicit newlines if desired, and surrounding parentheses to\\n\\n198 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0callow line spans (again, more on this latter form when we study syntax rules in Chap-\\nter 10 and Chapter 12):\\n\\n>>> menu = \"\"\"spam     # comments here added to string!\\n... eggs               # ditto\\n... \"\"\"\\n>>> menu\\n\\'spam     # comments here added to string!\\\\neggs               # ditto\\\\n\\'\\n\\n>>> menu = (\\n... \"spam\\\\n\"           # comments here ignored\\n... \"eggs\\\\n\"           # but newlines not automatic\\n... )\\n>>> menu\\n\\'spam\\\\neggs\\\\n\\'\\n\\nTriple-quoted strings are useful anytime you need multiline text in your program; for\\nexample, to embed multiline error messages or HTML, XML, or JSON code in your\\nPython source code files. You can embed such blocks directly in your scripts by triple-\\nquoting without resorting to external text files or explicit concatenation and newline\\ncharacters.\\nTriple-quoted  strings  are  also  commonly  used  for  documentation  strings,  which  are\\nstring literals that are taken as comments when they appear at specific points in your\\nfile (more on these later in the book). These don’t have to be triple-quoted blocks, but\\nthey usually are to allow for multiline comments.\\nFinally, triple-quoted strings are also sometimes used as a “horribly hackish” way to\\ntemporarily disable lines of code during development (OK, it’s not really too horrible,\\nand it’s actually a fairly common practice today, but it wasn’t the intent). If you wish\\nto turn off a few lines of code and run your script again, simply put three quotes above\\nand below them, like this:\\n\\nX = 1\\n\"\"\"\\nimport os                            # Disable this code temporarily\\nprint(os.getcwd())\\n\"\"\"\\nY = 2\\n\\nI said this was hackish because Python really might make a string out of the lines of\\ncode disabled this way, but this is probably not significant in terms of performance.\\nFor large sections of code, it’s also easier than manually adding hash marks before each\\nline and later removing them. This is especially true if you are using a text editor that\\ndoes not have support for editing Python code specifically. In Python, practicality often\\nbeats aesthetics.\\n\\nString Literals\\n\\n| 199\\n\\n\\x0cStrings in Action\\nOnce you’ve created a string with the literal expressions we just met, you will almost\\ncertainly want to do things with it. This section and the next two demonstrate string\\nexpressions,  methods,  and  formatting—the  first  line  of  text-processing  tools  in  the\\nPython language.\\n\\nBasic Operations\\nLet’s begin by interacting with the Python interpreter to illustrate the basic string op-\\nerations listed earlier in Table 7-1. You can concatenate strings using the + operator\\nand repeat them using the * operator:\\n\\n% python\\n>>> len(\\'abc\\')            # Length: number of items\\n3\\n>>> \\'abc\\' + \\'def\\'         # Concatenation: a new string\\n\\'abcdef\\'\\n>>> \\'Ni!\\' * 4             # Repetition: like \"Ni!\" + \"Ni!\" + ...\\n\\'Ni!Ni!Ni!Ni!\\'\\n\\nThe len built-in function here returns the length of a string (or any other object with a\\nlength). Formally, adding two string objects with + creates a new string object, with the\\ncontents of its operands joined, and repetition with * is like adding a string to itself a\\nnumber of times. In both cases, Python lets you create arbitrarily sized strings; there’s\\nno need to predeclare anything in Python, including the sizes of data structures—you\\nsimply create string objects as needed and let Python manage the underlying memory\\nspace  automatically  (see  Chapter  6  for  more  on  Python’s  memory  management\\n“garbage collector”).\\nRepetition may seem a bit obscure at first, but it comes in handy in a surprising number\\nof contexts. For example, to print a line of 80 dashes, you can count up to 80, or let\\nPython count for you:\\n\\n>>> print(\\'------- ...more... ---\\')      # 80 dashes, the hard way\\n>>> print(\\'-\\' * 80)                      # 80 dashes, the easy way\\n\\nNotice that operator overloading is at work here already: we’re using the same + and\\n* operators that perform addition and multiplication when using numbers. Python does\\nthe correct operation because it knows the types of the objects being added and mul-\\ntiplied. But be careful: the rules aren’t quite as liberal as you might expect. For instance,\\nPython doesn’t allow you to mix numbers and strings in + expressions: \\'abc\\'+9 raises\\nan error instead of automatically converting 9 to a string.\\nAs shown in the last row in Table 7-1, you can also iterate over strings in loops using\\nfor statements, which repeat actions, and test membership for both characters and\\nsubstrings with the in expression operator, which is essentially a search. For substrings,\\nin is much like the str.find() method covered later in this chapter, but it returns a\\n\\n200 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cBoolean result instead of the substring’s position (the following uses a 3.X print call\\nand may leave your cursor a bit indented; in 2.X say print c, instead):\\n\\n>>> myjob = \"hacker\"\\n>>> for c in myjob: print(c, end=\\' \\')   # Step through items, print each (3.X form)\\n...\\nh a c k e r\\n>>> \"k\" in myjob                        # Found\\nTrue\\n>>> \"z\" in myjob                        # Not found\\nFalse\\n>>> \\'spam\\' in \\'abcspamdef\\'              # Substring search, no position returned\\nTrue\\n\\nThe for loop assigns a variable to successive items in a sequence (here, a string) and\\nexecutes one or more statements for each item. In effect, the variable c becomes a cursor\\nstepping across the string’s characters here. We will discuss iteration tools like these\\nand others listed in Table 7-1 in more detail later in this book (especially in Chap-\\nter 14 and Chapter 20).\\n\\nIndexing and Slicing\\nBecause strings are defined as ordered collections of characters, we can access their\\ncomponents by position. In Python, characters in a string are fetched by indexing—\\nproviding the numeric offset of the desired component in square brackets after the\\nstring. You get back the one-character string at the specified position.\\nAs in the C language, Python offsets start at 0 and end at one less than the length of the\\nstring. Unlike C, however, Python also lets you fetch items from sequences such as\\nstrings using negative offsets. Technically, a negative offset is added to the length of a\\nstring to derive a positive offset. You can also think of negative offsets as counting\\nbackward from the end. The following interaction demonstrates:\\n\\n>>> S = \\'spam\\'\\n>>> S[0], S[−2]                         # Indexing from front or end\\n(\\'s\\', \\'a\\')\\n>>> S[1:3], S[1:], S[:−1]               # Slicing: extract a section\\n(\\'pa\\', \\'pam\\', \\'spa\\')\\n\\nThe first line defines a four-character string and assigns it the name S. The next line\\nindexes it in two ways: S[0] fetches the item at offset 0 from the left—the one-character\\nstring \\'s\\'; S[−2] gets the item at offset 2 back from the end—or equivalently, at offset\\n(4 + (−2)) from the front. In more graphic terms, offsets and slices map to cells as shown\\nin Figure 7-1.1\\n\\n1. More mathematically minded readers (and students in my classes) sometimes detect a small asymmetry\\nhere: the leftmost item is at offset 0, but the rightmost is at offset −1. Alas, there is no such thing as a\\ndistinct −0 value in Python.\\n\\nStrings in Action | 201\\n\\n\\x0cFigure 7-1. Offsets and slices: positive offsets start from the left end (offset 0 is the first item), and\\nnegatives count back from the right end (offset −1 is the last item). Either kind of offset can be used\\nto give positions in indexing and slicing operations.\\n\\nThe last line in the preceding example demonstrates slicing, a generalized form of in-\\ndexing that returns an entire section, not a single item. Probably the best way to think\\nof slicing is that it is a type of parsing (analyzing structure), especially when applied to\\nstrings—it allows us to extract an entire section (substring) in a single step. Slices can\\nbe used to extract columns of data, chop off leading and trailing text, and more. In fact,\\nwe’ll explore slicing in the context of text parsing later in this chapter.\\nThe basics of slicing are straightforward. When you index a sequence object such as a\\nstring on a pair of offsets separated by a colon, Python returns a new object containing\\nthe contiguous section identified by the offset pair. The left offset is taken to be the\\nlower bound (inclusive), and the right is the upper bound (noninclusive). That is, Python\\nfetches all items from the lower bound up to but not including the upper bound, and\\nreturns a new object containing the fetched items. If omitted, the left and right bounds\\ndefault to 0 and the length of the object you are slicing, respectively.\\nFor instance, in the example we just saw, S[1:3] extracts the items at offsets 1 and 2:\\nit grabs the second and third items, and stops before the fourth item at offset 3. Next,\\nS[1:] gets all items beyond the first—the upper bound, which is not specified, defaults\\nto the length of the string. Finally, S[:−1] fetches all but the last item—the lower bound\\ndefaults to 0, and −1 refers to the last item, noninclusive.\\nThis may seem confusing at first glance, but indexing and slicing are simple and pow-\\nerful tools to use, once you get the knack. Remember, if you’re unsure about the effects\\nof a slice, try it out interactively. In the next chapter, you’ll see that it’s even possible\\nto change an entire section of another object in one step by assigning to a slice (though\\nnot for immutables like strings). Here’s a summary of the details for reference:\\n\\nIndexing (S[i]) fetches components at offsets:\\n\\n• The first item is at offset 0.\\n• Negative indexes mean to count backward from the end or right.\\n• S[0] fetches the first item.\\n• S[−2] fetches the second item from the end (like S[len(S)−2]).\\n\\n202 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cSlicing (S[i:j]) extracts contiguous sections of sequences:\\n\\n• The upper bound is noninclusive.\\n• Slice boundaries default to 0 and the sequence length, if omitted.\\n• S[1:3] fetches items at offsets 1 up to but not including 3.\\n• S[1:] fetches items at offset 1 through the end (the sequence length).\\n• S[:3] fetches items at offset 0 up to but not including 3.\\n• S[:−1] fetches items at offset 0 up to but not including the last item.\\n• S[:] fetches items at offsets 0 through the end—making a top-level copy of S.\\n\\nExtended slicing (S[i:j:k]) accepts a step (or stride) k, which defaults to +1:\\n\\n• Allows for skipping items and reversing order—see the next section.\\n\\nThe second-to-last bullet item listed here turns out to be a very common technique: it\\nmakes a full top-level copy of a sequence object—an object with the same value, but a\\ndistinct piece of memory (you’ll find more on copies in Chapter 9). This isn’t very useful\\nfor immutable objects like strings, but it comes in handy for objects that may be changed\\nin place, such as lists.\\nIn the next chapter, you’ll see that the syntax used to index by offset (square brackets)\\nis used to index dictionaries by key as well; the operations look the same but have\\ndifferent interpretations.\\n\\nExtended slicing: The third limit and slice objects\\nIn Python 2.3 and later, slice expressions have support for an optional third index, used\\nas a step (sometimes called a stride). The step is added to the index of each item ex-\\ntracted. The full-blown form of a slice is now X[I:J:K], which means “extract all the\\nitems in X, from offset I through J−1, by K.” The third limit, K, defaults to +1, which is\\nwhy normally all items in a slice are extracted from left to right. If you specify an explicit\\nvalue, however, you can use the third limit to skip items or to reverse their order.\\nFor instance, X[1:10:2] will fetch every other item in X from offsets 1–9; that is, it will\\ncollect the items at offsets 1, 3, 5, 7, and 9. As usual, the first and second limits default\\nto 0 and the length of the sequence, respectively, so X[::2] gets every other item from\\nthe beginning to the end of the sequence:\\n\\n>>> S = \\'abcdefghijklmnop\\'\\n>>> S[1:10:2]                          # Skipping items\\n\\'bdfhj\\'\\n>>> S[::2]\\n\\'acegikmo\\'\\n\\nYou can also use a negative stride to collect items in the opposite order. For example,\\nthe  slicing  expression  \"hello\"[::−1]  returns  the  new  string  \"olleh\"—the  first  two\\nbounds default to 0 and the length of the sequence, as before, and a stride of −1 indicates\\nthat the slice should go from right to left instead of the usual left to right. The effect,\\ntherefore, is to reverse the sequence:\\n\\nStrings in Action | 203\\n\\n\\x0c>>> S = \\'hello\\'\\n>>> S[::−1]                            # Reversing items\\n\\'olleh\\'\\n\\nWith a negative stride, the meanings of the first two bounds are essentially reversed.\\nThat is, the slice S[5:1:−1] fetches the items from 2 to 5, in reverse order (the result\\ncontains items from offsets 5, 4, 3, and 2):\\n\\n>>> S = \\'abcedfg\\'\\n>>> S[5:1:−1]                          # Bounds roles differ\\n\\'fdec\\'\\n\\nSkipping and reversing like this are the most common use cases for three-limit slices,\\nbut see Python’s standard library manual for more details (or run a few experiments\\ninteractively). We’ll revisit three-limit slices again later in this book, in conjunction\\nwith the for loop statement.\\nLater in the book, we’ll also learn that slicing is equivalent to indexing with a slice\\nobject, a finding of importance to class writers seeking to support both operations:\\n\\n>>> \\'spam\\'[1:3]                        # Slicing syntax\\n\\'pa\\'\\n>>> \\'spam\\'[slice(1, 3)]                # Slice objects with index syntax + object\\n\\'pa\\'\\n>>> \\'spam\\'[::-1]\\n\\'maps\\'\\n>>> \\'spam\\'[slice(None, None, −1)]\\n\\'maps\\'\\n\\nWhy You Will Care: Slices\\n\\nThroughout this book, I will include common use-case sidebars (such as this one) to\\ngive you a peek at how some of the language features being introduced are typically\\nused in real programs. Because you won’t be able to make much sense of realistic use\\ncases until you’ve seen more of the Python picture, these sidebars necessarily contain\\nmany references to topics not introduced yet; at most, you should consider them pre-\\nviews of ways that you may find these abstract language concepts useful for common\\nprogramming tasks.\\n\\nFor instance, you’ll see later that the argument words listed on a system command line\\nused to launch a Python program are made available in the argv attribute of the built-\\nin sys module:\\n\\n# File echo.py\\nimport sys\\nprint(sys.argv)\\n\\n% python echo.py −a −b −c\\n[\\'echo.py\\', \\'−a\\', \\'−b\\', \\'−c\\']\\n\\nUsually, you’re only interested in inspecting the arguments that follow the program\\nname. This leads to a typical application of slices: a single slice expression can be used\\nto  return  all  but  the  first  item  of  a  list.  Here,  sys.argv[1:]  returns  the  desired  list,\\n\\n204 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0c[\\'−a\\', \\'−b\\', \\'−c\\']. You can then process this list without having to accommodate the\\nprogram name at the front.\\n\\nSlices are also often used to clean up lines read from input files. If you know that a line\\nwill have an end-of-line character at the end (a \\\\n newline marker), you can get rid of\\nit with a single expression such as line[:−1], which extracts all but the last character\\nin the line (the lower limit defaults to 0). In both cases, slices do the job of logic that\\nmust be explicit in a lower-level language.\\nHaving said that, calling the line.rstrip method is often preferred for stripping newline\\ncharacters because this call leaves the line intact if it has no newline character at the\\nend—a common case for files created with some text-editing tools. Slicing works if\\nyou’re sure the line is properly terminated.\\n\\nString Conversion Tools\\nOne of Python’s design mottos is that it refuses the temptation to guess. As a prime\\nexample, you cannot add a number and a string together in Python, even if the string\\nlooks like a number (i.e., is all digits):\\n\\n# Python 3.X\\n>>> \"42\" + 1\\nTypeError: Can\\'t convert \\'int\\' object to str implicitly\\n\\n# Python 2.X\\n>>> \"42\" + 1\\nTypeError: cannot concatenate \\'str\\' and \\'int\\' objects\\n\\nThis is by design: because + can mean both addition and concatenation, the choice of\\nconversion would be ambiguous. Instead, Python treats this as an error. In Python,\\nmagic is generally omitted if it will make your life more complex.\\nWhat to do, then, if your script obtains a number as a text string from a file or user\\ninterface? The trick is that you need to employ conversion tools before you can treat a\\nstring like a number, or vice versa. For instance:\\n\\n>>> int(\"42\"), str(42)          # Convert from/to string\\n(42, \\'42\\')\\n>>> repr(42)                    # Convert to as-code string\\n\\'42\\'\\n\\nThe int function converts a string to a number, and the str function converts a number\\nto  its  string  representation  (essentially,  what  it  looks  like  when  printed).  The  repr\\nfunction (and the older backquotes expression, removed in Python 3.X) also converts\\nan object to its string representation, but returns the object as a string of code that can\\nbe rerun to recreate the object. For strings, the result has quotes around it if displayed\\nwith a print statement, which differs in form between Python lines:\\n\\n>>> print(str(\\'spam\\'), repr(\\'spam\\'))       # 2.X: print str(\\'spam\\'), repr(\\'spam\\')\\nspam \\'spam\\'\\n\\nStrings in Action | 205\\n\\n\\x0c>>> str(\\'spam\\'), repr(\\'spam\\')              # Raw interactive echo displays\\n(\\'spam\\', \"\\'spam\\'\")\\n\\nSee the sidebar in Chapter 5’s “str and repr Display Formats” on page 144 for more on\\nthese topics. Of these, int and str are the generally prescribed to-number and to-string\\nconversion techniques.\\nNow, although you can’t mix strings and number types around operators such as +,\\nyou can manually convert operands before that operation if needed:\\n\\n>>> S = \"42\"\\n>>> I = 1\\n>>> S + I\\nTypeError: Can\\'t convert \\'int\\' object to str implicitly\\n\\n>>> int(S) + I            # Force addition\\n43\\n\\n>>> S + str(I)            # Force concatenation\\n\\'421\\'\\n\\nSimilar  built-in  functions  handle  floating-point-number  conversions  to  and  from\\nstrings:\\n\\n>>> str(3.1415), float(\"1.5\")\\n(\\'3.1415\\', 1.5)\\n\\n>>> text = \"1.234E-10\"\\n>>> float(text)           # Shows more digits before 2.7 and 3.1\\n1.234e-10\\n\\nLater, we’ll further study the built-in eval function; it runs a string containing Python\\nexpression code and so can convert a string to any kind of object. The functions int\\nand float convert only to numbers, but this restriction means they are usually faster\\n(and more secure, because they do not accept arbitrary expression code). As we saw\\nbriefly in Chapter 5, the string formatting expression also provides a way to convert\\nnumbers to strings. We’ll discuss formatting further later in this chapter.\\n\\nCharacter code conversions\\nOn the subject of conversions, it is also possible to convert a single character to its\\nunderlying integer code (e.g., its ASCII byte value) by passing it to the built-in  ord\\nfunction—this  returns  the  actual  binary  value  used  to  represent  the  corresponding\\ncharacter in memory. The chr function performs the inverse operation, taking an integer\\ncode and converting it to the corresponding character:\\n\\n>>> ord(\\'s\\')\\n115\\n>>> chr(115)\\n\\'s\\'\\n\\nTechnically, both of these convert characters to and from their Unicode ordinals or\\n“code points,” which are just their identifying number in the underlying character set.\\n\\n206 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cFor ASCII text, this is the familiar 7-bit integer that fits in a single byte in memory, but\\nthe range of code points for other kinds of Unicode text may be wider (more on char-\\nacter sets and Unicode in Chapter 37). You can use a loop to apply these functions to\\nall characters in a string if required. These tools can also be used to perform a sort of\\nstring-based math. To advance to the next character, for example, convert and do the\\nmath in integer:\\n>>> S = \\'5\\'\\n>>> S = chr(ord(S) + 1)\\n>>> S\\n\\'6\\'\\n>>> S = chr(ord(S) + 1)\\n>>> S\\n\\'7\\'\\n\\nAt least for single-character strings, this provides an alternative to using the built-in\\nint function to convert from string to integer (though this only makes sense in character\\nsets that order items as your code expects!):\\n\\n>>> int(\\'5\\')\\n5\\n>>> ord(\\'5\\') - ord(\\'0\\')\\n5\\n\\nSuch conversions can be used in conjunction with looping statements, introduced in\\nChapter 4 and covered in depth in the next part of this book, to convert a string of\\nbinary digits to their corresponding integer values. Each time through the loop, multiply\\nthe current value by 2 and add the next digit’s integer value:\\n\\n>>> B = \\'1101\\'                 # Convert binary digits to integer with ord\\n>>> I = 0\\n>>> while B != \\'\\':\\n...     I = I * 2 + (ord(B[0]) - ord(\\'0\\'))\\n...     B = B[1:]\\n...\\n>>> I\\n13\\n\\nA left-shift operation (I << 1) would have the same effect as multiplying by 2 here.\\nWe’ll leave this change as a suggested exercise, though, both because we haven’t stud-\\nied loops in detail yet and because the int and bin built-ins we met in Chapter 5 handle\\nbinary conversion tasks for us as of Python 2.6 and 3.0:\\n\\n>>> int(\\'1101\\', 2)             # Convert binary to integer: built-in\\n13\\n>>> bin(13)                    # Convert integer to binary: built-in\\n\\'0b1101\\'\\n\\nGiven enough time, Python tends to automate most common tasks!\\n\\nStrings in Action | 207\\n\\n\\x0cChanging Strings I\\nRemember the term “immutable sequence”? As we’ve seen, the immutable part means\\nthat you cannot change a string in place—for instance, by assigning to an index:\\n\\n>>> S = \\'spam\\'\\n>>> S[0] = \\'x\\'                 # Raises an error!\\nTypeError: \\'str\\' object does not support item assignment\\n\\nHow to modify text information in Python, then? To change a string, you generally\\nneed to build and assign a new string using tools such as concatenation and slicing,\\nand then, if desired, assign the result back to the string’s original name:\\n\\n>>> S = S + \\'SPAM!\\'            # To change a string, make a new one\\n>>> S\\n\\'spamSPAM!\\'\\n>>> S = S[:4] + \\'Burger\\' + S[−1]\\n>>> S\\n\\'spamBurger!\\'\\n\\nThe first example adds a substring at the end of S, by concatenation. Really, it makes\\na new string and assigns it back to S, but you can think of this as “changing” the original\\nstring. The second example replaces four characters with six by slicing, indexing, and\\nconcatenating. As you’ll see in the next section, you can achieve similar effects with\\nstring method calls like replace:\\n\\n>>> S = \\'splot\\'\\n>>> S = S.replace(\\'pl\\', \\'pamal\\')\\n>>> S\\n\\'spamalot\\'\\n\\nLike every operation that yields a new string value, string methods generate new string\\nobjects. If you want to retain those objects, you can assign them to variable names.\\nGenerating a new string object for each string change is not as inefficient as it may\\nsound—remember,  as  discussed  in  the  preceding  chapter,  Python  automatically \\ngarbage-collects (reclaims the space of) old unused string objects as you go, so newer\\nobjects reuse the space held by prior values. Python is usually more efficient than you\\nmight expect.\\nFinally, it’s also possible to build up new text values with string formatting expressions.\\nBoth of the following substitute objects into a string, in a sense converting the objects\\nto strings and changing the original string according to a format specification:\\n>>> \\'That is %d %s bird!\\' % (1, \\'dead\\')           # Format expression: all Pythons\\nThat is 1 dead bird!\\n>>> \\'That is {0} {1} bird!\\'.format(1, \\'dead\\')     # Format method in 2.6, 2.7, 3.X\\n\\'That is 1 dead bird!\\'\\n\\nDespite the substitution metaphor, though, the result of formatting is a new string\\nobject, not a modified one. We’ll study formatting later in this chapter; as we’ll find,\\nformatting turns out to be more general and useful than this example implies. Because\\n\\n208 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cthe second of the preceding calls is provided as a method, though, let’s get a handle on\\nstring method calls before we explore formatting further.\\n\\nAs previewed in Chapter 4 and to be covered in Chapter 37, Python 3.0\\nand 2.6 introduced a new string type known as bytearray, which is mu-\\ntable and so may be changed in place. bytearray objects aren’t really\\ntext strings; they’re sequences of small, 8-bit integers. However, they\\nsupport most of the same operations as normal strings and print as AS-\\nCII characters when displayed. Accordingly, they provide another op-\\ntion for large amounts of simple 8-bit text that must be changed fre-\\nquently  (richer  types  of  Unicode  text  imply  different  techniques).  In\\nChapter 37 we’ll also see that ord and chr handle Unicode characters,\\ntoo, which might not be stored in single bytes.\\n\\nString Methods\\nIn addition to expression operators, strings provide a set of methods that implement\\nmore sophisticated text-processing tasks. In Python, expressions and built-in functions\\nmay work across a range of types, but methods are generally specific to object types—\\nstring methods, for example, work only on string objects. The method sets of some\\ntypes intersect in Python 3.X (e.g., many types have count and copy methods), but they\\nare still more type-specific than other tools.\\n\\nMethod Call Syntax\\nAs introduced in Chapter 4, methods are simply functions that are associated with and\\nact upon particular objects. Technically, they are attributes attached to objects that\\nhappen to reference callable functions which always have an implied subject. In finer-\\ngrained detail, functions are packages of code, and method calls combine two opera-\\ntions at once—an attribute fetch and a call:\\n\\nAttribute fetches\\n\\nAn expression of the form object.attribute means “fetch the value of attribute\\nin object.”\\nCall expressions\\n\\nAn expression of the form function(arguments) means “invoke the code of func\\ntion, passing zero or more comma-separated  argument objects to it, and return\\nfunction’s result value.”\\n\\nPutting these two together allows us to call a method of an object. The method call\\nexpression:\\n\\nobject.method(arguments)\\n\\nString Methods\\n\\n| 209\\n\\n\\x0cis evaluated from left to right—Python will first fetch the method of the object and then\\ncall it, passing in both object and the arguments. Or, in plain words, the method call\\nexpression means this:\\n\\nCall method to process object with arguments.\\n\\nIf the method computes a result, it will also come back as the result of the entire method-\\ncall expression. As a more tangible example:\\n\\n>>> S = \\'spam\\'\\n>>> result = S.find(\\'pa\\')     # Call the find method to look for \\'pa\\' in string S\\n\\nThis mapping holds true for methods of both built-in types, as well as user-defined\\nclasses we’ll study later. As you’ll see throughout this part of the book, most objects\\nhave callable methods, and all are accessed using this same method-call syntax. To call\\nan object method, as you’ll see in the following sections, you have to go through an\\nexisting object; methods cannot be run (and make little sense) without a subject.\\n\\nMethods of Strings\\nTable 7-3 summarizes the methods and call patterns for built-in string objects in Python\\n3.3; these change frequently, so be sure to check Python’s standard library manual for\\nthe most up-to-date list, or run a dir or help call on any string (or the str type name)\\ninteractively. Python 2.X’s string methods vary slightly; it includes a decode, for exam-\\nple,  because  of  its  different  handling  of  Unicode  data  (something  we’ll  discuss  in\\nChapter 37). In this table, S is a string object, and optional arguments are enclosed in\\nsquare brackets. String methods in this table implement higher-level operations such\\nas splitting and joining, case conversions, content tests, and substring searches and\\nreplacements.\\n\\nTable 7-3. String method calls in Python 3.3\\n\\nS.capitalize()\\n\\nS.casefold()\\n\\nS.ljust(width [, fill])\\n\\nS.lower()\\n\\nS.center(width [, fill])\\n\\nS.lstrip([chars])\\n\\nS.count(sub [, start [, end]])\\n\\nS.maketrans(x[, y[, z]])\\n\\nS.encode([encoding [,errors]])\\n\\nS.partition(sep)\\n\\nS.endswith(suffix [, start [, end]])\\n\\nS.replace(old, new [, count])\\n\\nS.expandtabs([tabsize])\\n\\nS.rfind(sub [,start [,end]])\\n\\nS.find(sub [, start [, end]])\\n\\nS.rindex(sub [, start [, end]])\\n\\nS.format(fmtstr, *args, **kwargs)\\n\\nS.rjust(width [, fill])\\n\\nS.index(sub [, start [, end]])\\n\\nS.rpartition(sep)\\n\\nS.isalnum()\\n\\nS.isalpha()\\n\\nS.isdecimal()\\n\\nS.rsplit([sep[, maxsplit]])\\n\\nS.rstrip([chars])\\n\\nS.split([sep [,maxsplit]])\\n\\n210 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cS.isdigit()\\n\\nS.isidentifier()\\n\\nS.islower()\\n\\nS.isnumeric()\\n\\nS.isprintable()\\n\\nS.isspace()\\n\\nS.istitle()\\n\\nS.isupper()\\n\\nS.join(iterable)\\n\\nS.splitlines([keepends])\\n\\nS.startswith(prefix [, start [, end]])\\n\\nS.strip([chars])\\n\\nS.swapcase()\\n\\nS.title()\\n\\nS.translate(map)\\n\\nS.upper()\\n\\nS.zfill(width)\\n \\n\\nAs you can see, there are quite a few string methods, and we don’t have space to cover\\nthem all; see Python’s library manual or reference texts for all the fine points. To help\\nyou get started, though, let’s work through some code that demonstrates some of the\\nmost commonly used methods in action, and illustrates Python text-processing basics\\nalong the way.\\n\\nString Method Examples: Changing Strings II\\nAs we’ve seen, because strings are immutable, they cannot be changed in place directly. \\nThe bytearray supports in-place text changes in 2.6, 3.0, and later, but only for simple\\n8-bit types. We explored changes to text strings earlier, but let’s take a quick second\\nlook here in the context of string methods.\\nIn general, to make a new text value from an existing string, you construct a new string\\nwith operations such as slicing and concatenation. For example, to replace two char-\\nacters in the middle of a string, you can use code like this:\\n\\n>>> S = \\'spammy\\'\\n>>> S = S[:3] + \\'xx\\' + S[5:]          # Slice sections from S\\n>>> S\\n\\'spaxxy\\'\\n\\nBut, if you’re really just out to replace a substring, you can use the string replace method\\ninstead:\\n\\n>>> S = \\'spammy\\'\\n>>> S = S.replace(\\'mm\\', \\'xx\\')         # Replace all mm with xx in S\\n>>> S\\n\\'spaxxy\\'\\n\\nThe replace method is more general than this code implies. It takes as arguments the\\noriginal substring (of any length) and the string (of any length) to replace it with, and\\nperforms a global search and replace:\\n\\n>>> \\'aa$bb$cc$dd\\'.replace(\\'$\\', \\'SPAM\\')\\n\\'aaSPAMbbSPAMccSPAMdd\\'\\n\\nString Methods\\n\\n| 211\\n\\n\\x0cIn such a role, replace can be used as a tool to implement template replacements (e.g.,\\nin form letters). Notice that this time we simply printed the result, instead of assigning\\nit to a name—you need to assign results to names only if you want to retain them for\\nlater use.\\nIf you need to replace one fixed-size string that can occur at any offset, you can do a\\nreplacement again, or search for the substring with the string find method and then\\nslice:\\n\\n>>> S = \\'xxxxSPAMxxxxSPAMxxxx\\'\\n>>> where = S.find(\\'SPAM\\')            # Search for position\\n>>> where                             # Occurs at offset 4\\n4\\n>>> S = S[:where] + \\'EGGS\\' + S[(where+4):]\\n>>> S\\n\\'xxxxEGGSxxxxSPAMxxxx\\'\\n\\nThe find method returns the offset where the substring appears (by default, searching\\nfrom the front), or −1 if it is not found. As we saw earlier, it’s a substring search operation\\njust like the in expression, but find returns the position of a located substring.\\nAnother option is to use replace with a third argument to limit it to a single substitution:\\n\\n>>> S = \\'xxxxSPAMxxxxSPAMxxxx\\'\\n>>> S.replace(\\'SPAM\\', \\'EGGS\\')         # Replace all\\n\\'xxxxEGGSxxxxEGGSxxxx\\'\\n\\n>>> S.replace(\\'SPAM\\', \\'EGGS\\', 1)      # Replace one\\n\\'xxxxEGGSxxxxSPAMxxxx\\'\\n\\nNotice that replace returns a new string object each time. Because strings are immut-\\nable, methods never really change the subject strings in place, even if they are called\\n“replace”!\\nThe fact that concatenation operations and the replace method generate new string\\nobjects each time they are run is actually a potential downside of using them to change\\nstrings. If you have to apply many changes to a very large string, you might be able to\\nimprove your script’s performance by converting the string to an object that does sup-\\nport in-place changes:\\n\\n>>> S = \\'spammy\\'\\n>>> L = list(S)\\n>>> L\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\', \\'m\\', \\'y\\']\\n\\nThe built-in list function (an object construction call) builds a new list out of the items\\nin any sequence—in this case, “exploding” the characters of a string into a list. Once\\nthe string is in this form, you can make multiple changes to it without generating a new\\ncopy for each change:\\n\\n>>> L[3] = \\'x\\'                        # Works for lists, not strings\\n>>> L[4] = \\'x\\'\\n\\n212 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0c>>> L\\n[\\'s\\', \\'p\\', \\'a\\', \\'x\\', \\'x\\', \\'y\\']\\n\\nIf, after your changes, you need to convert back to a string (e.g., to write to a file), use\\nthe string join method to “implode” the list back into a string:\\n\\n>>> S = \\'\\'.join(L)\\n>>> S\\n\\'spaxxy\\'\\n\\nThe join method may look a bit backward at first sight. Because it is a method of strings\\n(not of lists), it is called through the desired delimiter. join puts the strings in a list (or\\nother iterable) together, with the delimiter between list items; in this case, it uses an\\nempty string delimiter to convert from a list back to a string. More generally, any string\\ndelimiter and iterable of strings will do:\\n\\n>>> \\'SPAM\\'.join([\\'eggs\\', \\'sausage\\', \\'ham\\', \\'toast\\'])\\n\\'eggsSPAMsausageSPAMhamSPAMtoast\\'\\n\\nIn fact, joining substrings all at once might often run faster than concatenating them\\nindividually. Be sure to also see the earlier note about the mutable bytearray string\\navailable as of Python 3.0 and 2.6, described fully in Chapter 37; because it may be\\nchanged in place, it offers an alternative to this list/join combination for some kinds\\nof 8-bit text that must be changed often.\\n\\nString Method Examples: Parsing Text\\nAnother common role for string methods is as a simple form of text parsing—that is,\\nanalyzing structure and extracting substrings. To extract substrings at fixed offsets, we\\ncan employ slicing techniques:\\n\\n>>> line = \\'aaa bbb ccc\\'\\n>>> col1 = line[0:3]\\n>>> col3 = line[8:]\\n>>> col1\\n\\'aaa\\'\\n>>> col3\\n\\'ccc\\'\\n\\nHere, the columns of data appear at fixed offsets and so may be sliced out of the original\\nstring. This technique passes for parsing, as long as the components of your data have\\nfixed positions. If instead some sort of delimiter separates the data, you can pull out its\\ncomponents by splitting. This will work even if the data may show up at arbitrary\\npositions within the string:\\n>>> line = \\'aaa bbb  ccc\\'\\n>>> cols = line.split()\\n>>> cols\\n[\\'aaa\\', \\'bbb\\', \\'ccc\\']\\n\\nThe string split method chops up a string into a list of substrings, around a delimiter\\nstring. We didn’t pass a delimiter in the prior example, so it defaults to whitespace—\\n\\nString Methods\\n\\n| 213\\n\\n\\x0cthe string is split at groups of one or more spaces, tabs, and newlines, and we get back\\na list of the resulting substrings. In other applications, more tangible delimiters may\\nseparate the data. This example splits (and hence parses) the string at commas, a sep-\\narator common in data returned by some database tools:\\n\\n>>> line = \\'bob,hacker,40\\'\\n>>> line.split(\\',\\')\\n[\\'bob\\', \\'hacker\\', \\'40\\']\\n\\nDelimiters can be longer than a single character, too:\\n\\n>>> line = \"i\\'mSPAMaSPAMlumberjack\"\\n>>> line.split(\"SPAM\")\\n[\"i\\'m\", \\'a\\', \\'lumberjack\\']\\n\\nAlthough there are limits to the parsing potential of slicing and splitting, both run very\\nfast and can handle basic text-extraction chores. Comma-separated text data is part of\\nthe CSV file format; for more advanced tools on this front, see also the csv module in\\nPython’s standard library.\\n\\nOther Common String Methods in Action\\nOther string methods have more focused roles—for example, to strip off whitespace\\nat the end of a line of text, perform case conversions, test content, and test for a substring\\nat the end or front:\\n\\n>>> line = \"The knights who say Ni!\\\\n\"\\n>>> line.rstrip()\\n\\'The knights who say Ni!\\'\\n>>> line.upper()\\n\\'THE KNIGHTS WHO SAY NI!\\\\n\\'\\n>>> line.isalpha()\\nFalse\\n>>> line.endswith(\\'Ni!\\\\n\\')\\nTrue\\n>>> line.startswith(\\'The\\')\\nTrue\\n\\nAlternative techniques can also sometimes be used to achieve the same results as string\\nmethods—the in membership operator can be used to test for the presence of a sub-\\nstring, for instance, and length and slicing operations can be used to mimic endswith:\\n\\n>>> line\\n\\'The knights who say Ni!\\\\n\\'\\n\\n>>> line.find(\\'Ni\\') != −1       # Search via method call or expression\\nTrue\\n>>> \\'Ni\\' in line\\nTrue\\n\\n>>> sub = \\'Ni!\\\\n\\'\\n>>> line.endswith(sub)          # End test via method call or slice\\nTrue\\n\\n214 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0c>>> line[-len(sub):] == sub\\nTrue\\n\\nSee also the format string formatting method described later in this chapter; it provides\\nmore advanced substitution tools that combine many operations in a single step.\\nAgain, because there are so many methods available for strings, we won’t look at every\\none here. You’ll see some additional string examples later in this book, but for more\\ndetails you can also turn to the Python library manual and other documentation sour-\\nces,  or  simply  experiment  interactively  on  your  own.  You  can  also  check  the\\nhelp(S.method) results for a method of any string object S for more hints; as we saw in\\nChapter 4, running help on str.method likely gives the same details.\\nNote that none of the string methods accepts patterns—for pattern-based text pro-\\ncessing, you must use the Python re standard library module, an advanced tool that\\nwas introduced in Chapter 4 but is mostly outside the scope of this text (one further\\nbrief example appears at the end of Chapter 37). Because of this limitation, though,\\nstring methods may sometimes run more quickly than the re module’s tools.\\n\\nThe Original string Module’s Functions (Gone in 3.X)\\nThe history of Python’s string methods is somewhat convoluted. For roughly the first\\ndecade of its existence, Python provided a standard library module called string that\\ncontained functions that largely mirrored the current set of string object methods. By\\npopular demand, in Python 2.0 these functions were made available as methods of\\nstring objects. Because so many people had written so much code that relied on the\\noriginal string module, however, it was retained for backward compatibility.\\nToday, you should use only string methods, not the original string module. In fact, the\\noriginal module call forms of today’s string methods have been removed completely\\nfrom Python 3.X, and you should not use them in new code in either 2.X or 3.X. How-\\never, because you may still see the module in use in older Python 2.X code, and this\\ntext covers both Pythons 2.X and 3.X, a brief look is in order here.\\nThe upshot of this legacy is that in Python 2.X, there technically are still two ways to\\ninvoke  advanced  string  operations:  by  calling  object  methods,  or  by  calling  string\\nmodule functions and passing in the objects as arguments. For instance, given a variable\\nX assigned to a string object, calling an object method:\\n\\nX.method(arguments)\\n\\nis usually equivalent to calling the same operation through the string module (provided\\nthat you have already imported the module):\\n\\nstring.method(X, arguments)\\n\\nHere’s an example of the method scheme in action:\\n\\n>>> S = \\'a+b+c+\\'\\n>>> x = S.replace(\\'+\\', \\'spam\\')\\n\\nString Methods\\n\\n| 215\\n\\n\\x0c>>> x\\n\\'aspambspamcspam\\'\\n\\nTo access the same operation through the string module in Python 2.X, you need to\\nimport the module (at least once in your process) and pass in the object:\\n\\n>>> import string\\n>>> y = string.replace(S, \\'+\\', \\'spam\\')\\n>>> y\\n\\'aspambspamcspam\\'\\n\\nBecause the module approach was the standard for so long, and because strings are\\nsuch a central component of most programs, you might see both call patterns in Python\\n2.X code you come across.\\nAgain, though, today you should always use method calls instead of the older module\\ncalls. There are good reasons for this, besides the fact that the module calls have gone\\naway in 3.X. For one thing, the module call scheme requires you to import the string\\nmodule (methods do not require imports). For another, the module makes calls a few\\ncharacters longer to type (when you load the module with import, that is, not using\\nfrom). And, finally, the module runs more slowly than methods (the module maps most\\ncalls back to the methods and so incurs an extra call along the way).\\nThe original string module itself, without its string method equivalents, is retained in\\nPython 3.X because it contains additional tools, including predefined string constants\\n(e.g., string.digits) and a Template object system—a relatively obscure formatting\\ntool that predates the string format method and is largely omitted here (for details, see\\nthe brief note comparing it to other formatting tools ahead, as well as Python’s library\\nmanual). Unless you really want to have to change your 2.X code to use 3.X, though,\\nyou should consider any basic string operation calls in it to be just ghosts of Python past.\\n\\nString Formatting Expressions\\nAlthough you can get a lot done with the string methods and sequence operations we’ve\\nalready met, Python also provides a more advanced way to combine string processing\\ntasks—string formatting allows us to perform multiple type-specific substitutions on a\\nstring in a single step. It’s never strictly required, but it can be convenient, especially\\nwhen formatting text to be displayed to a program’s users. Due to the wealth of new\\nideas in the Python world, string formatting is available in two flavors in Python today\\n(not counting the less-used  string module  Template system mentioned in the prior\\nsection):\\n\\nString formatting expressions: \\'...%s...\\' % (values)\\n\\nThe original technique available since Python’s inception, this form is based upon\\nthe C language’s “printf” model, and sees widespread use in much existing code.\\n\\n216 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cString formatting method calls: \\'...{}...\\'.format(values)\\n\\nA newer technique added in Python 2.6 and 3.0, this form is derived in part from\\na same-named tool in C#/.NET, and overlaps with string formatting expression\\nfunctionality.\\n\\nSince the method call flavor is newer, there is some chance that one or the other of these\\nmay become deprecated and removed over time. When 3.0 was released in 2008, the\\nexpression seemed more likely to be deprecated in later Python releases. Indeed, 3.0’s\\ndocumentation threatened deprecation in 3.1 and removal thereafter. This hasn’t hap-\\npened as of 2013 and 3.3, and now looks unlikely given the expression’s wide use—in\\nfact, it still appears even in Python’s own standard library thousands of times today!\\nNaturally, this story’s development depends on the future practice of Python’s users.\\nOn the other hand, because both the expression and method are valid to use today and\\neither may appear in code you’ll come across, this book covers both techniques in full\\nhere. As you’ll see, the two are largely variations on a theme, though the method has\\nsome extra features (such as thousands separators), and the expression is often more\\nconcise and seems second nature to most Python programmers.\\nThis book itself uses both techniques in later examples for illustrative purposes. If its\\nauthor has a preference, he will keep it largely classified, except to quote from Python’s\\nimport this motto:\\n\\nThere should be one—and preferably only one—obvious way to do it.\\n\\nUnless the newer string formatting method is compellingly better than the original and\\nwidely used expression, its doubling of Python programmers’ knowledge base require-\\nments in this domain seems unwarranted—and even un-Pythonic, per the original and\\nlongstanding meaning of that term. Programmers should not have to learn two com-\\nplicated tools if those tools largely overlap. You’ll have to judge for yourself whether\\nformatting merits the added language heft, of course, so let’s give both a fair hearing.\\n\\nFormatting Expression Basics\\nSince string formatting expressions are the original in this department, we’ll start with\\nthem. Python defines the % binary operator to work on strings (you may recall that this\\nis also the remainder of division, or modulus, operator for numbers). When applied to\\nstrings, the % operator provides a simple way to format values as strings according to a\\nformat definition. In short, the % operator provides a compact way to code multiple\\nstring substitutions all at once, instead of building and concatenating parts individually.\\nTo format strings:\\n\\n1. On the left of the % operator, provide a format string containing one or more em-\\n\\nbedded conversion targets, each of which starts with a % (e.g., %d).\\n\\nString Formatting Expressions\\n\\n| 217\\n\\n\\x0c2. On the right of the % operator, provide the object (or objects, embedded in a tuple)\\nthat you want Python to insert into the format string on the left in place of the\\nconversion target (or targets).\\n\\nFor instance, in the formatting example we saw earlier in this chapter, the integer 1\\nreplaces the %d in the format string on the left, and the string \\'dead\\' replaces the %s.\\nThe result is a new string that reflects these two substitutions, which may be printed\\nor saved for use in other roles:\\n\\n>>> \\'That is %d %s bird!\\' % (1, \\'dead\\')             # Format expression\\nThat is 1 dead bird!\\n\\nTechnically  speaking,  string  formatting  expressions  are  usually  optional—you  can\\ngenerally do similar work with multiple concatenations and conversions. However,\\nformatting  allows  us  to  combine  many  steps  into  a  single  operation.  It’s  powerful\\nenough to warrant a few more examples:\\n\\n>>> exclamation = \\'Ni\\'\\n>>> \\'The knights who say %s!\\' % exclamation         # String substitution\\n\\'The knights who say Ni!\\'\\n\\n>>> \\'%d %s %g you\\' % (1, \\'spam\\', 4.0)               # Type-specific substitutions\\n\\'1 spam 4 you\\'\\n\\n>>> \\'%s -- %s -- %s\\' % (42, 3.14159, [1, 2, 3])     # All types match a %s target\\n\\'42 -- 3.14159 -- [1, 2, 3]\\'\\n\\nThe first example here plugs the string \\'Ni\\' into the target on the left, replacing the\\n%s marker. In the second example, three values are inserted into the target string. Note\\nthat when you’re inserting more than one value, you need to group the values on the\\nright in parentheses (i.e., put them in a tuple). The % formatting expression operator\\nexpects either a single item or a tuple of one or more items on its right side.\\nThe third example again inserts three values—an integer, a floating-point object, and\\na list object—but notice that all of the targets on the left are %s, which stands for con-\\nversion to string. As every type of object can be converted to a string (the one used\\nwhen printing), every object type works with the %s conversion code. Because of this,\\nunless you will be doing some special formatting, %s is often the only code you need to\\nremember for the formatting expression.\\nAgain, keep in mind that formatting always makes a new string, rather than changing\\nthe string on the left; because strings are immutable, it must work this way. As before,\\nassign the result to a variable name if you need to retain it.\\n\\nAdvanced Formatting Expression Syntax\\nFor more advanced type-specific formatting, you can use any of the conversion type\\ncodes listed in Table 7-4 in formatting expressions; they appear after the % character in\\nsubstitution targets. C programmers will recognize most of these because Python string\\nformatting supports all the usual C printf format codes (but returns the result, instead\\n\\n218 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cof displaying it, like printf). Some of the format codes in the table provide alternative\\nways to format the same type; for instance, %e, %f, and %g provide alternative ways to\\nformat floating-point numbers.\\n\\nTable 7-4. String formatting type codes\\n\\nCode\\ns\\n\\nr\\n\\nc\\n\\nd\\n\\ni\\n\\nu\\n\\no\\n\\nx\\n\\nX\\n\\ne\\n\\nE\\n\\nf\\n\\nF\\n\\ng\\n\\nG\\n\\n%\\n\\nMeaning\\nString (or any object’s str(X) string)\\nSame as s, but uses repr, not str\\nCharacter (int or str)\\nDecimal (base-10 integer)\\nInteger\\nSame as d (obsolete: no longer unsigned)\\nOctal integer (base 8)\\nHex integer (base 16)\\nSame as x, but with uppercase letters\\nFloating point with exponent, lowercase\\nSame as e, but uses uppercase letters\\nFloating-point decimal\\nSame as f, but uses uppercase letters\\nFloating-point e or f\\nFloating-point E or F\\nLiteral % (coded as %%)\\n\\nIn fact, conversion targets in the format string on the expression’s left side support a\\nvariety of conversion operations with a fairly sophisticated syntax all their own. The\\ngeneral structure of conversion targets looks like this:\\n\\n%[(keyname)][flags][width][.precision]typecode\\n\\nThe type code characters in the first column of Table 7-4 show up at the end of this\\ntarget string’s format. Between the % and the type code character, you can do any of the\\nfollowing:\\n\\n• Provide a key name for indexing the dictionary used on the right side of the ex-\\n\\npression\\n\\n• List flags that specify things like left justification (−), numeric sign (+), a blank before\\n\\npositive numbers and a – for negatives (a space), and zero fills (0)\\n\\n• Give a total minimum field width for the substituted text\\n• Set the number of digits (precision) to display after a decimal point for floating-\\n\\npoint numbers\\n\\nString Formatting Expressions\\n\\n| 219\\n\\n\\x0cBoth the width and precision parts can also be coded as a * to specify that they should\\ntake their values from the next item in the input values on the expression’s right side\\n(useful when this isn’t known until runtime). And if you don’t need any of these extra\\ntools, a simple %s in the format string will be replaced by the corresponding value’s\\ndefault print string, regardless of its type.\\n\\nAdvanced Formatting Expression Examples\\nFormatting target syntax is documented in full in the Python standard manuals and\\nreference texts, but to demonstrate common usage, let’s look at a few examples. This\\none formats integers by default, and then in a six-character field with left justification\\nand zero padding:\\n\\n>>> x = 1234\\n>>> res = \\'integers: ...%d...%−6d...%06d\\' % (x, x, x)\\n>>> res\\n\\'integers: ...1234...1234  ...001234\\'\\n\\nThe %e, %f, and %g formats display floating-point numbers in different ways, as the\\nfollowing interaction demonstrates—%E is the same as %e but the exponent is uppercase,\\nand g chooses formats by number content (it’s formally defined to use exponential\\nformat e if the exponent is less than −4 or not less than precision, and decimal format\\nf otherwise, with a default total digits precision of 6):\\n\\n>>> x = 1.23456789\\n>>> x                                     # Shows more digits before 2.7 and 3.1\\n1.23456789\\n\\n>>> \\'%e | %f | %g\\' % (x, x, x)\\n\\'1.234568e+00 | 1.234568 | 1.23457\\'\\n\\n>>> \\'%E\\' % x\\n\\'1.234568E+00\\'\\n\\nFor floating-point numbers, you can achieve a variety of additional formatting effects\\nby specifying left justification, zero padding, numeric signs, total field width, and digits\\nafter the decimal point. For simpler tasks, you might get by with simply converting to\\nstrings with a %s format expression or the str built-in function shown earlier:\\n\\n>>> \\'%−6.2f | %05.2f | %+06.1f\\' % (x, x, x)\\n\\'1.23   | 01.23 | +001.2\\'\\n\\n>>> \\'%s\\' % x, str(x)\\n(\\'1.23456789\\', \\'1.23456789\\')\\n\\nWhen sizes are not known until runtime, you can use a computed width and precision\\nby specifying them with a * in the format string to force their values to be taken from\\nthe next item in the inputs to the right of the % operator—the 4 in the tuple here gives\\nprecision:\\n\\n>>> \\'%f, %.2f, %.*f\\' % (1/3.0, 1/3.0, 4, 1/3.0)\\n\\'0.333333, 0.33, 0.3333\\'\\n\\n220 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cIf you’re interested in this feature, experiment with some of these examples and oper-\\nations on your own for more insight.\\n\\nDictionary-Based Formatting Expressions\\nAs a more advanced extension, string formatting also allows conversion targets on the\\nleft to refer to the keys in a dictionary coded on the right and fetch the corresponding\\nvalues. This opens the door to using formatting as a sort of template tool. We’ve only\\nmet dictionaries briefly thus far in Chapter 4, but here’s an example that demonstrates\\nthe basics:\\n\\n>>> \\'%(qty)d more %(food)s\\' % {\\'qty\\': 1, \\'food\\': \\'spam\\'}\\n\\'1 more spam\\'\\n\\nHere, the (qty) and (food) in the format string on the left refer to keys in the dictionary\\nliteral on the right and fetch their associated values. Programs that generate text such\\nas HTML or XML often use this technique—you can build up a dictionary of values\\nand substitute them all at once with a single formatting expression that uses key-based\\nreferences (notice the first comment is above the triple quote so it’s not added to the\\nstring, and I’m typing this in IDLE without a “...” prompt for continuation lines):\\n\\n>>>                                           # Template with substitution targets\\n>>> reply = \"\"\"\\nGreetings...\\nHello %(name)s!\\nYour age is %(age)s\\n\"\"\"\\n>>> values = {\\'name\\': \\'Bob\\', \\'age\\': 40}       # Build up values to substitute\\n>>> print(reply % values)                     # Perform substitutions\\n\\nGreetings...\\nHello Bob!\\nYour age is 40\\n\\nThis trick is also used in conjunction with the vars built-in function, which returns a\\ndictionary containing all the variables that exist in the place it is called:\\n\\n>>> food = \\'spam\\'\\n>>> qty = 10\\n>>> vars()\\n{\\'food\\': \\'spam\\', \\'qty\\': 10, ...plus built-in names set by Python... }\\n\\nWhen used on the right side of a format operation, this allows the format string to refer\\nto variables by name—as dictionary keys:\\n\\n>>> \\'%(qty)d more %(food)s\\' % vars()          # Variables are keys in vars()\\n\\'10 more spam\\'\\n\\nWe’ll study dictionaries in more depth in Chapter 8. See also Chapter 5 for examples\\nthat convert to hexadecimal and octal number strings with the %x and %o formatting\\nexpression target codes, which we won’t repeat here. Additional formatting expression\\n\\nString Formatting Expressions\\n\\n| 221\\n\\n\\x0cexamples also appear ahead as comparisons to the formatting method—this chapter’s\\nnext and final string topic.\\n\\nString Formatting Method Calls\\nAs mentioned earlier, Python 2.6 and 3.0 introduced a new way to format strings that\\nis seen by some as a bit more Python-specific. Unlike formatting expressions, formatting\\nmethod  calls  are  not  closely  based  upon  the  C  language’s  “printf”  model,  and  are\\nsometimes more explicit in intent. On the other hand, the new technique still relies on\\ncore “printf” concepts, such as type codes and formatting specifications. Moreover, it\\nlargely overlaps with—and sometimes requires a bit more code than—formatting ex-\\npressions, and in practice can be just as complex in many roles. Because of this, there\\nis no best-use recommendation between expressions and method calls today, and most\\nprogrammers would be well served by a cursory understanding of both schemes. Luck-\\nily, the two are similar enough that many core concepts overlap.\\n\\nFormatting Method Basics\\nThe string object’s format method, available in Python 2.6, 2.7, and 3.X, is based on\\nnormal function call syntax, instead of an expression. Specifically, it uses the subject\\nstring as a template, and takes any number of arguments that represent values to be\\nsubstituted according to the template.\\nIts use requires knowledge of functions and calls, but is mostly straightforward. Within\\nthe subject string, curly braces designate substitution targets and arguments to be in-\\nserted either by position (e.g., {1}), or keyword (e.g., {food}), or relative position in\\n2.7, 3.1, and later ({}). As we’ll learn when we study argument passing in depth in\\nChapter 18, arguments to functions and methods may be passed by position or keyword\\nname, and Python’s ability to collect arbitrarily many positional and keyword argu-\\nments allows for such general method call patterns. For example:\\n\\n>>> template = \\'{0}, {1} and {2}\\'                             # By position\\n>>> template.format(\\'spam\\', \\'ham\\', \\'eggs\\')\\n\\'spam, ham and eggs\\'\\n\\n>>> template = \\'{motto}, {pork} and {food}\\'                   # By keyword\\n>>> template.format(motto=\\'spam\\', pork=\\'ham\\', food=\\'eggs\\')\\n\\'spam, ham and eggs\\'\\n\\n>>> template = \\'{motto}, {0} and {food}\\'                      # By both\\n>>> template.format(\\'ham\\', motto=\\'spam\\', food=\\'eggs\\')\\n\\'spam, ham and eggs\\'\\n\\n>>> template = \\'{}, {} and {}\\'                                # By relative position\\n>>> template.format(\\'spam\\', \\'ham\\', \\'eggs\\')                    # New in 3.1 and 2.7\\n\\'spam, ham and eggs\\'\\n\\n222 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cBy comparison, the last section’s formatting expression can be a bit more concise, but\\nuses dictionaries instead of keyword arguments, and doesn’t allow quite as much flex-\\nibility for value sources (which may be an asset or liability, depending on your per-\\nspective); more on how the two techniques compare ahead:\\n\\n>>> template = \\'%s, %s and %s\\'                                # Same via expression\\n>>> template % (\\'spam\\', \\'ham\\', \\'eggs\\')\\n\\'spam, ham and eggs\\'\\n\\n>>> template = \\'%(motto)s, %(pork)s and %(food)s\\'\\n>>> template % dict(motto=\\'spam\\', pork=\\'ham\\', food=\\'eggs\\')\\n\\'spam, ham and eggs\\'\\n\\nNote the use of dict() to make a dictionary from keyword arguments here, introduced\\nin Chapter 4 and covered in full in Chapter 8; it’s an often less-cluttered alternative to\\nthe {...} literal. Naturally, the subject string in the format method call can also be a\\nliteral that creates a temporary string, and arbitrary object types can be substituted at\\ntargets much like the expression’s %s code:\\n\\n>>> \\'{motto}, {0} and {food}\\'.format(42, motto=3.14, food=[1, 2])\\n\\'3.14, 42 and [1, 2]\\'\\n\\nJust as with the % expression and other string methods, format creates and returns a\\nnew string object, which can be printed immediately or saved for further work (recall\\nthat strings are immutable, so format really must make a new object). String formatting\\nis not just for display:\\n\\n>>> X = \\'{motto}, {0} and {food}\\'.format(42, motto=3.14, food=[1, 2])\\n>>> X\\n\\'3.14, 42 and [1, 2]\\'\\n\\n>>> X.split(\\' and \\')\\n[\\'3.14, 42\\', \\'[1, 2]\\']\\n\\n>>> Y = X.replace(\\'and\\', \\'but under no circumstances\\')\\n>>> Y\\n\\'3.14, 42 but under no circumstances [1, 2]\\'\\n\\nAdding Keys, Attributes, and Offsets\\nLike % formatting expressions, format calls can become more complex to support more\\nadvanced usage. For instance, format strings can name object attributes and dictionary\\nkeys—as  in  normal  Python  syntax,  square  brackets  name  dictionary  keys  and  dots\\ndenote object attributes of an item referenced by position or keyword. The first of the\\nfollowing examples indexes a dictionary on the key “spam” and then fetches the at-\\ntribute “platform” from the already imported sys module object. The second does the\\nsame, but names the objects by keyword instead of position:\\n\\n>>> import sys\\n\\n>>> \\'My {1[kind]} runs {0.platform}\\'.format(sys, {\\'kind\\': \\'laptop\\'})\\n\\'My laptop runs win32\\'\\n\\nString Formatting Method Calls\\n\\n| 223\\n\\n\\x0c>>> \\'My {map[kind]} runs {sys.platform}\\'.format(sys=sys, map={\\'kind\\': \\'laptop\\'})\\n\\'My laptop runs win32\\'\\n\\nSquare brackets in format strings can name list (and other sequence) offsets to perform\\nindexing, too, but only single positive offsets work syntactically within format strings,\\nso this feature is not as general as you might think. As with % expressions, to name\\nnegative offsets or slices, or to use arbitrary expression results in general, you must run\\nexpressions outside the format string itself (note the use of *parts here to unpack a\\ntuple’s items into individual function arguments, as we did in Chapter 5 when studying\\nfractions; more on this form in Chapter 18):\\n\\n>>> somelist = list(\\'SPAM\\')\\n>>> somelist\\n[\\'S\\', \\'P\\', \\'A\\', \\'M\\']\\n\\n>>> \\'first={0[0]}, third={0[2]}\\'.format(somelist)\\n\\'first=S, third=A\\'\\n\\n>>> \\'first={0}, last={1}\\'.format(somelist[0], somelist[-1])   # [-1] fails in fmt\\n\\'first=S, last=M\\'\\n\\n>>> parts = somelist[0], somelist[-1], somelist[1:3]          # [1:3] fails in fmt\\n>>> \\'first={0}, last={1}, middle={2}\\'.format(*parts)          # Or \\'{}\\' in 2.7/3.1+\\n\"first=S, last=M, middle=[\\'P\\', \\'A\\']\"\\n\\nAdvanced Formatting Method Syntax\\nAnother similarity with % expressions is that you can achieve more specific layouts by\\nadding extra syntax in the format string. For the formatting method, we use a colon\\nafter the possibly empty substitution target’s identification, followed by a format speci-\\nfier that can name the field size, justification, and a specific type code. Here’s the formal\\nstructure of what can appear as a substitution target in a format string—its four parts\\nare all optional, and must appear without intervening spaces:\\n\\n{fieldname component !conversionflag :formatspec}\\n\\nIn this substitution target syntax:\\n\\n• fieldname is an optional number or keyword identifying an argument, which may\\n\\nbe omitted to use relative argument numbering in 2.7, 3.1, and later.\\n\\n• component is a string of zero or more “.name” or “[index]” references used to fetch\\nattributes and indexed values of the argument, which may be omitted to use the\\nwhole argument value.\\n\\n• conversionflag starts with a ! if present, which is followed by r, s, or a to call repr,\\n\\nstr, or ascii built-in functions on the value, respectively.\\n\\n• formatspec starts with a : if present, which is followed by text that specifies how\\nthe value should be presented, including details such as field width, alignment,\\npadding, decimal precision, and so on, and ends with an optional data type code.\\n\\n224 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cThe formatspec component after the colon character has a rich format all its own, and\\nis formally described as follows (brackets denote optional components and are not\\ncoded literally):\\n\\n[[fill]align][sign][#][0][width][,][.precision][typecode]\\n\\nIn this, fill can be any fill character other than { or }; align may be <, >, =, or ^, for\\nleft alignment, right alignment, padding after a sign character, or centered alignment,\\nrespectively; sign may be +, −, or space; and the , (comma) option requests a comma\\nfor a thousands separator as of Python 2.7 and 3.1. width and precision are much as\\nin the % expression, and the formatspec may also contain nested {} format strings with\\nfield names only, to take values from the arguments list dynamically (much like the *\\nin formatting expressions).\\nThe method’s typecode options almost completely overlap with those used in % ex-\\npressions and listed previously in Table 7-4, but the format method also allows a b type\\ncode used to display integers in binary format (it’s equivalent to using the bin built-in\\ncall), allows a % type code to display percentages, and uses only d for base-10 integers\\n(i or u are not used here). Note that unlike the expression’s %s, the s type code here\\nrequires a string object argument; omit the type code to accept any type generically.\\nSee Python’s library manual for more on substitution syntax that we’ll omit here. In\\naddition to the string’s format method, a single object may also be formatted with the\\nformat(object, formatspec) built-in function (which the method uses internally), and\\nmay be customized in user-defined classes with the __format__ operator-overloading\\nmethod (see Part VI).\\n\\nAdvanced Formatting Method Examples\\nAs you can tell, the syntax can be complex in formatting methods. Because your best\\nally in such cases is often the interactive prompt here, let’s turn to some examples. In\\nthe following, {0:10} means the first positional argument in a field 10 characters wide,\\n{1:<10}  means  the  second  positional  argument  left-justified  in  a  10-character-wide\\nfield, and {0.platform:>10} means the platform attribute of the first argument right-\\njustified in a 10-character-wide field (note again the use of dict() to make a dictionary\\nfrom keyword arguments, covered in Chapter 4 and Chapter 8):\\n\\n>>> \\'{0:10} = {1:10}\\'.format(\\'spam\\', 123.4567)         # In Python 3.3\\n\\'spam       =   123.4567\\'\\n\\n>>> \\'{0:>10} = {1:<10}\\'.format(\\'spam\\', 123.4567)\\n\\'      spam = 123.4567  \\'\\n\\n>>> \\'{0.platform:>10} = {1[kind]:<10}\\'.format(sys, dict(kind=\\'laptop\\'))\\n\\'     win32 = laptop    \\'\\n\\nIn all cases, you can omit the argument number as of Python 2.7 and 3.1 if you’re\\nselecting them from left to right with relative autonumbering—though this makes your\\n\\nString Formatting Method Calls\\n\\n| 225\\n\\n\\x0ccode less explicit, thereby negating one of the reported advantages of the formatting\\nmethod over the formatting expression (see the related note ahead):\\n\\n>>> \\'{:10} = {:10}\\'.format(\\'spam\\', 123.4567)\\n\\'spam       =   123.4567\\'\\n\\n>>> \\'{:>10} = {:<10}\\'.format(\\'spam\\', 123.4567)\\n\\'      spam = 123.4567  \\'\\n\\n>>> \\'{.platform:>10} = {[kind]:<10}\\'.format(sys, dict(kind=\\'laptop\\'))\\n\\'     win32 = laptop    \\'\\n\\nFloating-point numbers support the same type codes and formatting specificity in for-\\nmatting method calls as in % expressions. For instance, in the following {2:g} means\\nthe third argument formatted by default according to the “g” floating-point represen-\\ntation, {1:.2f} designates the “f” floating-point format with just two decimal digits,\\nand {2:06.2f} adds a field with a width of six characters and zero padding on the left:\\n\\n>>> \\'{0:e}, {1:.3e}, {2:g}\\'.format(3.14159, 3.14159, 3.14159)\\n\\'3.141590e+00, 3.142e+00, 3.14159\\'\\n\\n>>> \\'{0:f}, {1:.2f}, {2:06.2f}\\'.format(3.14159, 3.14159, 3.14159)\\n\\'3.141590, 3.14, 003.14\\'\\n\\nHex, octal, and binary formats are supported by the format method as well. In fact,\\nstring formatting is an alternative to some of the built-in functions that format integers\\nto a given base:\\n\\n>>> \\'{0:X}, {1:o}, {2:b}\\'.format(255, 255, 255)      # Hex, octal, binary\\n\\'FF, 377, 11111111\\'\\n\\n>>> bin(255), int(\\'11111111\\', 2), 0b11111111         # Other to/from binary\\n(\\'0b11111111\\', 255, 255)\\n\\n>>> hex(255), int(\\'FF\\', 16), 0xFF                    # Other to/from hex\\n(\\'0xff\\', 255, 255)\\n\\n>>> oct(255), int(\\'377\\', 8), 0o377                   # Other to/from octal, in 3.X\\n(\\'0o377\\', 255, 255)                                  # 2.X prints and accepts 0377\\n\\nFormatting parameters can either be hardcoded in format strings or taken from the\\narguments list dynamically by nested format syntax, much like the * syntax in format-\\nting expressions’ width and precision:\\n\\n>>> \\'{0:.2f}\\'.format(1 / 3.0)                        # Parameters hardcoded\\n\\'0.33\\'\\n>>> \\'%.2f\\' % (1 / 3.0)                               # Ditto for expression\\n\\'0.33\\'\\n\\n>>> \\'{0:.{1}f}\\'.format(1 / 3.0, 4)                   # Take value from arguments\\n\\'0.3333\\'\\n>>> \\'%.*f\\' % (4, 1 / 3.0)                            # Ditto for expression\\n\\'0.3333\\'\\n\\n226 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cFinally, Python 2.6 and 3.0 also introduced a new built-in format function, which can\\nbe used to format a single item. It’s a more concise alternative to the string  format\\nmethod, and is roughly similar to formatting a single item with the % formatting ex-\\npression:\\n\\n>>> \\'{0:.2f}\\'.format(1.2345)                         # String method\\n\\'1.23\\'\\n>>> format(1.2345, \\'.2f\\')                            # Built-in function\\n\\'1.23\\'\\n>>> \\'%.2f\\' % 1.2345                                  # Expression\\n\\'1.23\\'\\n\\nTechnically, the format built-in runs the subject object’s __format__ method, which the\\nstr.format method does internally for each formatted item. It’s still more verbose than\\nthe original % expression’s equivalent here, though—which leads us to the next section.\\n\\nComparison to the % Formatting Expression\\nIf you study the prior sections closely, you’ll probably notice that at least for positional\\nreferences and dictionary keys, the string format method looks very much like the %\\nformatting expression, especially in advanced use with type codes and extra formatting\\nsyntax. In fact, in common use cases formatting expressions may be easier to code than\\nformatting method calls, especially when you’re using the generic %s print-string sub-\\nstitution target, and even with autonumbering of fields added in 2.7 and 3.1:\\n\\nprint(\\'%s=%s\\' % (\\'spam\\', 42))            # Format expression: in all 2.X/3.X\\n\\nprint(\\'{0}={1}\\'.format(\\'spam\\', 42))      # Format method: in 3.0+ and 2.6+\\n\\nprint(\\'{}={}\\'.format(\\'spam\\', 42))        # With autonumbering: in 3.1+ and 2.7\\n\\nAs we’ll see in a moment, more complex formatting tends to be a draw in terms of\\ncomplexity (difficult tasks are generally difficult, regardless of approach), and some see\\nthe formatting method as redundant given the pervasiveness of the expression.\\nOn the other hand, the formatting method also offers a few potential advantages. For\\nexample, the original % expression can’t handle keywords, attribute references, and\\nbinary  type  codes,  although  dictionary  key  references  in  %  format  strings  can  often\\nachieve similar goals. To see how the two techniques overlap, compare the following\\n% expressions to the equivalent format method calls shown earlier:\\n\\n>>> \\'%s, %s and %s\\' % (3.14, 42, [1, 2])                      # Arbitrary types\\n\\'3.14, 42 and [1, 2]\\'\\n\\n>>> \\'My %(kind)s runs %(platform)s\\' % {\\'kind\\': \\'laptop\\', \\'platform\\': sys.platform}\\n\\'My laptop runs win32\\'\\n\\n>>> \\'My %(kind)s runs %(platform)s\\' % dict(kind=\\'laptop\\', platform=sys.platform)\\n\\'My laptop runs win32\\'\\n\\n>>> somelist = list(\\'SPAM\\')\\n\\nString Formatting Method Calls\\n\\n| 227\\n\\n\\x0c>>> parts = somelist[0], somelist[-1], somelist[1:3]\\n>>> \\'first=%s, last=%s, middle=%s\\' % parts\\n\"first=S, last=M, middle=[\\'P\\', \\'A\\']\"\\n\\nWhen more complex formatting is applied the two techniques approach parity in terms\\nof  complexity,  although  if  you  compare  the  following  with  the  format  method  call\\nequivalents listed earlier you’ll again find that the % expressions tend to be a bit simpler\\nand more concise; in Python 3.3:\\n\\n# Adding specific formatting\\n\\n>>> \\'%-10s = %10s\\' % (\\'spam\\', 123.4567)\\n\\'spam       =   123.4567\\'\\n\\n>>> \\'%10s = %-10s\\' % (\\'spam\\', 123.4567)\\n\\'      spam = 123.4567  \\'\\n\\n>>> \\'%(plat)10s = %(kind)-10s\\' % dict(plat=sys.platform, kind=\\'laptop\\')\\n\\'     win32 = laptop    \\'\\n\\n# Floating-point numbers\\n\\n>>> \\'%e, %.3e, %g\\' % (3.14159, 3.14159, 3.14159)\\n\\'3.141590e+00, 3.142e+00, 3.14159\\'\\n\\n>>> \\'%f, %.2f, %06.2f\\' % (3.14159, 3.14159, 3.14159)\\n\\'3.141590, 3.14, 003.14\\'\\n\\n# Hex and octal, but not binary (see ahead)\\n\\n>>> \\'%x, %o\\' % (255, 255)\\n\\'ff, 377\\'\\n\\nThe format method has a handful of advanced features that the % expression does not,\\nbut even more involved formatting still seems to be essentially a draw in terms of com-\\nplexity. For instance, the following shows the same result generated with both techni-\\nques, with field sizes and justifications and various argument reference methods:\\n\\n# Hardcoded references in both\\n>>> import sys\\n\\n>>> \\'My {1[kind]:<8} runs {0.platform:>8}\\'.format(sys, {\\'kind\\': \\'laptop\\'})\\n\\'My laptop   runs    win32\\'\\n\\n>>> \\'My %(kind)-8s runs %(plat)8s\\' % dict(kind=\\'laptop\\', plat=sys.platform)\\n\\'My laptop   runs    win32\\'\\n\\nIn practice, programs are less likely to hardcode references like this than to execute\\ncode that builds up a set of substitution data ahead of time (for instance, to collect\\ninput form or database data to substitute into an HTML template all at once). When\\nwe account for common practice in examples like this, the comparison between the\\nformat method and the % expression is even more direct:\\n\\n228 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0c# Building data ahead of time in both\\n>>> data = dict(platform=sys.platform, kind=\\'laptop\\')\\n\\n>>> \\'My {kind:<8} runs {platform:>8}\\'.format(**data)\\n\\'My laptop   runs    win32\\'\\n\\n>>> \\'My %(kind)-8s runs %(platform)8s\\' % data\\n\\'My laptop   runs    win32\\'\\n\\nAs we’ll see in Chapter 18, the **data in the method call here is special syntax that\\nunpacks a dictionary of keys and values into individual “name=value” keyword argu-\\nments so they can be referenced by name in the format string—another unavoidable\\nfar conceptual forward reference to function call tools, which may be another downside\\nof the format method in general, especially for newcomers.\\nAs usual, though, the Python community will have to decide whether % expressions,\\nformat method calls, or a toolset with both techniques proves better over time. Experi-\\nment with these techniques on your own to get a feel for what they offer, and be sure\\nto see the library reference manuals for Python 2.6, 3.0, and later for more details.\\n\\nString format method enhancements in Python 3.1 and 2.7: Python 3.1\\nand 2.7 added a thousand-separator syntax for numbers, which inserts\\ncommas between three-digit groups. To make this work, add a comma\\nbefore the type code, and between the width and precision if present,\\nas follows:\\n\\n>>> \\'{0:d}\\'.format(999999999999)\\n\\'999999999999\\'\\n>>> \\'{0:,d}\\'.format(999999999999)\\n\\'999,999,999,999\\'\\n\\nThese Pythons also assign relative numbers to substitution targets au-\\ntomatically if they are not included explicitly, though using this exten-\\nsion  doesn’t  apply  in  all  use  cases,  and  may  negate  one  of  the  main\\nbenefits of the formatting method—its more explicit code:\\n\\n>>> \\'{:,d}\\'.format(999999999999)\\n\\'999,999,999,999\\'\\n>>> \\'{:,d} {:,d}\\'.format(9999999, 8888888)\\n\\'9,999,999 8,888,888\\'\\n>>> \\'{:,.2f}\\'.format(296999.2567)\\n\\'296,999.26\\'\\n\\nSee the 3.1 release notes for more details. See also the formats.py comma-\\ninsertion and money-formatting function examples in Chapter 25 for a\\nsimple manual solution that can be imported and used prior to Python\\n3.1 and 2.7. As typical in programming, it’s straightforward to imple-\\nment new functionality in a callable, reusable, and customizable func-\\ntion of your own, rather than relying on a fixed set of built-in tools:\\n\\n>>> from formats import commas, money\\n>>> \\'%s\\' % commas(999999999999)\\n\\'999,999,999,999\\'\\n>>> \\'%s %s\\' % (commas(9999999), commas(8888888))\\n\\nString Formatting Method Calls\\n\\n| 229\\n\\n\\x0c\\'9,999,999 8,888,888\\'\\n>>> \\'%s\\' % money(296999.2567)\\n\\'$296,999.26\\'\\n\\nAnd as usual, a simple function like this can be applied in more advanced\\ncontexts too, such as the iteration tools we met in Chapter 4 and will\\nstudy fully in later chapters:\\n\\n>>> [commas(x) for x in (9999999, 8888888)]\\n[\\'9,999,999\\', \\'8,888,888\\']\\n>>> \\'%s %s\\' % tuple(commas(x) for x in (9999999, 8888888))\\n\\'9,999,999 8,888,888\\'\\n>>> \\'\\'.join(commas(x) for x in (9999999, 8888888))\\n\\'9,999,9998,888,888\\'\\n\\nFor better or worse, Python developers often seem to prefer adding spe-\\ncial-case built-in tools over general development techniques—a tradeoff\\nexplored in the next section.\\n\\nWhy the Format Method?\\nNow that I’ve gone to such lengths to compare and contrast the two formatting tech-\\nniques, I wish to also explain why you still might want to consider using the format\\nmethod variant at times. In short, although the formatting method can sometimes re-\\nquire more code, it also:\\n\\n• Has a handful of extra features not found in the % expression itself (though % can\\n\\nuse alternatives)\\n\\n• Has more flexible value reference syntax (though it may be overkill, and % often\\n\\nhas equivalents)\\n\\n• Can make substitution value references more explicit (though this is now optional)\\n• Trades an operator for a more mnemonic method name (though this is also more\\n\\nverbose)\\n\\n• Does not allow different syntax for single and multiple values (though practice\\n\\nsuggests this is trivial)\\n\\n• As a function can be used in places an expression cannot (though a one-line func-\\n\\ntion renders this moot)\\n\\nAlthough both techniques are available today and the formatting expression is still\\nwidely used, the format method might eventually grow in popularity and may receive\\nmore attention from Python developers in the future. Further, with both the expression\\nand method in the language, either may appear in code you will encounter so it be-\\nhooves you to understand both. But because the choice is currently still yours to make\\nin new code, let’s briefly expand on the tradeoffs before closing the book on this topic.\\n\\nExtra features: Special-case “batteries” versus general techniques\\nThe method call supports a few extras that the expression does not, such as binary type\\ncodes and (as of Python 2.7 and 3.1) thousands groupings. As we’ve seen, though, the\\n\\n230 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cformatting expression can usually achieve the same effects in other ways. Here’s the \\ncase for binary formatting:\\n\\n>>> \\'{0:b}\\'.format((2 ** 16) − 1)        # Expression (only) binary format code\\n\\'1111111111111111\\'\\n>>> \\'%b\\' % ((2 ** 16) − 1)\\nValueError: unsupported format character \\'b\\'...\\n\\n>>> bin((2 ** 16) − 1)                   # But other more general options work too\\n\\'0b1111111111111111\\'\\n>>> \\'%s\\' % bin((2 ** 16) - 1)            # Usable with both method and % expression\\n\\'0b1111111111111111\\'\\n>>> \\'{}\\'.format(bin((2 ** 16) - 1))      # With 2.7/3.1+ relative numbering\\n\\'0b1111111111111111\\'\\n\\n>>> \\'%s\\' % bin((2 ** 16) - 1)[2:]        # Slice off 0b to get exact equivalent\\n\\'1111111111111111\\'\\n\\nThe preceding note showed that general functions could similarly stand in for the for-\\nmat method’s thousands groupings option, and more fully support customization. In\\nthis case, a simple 8-line reusable function buys us the same utility without extra special-\\ncase syntax:\\n\\n>>> \\'{:,d}\\'.format(999999999999)         # New str.format method feature in 3.1/2.7\\n\\'999,999,999,999\\'\\n\\n>>> \\'%s\\' % commas(999999999999)          # But % is same with simple 8-line function\\n\\'999,999,999,999\\'\\n\\nSee the prior note for more comma comparisons. This is essentially the same as the\\npreceding bin case for binary formatting, but the commas function here is user-defined,\\nnot built in. As such, this technique is far more general purpose than precoded tools or\\nspecial syntax added for a single purpose.\\nThis case also seems indicative, perhaps, of a trend in Python (and scripting language\\nin general) toward relying more on special-case “batteries included” tools than on gen-\\neral development techniques—a mindset that makes code dependent on those batter-\\nies, and seems difficult to justify unless one views software development as an end-user\\nenterprise. To some, programmers might be better served learning how to code an\\nalgorithm to insert commas than be provided a tool that does.\\nWe’ll leave that philosophical debate aside here, but in practical terms the net effect of\\nthe trend in this case is extra syntax for you to have to both learn and remember. Given\\ntheir alternatives, it’s not clear that these extra features of the methods by themselves\\nare compelling enough to be decisive.\\n\\nFlexible reference syntax: Extra complexity and functional overlap\\nThe method call also supports key and attribute references directly, which some may\\nsee as more flexible. But as we saw in earlier examples comparing dictionary-based\\nformatting in the % expression to key and attribute references in the format method, the\\n\\nString Formatting Method Calls\\n\\n| 231\\n\\n\\x0ctwo are usually too similar to warrant a preference on these grounds. For instance, both\\ncan reference the same value multiple times:\\n\\n>>> \\'{name} {job} {name}\\'.format(name=\\'Bob\\', job=\\'dev\\')\\n\\'Bob dev Bob\\'\\n>>> \\'%(name)s %(job)s %(name)s\\' % dict(name=\\'Bob\\', job=\\'dev\\')\\n\\'Bob dev Bob\\'\\n\\nEspecially in common practice, though, the expression seems just as simple, or simpler:\\n\\n>>> D = dict(name=\\'Bob\\', job=\\'dev\\')\\n>>> \\'{0[name]} {0[job]} {0[name]}\\'.format(D)      # Method, key references\\n\\'Bob dev Bob\\'\\n>>> \\'{name} {job} {name}\\'.format(**D)             # Method, dict-to-args\\n\\'Bob dev Bob\\'\\n>>> \\'%(name)s %(job)s %(name)s\\' % D               # Expression, key references\\n\\'Bob dev Bob\\'\\n\\nTo be fair, the method has even more specialized substitution syntax, and other com-\\nparisons  might  favor  either  scheme  in  small  ways.  But  given  the  overlap  and  extra\\ncomplexity, one could argue that the format method’s utility seems either a wash, or\\nfeatures in search of use cases. At the least, the added conceptual burden on Python\\nprogrammers who may now need to know both tools doesn’t seem clearly justified.\\n\\nExplicit value references: Now optional and unlikely to be used\\nOne use case where the format method is at least debatably clearer is when there are\\nmany values to be substituted into the format string. The lister.py classes example we’ll\\nmeet in Chapter 31, for example, substitutes six items into a single string, and in this\\ncase the method’s {i} position labels seem marginally easier to read than the expres-\\nsion’s %s:\\n\\n\\'\\\\n%s<Class %s, address %s:\\\\n%s%s%s>\\\\n\\' % (...)               # Expression\\n\\n\\'\\\\n{0}<Class {1}, address {2}:\\\\n{3}{4}{5}>\\\\n\\'.format(...)     # Method\\n\\nOn the other hand, using dictionary keys in % expressions can mitigate much of this\\ndifference. This is also something of a worst-case scenario for formatting complexity,\\nand not very common in practice; more typical use cases seem more of a tossup. Further,\\nas of Python 3.1 and 2.7, numbering substitution targets becomes optional when rel-\\native to position, potentially subverting this purported benefit altogether:\\n\\n>>> \\'The {0} side {1} {2}\\'.format(\\'bright\\', \\'of\\', \\'life\\')     # Python 3.X, 2.6+\\n\\'The bright side of life\\'\\n\\n>>> \\'The {} side {} {}\\'.format(\\'bright\\', \\'of\\', \\'life\\')        # Python 3.1+, 2.7+\\n\\'The bright side of life\\'\\n\\n>>> \\'The %s side %s %s\\' % (\\'bright\\', \\'of\\', \\'life\\')            # All Pythons\\n\\'The bright side of life\\'\\n\\nGiven its conciseness, the second of these is likely to be preferred to the first, but seems\\nto negate part of the method’s advantage. Compare the effect on floating-point for-\\n\\n232 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cmatting, for example—the formatting expression is still more concise, and still seems\\nless cluttered:\\n\\n>>> \\'{0:f}, {1:.2f}, {2:05.2f}\\'.format(3.14159, 3.14159, 3.14159)\\n\\'3.141590, 3.14, 03.14\\'\\n\\n>>> \\'{:f}, {:.2f}, {:06.2f}\\'.format(3.14159, 3.14159, 3.14159)\\n\\'3.141590, 3.14, 003.14\\'\\n\\n>>> \\'%f, %.2f, %06.2f\\' % (3.14159, 3.14159, 3.14159)\\n\\'3.141590, 3.14, 003.14\\'\\n\\nNamed method and context-neutral arguments: Aesthetics versus practice\\nThe formatting method also claims an advantage in replacing the % operator with a\\nmore mnemonic format method name, and not distinguishing between single and mul-\\ntiple substitution values. The former may make the method appear simpler to beginners\\nat first glance (“format” may be easier to parse than multiple “%” characters), though\\nthis probably varies per reader and seems minor.\\nSome may see the latter difference as more significant—with the format expression, a\\nsingle value can be given by itself, but multiple values must be enclosed in a tuple:\\n\\n>>> \\'%.2f\\' % 1.2345                       # Single value\\n\\'1.23\\'\\n>>> \\'%.2f %s\\' % (1.2345, 99)              # Multiple values tuple\\n\\'1.23 99\\'\\n\\nTechnically, the formatting expression accepts either a single substitution value, or a\\ntuple of one or more items. As a consequence, because a single item can be given either\\nby itself or within a tuple, a tuple to be formatted must be provided as a nested tuple\\n—a perhaps rare but plausible case:\\n\\n>>> \\'%s\\' % 1.23                           # Single value, by itself\\n\\'1.23\\'\\n>>> \\'%s\\' % (1.23,)                        # Single value, in a tuple\\n\\'1.23\\'\\n>>> \\'%s\\' % ((1.23,),)                     # Single value that is a tuple\\n\\'(1.23,)\\'\\n\\nThe formatting method, on the other hand, tightens this up by accepting only general\\nfunction arguments in both cases, instead of requiring a tuple both for multiple values\\nor a single value that is a tuple:\\n\\n>>> \\'{0:.2f}\\'.format(1.2345)              # Single value\\n\\'1.23\\'\\n>>> \\'{0:.2f} {1}\\'.format(1.2345, 99)      # Multiple values\\n\\'1.23 99\\'\\n\\n>>> \\'{0}\\'.format(1.23)                    # Single value, by itself\\n\\'1.23\\'\\n>>> \\'{0}\\'.format((1.23,))                 # Single value that is a tuple\\n\\'(1.23,)\\'\\n\\nString Formatting Method Calls\\n\\n| 233\\n\\n\\x0cConsequently, the method might be less confusing to beginners and cause fewer pro-\\ngramming mistakes. This seems a fairly minor issue, though—if you always enclose\\nvalues in a tuple and ignore the nontupled option, the expression is essentially the same\\nas the method call here. Moreover, the method incurs a price in inflated code size to\\nachieve its constrained usage mode. Given the expression’s wide use over Python’s\\nhistory, this issue may be more theoretical than practical, and may not justify porting\\nexisting code to a new tool that is so similar to that it seeks to subsume.\\n\\nFunctions versus expressions: A minor convenience\\nThe final rationale for the format method—it’s a function that can appear where an\\nexpression cannot—requires more information about functions than we yet have at\\nthis point in the book, so we won’t dwell on it here. Suffice it to say that both the\\nstr.format method and the format built-in function can be passed to other functions,\\nstored in other objects, and so on. An expression like % cannot directly, but this may\\nbe narrow-sighted—it’s trivial to wrap any expression in a one-line def or partial-line\\nlambda once to turn it into a function with the same properties (though finding a reason\\nto do so may be more challenging):\\n\\ndef myformat(fmt, args): return fmt % args       # See Part IV\\n\\nmyformat(\\'%s %s\\', (88, 99))                      # Call your function object\\nstr.format(\\'{} {}\\', 88, 99)                      # Versus calling the built-in\\n\\notherfunction(myformat)                          # Your function is an object too\\n\\nIn the end, this may not be an either/or choice. While the expression still seems more\\npervasive in Python code, both formatting expressions and methods are available for\\nuse in Python today, and most programmers will benefit from being familiar with both\\ntechniques for years to come. That may double the work of newcomers to the language\\nin this department, but in this bazaar of ideas we call the open source software world,\\nthere always seems to be room for more.2\\n\\nPlus one more: Technically speaking, there are 3 (not 2) formatting tools\\nbuilt into Python, if we include the obscure string module’s Template\\ntool mentioned earlier. Now that we’ve seen the other two, I can show\\nyou how it compares. The expression and method can be used as tem-\\nplating tools too, referring to substitution values by name via dictionary\\nkeys or keyword arguments:\\n\\n>>> \\'%(num)i = %(title)s\\' % dict(num=7, title=\\'Strings\\')\\n\\'7 = Strings\\'\\n\\n2. See also the Chapter 31 note about a str.format bug (or regression) in Pythons 3.2 and 3.3 concerning\\ngeneric empty substitution targets for object attributes that define no __format__ handler. This impacted\\na working example from this book’s prior edition. While it may be a temporary regression, it does at the\\nleast underscore that this method is still a bit of a moving target—yet another reason to question the\\nfeature redundancy it implies.\\n\\n234 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0c>>> \\'{num:d} = {title:s}\\'.format(num=7, title=\\'Strings\\')\\n\\'7 = Strings\\'\\n>>> \\'{num} = {title}\\'.format(**dict(num=7, title=\\'Strings\\'))\\n\\'7 = Strings\\'\\n\\nThe module’s templating system allows values to be referenced by name\\ntoo, prefixed by a $, as either dictionary keys or keywords, but does not\\nsupport  all  the  utilities  of  the  other  two  methods—a  limitation  that\\nyields simplicity, the prime motivation for this tool:\\n\\n>>> import string\\n>>> t = string.Template(\\'$num = $title\\')\\n>>> t.substitute({\\'num\\': 7, \\'title\\': \\'Strings\\'})\\n\\'7 = Strings\\'\\n>>> t.substitute(num=7, title=\\'Strings\\')\\n\\'7 = Strings\\'\\n>>> t.substitute(dict(num=7, title=\\'Strings\\'))\\n\\'7 = Strings\\'\\n\\nSee Python’s manuals for more details. It’s possible that you may see\\nthis alternative (as well as additional tools in the third-party domain) in\\nPython code too; thankfully this technique is simple, and is used rarely\\nenough to warrant its limited coverage here. The best bet for most new-\\ncomers today is to learn and use %, str.format, or both.\\n\\nGeneral Type Categories\\nNow that we’ve explored the first of Python’s collection objects, the string, let’s close\\nthis chapter by defining a few general type concepts that will apply to most of the types\\nwe look at from here on. With regard to built-in types, it turns out that operations work\\nthe same for all the types in the same category, so we’ll only need to define most of\\nthese ideas once. We’ve only examined numbers and strings so far, but because they\\nare representative of two of the three major type categories in Python, you already know\\nmore about several other types than you might think.\\n\\nTypes Share Operation Sets by Categories\\nAs you’ve learned, strings are immutable sequences: they cannot be changed in place\\n(the immutable part), and they are positionally ordered collections that are accessed by\\noffset (the sequence part). It so happens that all the sequences we’ll study in this part\\nof the book respond to the same sequence operations shown in this chapter at work\\non strings—concatenation, indexing, iteration, and so on. More formally, there are\\nthree major type (and operation) categories in Python that have this generic nature:\\n\\nNumbers (integer, floating-point, decimal, fraction, others)\\n\\nSupport addition, multiplication, etc.\\n\\nSequences (strings, lists, tuples)\\n\\nSupport indexing, slicing, concatenation, etc.\\n\\nGeneral Type Categories\\n\\n| 235\\n\\n\\x0cMappings (dictionaries)\\n\\nSupport indexing by key, etc.\\n\\nI’m including the Python 3.X byte strings and 2.X Unicode strings I mentioned at the\\nstart of this chapter under the general “strings” label here (see Chapter 37). Sets are\\nsomething of a category unto themselves (they don’t map keys to values and are not\\npositionally ordered sequences), and we haven’t yet explored mappings on our in-depth\\ntour (we will in the next chapter). However, many of the other types we will encounter\\nwill be similar to numbers and strings. For example, for any sequence objects X and Y:\\n\\n• X + Y makes a new sequence object with the contents of both operands.\\n• X * N makes a new sequence object with N copies of the sequence operand X.\\n\\nIn other words, these operations work the same way on any kind of sequence, including\\nstrings, lists, tuples, and some user-defined object types. The only difference is that the\\nnew result object you get back is of the same type as the operands X and Y—if you\\nconcatenate lists, you get back a new list, not a string. Indexing, slicing, and other\\nsequence operations work the same on all sequences, too; the type of the objects being\\nprocessed tells Python which flavor of the task to perform.\\n\\nMutable Types Can Be Changed in Place\\nThe immutable classification is an important constraint to be aware of, yet it tends to\\ntrip up new users. If an object type is immutable, you cannot change its value in place;\\nPython raises an error if you try. Instead, you must run code to make a new object\\ncontaining the new value. The major core types in Python break down as follows:\\n\\nImmutables (numbers, strings, tuples, frozensets)\\n\\nNone  of  the  object  types  in  the  immutable  category  support  in-place  changes,\\nthough we can always run expressions to make new objects and assign their results\\nto variables as needed.\\n\\nMutables (lists, dictionaries, sets, bytearray)\\n\\nConversely, the mutable types can always be changed in place with operations that\\ndo not create new objects. Although such objects can be copied, in-place changes\\nsupport direct modification.\\n\\nGenerally, immutable types give some degree of integrity by guaranteeing that an object\\nwon’t be changed by another part of a program. For a refresher on why this matters,\\nsee the discussion of shared object references in Chapter 6. To see how lists, diction-\\naries, and tuples participate in type categories, we need to move ahead to the next \\nchapter.\\n\\n236 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cChapter Summary\\nIn this chapter, we took an in-depth tour of the string object type. We learned about\\ncoding string literals, and we explored string operations, including sequence expres-\\nsions, string method calls, and string formatting with both expressions and method\\ncalls. Along the way, we studied a variety of concepts in depth, such as slicing, method\\ncall syntax, and triple-quoted block strings. We also defined some core ideas common\\nto a variety of types: sequences, for example, share an entire set of operations.\\nIn the next chapter, we’ll continue our types tour with a look at the most general object\\ncollections  in  Python—lists  and  dictionaries.  As  you’ll  find,  much  of  what  you’ve\\nlearned here will apply to those types as well. And as mentioned earlier, in the final part\\nof this book we’ll return to Python’s string model to flesh out the details of Unicode\\ntext and binary data, which are of interest to some, but not all, Python programmers.\\nBefore moving on, though, here’s another chapter quiz to review the material covered\\nhere.\\n\\nTest Your Knowledge: Quiz\\n1. Can the string find method be used to search a list?\\n2. Can a string slice expression be used on a list?\\n3. How would you convert a character to its ASCII integer code? How would you\\n\\nconvert the other way, from an integer to a character?\\n4. How might you go about changing a string in Python?\\n5. Given a string S with the value \"s,pa,m\", name two ways to extract the two char-\\n\\nacters in the middle.\\n\\n6. How many characters are there in the string \"a\\\\nb\\\\x1f\\\\000d\"?\\n7. Why might you use the string module instead of string method calls?\\n\\nTest Your Knowledge: Answers\\n1. No, because methods are always type-specific; that is, they only work on a single\\ndata  type.  Expressions  like  X+Y  and  built-in  functions  like  len(X)  are  generic,\\nthough, and may work on a variety of types. In this case, for instance, the in mem-\\nbership expression has a similar effect as the string find, but it can be used to search\\nboth strings and lists. In Python 3.X, there is some attempt to group methods by\\ncategories (for example, the mutable sequence types list and bytearray have sim-\\nilar method sets), but methods are still more type-specific than other operation sets.\\n2. Yes. Unlike methods, expressions are generic and apply to many types. In this case,\\nthe slice expression is really a sequence operation—it works on any type of se-\\n\\nTest Your Knowledge: Answers\\n\\n| 237\\n\\n\\x0cquence object, including strings, lists, and tuples. The only difference is that when\\nyou slice a list, you get back a new list.\\n\\n3. The built-in  ord(S) function converts from a one-character string to an integer\\ncharacter code; chr(I) converts from the integer code back to a string. Keep in\\nmind, though, that these integers are only ASCII codes for text whose characters\\nare drawn only from ASCII character set. In the Unicode model, text strings are\\nreally sequences of Unicode code point identifying integers, which may fall outside\\nthe 7-bit range of numbers reserved by ASCII (more on Unicode in Chapter 4 and\\nChapter 37).\\n\\n4. Strings cannot be changed; they are immutable. However, you can achieve a similar\\neffect by creating a new string—by concatenating, slicing, running formatting ex-\\npressions, or using a method call like replace—and then assigning the result back\\nto the original variable name.\\n\\n5. You can slice the string using S[2:4], or split on the comma and index the string\\n\\nusing S.split(\\',\\')[1]. Try these interactively to see for yourself.\\n\\n6. Six. The string \"a\\\\nb\\\\x1f\\\\000d\" contains the characters a, newline (\\\\n), b, binary\\n31 (a hex escape \\\\x1f), binary 0 (an octal escape \\\\000), and d. Pass the string to the\\nbuilt-in len function to verify this, and print each of its character’s ord results to\\nsee the actual code point (identifying number) values. See Table 7-2 for more details\\non escapes.\\n\\n7. You should never use the string module instead of string object method calls today\\n—it’s deprecated, and its calls are removed completely in Python 3.X. The only\\nvalid reason for using the string module at all today is for its other tools, such as\\npredefined constants. You might also see it appear in what is now very old and\\ndusty Python code (and books of the misty past—like the 1990s).\\n\\n238 | Chapter 7:\\u2002String Fundamentals\\n\\n\\x0cCHAPTER 8\\nLists and Dictionaries\\n\\nNow that we’ve learned about numbers and strings, this chapter moves on to give the\\nfull story on Python’s list and dictionary object types—collections of other objects, and\\nthe main workhorses in almost all Python scripts. As you’ll see, both types are remark-\\nably flexible: they can be changed in place, can grow and shrink on demand, and may\\ncontain and be nested in any other kind of object. By leveraging these types, you can\\nbuild up and process arbitrarily rich information structures in your scripts.\\n\\nLists\\nThe next stop on our built-in object tour is the Python list. Lists are Python’s most\\nflexible ordered collection object type. Unlike strings, lists can contain any sort of ob-\\nject: numbers, strings, and even other lists. Also, unlike strings, lists may be changed\\nin place by assignment to offsets and slices, list method calls, deletion statements, and\\nmore—they are mutable objects.\\nPython lists do the work of many of the collection data structures you might have to\\nimplement manually in lower-level languages such as C. Here is a quick look at their\\nmain properties. Python lists are:\\n\\nOrdered collections of arbitrary objects\\n\\nFrom a functional view, lists are just places to collect other objects so you can treat\\nthem as groups. Lists also maintain a left-to-right positional ordering among the\\nitems they contain (i.e., they are sequences).\\n\\nAccessed by offset\\n\\nJust as with strings, you can fetch a component object out of a list by indexing the\\nlist on the object’s offset. Because items in lists are ordered by their positions, you\\ncan also do tasks such as slicing and concatenation.\\n\\nVariable-length, heterogeneous, and arbitrarily nestable\\n\\nUnlike strings, lists can grow and shrink in place (their lengths can vary), and they\\ncan contain any sort of object, not just one-character strings (they’re heterogene-\\n\\n239\\n\\n\\x0cous). Because lists can contain other complex objects, they also support arbitrary\\nnesting; you can create lists of lists of lists, and so on.\\n\\nOf the category “mutable sequence”\\n\\nIn terms of our type category qualifiers, lists are mutable (i.e., can be changed in\\nplace) and can respond to all the sequence operations used with strings, such as\\nindexing, slicing, and concatenation. In fact, sequence operations work the same\\non lists as they do on strings; the only difference is that sequence operations such\\nas concatenation and slicing return new lists instead of new strings when applied\\nto lists. Because lists are mutable, however, they also support other operations that\\nstrings don’t, such as deletion and index assignment operations, which change the\\nlists in place.\\n\\nArrays of object references\\n\\nTechnically, Python lists contain zero or more references to other objects. Lists\\nmight remind you of arrays of pointers (addresses) if you have a background in\\nsome other languages. Fetching an item from a Python list is about as fast as in-\\ndexing a C array; in fact, lists really are arrays inside the standard Python inter-\\npreter, not linked structures. As we learned in Chapter 6, though, Python always\\nfollows a reference to an object whenever the reference is used, so your program\\ndeals only with objects. Whenever you assign an object to a data structure com-\\nponent or variable name, Python always stores a reference to that same object, not\\na copy of it (unless you request a copy explicitly).\\n\\nAs  a  preview  and  reference,  Table  8-1  summarizes  common  and  representative  list\\nobject operations. It is fairly complete for Python 3.3, but for the full story, consult the\\nPython standard library manual, or run a help(list) or dir(list) call interactively for\\na complete list of list methods—you can pass in a real list, or the word list, which is\\nthe name of the list data type. The set of methods here is especially prone to change—\\nin fact, two are new as of Python 3.3.\\n\\nTable 8-1. Common list literals and operations\\n\\nOperation\\nL = []\\n\\nL = [123, \\'abc\\', 1.23, {}]\\n\\nL = [\\'Bob\\', 40.0, [\\'dev\\', \\'mgr\\']]\\n\\nL = list(\\'spam\\')\\n\\nL = list(range(-4, 4))\\n\\nL[i]\\n\\nL[i][j]\\n\\nL[i:j]\\n\\nlen(L)\\n\\nL1 + L2\\n\\nInterpretation\\nAn empty list\\nFour items: indexes 0..3\\nNested sublists\\nList of an iterable’s items, list of successive integers\\n\\nIndex, index of index, slice, length\\n\\nConcatenate, repeat\\n\\n240 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cOperation\\nL * 3\\n\\nInterpretation\\n\\nfor x in L: print(x)\\n\\nIteration, membership\\n\\n3 in L\\n\\nL.append(4)\\n\\nL.extend([5,6,7])\\n\\nL.insert(i, X)\\n\\nL.index(X)\\n\\nL.count(X)\\n\\nL.sort()\\n\\nL.reverse()\\n\\nL.copy()\\n\\nL.clear()\\n\\nL.pop(i)\\n\\nL.remove(X)\\n\\ndel L[i]\\n\\ndel L[i:j]\\n\\nL[i:j] = []\\n\\nL[i] = 3\\n\\nMethods: growing\\n\\nMethods: searching\\n\\nMethods: sorting, reversing,\\ncopying (3.3+), clearing (3.3+)\\n\\nMethods, statements: shrinking\\n\\nIndex assignment, slice assignment\\n\\nL[i:j] = [4,5,6]\\n\\nL = [x**2 for x in range(5)]\\n\\nList comprehensions and maps (Chapter 4, Chapter 14, Chapter 20)\\n\\nlist(map(ord, \\'spam\\'))\\n\\nWhen written down as a literal expression, a list is coded as a series of objects (really,\\nexpressions that return objects) in square brackets, separated by commas. For instance,\\nthe second row in Table 8-1 assigns the variable L to a four-item list. A nested list is\\ncoded as a nested square-bracketed series (row 3), and the empty list is just a square-\\nbracket pair with nothing inside (row 1).1\\nMany of the operations in Table 8-1 should look familiar, as they are the same sequence\\noperations we put to work on strings earlier—indexing, concatenation, iteration, and\\nso on. Lists also respond to list-specific method calls (which provide utilities such as\\nsorting, reversing, adding items to the end, etc.), as well as in-place change operations\\n\\n1. In practice, you won’t see many lists written out like this in list-processing programs. It’s more common\\nto see code that processes lists constructed dynamically (at runtime), from user inputs, file contents, and\\nso on. In fact, although it’s important to master literal syntax, many data structures in Python are built\\nby running program code at runtime.\\n\\nLists\\n\\n| 241\\n\\n\\x0c(deleting items, assignment to indexes and slices, and so forth). Lists have these tools\\nfor change operations because they are a mutable object type.\\n\\nLists in Action\\nPerhaps the best way to understand lists is to see them at work. Let’s once again turn\\nto some simple interpreter interactions to illustrate the operations in Table 8-1.\\n\\nBasic List Operations\\nBecause they are sequences, lists support many of the same operations as strings. For\\nexample, lists respond to the + and * operators much like strings—they mean concat-\\nenation and repetition here too, except that the result is a new list, not a string:\\n\\n% python\\n>>> len([1, 2, 3])                           # Length\\n3\\n>>> [1, 2, 3] + [4, 5, 6]                    # Concatenation\\n[1, 2, 3, 4, 5, 6]\\n>>> [\\'Ni!\\'] * 4                              # Repetition\\n[\\'Ni!\\', \\'Ni!\\', \\'Ni!\\', \\'Ni!\\']\\n\\nAlthough the + operator works the same for lists and strings, it’s important to know\\nthat it expects the same sort of sequence on both sides—otherwise, you get a type error\\nwhen the code runs. For instance, you cannot concatenate a list and a string unless you\\nfirst convert the list to a string (using tools such as str or % formatting) or convert the\\nstring to a list (the list built-in function does the trick):\\n\\n>>> str([1, 2]) + \"34\"                       # Same as \"[1, 2]\" + \"34\"\\n\\'[1, 2]34\\'\\n>>> [1, 2] + list(\"34\")                      # Same as [1, 2] + [\"3\", \"4\"]\\n[1, 2, \\'3\\', \\'4\\']\\n\\nList Iteration and Comprehensions\\nMore generally, lists respond to all the sequence operations we used on strings in the\\nprior chapter, including iteration tools:\\n\\n>>> 3 in [1, 2, 3]                           # Membership\\nTrue\\n>>> for x in [1, 2, 3]:\\n...     print(x, end=\\' \\')                    # Iteration (2.X uses: print x,)\\n...\\n1 2 3\\n\\nWe will talk more formally about for iteration and the range built-ins of Table 8-1 in\\nChapter  13,  because  they  are  related  to  statement  syntax.  In  short,  for  loops  step\\nthrough items in any sequence from left to right, executing one or more statements for\\neach item; range produces successive integers.\\n\\n242 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cThe last items in Table 8-1, list comprehensions and map calls, are covered in more detail\\nin Chapter 14 and expanded on in Chapter 20. Their basic operation is straightforward,\\nthough—as introduced in Chapter 4, list comprehensions are a way to build a new list\\nby applying an expression to each item in a sequence (really, in any iterable), and are\\nclose relatives to for loops:\\n\\n>>> res = [c * 4 for c in \\'SPAM\\']            # List comprehensions\\n>>> res\\n[\\'SSSS\\', \\'PPPP\\', \\'AAAA\\', \\'MMMM\\']\\n\\nThis expression is functionally equivalent to a for loop that builds up a list of results\\nmanually, but as we’ll learn in later chapters, list comprehensions are simpler to code\\nand likely faster to run today:\\n\\n>>> res = []\\n>>> for c in \\'SPAM\\':                         # List comprehension equivalent\\n...     res.append(c * 4)\\n...\\n>>> res\\n[\\'SSSS\\', \\'PPPP\\', \\'AAAA\\', \\'MMMM\\']\\n\\nAs also introduced briefly in Chapter 4, the map built-in function does similar work, but\\napplies a function to items in a sequence and collects all the results in a new list:\\n\\n>>> list(map(abs, [−1, −2, 0, 1, 2]))        # Map a function across a sequence\\n[1, 2, 0, 1, 2]\\n\\nBecause we’re not quite ready for the full iteration story, we’ll postpone further details\\nfor now, but watch for a similar comprehension expression for dictionaries later in this\\nchapter.\\n\\nIndexing, Slicing, and Matrixes\\nBecause lists are sequences, indexing and slicing work the same way for lists as they do\\nfor strings. However, the result of indexing a list is whatever type of object lives at the\\noffset you specify, while slicing a list always returns a new list:\\n\\n>>> L = [\\'spam\\', \\'Spam\\', \\'SPAM!\\']\\n>>> L[2]                              # Offsets start at zero\\n\\'SPAM!\\'\\n>>> L[−2]                             # Negative: count from the right\\n\\'Spam\\'\\n>>> L[1:]                             # Slicing fetches sections\\n[\\'Spam\\', \\'SPAM!\\']\\n\\nOne note here: because you can nest lists and other object types within lists, you will\\nsometimes need to string together index operations to go deeper into a data structure.\\nFor example, one of the simplest ways to represent matrixes (multidimensional arrays)\\nin Python is as lists with nested sublists. Here’s a basic 3 × 3 two-dimensional list-based\\narray:\\n\\n>>> matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\n\\nLists in Action | 243\\n\\n\\x0cWith one index, you get an entire row (really, a nested sublist), and with two, you get\\nan item within the row:\\n\\n>>> matrix[1]\\n[4, 5, 6]\\n>>> matrix[1][1]\\n5\\n>>> matrix[2][0]\\n7\\n>>> matrix = [[1, 2, 3],\\n...           [4, 5, 6],\\n...           [7, 8, 9]]\\n>>> matrix[1][1]\\n5\\n\\nNotice in the preceding interaction that lists can naturally span multiple lines if you\\nwant  them  to  because  they  are  contained  by  a  pair  of  brackets;  the  “...”s  here  are\\nPython’s continuation line prompt (see Chapter 4 for comparable code without the\\n“...”s, and watch for more on syntax in the next part of the book).\\nFor more on matrixes, watch later in this chapter for a dictionary-based matrix repre-\\nsentation, which can be more efficient when matrixes are largely empty. We’ll also\\ncontinue this thread in Chapter 20 where we’ll write additional matrix code, especially\\nwith  list  comprehensions.  For  high-powered  numeric  work,  the  NumPy  extension\\nmentioned in Chapter 4 and Chapter 5 provides other ways to handle matrixes.\\n\\nChanging Lists in Place\\nBecause lists are mutable, they support operations that change a list object in place.\\nThat is, the operations in this section all modify the list object directly—overwriting\\nits former value—without requiring that you make a new copy, as you had to for strings.\\nBecause Python deals only in object references, this distinction between changing an\\nobject in place and creating a new object matters; as discussed in Chapter 6, if you\\nchange an object in place, you might impact more than one reference to it at the same\\ntime.\\n\\nIndex and slice assignments\\nWhen using a list, you can change its contents by assigning to either a particular item\\n(offset) or an entire section (slice):\\n\\n>>> L = [\\'spam\\', \\'Spam\\', \\'SPAM!\\']\\n>>> L[1] = \\'eggs\\'                     # Index assignment\\n>>> L\\n[\\'spam\\', \\'eggs\\', \\'SPAM!\\']\\n\\n>>> L[0:2] = [\\'eat\\', \\'more\\']          # Slice assignment: delete+insert\\n>>> L                                 # Replaces items 0,1\\n[\\'eat\\', \\'more\\', \\'SPAM!\\']\\n\\n244 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cBoth index and slice assignments are in-place changes—they modify the subject list\\ndirectly, rather than generating a new list object for the result. Index assignment in\\nPython works much as it does in C and most other languages: Python replaces the single\\nobject reference at the designated offset with a new one.\\nSlice assignment, the last operation in the preceding example, replaces an entire section\\nof a list in a single step. Because it can be a bit complex, it is perhaps best thought of\\nas a combination of two steps:\\n\\n1. Deletion. The slice you specify to the left of the = is deleted.\\n2. Insertion. The new items contained in the iterable object to the right of the = are\\n\\ninserted into the list on the left, at the place where the old slice was deleted.2\\n\\nThis isn’t what really happens, but it can help clarify why the number of items inserted\\ndoesn’t have to match the number of items deleted. For instance, given a list L of two\\nor more items, an assignment L[1:2]=[4,5] replaces one item with two—Python first\\ndeletes the one-item slice at [1:2] (from offset 1, up to but not including offset 2), then\\ninserts both 4 and 5 where the deleted slice used to be.\\nThis also explains why the second slice assignment in the following is really an insert\\n—Python replaces an empty slice at [1:1] with two items; and why the third is really\\na deletion—Python deletes the slice (the item at offset 1), and then inserts nothing:\\n\\n>>> L = [1, 2, 3]\\n>>> L[1:2] = [4, 5]                   # Replacement/insertion\\n>>> L\\n[1, 4, 5, 3]\\n>>> L[1:1] = [6, 7]                   # Insertion (replace nothing)\\n>>> L\\n[1, 6, 7, 4, 5, 3]\\n>>> L[1:2] = []                       # Deletion (insert nothing)\\n>>> L\\n[1, 7, 4, 5, 3]\\n\\nIn effect, slice assignment replaces an entire section, or “column,” all at once—even if\\nthe column or its replacement is empty. Because the length of the sequence being as-\\nsigned does not have to match the length of the slice being assigned to, slice assignment\\ncan be used to replace (by overwriting), expand (by inserting), or shrink (by deleting)\\nthe subject list. It’s a powerful operation, but frankly, one that you may not see very\\noften in practice. There are often more straightforward and mnemonic ways to replace,\\ninsert, and delete (concatenation, and the insert, pop, and remove list methods, for\\nexample), which Python programmers tend to prefer in practice.\\n\\n2. This  description  requires  elaboration  when  the  value  and  the  slice  being  assigned  overlap:\\nL[2:5]=L[3:6], for instance, works fine because the value to be inserted is fetched before the deletion\\nhappens on the left.\\n\\nLists in Action | 245\\n\\n\\x0cOn the other hand, this operation can be used as a sort of in-place concatenation at the\\nfront of the list—per the next section’s method coverage, something the list’s extend\\ndoes more mnemonically at list end:\\n\\n>>> L = [1]\\n>>> L[:0] = [2, 3, 4]        # Insert all at :0, an empty slice at front\\n>>> L\\n[2, 3, 4, 1]\\n>>> L[len(L):] = [5, 6, 7]   # Insert all at len(L):, an empty slice at end\\n>>> L\\n[2, 3, 4, 1, 5, 6, 7]\\n>>> L.extend([8, 9, 10])     # Insert all at end, named method\\n>>> L\\n[2, 3, 4, 1, 5, 6, 7, 8, 9, 10]\\n\\nList method calls\\nLike strings, Python list objects also support type-specific method calls, many of which\\nchange the subject list in place:\\n\\n>>> L = [\\'eat\\', \\'more\\', \\'SPAM!\\']\\n>>> L.append(\\'please\\')                # Append method call: add item at end\\n>>> L\\n[\\'eat\\', \\'more\\', \\'SPAM!\\', \\'please\\']\\n>>> L.sort()                          # Sort list items (\\'S\\' < \\'e\\')\\n>>> L\\n[\\'SPAM!\\', \\'eat\\', \\'more\\', \\'please\\']\\n\\nMethods were introduced in Chapter 7. In brief, they are functions (really, object at-\\ntributes that reference functions) that are associated with and act upon particular ob-\\njects. Methods provide type-specific tools; the list methods presented here, for instance,\\nare generally available only for lists.\\nPerhaps the most commonly used list method is append, which simply tacks a single\\nitem (object reference) onto the end of the list. Unlike concatenation, append expects\\nyou to pass in a single object, not a list. The effect of L.append(X) is similar to L+[X],\\nbut while the former changes L in place, the latter makes a new list.3 The sort method\\norders the list’s items here, but merits a section of its own.\\n\\nMore on sorting lists\\nAnother commonly seen method, sort, orders a list in place; it uses Python standard\\ncomparison tests (here, string comparisons, but applicable to every object type), and\\n\\n3. Unlike + concatenation, append doesn’t have to generate new objects, so it’s usually faster than + too. You\\ncan  also  mimic  append  with  the  clever  slice  assignments  of  the  prior  section:  L[len(L):]=[X]  is  like\\nL.append(X), and L[:0]=[X] is like appending at the front of a list. Both delete an empty slice and insert\\nX, changing L in place quickly, like append. Both are arguably more complex than list methods, though.\\nFor instance, L.insert(0, X) can also append an item to the front of a list, and seems noticeably more\\nmnemonic; L.insert(len(L), X) inserts one object at the end too, but unless you like typing, you might\\nas well use L.append(X)!\\n\\n246 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cby default sorts in ascending order. You can modify sort behavior by passing in keyword\\narguments—a special “name=value” syntax in function calls that specifies passing by\\nname and is often used for giving configuration options.\\nIn sorts, the reverse argument allows sorts to be made in descending instead of as-\\ncending order, and the key argument gives a one-argument function that returns the\\nvalue to be used in sorting—the string object’s standard lower case converter in the\\nfollowing (though its newer casefold may handle some types of Unicode text better):\\n\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> L.sort()                                # Sort with mixed case\\n>>> L\\n[\\'ABD\\', \\'aBe\\', \\'abc\\']\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> L.sort(key=str.lower)                   # Normalize to lowercase\\n>>> L\\n[\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>>\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> L.sort(key=str.lower, reverse=True)     # Change sort order\\n>>> L\\n[\\'aBe\\', \\'ABD\\', \\'abc\\']\\n\\nThe sort key argument might also be useful when sorting lists of dictionaries, to pick\\nout a sort key by indexing each dictionary. We’ll study dictionaries later in this chapter,\\nand you’ll learn more about keyword function arguments in Part IV.\\n\\nComparison and sorts in 3.X: In Python 2.X, relative magnitude com-\\nparisons of differently typed objects (e.g., a string and a list) work—the\\nlanguage defines a fixed ordering among different types, which is de-\\nterministic, if not aesthetically pleasing. That is, the ordering is based\\non the names of the types involved: all integers are less than all strings,\\nfor example, because \"int\" is less than \"str\". Comparisons never au-\\ntomatically  convert  types,  except  when  comparing  numeric  type  ob-\\njects.\\n\\nIn Python 3.X, this has changed: magnitude comparison of mixed types\\nraises an exception instead of falling back on the fixed cross-type or-\\ndering.  Because  sorting  uses  comparisons  internally,  this  means  that\\n[1, 2, \\'spam\\'].sort() succeeds in Python 2.X but will raise an excep-\\ntion in Python 3.X. Sorting mixed-types fails by proxy.\\n\\nPython 3.X also no longer supports passing in an arbitrary comparison\\nfunction to sorts, to implement different orderings. The suggested work-\\naround is to use the key=func keyword argument to code value trans-\\nformations during the sort, and use the reverse=True keyword argument\\nto change the sort order to descending. These were the typical uses of\\ncomparison functions in the past.\\n\\nLists in Action | 247\\n\\n\\x0cOne warning here: beware that append and sort change the associated list object in\\nplace, but don’t return the list as a result (technically, they both return a value called\\nNone). If you say something like L=L.append(X), you won’t get the modified value of L\\n(in fact, you’ll lose the reference to the list altogether!). When you use attributes such\\nas append and sort, objects are changed as a side effect, so there’s no reason to reassign.\\nPartly because of such constraints, sorting is also available in recent Pythons as a built-\\nin function, which sorts any collection (not just lists) and returns a new list for the result\\n(instead of in-place changes):\\n\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> sorted(L, key=str.lower, reverse=True)          # Sorting built-in\\n[\\'aBe\\', \\'ABD\\', \\'abc\\']\\n\\n>>> L = [\\'abc\\', \\'ABD\\', \\'aBe\\']\\n>>> sorted([x.lower() for x in L], reverse=True)    # Pretransform items: differs!\\n[\\'abe\\', \\'abd\\', \\'abc\\']\\n\\nNotice the last example here—we can convert to lowercase prior to the sort with a list\\ncomprehension, but the result does not contain the original list’s values as it does with\\nthe key argument. The latter is applied temporarily during the sort, instead of changing\\nthe values to be sorted altogether. As we move along, we’ll see contexts in which the\\nsorted built-in can sometimes be more useful than the sort method.\\n\\nOther common list methods\\nLike strings, lists have other methods that perform other specialized operations. For\\ninstance, reverse reverses the list in-place, and the extend and pop methods insert mul-\\ntiple items at and delete an item from the end of the list, respectively. There is also a\\nreversed built-in function that works much like sorted and returns a new result object,\\nbut it must be wrapped in a list call in both 2.X and 3.X here because its result is an\\niterator that produces results on demand (more on iterators later):\\n\\n>>> L = [1, 2]\\n>>> L.extend([3, 4, 5])              # Add many items at end (like in-place +)\\n>>> L\\n[1, 2, 3, 4, 5]\\n>>> L.pop()                          # Delete and return last item (by default: −1)\\n5\\n>>> L\\n[1, 2, 3, 4]\\n>>> L.reverse()                      # In-place reversal method\\n>>> L\\n[4, 3, 2, 1]\\n>>> list(reversed(L))                # Reversal built-in with a result (iterator)\\n[1, 2, 3, 4]\\n\\nTechnically, the extend method always iterates through and adds each item in an itera-\\nble object, whereas append simply adds a single item as is without iterating through it\\n—a distinction that will be more meaningful by Chapter 14. For now, it’s enough to\\nknow that extend adds many items, and append adds one. In some types of programs,\\n\\n248 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cthe list pop method is often used in conjunction with append to implement a quick last-\\nin-first-out (LIFO) stack structure. The end of the list serves as the top of the stack:\\n\\n>>> L = []\\n>>> L.append(1)                      # Push onto stack\\n>>> L.append(2)\\n>>> L\\n[1, 2]\\n>>> L.pop()                          # Pop off stack\\n2\\n>>> L\\n[1]\\n\\nThe pop method also accepts an optional offset of the item to be deleted and returned\\n(the default is the last item at offset −1). Other list methods remove an item by value\\n(remove),  insert  an  item  at  an  offset  (insert),  count  the  number  of  occurrences\\n(count), and search for an item’s offset (index—a search for the index of an item, not\\nto be confused with indexing!):\\n\\n>>> L = [\\'spam\\', \\'eggs\\', \\'ham\\']\\n>>> L.index(\\'eggs\\')                  # Index of an object (search/find)\\n1\\n>>> L.insert(1, \\'toast\\')             # Insert at position\\n>>> L\\n[\\'spam\\', \\'toast\\', \\'eggs\\', \\'ham\\']\\n>>> L.remove(\\'eggs\\')                 # Delete by value\\n>>> L\\n[\\'spam\\', \\'toast\\', \\'ham\\']\\n>>> L.pop(1)                         # Delete by position\\n\\'toast\\'\\n>>> L\\n[\\'spam\\', \\'ham\\']\\n>>> L.count(\\'spam\\')                  # Number of occurrences\\n1\\n\\nNote that unlike other list methods, count and index do not change the list itself, but\\nreturn information about its content. See other documentation sources or experiment\\nwith these calls interactively on your own to learn more about list methods.\\n\\nOther common list operations\\nBecause lists are mutable, you can use the del statement to delete an item or section in\\nplace:\\n\\n>>> L = [\\'spam\\', \\'eggs\\', \\'ham\\', \\'toast\\']\\n>>> del L[0]                         # Delete one item\\n>>> L\\n[\\'eggs\\', \\'ham\\', \\'toast\\']\\n>>> del L[1:]                        # Delete an entire section\\n>>> L                                # Same as L[1:] = []\\n[\\'eggs\\']\\n\\nAs we saw earlier, because slice assignment is a deletion plus an insertion, you can also\\ndelete a section of a list by assigning an empty list to a slice (L[i:j]=[]); Python deletes\\n\\nLists in Action | 249\\n\\n\\x0cthe slice named on the left, and then inserts nothing. Assigning an empty list to an\\nindex, on the other hand, just stores a reference to the empty list object in the specified\\nslot, rather than deleting an item:\\n\\n>>> L = [\\'Already\\', \\'got\\', \\'one\\']\\n>>> L[1:] = []\\n>>> L\\n[\\'Already\\']\\n>>> L[0] = []\\n>>> L\\n[[]]\\n\\nAlthough  all  the  operations  just  discussed  are  typical,  there  may  be  additional  list\\nmethods and operations not illustrated here. The method set, for example, may change\\nover time, and in fact has in Python 3.3—its new L.copy() method makes a top-level\\ncopy of the list, much like L[:] and list(L), but is symmetric with copy in sets and\\ndictionaries. For a comprehensive and up-to-date list of type tools, you should always\\nconsult  Python’s  manuals,  Python’s  dir  and  help  functions  (which  we  first  met  in\\nChapter 4), or one of the reference texts mentioned in the preface.\\nAnd because it’s such a common hurdle, I’d also like to remind you again that all the\\nin-place change operations discussed here work only for mutable objects: they won’t\\nwork on strings (or tuples, discussed in Chapter 9), no matter how hard you try. Mu-\\ntability is an inherent property of each object type.\\n\\nDictionaries\\nAlong with lists, dictionaries are one of the most flexible built-in data types in Python.\\nIf you think of lists as ordered collections of objects, you can think of dictionaries as\\nunordered collections; the chief distinction is that in dictionaries, items are stored and\\nfetched by key, instead of by positional offset. While lists can serve roles similar to\\narrays in other languages, dictionaries take the place of records, search tables, and any\\nother sort of aggregation where item names are more meaningful than item positions.\\nFor example, dictionaries can replace many of the searching algorithms and data struc-\\ntures you might have to implement manually in lower-level languages—as a highly\\noptimized built-in type, indexing a dictionary is a very fast search operation. Diction-\\naries also sometimes do the work of records, structs, and symbol tables used in other\\nlanguages; can be used to represent sparse (mostly empty) data structures; and much\\nmore. Here’s a rundown of their main properties. Python dictionaries are:\\n\\nAccessed by key, not offset position\\n\\nDictionaries are sometimes called associative arrays or hashes (especially by users\\nof other scripting languages). They associate a set of values with keys, so you can\\nfetch an item out of a dictionary using the key under which you originally stored\\nit. You use the same indexing operation to get components in a dictionary as you\\ndo in a list, but the index takes the form of a key, not a relative offset.\\n\\n250 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cUnordered collections of arbitrary objects\\n\\nUnlike in a list, items stored in a dictionary aren’t kept in any particular order; in\\nfact, Python pseudo-randomizes their left-to-right order to provide quick lookup.\\nKeys provide the symbolic (not physical) locations of items in a dictionary.\\n\\nVariable-length, heterogeneous, and arbitrarily nestable\\n\\nLike lists, dictionaries can grow and shrink in place (without new copies being\\nmade), they can contain objects of any type, and they support nesting to any depth\\n(they can contain lists, other dictionaries, and so on). Each key can have just one\\nassociated value, but that value can be a collection of multiple objects if needed,\\nand a given value can be stored under any number of keys.\\n\\nOf the category “mutable mapping”\\n\\nYou can change dictionaries in place by assigning to indexes (they are mutable),\\nbut they don’t support the sequence operations that work on strings and lists.\\nBecause dictionaries are unordered collections, operations that depend on a fixed\\npositional order (e.g., concatenation, slicing) don’t make sense. Instead, diction-\\naries  are  the  only  built-in,  core  type  representatives  of  the  mapping  category—\\nobjects that map keys to values. Other mappings in Python are created by imported\\nmodules.\\n\\nTables of object references (hash tables)\\n\\nIf lists are arrays of object references that support access by position, dictionaries\\nare unordered tables of object references that support access by key. Internally,\\ndictionaries are implemented as hash tables (data structures that support very fast\\nretrieval), which start small and grow on demand. Moreover, Python employs op-\\ntimized hashing algorithms to find keys, so retrieval is quick. Like lists, dictionaries\\nstore object references (not copies, unless you ask for them explicitly).\\n\\nFor reference and preview again, Table 8-2 summarizes some of the most common and\\nrepresentative dictionary operations, and is relatively complete as of Python 3.3. As\\nusual, though, see the library manual or run a dir(dict) or help(dict) call for a com-\\nplete list—dict is the name of the type. When coded as a literal expression, a dictionary\\nis  written  as  a  series  of  key:value  pairs,  separated  by  commas,  enclosed  in  curly\\nbraces.4 An empty dictionary is an empty set of braces, and you can nest dictionaries\\nby simply coding one as a value inside another dictionary, or within a list or tuple.\\n\\n4. As for lists, you might not see dictionaries coded in full using literals very often—programs rarely know\\nall their data before they are run, and more typically extract it dynamically from users, files, and so on.\\nLists and dictionaries are grown in different ways, though. In the next section you’ll see that you often\\nbuild up dictionaries by assigning to new keys at runtime; this approach fails for lists, which are commonly\\ngrown with append or extend instead.\\n\\nDictionaries\\n\\n| 251\\n\\n\\x0cTable 8-2. Common dictionary literals and operations\\n\\nOperation\\nD = {}\\n\\nD = {\\'name\\': \\'Bob\\', \\'age\\': 40}\\n\\nE = {\\'cto\\': {\\'name\\': \\'Bob\\', \\'age\\': 40}}\\n\\nD = dict(name=\\'Bob\\', age=40)\\n\\nD = dict([(\\'name\\', \\'Bob\\'), (\\'age\\', 40)])\\n\\nD = dict(zip(keyslist, valueslist))\\n\\nD = dict.fromkeys([\\'name\\', \\'age\\'])\\n\\nInterpretation\\nEmpty dictionary\\nTwo-item dictionary\\nNesting\\nAlternative construction techniques:\\nkeywords, key/value pairs, zipped key/value pairs, key lists\\n\\nD[\\'name\\']\\n\\nE[\\'cto\\'][\\'age\\']\\n\\n\\'age\\' in D\\n\\nD.keys()\\n\\nD.values()\\n\\nD.items()\\n\\nD.copy()\\n\\nD.clear()\\n\\nD.update(D2)\\n\\nD.get(key, default?)\\n\\nD.pop(key, default?)\\n\\nD.setdefault(key, default?)\\n\\nD.popitem()\\n\\nlen(D)\\n\\nD[key] = 42\\n\\ndel D[key]\\n\\nlist(D.keys())\\n\\nD1.keys() & D2.keys()\\n\\nIndexing by key\\n\\nMembership: key present test\\nMethods: all keys,\\nall values,\\nall key+value tuples,\\ncopy (top-level),\\nclear (remove all items),\\nmerge by keys,\\nfetch by key, if absent default (or None),\\nremove by key, if absent default (or error)\\nfetch by key, if absent set default (or None),\\nremove/return any (key, value) pair; etc.\\nLength: number of stored entries\\nAdding/changing keys\\nDeleting entries by key\\nDictionary views (Python 3.X)\\n\\nD.viewkeys(), D.viewvalues()\\n\\nD = {x: x*2 for x in range(10)}\\n\\nDictionary views (Python 2.7)\\nDictionary comprehensions (Python 3.X, 2.7)\\n\\nDictionaries in Action\\nAs Table 8-2 suggests, dictionaries are indexed by key, and nested dictionary entries\\nare referenced by a series of indexes (keys in square brackets). When Python creates a\\ndictionary, it stores its items in any left-to-right order it chooses; to fetch a value back,\\n\\n252 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cyou supply the key with which it is associated, not its relative position. Let’s go back\\nto the interpreter to get a feel for some of the dictionary operations in Table 8-2.\\n\\nBasic Dictionary Operations\\nIn normal operation, you create dictionaries with literals and store and access items by\\nkey with indexing:\\n\\n% python\\n>>> D = {\\'spam\\': 2, \\'ham\\': 1, \\'eggs\\': 3}      # Make a dictionary\\n>>> D[\\'spam\\']                                 # Fetch a value by key\\n2\\n>>> D                                         # Order is \"scrambled\"\\n{\\'eggs\\': 3, \\'spam\\': 2, \\'ham\\': 1}\\n\\nHere, the dictionary is assigned to the variable D; the value of the key \\'spam\\' is the\\ninteger 2, and so on. We use the same square bracket syntax to index dictionaries by\\nkey as we did to index lists by offset, but here it means access by key, not by position.\\nNotice the end of this example—much like sets, the  left-to-right order of keys in a\\ndictionary will almost always be different from what you originally typed. This is on\\npurpose: to implement fast key lookup (a.k.a. hashing), keys need to be reordered in\\nmemory. That’s why operations that assume a fixed left-to-right order (e.g., slicing,\\nconcatenation) do not apply to dictionaries; you can fetch values only by key, not by\\nposition. Technically, the ordering is pseudo-random—it’s not truly random (you might\\nbe able to decipher it given Python’s source code and a lot of time to kill), but it’s\\narbitrary, and might vary per release and platform, and even per interactive session in\\nPython 3.3.\\nThe built-in len function works on dictionaries, too; it returns the number of items\\nstored in the dictionary or, equivalently, the length of its keys list. The dictionary in\\nmembership operator allows you to test for key existence, and the keys method returns\\nall the keys in the dictionary. The latter of these can be useful for processing dictionaries\\nsequentially, but you shouldn’t depend on the order of the keys list. Because the keys\\nresult can be used as a normal list, however, it can always be sorted if order matters\\n(more on sorting and dictionaries later):\\n\\n>>> len(D)                                    # Number of entries in dictionary\\n3\\n>>> \\'ham\\' in D                                # Key membership test alternative\\nTrue\\n>>> list(D.keys())                            # Create a new list of D\\'s keys\\n[\\'eggs\\', \\'spam\\', \\'ham\\']\\n\\nObserve the second expression in this listing. As mentioned earlier, the in membership\\ntest used for strings and lists also works on dictionaries—it checks whether a key is\\nstored in the dictionary. Technically, this works because dictionaries define iterators\\nthat step through their keys lists automatically. Other types provide iterators that reflect\\n\\nDictionaries in Action | 253\\n\\n\\x0ctheir common uses; files, for example, have iterators that read line by line. We’ll discuss\\niterators more formally in Chapter 14 and Chapter 20.\\nAlso note the syntax of the last example in this listing. We have to enclose it in a list\\ncall in Python 3.X for similar reasons—keys in 3.X returns an iterable object, instead\\nof a physical list. The list call forces it to produce all its values at once so we can print\\nthem interactively, though this call isn’t required some other contexts. In 2.X, keys\\nbuilds and returns an actual list, so the list call isn’t even needed to display a result;\\nmore on this later in this chapter.\\n\\nChanging Dictionaries in Place\\nLet’s continue with our interactive session. Dictionaries, like lists, are mutable, so you\\ncan change, expand, and shrink them in place without making new dictionaries: simply\\nassign a value to a key to change or create an entry. The del statement works here, too;\\nit deletes the entry associated with the key specified as an index. Notice also the nesting\\nof a list inside a dictionary in this example (the value of the key \\'ham\\'). All collection\\ndata types in Python can nest inside each other arbitrarily:\\n\\n>>> D\\n{\\'eggs\\': 3, \\'spam\\': 2, \\'ham\\': 1}\\n\\n>>> D[\\'ham\\'] = [\\'grill\\', \\'bake\\', \\'fry\\']           # Change entry (value=list)\\n>>> D\\n{\\'eggs\\': 3, \\'spam\\': 2, \\'ham\\': [\\'grill\\', \\'bake\\', \\'fry\\']}\\n\\n>>> del D[\\'eggs\\']                                 # Delete entry\\n>>> D\\n{\\'spam\\': 2, \\'ham\\': [\\'grill\\', \\'bake\\', \\'fry\\']}\\n\\n>>> D[\\'brunch\\'] = \\'Bacon\\'                         # Add new entry\\n>>> D\\n{\\'brunch\\': \\'Bacon\\', \\'spam\\': 2, \\'ham\\': [\\'grill\\', \\'bake\\', \\'fry\\']}\\n\\nLike lists, assigning to an existing index in a dictionary changes its associated value.\\nUnlike lists, however, whenever you assign a new dictionary key (one that hasn’t been\\nassigned before) you create a new entry in the dictionary, as was done in the previous\\nexample for the key \\'brunch\\'. This doesn’t work for lists because you can only assign\\nto existing list offsets—Python considers an offset beyond the end of a list out of bounds\\nand raises an error. To expand a list, you need to use tools such as the append method\\nor slice assignment instead.\\n\\nMore Dictionary Methods\\nDictionary methods provide a variety of type-specific tools. For instance, the dictionary\\nvalues and items methods return all of the dictionary’s values and (key,value) pair\\ntuples, respectively; along with keys, these are useful in loops that need to step through\\ndictionary entries one by one (we’ll start coding examples of such loops in the next\\n\\n254 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0csection). As for keys, these two methods also return iterable objects in 3.X, so wrap\\nthem in a list call there to collect their values all at once for display:\\n\\n>>> D = {\\'spam\\': 2, \\'ham\\': 1, \\'eggs\\': 3}\\n>>> list(D.values())\\n[3, 2, 1]\\n>>> list(D.items())\\n [(\\'eggs\\', 3), (\\'spam\\', 2), (\\'ham\\', 1)]\\n\\nIn realistic programs that gather data as they run, you often won’t be able to predict\\nwhat will be in a dictionary before the program is launched, much less when it’s coded.\\nFetching a nonexistent key is normally an error, but the get method returns a default\\nvalue—None, or a passed-in default—if the key doesn’t exist. It’s an easy way to fill in\\na default for a key that isn’t present, and avoid a missing-key error when your program\\ncan’t anticipate contents ahead of time:\\n\\n>>> D.get(\\'spam\\')                          # A key that is there\\n2\\n>>> print(D.get(\\'toast\\'))                  # A key that is missing\\nNone\\n>>> D.get(\\'toast\\', 88)\\n88\\n\\nThe  update  method  provides  something  similar  to  concatenation  for  dictionaries,\\nthough it has nothing to do with left-to-right ordering (again, there is no such thing in\\ndictionaries).  It  merges  the  keys  and  values  of  one  dictionary  into  another,  blindly\\noverwriting values of the same key if there’s a clash:\\n\\n>>> D\\n{\\'eggs\\': 3, \\'spam\\': 2, \\'ham\\': 1}\\n>>> D2 = {\\'toast\\':4, \\'muffin\\':5}           # Lots of delicious scrambled order here\\n>>> D.update(D2)\\n>>> D\\n{\\'eggs\\': 3, \\'muffin\\': 5, \\'toast\\': 4, \\'spam\\': 2, \\'ham\\': 1}\\n\\nNotice how mixed up the key order is in the last result; again, that’s just how diction-\\naries work. Finally, the dictionary pop method deletes a key from a dictionary and re-\\nturns the value it had. It’s similar to the list pop method, but it takes a key instead of\\nan optional position:\\n\\n# pop a dictionary by key\\n>>> D\\n{\\'eggs\\': 3, \\'muffin\\': 5, \\'toast\\': 4, \\'spam\\': 2, \\'ham\\': 1}\\n>>> D.pop(\\'muffin\\')\\n5\\n>>> D.pop(\\'toast\\')                         # Delete and return from a key\\n4\\n>>> D\\n{\\'eggs\\': 3, \\'spam\\': 2, \\'ham\\': 1}\\n\\n# pop a list by position\\n>>> L = [\\'aa\\', \\'bb\\', \\'cc\\', \\'dd\\']\\n>>> L.pop()                                # Delete and return from the end\\n\\'dd\\'\\n\\nDictionaries in Action | 255\\n\\n\\x0c>>> L\\n[\\'aa\\', \\'bb\\', \\'cc\\']\\n>>> L.pop(1)                               # Delete from a specific position\\n\\'bb\\'\\n>>> L\\n[\\'aa\\', \\'cc\\']\\n\\nDictionaries also provide a copy method; we’ll revisit this in Chapter 9, as it’s a way to\\navoid the potential side effects of shared references to the same dictionary. In fact,\\ndictionaries come with more methods than those listed in Table 8-2; see the Python\\nlibrary manual, dir and help, or other reference sources for a comprehensive list.\\n\\nYour dictionary ordering may vary: Don’t be alarmed if your dictionaries\\nprint in a different order than shown here. As mentioned, key order is\\narbitrary, and might vary per release, platform, and interactive session\\nin 3.3 (and quite possibly per day of the week, and phase of the moon!).\\n\\nMost of the dictionary examples in this book reflect Python 3.3’s key\\nordering, but it has changed both since and prior to 3.0. Your Python’s\\nkey order may vary, but you’re not supposed to care anyhow: diction-\\naries are processed by key, not position. Programs shouldn’t rely on the\\narbitrary order of keys in dictionaries, even if shown in books.\\n\\nThere are extension types in Python’s standard library that maintain\\ninsertion order among their keys—see OrderedDict in the collections\\nmodule—but they are hybrids that incur extra space and speed over-\\nheads to achieve their extra utility, and are not true dictionaries. In short,\\nkeys are kept redundantly in a linked list to support sequence opera-\\ntions.\\n\\nAs we’ll see in Chapter 9, this module also implements a namedtuple that\\nallows tuple items to be accessed by both attribute name and sequence\\nposition—a sort of tuple/class/dictionary hybrid that adds processing\\nsteps and is not a core object type in any event. Python’s library manual\\nhas the full story on these and other extension types.\\n\\nExample: Movie Database\\nLet’s look at a more realistic dictionary example. In honor of Python’s namesake, the\\nfollowing example creates a simple in-memory Monty Python movie database, as a\\ntable that maps movie release date years (the keys) to movie titles (the values). As coded,\\nyou fetch movie names by indexing on release year strings:\\n>>> table = {\\'1975\\': \\'Holy Grail\\',              # Key: Value\\n...          \\'1979\\': \\'Life of Brian\\',\\n...          \\'1983\\': \\'The Meaning of Life\\'}\\n>>>\\n>>> year  = \\'1983\\'\\n>>> movie = table[year]                         # dictionary[Key] => Value\\n>>> movie\\n\\'The Meaning of Life\\'\\n\\n256 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0c>>> for year in table:                          # Same as: for year in table.keys()\\n...     print(year + \\'\\\\t\\' + table[year])\\n...\\n1979    Life of Brian\\n1975    Holy Grail\\n1983    The Meaning of Life\\n\\nThe last command uses a for loop, which we previewed in Chapter 4 but haven’t cov-\\nered in detail yet. If you aren’t familiar with for loops, this command simply iterates\\nthrough each key in the table and prints a tab-separated list of keys and their values.\\nWe’ll learn more about for loops in Chapter 13.\\nDictionaries aren’t sequences like lists and strings, but if you need to step through the\\nitems in a dictionary, it’s easy—calling the dictionary keys method returns all stored\\nkeys, which you can iterate through with a for. If needed, you can index from key to\\nvalue inside the for loop as you go, as was done in this code.\\nIn fact, Python also lets you step through a dictionary’s keys list without actually calling\\nthe keys method in most for loops. For any dictionary D, saying for key in D works\\nthe same as saying the complete for key in D.keys(). This is really just another instance\\nof the iterators mentioned earlier, which allow the in membership operator to work on\\ndictionaries as well; more on iterators later in this book.\\n\\nPreview: Mapping values to keys\\nNotice how the prior table maps year to titles, but not vice versa. If you want to map\\nthe other way—titles to years—you can either code the dictionary differently, or use\\nmethods like items that give searchable sequences, though using them to best effect\\nrequires more background information than we yet have:\\n\\n>>> table = {\\'Holy Grail\\':          \\'1975\\',        # Key=>Value (title=>year)\\n...          \\'Life of Brian\\':       \\'1979\\',\\n...          \\'The Meaning of Life\\': \\'1983\\'}\\n>>>\\n>>> table[\\'Holy Grail\\']\\n\\'1975\\'\\n\\n>>> list(table.items())                            # Value=>Key (year=>title)\\n[(\\'The Meaning of Life\\', \\'1983\\'), (\\'Holy Grail\\', \\'1975\\'), (\\'Life of Brian\\', \\'1979\\')]\\n>>> [title for (title, year) in table.items() if year == \\'1975\\']\\n[\\'Holy Grail\\']\\n\\nThe last command here is in part a preview for the comprehension syntax introduced\\nin Chapter 4 and covered in full in Chapter 14. In short, it scans the dictionary’s (key,\\nvalue) tuple pairs returned by the items method, selecting keys having a specified value.\\nThe net effect is to index backward—from value to key, instead of key to value—useful\\nif you want to store data just once and map backward only rarely (searching through\\nsequences like this is generally much slower than a direct key index).\\n\\nDictionaries in Action | 257\\n\\n\\x0cIn fact, although dictionaries by nature map keys to values unidirectionally, there are\\nmultiple ways to map values back to keys with a bit of extra generalizable code:\\n\\n>>> K = \\'Holy Grail\\'\\n>>> table[K]              # Key=>Value (normal usage)\\n\\'1975\\'\\n\\n>>> V = \\'1975\\'\\n>>> [key for (key, value) in table.items() if value == V]         # Value=>Key\\n[\\'Holy Grail\\']\\n>>> [key for key in table.keys() if table[key] == V]              # Ditto\\n[\\'Holy Grail\\']\\n\\nNote that both of the last two commands return a list of titles: in dictionaries, there’s\\njust one value per key, but there may be many keys per value. A given value may be\\nstored under multiple keys (yielding multiple keys per value), and a value might be a\\ncollection itself (supporting multiple values per key). For more on this front, also watch\\nfor a dictionary inversion function in Chapter 32’s mapattrs.py example—code that\\nwould  surely  stretch  this  preview  past  its  breaking  point  if  included  here.  For  this\\nchapter’s purposes, let’s explore more dictionary basics.\\n\\nDictionary Usage Notes\\nDictionaries are fairly straightforward tools once you get the hang of them, but here\\nare a few additional pointers and reminders you should be aware of when using them:\\n\\n• Sequence operations don’t work. Dictionaries are mappings, not sequences; be-\\ncause there’s no notion of ordering among their items, things like concatenation\\n(an ordered joining) and slicing (extracting a contiguous section) simply don’t ap-\\nply. In fact, Python raises an error when your code runs if you try to do such things.\\n• Assigning to new indexes adds entries. Keys can be created when you write a\\ndictionary literal (embedded in the code of the literal itself), or when you assign\\nvalues to new keys of an existing dictionary object individually. The end result is\\nthe same.\\n\\n• Keys need not always be strings. Our examples so far have used strings as keys,\\nbut any other immutable objects work just as well. For instance, you can use inte-\\ngers as keys, which makes the dictionary look much like a list (when indexing, at\\nleast). Tuples may be used as dictionary keys too, allowing compound key values\\n—such as dates and IP addresses—to have associated values. User-defined class\\ninstance objects (discussed in Part VI) can also be used as keys, as long as they have\\nthe proper protocol methods; roughly, they need to tell Python that their values\\nare “hashable” and thus won’t change, as otherwise they would be useless as fixed\\nkeys. Mutable objects such as lists, sets, and other dictionaries don’t work as keys,\\nbut are allowed as values.\\n\\n258 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cUsing dictionaries to simulate flexible lists: Integer keys\\nThe last point in the prior list is important enough to demonstrate with a few examples.\\nWhen you use lists, it is illegal to assign to an offset that is off the end of the list:\\n\\n>>> L = []\\n>>> L[99] = \\'spam\\'\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in ?\\nIndexError: list assignment index out of range\\n\\nAlthough  you  can  use  repetition  to  preallocate  as  big  a  list  as  you’ll  need  (e.g.,\\n[0]*100), you can also do something that looks similar with dictionaries that does not\\nrequire such space allocations. By using integer keys, dictionaries can emulate lists that\\nseem to grow on offset assignment:\\n\\n>>> D = {}\\n>>> D[99] = \\'spam\\'\\n>>> D[99]\\n\\'spam\\'\\n>>> D\\n{99: \\'spam\\'}\\n\\nHere, it looks as if D is a 100-item list, but it’s really a dictionary with a single entry; the\\nvalue of the key 99 is the string \\'spam\\'. You can access this structure with offsets much\\nlike a list, catching nonexistent keys with get or in tests if required, but you don’t have\\nto allocate space for all the positions you might ever need to assign values to in the\\nfuture. When used like this, dictionaries are like more flexible equivalents of lists.\\nAs another example, we might also employ integer keys in our first movie database’s\\ncode earlier to avoid quoting the year, albeit at the expense of some expressiveness\\n(keys cannot contain nondigit characters):\\n\\n>>> table = {1975: \\'Holy Grail\\',\\n...          1979: \\'Life of Brian\\',              # Keys are integers, not strings\\n...          1983: \\'The Meaning of Life\\'}\\n>>> table[1975]\\n\\'Holy Grail\\'\\n>>> list(table.items())\\n[(1979, \\'Life of Brian\\'), (1983, \\'The Meaning of Life\\'), (1975, \\'Holy Grail\\')]\\n\\nUsing dictionaries for sparse data structures: Tuple keys\\nIn a similar way, dictionary keys are also commonly leveraged to implement sparse data\\nstructures—for example, multidimensional arrays where only a few positions have val-\\nues stored in them:\\n>>> Matrix = {}\\n>>> Matrix[(2, 3, 4)] = 88\\n>>> Matrix[(7, 8, 9)] = 99\\n>>>\\n>>> X = 2; Y = 3; Z = 4           # ; separates statements: see Chapter 10\\n>>> Matrix[(X, Y, Z)]\\n88\\n\\nDictionaries in Action | 259\\n\\n\\x0c>>> Matrix\\n{(2, 3, 4): 88, (7, 8, 9): 99}\\n\\nHere,  we’ve  used  a  dictionary  to  represent  a  three-dimensional  array  that  is  empty\\nexcept for the two positions (2,3,4) and (7,8,9). The keys are tuples that record the\\ncoordinates of nonempty slots. Rather than allocating a large and mostly empty three-\\ndimensional matrix to hold these values, we can use a simple two-item dictionary. In\\nthis scheme, accessing an empty slot triggers a nonexistent key exception, as these slots\\nare not physically stored:\\n\\n>>> Matrix[(2,3,6)]\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in ?\\nKeyError: (2, 3, 6)\\n\\nAvoiding missing-key errors\\nErrors for nonexistent key fetches are common in sparse matrixes, but you probably\\nwon’t want them to shut down your program. There are at least three ways to fill in a\\ndefault value instead of getting such an error message—you can test for keys ahead of\\ntime in if statements, use a try statement to catch and recover from the exception\\nexplicitly, or simply use the dictionary get method shown earlier to provide a default\\nfor keys that do not exist. Consider the first two of these previews for statement syntax\\nwe’ll begin studying in Chapter 10:\\n\\n>>> if (2, 3, 6) in Matrix:            # Check for key before fetch\\n...     print(Matrix[(2, 3, 6)])       # See Chapters 10 and 12 for if/else\\n... else:\\n...     print(0)\\n...\\n0\\n>>> try:\\n...     print(Matrix[(2, 3, 6)])       # Try to index\\n... except KeyError:                   # Catch and recover\\n...     print(0)                       # See Chapters 10 and 34 for try/except\\n...\\n0\\n>>> Matrix.get((2, 3, 4), 0)           # Exists: fetch and return\\n88\\n>>> Matrix.get((2, 3, 6), 0)           # Doesn\\'t exist: use default arg\\n0\\n\\nOf these, the get method is the most concise in terms of coding requirements, but the\\nif and try statements are much more general in scope; again, more on these starting\\nin Chapter 10.\\n\\nNesting in dictionaries\\nAs you can see, dictionaries can play many roles in Python. In general, they can replace\\nsearch data structures (because indexing by key is a search operation) and can represent\\nmany types of structured information. For example, dictionaries are one of many ways\\n\\n260 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cto describe the properties of an item in your program’s domain; that is, they can serve\\nthe same role as “records” or “structs” in other languages.\\nThe following, for example, fills out a dictionary describing a hypothetical person, by\\nassigning to new keys over time (if you are a Bob, my apologies for picking on your\\nname in this book—it’s easy to type!):\\n\\n>>> rec = {}\\n>>> rec[\\'name\\'] = \\'Bob\\'\\n>>> rec[\\'age\\']  = 40.5\\n>>> rec[\\'job\\']  = \\'developer/manager\\'\\n>>>\\n>>> print(rec[\\'name\\'])\\nBob\\n\\nEspecially when nested, Python’s built-in data types allow us to easily represent struc-\\ntured information. The following again uses a dictionary to capture object properties,\\nbut it codes it all at once (rather than assigning to each key separately) and nests a list\\nand a dictionary to represent structured property values:\\n\\n>>> rec = {\\'name\\': \\'Bob\\',\\n...        \\'jobs\\': [\\'developer\\', \\'manager\\'],\\n...        \\'web\\':  \\'www.bobs.org/˜Bob\\',\\n...        \\'home\\': {\\'state\\': \\'Overworked\\', \\'zip\\': 12345}}\\n\\nTo fetch components of nested objects, simply string together indexing operations:\\n\\n>>> rec[\\'name\\']\\n\\'Bob\\'\\n>>> rec[\\'jobs\\']\\n[\\'developer\\', \\'manager\\']\\n>>> rec[\\'jobs\\'][1]\\n\\'manager\\'\\n>>> rec[\\'home\\'][\\'zip\\']\\n12345\\n\\nAlthough we’ll learn in Part VI that classes (which group both data and logic) can be\\nbetter in this record role, dictionaries are an easy-to-use tool for simpler requirements.\\nFor more on record representation choices, see also the upcoming sidebar “Why You\\nWill Care: Dictionaries Versus Lists” on page 263, as well as its extension to tuples in\\nChapter 9 and classes in Chapter 27.\\nAlso notice that while we’ve focused on a single “record” with nested data here, there’s\\nno reason we couldn’t nest the record itself in a larger, enclosing database collection\\ncoded as a list or dictionary, though an external file or formal database interface often\\nplays the role of top-level container in realistic programs:\\n\\ndb = []\\ndb.append(rec)             # A list \"database\"\\ndb.append(other)\\ndb[0][\\'jobs\\']\\n\\ndb = {}\\ndb[\\'bob\\'] = rec            # A dictionary \"database\"\\n\\nDictionaries in Action | 261\\n\\n\\x0cdb[\\'sue\\'] = other\\ndb[\\'bob\\'][\\'jobs\\']\\n\\nLater in the book we’ll meet tools such as Python’s shelve, which works much the same\\nway, but automatically maps objects to and from files to make them permanent (watch\\nfor  more  in  this  chapter’s  sidebar  “Why  You  Will  Care:  Dictionary  Inter-\\nfaces” on page 271).\\n\\nOther Ways to Make Dictionaries\\nFinally, note that because dictionaries are so useful, more ways to build them have\\nemerged over time. In Python 2.3 and later, for example, the last two calls to the dict\\nconstructor (really, type name) shown here have the same effect as the literal and key-\\nassignment forms above them:\\n\\n{\\'name\\': \\'Bob\\', \\'age\\': 40}             # Traditional literal expression\\n\\nD = {}                                 # Assign by keys dynamically\\nD[\\'name\\'] = \\'Bob\\'\\nD[\\'age\\']  = 40\\n\\ndict(name=\\'Bob\\', age=40)               # dict keyword argument form\\n\\ndict([(\\'name\\', \\'Bob\\'), (\\'age\\', 40)])   # dict key/value tuples form\\n\\nAll four of these forms create the same two-key dictionary, but they are useful in dif-\\nfering circumstances:\\n\\n• The first is handy if you can spell out the entire dictionary ahead of time.\\n• The second is of use if you need to create the dictionary one field at a time on the\\n\\nfly.\\n\\n• The third involves less typing than the first, but it requires all keys to be strings.\\n• The last is useful if you need to build up keys and values as sequences at runtime.\\n\\nWe met keyword arguments earlier when sorting; the third form illustrated in this code\\nlisting has become especially popular in Python code today, since it has less syntax (and\\nhence there is less opportunity for mistakes). As suggested previously in Table 8-2, the\\nlast form in the listing is also commonly used in conjunction with the zip function, to\\ncombine separate lists of keys and values obtained dynamically at runtime (parsed out\\nof a data file’s columns, for instance):\\n\\ndict(zip(keyslist, valueslist))        # Zipped key/value tuples form (ahead)\\n\\nMore on zipping dictionary keys in the next section. Provided all the key’s values are\\nthe same initially, you can also create a dictionary with this special form—simply pass\\nin a list of keys and an initial value for all of the values (the default is None):\\n\\n>>> dict.fromkeys([\\'a\\', \\'b\\'], 0)\\n{\\'a\\': 0, \\'b\\': 0}\\n\\n262 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cAlthough you could get by with just literals and key assignments at this point in your\\nPython career, you’ll probably find uses for all of these dictionary-creation forms as\\nyou start applying them in realistic, flexible, and dynamic Python programs.\\nThe listings in this section document the various ways to create dictionaries in both\\nPython 2.X and 3.X. However, there is yet another way to create dictionaries, available\\nonly in Python 3.X and 2.7: the dictionary comprehension expression. To see how this\\nlast form looks, we need to move on to the next and final section of this chapter.\\n\\nWhy You Will Care: Dictionaries Versus Lists\\n\\nWith all the objects in Python’s core types arsenal, some readers may be puzzled over\\nthe choice between lists and dictionaries. In short, although both are flexible collections\\nof other objects, lists assign items to positions, and dictionaries assign them to more\\nmnemonic keys. Because of this, dictionary data often carries more meaning to human\\nreaders. For example, the nested list structure in row 3 of Table 8-1 could be used to\\nrepresent a record too:\\n\\n>>> L = [\\'Bob\\', 40.5, [\\'dev\\', \\'mgr\\']]  # List-based \"record\"\\n>>> L[0]\\n\\'Bob\\'\\n>>> L[1]                               # Positions/numbers for fields\\n40.5\\n>>> L[2][1]\\n\\'mgr\\'\\n\\nFor some types of data, the list’s access-by-position makes sense—a list of employees\\nin a company, the files in a directory, or numeric matrixes, for example. But a more\\nsymbolic record like this may be more meaningfully coded as a dictionary along the\\nlines of row 2 in Table 8-2, with labeled fields replacing field positions (this is similar\\nto a record we coded in Chapter 4):\\n\\n>>> D = {\\'name\\': \\'Bob\\', \\'age\\': 40.5, \\'jobs\\': [\\'dev\\', \\'mgr\\']}\\n>>> D[\\'name\\']\\n\\'Bob\\'\\n>>> D[\\'age\\']                           # Dictionary-based \"record\"\\n40.5\\n>>> D[\\'jobs\\'][1]                       # Names mean more than numbers\\n\\'mgr\\'\\n\\nFor variety, here is the same record recoded with keywords, which may seem even more\\nreadable to some human readers:\\n\\n>>> D = dict(name=\\'Bob\\', age=40.5, jobs=[\\'dev\\', \\'mgr\\'])\\n>>> D[\\'name\\']\\n\\'Bob\\'\\n>>> D[\\'jobs\\'].remove(\\'mgr\\')\\n>>> D\\n{\\'jobs\\': [\\'dev\\'], \\'age\\': 40.5, \\'name\\': \\'Bob\\'}\\n\\nIn practice, dictionaries tend to be best for data with labeled components, as well as\\nstructures that can benefit from quick, direct lookups by name, instead of slower linear\\nsearches. As we’ve seen, they also may be better for sparse collections and collections\\nthat grow at arbitrary positions.\\n\\nDictionaries in Action | 263\\n\\n\\x0cPython programmers also have access to the sets we studied in Chapter 5, which are\\nmuch like the keys of a valueless dictionary; they don’t map keys to values, but can\\noften be used like dictionaries for fast lookups when there is no associated value, es-\\npecially in search routines:\\n\\n>>> D = {}\\n>>> D[\\'state1\\'] = True                 # A visited-state dictionary\\n>>> \\'state1\\' in D\\nTrue\\n>>> S = set()\\n>>> S.add(\\'state1\\')                    # Same, but with sets\\n>>> \\'state1\\' in S\\nTrue\\n\\nWatch for a rehash of this record representation thread in the next chapter, where we’ll\\nsee  how  tuples  and  named  tuples  compare  to  dictionaries  in  this  role,  as  well  as  in\\nChapter 27, where we’ll learn how user-defined classes factor into this picture, com-\\nbining both data and logic to process it.\\n\\nDictionary Changes in Python 3.X and 2.7\\nThis chapter has so far focused on dictionary basics that span releases, but the dictio-\\nnary’s functionality has mutated in Python 3.X. If you are using Python 2.X code, you\\nmay come across some dictionary tools that either behave differently or are missing\\naltogether in 3.X. Moreover, 3.X coders have access to additional dictionary tools not\\navailable in 2.X, apart from two back-ports to 2.7.\\nSpecifically, dictionaries in Python 3.X:\\n\\n• Support a new dictionary comprehension expression, a close cousin to list and set\\n\\ncomprehensions\\n\\n• Return set-like iterable views instead of lists for the methods D.keys, D.values, and\\n\\nD.items\\n\\n• Require new coding styles for scanning by sorted keys, because of the prior point\\n• No longer support relative magnitude comparisons directly—compare manually\\n\\ninstead\\n\\n• No longer have the D.has_key method—the in membership test is used instead\\n\\nAs later back-ports from 3.X, dictionaries in Python 2.7 (but not earlier in 2.X):\\n\\n• Support item 1 in the prior list—dictionary comprehensions—as a direct back-port\\n\\nfrom 3.X\\n\\n• Support item 2 in the prior list—set-like iterable views—but do so with special\\nmethod  names  D.viewkeys,  D.viewvalues,  D.viewitems);  their  nonview  methods\\nreturn lists as before\\n\\n264 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cBecause of this overlap, some of the material in this section pertains both to 3.X and\\n2.7, but is presented here in the context of 3.X extensions because of its origin. With\\nthat in mind, let’s take a look at what’s new in dictionaries in 3.X and 2.7.\\n\\nDictionary comprehensions in 3.X and 2.7\\nAs mentioned at the end of the prior section, dictionaries in 3.X and 2.7 can also be\\ncreated  with  dictionary  comprehensions.  Like  the  set  comprehensions  we  met  in\\nChapter 5, dictionary comprehensions are available only in 3.X and 2.7 (not in 2.6 and\\nearlier). Like the longstanding list comprehensions we met briefly in Chapter 4 and\\nearlier in this chapter, they run an implied loop, collecting the key/value results of\\nexpressions on each iteration and using them to fill out a new dictionary. A loop variable\\nallows the comprehension to use loop iteration values along the way.\\nTo illustrate, a standard way to initialize a dictionary dynamically in both 2.X and 3.X\\nis to combine its keys and values with zip, and pass the result to the dict call. The\\nzip built-in function is the hook that allows us to construct a dictionary from key and\\nvalue lists this way—if you cannot predict the set of keys and values in your code, you\\ncan always build them up as lists and zip them together. We’ll study zip in detail in\\nChapter 13 and Chapter 14 after exploring statements; it’s an iterable in 3.X, so we\\nmust wrap it in a list call to show its results there, but its basic usage is otherwise\\nstraightforward:\\n\\n>>> list(zip([\\'a\\', \\'b\\', \\'c\\'], [1, 2, 3]))        # Zip together keys and values\\n[(\\'a\\', 1), (\\'b\\', 2), (\\'c\\', 3)]\\n\\n>>> D = dict(zip([\\'a\\', \\'b\\', \\'c\\'], [1, 2, 3]))    # Make a dict from zip result\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n\\nIn Python 3.X and 2.7, though, you can achieve the same effect with a dictionary com-\\nprehension expression. The following builds a new dictionary with a key/value pair for\\nevery such pair in the zip result (it reads almost the same in Python, but with a bit more\\nformality):\\n\\n>>> D = {k: v for (k, v) in zip([\\'a\\', \\'b\\', \\'c\\'], [1, 2, 3])}\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n\\nComprehensions actually require more code in this case, but they are also more general\\nthan this example implies—we can use them to map a single stream of values to dic-\\ntionaries as well, and keys can be computed with expressions just like values:\\n\\n>>> D = {x: x ** 2 for x in [1, 2, 3, 4]}        # Or: range(1, 5)\\n>>> D\\n{1: 1, 2: 4, 3: 9, 4: 16}\\n\\n>>> D = {c: c * 4 for c in \\'SPAM\\'}               # Loop over any iterable\\n>>> D\\n{\\'S\\': \\'SSSS\\', \\'P\\': \\'PPPP\\', \\'A\\': \\'AAAA\\', \\'M\\': \\'MMMM\\'}\\n\\nDictionaries in Action | 265\\n\\n\\x0c>>> D = {c.lower(): c + \\'!\\' for c in [\\'SPAM\\', \\'EGGS\\', \\'HAM\\']}\\n>>> D\\n{\\'eggs\\': \\'EGGS!\\', \\'spam\\': \\'SPAM!\\', \\'ham\\': \\'HAM!\\'}\\n\\nDictionary comprehensions are also useful for initializing dictionaries from keys lists,\\nin much the same way as the fromkeys method we met at the end of the preceding\\nsection:\\n\\n>>> D = dict.fromkeys([\\'a\\', \\'b\\', \\'c\\'], 0)        # Initialize dict from keys\\n>>> D\\n{\\'b\\': 0, \\'c\\': 0, \\'a\\': 0}\\n\\n>>> D = {k:0 for k in [\\'a\\', \\'b\\', \\'c\\']}           # Same, but with a comprehension\\n>>> D\\n{\\'b\\': 0, \\'c\\': 0, \\'a\\': 0}\\n\\n>>> D = dict.fromkeys(\\'spam\\')                    # Other iterables, default value\\n>>> D\\n{\\'s\\': None, \\'p\\': None, \\'a\\': None, \\'m\\': None}\\n\\n>>> D = {k: None for k in \\'spam\\'}\\n>>> D\\n{\\'s\\': None, \\'p\\': None, \\'a\\': None, \\'m\\': None}\\n\\nLike related tools, dictionary comprehensions support additional syntax not shown\\nhere, including nested loops and if clauses. Unfortunately, to truly understand dictio-\\nnary comprehensions, we need to also know more about iteration statements and con-\\ncepts in Python, and we don’t yet have enough information to address that story well.\\nWe’ll learn much more about all flavors of comprehensions (list, set, dictionary, and\\ngenerator) in Chapter 14 and Chapter 20, so we’ll defer further details until later. We’ll\\nalso revisit the zip built-in we used in this section in more detail in Chapter 13, when\\nwe explore for loops.\\n\\nDictionary views in 3.X (and 2.7 via new methods)\\nIn 3.X the dictionary keys, values, and items methods all return view objects, whereas\\nin 2.X they return actual result lists. This functionality is also available in Python 2.7,\\nbut in the guise of the special, distinct method names listed at the start of this section\\n(2.7’s normal methods still return simple lists, so as to avoid breaking existing 2.X\\ncode); because of this, I’ll refer to this as a 3.X feature in this section.\\nView objects are iterables, which simply means objects that generate result items one\\nat  a  time,  instead  of  producing  the  result  list  all  at  once  in  memory.  Besides  being\\niterable, dictionary views also retain the original order of dictionary components, reflect\\nfuture changes to the dictionary, and may support set operations. On the other hand,\\nbecause they are not lists, they do not directly support operations like indexing or the\\nlist sort method, and do not display their items as a normal list when printed (they do\\nshow their components as of Python 3.1 but not as a list, and are still a divergence from\\n2.X).\\n\\n266 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cWe’ll discuss the notion of iterables more formally in Chapter 14, but for our purposes\\nhere it’s enough to know that we have to run the results of these three methods through \\nthe list built-in if we want to apply list operations or display their values. For example,\\nin Python 3.3 (other version’s outputs may differ slightly):\\n\\n>>> D = dict(a=1, b=2, c=3)\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n\\n>>> K = D.keys()                   # Makes a view object in 3.X, not a list\\n>>> K\\ndict_keys([\\'b\\', \\'c\\', \\'a\\'])\\n>>> list(K)                        # Force a real list in 3.X if needed\\n[\\'b\\', \\'c\\', \\'a\\']\\n\\n>>> V = D.values()                 # Ditto for values and items views\\n>>> V\\ndict_values([2, 3, 1])\\n>>> list(V)\\n[2, 3, 1]\\n\\n>>> D.items()\\ndict_items([(\\'b\\', 2), (\\'c\\', 3), (\\'a\\', 1)])\\n>>> list(D.items())\\n[(\\'b\\', 2), (\\'c\\', 3), (\\'a\\', 1)]\\n\\n>>> K[0]                           # List operations fail unless converted\\nTypeError: \\'dict_keys\\' object does not support indexing\\n>>> list(K)[0]\\n\\'b\\'\\n\\nApart  from  result  displays  at  the  interactive  prompt,  you  will  probably  rarely  even\\nnotice this change, because looping constructs in Python automatically force iterable\\nobjects to produce one result on each iteration:\\n\\n>>> for k in D.keys(): print(k)    # Iterators used automatically in loops\\n...\\nb\\nc\\na\\n\\nIn addition, 3.X dictionaries still have iterators themselves, which return successive\\nkeys—as in 2.X, it’s still often not necessary to call keys directly:\\n\\n>>> for key in D: print(key)       # Still no need to call keys() to iterate\\n...\\nb\\nc\\na\\n\\nUnlike 2.X’s list results, though, dictionary views in 3.X are not carved in stone when\\ncreated—they dynamically reflect future changes made to the dictionary after the view\\nobject has been created:\\n\\nDictionaries in Action | 267\\n\\n\\x0c>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n\\n>>> K = D.keys()\\n>>> V = D.values()\\n>>> list(K)                        # Views maintain same order as dictionary\\n [\\'b\\', \\'c\\', \\'a\\']\\n>>> list(V)\\n[2, 3, 1]\\n\\n>>> del D[\\'b\\']                     # Change the dictionary in place\\n>>> D\\n{\\'c\\': 3, \\'a\\': 1}\\n\\n>>> list(K)                        # Reflected in any current view objects\\n[\\'c\\', \\'a\\']\\n>>> list(V)                        # Not true in 2.X! - lists detached from dict\\n[3, 1]\\n\\nDictionary views and sets\\nAlso unlike 2.X’s list results, 3.X’s view objects returned by the keys method are set-\\nlike and support common set operations such as intersection and union; values views\\nare not set-like, but items results are if their (key, value) pairs are unique and hashable\\n(immutable). Given that sets behave much like valueless dictionaries (and may even be\\ncoded in curly braces like dictionaries in 3.X and 2.7), this is a logical symmetry. Per\\nChapter 5, set items are unordered, unique, and immutable, just like dictionary keys.\\nHere is what keys views look like when used in set operations (continuing the prior\\nsection’s session); dictionary value views are never set-like, since their items are not\\nnecessarily unique or immutable:\\n\\n>>> K, V\\n(dict_keys([\\'c\\', \\'a\\']), dict_values([3, 1]))\\n\\n>>> K | {\\'x\\': 4}                   # Keys (and some items) views are set-like\\n{\\'c\\', \\'x\\', \\'a\\'}\\n\\n>>> V & {\\'x\\': 4}\\nTypeError: unsupported operand type(s) for &: \\'dict_values\\' and \\'dict\\'\\n>>> V & {\\'x\\': 4}.values()\\nTypeError: unsupported operand type(s) for &: \\'dict_values\\' and \\'dict_values\\'\\n\\nIn set operations, views may be mixed with other views, sets, and dictionaries; dic-\\ntionaries are treated the same as their keys views in this context:\\n\\n>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> D.keys() & D.keys()            # Intersect keys views\\n{\\'b\\', \\'c\\', \\'a\\'}\\n>>> D.keys() & {\\'b\\'}               # Intersect keys and set\\n{\\'b\\'}\\n>>> D.keys() & {\\'b\\': 1}            # Intersect keys and dict\\n{\\'b\\'}\\n\\n268 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0c>>> D.keys() | {\\'b\\', \\'c\\', \\'d\\'}     # Union keys and set\\n{\\'b\\', \\'c\\', \\'a\\', \\'d\\'}\\n\\nItems views are set-like too if they are hashable—that is, if they contain only immutable\\nobjects:\\n\\n>>> D = {\\'a\\': 1}\\n>>> list(D.items())                # Items set-like if hashable\\n[(\\'a\\', 1)]\\n>>> D.items() | D.keys()           # Union view and view\\n{(\\'a\\', 1), \\'a\\'}\\n>>> D.items() | D                  # dict treated same as its keys\\n{(\\'a\\', 1), \\'a\\'}\\n\\n>>> D.items() | {(\\'c\\', 3), (\\'d\\', 4)}           # Set of key/value pairs\\n{(\\'d\\', 4), (\\'a\\', 1), (\\'c\\', 3)}\\n\\n>>> dict(D.items() | {(\\'c\\', 3), (\\'d\\', 4)})     # dict accepts iterable sets too\\n{\\'c\\': 3, \\'a\\': 1, \\'d\\': 4}\\n\\nSee Chapter 5’s coverage of sets if you need a refresher on these operations. Here, let’s\\nwrap up with three other quick coding notes for 3.X dictionaries.\\n\\nSorting dictionary keys in 3.X\\nFirst of all, because keys does not return a list in 3.X, the traditional coding pattern for\\nscanning a dictionary by sorted keys in 2.X won’t work in 3.X:\\n\\n>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n\\n>>> Ks = D.keys()                            # Sorting a view object doesn\\'t work!\\n>>> Ks.sort()\\nAttributeError: \\'dict_keys\\' object has no attribute \\'sort\\'\\n\\nTo  work  around  this,  in  3.X  you  must  either  convert  to  a  list  manually  or  use  the\\nsorted call (introduced in Chapter 4 and covered in this chapter) on either a keys view\\nor the dictionary itself:\\n\\n>>> Ks = list(Ks)                            # Force it to be a list and then sort\\n>>> Ks.sort()\\n>>> for k in Ks: print(k, D[k])              # 2.X: omit outer parens in prints\\n...\\na 1\\nb 2\\nc 3\\n\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n>>> Ks = D.keys()                            # Or you can use sorted() on the keys\\n>>> for k in sorted(Ks): print(k, D[k])      # sorted() accepts any iterable\\n...                                          # sorted() returns its result\\na 1\\n\\nDictionaries in Action | 269\\n\\n\\x0cb 2\\nc 3\\n\\nOf these, using the dictionary’s keys iterator is probably preferable in 3.X, and works\\nin 2.X as well:\\n\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}                     # Better yet, sort the dict directly\\n>>> for k in sorted(D): print(k, D[k])       # dict iterators return keys\\n...\\na 1\\nb 2\\nc 3\\n\\nDictionary magnitude comparisons no longer work in 3.X\\nSecondly, while in Python 2.X dictionaries may be compared for relative magnitude\\ndirectly with <, >, and so on, in Python 3.X this no longer works. However, you can\\nsimulate it by comparing sorted keys lists manually:\\n\\nsorted(D1.items()) < sorted(D2.items())      # Like 2.X D1 < D2\\n\\nDictionary equality tests (e.g., D1 == D2) still work in 3.X, though. Since we’ll revisit\\nthis near the end of the next chapter in the context of comparisons at large, we’ll post-\\npone further details here.\\n\\nThe has_key method is dead in 3.X: Long live in!\\nFinally, the widely used dictionary has_key key presence test method is gone in 3.X.\\nInstead, use the in membership expression, or a get with a default test (of these, in is\\ngenerally preferred):\\n\\n>>> D\\n{\\'b\\': 2, \\'c\\': 3, \\'a\\': 1}\\n\\n>>> D.has_key(\\'c\\')                                        # 2.X only: True/False\\nAttributeError: \\'dict\\' object has no attribute \\'has_key\\'\\n\\n>>> \\'c\\' in D                                              # Required in 3.X\\nTrue\\n>>> \\'x\\' in D                                              # Preferred in 2.X today\\nFalse\\n>>> if \\'c\\' in D: print(\\'present\\', D[\\'c\\'])                 # Branch on result\\n...\\npresent 3\\n\\n>>> print(D.get(\\'c\\'))                                     # Fetch with default\\n3\\n>>> print(D.get(\\'x\\'))\\nNone\\n>>> if D.get(\\'c\\') != None: print(\\'present\\', D[\\'c\\'])       # Another option\\n...\\npresent 3\\n\\n270 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0cTo summarize, the dictionary story changes substantially in 3.X. If you work in 2.X\\nand care about 3.X compatibility (or suspect that you might someday), here are some\\npointers. Of the 3.X changes we’ve met in this section:\\n\\n• The first (dictionary comprehensions) can be coded only in 3.X and 2.7.\\n• The second (dictionary views) can be coded only in 3.X, and with special method\\n\\nnames in 2.7.\\n\\nHowever,  the  last  three  techniques—sorted,  manual  comparisons,  and  in—can  be\\ncoded in 2.X today to ease 3.X migration in the future.\\n\\nWhy You Will Care: Dictionary Interfaces\\n\\nDictionaries aren’t just a convenient way to store information by key in your programs\\n—some Python extensions also present interfaces that look like and work the same as\\ndictionaries. For instance, Python’s interface to DBM access-by-key files looks much\\nlike a dictionary that must be opened. You store and fetch strings using key indexes:\\n\\nimport dbm                     # Named anydbm in Python 2.X\\nfile = dbm.open(\"filename\")    # Link to file\\nfile[\\'key\\'] = \\'data\\'           # Store data by key\\ndata = file[\\'key\\']             # Fetch data by key\\n\\nIn Chapter 28, you’ll see that you can store entire Python objects this way, too, if you\\nreplace dbm in the preceding code with shelve (shelves are access-by-key databases that\\nstore persistent Python objects, not just strings). For Internet work, Python’s CGI script\\nsupport also presents a dictionary-like interface. A call to cgi.FieldStorage yields a\\ndictionary-like object with one entry per input field on the client’s web page:\\n\\nimport cgi\\nform = cgi.FieldStorage()      # Parse form data\\nif \\'name\\' in form:\\n    showReply(\\'Hello, \\' + form[\\'name\\'].value)\\n\\nThough dictionaries are the only core mapping type, all of these others are instances\\nof mappings, and support most of the same operations. Once you learn dictionary\\ninterfaces, you’ll find that they apply to a variety of built-in tools in Python.\\n\\nFor another dictionary use case, see also Chapter 9’s upcoming overview of JSON—a\\nlanguage-neutral data format used for databases and data transfer. Python dictionaries,\\nlists, and nested combinations of them can almost pass for records in this format as is,\\nand  may  be  easily  translated  to  and  from  formal  JSON  text  strings  with  Python’s\\njson standard library module.\\n\\nChapter Summary\\nIn  this  chapter,  we  explored  the  list  and  dictionary  types—probably  the  two  most\\ncommon, flexible, and powerful collection types you will see and use in Python code.\\nWe learned that the list type supports positionally ordered collections of arbitrary ob-\\n\\nChapter Summary | 271\\n\\n\\x0cjects, and that it may be freely nested and grown and shrunk on demand. The dictionary\\ntype is similar, but it stores items by key instead of by position and does not maintain\\nany reliable left-to-right order among its items. Both lists and dictionaries are mutable,\\nand so support a variety of in-place change operations not available for strings: for\\nexample, lists can be grown by append calls, and dictionaries by assignment to new keys.\\nIn the next chapter, we will wrap up our in-depth core object type tour by looking at\\ntuples and files. After that, we’ll move on to statements that code the logic that processes\\nour objects, taking us another step toward writing complete programs. Before we tackle\\nthose topics, though, here are some chapter quiz questions to review.\\n\\nTest Your Knowledge: Quiz\\n1. Name two ways to build a list containing five integer zeros.\\n2. Name two ways to build a dictionary with two keys, \\'a\\' and \\'b\\', each having an\\n\\nassociated value of 0.\\n\\n3. Name four operations that change a list object in place.\\n4. Name four operations that change a dictionary object in place.\\n5. Why might you use a dictionary instead of a list?\\n\\nTest Your Knowledge: Answers\\n1. A literal expression like [0, 0, 0, 0, 0] and a repetition expression like [0] * 5\\nwill each create a list of five zeros. In practice, you might also build one up with a\\nloop  that  starts  with  an  empty  list  and  appends  0  to  it  in  each  iteration,  with\\nL.append(0). A list comprehension ([0 for i in range(5)]) could work here, too,\\nbut this is more work than you need to do for this answer.\\n\\n2. A literal expression such as {\\'a\\': 0, \\'b\\': 0} or a series of assignments like D =\\n{}, D[\\'a\\'] = 0, and D[\\'b\\'] = 0 would create the desired dictionary. You can also\\nuse  the  newer  and  simpler-to-code  dict(a=0, b=0)  keyword  form,  or  the  more\\nflexible dict([(\\'a\\', 0), (\\'b\\', 0)]) key/value sequences form. Or, because all the\\nvalues are the same, you can use the special form dict.fromkeys(\\'ab\\', 0). In 3.X\\nand 2.7, you can also use a dictionary comprehension: {k:0 for k in \\'ab\\'}, though\\nagain, this may be overkill here.\\n\\n3. The append and extend methods grow a list in place, the sort and reverse methods\\norder and reverse lists, the insert method inserts an item at an offset, the remove\\nand pop methods delete from a list by value and by position, the del statement\\ndeletes an item or slice, and index and slice assignment statements replace an item\\nor entire section. Pick any four of these for the quiz.\\n\\n4. Dictionaries are primarily changed by assignment to a new or existing key, which\\ncreates or changes the key’s entry in the table. Also, the del statement deletes a\\n\\n272 | Chapter 8:\\u2002Lists and Dictionaries\\n\\n\\x0ckey’s entry, the dictionary update method merges one dictionary into another in\\nplace, and D.pop(key) removes a key and returns the value it had. Dictionaries also\\nhave other, more exotic in-place change methods not presented in this chapter,\\nsuch as setdefault; see reference sources for more details.\\n\\n5. Dictionaries are generally better when the data is labeled (a record with field names,\\nfor example); lists are best suited to collections of unlabeled items (such as all the\\nfiles in a directory). Dictionary lookup is also usually quicker than searching a list,\\nthough this might vary per program.\\n\\nTest Your Knowledge: Answers\\n\\n| 273\\n\\n\\x0c\\x0cCHAPTER 9\\nTuples, Files, and Everything Else\\n\\nThis chapter rounds out our in-depth tour of the core object types in Python by ex-\\nploring the tuple, a collection of other objects that cannot be changed, and the file, an\\ninterface to external files on your computer. As you’ll see, the tuple is a relatively simple\\nobject that largely performs operations you’ve already learned about for strings and\\nlists. The file object is a commonly used and full-featured tool for processing files on\\nyour computer. Because files are so pervasive in programming, the basic overview of\\nfiles here is supplemented by larger examples in later chapters.\\nThis chapter also concludes this part of the book by looking at properties common to\\nall  the  core  object  types  we’ve  met—the  notions  of  equality,  comparisons,  object\\ncopies, and so on. We’ll also briefly explore other object types in Python’s toolbox,\\nincluding the None placeholder and the namedtuple hybrid; as you’ll see, although we’ve\\ncovered all the primary built-in types, the object story in Python is broader than I’ve\\nimplied thus far. Finally, we’ll close this part of the book by taking a look at a set of\\ncommon object type pitfalls and exploring some exercises that will allow you to ex-\\nperiment with the ideas you’ve learned.\\n\\nThis chapter’s scope—files: As in Chapter 7 on strings, our look at files\\nhere will be limited in scope to file fundamentals that most Python pro-\\ngrammers—including newcomers to programming—need to know. In\\nparticular, Unicode text files were previewed in Chapter 4, but we’re\\ngoing to postpone full coverage of them until Chapter 37, as optional\\nor deferred reading in the Advanced Topics part of this book.\\n\\nFor this chapter’s purpose, we’ll assume any text files used will be en-\\ncoded and decoded per your platform’s default, which may be UTF-8\\non Windows, and ASCII or other elsewhere (and if you don’t know why\\nthis matters, you probably don’t need to up front). We’ll also assume\\nthat filenames encode properly on the underlying platform, though we’ll\\nstick with ASCII names for portability here.\\n\\nIf Unicode text and files is a critical subject for you, I suggest reading\\nthe  Chapter  4  preview  for  a  quick  first  look,  and  continuing  on  to\\n\\n275\\n\\n\\x0cChapter 37 after you master the file basics covered here. For all others,\\nthe file coverage here will apply both to typical text and binary files of\\nthe sort we’ll meet here, as well as to more advanced file-processing\\nmodes you may choose to explore later.\\n\\nTuples\\nThe  last  collection  type  in  our  survey  is  the  Python  tuple.  Tuples  construct  simple\\ngroups of objects. They work exactly like lists, except that tuples can’t be changed in\\nplace (they’re immutable) and are usually written as a series of items in parentheses,\\nnot square brackets. Although they don’t support as many methods, tuples share most\\nof their properties with lists. Here’s a quick look at the basics. Tuples are:\\n\\nOrdered collections of arbitrary objects\\n\\nLike strings and lists, tuples are positionally ordered collections of objects (i.e.,\\nthey maintain a left-to-right order among their contents); like lists, they can embed\\nany kind of object.\\n\\nAccessed by offset\\n\\nLike strings and lists, items in a tuple are accessed by offset (not by key); they\\nsupport all the offset-based access operations, such as indexing and slicing.\\n\\nOf the category “immutable sequence”\\n\\nLike strings and lists, tuples are sequences; they support many of the same opera-\\ntions. However, like strings, tuples are immutable; they don’t support any of the\\nin-place change operations applied to lists.\\n\\nFixed-length, heterogeneous, and arbitrarily nestable\\n\\nBecause tuples are immutable, you cannot change the size of a tuple without mak-\\ning a copy. On the other hand, tuples can hold any type of object, including other\\ncompound objects (e.g., lists, dictionaries, other tuples), and so support arbitrary\\nnesting.\\n\\nArrays of object references\\n\\nLike lists, tuples are best thought of as object reference arrays; tuples store access\\npoints to other objects (references), and indexing a tuple is relatively quick.\\n\\nTable 9-1 highlights common tuple operations. A tuple is written as a series of objects\\n(technically, expressions that generate objects), separated by commas and normally\\nenclosed in parentheses. An empty tuple is just a parentheses pair with nothing inside.\\n\\nTable 9-1. Common tuple literals and operations\\n\\nOperation\\n()\\n\\nT = (0,)\\n\\nT = (0, \\'Ni\\', 1.2, 3)\\n\\nT = 0, \\'Ni\\', 1.2, 3\\n\\nInterpretation\\nAn empty tuple\\nA one-item tuple (not an expression)\\nA four-item tuple\\nAnother four-item tuple (same as prior line)\\n\\n276 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cOperation\\nT = (\\'Bob\\', (\\'dev\\', \\'mgr\\'))\\n\\nT = tuple(\\'spam\\')\\n\\nT[i]\\n\\nT[i][j]\\n\\nT[i:j]\\n\\nlen(T)\\n\\nT1 + T2\\n\\nT * 3\\n\\nfor x in T: print(x)\\n\\n\\'spam\\' in T\\n\\n[x ** 2 for x in T]\\n\\nT.index(\\'Ni\\')\\n\\nT.count(\\'Ni\\')\\n\\nInterpretation\\nNested tuples\\nTuple of items in an iterable\\nIndex, index of index, slice, length\\n\\nConcatenate, repeat\\n\\nIteration, membership\\n\\nMethods in 2.6, 2.7, and 3.X: search, count\\n\\nnamedtuple(\\'Emp\\', [\\'name\\', \\'jobs\\'])\\n\\nNamed tuple extension type\\n\\nTuples in Action\\nAs  usual,  let’s  start  an  interactive  session  to  explore  tuples  at  work.  Notice  in  Ta-\\nble 9-1 that tuples do not have all the methods that lists have (e.g., an append call won’t\\nwork here). They do, however, support the usual sequence operations that we saw for\\nboth strings and lists:\\n\\n>>> (1, 2) + (3, 4)            # Concatenation\\n(1, 2, 3, 4)\\n\\n>>> (1, 2) * 4                 # Repetition\\n(1, 2, 1, 2, 1, 2, 1, 2)\\n\\n>>> T = (1, 2, 3, 4)           # Indexing, slicing\\n>>> T[0], T[1:3]\\n(1, (2, 3))\\n\\nTuple syntax peculiarities: Commas and parentheses\\nThe  second  and  fourth  entries  in  Table  9-1  merit  a  bit  more  explanation.  Because\\nparentheses can also enclose expressions (see Chapter 5), you need to do something\\nspecial to tell Python when a single object in parentheses is a tuple object and not a\\nsimple expression. If you really want a single-item tuple, simply add a trailing comma\\nafter the single item, before the closing parenthesis:\\n\\n>>> x = (40)                   # An integer!\\n>>> x\\n40\\n\\nTuples\\n\\n| 277\\n\\n\\x0c>>> y = (40,)                  # A tuple containing an integer\\n>>> y\\n(40,)\\n\\nAs a special case, Python also allows you to omit the opening and closing parentheses\\nfor a tuple in contexts where it isn’t syntactically ambiguous to do so. For instance, the\\nfourth line of Table 9-1 simply lists four items separated by commas. In the context of\\nan assignment statement, Python recognizes this as a tuple, even though it doesn’t have\\nparentheses.\\nNow, some people will tell you to always use parentheses in your tuples, and some will\\ntell you to never use parentheses in tuples (and still others have lives, and won’t tell\\nyou what to do with your tuples!). The most common places where the parentheses\\nare required for tuple literals are those where:\\n\\n• Parentheses matter—within a function call, or nested in a larger expression.\\n• Commas matter—embedded in the literal of a larger data structure like a list or\\n\\ndictionary, or listed in a Python 2.X print statement.\\n\\nIn most other contexts, the enclosing parentheses are optional. For beginners, the best\\nadvice is that it’s probably easier to use the parentheses than it is to remember when\\nthey  are  optional  or  required.  Many  programmers  (myself  included)  also  find  that\\nparentheses tend to aid script readability by making the tuples more explicit and ob-\\nvious, but your mileage may vary.\\n\\nConversions, methods, and immutability\\nApart from literal syntax differences, tuple operations (the middle rows in Table 9-1)\\nare identical to string and list operations. The only differences worth noting are that\\nthe +, *, and slicing operations return new tuples when applied to tuples, and that tuples\\ndon’t provide the same methods you saw for strings, lists, and dictionaries. If you want\\nto sort a tuple, for example, you’ll usually have to either first convert it to a list to gain\\naccess to a sorting method call and make it a mutable object, or use the newer sorted\\nbuilt-in that accepts any sequence object (and other iterables—a term introduced in\\nChapter 4 that we’ll be more formal about in the next part of this book):\\n\\n>>> T = (\\'cc\\', \\'aa\\', \\'dd\\', \\'bb\\')\\n>>> tmp = list(T)                  # Make a list from a tuple\\'s items\\n>>> tmp.sort()                     # Sort the list\\n>>> tmp\\n[\\'aa\\', \\'bb\\', \\'cc\\', \\'dd\\']\\n>>> T = tuple(tmp)                 # Make a tuple from the list\\'s items\\n>>> T\\n(\\'aa\\', \\'bb\\', \\'cc\\', \\'dd\\')\\n\\n>>> sorted(T)                      # Or use the sorted built-in, and save two steps\\n[\\'aa\\', \\'bb\\', \\'cc\\', \\'dd\\']\\n\\n278 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cHere, the list and tuple built-in functions are used to convert the object to a list and\\nthen back to a tuple; really, both calls make new objects, but the net effect is like a\\nconversion.\\nList comprehensions can also be used to convert tuples. The following, for example,\\nmakes a list from a tuple, adding 20 to each item along the way:\\n\\n>>> T = (1, 2, 3, 4, 5)\\n>>> L = [x + 20 for x in T]\\n>>> L\\n[21, 22, 23, 24, 25]\\n\\nList comprehensions are really sequence operations—they always build new lists, but\\nthey may be used to iterate over any sequence objects, including tuples, strings, and\\nother lists. As we’ll see later in the book, they even work on some things that are not\\nphysically stored sequences—any iterable objects will do, including files, which are\\nautomatically read line by line. Given this, they may be better called iteration tools.\\nAlthough tuples don’t have the same methods as lists and strings, they do have two of\\ntheir own as of Python 2.6 and 3.0—index and count work as they do for lists, but they\\nare defined for tuple objects:\\n\\n>>> T = (1, 2, 3, 2, 4, 2)         # Tuple methods in 2.6, 3.0, and later\\n>>> T.index(2)                     # Offset of first appearance of 2\\n1\\n>>> T.index(2, 2)                  # Offset of appearance after offset 2\\n3\\n>>> T.count(2)                     # How many 2s are there?\\n3\\n\\nPrior to 2.6 and 3.0, tuples have no methods at all—this was an old Python convention\\nfor  immutable  types,  which  was  violated  years  ago  on  grounds  of  practicality  with\\nstrings, and more recently with both numbers and tuples.\\nAlso, note that the rule about tuple immutability applies only to the top level of the\\ntuple itself, not to its contents. A list inside a tuple, for instance, can be changed as usual:\\n\\n>>> T = (1, [2, 3], 4)\\n>>> T[1] = \\'spam\\'                  # This fails: can\\'t change tuple itself\\nTypeError: object doesn\\'t support item assignment\\n\\n>>> T[1][0] = \\'spam\\'               # This works: can change mutables inside\\n>>> T\\n(1, [\\'spam\\', 3], 4)\\n\\nFor most programs, this one-level-deep immutability is sufficient for common tuple\\nroles. Which, coincidentally, brings us to the next section.\\n\\nWhy Lists and Tuples?\\nThis seems to be the first question that always comes up when teaching beginners about\\ntuples: why do we need tuples if we have lists? Some of the reasoning may be historic;\\n\\nTuples\\n\\n| 279\\n\\n\\x0cPython’s creator is a mathematician by training, and he has been quoted as seeing a\\ntuple as a simple association of objects and a list as a data structure that changes over\\ntime. In fact, this use of the word “tuple” derives from mathematics, as does its frequent\\nuse for a row in a relational database table.\\nThe best answer, however, seems to be that the immutability of tuples provides some\\nintegrity—you can be sure a tuple won’t be changed through another reference else-\\nwhere in a program, but there’s no such guarantee for lists. Tuples and other immut-\\nables,  therefore,  serve  a  similar  role  to  “constant”  declarations  in  other  languages,\\nthough the notion of constantness is associated with objects in Python, not variables.\\nTuples can also be used in places that lists cannot—for example, as dictionary keys\\n(see the sparse matrix example in Chapter 8). Some built-in operations may also require\\nor imply tuples instead of lists (e.g., the substitution values in a string format expres-\\nsion), though such operations have often been generalized in recent years to be more\\nflexible. As a rule of thumb, lists are the tool of choice for ordered collections that might\\nneed to change; tuples can handle the other cases of fixed associations.\\n\\nRecords Revisited: Named Tuples\\nIn fact, the choice of data types is even richer than the prior section may have implied\\n—today’s Python programmers can choose from an assortment of both built-in core\\ntypes, and extension types built on top of them. For example, in the prior chapter’s\\nsidebar “Why You Will Care: Dictionaries Versus Lists” on page 263, we saw how to\\nrepresent  record-like  information  with  both  a  list  and  a  dictionary,  and  noted  that\\ndictionaries offer the advantage of more mnemonic keys that label data. As long as we\\ndon’t require mutability, tuples can serve similar roles, with positions for record fields\\nlike lists:\\n\\n>>> bob = (\\'Bob\\', 40.5, [\\'dev\\', \\'mgr\\'])                    # Tuple record\\n>>> bob\\n(\\'Bob\\', 40.5, [\\'dev\\', \\'mgr\\'])\\n\\n>>> bob[0], bob[2]                                         # Access by position\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n\\nAs for lists, though, field numbers in tuples generally carry less information than the\\nnames of keys in a dictionary. Here’s the same record recoded as a dictionary with\\nnamed fields:\\n\\n>>> bob = dict(name=\\'Bob\\', age=40.5, jobs=[\\'dev\\', \\'mgr\\'])  # Dictionary record\\n>>> bob\\n{\\'jobs\\': [\\'dev\\', \\'mgr\\'], \\'name\\': \\'Bob\\', \\'age\\': 40.5}\\n\\n>>> bob[\\'name\\'], bob[\\'jobs\\']                               # Access by key\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n\\nIn fact, we can convert parts of the dictionary to a tuple if needed:\\n\\n280 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c>>> tuple(bob.values())                                    # Values to tuple\\n([\\'dev\\', \\'mgr\\'], \\'Bob\\', 40.5)\\n>>> list(bob.items())                                      # Items to tuple list\\n[(\\'jobs\\', [\\'dev\\', \\'mgr\\']), (\\'name\\', \\'Bob\\'), (\\'age\\', 40.5)]\\n\\nBut with a bit of extra work, we can implement objects that offer both positional and\\nnamed  access  to  record  fields.  For  example,  the  namedtuple  utility,  available  in  the\\nstandard library’s collections module mentioned in Chapter 8, implements an exten-\\nsion  type  that  adds  logic  to  tuples  that  allows  components  to  be  accessed  by  both\\nposition and attribute name, and can be converted to dictionary-like form for access by\\nkey if desired. Attribute names come from classes and are not exactly dictionary keys,\\nbut they are similarly mnemonic:\\n\\n>>> from collections import namedtuple                     # Import extension type\\n>>> Rec = namedtuple(\\'Rec\\', [\\'name\\', \\'age\\', \\'jobs\\'])       # Make a generated class\\n>>> bob = Rec(\\'Bob\\', age=40.5, jobs=[\\'dev\\', \\'mgr\\'])        # A named-tuple record\\n>>> bob\\nRec(name=\\'Bob\\', age=40.5, jobs=[\\'dev\\', \\'mgr\\'])\\n\\n>>> bob[0], bob[2]                                         # Access by position\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n>>> bob.name, bob.jobs                                     # Access by attribute\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n\\nConverting to a dictionary supports key-based behavior when needed:\\n\\n>>> O = bob._asdict()                                      # Dictionary-like form\\n>>> O[\\'name\\'], O[\\'jobs\\']                                   # Access by key too\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n>>> O\\nOrderedDict([(\\'name\\', \\'Bob\\'), (\\'age\\', 40.5), (\\'jobs\\', [\\'dev\\', \\'mgr\\'])])\\n\\nAs you can see, named tuples are a tuple/class/dictionary hybrid. They also represent\\na classic tradeoff. In exchange for their extra utility, they require extra code (the two\\nstartup lines in the preceding examples that import the type and make the class), and\\nincur some performance costs to work this magic. (In short, named tuples build new\\nclasses that extend the tuple type, inserting a property accessor method for each named\\nfield that maps the name to its position—a technique that relies on advanced topics\\nwe’ll explore in Part VIII, and uses formatted code strings instead of class annotation\\ntools like decorators and metaclasses.) Still, they are a good example of the kind of\\ncustom data types that we can build on top of built-in types like tuples when extra\\nutility is desired.\\nNamed tuples are available in Python 3.X, 2.7, 2.6 (where _asdict returns a true dic-\\ntionary), and perhaps earlier, though they rely on features relatively modern by Python\\nstandards. They are also extensions, not core types—they live in the standard library\\nand fall into the same category as Chapter 5’s Fraction and Decimal—so we’ll delegate\\nto the Python library manual for more details.\\nAs a quick preview, though, both tuples and named tuples support unpacking tuple\\nassignment, which we’ll study formally in Chapter 13, as well as the iteration contexts\\n\\nTuples\\n\\n| 281\\n\\n\\x0cwe’ll explore in Chapter 14 and Chapter 20 (notice the positional initial values here:\\nnamed tuples accept these by name, position, or both):\\n\\n>>> bob = Rec(\\'Bob\\', 40.5, [\\'dev\\', \\'mgr\\'])    # For both tuples and named tuples\\n>>> name, age, jobs = bob                     # Tuple assignment (Chapter 11)\\n>>> name, jobs\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n\\n>>> for x in bob: print(x)                    # Iteration context (Chapters 14, 20)\\n...prints Bob, 40.5, [\\'dev\\', \\'mgr\\']...\\n\\nTuple-unpacking assignment doesn’t quite apply to dictionaries, short of fetching and\\nconverting keys and values and assuming or imposing an positional ordering on them\\n(dictionaries are not sequences), and iteration steps through keys, not values (notice\\nthe dictionary literal form here: an alternative to dict):\\n\\n>>> bob = {\\'name\\': \\'Bob\\', \\'age\\': 40.5, \\'jobs\\': [\\'dev\\', \\'mgr\\']}\\n>>> job, name, age = bob.values()\\n>>> name, job                                 # Dict equivalent (but order may vary)\\n(\\'Bob\\', [\\'dev\\', \\'mgr\\'])\\n\\n>>> for x in bob: print(bob[x])               # Step though keys, index values\\n...prints values...\\n>>> for x in bob.values(): print(x)           # Step through values view\\n...prints values...\\n\\nWatch for a final rehash of this record representation thread when we see how user-\\ndefined classes compare in Chapter 27; as we’ll find, classes label fields with names too,\\nbut can also provide program logic to process the record’s data in the same package.\\n\\nFiles\\nYou may already be familiar with the notion of files, which are named storage com-\\npartments on your computer that are managed by your operating system. The last major\\nbuilt-in object type that we’ll examine on our object types tour provides a way to access\\nthose files inside Python programs.\\nIn short, the built-in open function creates a Python file object, which serves as a link\\nto a file residing on your machine. After calling open, you can transfer strings of data\\nto and from the associated external file by calling the returned file object’s methods.\\nCompared to the types you’ve seen so far, file objects are somewhat unusual. They are\\nconsidered a core type because they are created by a built-in function, but they’re not\\nnumbers, sequences, or mappings, and they don’t respond to expression operators;\\nthey export only methods for common file-processing tasks. Most file methods are\\nconcerned with performing input from and output to the external file associated with\\na file object, but other file methods allow us to seek to a new position in the file, flush\\noutput buffers, and so on. Table 9-2 summarizes common file operations.\\n\\n282 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cTable 9-2. Common file operations\\n\\nOperation\\noutput = open(r\\'C:\\\\spam\\', \\'w\\')\\n\\ninput = open(\\'data\\', \\'r\\')\\n\\ninput = open(\\'data\\')\\n\\naString = input.read()\\n\\naString = input.read(N)\\n\\naString = input.readline()\\n\\naList = input.readlines()\\n\\noutput.write(aString)\\n\\noutput.writelines(aList)\\n\\noutput.close()\\n\\noutput.flush()\\n\\nanyFile.seek(N)\\nfor line in open(\\'data\\'): use line\\nopen(\\'f.txt\\', encoding=\\'latin-1\\')\\n\\nopen(\\'f.bin\\', \\'rb\\')\\n\\ncodecs.open(\\'f.txt\\', encoding=\\'utf8\\')\\n\\nopen(\\'f.bin\\', \\'rb\\')\\n\\nInterpretation\\nCreate output file (\\'w\\' means write)\\nCreate input file (\\'r\\' means read)\\nSame as prior line (\\'r\\' is the default)\\nRead entire file into a single string\\nRead up to next N characters (or bytes) into a string\\nRead next line (including \\\\n newline) into a string\\nRead entire file into list of line strings (with \\\\n)\\nWrite a string of characters (or bytes) into file\\nWrite all line strings in a list into file\\nManual close (done for you when file is collected)\\nFlush output buffer to disk without closing\\nChange file position to offset N for next operation\\nFile iterators read line by line\\nPython 3.X Unicode text files (str strings)\\nPython 3.X bytes files (bytes strings)\\nPython 2.X Unicode text files (unicode strings)\\nPython 2.X bytes files (str strings)\\n\\nOpening Files\\nTo open a file, a program calls the built-in open function, with the external filename\\nfirst, followed by a processing mode. The call returns a file object, which in turn has\\nmethods for data transfer:\\n\\nafile = open(filename, mode)\\nafile.method()\\n\\nThe first argument to open, the external filename, may include a platform-specific and\\nabsolute or relative directory path prefix. Without a directory path, the file is assumed\\nto exist in the current working directory (i.e., where the script runs). As we’ll see in\\nChapter 37’s expanded file coverage, the filename may also contain non-ASCII Unicode\\ncharacters that Python automatically translates to and from the underlying platform’s\\nencoding, or be provided as a pre-encoded byte string.\\nThe second argument to open, processing mode, is typically the string \\'r\\' to open for\\ntext  input  (the  default),  \\'w\\'  to  create  and  open  for  text  output,  or  \\'a\\'  to  open  for\\nappending text to the end (e.g., for adding to logfiles). The processing mode argument\\ncan specify additional options:\\n\\nFiles\\n\\n| 283\\n\\n\\x0c• Adding a b to the mode string allows for binary data (end-of-line translations and\\n\\n3.X Unicode encodings are turned off).\\n\\n• Adding a + opens the file for both input and output (i.e., you can both read and\\nwrite to the same file object, often in conjunction with seek operations to reposition\\nin the file).\\n\\nBoth of the first two arguments to open must be Python strings. An optional third ar-\\ngument can be used to control output buffering—passing a zero means that output is\\nunbuffered (it is transferred to the external file immediately on a write method call),\\nand additional arguments may be provided for special types of files (e.g., an encoding\\nfor Unicode text files in Python 3.X).\\nWe’ll cover file fundamentals and explore some basic examples here, but we won’t go\\ninto all file-processing mode options; as usual, consult the Python library manual for\\nadditional details.\\n\\nUsing Files\\nOnce you make a file object with open, you can call its methods to read from or write\\nto the associated external file. In all cases, file text takes the form of strings in Python\\nprograms; reading a file returns its content in strings, and content is passed to the write\\nmethods as strings. Reading and writing methods come in multiple flavors; Table 9-2\\nlists the most common. Here are a few fundamental usage notes:\\n\\nFile iterators are best for reading lines\\n\\nThough the reading and writing methods in the table are common, keep in mind\\nthat probably the best way to read lines from a text file today is to not read the file\\nat all—as we’ll see in Chapter 14, files also have an iterator that automatically reads\\none line at a time in a for loop, list comprehension, or other iteration context.\\n\\nContent is strings, not objects\\n\\nNotice in Table 9-2 that data read from a file always comes back to your script as\\na string, so you’ll have to convert it to a different type of Python object if a string\\nis not what you need. Similarly, unlike with the print operation, Python does not\\nadd any formatting and does not convert objects to strings automatically when you\\nwrite data to a file—you must send an already formatted string. Because of this,\\nthe tools we have already met to convert objects to and from strings (e.g., int,\\nfloat, str, and the string formatting expression and method) come in handy when\\ndealing with files.\\nPython also includes advanced standard library tools for handling generic object\\nstorage  (the  pickle  module),  for  dealing  with  packed  binary  data  in  files  (the\\nstruct module), and for processing special types of content such as JSON, XML,\\nand CSV text. We’ll see these at work later in this chapter and book, but Python’s\\nmanuals document them in full.\\n\\n284 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cFiles are buffered and seekable\\n\\nBy default, output files are always buffered, which means that text you write may\\nnot be transferred from memory to disk immediately—closing a file, or running its\\nflush method, forces the buffered data to disk. You can avoid buffering with extra\\nopen arguments, but it may impede performance. Python files are also random-\\naccess on a byte offset basis—their seek method allows your scripts to jump around\\nto read and write at specific locations.\\n\\nclose is often optional: auto-close on collection\\n\\nCalling the file close method terminates your connection to the external file, re-\\nleases its system resources, and flushes its buffered output to disk if any is still in\\nmemory. As discussed in Chapter 6, in Python an object’s memory space is auto-\\nmatically reclaimed as soon as the object is no longer referenced anywhere in the\\nprogram. When file objects are reclaimed, Python also automatically closes the files\\nif they are still open (this also happens when a program shuts down). This means\\nyou don’t always need to manually close your files in standard Python, especially\\nthose in simple scripts with short runtimes, and temporary files used by a single\\nline or expression.\\nOn the other hand, including manual close calls doesn’t hurt, and may be a good\\nhabit to form, especially in long-running systems. Strictly speaking, this auto-close-\\non-collection feature of files is not part of the language definition—it may change\\nover time, may not happen when you expect it to in interactive shells, and may not\\nwork the same in other Python implementations whose garbage collectors may not\\nreclaim and close files at the same points as standard CPython. In fact, when many\\nfiles are opened within loops, Pythons other than CPython may require close calls\\nto free up system resources immediately, before garbage collection can get around\\nto freeing objects. Moreover, close calls may sometimes be required to flush buf-\\nfered output of file objects not yet reclaimed. For an alternative way to guarantee\\nautomatic  file  closes,  also  see  this  section’s  later  discussion  of  the  file  object’s\\ncontext manager, used with the with/as statement in Python 2.6, 2.7, and 3.X.\\n\\nFiles in Action\\nLet’s work through a simple example that demonstrates file-processing basics. The\\nfollowing code begins by opening a new text file for output, writing two lines (strings\\nterminated with a newline marker, \\\\n), and closing the file. Later, the example opens\\nthe same file again in input mode and reads the lines back one at a time with read\\nline. Notice that the third readline call returns an empty string; this is how Python file\\nmethods tell you that you’ve reached the end of the file (empty lines in the file come\\nback as strings containing just a newline character, not as empty strings). Here’s the\\ncomplete interaction:\\n\\n>>> myfile = open(\\'myfile.txt\\', \\'w\\')        # Open for text output: create/empty\\n>>> myfile.write(\\'hello text file\\\\n\\')       # Write a line of text: string\\n16\\n\\nFiles\\n\\n| 285\\n\\n\\x0c>>> myfile.write(\\'goodbye text file\\\\n\\')\\n18\\n>>> myfile.close()                          # Flush output buffers to disk\\n\\n>>> myfile = open(\\'myfile.txt\\')             # Open for text input: \\'r\\' is default\\n>>> myfile.readline()                       # Read the lines back\\n\\'hello text file\\\\n\\'\\n>>> myfile.readline()\\n\\'goodbye text file\\\\n\\'\\n>>> myfile.readline()                       # Empty string: end-of-file\\n\\'\\'\\n\\nNotice that file write calls return the number of characters written in Python 3.X; in\\n2.X they don’t, so you won’t see these numbers echoed interactively. This example\\nwrites each line of text, including its end-of-line terminator, \\\\n, as a string; write meth-\\nods don’t add the end-of-line character for us, so we must include it to properly ter-\\nminate our lines (otherwise the next write will simply extend the current line in the file).\\nIf you want to display the file’s content with end-of-line characters interpreted, read\\nthe entire file into a string all at once with the file object’s read method and print it:\\n\\n>>> open(\\'myfile.txt\\').read()               # Read all at once into string\\n\\'hello text file\\\\ngoodbye text file\\\\n\\'\\n\\n>>> print(open(\\'myfile.txt\\').read())        # User-friendly display\\nhello text file\\ngoodbye text file\\n\\nAnd if you want to scan a text file line by line, file iterators are often your best option:\\n\\n>>> for line in open(\\'myfile.txt\\'):         # Use file iterators, not reads\\n...     print(line, end=\\'\\')\\n...\\nhello text file\\ngoodbye text file\\n\\nWhen coded this way, the temporary file object created by open will automatically read\\nand return one line on each loop iteration. This form is usually easiest to code, good\\non memory use, and may be faster than some other options (depending on many vari-\\nables, of course). Since we haven’t reached statements or iterators yet, though, you’ll\\nhave to wait until Chapter 14 for a more complete explanation of this code.\\n\\nWindows users: As mentioned in Chapter 7, open accepts Unix-style for-\\nward slashes in place of backward slashes on Windows, so any of the\\nfollowing forms work for directory paths—raw strings, forward slashes,\\nor doubled-up backslashes:\\n\\n>>> open(r\\'C:\\\\Python33\\\\Lib\\\\pdb.py\\').readline()\\n\\'#! /usr/bin/env python3\\\\n\\'\\n>>> open(\\'C:/Python33/Lib/pdb.py\\').readline()\\n\\'#! /usr/bin/env python3\\\\n\\'\\n\\n286 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c>>> open(\\'C:\\\\\\\\Python33\\\\\\\\Lib\\\\\\\\pdb.py\\').readline()\\n\\'#! /usr/bin/env python3\\\\n\\'\\n\\nThe raw string form in the second command is still useful to turn off\\naccidental escapes when you can’t control string content, and in other\\ncontexts.\\n\\nText and Binary Files: The Short Story\\nStrictly speaking, the example in the prior section uses text files. In both Python 3.X\\nand 2.X, file type is determined by the second argument to open, the mode string—an\\nincluded “b” means binary. Python has always supported both text and binary files,\\nbut in Python 3.X there is a sharper distinction between the two:\\n\\n• Text files represent content as normal str strings, perform Unicode encoding and\\n\\ndecoding automatically, and perform end-of-line translation by default.\\n\\n• Binary files represent content as a special bytes string type and allow programs to\\n\\naccess file content unaltered.\\n\\nIn contrast, Python 2.X text files handle both 8-bit text and binary data, and a special\\nstring type and file interface (unicode strings and codecs.open) handles Unicode text.\\nThe differences in Python 3.X stem from the fact that simple and Unicode text have\\nbeen merged in the normal string type—which makes sense, given that all text is Uni-\\ncode, including ASCII and other 8-bit encodings.\\nBecause most programmers deal only with ASCII text, they can get by with the basic\\ntext file interface used in the prior example, and normal strings. All strings are techni-\\ncally Unicode in 3.X, but ASCII users will not generally notice. In fact, text files and\\nstrings work the same in 3.X and 2.X if your script’s scope is limited to such simple\\nforms of text.\\nIf you need to handle internationalized applications or byte-oriented data, though, the\\ndistinction in 3.X impacts your code (usually for the better). In general, you must use\\nbytes strings for binary files, and normal str strings for text files. Moreover, because\\ntext files implement Unicode encodings, you should not open a binary data file in text\\nmode—decoding its content to Unicode text will likely fail.\\nLet’s look at an example. When you read a binary data file you get back a bytes object\\n—a sequence of small integers that represent absolute byte values (which may or may\\nnot correspond to characters), which looks and feels almost exactly like a normal string.\\nIn Python 3.X, and assuming an existing binary file:\\n\\n>>> data = open(\\'data.bin\\', \\'rb\\').read()    # Open binary file: rb=read binary\\n>>> data                                    # bytes string holds binary data\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>> data[4:8]                               # Act like strings\\nb\\'spam\\'\\n>>> data[4:8][0]                            # But really are small 8-bit integers\\n115\\n\\nFiles\\n\\n| 287\\n\\n\\x0c>>> bin(data[4:8][0])                       # Python 3.X/2.6+ bin() function\\n\\'0b1110011\\'\\n\\nIn addition, binary files do not perform any end-of-line translation on data; text files by\\ndefault map all forms to and from \\\\n when written and read and implement Unicode\\nencodings on transfers in 3.X. Binary files like this one work the same in Python 2.X,\\nbut byte strings are simply normal strings and have no leading b when displayed, and\\ntext files must use the codecs module to add Unicode processing.\\nPer the note at the start of this chapter, though, that’s as much as we’re going to say\\nabout Unicode text and binary data files here, and just enough to understand upcoming\\nexamples in this chapter. Since the distinction is of marginal interest to many Python\\nprogrammers, we’ll defer to the files preview in Chapter 4 for a quick tour and postpone\\nthe full story until Chapter 37. For now, let’s move on to some more substantial file\\nexamples to demonstrate a few common use cases.\\n\\nStoring Python Objects in Files: Conversions\\nOur next example writes a variety of Python objects into a text file on multiple lines.\\nNotice that it must convert objects to strings using conversion tools. Again, file data is\\nalways strings in our scripts, and write methods do not do any automatic to-string\\nformatting for us (for space, I’m omitting byte-count return values from write methods \\nfrom here on):\\n\\n>>> X, Y, Z = 43, 44, 45                       # Native Python objects\\n>>> S = \\'Spam\\'                                 # Must be strings to store in file\\n>>> D = {\\'a\\': 1, \\'b\\': 2}\\n>>> L = [1, 2, 3]\\n>>>\\n>>> F = open(\\'datafile.txt\\', \\'w\\')              # Create output text file\\n>>> F.write(S + \\'\\\\n\\')                          # Terminate lines with \\\\n\\n>>> F.write(\\'%s,%s,%s\\\\n\\' % (X, Y, Z))          # Convert numbers to strings\\n>>> F.write(str(L) + \\'$\\' + str(D) + \\'\\\\n\\')      # Convert and separate with $\\n>>> F.close()\\n\\nOnce we have created our file, we can inspect its contents by opening it and reading it\\ninto a string (strung together as a single operation here). Notice that the interactive\\necho gives the exact byte contents, while the print operation interprets embedded end-\\nof-line characters to render a more user-friendly display:\\n\\n>>> chars = open(\\'datafile.txt\\').read()        # Raw string display\\n>>> chars\\n\"Spam\\\\n43,44,45\\\\n[1, 2, 3]${\\'a\\': 1, \\'b\\': 2}\\\\n\"\\n>>> print(chars)                               # User-friendly display\\nSpam\\n43,44,45\\n[1, 2, 3]${\\'a\\': 1, \\'b\\': 2}\\n\\nWe now have to use other conversion tools to translate from the strings in the text file\\nto real Python objects. As Python never converts strings to numbers (or other types of\\n\\n288 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cobjects) automatically, this is required if we need to gain access to normal object tools\\nlike indexing, addition, and so on:\\n\\n>>> F = open(\\'datafile.txt\\')                   # Open again\\n>>> line = F.readline()                        # Read one line\\n>>> line\\n\\'Spam\\\\n\\'\\n>>> line.rstrip()                              # Remove end-of-line\\n\\'Spam\\'\\n\\nFor this first line, we used the string rstrip method to get rid of the trailing end-of-line\\ncharacter; a line[:−1] slice would work, too, but only if we can be sure all lines end in\\nthe \\\\n character (the last line in a file sometimes does not).\\nSo far, we’ve read the line containing the string. Now let’s grab the next line, which\\ncontains numbers, and parse out (that is, extract) the objects on that line:\\n\\n>>> line = F.readline()                       # Next line from file\\n>>> line                                      # It\\'s a string here\\n\\'43,44,45\\\\n\\'\\n>>> parts = line.split(\\',\\')                   # Split (parse) on commas\\n>>> parts\\n[\\'43\\', \\'44\\', \\'45\\\\n\\']\\n\\nWe used the string split method here to chop up the line on its comma delimiters; the\\nresult is a list of substrings containing the individual numbers. We still must convert\\nfrom strings to integers, though, if we wish to perform math on these:\\n>>> int(parts[1])                              # Convert from string to int\\n44\\n>>> numbers = [int(P) for P in parts]          # Convert all in list at once\\n>>> numbers\\n[43, 44, 45]\\n\\nAs we have learned, int translates a string of digits into an integer object, and the list\\ncomprehension expression introduced in Chapter 4 can apply the call to each item in\\nour list all at once (you’ll find more on list comprehensions later in this book). Notice\\nthat we didn’t have to run rstrip to delete the \\\\n at the end of the last part; int and\\nsome other converters quietly ignore whitespace around digits.\\nFinally, to convert the stored list and dictionary in the third line of the file, we can run\\nthem through eval, a built-in function that treats a string as a piece of executable pro-\\ngram code (technically, a string containing a Python expression):\\n\\n>>> line = F.readline()\\n>>> line\\n\"[1, 2, 3]${\\'a\\': 1, \\'b\\': 2}\\\\n\"\\n>>> parts = line.split(\\'$\\')                    # Split (parse) on $\\n>>> parts\\n[\\'[1, 2, 3]\\', \"{\\'a\\': 1, \\'b\\': 2}\\\\n\"]\\n>>> eval(parts[0])                             # Convert to any object type\\n[1, 2, 3]\\n>>> objects = [eval(P) for P in parts]         # Do same for all in list\\n\\nFiles\\n\\n| 289\\n\\n\\x0c>>> objects\\n[[1, 2, 3], {\\'a\\': 1, \\'b\\': 2}]\\n\\nBecause the end result of all this parsing and converting is a list of normal Python objects\\ninstead of strings, we can now apply list and dictionary operations to them in our script.\\n\\nStoring Native Python Objects: pickle\\nUsing eval to convert from strings to objects, as demonstrated in the preceding code,\\nis a powerful tool. In fact, sometimes it’s too powerful. eval will happily run any Python\\nexpression—even one that might delete all the files on your computer, given the nec-\\nessary permissions! If you really want to store native Python objects, but you can’t trust\\nthe source of the data in the file, Python’s standard library pickle module is ideal.\\nThe pickle module is a more advanced tool that allows us to store almost any Python\\nobject in a file directly, with no to- or from-string conversion requirement on our part.\\nIt’s like a super-general data formatting and parsing utility. To store a dictionary in a\\nfile, for instance, we pickle it directly:\\n\\n>>> D = {\\'a\\': 1, \\'b\\': 2}\\n>>> F = open(\\'datafile.pkl\\', \\'wb\\')\\n>>> import pickle\\n>>> pickle.dump(D, F)                          # Pickle any object to file\\n>>> F.close()\\n\\nThen, to get the dictionary back later, we simply use pickle again to re-create it:\\n\\n>>> F = open(\\'datafile.pkl\\', \\'rb\\')\\n>>> E = pickle.load(F)                         # Load any object from file\\n>>> E\\n{\\'a\\': 1, \\'b\\': 2}\\n\\nWe get back an equivalent dictionary object, with no manual splitting or converting\\nrequired. The pickle module performs what is known as object serialization—convert-\\ning objects to and from strings of bytes—but requires very little work on our part. In\\nfact, pickle internally translates our dictionary to a string form, though it’s not much\\nto look at (and may vary if we pickle in other data protocol modes):\\n\\n>>> open(\\'datafile.pkl\\', \\'rb\\').read()          # Format is prone to change!\\nb\\'\\\\x80\\\\x03}q\\\\x00(X\\\\x01\\\\x00\\\\x00\\\\x00bq\\\\x01K\\\\x02X\\\\x01\\\\x00\\\\x00\\\\x00aq\\\\x02K\\\\x01u.\\'\\n\\nBecause pickle can reconstruct the object from this format, we don’t have to deal with\\nit ourselves. For more on the pickle module, see the Python standard library manual,\\nor import pickle and pass it to help interactively. While you’re exploring, also take a\\nlook at the shelve module. shelve is a tool that uses pickle to store Python objects in\\nan access-by-key filesystem, which is beyond our scope here (though you will get to see\\nan example of shelve in action in Chapter 28, and other pickle examples in Chap-\\nter 31 and Chapter 37).\\n\\n290 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cNotice that I opened the file used to store the pickled object in binary\\nmode; binary mode is always required in Python 3.X, because the pickler\\ncreates and uses a bytes string object, and these objects imply binary-\\nmode files (text-mode files imply str strings in 3.X). In earlier Pythons\\nit’s OK to use text-mode files for protocol 0 (the default, which creates\\nASCII text), as long as text mode is used consistently; higher protocols\\nrequire binary-mode files. Python 3.X’s default protocol is 3 (binary),\\nbut it creates bytes even for protocol 0. See Chapter 28, Chapter 31, and\\nChapter 37; Python’s library manual; or reference books for more details\\non and examples of pickled data.\\n\\nPython 2.X also has a cPickle module, which is an optimized version of\\npickle that can be imported directly for speed. Python 3.X renames this\\nmodule _pickle and uses it automatically in pickle—scripts simply im-\\nport pickle and let Python optimize itself.\\n\\nStoring Python Objects in JSON Format\\nThe prior section’s pickle module translates nearly arbitrary Python objects to a pro-\\nprietary  format  developed  specifically  for  Python,  and  honed  for  performance  over\\nmany years. JSON is a newer and emerging data interchange format, which is both\\nprogramming-language-neutral and supported by a variety of systems. MongoDB, for\\ninstance, stores data in a JSON document database (using a binary JSON format).\\nJSON  does  not  support  as  broad  a  range  of  Python  object  types  as  pickle,  but  its\\nportability is an advantage in some contexts, and it represents another way to serialize\\na specific category of Python objects for storage and transmission. Moreover, because\\nJSON is so close to Python dictionaries and lists in syntax, the translation to and from\\nPython objects is trivial, and is automated by the json standard library module.\\nFor example, a Python dictionary with nested structures is very similar to JSON data,\\nthough Python’s variables and expressions support richer structuring options (any part\\nof the following can be an arbitrary expression in Python code):\\n\\n>>> name = dict(first=\\'Bob\\', last=\\'Smith\\')\\n>>> rec  = dict(name=name, job=[\\'dev\\', \\'mgr\\'], age=40.5)\\n>>> rec\\n{\\'job\\': [\\'dev\\', \\'mgr\\'], \\'name\\': {\\'last\\': \\'Smith\\', \\'first\\': \\'Bob\\'}, \\'age\\': 40.5}\\n\\nThe final dictionary format displayed here is a valid literal in Python code, and almost\\npasses for JSON when printed as is, but the json module makes the translation official\\n—here translating Python objects to and from a JSON serialized string representation\\nin memory:\\n\\n>>> import json\\n>>> json.dumps(rec)\\n\\'{\"job\": [\"dev\", \"mgr\"], \"name\": {\"last\": \"Smith\", \"first\": \"Bob\"}, \"age\": 40.5}\\'\\n\\n>>> S = json.dumps(rec)\\n>>> S\\n\\nFiles\\n\\n| 291\\n\\n\\x0c\\'{\"job\": [\"dev\", \"mgr\"], \"name\": {\"last\": \"Smith\", \"first\": \"Bob\"}, \"age\": 40.5}\\'\\n\\n>>> O = json.loads(S)\\n>>> O\\n{\\'job\\': [\\'dev\\', \\'mgr\\'], \\'name\\': {\\'last\\': \\'Smith\\', \\'first\\': \\'Bob\\'}, \\'age\\': 40.5}\\n>>> O == rec\\nTrue\\n\\nIt’s similarly straightforward to translate Python objects to and from JSON data strings\\nin files. Prior to being stored in a file, your data is simply Python objects; the JSON\\nmodule recreates them from the JSON textual representation when it loads it from the\\nfile:\\n\\n>>> json.dump(rec, fp=open(\\'testjson.txt\\', \\'w\\'), indent=4)\\n>>> print(open(\\'testjson.txt\\').read())\\n{\\n    \"job\": [\\n        \"dev\",\\n        \"mgr\"\\n    ],\\n    \"name\": {\\n        \"last\": \"Smith\",\\n        \"first\": \"Bob\"\\n    },\\n    \"age\": 40.5\\n}\\n>>> P = json.load(open(\\'testjson.txt\\'))\\n>>> P\\n{\\'job\\': [\\'dev\\', \\'mgr\\'], \\'name\\': {\\'last\\': \\'Smith\\', \\'first\\': \\'Bob\\'}, \\'age\\': 40.5}\\n\\nOnce you’ve translated from JSON text, you process the data using normal Python\\nobject operations in your script. For more details on JSON-related topics, see Python’s\\nlibrary manuals and search the Web.\\nNote that strings are all Unicode in JSON to support text drawn from international\\ncharacter sets, so you’ll see a leading u on strings after translating from JSON data in\\nPython 2.X (but not in 3.X); this is just the syntax of Unicode objects in 2.X, as intro-\\nduced Chapter 4 and Chapter 7, and covered in full in Chapter 37. Because Unicode\\ntext strings support all the usual string operations, the difference is negligible to your\\ncode while text resides in memory; the distinction matters most when transferring text\\nto and from files, and then usually only for non-ASCII types of text where encodings\\ncome into play.\\n\\nThere is also support in the Python world for translating objects to and\\nfrom XML, a text format used in Chapter 37; see the web for details.For\\nanother semirelated tool that deals with formatted data files, see the\\nstandard library’s csv module. It parses and creates CSV (comma-sep-\\narated value) data in files and strings. This doesn’t map as directly to\\nPython objects, but is another common data exchange format:\\n\\n>>> import csv\\n>>> rdr = csv.reader(open(\\'csvdata.txt\\'))\\n\\n292 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c>>> for row in rdr: print(row)\\n...\\n[\\'a\\', \\'bbb\\', \\'cc\\', \\'dddd\\']\\n[\\'11\\', \\'22\\', \\'33\\', \\'44\\']\\n\\nStoring Packed Binary Data: struct\\nOne other file-related note before we move on: some advanced applications also need\\nto deal with packed binary data, created perhaps by a C language program or a network\\nconnection.  Python’s  standard  library  includes  a  tool  to  help  in  this  domain—the\\nstruct module knows how to both compose and parse packed binary data. In a sense,\\nthis is another data-conversion tool that interprets strings in files as binary data.\\nWe saw an overview of this tool in Chapter 4, but let’s take another quick look here\\nfor more perspective. To create a packed binary data file, open it in \\'wb\\' (write binary)\\nmode, and pass struct a format string and some Python objects. The format string used\\nhere means pack as a 4-byte integer, a 4-character string (which must be a bytes string\\nas of Python 3.2), and a 2-byte integer, all in big-endian form (other format codes handle\\npadding bytes, floating-point numbers, and more):\\n\\n>>> F = open(\\'data.bin\\', \\'wb\\')                     # Open binary output file\\n>>> import struct\\n>>> data = struct.pack(\\'>i4sh\\', 7, b\\'spam\\', 8)     # Make packed binary data\\n>>> data\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>> F.write(data)                                  # Write byte string\\n>>> F.close()\\n\\nPython creates a binary bytes data string, which we write out to the file normally—this\\none consists mostly of nonprintable characters printed in hexadecimal escapes, and is\\nthe same binary file we met earlier. To parse the values out to normal Python objects,\\nwe simply read the string back and unpack it using the same format string. Python\\nextracts the values into normal Python objects—integers and a string:\\n\\n>>> F = open(\\'data.bin\\', \\'rb\\')\\n>>> data = F.read()                                # Get packed binary data\\n>>> data\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>> values = struct.unpack(\\'>i4sh\\', data)          # Convert to Python objects\\n>>> values\\n(7, b\\'spam\\', 8)\\n\\nBinary data files are advanced and somewhat low-level tools that we won’t cover in\\nmore detail here; for more help, see the struct coverage in Chapter 37, consult the\\nPython library manual, or import struct and pass it to the help function interactively.\\nAlso note that you can use the binary file-processing modes \\'wb\\' and \\'rb\\' to process a\\nsimpler binary file, such as an image or audio file, as a whole without having to unpack\\nits contents; in such cases your code might pass it unparsed to other files or tools.\\n\\nFiles\\n\\n| 293\\n\\n\\x0cFile Context Managers\\nYou’ll also want to watch for Chapter 34’s discussion of the file’s context manager\\nsupport, new as of Python 3.0 and 2.6. Though more a feature of exception processing\\nthan files themselves, it allows us to wrap file-processing code in a logic layer that\\nensures  that  the  file  will  be  closed  (and  if  needed,  have  its  output  flushed  to  disk)\\nautomatically on exit, instead of relying on the auto-close during garbage collection:\\n\\nwith open(r\\'C:\\\\code\\\\data.txt\\') as myfile:     # See Chapter 34 for details\\n    for line in myfile:\\n        ...use line here...\\n\\nThe  try/finally  statement  that  we’ll  also  study  in  Chapter  34  can  provide  similar\\nfunctionality, but at some cost in extra code—three extra lines, to be precise (though\\nwe can often avoid both options and let Python close files for us automatically):\\n\\nmyfile = open(r\\'C:\\\\code\\\\data.txt\\')\\ntry:\\n    for line in myfile:\\n        ...use line here...\\nfinally:\\n    myfile.close()\\n\\nThe with context manager scheme ensures release of system resources in all Pythons,\\nand may be more useful for output files to guarantee buffer flushes; unlike the more\\ngeneral try, though, it is also limited to objects that support its protocol. Since both\\nthese  options  require  more  information  than  we  have  yet  obtained,  however,  we’ll\\npostpone details until later in this book.\\n\\nOther File Tools\\nThere are additional, more specialized file methods shown in Table 9-2, and even more\\nthat are not in the table. For instance, as mentioned earlier, seek resets your current\\nposition in a file (the next read or write happens at that position), flush forces buffered \\noutput to be written out to disk without closing the connection (by default, files are\\nalways buffered), and so on.\\nThe Python standard library manual and the reference books described in the preface\\nprovide complete lists of file methods; for a quick look, run a dir or help call interac-\\ntively, passing in an open file object (in Python 2.X but not 3.X, you can pass in the\\nname file instead). For more file-processing examples, watch for the sidebar “Why\\nYou Will Care: File Scanners” on page 400 in Chapter 13. It sketches common file-\\nscanning loop code patterns with statements we have not covered enough yet to use\\nhere.\\nAlso, note that although the open function and the file objects it returns are your main\\ninterface to external files in a Python script, there are additional file-like tools in the\\nPython toolset. Among these:\\n\\n294 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cStandard streams\\n\\nPreopened file objects in the sys module, such as sys.stdout (see “Print Opera-\\ntions” on page 358 in Chapter 11 for details)\\n\\nDescriptor files in the os module\\n\\nInteger file handles that support lower-level tools such as file locking (see also the\\n“x” mode in Python 3.3’s open for exclusive creation)\\n\\nSockets, pipes, and FIFOs\\n\\nFile-like objects used to synchronize processes or communicate over networks\\n\\nAccess-by-key files known as “shelves”\\n\\nUsed to store unaltered and pickled Python objects directly, by key (used in Chap-\\nter 28)\\n\\nShell command streams\\n\\nTools such as os.popen and subprocess.Popen that support spawning shell com-\\nmands  and  reading  and  writing  to  their  standard  streams  (see  Chapter  13  and\\nChapter 21 for examples)\\n\\nThe third-party open source domain offers even more file-like tools, including support\\nfor communicating with serial ports in the PySerial extension and interactive programs\\nin the pexpect system. See applications-focused Python texts and the Web at large for\\nadditional information on file-like tools.\\n\\nVersion skew note: In Python 2.X, the built-in name open is essentially a\\nsynonym for the name file, and you may technically open files by call-\\ning either open or file (though open is generally preferred for opening).\\nIn Python 3.X, the name file is no longer available, because of its re-\\ndundancy with open.\\n\\nPython 2.X users may also use the name file as the file object type, in\\norder to customize files with object-oriented programming (described\\nlater  in  this  book).  In  Python  3.X,  files  have  changed  radically.  The\\nclasses used to implement file objects live in the standard library module\\nio. See this module’s documentation or code for the classes it makes\\navailable for customization, and run a type(F) call on an open file F for\\nhints.\\n\\nCore Types Review and Summary\\nNow that we’ve seen all of Python’s core built-in types in action, let’s wrap up our\\nobject types tour by reviewing some of the properties they share. Table 9-3 classifies\\nall the major types we’ve seen so far according to the type categories introduced earlier.\\nHere are some points to remember:\\n\\nCore Types Review and Summary | 295\\n\\n\\x0c• Objects share operations according to their category; for instance, sequence objects\\n—strings, lists, and tuples—all share sequence operations such as concatenation,\\nlength, and indexing.\\n\\n• Only mutable objects—lists, dictionaries, and sets—may be changed in place; you\\n\\ncannot change numbers, strings, or tuples in place.\\n\\n• Files export only methods, so mutability doesn’t really apply to them—their state\\nmay be changed when they are processed, but this isn’t quite the same as Python\\ncore type mutability constraints.\\n\\n• “Numbers” in Table 9-3 includes all number types: integer (and the distinct long\\n\\ninteger in 2.X), floating point, complex, decimal, and fraction.\\n\\n• “Strings” in Table 9-3 includes str, as well as bytes in 3.X and unicode in 2.X; the\\n\\nbytearray string type in 3.X, 2.6, and 2.7 is mutable.\\n\\n• Sets are something like the keys of a valueless dictionary, but they don’t map to\\nvalues and are not ordered, so sets are neither a mapping nor a sequence type;\\nfrozenset is an immutable variant of set.\\n\\n• In addition to type category operations, as of Python 2.6 and 3.0 all the types in\\n\\nTable 9-3 have callable methods, which are generally specific to their type.\\n\\nTable 9-3. Object classifications\\n\\nObject type\\nNumbers (all)\\nStrings (all)\\nLists\\nDictionaries\\nTuples\\nFiles\\nSets\\nFrozenset\\n\\nbytearray\\n\\nCategory\\nNumeric\\nSequence\\nSequence\\nMapping\\nSequence\\nExtension\\nSet\\nSet\\nSequence\\n\\nMutable?\\nNo\\nNo\\nYes\\nYes\\nNo\\nN/A\\nYes\\nNo\\nYes\\n\\nWhy You Will Care: Operator Overloading\\n\\nIn Part VI of this book, we’ll see that objects we implement with classes can pick and\\nchoose from these categories arbitrarily. For instance, if we want to provide a new kind\\nof specialized sequence object that is consistent with built-in sequences, we can code\\na class that overloads things like indexing and concatenation:\\n\\nclass MySequence:\\n    def __getitem__(self, index):\\n        # Called on self[index], others\\n    def __add__(self, other):\\n        # Called on self + other\\n\\n296 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c    def __iter__(self):\\n        # Preferred in iterations\\n\\nand so on. We can also make the new object mutable or not by selectively implementing\\nmethods  called  for  in-place  change  operations  (e.g.,  __setitem__  is  called  on\\nself[index]=value assignments). Although it’s beyond this book’s scope, it’s also pos-\\nsible to implement new objects in an external language like C as C extension types. For\\nthese, we fill in C function pointer slots to choose between number, sequence, and\\nmapping operation sets.\\n\\nObject Flexibility\\nThis part of the book introduced a number of compound object types—collections\\nwith components. In general:\\n\\n• Lists, dictionaries, and tuples can hold any kind of object.\\n• Sets can contain any type of immutable object.\\n• Lists, dictionaries, and tuples can be arbitrarily nested.\\n• Lists, dictionaries, and sets can dynamically grow and shrink.\\n\\nBecause they support arbitrary structures, Python’s compound object types are good\\nat representing complex information in programs. For example, values in dictionaries\\nmay be lists, which may contain tuples, which may contain dictionaries, and so on. The\\nnesting can be as deep as needed to model the data to be processed.\\nLet’s look at an example of nesting. The following interaction defines a tree of nested\\ncompound sequence objects, shown in Figure 9-1. To access its components, you may\\ninclude as many index operations as required. Python evaluates the indexes from left\\nto  right,  and  fetches  a  reference  to  a  more  deeply  nested  object  at  each  step.  Fig-\\nure 9-1 may be a pathologically complicated data structure, but it illustrates the syntax\\nused to access nested objects in general:\\n>>> L = [\\'abc\\', [(1, 2), ([3], 4)], 5]\\n>>> L[1]\\n[(1, 2), ([3], 4)]\\n>>> L[1][1]\\n([3], 4)\\n>>> L[1][1][0]\\n[3]\\n>>> L[1][1][0][0]\\n3\\n\\nReferences Versus Copies\\nChapter 6 mentioned that assignments always store references to objects, not copies\\nof those objects. In practice, this is usually what you want. Because assignments can\\ngenerate multiple references to the same object, though, it’s important to be aware that\\n\\nCore Types Review and Summary | 297\\n\\n\\x0cFigure 9-1. A nested object tree with the offsets of its components, created by running the literal\\nexpression  [‘abc’,  [(1,  2),  ([3],  4)],  5].  Syntactically  nested  objects  are  internally  represented  as\\nreferences (i.e., pointers) to separate pieces of memory.\\n\\nchanging a mutable object in place may affect other references to the same object else-\\nwhere in your program. If you don’t want such behavior, you’ll need to tell Python to\\ncopy the object explicitly.\\nWe studied this phenomenon in Chapter 6, but it can become more subtle when larger\\nobjects of the sort we’ve explored since then come into play. For instance, the following\\nexample creates a list assigned to X, and another list assigned to L that embeds a refer-\\nence back to list X. It also creates a dictionary D that contains another reference back to\\nlist X:\\n\\n>>> X = [1, 2, 3]\\n>>> L = [\\'a\\', X, \\'b\\']            # Embed references to X\\'s object\\n>>> D = {\\'x\\':X, \\'y\\':2}\\n\\nAt this point, there are three references to the first list created: from the name X, from\\ninside the list assigned to L, and from inside the dictionary assigned to D. The situation\\nis illustrated in Figure 9-2.\\nBecause lists are mutable, changing the shared list object from any of the three refer-\\nences also changes what the other two reference:\\n\\n>>> X[1] = \\'surprise\\'             # Changes all three references!\\n>>> L\\n[\\'a\\', [1, \\'surprise\\', 3], \\'b\\']\\n>>> D\\n{\\'x\\': [1, \\'surprise\\', 3], \\'y\\': 2}\\n\\nReferences are a higher-level analog of pointers in other languages that are always fol-\\nlowed when used. Although you can’t grab hold of the reference itself, it’s possible to\\n\\n298 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cFigure 9-2. Shared object references: because the list referenced by variable X is also referenced from\\nwithin the objects referenced by L and D, changing the shared list from X makes it look different from\\nL and D, too.\\n\\nstore the same reference in more than one place (variables, lists, and so on). This is a\\nfeature—you can pass a large object around a program without generating expensive\\ncopies of it along the way. If you really do want copies, however, you can request them:\\n\\n• Slice expressions with empty limits (L[:]) copy sequences.\\n• The dictionary, set, and list copy method (X.copy()) copies a dictionary, set, or list\\n\\n(the list’s copy is new as of 3.3).\\n\\n• Some  built-in  functions,  such  as  list  and  dict  make  copies  (list(L),  dict(D),\\n\\nset(S)).\\n\\n• The copy standard library module makes full copies when needed.\\n\\nFor example, say you have a list and a dictionary, and you don’t want their values to\\nbe changed through other variables:\\n\\n>>> L = [1,2,3]\\n>>> D = {\\'a\\':1, \\'b\\':2}\\n\\nTo prevent this, simply assign copies to the other variables, not references to the same\\nobjects:\\n\\n>>> A = L[:]                      # Instead of A = L (or list(L))\\n>>> B = D.copy()                  # Instead of B = D (ditto for sets)\\n\\nThis way, changes made from the other variables will change the copies, not the orig-\\ninals:\\n\\n>>> A[1] = \\'Ni\\'\\n>>> B[\\'c\\'] = \\'spam\\'\\n>>>\\n>>> L, D\\n([1, 2, 3], {\\'a\\': 1, \\'b\\': 2})\\n\\nCore Types Review and Summary | 299\\n\\n\\x0c>>> A, B\\n([1, \\'Ni\\', 3], {\\'a\\': 1, \\'c\\': \\'spam\\', \\'b\\': 2})\\n\\nIn terms of our original example, you can avoid the reference side effects by slicing the\\noriginal list instead of simply naming it:\\n\\n>>> X = [1, 2, 3]\\n>>> L = [\\'a\\', X[:], \\'b\\']           # Embed copies of X\\'s object\\n>>> D = {\\'x\\':X[:], \\'y\\':2}\\n\\nThis changes the picture in Figure 9-2—L and D will now point to different lists than\\nX. The net effect is that changes made through X will impact only X, not L and D; similarly,\\nchanges to L or D will not impact X.\\nOne final note on copies: empty-limit slices and the dictionary copy method only make\\ntop-level copies; that is, they do not copy nested data structures, if any are present. If\\nyou need a complete, fully independent copy of a deeply nested data structure (like the\\nvarious record structures we’ve coded in recent chapters), use the standard copy mod-\\nule, introduced in Chapter 6:\\n\\nimport copy\\nX = copy.deepcopy(Y)               # Fully copy an arbitrarily nested object Y\\n\\nThis call recursively traverses objects to copy all their parts. This is a much more rare\\ncase, though, which is why you have to say more to use this scheme. References are\\nusually what you will want; when they are not, slices and copy methods are usually as\\nmuch copying as you’ll need to do.\\n\\nComparisons, Equality, and Truth\\nAll Python objects also respond to comparisons: tests for equality, relative magnitude,\\nand so on. Python comparisons always inspect all parts of compound objects until a\\nresult can be determined. In fact, when nested objects are present, Python automatically\\ntraverses  data  structures  to  apply  comparisons  from  left  to  right,  and  as  deeply  as\\nneeded. The first difference found along the way determines the comparison result.\\nThis is sometimes called a recursive comparison—the same comparison requested on\\nthe top-level objects is applied to each of the nested objects, and to each of their nested\\nobjects, and so on, until a result is found. Later in this book—in Chapter 19—we’ll see\\nhow to write recursive functions of our own that work similarly on nested structures.\\nFor now, think about comparing all the linked pages at two websites if you want a\\nmetaphor for such structures, and a reason for writing recursive functions to process\\nthem.\\nIn terms of core types, the recursion is automatic. For instance, a comparison of list\\nobjects compares all their components automatically until a mismatch is found or the\\nend is reached:\\n\\n>>> L1 = [1, (\\'a\\', 3)]           # Same value, unique objects\\n>>> L2 = [1, (\\'a\\', 3)]\\n\\n300 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c>>> L1 == L2, L1 is L2           # Equivalent? Same object?\\n(True, False)\\n\\nHere, L1 and L2 are assigned lists that are equivalent but distinct objects. As a review\\nof what we saw in Chapter 6, because of the nature of Python references, there are two\\nways to test for equality:\\n\\n• The == operator tests value equivalence. Python performs an equivalence test,\\n\\ncomparing all nested objects recursively.\\n\\n• The is operator tests object identity. Python tests whether the two are really the\\n\\nsame object (i.e., live at the same address in memory).\\n\\nIn the preceding example, L1 and L2 pass the == test (they have equivalent values because\\nall their components are equivalent) but fail the is check (they reference two different\\nobjects, and hence two different pieces of memory). Notice what happens for short\\nstrings, though:\\n\\n>>> S1 = \\'spam\\'\\n>>> S2 = \\'spam\\'\\n>>> S1 == S2, S1 is S2\\n(True, True)\\n\\nHere, we should again have two distinct objects that happen to have the same value:\\n== should be true, and is should be false. But because Python internally caches and\\nreuses  some  strings  as  an  optimization,  there  really  is  just  a  single  string  \\'spam\\'  in\\nmemory, shared by S1 and S2; hence, the is identity test reports a true result. To trigger\\nthe normal behavior, we need to use longer strings:\\n\\n>>> S1 = \\'a longer string\\'\\n>>> S2 = \\'a longer string\\'\\n>>> S1 == S2, S1 is S2\\n(True, False)\\n\\nOf course, because strings are immutable, the object caching mechanism is irrelevant\\nto your code—strings can’t be changed in place, regardless of how many variables refer\\nto them. If identity tests seem confusing, see Chapter 6 for a refresher on object refer-\\nence concepts.\\nAs a rule of thumb, the == operator is what you will want to use for almost all equality\\nchecks; is is reserved for highly specialized roles. We’ll see cases later in the book where\\nboth operators are put to use.\\nRelative magnitude comparisons are also applied recursively to nested data structures:\\n\\n>>> L1 = [1, (\\'a\\', 3)]\\n>>> L2 = [1, (\\'a\\', 2)]\\n>>> L1 < L2, L1 == L2, L1 > L2        # Less, equal, greater: tuple of results\\n(False, False, True)\\n\\nHere, L1 is greater than L2 because the nested 3 is greater than 2. By now you should\\nknow that the result of the last line is really a tuple of three objects—the results of the\\nthree expressions typed (an example of a tuple without its enclosing parentheses).\\n\\nCore Types Review and Summary | 301\\n\\n\\x0cMore specifically, Python compares types as follows:\\n\\n• Numbers are compared by relative magnitude, after conversion to the common\\n\\nhighest type if needed.\\n\\n• Strings are compared lexicographically (by the character set code point values re-\\nturned by ord), and character by character until the end or first mismatch (\"abc\"\\n< \"ac\").\\n\\n• Lists and tuples are compared by comparing each component from left to right,\\nand recursively for nested structures, until the end or first mismatch ([2] > [1, 2]).\\n• Sets are equal if both contain the same items (formally, if each is a subset of the\\n\\nother), and set relative magnitude comparisons apply subset and superset tests.\\n\\n• Dictionaries compare as equal if their sorted (key, value) lists are equal. Relative\\nmagnitude comparisons are not supported for dictionaries in Python 3.X, but they\\nwork in 2.X as though comparing sorted (key, value) lists.\\n\\n• Nonnumeric mixed-type magnitude comparisons (e.g., 1 < \\'spam\\') are errors in\\nPython 3.X. They are allowed in Python 2.X, but use a fixed but arbitrary ordering\\nrule based on type name string. By proxy, this also applies to sorts, which use\\ncomparisons internally: nonnumeric mixed-type collections cannot be sorted in\\n3.X.\\n\\nIn general, comparisons of structured objects proceed as though you had written the\\nobjects as literals and compared all their parts one at a time from left to right. In later\\nchapters, we’ll see other object types that can change the way they get compared.\\n\\nPython 2.X and 3.X mixed-type comparisons and sorts\\nPer the last point in the preceding section’s list, the change in Python 3.X for nonnu-\\nmeric mixed-type comparisons applies to magnitude tests, not equality, but it also ap-\\nplies by proxy to sorting, which does magnitude testing internally. In Python 2.X these\\nall work, though mixed types compare by an arbitrary ordering:\\n\\nc:\\\\code> c:\\\\python27\\\\python\\n>>> 11 == \\'11\\'                          # Equality does not convert non-numbers\\nFalse\\n>>> 11 >= \\'11\\'                          # 2.X compares by type name string: int, str\\nFalse\\n>>> [\\'11\\', \\'22\\'].sort()                 # Ditto for sorts\\n>>> [11, \\'11\\'].sort()\\n\\nBut Python 3.X disallows mixed-type magnitude testing, except numeric types and\\nmanually converted types:\\n\\nc:\\\\code> c:\\\\python33\\\\python\\n>>> 11 == \\'11\\'                          # 3.X: equality works but magnitude does not\\nFalse\\n>>> 11 >= \\'11\\'\\nTypeError: unorderable types: int() > str()\\n\\n302 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c>>> [\\'11\\', \\'22\\'].sort()                 # Ditto for sorts\\n>>> [11, \\'11\\'].sort()\\nTypeError: unorderable types: str() < int()\\n\\n>>> 11 > 9.123                          # Mixed numbers convert to highest type\\nTrue\\n>>> str(11) >= \\'11\\', 11 >= int(\\'11\\')    # Manual conversions force the issue\\n(True, True)\\n\\nPython 2.X and 3.X dictionary comparisons\\nThe second-to-last point in the preceding section also merits illustration. In Python\\n2.X, dictionaries support magnitude comparisons, as though you were comparing sor-\\nted key/value lists:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> D1 = {\\'a\\':1, \\'b\\':2}\\n>>> D2 = {\\'a\\':1, \\'b\\':3}\\n>>> D1 == D2                            # Dictionary equality: 2.X + 3.X\\nFalse\\n>>> D1 < D2                             # Dictionary magnitude: 2.X only\\nTrue\\n\\nAs  noted  briefly  in  Chapter  8,  though,  magnitude  comparisons  for  dictionaries  are\\nremoved in Python 3.X because they incur too much overhead when equality is desired\\n(equality uses an optimized scheme in 3.X that doesn’t literally compare sorted key/\\nvalue lists):\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> D1 = {\\'a\\':1, \\'b\\':2}\\n>>> D2 = {\\'a\\':1, \\'b\\':3}\\n>>> D1 == D2\\nFalse\\n>>> D1 < D2\\nTypeError: unorderable types: dict() < dict()\\n\\nThe alternative in 3.X is to either write loops to compare values by key, or compare the\\nsorted key/value lists manually—the items dictionary methods and sorted built-in suf-\\nfice:\\n\\n>>> list(D1.items())\\n[(\\'b\\', 2), (\\'a\\', 1)]\\n>>> sorted(D1.items())\\n[(\\'a\\', 1), (\\'b\\', 2)]\\n>>>\\n>>> sorted(D1.items()) < sorted(D2.items())          # Magnitude test in 3.X\\nTrue\\n>>> sorted(D1.items()) > sorted(D2.items())\\nFalse\\n\\nThis takes more code, but in practice, most programs requiring this behavior will de-\\nvelop more efficient ways to compare data in dictionaries than either this workaround\\nor the original behavior in Python 2.X.\\n\\nCore Types Review and Summary | 303\\n\\n\\x0cThe Meaning of True and False in Python\\nNotice that the test results returned in the last two examples represent true and false\\nvalues. They print as the words True and False, but now that we’re using logical tests\\nlike these in earnest, I should be a bit more formal about what these names really mean.\\nIn Python, as in most programming languages, an integer 0 represents false, and an\\ninteger 1 represents true. In addition, though, Python recognizes any empty data struc-\\nture as false and any nonempty data structure as true. More generally, the notions of\\ntrue and false are intrinsic properties of every object in Python—each object is either\\ntrue or false, as follows:\\n\\n• Numbers are false if zero, and true otherwise.\\n• Other objects are false if empty, and true otherwise.\\n\\nTable 9-4 gives examples of true and false values of objects in Python.\\n\\nTable 9-4. Example object truth values\\n\\nObject\\n\"spam\"\\n\\n\"\"\\n\\n[1, 2]\\n\\n[]\\n\\nValue\\nTrue\\n\\nFalse\\n\\nTrue\\n\\nFalse\\n\\n{\\'a\\': 1}\\n\\nTrue\\n\\n{}\\n\\n1\\n\\n0.0\\n\\nNone\\n\\nFalse\\n\\nTrue\\n\\nFalse\\n\\nFalse\\n\\nAs one application, because objects are true or false themselves, it’s common to see\\nPython programmers code tests like if X:, which, assuming X is a string, is the same\\nas if X != \\'\\':. In other words, you can test the object itself to see if it contains anything,\\ninstead of comparing it to an empty, and therefore false, object of the same type (more\\non if statements in the next chapter).\\n\\nThe None object\\nAs shown in the last row in Table 9-4, Python also provides a special object called\\nNone,  which  is  always  considered  to  be  false.  None  was  introduced  briefly  in  Chap-\\nter 4; it is the only value of a special data type in Python and typically serves as an empty\\nplaceholder (much like a NULL pointer in C).\\nFor example, recall that for lists you cannot assign to an offset unless that offset already\\nexists—the list does not magically grow if you attempt an out-of-bounds assignment.\\n\\n304 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cTo preallocate a 100-item list such that you can add to any of the 100 offsets, you can\\nfill it with None objects:\\n>>> L = [None] * 100\\n>>>\\n>>> L\\n[None, None, None, None, None, None, None, ... ]\\n\\nThis doesn’t limit the size of the list (it can still grow and shrink later), but simply\\npresets an initial size to allow for future index assignments. You could initialize a list\\nwith zeros the same way, of course, but best practice dictates using None if the type of\\nthe list’s contents is variable or not yet known.\\nKeep in mind that None does not mean “undefined.” That is, None is something, not\\nnothing (despite its name!)—it is a real object and a real piece of memory that is created\\nand given a built-in name by Python itself. Watch for other uses of this special object\\nlater in the book; as we’ll learn in Part IV, it is also the default return value of functions\\nthat don’t exit by running into a return statement with a result value.\\n\\nThe bool type\\nWhile we’re on the topic of truth, also keep in mind that the Python Boolean type\\nbool, introduced in Chapter 5, simply augments the notions of true and false in Python.\\nAs we learned in Chapter 5, the built-in words  True and  False are just customized\\nversions of the integers 1 and 0—it’s as if these two words have been preassigned to 1\\nand 0 everywhere in Python. Because of the way this new type is implemented, this is\\nreally just a minor extension to the notions of true and false already described, designed\\nto make truth values more explicit:\\n\\n• When used explicitly in truth test code, the words True and False are equivalent\\n\\nto 1 and 0, but they make the programmer’s intent clearer.\\n\\n• Results of Boolean tests run interactively print as the words True and False, instead\\n\\nof as 1 and 0, to make the type of result clearer.\\n\\nYou are not required to use only Boolean types in logical statements such as if; all\\nobjects are still inherently true or false, and all the Boolean concepts mentioned in this\\nchapter still work as described if you use other types. Python also provides a bool built-\\nin function that can be used to test the Boolean value of an object if you want to make\\nthis explicit (i.e., whether it is true—that is, nonzero or nonempty):\\n\\n>>> bool(1)\\nTrue\\n>>> bool(\\'spam\\')\\nTrue\\n>>> bool({})\\nFalse\\n\\nIn practice, though, you’ll rarely notice the Boolean type produced by logic tests, be-\\ncause Boolean results are used automatically by if statements and other selection tools.\\nWe’ll explore Booleans further when we study logical statements in Chapter 12.\\n\\nCore Types Review and Summary | 305\\n\\n\\x0cPython’s Type Hierarchies\\nAs a summary and reference, Figure 9-3 sketches all the built-in object types available\\nin Python and their relationships. We’ve looked at the most prominent of these; most\\nof the other kinds of objects in Figure 9-3 correspond to program units (e.g., functions\\nand modules) or exposed interpreter internals (e.g., stack frames and compiled code).\\nThe largest point to notice here is that everything in a Python system is an object type\\nand may be processed by your Python programs. For instance, you can pass a class to\\na function, assign it to a variable, stuff it in a list or dictionary, and so on.\\n\\nType Objects\\nIn fact, even types themselves are an object type in Python: the type of an object is an\\nobject of type type (say that three times fast!). Seriously, a call to the built-in function\\ntype(X) returns the type object of object X. The practical application of this is that type\\nobjects can be used for manual type comparisons in Python if statements. However,\\nfor reasons introduced in Chapter 4, manual type testing is usually not the right thing\\nto do in Python, since it limits your code’s flexibility.\\nOne note on type names: as of Python 2.2, each core type has a new built-in name\\nadded to support type customization through object-oriented subclassing: dict, list,\\nstr, tuple, int, float, complex, bytes, type, set, and more. In Python 3.X names all\\nreferences classes, and in Python 2.X but not 3.X, file is also a type name and a syn-\\nonym for open. Calls to these names are really object constructor calls, not simply con-\\nversion functions, though you can treat them as simple functions for basic usage.\\nIn addition, the types standard library module in Python 3.X provides additional type\\nnames for types that are not available as built-ins (e.g., the type of a function; in Python\\n2.X but not 3.X, this module also includes synonyms for built-in type names), and it is\\npossible to do type tests with the isinstance function. For example, all of the following\\ntype tests are true:\\n\\ntype([1]) == type([])               # Compare to type of another list\\ntype([1]) == list                   # Compare to list type name\\nisinstance([1], list)               # Test if list or customization thereof\\n\\nimport types                        # types has names for other types\\ndef f(): pass\\ntype(f) == types.FunctionType\\n\\nBecause types can be subclassed in Python today, the isinstance technique is generally\\nrecommended. See Chapter 32 for more on subclassing built-in types in Python 2.2 \\nand later.\\n\\n306 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cFigure 9-3. Python’s major built-in object types, organized by categories. Everything is a type of object\\nin Python, even the type of an object! Some extension types, such as named tuples, might belong in\\nthis figure too, but the criteria for inclusion in the core types set are not formal.\\n\\nCore Types Review and Summary | 307\\n\\n\\x0cAlso in Chapter 32, we will explore how type(X) and type testing in\\ngeneral apply to instances of user-defined classes. In short, in Python\\n3.X and for new-style classes in Python 2.X, the type of a class instance\\nis the class from which the instance was made. For classic classes in\\nPython 2.X, all class instances are instead of the type “instance,” and\\nwe must compare instance __class__ attributes to compare their types\\nmeaningfully.  Since  we’re  not  yet  equipped  to  tackle  the  subject  of\\nclasses, we’ll postpone the rest of this story until Chapter 32.\\n\\nOther Types in Python\\nBesides the core objects studied in this part of the book, and the program-unit objects\\nsuch as functions, modules, and classes that we’ll meet later, a typical Python instal-\\nlation  has  dozens  of  additional  object  types  available  as  linked-in  C  extensions  or\\nPython classes—regular expression objects, DBM files, GUI widgets, network sockets,\\nand so on. Depending on whom you ask, the named tuple we met earlier in this chapter\\nmay fall in this category too (Decimal and Fraction of Chapter 5 tend to be more am-\\nbiguous).\\nThe main difference between these extra tools and the built-in types we’ve seen so far\\nis that the built-ins provide special language creation syntax for their objects (e.g., 4 for\\nan integer, [1,2] for a list, the open function for files, and def and lambda for functions).\\nOther tools are generally made available in standard library modules that you must first\\nimport to use, and aren’t usually considered core types. For instance, to make a regular\\nexpression object, you import re and call re.compile(). See Python’s library reference\\nfor a comprehensive guide to all the tools available to Python programs.\\n\\nBuilt-in Type Gotchas\\nThat’s the end of our look at core data types. We’ll wrap up this part of the book with\\na discussion of common problems that seem to trap new users (and the occasional\\nexpert), along with their solutions. Some of this is a review of ideas we’ve already cov-\\nered, but these issues are important enough to warn about again here.\\n\\nAssignment Creates References, Not Copies\\nBecause this is such a central concept, I’ll mention it again: shared references to mutable\\nobjects in your program can matter. For instance, in the following example, the list\\nobject assigned to the name L is referenced both from L and from inside the list assigned\\nto the name M. Changing L in place changes what M references, too:\\n\\n>>> L = [1, 2, 3]\\n>>> M = [\\'X\\', L, \\'Y\\']           # Embed a reference to L\\n>>> M\\n[\\'X\\', [1, 2, 3], \\'Y\\']\\n\\n308 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0c>>> L[1] = 0                    # Changes M too\\n>>> M\\n[\\'X\\', [1, 0, 3], \\'Y\\']\\n\\nThis effect usually becomes important only in larger programs, and shared references\\nare often exactly what you want. If objects change out from under you in unwanted\\nways, you can avoid sharing objects by copying them explicitly. For lists, you can always\\nmake a top-level copy by using an empty-limits slice, among other techniques described\\nearlier:\\n\\n>>> L = [1, 2, 3]\\n>>> M = [\\'X\\', L[:], \\'Y\\']        # Embed a copy of L (or list(L), or L.copy())\\n>>> L[1] = 0                    # Changes only L, not M\\n>>> L\\n[1, 0, 3]\\n>>> M\\n[\\'X\\', [1, 2, 3], \\'Y\\']\\n\\nRemember, slice limits default to 0 and the length of the sequence being sliced; if both\\nare omitted, the slice extracts every item in the sequence and so makes a top-level copy\\n(a new, unshared object).\\n\\nRepetition Adds One Level Deep\\nRepeating  a  sequence  is  like  adding  it  to  itself  a  number  of  times.  However,  when\\nmutable sequences are nested, the effect might not always be what you expect. For\\ninstance, in the following example X is assigned to L repeated four times, whereas Y is\\nassigned to a list containing L repeated four times:\\n\\n>>> L = [4, 5, 6]\\n>>> X = L * 4                   # Like [4, 5, 6] + [4, 5, 6] + ...\\n>>> Y = [L] * 4                 # [L] + [L] + ... = [L, L,...]\\n\\n>>> X\\n[4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6]\\n>>> Y\\n[[4, 5, 6], [4, 5, 6], [4, 5, 6], [4, 5, 6]]\\n\\nBecause L was nested in the second repetition, Y winds up embedding references back\\nto the original list assigned to L, and so is open to the same sorts of side effects noted\\nin the preceding section:\\n\\n>>> L[1] = 0                    # Impacts Y but not X\\n>>> X\\n[4, 5, 6, 4, 5, 6, 4, 5, 6, 4, 5, 6]\\n>>> Y\\n[[4, 0, 6], [4, 0, 6], [4, 0, 6], [4, 0, 6]]\\n\\nThis may seem artificial and academic—until it happens unexpectedly in your code!\\nThe same solutions to this problem apply here as in the previous section, as this is really\\njust another way to create the shared mutable object reference case—make copies when\\nyou don’t want shared references:\\n\\nBuilt-in Type Gotchas\\n\\n| 309\\n\\n\\x0c>>> L = [4, 5, 6]\\n>>> Y = [list(L)] * 4           # Embed a (shared) copy of L\\n>>> L[1] = 0\\n>>> Y\\n[[4, 5, 6], [4, 5, 6], [4, 5, 6], [4, 5, 6]]\\n\\nEven more subtly, although Y doesn’t share an object with L anymore, it still embeds\\nfour references to the same copy of it. If you must avoid that sharing too, you’ll want\\nto make sure each embedded copy is unique:\\n\\n>>> Y[0][1] = 99                # All four copies are still the same\\n>>> Y\\n[[4, 99, 6], [4, 99, 6], [4, 99, 6], [4, 99, 6]]\\n\\n>>> L = [4, 5, 6]\\n>>> Y = [list(L) for i in range(4)]\\n>>> Y\\n[[4, 5, 6], [4, 5, 6], [4, 5, 6], [4, 5, 6]]\\n>>> Y[0][1] = 99\\n>>> Y\\n[[4, 99, 6], [4, 5, 6], [4, 5, 6], [4, 5, 6]]\\n\\nIf you remember that repetition, concatenation, and slicing copy only the top level of\\ntheir operand objects, these sorts of cases make much more sense.\\n\\nBeware of Cyclic Data Structures\\nWe actually encountered this concept in a prior exercise: if a collection object contains\\na reference to itself, it’s called a cyclic object. Python prints a [...] whenever it detects\\na cycle in the object, rather than getting stuck in an infinite loop (as it once did long ago):\\n\\n>>> L = [\\'grail\\']                # Append reference to same object\\n>>> L.append(L)                  # Generates cycle in object: [...]\\n>>> L\\n[\\'grail\\', [...]]\\n\\nBesides understanding that the three dots in square brackets represent a cycle in the\\nobject, this case is worth knowing about because it can lead to gotchas—cyclic struc-\\ntures may cause code of your own to fall into unexpected loops if you don’t anticipate\\nthem.\\nFor instance, some programs that walk through structured data must keep a list, dic-\\ntionary, or set of already visited items, and check it when they’re about to step into a\\ncycle that could cause an unwanted loop. See the solutions to the “Test Your Knowl-\\nedge: Part I Exercises” on page 87 in Appendix D for more on this problem. Also watch\\nfor general discussion of recursion in Chapter 19, as well as the reloadall.py program\\nin Chapter 25 and the ListTree class in Chapter 31, for concrete examples of programs\\nwhere cycle detection can matter.\\nThe solution is knowledge: don’t use cyclic references unless you really need to, and\\nmake sure you anticipate them in programs that must care. There are good reasons to\\n\\n310 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0ccreate cycles, but unless you have code that knows how to handle them, objects that\\nreference themselves may be more surprise than asset.\\n\\nImmutable Types Can’t Be Changed in Place\\nAnd once more for completeness: you can’t change an immutable object in place. In-\\nstead, you construct a new object with slicing, concatenation, and so on, and assign it\\nback to the original reference, if needed:\\n\\nT = (1, 2, 3)\\n\\nT[2] = 4              # Error!\\n\\nT = T[:2] + (4,)      # OK: (1, 2, 4)\\n\\nThat might seem like extra coding work, but the upside is that the previous gotchas in\\nthis  section  can’t  happen  when  you’re  using  immutable  objects  such  as  tuples  and\\nstrings; because they can’t be changed in place, they are not open to the sorts of side\\neffects that lists are.\\n\\nChapter Summary\\nThis chapter explored the last two major core object types—the tuple and the file. We\\nlearned that tuples support all the usual sequence operations, have just a few methods,\\ndo not allow any in-place changes because they are immutable, and are extended by\\nthe named tuple type. We also learned that files are returned by the built-in open func-\\ntion and provide methods for reading and writing data.\\nAlong the way we explored how to translate Python objects to and from strings for\\nstoring in files, and we looked at the pickle, json, and struct modules for advanced\\nroles (object serialization and binary data). Finally, we wrapped up by reviewing some\\nproperties common to all object types (e.g., shared references) and went through a list\\nof common mistakes (“gotchas”) in the object type domain.\\nIn the next part of this book, we’ll shift gears, turning to the topic of statement syntax—\\nthe way you code processing logic in your scripts. Along the way, this next part explores\\nall of Python’s basic procedural statements. The next chapter kicks off this topic with\\nan introduction to Python’s general syntax model, which is applicable to all statement\\ntypes. Before moving on, though, take the chapter quiz, and then work through the\\nend-of-part lab exercises to review type concepts. Statements largely just create and\\nprocess objects, so make sure you’ve mastered this domain by working through all the\\nexercises before reading on.\\n\\nTest Your Knowledge: Quiz\\n1. How can you determine how large a tuple is? Why is this tool located where it is?\\n\\nTest Your Knowledge: Quiz | 311\\n\\n\\x0c2. Write an expression that changes the first item in a tuple. (4, 5, 6) should become\\n\\n(1, 5, 6) in the process.\\n\\n3. What is the default for the processing mode argument in a file open call?\\n4. What module might you use to store Python objects in a file without converting\\n\\nthem to strings yourself?\\n\\n5. How might you go about copying all parts of a nested structure at once?\\n6. When does Python consider an object true?\\n7. What is your quest?\\n\\nTest Your Knowledge: Answers\\n1. The built-in len function returns the length (number of contained items) for any\\ncontainer object in Python, including tuples. It is a built-in function instead of a\\ntype method because it applies to many different types of objects. In general, built-\\nin functions and expressions may span many object types; methods are specific to\\na single object type, though some may be available on more than one type (index,\\nfor example, works on lists and tuples).\\n\\n2. Because they are immutable, you can’t really change tuples in place, but you can\\ngenerate a new tuple with the desired value. Given T = (4, 5, 6), you can change\\nthe first item by making a new tuple from its parts by slicing and concatenating: T\\n= (1,) + T[1:]. (Recall that single-item tuples require a trailing comma.) You could\\nalso convert the tuple to a list, change it in place, and convert it back to a tuple,\\nbut this is more expensive and is rarely required in practice—simply use a list if\\nyou know that the object will require in-place changes.\\n\\n3. The default for the processing mode argument in a file open call is \\'r\\', for reading\\n\\ntext input. For input text files, simply pass in the external file’s name.\\n\\n4. The pickle module can be used to store Python objects in a file without explicitly\\nconverting them to strings. The struct module is related, but it assumes the data\\nis to be in packed binary format in the file; json similarly converts a limited set of\\nPython objects to and from strings per the JSON format.\\n\\n5. Import the copy module, and call copy.deepcopy(X) if you need to copy all parts of\\na nested structure X. This is also rarely seen in practice; references are usually the\\ndesired  behavior,  and  shallow  copies  (e.g.,  aList[:],  aDict.copy(),  set(aSet))\\nusually suffice for most copies.\\n\\n6. An object is considered true if it is either a nonzero number or a nonempty collec-\\ntion object. The built-in words True and False are essentially predefined to have\\nthe same meanings as integer 1 and 0, respectively.\\n\\n7. Acceptable answers include “To learn Python,” “To move on to the next part of\\n\\nthe book,” or “To seek the Holy Grail.”\\n\\n312 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0cTest Your Knowledge: Part II Exercises\\nThis session asks you to get your feet wet with built-in object fundamentals. As before,\\na few new ideas may pop up along the way, so be sure to flip to the answers in Appen-\\ndix D when you’re done (or even when you’re not). If you have limited time, I suggest\\nstarting with exercises 10 and 11 (the most practical of the bunch), and then working\\nfrom first to last as time allows. This is all fundamental material, so try to do as many\\nof these as you can; programming is a hands-on activity, and there is no substitute for\\npracticing what you’ve read to make ideas gel.\\n\\n1. The basics. Experiment interactively with the common type operations found in\\nthe various operation tables in this part of the book. To get started, bring up the\\nPython interactive interpreter, type each of the following expressions, and try to\\nexplain what’s happening in each case. Note that the semicolon in some of these\\nis being used as a statement separator, to squeeze multiple statements onto a single\\nline:  for  example,  X=1;X  assigns  and  then  prints  a  variable  (more  on  statement\\nsyntax in the next part of the book). Also remember that a comma between ex-\\npressions usually builds a tuple, even if there are no enclosing parentheses: X,Y,Z\\nis a three-item tuple, which Python prints back to you in parentheses.\\n\\n2 ** 16\\n2 / 5, 2 / 5.0\\n\\n\"spam\" + \"eggs\"\\nS = \"ham\"\\n\"eggs \" + S\\nS * 5\\nS[:0]\\n\"green %s and %s\" % (\"eggs\", S)\\n\\'green {0} and {1}\\'.format(\\'eggs\\', S)\\n\\n(\\'x\\',)[0]\\n(\\'x\\', \\'y\\')[1]\\n\\nL = [1,2,3] + [4,5,6]\\nL, L[:], L[:0], L[−2], L[−2:]\\n([1,2,3] + [4,5,6])[2:4]\\n[L[2], L[3]]\\nL.reverse(); L\\nL.sort(); L\\nL.index(4)\\n\\n{\\'a\\':1, \\'b\\':2}[\\'b\\']\\nD = {\\'x\\':1, \\'y\\':2, \\'z\\':3}\\nD[\\'w\\'] = 0\\nD[\\'x\\'] + D[\\'w\\']\\nD[(1,2,3)] = 4\\nlist(D.keys()), list(D.values()), (1,2,3) in D\\n\\n[[]], [\"\",[],(),{},None]\\n\\nTest Your Knowledge: Part II Exercises\\n\\n| 313\\n\\n\\x0c2. Indexing and slicing. At the interactive prompt, define a list named L that contains\\nfour strings or numbers (e.g., L=[0,1,2,3]). Then, experiment with the following\\nboundary cases. You may never see these cases in real programs (especially not in\\nthe bizarre ways they appear here!), but they are intended to make you think about\\nthe underlying model, and some may be useful in less artificial forms—slicing out\\nof bounds can help, for example, if a sequence is as long as you expect:\\n\\na. What happens when you try to index out of bounds (e.g., L[4])?\\nb. What about slicing out of bounds (e.g., L[−1000:100])?\\nc. Finally, how does Python handle it if you try to extract a sequence in reverse,\\nwith the lower bound greater than the higher bound (e.g., L[3:1])? Hint: try\\nassigning to this slice (L[3:1]=[\\'?\\']), and see where the value is put. Do you\\nthink this may be the same phenomenon you saw when slicing out of bounds?\\n3. Indexing, slicing, and del. Define another list L with four items, and assign an empty\\nlist to one of its offsets (e.g., L[2]=[]). What happens? Then, assign an empty list\\nto a slice (L[2:3]=[]). What happens now? Recall that slice assignment deletes the\\nslice and inserts the new value where it used to be.\\nThe del statement deletes offsets, keys, attributes, and names. Use it on your list\\nto delete an item (e.g., del L[0]). What happens if you delete an entire slice (del\\nL[1:])? What happens when you assign a nonsequence to a slice (L[1:2]=1)?\\n\\n4. Tuple assignment. Type the following lines:\\n\\n>>> X = \\'spam\\'\\n>>> Y = \\'eggs\\'\\n>>> X, Y = Y, X\\n\\nWhat do you think is happening to X and Y when you type this sequence?\\n\\n5. Dictionary keys. Consider the following code fragments:\\n\\n>>> D = {}\\n>>> D[1] = \\'a\\'\\n>>> D[2] = \\'b\\'\\n\\nYou’ve learned that dictionaries aren’t accessed by offsets, so what’s going on here?\\nDoes the following shed any light on the subject? (Hint: strings, integers, and tuples\\nshare which type category?)\\n\\n>>> D[(1, 2, 3)] = \\'c\\'\\n>>> D\\n{1: \\'a\\', 2: \\'b\\', (1, 2, 3): \\'c\\'}\\n\\n6. Dictionary indexing. Create a dictionary named D with three entries, for keys \\'a\\',\\n\\'b\\', and \\'c\\'. What happens if you try to index a nonexistent key (D[\\'d\\'])? What\\ndoes Python do if you try to assign to a nonexistent key \\'d\\' (e.g., D[\\'d\\']=\\'spam\\')?\\nHow  does  this  compare  to  out-of-bounds  assignments  and  references  for  lists?\\nDoes this sound like the rule for variable names?\\n\\n7. Generic operations. Run interactive tests to answer the following questions:\\n\\n314 | Chapter 9:\\u2002Tuples, Files, and Everything Else\\n\\n\\x0ca. What happens when you try to use the + operator on different/mixed types\\n\\n(e.g., string + list, list + tuple)?\\n\\nb. Does + work when one of the operands is a dictionary?\\nc. Does the append method work for both lists and strings? How about using the\\nkeys method on lists? (Hint: what does append assume about its subject object?)\\nd. Finally, what type of object do you get back when you slice or concatenate two\\n\\nlists or two strings?\\n\\n8. String indexing. Define a string S of four characters: S = \"spam\". Then type the\\nfollowing expression: S[0][0][0][0][0]. Any clue as to what’s happening this time?\\n(Hint: recall that a string is a collection of characters, but Python characters are\\none-character strings.) Does this indexing expression still work if you apply it to a\\nlist such as [\\'s\\', \\'p\\', \\'a\\', \\'m\\']? Why?\\n\\n9. Immutable types. Define a string S of four characters again: S = \"spam\". Write an\\nassignment that changes the string to \"slam\", using only slicing and concatenation.\\nCould you perform the same operation using just indexing and concatenation?\\nHow about index assignment?\\n\\n10. Nesting. Write a data structure that represents your personal information: name\\n(first, middle, last), age, job, address, email address, and phone number. You may\\nbuild the data structure with any combination of built-in object types you like (lists,\\ntuples, dictionaries, strings, numbers). Then, access the individual components of\\nyour data structures by indexing. Do some structures make more sense than others\\nfor this object?\\n\\n11. Files. Write a script that creates a new output file called myfile.txt and writes the\\nstring  \"Hello  file  world!\"  into  it.  Then  write  another  script  that  opens  my-\\nfile.txt and reads and prints its contents. Run your two scripts from the system\\ncommand line. Does the new file show up in the directory where you ran your\\nscripts? What if you add a different directory path to the filename passed to open?\\nNote: file write methods do not add newline characters to your strings; add an\\nexplicit \\\\n at the end of the string if you want to fully terminate the line in the file.\\n\\nTest Your Knowledge: Part II Exercises\\n\\n| 315\\n\\n\\x0c\\x0cPART III\\nStatements and Syntax\\n\\n\\x0c\\x0cCHAPTER 10\\nIntroducing Python Statements\\n\\nNow that you’re familiar with Python’s core built-in object types, this chapter begins\\nour exploration of its fundamental statement forms. As in the previous part, we’ll begin\\nhere with a general introduction to statement syntax, and we’ll follow up with more\\ndetails about specific statements in the next few chapters.\\nIn simple terms, statements are the things you write to tell Python what your programs\\nshould do. If, as suggested in Chapter 4, programs “do things with stuff,” then state-\\nments are the way you specify what sort of things a program does. Less informally,\\nPython is a procedural, statement-based language; by combining statements, you spec-\\nify a procedure that Python performs to satisfy a program’s goals.\\n\\nThe Python Conceptual Hierarchy Revisited\\nAnother way to understand the role of statements is to revisit the concept hierarchy\\nintroduced in Chapter 4, which talked about built-in objects and the expressions used\\nto manipulate them. This chapter climbs the hierarchy to the next level of Python \\nprogram structure:\\n\\n1. Programs are composed of modules.\\n2. Modules contain statements.\\n3. Statements contain expressions.\\n4. Expressions create and process objects.\\n\\nAt their base, programs written in the Python language are composed of statements\\nand expressions. Expressions process objects and are embedded in statements. State-\\nments code the larger logic of a program’s operation—they use and direct expressions\\nto process the objects we studied in the preceding chapters. Moreover, statements are\\nwhere objects spring into existence (e.g., in expressions within assignment statements),\\nand some statements create entirely new kinds of objects (functions, classes, and so\\non). At the top, statements always exist in modules, which themselves are managed\\nwith statements.\\n\\n319\\n\\n\\x0cPython’s Statements\\nTable 10-1 summarizes Python’s statement set. Each statement in Python has its own\\nspecific  purpose  and  its  own  specific  syntax—the  rules  that  define  its  structure—\\nthough, as we’ll see, many share common syntax patterns, and some statements’ roles\\noverlap. Table 10-1 also gives examples of each statement, when coded according to\\nits syntax rules. In your programs, these units of code can perform actions, repeat tasks,\\nmake choices, build larger program structures, and so on.\\nThis part of the book deals with entries in the table from the top through break and\\ncontinue. You’ve informally been introduced to a few of the statements in Table 10-1\\nalready; this part of the book will fill in details that were skipped earlier, introduce the\\nrest of Python’s procedural statement set, and cover the overall syntax model. State-\\nments  lower  in  Table  10-1  that  have  to  do  with  larger  program  units—functions,\\nclasses, modules, and exceptions—lead to larger programming ideas, so they will each\\nhave a section of their own. More focused statements (like del, which deletes various\\ncomponents) are covered elsewhere in the book, or in Python’s standard manuals.\\n\\nTable 10-1. Python statements\\n\\nStatement\\nAssignment\\nCalls and other expressions\\nprint calls\\nif/elif/else\\n\\nRole\\nCreating references\\nRunning functions\\nPrinting objects\\nSelecting actions\\n\\nfor/else\\n\\nwhile/else\\n\\npass\\n\\nbreak\\n\\ncontinue\\n\\ndef\\n\\nreturn\\n\\nyield\\n\\nglobal\\n\\nIteration\\n\\nGeneral loops\\n\\nEmpty placeholder\\n\\nLoop exit\\n\\nLoop continue\\n\\nFunctions and methods\\n\\nFunctions results\\n\\nGenerator functions\\n\\nNamespaces\\n\\nnonlocal\\n\\nNamespaces (3.X)\\n\\n320 | Chapter 10:\\u2002Introducing Python Statements\\n\\nExample\\na, b = \\'good\\', \\'bad\\'\\n\\nlog.write(\"spam, ham\")\\n\\nprint(\\'The Killer\\', joke)\\n\\nif \"python\" in text:\\n    print(text)\\nfor x in mylist:\\n    print(x)\\nwhile X > Y:\\n    print(\\'hello\\')\\nwhile True:\\n    pass\\nwhile True:\\n    if exittest(): break\\nwhile True:\\n    if skiptest(): continue\\ndef f(a, b, c=1, *d):\\n    print(a+b+c+d[0])\\ndef f(a, b, c=1, *d):\\n    return a+b+c+d[0]\\ndef gen(n):\\n    for i in n: yield i*2\\nx = \\'old\\'\\ndef function():\\n    global x, y; x = \\'new\\'\\ndef outer():\\n    x = \\'old\\'\\n\\n\\x0cStatement\\n\\nRole\\n\\nimport\\n\\nfrom\\n\\nclass\\n\\nModule access\\nAttribute access\\nBuilding objects\\n\\ntry/except/ finally\\n\\nCatching exceptions\\n\\nraise\\n\\nassert\\nwith/as\\n\\ndel\\n\\nTriggering exceptions\\nDebugging checks\\nContext managers (3.X, 2.6+)\\n\\nDeleting references\\n\\nExample\\n    def function():\\n        nonlocal x; x = \\'new\\'\\nimport sys\\n\\nfrom sys import stdin\\n\\nclass Subclass(Superclass):\\n    staticData = []\\n    def method(self): pass\\ntry:\\n    action()\\nexcept:\\n    print(\\'action error\\')\\nraise EndSearch(location)\\n\\nassert X > Y, \\'X too small\\'\\n\\nwith open(\\'data\\') as myfile:\\n    process(myfile)\\ndel data[k]\\ndel data[i:j]\\ndel obj.attr\\ndel variable\\n\\nTechnically, Table 10-1 reflects Python 3.X’s statements. Though sufficient as a quick\\npreview and reference, it’s not quite complete as is. Here are a few fine points about its\\ncontent:\\n\\n• Assignment  statements  come  in  a  variety  of  syntax  flavors,  described  in  Chap-\\n\\nter 11: basic, sequence, augmented, and more.\\n\\n• print is technically neither a reserved word nor a statement in 3.X, but a built-in\\nfunction  call;  because  it  will  nearly  always  be  run  as  an  expression  statement,\\nthough (and often on a line by itself), it’s generally thought of as a statement type.\\nWe’ll study print operations in Chapter 11.\\n\\n• yield is also an expression instead of a statement as of 2.5; like print, it’s typically\\nused as an expression statement and so is included in this table, but scripts occa-\\nsionally assign or otherwise use its result, as we’ll see in Chapter 20. As an expres-\\nsion, yield is also a reserved word, unlike print.\\n\\nMost of this table applies to Python 2.X, too, except where it doesn’t—if you are using\\nPython 2.X, here are a few notes for your Python, too:\\n\\n• In 2.X, nonlocal is not available; as we’ll see in Chapter 17, there are alternative\\n\\nways to achieve this statement’s writeable state-retention effect.\\n\\n• In 2.X, print is a statement instead of a built-in function call, with specific syntax\\n\\ncovered in Chapter 11.\\n\\n• In 2.X, the 3.X exec code execution built-in function is a statement, with specific\\nsyntax; since it supports enclosing parentheses, though, you can generally use its\\n3.X call form in 2.X code.\\n\\nPython’s Statements\\n\\n| 321\\n\\n\\x0c• In 2.5, the try/except and try/finally statements were merged: the two were for-\\nmerly separate statements, but we can now say both except and finally in the same\\ntry statement.\\n\\n• In 2.5, with/as is an optional extension, and it is not available unless you explicitly\\nturn it on by running the statement from __future__ import with_statement (see\\nChapter 34).\\n\\nA Tale of Two ifs\\nBefore we delve into the details of any of the concrete statements in Table 10-1, I want\\nto begin our look at Python statement syntax by showing you what you are not going\\nto type in Python code so you can compare and contrast it with other syntax models\\nyou might have seen in the past.\\nConsider the following if statement, coded in a C-like language:\\n\\nif (x > y) {\\n    x = 1;\\n    y = 2;\\n}\\n\\nThis might be a statement in C, C++, Java, JavaScript, or similar. Now, look at the\\nequivalent statement in the Python language:\\n\\nif x > y:\\n    x = 1\\n    y = 2\\n\\nThe first thing that may pop out at you is that the equivalent Python statement is less,\\nwell, cluttered—that is, there are fewer syntactic components. This is by design; as a\\nscripting language, one of Python’s goals is to make programmers’ lives easier by re-\\nquiring less typing.\\nMore specifically, when you compare the two syntax models, you’ll notice that Python\\nadds  one  new  thing  to  the  mix,  and  that  three  items  that  are  present  in  the  C-like\\nlanguage are not present in Python code.\\n\\nWhat Python Adds\\nThe one new syntax component in Python is the colon character (:). All Python com-\\npound statements—statements that have other statements nested inside them—follow\\nthe same general pattern of a header line terminated in a colon, followed by a nested\\nblock of code usually indented underneath the header line, like this:\\n\\nHeader line:\\n    Nested statement block\\n\\nThe colon is required, and omitting it is probably the most common coding mistake\\namong new Python programmers—it’s certainly one I’ve witnessed thousands of times\\n\\n322 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0cin Python training classes I’ve taught. In fact, if you are new to Python, you’ll almost\\ncertainly forget the colon character very soon. You’ll get an error message if you do,\\nand most Python-friendly editors make this mistake easy to spot. Including it eventually\\nbecomes an unconscious habit (so much so that you may start typing colons in your\\nC-like language code, too, generating many entertaining error messages from that lan-\\nguage’s compiler!).\\n\\nWhat Python Removes\\nAlthough Python requires the extra colon character, there are three things programmers\\nin C-like languages must include that you don’t generally have to in Python.\\n\\nParentheses are optional\\nThe first of these is the set of parentheses around the tests at the top of the statement:\\n\\nif (x < y)\\n\\nThe parentheses here are required by the syntax of many C-like languages. In Python,\\nthough, they are not—we simply omit the parentheses, and the statement works the\\nsame way:\\n\\nif x < y\\n\\nTechnically speaking, because every expression can be enclosed in parentheses, in-\\ncluding them will not hurt in this Python code, and they are not treated as an error if\\npresent.\\nBut don’t do that: you’ll be wearing out your keyboard needlessly, and broadcasting to\\nthe world that you’re a programmer of a C-like language still learning Python (I know,\\nbecause I was once, too). The “Python way” is to simply omit the parentheses in these\\nkinds of statements altogether.\\n\\nEnd-of-line is end of statement\\nThe second and more significant syntax component you won’t find in Python code is\\nthe semicolon. You don’t need to terminate statements with semicolons in Python the\\nway you do in C-like languages:\\n\\nx = 1;\\n\\nIn Python, the general rule is that the end of a line automatically terminates the state-\\nment that appears on that line. In other words, you can leave off the semicolons, and\\nit works the same way:\\n\\nx = 1\\n\\nThere are some ways to work around this rule, as you’ll see in a moment (for instance,\\nwrapping code in a bracketed structure allows it to span lines). But, in general, you\\n\\nA Tale of Two ifs\\n\\n| 323\\n\\n\\x0cwrite one statement per line for the vast majority of Python code, and no semicolon is\\nrequired.\\nHere, too, if you are pining for your C programming days (if such a state is possible)\\nyou can continue to use semicolons at the end of each statement—the language lets\\nyou get away with them if they are present, because the semicolon is also a separator\\nwhen statements are combined.\\nBut don’t do that either (really!). Again, doing so tells the world that you’re a program-\\nmer of a C-like language who still hasn’t quite made the switch to Python coding. The\\nPythonic style is to leave off the semicolons altogether. Judging from students in classes,\\nthis seems a tough habit for some veteran programmers to break. But you’ll get there;\\nsemicolons are useless noise in this role in Python.\\n\\nEnd of indentation is end of block\\nThe third and final syntax component that Python removes, and the one that may seem\\nthe most unusual to soon-to-be-ex-programmers of C-like languages (until they’ve used\\nit for 10 minutes and realize it’s actually a feature), is that you do not type anything\\nexplicit in your code to syntactically mark the beginning and end of a nested block of\\ncode. You don’t need to include begin/end, then/endif, or braces around the nested\\nblock, as you do in C-like languages:\\n\\nif (x > y) {\\n    x = 1;\\n    y = 2;\\n}\\n\\nInstead, in Python, we consistently indent all the statements in a given single nested\\nblock the same distance to the right, and Python uses the statements’ physical inden-\\ntation to determine where the block starts and stops:\\n\\nif x > y:\\n    x = 1\\n    y = 2\\n\\nBy indentation, I mean the blank whitespace all the way to the left of the two nested\\nstatements here. Python doesn’t care how you indent (you may use either spaces or\\ntabs), or how much you indent (you may use any number of spaces or tabs). In fact, the\\nindentation of one nested block can be totally different from that of another. The syntax\\nrule is only that for a given single nested block, all of its statements must be indented\\nthe same distance to the right. If this is not the case, you will get a syntax error, and\\nyour code will not run until you repair its indentation to be consistent.\\n\\nWhy Indentation Syntax?\\nThe indentation rule may seem unusual at first glance to programmers accustomed to\\nC-like languages, but it is a deliberate feature of Python, and it’s one of the main ways\\nthat  Python  almost  forces  programmers  to  produce  uniform,  regular,  and  readable\\n\\n324 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0ccode. It essentially means that you must line up your code vertically, in columns, ac-\\ncording to its logical structure. The net effect is to make your code more consistent and\\nreadable (unlike much of the code written in C-like languages).\\nTo put that more strongly, aligning your code according to its logical structure is a\\nmajor part of making it readable, and thus reusable and maintainable, by yourself and\\nothers. In fact, even if you never use Python after reading this book, you should get into\\nthe habit of aligning your code for readability in any block-structured language. Python\\nunderscores the issue by making this a part of its syntax, but it’s an important thing to\\ndo in any programming language, and it has a huge impact on the usefulness of your\\ncode.\\nYour experience may vary, but when I was still doing development on a full-time basis,\\nI was mostly paid to work on large old C++ programs that had been worked on by\\nmany programmers over the years. Almost invariably, each programmer had his or her\\nown style for indenting code. For example, I’d often be asked to change a while loop\\ncoded in the C++ language that began like this:\\n\\nwhile (x > 0) {\\n\\nBefore we even get into indentation, there are three or four ways that programmers can\\narrange these braces in a C-like language, and organizations often endure political bat-\\ntles and standards manuals to address the options (which seems more than a little off-\\ntopic  for  the  problem  to  be  solved  by  programming).  Be  that  as  it  may,  here’s  the\\nscenario I often encountered in C++ code. The first person who worked on the code\\nindented the loop four spaces:\\n\\nwhile (x > 0) {\\n    --------;\\n    --------;\\n\\nThat person eventually moved on to management, only to be replaced by someone who\\nliked to indent further to the right:\\n\\nwhile (x > 0) {\\n    --------;\\n    --------;\\n           --------;\\n           --------;\\n\\nThat person later moved on to other opportunities (ending that individual’s reign of\\ncoding terror...), and someone else picked up the code who liked to indent less:\\n\\nwhile (x > 0) {\\n    --------;\\n    --------;\\n           --------;\\n           --------;\\n--------;\\n--------;\\n}\\n\\nA Tale of Two ifs\\n\\n| 325\\n\\n\\x0cAnd so on. Eventually, the block is terminated by a closing brace (}), which of course\\nmakes this “block-structured code” (he says, sarcastically). No: in any block-structured\\nlanguage, Python or otherwise, if nested blocks are not indented consistently, they\\nbecome very difficult for the reader to interpret, change, or reuse, because the code no\\nlonger visually reflects its logical meaning. Readability matters, and indentation is a\\nmajor component of readability.\\nHere is another example that may have burned you in the past if you’ve done much\\nprogramming in a C-like language. Consider the following statement in C:\\n\\nif (x)\\n     if (y)\\n          statement1;\\nelse\\n     statement2;\\n\\nWhich if does the else here go with? Surprisingly, the else is paired with the nested\\nif statement (if (y)) in C, even though it looks visually as though it is associated with\\nthe outer if (x). This is a classic pitfall in the C language, and it can lead to the reader\\ncompletely misinterpreting the code and changing it incorrectly in ways that might not\\nbe uncovered until the Mars rover crashes into a giant rock!\\nThis cannot happen in Python—because indentation is significant, the way the code\\nlooks is the way it will work. Consider an equivalent Python statement:\\n\\nif x:\\n     if y:\\n          statement1\\nelse:\\n     statement2\\n\\nIn this example, the if that the else lines up with vertically is the one it is associated\\nwith logically (the outer if x). In a sense, Python is a WYSIWYG language—what you\\nsee is what you get—because the way code looks is the way it runs, regardless of who\\ncoded it.\\nIf this still isn’t enough to underscore the benefits of Python’s syntax, here’s another\\nanecdote. Early in my career, I worked at a successful company that developed systems\\nsoftware in the C language, where consistent indentation is not required. Even so, when\\nwe checked our code into source control at the end of the day, this company ran an\\nautomated script that analyzed the indentation used in the code. If the script noticed\\nthat we’d indented our code inconsistently, we received an automated email about it\\nthe next morning—and so did our managers!\\nThe point is that even when a language doesn’t require it, good programmers know\\nthat consistent use of indentation has a huge impact on code readability and quality.\\nThe fact that Python promotes this to the level of syntax is seen by most as a feature of\\nthe language.\\nAlso keep in mind that nearly every programmer-friendly text editor has built-in sup-\\nport for Python’s syntax model. In the IDLE Python GUI, for example, lines of code\\n\\n326 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0care automatically indented when you are typing a nested block; pressing the Backspace\\nkey backs up one level of indentation, and you can customize how far to the right IDLE\\nindents statements in a nested block. There is no universal standard on this: four spaces\\nor one tab per level is common, but it’s generally up to you to decide how and how\\nmuch you wish to indent (unless you work at a company that’s endured politics and\\nmanuals to standardize this too). Indent further to the right for further nested blocks,\\nand less to close the prior block.\\nAs a rule of thumb, you probably shouldn’t mix tabs and spaces in the same block in\\nPython, unless you do so consistently; use tabs or spaces in a given block, but not both\\n(in fact, Python 3.X now issues an error for inconsistent use of tabs and spaces, as we’ll\\nsee in Chapter 12). Then again, you probably shouldn’t mix tabs or spaces in inden-\\ntation in any structured language—such code can cause major readability issues if the\\nnext programmer has his or her editor set to display tabs differently than yours. C-like\\nlanguages might let coders get away with this, but they shouldn’t: the result can be a\\nmangled mess.\\nRegardless of which language you code in, you should be indenting consistently for\\nreadability. In fact, if you weren’t taught to do this earlier in your career, your teachers\\ndid you a disservice. Most programmers—especially those who must read others’ code\\n—consider it a major asset that Python elevates this to the level of syntax. Moreover,\\ngenerating tabs instead of braces is no more difficult in practice for tools that must\\noutput Python code. In general, if you do what you should be doing in a C-like language\\nanyhow, but get rid of the braces, your code will satisfy Python’s syntax rules.\\n\\nA Few Special Cases\\nAs mentioned previously, in Python’s syntax model:\\n\\n• The end of a line terminates the statement on that line (without semicolons).\\n• Nested  statements  are  blocked  and  associated  by  their  physical  indentation\\n\\n(without braces).\\n\\nThose  rules  cover  almost  all  Python  code  you’ll  write  or  see  in  practice.  However,\\nPython  also  provides  some  special-purpose  rules  that  allow  customization  of  both\\nstatements  and  nested  statement  blocks.  They’re  not  required  and  should  be  used\\nsparingly, but programmers have found them useful in practice.\\n\\nStatement rule special cases\\nAlthough statements normally appear one per line, it is possible to squeeze more than\\none statement onto a single line in Python by separating them with semicolons:\\n\\na = 1; b = 2; print(a + b)               # Three statements on one line\\n\\nThis is the only place in Python where semicolons are required: as statement separa-\\ntors. This only works, though, if the statements thus combined are not themselves\\n\\nA Tale of Two ifs\\n\\n| 327\\n\\n\\x0ccompound statements. In other words, you can chain together only simple statements,\\nlike assignments, prints, and function calls. Compound statements like if tests and\\nwhile loops must still appear on lines of their own (otherwise, you could squeeze an\\nentire program onto one line, which probably would not make you very popular among\\nyour coworkers!).\\nThe other special rule for statements is essentially the inverse: you can make a single\\nstatement span across multiple lines. To make this work, you simply have to enclose\\npart of your statement in a bracketed pair—parentheses (()), square brackets ([]), or \\ncurly braces ({}). Any code enclosed in these constructs can cross multiple lines: your\\nstatement doesn’t end until Python reaches the line containing the closing part of the\\npair. For instance, to continue a list literal:\\n\\nmylist = [1111,\\n          2222,\\n          3333]\\n\\nBecause the code is enclosed in a square brackets pair, Python simply drops down to\\nthe next line until it encounters the closing bracket. The curly braces surrounding dic-\\ntionaries (as well as set literals and dictionary and set comprehensions in 3.X and 2.7)\\nallow them to span lines this way too, and parentheses handle tuples, function calls,\\nand expressions. The indentation of the continuation lines does not matter, though\\ncommon sense dictates that the lines should be aligned somehow for readability.\\nParentheses are the catchall device—because any expression can be wrapped in them,\\nsimply inserting a left parenthesis allows you to drop down to the next line and continue\\nyour statement:\\nX = (A + B +\\n     C + D)\\n\\nThis technique works with compound statements, too, by the way. Anywhere you need\\nto code a large expression, simply wrap it in parentheses to continue it on the next line:\\n\\nif (A == 1 and\\n    B == 2 and\\n    C == 3):\\n        print(\\'spam\\' * 3)\\n\\nAn older rule also allows for continuation lines when the prior line ends in a backslash:\\n\\nX = A + B + \\\\\\n      C + D                  # An error-prone older alternative\\n\\nThis alternative technique is dated, though, and is frowned on today because it’s dif-\\nficult to notice and maintain the backslashes. It’s also fairly brittle and error-prone—\\nthere can be no spaces after the backslash, and accidentally omitting it can have unex-\\npected effects if the next line is mistaken to be a new statement (in this example, “C +\\nD” is a valid statement by itself if it’s not indented). This rule is also another throwback\\nto the C language, where it is commonly used in “#define” macros; again, when in\\nPythonland, do as Pythonistas do, not as C programmers do.\\n\\n328 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0cBlock rule special case\\nAs mentioned previously, statements in a nested block of code are normally associated\\nby being indented the same amount to the right. As one special case here, the body of\\na compound statement can instead appear on the same line as the header in Python,\\nafter the colon:\\n\\nif x > y: print(x)\\n\\nThis allows us to code single-line if statements, single-line while and for loops, and\\nso on. Here again, though, this will work only if the body of the compound statement\\nitself does not contain any compound statements. That is, only simple statements—\\nassignments, prints, function calls, and the like—are allowed after the colon. Larger\\nstatements must still appear on lines by themselves. Extra parts of compound state-\\nments (such as the else part of an if, which we’ll meet in the next section) must also\\nbe  on  separate  lines  of  their  own.  Compound  statement  bodies  can  also  consist  of\\nmultiple simple statements separated by semicolons, but this tends to be frowned upon.\\nIn general, even though it’s not always required, if you keep all your statements on\\nindividual lines and always indent your nested blocks, your code will be easier to read\\nand change in the future. Moreover, some code profiling and coverage tools may not\\nbe able to distinguish between multiple statements squeezed onto a single line or the\\nheader and body of a one-line compound statement. It is almost always to your ad-\\nvantage to keep things simple in Python. You can use the special-case exceptions to\\nwrite Python code that’s hard to read, but it takes a lot of work, and there are probably\\nbetter ways to spend your time.\\nTo see a prime and common exception to one of these rules in action, however (the use\\nof a single-line if statement to break out of a loop), and to introduce more of Python’s\\nsyntax, let’s move on to the next section and write some real code.\\n\\nA Quick Example: Interactive Loops\\nWe’ll see all these syntax rules in action when we tour Python’s specific compound\\nstatements in the next few chapters, but they work the same everywhere in the Python\\nlanguage. To get started, let’s work through a brief, realistic example that demonstrates\\nthe way that statement syntax and statement nesting come together in practice, and\\nintroduces a few statements along the way.\\n\\nA Simple Interactive Loop\\nSuppose you’re asked to write a Python program that interacts with a user in a console\\nwindow. Maybe you’re accepting inputs to send to a database, or reading numbers to\\nbe used in a calculation. Regardless of the purpose, you need to code a loop that reads\\none or more inputs from a user typing on a keyboard, and prints back a result for each.\\nIn other words, you need to write a classic read/evaluate/print loop program.\\n\\nA Quick Example: Interactive Loops\\n\\n| 329\\n\\n\\x0cIn Python, typical boilerplate code for such an interactive loop might look like this:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\': break\\n    print(reply.upper())\\n\\nThis code makes use of a few new ideas and some we’ve already seen:\\n\\n• The code leverages the Python while loop, Python’s most general looping state-\\nment. We’ll study the while statement in more detail later, but in short, it consists\\nof the word while, followed by an expression that is interpreted as a true or false\\nresult, followed by a nested block of code that is repeated while the test at the top\\nis true (the word True here is considered always true).\\n\\n• The  input built-in function we met earlier in the book is used here for general\\nconsole input—it prints its optional argument string as a prompt and returns the\\nuser’s typed reply as a string. Use raw_input in 2.X instead, per the upcoming note.\\n• A single-line if statement that makes use of the special rule for nested blocks also\\nappears here: the body of the if appears on the header line after the colon instead\\nof being indented on a new line underneath it. This would work either way, but as\\nit’s coded, we’ve saved an extra line.\\n\\n• Finally, the Python break statement is used to exit the loop immediately—it simply\\njumps out of the loop statement altogether, and the program continues after the\\nloop. Without this exit statement, the while would loop forever, as its test is always\\ntrue.\\n\\nIn effect, this combination of statements essentially means “read a line from the user\\nand print it in uppercase until the user enters the word ‘stop.’” There are other ways\\nto code such a loop, but the form used here is very common in Python code.\\nNotice that all three lines nested under the while header line are indented the same\\namount—because they line up vertically in a column this way, they are the block of\\ncode that is associated with the while test and repeated. Either the end of the source\\nfile or a lesser-indented statement will suffice to terminate the loop body block.\\nWhen this code is run, either interactively or as a script file, here is the sort of interaction\\nwe get—all of the code for this example is in interact.py in the book’s examples package:\\n\\nEnter text:spam\\nSPAM\\nEnter text:42\\n42\\nEnter text:stop\\n\\n330 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0cVersion skew note: This example is coded for Python 3.X. If you are\\nworking in Python 2.X, the code works the same, but you must use\\nraw_input instead of input in all of this chapter’s examples, and you can\\nomit the outer parentheses in print statements (though they don’t hurt).\\nIn fact, if you study the interact.py file in the examples package, you’ll\\nsee that it does this automatically—to support 2.X compatibility, it re-\\nsets input if the running Python’s major version is 2 (“input” winds up\\nrunning raw_input):\\n\\nimport sys\\nif sys.version[0] == \\'2\\': input = raw_input   # 2.X compatible\\n\\nIn 3.X, raw_input was renamed input, and print is a built-in function\\ninstead of a statement (more on prints in the next chapter). Python 2.X\\nhas an input too, but it tries to evaluate the input string as though it\\nwere  Python  code,  which  probably  won’t  work  in  this  context;\\neval(input()) can yield the same effect 3.X.\\n\\nDoing Math on User Inputs\\nOur script works, but now suppose that instead of converting a text string to uppercase,\\nwe want to do some math with numeric input—squaring it, for example, perhaps in\\nsome misguided effort of an age-input program to tease its users. We might try state-\\nments like these to achieve the desired effect:\\n\\n>>> reply = \\'20\\'\\n>>> reply ** 2\\n...error text omitted...\\nTypeError: unsupported operand type(s) for ** or pow(): \\'str\\' and \\'int\\'\\n\\nThis won’t quite work in our script, though, because (as discussed in the prior part of\\nthe book) Python won’t convert object types in expressions unless they are all numeric,\\nand input from a user is always returned to our script as a string. We cannot raise a\\nstring of digits to a power unless we convert it manually to an integer:\\n\\n>>> int(reply) ** 2\\n400\\n\\nArmed with this information, we can now recode our loop to perform the necessary\\nmath. Type the following in a file to test it:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\': break\\n    print(int(reply) ** 2)\\nprint(\\'Bye\\')\\n\\nThis script uses a single-line if statement to exit on “stop” as before, but it also converts\\ninputs to perform the required math. This version also adds an exit message at the\\nbottom. Because the print statement in the last line is not indented as much as the\\n\\nA Quick Example: Interactive Loops\\n\\n| 331\\n\\n\\x0cnested block of code, it is not considered part of the loop body and will run only once,\\nafter the loop is exited:\\n\\nEnter text:2\\n4\\nEnter text:40\\n1600\\nEnter text:stop\\nBye\\n\\nUsage note: From this point on I’ll assume that this code is stored in and\\nrun from a script file, via command line, IDLE menu option, or any of\\nthe  other  file  launching  techniques  we  met  in  Chapter  3.  Again,  it’s\\nnamed interact.py in the book’s examples. If you are entering this code\\ninteractively, though, be sure to include a blank line (i.e., press Enter\\ntwice) before the final print statement, to terminate the loop. This im-\\nplies that you also can’t cut and paste the code in its entirety into an\\ninteractive prompt: an extra blank line is required interactively, but not\\nin script files. The final print doesn’t quite make sense in interactive\\nmode, though—you’ll have to code it after interacting with the loop!\\n\\nHandling Errors by Testing Inputs\\nSo far so good, but notice what happens when the input is invalid:\\n\\nEnter text:xxx\\n...error text omitted...\\nValueError: invalid literal for int() with base 10: \\'xxx\\'\\n\\nThe built-in int function raises an exception here in the face of a mistake. If we want\\nour script to be robust, we can check the string’s content ahead of time with the string \\nobject’s isdigit method:\\n\\n>>> S = \\'123\\'\\n>>> T = \\'xxx\\'\\n>>> S.isdigit(), T.isdigit()\\n(True, False)\\n\\nThis also gives us an excuse to further nest the statements in our example. The following\\nnew version of our interactive script uses a full-blown if statement to work around the\\nexception on errors:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\':\\n        break\\n    elif not reply.isdigit():\\n        print(\\'Bad!\\' * 8)\\n    else:\\n        print(int(reply) ** 2)\\nprint(\\'Bye\\')\\n\\n332 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0cWe’ll study the if statement in more detail in Chapter 12, but it’s a fairly lightweight\\ntool for coding logic in scripts. In its full form, it consists of the word if followed by a\\ntest and an associated block of code, one or more optional elif (“else if”) tests and\\ncode blocks, and an optional else part, with an associated block of code at the bottom\\nto serve as a default. Python runs the block of code associated with the first test that is\\ntrue, working from top to bottom, or the else part if all tests are false.\\nThe if, elif, and else parts in the preceding example are associated as part of the same\\nstatement because they all line up vertically (i.e., share the same level of indentation).\\nThe if statement spans from the word if to the start of the print statement on the last\\nline of the script. In turn, the entire if block is part of the while loop because all of it\\nis indented under the loop’s header line. Statement nesting like this is natural once you\\nget the hang of it.\\nWhen we run our new script, its code catches errors before they occur and prints an\\nerror  message  before  continuing  (which  you’ll  probably  want  to  improve  in  a  later\\nrelease), but “stop” still gets us out, and valid numbers are still squared:\\n\\nEnter text:5\\n25\\nEnter text:xyz\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\nEnter text:10\\n100\\nEnter text:stop\\n\\nHandling Errors with try Statements\\nThe preceding solution works, but as you’ll see later in the book, the most general way\\nto handle errors in Python is to catch and recover from them completely using the\\nPython try statement. We’ll explore this statement in depth in Part VII of this book,\\nbut as a preview, using a try here can lead to code that some would see as simpler than\\nthe prior version:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\': break\\n    try:\\n        num = int(reply)\\n    except:\\n        print(\\'Bad!\\' * 8)\\n    else:\\n        print(num ** 2)\\nprint(\\'Bye\\')\\n\\nThis version works exactly like the previous one, but we’ve replaced the explicit error\\ncheck with code that assumes the conversion will work and wraps it in an exception\\nhandler for cases when it doesn’t. In other words, rather than detecting an error, we\\nsimply respond if one occurs.\\n\\nA Quick Example: Interactive Loops\\n\\n| 333\\n\\n\\x0cThis try statement is another compound statement, and follows the same pattern as\\nif and while. It’s composed of the word try, followed by the main block of code (the\\naction we are trying to run), followed by an except part that gives the exception handler\\ncode and an else part to be run if no exception is raised in the try part. Python first\\nruns the try part, then runs either the except part (if an exception occurs) or the else\\npart (if no exception occurs).\\nIn terms of statement nesting, because the words try, except, and else are all indented\\nto the same level, they are all considered part of the same single try statement. Notice\\nthat the else part is associated with the try here, not the if. As we’ve seen, else can\\nappear in if statements in Python, but it can also appear in try statements and loops\\n—its indentation tells you what statement it is a part of. In this case, the try statement\\nspans from the word try through the code indented under the word else, because the\\nelse is indented the same as try. The if statement in this code is a one-liner and ends\\nafter the break.\\n\\nSupporting floating-point numbers\\nAgain, we’ll come back to the try statement later in this book. For now, be aware that\\nbecause try can be used to intercept any error, it reduces the amount of error-checking\\ncode you have to write, and it’s a very general approach to dealing with unusual cases.\\nIf we’re sure that print won’t fail, for instance, this example could be even more concise:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\': break\\n    try:\\n        print(int(reply) ** 2)\\n    except:\\n        print(\\'Bad!\\' * 8)\\nprint(\\'Bye\\')\\n\\nAnd if we wanted to support input of floating-point numbers instead of just integers,\\nfor example, using try would be much easier than manual error testing—we could\\nsimply run a float call and catch its exceptions:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\': break\\n    try:\\n        print(float(reply) ** 2)\\n    except:\\n        print(\\'Bad!\\' * 8)\\nprint(\\'Bye\\')\\n\\nThere is no isfloat for strings today, so this exception-based approach spares us from\\nhaving to analyze all possible floating-point syntax in an explicit error check. When\\ncoding this way, we can enter a wider variety of numbers, but errors and exits still work\\nas before:\\n\\n334 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0cEnter text:50\\n2500.0\\nEnter text:40.5\\n1640.25\\nEnter text:1.23E-100\\n1.5129e-200\\nEnter text:spam\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\nEnter text:stop\\nBye\\n\\nPython’s eval call, which we used in Chapter 5 and Chapter 9 to convert\\ndata in strings and files, would work in place of float here too, and\\nwould allow input of arbitrary expressions (“2 ** 100” would be a legal,\\nif curious, input, especially if we’re assuming the program is processing\\nages!). This is a powerful concept that is open to the same security issues\\nmentioned in the prior chapters. If you can’t trust the source of a code\\nstring, use more restrictive conversion tools like int and float.\\n\\nPython’s exec, used in Chapter 3 to run code read from a file, is similar\\nto eval (but assumes the string is a statement instead of an expression\\nand has no result), and its compile call precompiles frequently used code\\nstrings to bytecode objects for speed. Run a help on any of these for\\nmore details; as mentioned, exec is a statement in 2.X but a function in\\n3.X, so see its manual entry in 2.X instead. We’ll also use exec to import\\nmodules by name string in Chapter 25—an example of its more dynamic\\nroles.\\n\\nNesting Code Three Levels Deep\\nLet’s look at one last mutation of our code. Nesting can take us even further if we need\\nit to—we could, for example, extend our prior integer-only script to branch to one of\\na set of alternatives based on the relative magnitude of a valid input:\\n\\nwhile True:\\n    reply = input(\\'Enter text:\\')\\n    if reply == \\'stop\\':\\n        break\\n    elif not reply.isdigit():\\n        print(\\'Bad!\\' * 8)\\n    else:\\n        num = int(reply)\\n        if num < 20:\\n            print(\\'low\\')\\n        else:\\n            print(num ** 2)\\nprint(\\'Bye\\')\\n\\nThis version adds an if statement nested in the else clause of another if statement,\\nwhich is in turn nested in the while loop. When code is conditional or repeated like\\n\\nA Quick Example: Interactive Loops\\n\\n| 335\\n\\n\\x0cthis, we simply indent it further to the right. The net effect is like that of prior versions,\\nbut we’ll now print “low” for numbers less than 20:\\n\\nEnter text:19\\nlow\\nEnter text:20\\n400\\nEnter text:spam\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\nEnter text:stop\\nBye\\n\\nChapter Summary\\nThat concludes our quick look at Python statement syntax. This chapter introduced\\nthe general rules for coding statements and blocks of code. As you’ve learned, in Python\\nwe normally code one statement per line and indent all the statements in a nested block\\nthe same amount (indentation is part of Python’s syntax). However, we also looked at\\na few exceptions to these rules, including continuation lines and single-line tests and\\nloops. Finally, we put these ideas to work in an interactive script that demonstrated a\\nhandful of statements and showed statement syntax in action.\\nIn the next chapter, we’ll start to dig deeper by going over each of Python’s basic pro-\\ncedural statements in depth. As you’ll see, though, all statements follow the same gen-\\neral rules introduced here.\\n\\nTest Your Knowledge: Quiz\\n1. What three things are required in a C-like language but omitted in Python?\\n2. How is a statement normally terminated in Python?\\n3. How are the statements in a nested block of code normally associated in Python?\\n4. How can you make a single statement span multiple lines?\\n5. How can you code a compound statement on a single line?\\n6. Is there any valid reason to type a semicolon at the end of a statement in Python?\\n7. What is a try statement for?\\n8. What is the most common coding mistake among Python beginners?\\n\\nTest Your Knowledge: Answers\\n1. C-like languages require parentheses around the tests in some statements, semi-\\n\\ncolons at the end of each statement, and braces around a nested block of code.\\n\\n2. The end of a line terminates the statement that appears on that line. Alternatively,\\nif more than one statement appears on the same line, they can be terminated with\\n\\n336 | Chapter 10:\\u2002Introducing Python Statements\\n\\n\\x0csemicolons; similarly, if a statement spans many lines, you must terminate it by\\nclosing a bracketed syntactic pair.\\n\\n3. The statements in a nested block are all indented the same number of tabs or spaces.\\n4. You can make a statement span many lines by enclosing part of it in parentheses,\\nsquare brackets, or curly braces; the statement ends when Python sees a line that\\ncontains the closing part of the pair.\\n\\n5. The body of a compound statement can be moved to the header line after the colon,\\n\\nbut only if the body consists of only noncompound statements.\\n\\n6. Only when you need to squeeze more than one statement onto a single line of code.\\nEven then, this only works if all the statements are noncompound, and it’s dis-\\ncouraged because it can lead to code that is difficult to read.\\n\\n7. The try statement is used to catch and recover from exceptions (errors) in a Python\\n\\nscript. It’s usually an alternative to manually checking for errors in your code.\\n\\n8. Forgetting to type the colon character at the end of the header line in a compound\\nstatement is the most common beginner’s mistake. If you’re new to Python and\\nhaven’t made it yet, you probably will soon!\\n\\nTest Your Knowledge: Answers\\n\\n| 337\\n\\n\\x0c\\x0cCHAPTER 11\\nAssignments, Expressions, and Prints\\n\\nNow that we’ve had a quick introduction to Python statement syntax, this chapter\\nbegins our in-depth tour of specific Python statements. We’ll begin with the basics:\\nassignment statements, expression statements, and print operations. We’ve already\\nseen all of these in action, but here we’ll fill in important details we’ve skipped so far.\\nAlthough they’re relatively simple, as you’ll see, there are optional variations for each\\nof these statement types that will come in handy once you begin writing realistic Python\\nprograms.\\n\\nAssignment Statements\\nWe’ve been using the Python assignment statement for a while to assign objects to\\nnames. In its basic form, you write the target of an assignment on the left of an equals\\nsign, and the object to be assigned on the right. The target on the left may be a name\\nor object component, and the object on the right can be an arbitrary expression that\\ncomputes an object. For the most part, assignments are straightforward, but here are\\na few properties to keep in mind:\\n\\n• Assignments create object references. As discussed in Chapter 6, Python as-\\nsignments store references to objects in names or data structure components. They\\nalways create references to objects instead of copying the objects. Because of that,\\nPython variables are more like pointers than data storage areas.\\n\\n• Names are created when first assigned. Python creates a variable name the first\\ntime you assign it a value (i.e., an object reference), so there’s no need to predeclare\\nnames  ahead  of  time.  Some  (but  not  all)  data  structure  slots  are  created  when\\nassigned, too (e.g., dictionary entries, some object attributes). Once assigned, a\\nname is replaced with the value it references whenever it appears in an expression.\\n• Names must be assigned before being referenced. It’s an error to use a name\\nto which you haven’t yet assigned a value. Python raises an exception if you try,\\nrather than returning some sort of ambiguous default value. This turns out to be\\ncrucial in Python because names are not predeclared—if Python provided default\\n\\n339\\n\\n\\x0cvalues  for  unassigned  names  used  in  your  program  instead  of  treating  them  as\\nerrors, it would be much more difficult for you to spot name typos in your code.\\n• Some operations perform assignments implicitly. In this section we’re con-\\ncerned with the = statement, but assignment occurs in many contexts in Python.\\nFor instance, we’ll see later that module imports, function and class definitions,\\nfor loop variables, and function arguments are all implicit assignments. Because\\nassignment works the same everywhere it pops up, all these contexts simply bind\\nnames to object references at runtime.\\n\\nAssignment Statement Forms\\nAlthough assignment is a general and pervasive concept in Python, we are primarily\\ninterested in assignment statements in this chapter. Table 11-1 illustrates the different\\nassignment statement forms in Python, and their syntax patterns.\\n\\nTable 11-1. Assignment statement forms\\n\\nOperation\\nspam = \\'Spam\\'\\n\\nspam, ham = \\'yum\\', \\'YUM\\'\\n\\n[spam, ham] = [\\'yum\\', \\'YUM\\']\\n\\na, b, c, d = \\'spam\\'\\n\\na, *b = \\'spam\\'\\n\\nspam = ham = \\'lunch\\'\\n\\nspams += 42\\n\\nInterpretation\\nBasic form\\nTuple assignment (positional)\\nList assignment (positional)\\nSequence assignment, generalized\\nExtended sequence unpacking (Python 3.X)\\nMultiple-target assignment\\nAugmented assignment (equivalent to spams = spams + 42)\\n\\nThe first form in Table 11-1 is by far the most common: binding a name (or data struc-\\nture component) to a single object. In fact, you could get all your work done with this\\nbasic form alone. The other table entries represent special forms that are all optional,\\nbut that programmers often find convenient in practice:\\n\\nTuple- and list-unpacking assignments\\n\\nThe second and third forms in the table are related. When you code a tuple or list\\non the left side of the =, Python pairs objects on the right side with targets on the\\nleft by position and assigns them from left to right. For example, in the second line\\nof Table 11-1, the name spam is assigned the string \\'yum\\', and the name ham is bound\\nto the string \\'YUM\\'. In this case Python internally may make a tuple of the items on\\nthe right, which is why this is called tuple-unpacking assignment.\\n\\nSequence assignments\\n\\nIn later versions of Python, tuple and list assignments were generalized into in-\\nstances of what we now call sequence assignment—any sequence of names can be\\nassigned to any sequence of values, and Python assigns the items one at a time by\\nposition. We can even mix and match the types of the sequences involved. The\\n\\n340 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cfourth  line  in  Table  11-1,  for  example,  pairs  a  tuple  of  names  with  a  string  of\\ncharacters: a is assigned \\'s\\', b is assigned \\'p\\', and so on.\\n\\nExtended sequence unpacking\\n\\nIn Python 3.X (only), a new form of sequence assignment allows us to be more\\nflexible in how we select portions of a sequence to assign. The fifth line in Ta-\\nble 11-1, for example, matches a with the first character in the string on the right\\nand b with the rest: a is assigned \\'s\\', and b is assigned \\'pam\\'. This provides a simpler\\nalternative to assigning the results of manual slicing operations.\\n\\nMultiple-target assignments\\n\\nThe sixth line in Table 11-1 shows the multiple-target form of assignment. In this\\nform, Python assigns a reference to the same object (the object farthest to the right)\\nto all the targets on the left. In the table, the names spam and ham are both assigned\\nreferences to the same string object, \\'lunch\\'. The effect is the same as if we had\\ncoded ham = \\'lunch\\' followed by spam = ham, as ham evaluates to the original string\\nobject (i.e., not a separate copy of that object).\\n\\nAugmented assignments\\n\\nThe last line in Table 11-1 is an example of augmented assignment—a shorthand\\nthat combines an expression and an assignment in a concise way. Saying spam +=\\n42, for example, has the same effect as spam = spam + 42, but the augmented form\\nrequires less typing and is generally quicker to run. In addition, if the subject is\\nmutable  and  supports  the  operation,  an  augmented  assignment  may  run  even\\nquicker by choosing an in-place update operation instead of an object copy. There\\nis one augmented assignment statement for every binary expression operator in \\nPython.\\n\\nSequence Assignments\\nWe’ve already used and explored basic assignments in this book, so we’ll take them as\\na given. Here are a few simple examples of sequence-unpacking assignments in action:\\n\\n% python\\n>>> nudge = 1                      # Basic assignment\\n>>> wink  = 2\\n>>> A, B = nudge, wink             # Tuple assignment\\n>>> A, B                           # Like A = nudge; B = wink\\n(1, 2)\\n>>> [C, D] = [nudge, wink]         # List assignment\\n>>> C, D\\n(1, 2)\\n\\nNotice that we really are coding two tuples in the third line in this interaction—we’ve\\njust omitted their enclosing parentheses. Python pairs the values in the tuple on the\\nright side of the assignment operator with the variables in the tuple on the left side and\\nassigns the values one at a time.\\n\\nAssignment Statements\\n\\n| 341\\n\\n\\x0cTuple assignment leads to a common coding trick in Python that was introduced in a\\nsolution to the exercises at the end of Part II. Because Python creates a temporary tuple\\nthat saves the original values of the variables on the right while the statement runs,\\nunpacking assignments are also a way to swap two variables’ values without creating\\na temporary variable of your own—the tuple on the right remembers the prior values\\nof the variables automatically:\\n\\n>>> nudge = 1\\n>>> wink  = 2\\n>>> nudge, wink = wink, nudge      # Tuples: swaps values\\n>>> nudge, wink                    # Like T = nudge; nudge = wink; wink = T\\n(2, 1)\\n\\nIn fact, the original tuple and list assignment forms in Python have been generalized to\\naccept any type of sequence (really, iterable) on the right as long as it is of the same\\nlength as the sequence on the left. You can assign a tuple of values to a list of variables,\\na string of characters to a tuple of variables, and so on. In all cases, Python assigns items\\nin the sequence on the right to variables in the sequence on the left by position, from\\nleft to right:\\n\\n>>> [a, b, c] = (1, 2, 3)          # Assign tuple of values to list of names\\n>>> a, c\\n(1, 3)\\n>>> (a, b, c) = \"ABC\"              # Assign string of characters to tuple\\n>>> a, c\\n(\\'A\\', \\'C\\')\\n\\nTechnically speaking, sequence assignment actually supports any iterable object on the\\nright, not just any sequence. This is a more general category that includes collections\\nboth physical (e.g., lists) and virtual (e.g., a file’s lines), which was defined briefly in\\nChapter 4 and has popped up in passing ever since. We’ll firm up this term when we\\nexplore iterables in Chapter 14 and Chapter 20.\\n\\nAdvanced sequence assignment patterns\\nAlthough we can mix and match sequence types around the = symbol, we must generally\\nhave the same number of items on the right as we have variables on the left, or we’ll get\\nan error. Python 3.X allows us to be more general with extended unpacking * syntax,\\ndescribed in the next section. But normally in 3.X—and always in 2.X—the number of\\nitems in the assignment target and subject must match:\\n\\n>>> string = \\'SPAM\\'\\n>>> a, b, c, d = string                            # Same number on both sides\\n>>> a, d\\n(\\'S\\', \\'M\\')\\n\\n>>> a, b, c = string                               # Error if not\\n...error text omitted...\\nValueError: too many values to unpack (expected 3)\\n\\n342 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cTo be more flexible, we can slice in both 2.X and 3.X. There are a variety of ways to\\nemploy slicing to make this last case work:\\n\\n>>> a, b, c = string[0], string[1], string[2:]     # Index and slice\\n>>> a, b, c\\n(\\'S\\', \\'P\\', \\'AM\\')\\n\\n>>> a, b, c = list(string[:2]) + [string[2:]]      # Slice and concatenate\\n>>> a, b, c\\n(\\'S\\', \\'P\\', \\'AM\\')\\n\\n>>> a, b = string[:2]                              # Same, but simpler\\n>>> c = string[2:]\\n>>> a, b, c\\n(\\'S\\', \\'P\\', \\'AM\\')\\n\\n>>> (a, b), c = string[:2], string[2:]             # Nested sequences\\n>>> a, b, c\\n(\\'S\\', \\'P\\', \\'AM\\')\\n\\nAs the last example in this interaction demonstrates, we can even assign nested se-\\nquences, and Python unpacks their parts according to their shape, as expected. In this\\ncase, we are assigning a tuple of two items, where the first item is a nested sequence (a\\nstring), exactly as though we had coded it this way:\\n\\n>>> ((a, b), c) = (\\'SP\\', \\'AM\\')                     # Paired by shape and position\\n>>> a, b, c\\n(\\'S\\', \\'P\\', \\'AM\\')\\n\\nPython pairs the first string on the right (\\'SP\\') with the first tuple on the left ((a, b))\\nand assigns one character at a time, before assigning the entire second string (\\'AM\\') to\\nthe variable c all at once. In this event, the sequence-nesting shape of the object on the\\nleft must match that of the object on the right. Nested sequence assignment like this is\\nsomewhat rare to see, but it can be convenient for picking out the parts of data struc-\\ntures with known shapes.\\nFor example, we’ll see in Chapter 13 that this technique also works in for loops, because\\nloop items are assigned to the target given in the loop header:\\n\\nfor (a, b, c) in [(1, 2, 3), (4, 5, 6)]: ...          # Simple tuple assignment\\n\\nfor ((a, b), c) in [((1, 2), 3), ((4, 5), 6)]: ...    # Nested tuple assignment\\n\\nIn a note in Chapter 18, we’ll also see that this nested tuple (really, sequence) unpacking\\nassignment form works for function argument lists in Python 2.X (though not in 3.X),\\nbecause function arguments are passed by assignment as well:\\n\\ndef f(((a, b), c)): ...          # For arguments too in Python 2.X, but not 3.X\\nf(((1, 2), 3))\\n\\nSequence-unpacking assignments also give rise to another common coding idiom in\\nPython—assigning an integer series to a set of variables:\\n\\nAssignment Statements\\n\\n| 343\\n\\n\\x0c>>> red, green, blue = range(3)\\n>>> red, blue\\n(0, 2)\\n\\nThis initializes the three names to the integer codes 0, 1, and 2, respectively (it’s Python’s\\nequivalent of the enumerated data types you may have seen in other languages). To\\nmake sense of this, you need to know that the range built-in function generates a list\\nof successive integers (in 3.X only, it requires a list around it if you wish to display its\\nvalues all at once like this):\\n\\n>>> list(range(3))                       # list() required in Python 3.X only\\n[0, 1, 2]\\n\\nThis call was previewed briefly in Chapter 4; because range is commonly used in for\\nloops, we’ll say more about it in Chapter 13.\\nAnother place you may see a tuple assignment at work is for splitting a sequence into\\nits front and the rest in loops like this:\\n\\n>>> L = [1, 2, 3, 4]\\n>>> while L:\\n...     front, L = L[0], L[1:]           # See next section for 3.X * alternative\\n...     print(front, L)\\n...\\n1 [2, 3, 4]\\n2 [3, 4]\\n3 [4]\\n4 []\\n\\nThe tuple assignment in the loop here could be coded as the following two lines instead,\\nbut it’s often more convenient to string them together:\\n\\n...     front = L[0]\\n...     L = L[1:]\\n\\nNotice that this code is using the list as a sort of stack data structure, which can often\\nalso  be  achieved  with  the  append  and  pop  methods  of  list  objects;  here,  front  =\\nL.pop(0) would have much the same effect as the tuple assignment statement, but it\\nwould be an in-place change. We’ll learn more about while loops, and other (often\\nbetter) ways to step through a sequence with for loops, in Chapter 13.\\n\\nExtended Sequence Unpacking in Python 3.X\\nThe prior section demonstrated how to use manual slicing to make sequence assign-\\nments more general. In Python 3.X (but not 2.X), sequence assignment has been gen-\\neralized to make this easier. In short, a single  starred name,  *X, can be used in the\\nassignment target in order to specify a more general matching against the sequence—\\nthe starred name is assigned a list, which collects all items in the sequence not assigned\\nto other names. This is especially handy for common coding patterns such as splitting\\na sequence into its “front” and “rest,” as in the preceding section’s last example.\\n\\n344 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cExtended unpacking in action\\nLet’s look at an example. As we’ve seen, sequence assignments normally require exactly\\nas many names in the target on the left as there are items in the subject on the right.\\nWe get an error if the lengths disagree in both 2.X and 3.X (unless we manually sliced\\non the right, as shown in the prior section):\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> seq = [1, 2, 3, 4]\\n\\n>>> a, b, c, d = seq\\n>>> print(a, b, c, d)\\n1 2 3 4\\n\\n>>> a, b = seq\\nValueError: too many values to unpack (expected 2)\\n\\nIn Python 3.X, though, we can use a single starred name in the target to match more\\ngenerally. In the following continuation of our interactive session, a matches the first\\nitem in the sequence, and b matches the rest:\\n\\n>>> a, *b = seq\\n>>> a\\n1\\n>>> b\\n[2, 3, 4]\\n\\nWhen a starred name is used, the number of items in the target on the left need not\\nmatch the length of the subject sequence. In fact, the starred name can appear anywhere\\nin the target. For instance, in the next interaction b matches the last item in the se-\\nquence, and a matches everything before the last:\\n\\n>>> *a, b = seq\\n>>> a\\n[1, 2, 3]\\n>>> b\\n4\\n\\nWhen the starred name appears in the middle, it collects everything between the other\\nnames listed. Thus, in the following interaction a and c are assigned the first and last\\nitems, and b gets everything in between them:\\n\\n>>> a, *b, c = seq\\n>>> a\\n1\\n>>> b\\n[2, 3]\\n>>> c\\n4\\n\\nMore generally, wherever the starred name shows up, it will be assigned a list that\\ncollects every unassigned name at that position:\\n\\n>>> a, b, *c = seq\\n>>> a\\n\\nAssignment Statements\\n\\n| 345\\n\\n\\x0c1\\n>>> b\\n2\\n>>> c\\n[3, 4]\\n\\nNaturally,  like  normal  sequence  assignment,  extended  sequence  unpacking  syntax\\nworks for any sequence types (really, again, any iterable), not just lists. Here it is un-\\npacking characters in a string and a range (an iterable in 3.X):\\n\\n>>> a, *b = \\'spam\\'\\n>>> a, b\\n(\\'s\\', [\\'p\\', \\'a\\', \\'m\\'])\\n\\n>>> a, *b, c = \\'spam\\'\\n>>> a, b, c\\n(\\'s\\', [\\'p\\', \\'a\\'], \\'m\\')\\n\\n>>> a, *b, c = range(4)\\n>>> a, b, c\\n(0, [1, 2], 3)\\n\\nThis is similar in spirit to slicing, but not exactly the same—a sequence unpacking\\nassignment always returns a list for multiple matched items, whereas slicing returns a\\nsequence of the same type as the object sliced:\\n\\n>>> S = \\'spam\\'\\n\\n>>> S[0], S[1:]    # Slices are type-specific, * assignment always returns a list\\n(\\'s\\', \\'pam\\')\\n\\n>>> S[0], S[1:3], S[3]\\n(\\'s\\', \\'pa\\', \\'m\\')\\n\\nGiven this extension in 3.X, as long as we’re processing a list the last example of the\\nprior section becomes even simpler, since we don’t have to manually slice to get the\\nfirst and rest of the items:\\n\\n>>> L = [1, 2, 3, 4]\\n>>> while L:\\n...     front, *L = L                    # Get first, rest without slicing\\n...     print(front, L)\\n...\\n1 [2, 3, 4]\\n2 [3, 4]\\n3 [4]\\n4 []\\n\\nBoundary cases\\nAlthough extended sequence unpacking is flexible, some boundary cases are worth\\nnoting. First, the starred name may match just a single item, but is always assigned a list:\\n\\n>>> seq = [1, 2, 3, 4]\\n\\n346 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0c>>> a, b, c, *d = seq\\n>>> print(a, b, c, d)\\n1 2 3 [4]\\n\\nSecond, if there is nothing left to match the starred name, it is assigned an empty list,\\nregardless of where it appears. In the following, a, b, c, and d have matched every item\\nin the sequence, but Python assigns e an empty list instead of treating this as an error\\ncase:\\n\\n>>> a, b, c, d, *e = seq\\n>>> print(a, b, c, d, e)\\n1 2 3 4 []\\n\\n>>> a, b, *e, c, d = seq\\n>>> print(a, b, c, d, e)\\n1 2 3 4 []\\n\\nFinally, errors can still be triggered if there is more than one starred name, if there are\\ntoo few values and no star (as before), and if the starred name is not itself coded inside\\na sequence:\\n\\n>>> a, *b, c, *d = seq\\nSyntaxError: two starred expressions in assignment\\n\\n>>> a, b = seq\\nValueError: too many values to unpack (expected 2)\\n\\n>>> *a = seq\\nSyntaxError: starred assignment target must be in a list or tuple\\n\\n>>> *a, = seq\\n>>> a\\n[1, 2, 3, 4]\\n\\nA useful convenience\\nKeep in mind that extended sequence unpacking assignment is just a convenience. We\\ncan usually achieve the same effects with explicit indexing and slicing (and in fact must\\nin Python 2.X), but extended unpacking is simpler to code. The common “first, rest”\\nsplitting coding pattern, for example, can be coded either way, but slicing involves extra\\nwork:\\n\\n>>> seq\\n[1, 2, 3, 4]\\n\\n>>> a, *b = seq                        # First, rest\\n>>> a, b\\n(1, [2, 3, 4])\\n\\n>>> a, b = seq[0], seq[1:]             # First, rest: traditional\\n>>> a, b\\n(1, [2, 3, 4])\\n\\nAssignment Statements\\n\\n| 347\\n\\n\\x0cThe also-common “rest, last” splitting pattern can similarly be coded either way, but\\nthe new extended unpacking syntax requires noticeably fewer keystrokes:\\n\\n>>> *a, b = seq                        # Rest, last\\n>>> a, b\\n([1, 2, 3], 4)\\n\\n>>> a, b = seq[:-1], seq[-1]           # Rest, last: traditional\\n>>> a, b\\n([1, 2, 3], 4)\\n\\nBecause it is not only simpler but, arguably, more natural, extended sequence unpack-\\ning syntax will likely become widespread in Python code over time.\\n\\nApplication to for loops\\nBecause the loop variable in the for loop statement can be any assignment target, ex-\\ntended sequence assignment works here too. We met the for loop iteration tool briefly\\nin Chapter 4 and will study it formally in Chapter 13. In Python 3.X, extended assign-\\nments may show up after the word for, where a simple variable name is more commonly\\nused:\\n\\nfor (a, *b, c) in [(1, 2, 3, 4), (5, 6, 7, 8)]:\\n    ...\\n\\nWhen used in this context, on each iteration Python simply assigns the next tuple of\\nvalues to the tuple of names. On the first loop, for example, it’s as if we’d run the\\nfollowing assignment statement:\\n\\na, *b, c = (1, 2, 3, 4)                            # b gets [2, 3]\\n\\nThe names a, b, and c can be used within the loop’s code to reference the extracted\\ncomponents. In fact, this is really not a special case at all, but just an instance of general\\nassignment at work. As we saw earlier in this chapter, we can do the same thing with\\nsimple tuple assignment in both Python 2.X and 3.X:\\n\\nfor (a, b, c) in [(1, 2, 3), (4, 5, 6)]:           # a, b, c = (1, 2, 3), ...\\n\\nAnd we can always emulate 3.X’s extended assignment behavior in 2.X by manually\\nslicing:\\n\\nfor all in [(1, 2, 3, 4), (5, 6, 7, 8)]:\\n    a, b, c = all[0], all[1:3], all[3]\\n\\nSince we haven’t learned enough to get more detailed about the syntax of for loops,\\nwe’ll return to this topic in Chapter 13.\\n\\nMultiple-Target Assignments\\nA multiple-target assignment simply assigns all the given names to the object all the\\nway to the right. The following, for example, assigns the three variables a, b, and c to\\nthe string \\'spam\\':\\n\\n348 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0c>>> a = b = c = \\'spam\\'\\n>>> a, b, c\\n(\\'spam\\', \\'spam\\', \\'spam\\')\\n\\nThis form is equivalent to (but easier to code than) these three assignments:\\n\\n>>> c = \\'spam\\'\\n>>> b = c\\n>>> a = b\\n\\nMultiple-target assignment and shared references\\nKeep in mind that there is just one object here, shared by all three variables (they all\\nwind up pointing to the same object in memory). This behavior is fine for immutable\\ntypes—for example, when initializing a set of counters to zero (recall that variables\\nmust be assigned before they can be used in Python, so you must initialize counters to\\nzero before you can start adding to them):\\n\\n>>> a = b = 0\\n>>> b = b + 1\\n>>> a, b\\n(0, 1)\\n\\nHere, changing b only changes b because numbers do not support in-place changes. As\\nlong as the object assigned is immutable, it’s irrelevant if more than one name references\\nit.\\nAs usual, though, we have to be more cautious when initializing variables to an empty\\nmutable object such as a list or dictionary:\\n\\n>>> a = b = []\\n>>> b.append(42)\\n>>> a, b\\n([42], [42])\\n\\nThis time, because a and b reference the same object, appending to it in place through\\nb will impact what we see through a as well. This is really just another example of the\\nshared reference phenomenon we first met in Chapter 6. To avoid the issue, initialize\\nmutable objects in separate statements instead, so that each creates a distinct empty\\nobject by running a distinct literal expression:\\n\\n>>> a = []\\n>>> b = []                 # a and b do not share the same object\\n>>> b.append(42)\\n>>> a, b\\n([], [42])\\n\\nA tuple assignment like the following has the same effect—by running two list expres-\\nsions, it creates two distinct objects:\\n\\n>>> a, b = [], []          # a and b do not share the same object\\n\\nAssignment Statements\\n\\n| 349\\n\\n\\x0cAugmented Assignments\\nBeginning with Python 2.0, the set of additional assignment statement formats listed\\nin Table 11-2 became available. Known as augmented assignments, and borrowed from\\nthe C language, these formats are mostly just shorthand. They imply the combination\\nof a binary expression and an assignment. For instance, the following two formats are\\nroughly equivalent:\\n\\nX = X + Y                       # Traditional form\\nX += Y                          # Newer augmented form\\n\\nTable 11-2. Augmented assignment statements\\n\\nX += Y\\n\\nX &= Y\\n\\nX *= Y\\n\\nX ^= Y\\n\\nX −= Y\\n\\nX /= Y\\n\\nX |= Y\\n\\nX >>= Y\\n\\nX %= Y\\n\\nX <<= Y\\n\\nX **= Y\\n\\nX //= Y\\n\\nAugmented assignment works on any type that supports the implied binary expression.\\nFor example, here are two ways to add 1 to a name:\\n\\n>>> x = 1\\n>>> x = x + 1                   # Traditional\\n>>> x\\n2\\n>>> x += 1                      # Augmented\\n>>> x\\n3\\n\\nWhen applied to a sequence such as a string, the augmented form performs concate-\\nnation instead. Thus, the second line here is equivalent to typing the longer S = S +\\n\"SPAM\":\\n\\n>>> S = \"spam\"\\n>>> S += \"SPAM\"                 # Implied concatenation\\n>>> S\\n\\'spamSPAM\\'\\n\\nAs shown in Table 11-2, there are analogous augmented assignment forms for every\\nPython binary expression operator (i.e., each operator with values on the left and right\\nside). For instance, X *= Y multiplies and assigns, X >>= Y shifts right and assigns, and\\nso on. X //= Y (for floor division) was added in version 2.2.\\nAugmented assignments have three advantages:1\\n\\n• There’s less for you to type. Need I say more?\\n• The left side has to be evaluated only once. In X += Y, X may be a complicated object\\nexpression. In the augmented form, its code must be run only once. However, in\\n\\n1. C/C++ programmers take note: although Python now supports statements like X += Y, it still does not\\nhave C’s auto-increment/decrement operators (e.g., X++, −−X). These don’t quite map to the Python object\\nmodel because Python has no notion of in-place changes to immutable objects like numbers.\\n\\n350 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cthe long form, X = X + Y, X appears twice and must be run twice. Because of this,\\naugmented assignments usually run faster.\\n\\n• The optimal technique is automatically chosen. That is, for objects that support\\nin-place changes, the augmented forms automatically perform in-place change op-\\nerations instead of slower copies.\\n\\nThe last point here requires a bit more explanation. For augmented assignments, in-\\nplace operations may be applied for mutable objects as an optimization. Recall that\\nlists can be extended in a variety of ways. To add a single item to the end of a list, we\\ncan concatenate or call append:\\n\\n>>> L = [1, 2]\\n>>> L = L + [3]                 # Concatenate: slower\\n>>> L\\n[1, 2, 3]\\n>>> L.append(4)                 # Faster, but in place\\n>>> L\\n[1, 2, 3, 4]\\n\\nAnd to add a set of items to the end, we can either concatenate again or call the list\\nextend method:2\\n\\n>>> L = L + [5, 6]              # Concatenate: slower\\n>>> L\\n[1, 2, 3, 4, 5, 6]\\n>>> L.extend([7, 8])            # Faster, but in place\\n>>> L\\n[1, 2, 3, 4, 5, 6, 7, 8]\\n\\nIn both cases, concatenation is less prone to the side effects of shared object references\\nbut will generally run slower than the in-place equivalent. Concatenation operations\\nmust create a new object, copy in the list on the left, and then copy in the list on the\\nright. By contrast, in-place method calls simply add items at the end of a memory block\\n(it can be a bit more complicated than that internally, but this description suffices).\\nWhen we use augmented assignment to extend a list, we can largely forget these details\\n—Python automatically calls the quicker extend method instead of using the slower\\nconcatenation operation implied by +:\\n\\n>>> L += [9, 10]                # Mapped to L.extend([9, 10])\\n>>> L\\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\\n\\nNote however, that because of this equivalence += for a list is not exactly the same as a\\n+ and = in all cases—for lists += allows arbitrary sequences (just like extend), but con-\\ncatenation normally does not:\\n\\n>>> L = []\\n>>> L += \\'spam\\'                 # += and extend allow any sequence, but + does not!\\n\\n2. As suggested in Chapter 6, we can also use slice assignment (e.g., L[len(L):] = [11,12,13]), but this\\n\\nworks roughly the same as the simpler and more mnemonic list extend method.\\n\\nAssignment Statements\\n\\n| 351\\n\\n\\x0c>>> L\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\']\\n>>> L = L + \\'spam\\'\\nTypeError: can only concatenate list (not \"str\") to list\\n\\nAugmented assignment and shared references\\nThis behavior is usually what we want, but notice that it implies that the += is an in-\\nplace change for lists; thus, it is not exactly like + concatenation, which always makes\\na new object. As for all shared reference cases, this difference might matter if other\\nnames reference the object being changed:\\n\\n>>> L = [1, 2]\\n>>> M = L                       # L and M reference the same object\\n>>> L = L + [3, 4]              # Concatenation makes a new object\\n>>> L, M                        # Changes L but not M\\n([1, 2, 3, 4], [1, 2])\\n\\n>>> L = [1, 2]\\n>>> M = L\\n>>> L += [3, 4]                 # But += really means extend\\n>>> L, M                        # M sees the in-place change too!\\n([1, 2, 3, 4], [1, 2, 3, 4])\\n\\nThis only matters for mutables like lists and dictionaries, and it is a fairly obscure case\\n(at least, until it impacts your code!). As always, make copies of your mutable objects\\nif you need to break the shared reference structure.\\n\\nVariable Name Rules\\nNow that we’ve explored assignment statements, it’s time to get more formal about the\\nuse of variable names. In Python, names come into existence when you assign values\\nto them, but there are a few rules to follow when choosing names for the subjects of\\nyour programs:\\n\\nSyntax: (underscore or letter) + (any number of letters, digits, or underscores)\\n\\nVariable names must start with an underscore or letter, which can be followed by\\nany  number  of  letters,  digits,  or  underscores.  _spam,  spam,  and  Spam_1  are  legal\\nnames, but 1_Spam, spam$, and @#! are not.\\n\\nCase matters: SPAM is not the same as spam\\n\\nPython always pays attention to case in programs, both in names you create and\\nin reserved words. For instance, the names X and x refer to two different variables.\\nFor portability, case also matters in the names of imported module files, even on\\nplatforms where the filesystems are case-insensitive. That way, your imports still\\nwork after programs are copied to differing platforms.\\n\\nReserved words are off-limits\\n\\nNames you define cannot be the same as words that mean special things in the\\nPython language. For instance, if you try to use a variable name like class, Python\\n\\n352 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cwill raise a syntax error, but klass and Class work fine. Table 11-3 lists the words\\nthat are currently reserved (and hence off-limits for names of your own) in Python.\\n\\nTable 11-3. Python 3.X reserved words\\n\\nFalse\\n\\nclass\\n\\nfinally\\n\\nis\\n\\nreturn\\n\\ncontinue\\n\\nfor\\n\\nlambda\\n\\ntry\\n\\nnonlocal\\n\\nwhile\\n\\nnot\\n\\nor\\n\\npass\\n\\nraise\\n\\nwith\\n\\nyield\\n \\n \\n\\nNone\\n\\nTrue\\n\\nand\\n\\nas\\n\\nassert\\n\\ndef\\n\\ndel\\n\\nelif\\n\\nelse\\n\\nfrom\\n\\nglobal\\n\\nif\\n\\nimport\\n\\nbreak\\n\\nexcept\\n\\nin\\n\\nTable 11-3 is specific to Python 3.X. In Python 2.X, the set of reserved words differs\\nslightly:\\n\\n• print is a reserved word, because printing is a statement, not a built-in function\\n\\n(more on this later in this chapter).\\n\\n• exec is a reserved word, because it is a statement, not a built-in function.\\n• nonlocal is not a reserved word because this statement is not available.\\n\\nIn older Pythons the story is also more or less the same, with a few variations:\\n\\n• with and as were not reserved until 2.6, when context managers were officially\\n\\nenabled.\\n\\n• yield was not reserved until Python 2.3, when generator functions came online.\\n• yield morphed from statement to expression in 2.5, but it’s still a reserved word,\\n\\nnot a built-in function.\\n\\nAs you can see, most of Python’s reserved words are all lowercase. They are also all\\ntruly reserved—unlike names in the built-in scope that you will meet in the next part\\nof this book, you cannot redefine reserved words by assignment (e.g., and = 1 results\\nin a syntax error).3\\nBesides  being  of  mixed  case,  the  first  three  entries  in  Table  11-3,  True,  False,  and\\nNone,  are  somewhat  unusual  in  meaning—they  also  appear  in  the  built-in  scope  of\\nPython described in Chapter 17, and they are technically names assigned to objects. In\\n3.X they are truly reserved in all other senses, though, and cannot be used for any other\\npurpose in your script other than that of the objects they represent. All the other re-\\nserved words are hardwired into Python’s syntax and can appear only in the specific\\ncontexts for which they are intended.\\n\\n3. In standard CPython, at least. Alternative implementations of Python might allow user-defined variable\\nnames  to  be  the  same  as  Python  reserved  words.  See  Chapter  2  for  an  overview  of  alternative\\nimplementations, such as Jython.\\n\\nAssignment Statements\\n\\n| 353\\n\\n\\x0cFurthermore, because module names in import statements become variables in your\\nscripts, variable name constraints extend to your module filenames too. For instance,\\nyou can code files called and.py and my-code.py and run them as top-level scripts, but\\nyou cannot import them: their names without the “.py” extension become variables in\\nyour code and so must follow all the variable rules just outlined. Reserved words are\\noff-limits, and dashes won’t work, though underscores will. We’ll revisit this module\\nidea in Part V of this book.\\n\\nPython’s Deprecation Protocol\\n\\nIt is interesting to note how reserved word changes are gradually phased into the lan-\\nguage. When a new feature might break existing code, Python normally makes it an\\noption and begins issuing “deprecation” warnings one or more releases before the fea-\\nture is officially enabled. The idea is that you should have ample time to notice the\\nwarnings and update your code before migrating to the new release. This is not true\\nfor major new releases like 3.0 (which breaks existing code freely), but it is generally\\ntrue in other cases.\\nFor example, yield was an optional extension in Python 2.2, but is a standard keyword\\nas of 2.3. It is used in conjunction with generator functions. This was one of a small\\nhandful of instances where Python broke with backward compatibility. Still, yield was\\nphased in over time: it began generating deprecation warnings in 2.2 and was not en-\\nabled until 2.3.\\nSimilarly, in Python 2.6, the words with and as become new reserved words for use in\\ncontext managers (a newer form of exception handling). These two words are not re-\\nserved  in  2.5,  unless  the  context  manager  feature  is  turned  on  manually  with  a\\nfrom__future__import (discussed later in this book). When used in 2.5, with and as\\ngenerate  warnings  about  the  upcoming  change—except  in  the  version  of  IDLE  in\\nPython 2.5, which appears to have enabled this feature for you (that is, using these\\nwords as variable names does generate errors in 2.5, but only in its version of the IDLE\\nGUI).\\n\\nNaming conventions\\nBesides these rules, there is also a set of naming conventions—rules that are not required\\nbut are followed in normal practice. For instance, because names with two leading and\\ntrailing underscores (e.g., __name__) generally have special meaning to the Python in-\\nterpreter, you should avoid this pattern for your own names. Here is a list of the con-\\nventions Python follows:\\n\\n• Names that begin with a single underscore (_X) are not imported by a from module\\n\\nimport * statement (described in Chapter 23).\\n\\n• Names that have two leading and trailing underscores (__X__) are system-defined\\n\\nnames that have special meaning to the interpreter.\\n\\n354 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0c• Names that begin with two underscores and do not end with two more (__X) are\\nlocalized  (“mangled”)  to  enclosing  classes  (see  the  discussion  of  pseudoprivate\\nattributes in Chapter 31).\\n\\n• The name that is just a single underscore (_) retains the result of the last expression\\n\\nwhen you are working interactively.\\n\\nIn addition to these Python interpreter conventions, there are various other conventions\\nthat Python programmers usually follow. For instance, later in the book we’ll see that\\nclass names commonly start with an uppercase letter and module names with a low-\\nercase letter, and that the name self, though not reserved, usually has a special role in\\nclasses. In Chapter 17 we’ll also study another, larger category of names known as the\\nbuilt-ins, which are predefined but not reserved (and so can be reassigned: open = 42\\nworks, though sometimes you might wish it didn’t!).\\n\\nNames have no type, but objects do\\nThis is mostly review, but remember that it’s crucial to keep Python’s distinction be-\\ntween names and objects clear. As described in Chapter 6, objects have a type (e.g.,\\ninteger, list) and may be mutable or not. Names (a.k.a. variables), on the other hand,\\nare always just references to objects; they have no notion of mutability and have no\\nassociated type information, apart from the type of the object they happen to reference\\nat a given point in time.\\nThus, it’s OK to assign the same name to different kinds of objects at different times:\\n\\n>>> x = 0               # x bound to an integer object\\n>>> x = \"Hello\"         # Now it\\'s a string\\n>>> x = [1, 2, 3]       # And now it\\'s a list\\n\\nIn later examples, you’ll see that this generic nature of names can be a decided advantage\\nin Python programming. In Chapter 17, you’ll also learn that names also live in some-\\nthing called a scope, which defines where they can be used; the place where you assign\\na name determines where it is visible.4\\n\\nFor additional naming suggestions, see the discussion of naming con-\\nventions in Python’s semi-official style guide, known as  PEP 8. This\\nguide is available at http://www.python.org/dev/peps/pep-0008, or via a\\nweb search for “Python PEP 8.” Technically, this document formalizes\\ncoding standards for Python library code.\\n\\nThough useful, the usual caveats about coding standards apply here.\\nFor one thing, PEP 8 comes with more detail than you are probably ready\\n\\n4. If you’ve used a more restrictive language like C++, you may be interested to know that there is no notion\\nof  C++’s  const  declaration  in  Python;  certain  objects  may  be  immutable,  but  names  can  always  be\\nassigned. Python also has ways to hide names in classes and modules, but they’re not the same as C++’s\\ndeclarations (if hiding attributes matters to you, see the coverage of _X module names in Chapter 25,\\n__X class names in Chapter 31, and the Private and Public class decorators example in Chapter 39).\\n\\nAssignment Statements\\n\\n| 355\\n\\n\\x0cfor at this point in the book. And frankly, it has become more complex,\\nrigid, and subjective than it may need to be—some of its suggestions\\nare not at all universally accepted or followed by Python programmers\\ndoing  real  work.  Moreover,  some  of  the  most  prominent  companies\\nusing Python today have adopted coding standards of their own that\\ndiffer.\\n\\nPEP 8 does codify useful rule-of-thumb Python knowledge, though, and\\nit’s a great read for Python beginners, as long as you take its recom-\\nmendations as guidelines, not gospel.\\n\\nExpression Statements\\nIn Python, you can use an expression as a statement, too—that is, on a line by itself.\\nBut because the result of the expression won’t be saved, it usually makes sense to do\\nso only if the expression does something useful as a side effect. Expressions are com-\\nmonly used as statements in two situations:\\n\\nFor calls to functions and methods\\n\\nSome functions and methods do their work without returning a value. Such func-\\ntions are sometimes called procedures in other languages. Because they don’t return\\nvalues that you might be interested in retaining, you can call these functions with\\nexpression statements.\\n\\nFor printing values at the interactive prompt\\n\\nPython echoes back the results of expressions typed at the interactive command\\nline. Technically, these are expression statements, too; they serve as a shorthand\\nfor typing print statements.\\n\\nTable 11-4 lists some common expression statement forms in Python. Calls to functions\\nand methods are coded with zero or more argument objects (really, expressions that\\nevaluate to objects) in parentheses, after the function/method name.\\n\\nTable 11-4. Common Python expression statements\\n\\nOperation\\nspam(eggs, ham)\\n\\nspam.ham(eggs)\\n\\nspam\\n\\nprint(a, b, c, sep=\\'\\')\\n\\nyield x ** 2\\n\\nInterpretation\\nFunction calls\\nMethod calls\\nPrinting variables in the interactive interpreter\\nPrinting operations in Python 3.X\\nYielding expression statements\\n\\nThe last two entries in Table 11-4 are somewhat special cases—as we’ll see later in this\\nchapter, printing in Python 3.X is a function call usually coded on a line by itself, and\\nthe yield operation in generator functions (discussed in Chapter 20) is often coded as\\na statement as well. Both are really just instances of expression statements.\\n\\n356 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cFor instance, though you normally run a 3.X print call on a line by itself as an expression\\nstatement, it returns a value like any other function call (its return value is None, the\\ndefault return value for functions that don’t return anything meaningful):\\n\\n>>> x = print(\\'spam\\')         # print is a function call expression in 3.X\\nspam\\n>>> print(x)                  # But it is coded as an expression statement\\nNone\\n\\nAlso keep in mind that although expressions can appear as statements in Python, state-\\nments cannot be used as expressions. A statement that is not an expression must gen-\\nerally appear on a line all by itself, not nested in a larger syntactic structure. For example,\\nPython doesn’t allow you to embed assignment statements (=) in other expressions.\\nThe rationale for this is that it avoids common coding mistakes; you can’t accidentally\\nchange a variable by typing = when you really mean to use the == equality test. You’ll\\nsee how to code around this restriction when you meet the Python while loop in Chap-\\nter 13.\\n\\nExpression Statements and In-Place Changes\\nThis brings up another mistake that is common in Python work. Expression statements\\nare often used to run list methods that change a list in place:\\n\\n>>> L = [1, 2]\\n>>> L.append(3)               # Append is an in-place change\\n>>> L\\n[1, 2, 3]\\n\\nHowever, it’s not unusual for Python newcomers to code such an operation as an as-\\nsignment statement instead, intending to assign L to the larger list:\\n\\n>>> L = L.append(4)           # But append returns None, not L\\n>>> print(L)                  # So we lose our list!\\nNone\\n\\nThis doesn’t quite work, though. Calling an in-place change operation such as append,\\nsort, or reverse on a list always changes the list in place, but these methods do not\\nreturn the list they have changed; instead, they return the None object. Thus, if you\\nassign such an operation’s result back to the variable name, you effectively lose the list\\n(and it is probably garbage-collected in the process!).\\nThe moral of the story is, don’t do this—call in-place change operations without as-\\nsigning their results. We’ll revisit this phenomenon in the section “Common Coding\\nGotchas” on page 463 because it can also appear in the context of some looping state-\\nments we’ll meet in later chapters.\\n\\nExpression Statements\\n\\n| 357\\n\\n\\x0cPrint Operations\\nIn Python, print prints things—it’s simply a programmer-friendly interface to the stan-\\ndard output stream.\\nTechnically, printing converts one or more objects to their textual representations, adds\\nsome minor formatting, and sends the resulting text to either standard output or an-\\nother file-like stream. In a bit more detail, print is strongly bound up with the notions\\nof files and streams in Python:\\n\\nFile object methods\\n\\nIn  Chapter  9,  we  learned  about  file  object  methods  that  write  text  (e.g.,\\nfile.write(str)). Printing operations are similar, but more focused—whereas file\\nwrite methods write strings to arbitrary files, print writes objects to the stdout\\nstream by default, with some automatic formatting added. Unlike with file meth-\\nods, there is no need to convert objects to strings when using print operations.\\n\\nStandard output stream\\n\\nThe standard output stream (often known as stdout) is simply a default place to\\nsend a program’s text output. Along with the standard input and error streams,\\nit’s one of three data connections created when your script starts. The standard\\noutput stream is usually mapped to the window where you started your Python\\nprogram, unless it’s been redirected to a file or pipe in your operating system’s shell.\\nBecause the standard output stream is available in Python as the stdout file object\\nin the built-in sys module (i.e., sys.stdout), it’s possible to emulate print with file\\nwrite method calls. However, print is noticeably easier to use and makes it easy to\\nprint text to other files and streams.\\n\\nPrinting is also one of the most visible places where Python 3.X and 2.X have diverged.\\nIn fact, this divergence is usually the first reason that most 2.X code won’t run un-\\nchanged under 3.X. Specifically, the way you code print operations depends on which\\nversion of Python you use:\\n\\n• In Python 3.X, printing is a built-in function, with keyword arguments for special\\n\\nmodes.\\n\\n• In Python 2.X, printing is a statement with specific syntax all its own.\\n\\nBecause this book covers both 3.X and 2.X, we will look at each form in turn here. If\\nyou are fortunate enough to be able to work with code written for just one version of\\nPython, feel free to pick the section that is relevant to you. Because your needs may\\nchange, however, it probably won’t hurt to be familiar with both cases. Moreover, users\\nof recent Python 2.X releases can also import and use 3.X’s flavor of printing in their\\nPythons if desired—both for its extra functionality and to ease future migration to 3.X.\\n\\n358 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cThe Python 3.X print Function\\nStrictly speaking, printing is not a separate statement form in 3.X. Instead, it is simply\\nan instance of the expression statement we studied in the preceding section.\\nThe print built-in function is normally called on a line of its own, because it doesn’t\\nreturn any value we care about (technically, it returns None, as we saw in the preceding\\nsection). Because it is a normal function, though, printing in 3.X uses standard function-\\ncall syntax, rather than a special statement form. And because it provides special op-\\neration modes with keyword arguments, this form is both more general and supports\\nfuture enhancements better.\\nBy comparison, Python 2.X print statements have somewhat ad hoc syntax to support\\nextensions such as end-of-line suppression and target files. Further, the 2.X statement\\ndoes not support separator specification at all; in 2.X, you wind up building strings\\nahead of time more often than you do in 3.X. Rather than adding yet more ad hoc\\nsyntax, Python 3.X’s print takes a single, general approach that covers them all.\\n\\nCall format\\nSyntactically, calls to the 3.X print function have the following form (the flush argu-\\nment is new as of Python 3.3):\\n\\nprint([object, ...][, sep=\\' \\'][, end=\\'\\\\n\\'][, file=sys.stdout][, flush=False])\\n\\nIn this formal notation, items in square brackets are optional and may be omitted in a\\ngiven call, and values after = give argument defaults. In English, this built-in function\\nprints the textual representation of one or more objects separated by the string sep and\\nfollowed by the string end to the stream file, flushing buffered output or not per flush.\\nThe sep, end, file, and (in 3.3 and later) flush parts, if present, must be given as keyword\\narguments—that is, you must use a special “name=value” syntax to pass the arguments\\nby name instead of position. Keyword arguments are covered in depth in Chapter 18,\\nbut they’re straightforward to use. The keyword arguments sent to this call may appear\\nin  any  left-to-right  order  following  the  objects  to  be  printed,  and  they  control  the\\nprint operation:\\n\\n• sep is a string inserted between each object’s text, which defaults to a single space\\n\\nif not passed; passing an empty string suppresses separators altogether.\\n\\n• end is a string added at the end of the printed text, which defaults to a \\\\n newline\\ncharacter if not passed. Passing an empty string avoids dropping down to the next\\noutput line at the end of the printed text—the next print will keep adding to the\\nend of the current output line.\\n\\n• file specifies the file, standard stream, or other file-like object to which the text\\nwill be sent; it defaults to the sys.stdout standard output stream if not passed. Any\\nobject with a file-like write(string) method may be passed, but real files should\\nbe already opened for output.\\n\\nPrint Operations\\n\\n| 359\\n\\n\\x0c• flush, added in 3.3, defaults to False. It allows prints to mandate that their text be\\nflushed through the output stream immediately to any waiting recipients. Nor-\\nmally,  whether  printed  output  is  buffered  in  memory  or  not  is  determined  by\\nfile; passing a true value to flush forcibly flushes the stream.\\n\\nThe textual representation of each object to be printed is obtained by passing the object\\nto the str built-in call (or its equivalent inside Python); as we’ve seen, this built-in\\nreturns a “user friendly” display string for any object.5 With no arguments at all, the\\nprint function simply prints a newline character to the standard output stream, which\\nusually displays a blank line.\\n\\nThe 3.X print function in action\\nPrinting in 3.X is probably simpler than some of its details may imply. To illustrate,\\nlet’s run some quick examples. The following prints a variety of object types to the\\ndefault standard output stream, with the default separator and end-of-line formatting\\nadded (these are the defaults because they are the most common use case):\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> print()                                      # Display a blank line\\n\\n>>> x = \\'spam\\'\\n>>> y = 99\\n>>> z = [\\'eggs\\']\\n>>>\\n>>> print(x, y, z)                               # Print three objects per defaults\\nspam 99 [\\'eggs\\']\\n\\nThere’s no need to convert objects to strings here, as would be required for file write\\nmethods. By default, print calls add a space between the objects printed. To suppress\\nthis, send an empty string to the sep keyword argument, or send an alternative separator\\nof your choosing:\\n\\n>>> print(x, y, z, sep=\\'\\')                       # Suppress separator\\nspam99[\\'eggs\\']\\n>>>\\n>>> print(x, y, z, sep=\\', \\')                     # Custom separator\\nspam, 99, [\\'eggs\\']\\n\\nAlso by default, print adds an end-of-line character to terminate the output line. You\\ncan suppress this and avoid the line break altogether by passing an empty string to the\\nend keyword argument, or you can pass a different terminator of your own including a\\n\\\\n character to break the line manually if desired (the second of the following is two\\nstatements on one line, separated by a semicolon):\\n\\n5. Technically, printing uses the equivalent of str in the internal implementation of Python, but the effect\\nis the same. Besides this to-string conversion role, str is also the name of the string data type and can be\\nused  to  decode  Unicode  strings  from  raw  bytes  with  an  extra  encoding  argument,  as  we’ll  learn  in\\nChapter 37; this latter role is an advanced usage that we can safely ignore here.\\n\\n360 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0c>>> print(x, y, z, end=\\'\\')                        # Suppress line break\\nspam 99 [\\'eggs\\']>>>\\n>>>\\n>>> print(x, y, z, end=\\'\\'); print(x, y, z)        # Two prints, same output line\\nspam 99 [\\'eggs\\']spam 99 [\\'eggs\\']\\n>>> print(x, y, z, end=\\'...\\\\n\\')                   # Custom line end\\nspam 99 [\\'eggs\\']...\\n>>>\\n\\nYou can also combine keyword arguments to specify both separators and end-of-line\\nstrings—they  may  appear  in  any  order  but  must  appear  after  all  the  objects  being\\nprinted:\\n\\n>>> print(x, y, z, sep=\\'...\\', end=\\'!\\\\n\\')          # Multiple keywords\\nspam...99...[\\'eggs\\']!\\n>>> print(x, y, z, end=\\'!\\\\n\\', sep=\\'...\\')          # Order doesn\\'t matter\\nspam...99...[\\'eggs\\']!\\n\\nHere is how the file keyword argument is used—it directs the printed text to an open\\noutput file or other compatible object for the duration of the single print (this is really\\na form of stream redirection, a topic we will revisit later in this section):\\n\\n>>> print(x, y, z, sep=\\'...\\', file=open(\\'data.txt\\', \\'w\\'))      # Print to a file\\n>>> print(x, y, z)                                             # Back to stdout\\nspam 99 [\\'eggs\\']\\n>>> print(open(\\'data.txt\\').read())                             # Display file text\\nspam...99...[\\'eggs\\']\\n\\nFinally, keep in mind that the separator and end-of-line options provided by print op-\\nerations are just conveniences. If you need to display more specific formatting, don’t\\nprint this way. Instead, build up a more complex string ahead of time or within the\\nprint itself using the string tools we met in Chapter 7, and print the string all at once:\\n\\n>>> text = \\'%s: %-.4f, %05d\\' % (\\'Result\\', 3.14159, 42)\\n>>> print(text)\\nResult: 3.1416, 00042\\n>>> print(\\'%s: %-.4f, %05d\\' % (\\'Result\\', 3.14159, 42))\\nResult: 3.1416, 00042\\n\\nAs  we’ll  see  in  the  next  section,  almost  everything  we’ve  just  seen  about  the  3.X\\nprint function also applies directly to 2.X print statements—which makes sense, given\\nthat the function was intended to both emulate and improve upon 2.X printing support.\\n\\nThe Python 2.X print Statement\\nAs mentioned earlier, printing in Python 2.X uses a statement with unique and specific\\nsyntax, rather than a built-in function. In practice, though, 2.X printing is mostly a\\nvariation on a theme; with the exception of separator strings (which are supported in\\n3.X but not 2.X) and flushes on prints (available as of 3.3 only), everything we can do\\nwith the 3.X print function has a direct translation to the 2.X print statement.\\n\\nPrint Operations\\n\\n| 361\\n\\n\\x0cStatement forms\\nTable 11-5 lists the print statement’s forms in Python 2.X and gives their Python 3.X\\nprint  function  equivalents  for  reference.  Notice  that  the  comma  is  significant  in\\nprint statements—it separates objects to be printed, and a trailing comma suppresses\\nthe end-of-line character normally added at the end of the printed text (not to be con-\\nfused with tuple syntax!). The >> syntax, normally used as a bitwise right-shift opera-\\ntion, is used here as well, to specify a target output stream other than the sys.stdout\\ndefault.\\n\\nTable 11-5. Python 2.X print statement forms\\n\\nPython 2.X statement\\nprint x, y\\n\\nPython 3.X equivalent\\nprint(x, y)\\n\\nprint x, y,\\n\\nprint(x, y, end=\\'\\')\\n\\nprint >> afile, x, y\\n\\nprint(x, y, file=afile)\\n\\nInterpretation\\nPrint objects’ textual forms to sys.stdout; add a\\nspace between the items and an end-of-line at the end\\nSame, but don’t add end-of-line at end of text\\nSend text to afile.write, not to\\nsys.stdout.write\\n\\nThe 2.X print statement in action\\nAlthough the 2.X print statement has more unique syntax than the 3.X function, it’s\\nsimilarly easy to use. Let’s turn to some basic examples again. The 2.X print statement\\nadds a space between the items separated by commas and by default adds a line break\\nat the end of the current output line:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> x = \\'a\\'\\n>>> y = \\'b\\'\\n>>> print x, y\\na b\\n\\nThis formatting is just a default; you can choose to use it or not. To suppress the line\\nbreak so you can add more text to the current line later, end your print statement with\\na comma, as shown in the second line of Table 11-5 (the following uses a semicolon to\\nseparate two statements on one line again):\\n\\n>>> print x, y,; print x, y\\na b a b\\n\\nTo suppress the space between items, again, don’t print this way. Instead, build up an\\noutput string using the string concatenation and formatting tools covered in Chap-\\nter 7, and print the string all at once:\\n\\n>>> print x + y\\nab\\n>>> print \\'%s...%s\\' % (x, y)\\na...b\\n\\n362 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cAs you can see, apart from their special syntax for usage modes, 2.X print statements\\nare roughly as simple to use as 3.X’s function. The next section uncovers the way that\\nfiles are specified in 2.X prints.\\n\\nPrint Stream Redirection\\nIn  both  Python  3.X  and  2.X,  printing  sends  text  to  the  standard  output  stream  by\\ndefault. However, it’s often useful to send it elsewhere—to a text file, for example, to\\nsave results for later use or testing purposes. Although such redirection can be accom-\\nplished in system shells outside Python itself, it turns out to be just as easy to redirect\\na script’s streams from within the script.\\n\\nThe Python “hello world” program\\nLet’s start off with the usual (and largely pointless) language benchmark—the “hello\\nworld” program. To print a “hello world” message in Python, simply print the string\\nper your version’s print operation:\\n\\n>>> print(\\'hello world\\')               # Print a string object in 3.X\\nhello world\\n\\n>>> print \\'hello world\\'                # Print a string object in 2.X\\nhello world\\n\\nBecause expression results are echoed on the interactive command line, you often don’t\\neven need to use a print statement there—simply type the expressions you’d like to\\nhave printed, and their results are echoed back:\\n\\n>>> \\'hello world\\'                      # Interactive echoes\\n\\'hello world\\'\\n\\nThis code isn’t exactly an earth-shattering piece of software mastery, but it serves to\\nillustrate printing behavior. Really, the print operation is just an ergonomic feature of\\nPython—it provides a simple interface to the sys.stdout object, with a bit of default\\nformatting. In fact, if you enjoy working harder than you must, you can also code print\\noperations this way:\\n\\n>>> import sys                         # Printing the hard way\\n>>> sys.stdout.write(\\'hello world\\\\n\\')\\nhello world\\n\\nThis code explicitly calls the write method of sys.stdout—an attribute preset when\\nPython  starts  up  to  an  open  file  object  connected  to  the  output  stream.  The  print\\noperation hides most of those details, providing a simple tool for simple printing tasks.\\n\\nManual stream redirection\\nSo, why did I just show you the hard way to print? The sys.stdout print equivalent\\nturns  out  to  be  the  basis  of  a  common  technique  in  Python.  In  general,  print  and\\nsys.stdout are directly related as follows. This statement:\\n\\nPrint Operations\\n\\n| 363\\n\\n\\x0cprint(X, Y)                            # Or, in 2.X: print X, Y\\n\\nis equivalent to the longer:\\n\\nimport sys\\nsys.stdout.write(str(X) + \\' \\' + str(Y) + \\'\\\\n\\')\\n\\nwhich manually performs a string conversion with str, adds a separator and newline\\nwith +, and calls the output stream’s write method. Which would you rather code? (He\\nsays, hoping to underscore the programmer-friendly nature of prints...)\\nObviously, the long form isn’t all that useful for printing by itself. However, it is useful\\nto know that this is exactly what print operations do because it is possible to reas-\\nsign sys.stdout to something different from the standard output stream. In other words,\\nthis equivalence provides a way of making your print operations send their text to other\\nplaces. For example:\\n\\nimport sys\\nsys.stdout = open(\\'log.txt\\', \\'a\\')       # Redirects prints to a file\\n...\\nprint(x, y, x)                          # Shows up in log.txt\\n\\nHere, we reset sys.stdout to a manually opened file named log.txt, located in the script’s\\nworking directory and opened in append mode (so we add to its current content). After\\nthe reset, every print operation anywhere in the program will write its text to the end\\nof the file log.txt instead of to the original output stream. The print operations are\\nhappy to keep calling sys.stdout’s write method, no matter what sys.stdout happens\\nto  refer  to.  Because  there  is  just  one  sys  module  in  your  process,  assigning\\nsys.stdout this way will redirect every print anywhere in your program.\\nIn fact, as the sidebar “Why You Will Care: print and stdout” on page 368 will explain,\\nyou can even reset sys.stdout to an object that isn’t a file at all, as long as it has the\\nexpected interface: a method named write to receive the printed text string argument.\\nWhen that object is a class, printed text can be routed and processed arbitrarily per a\\nwrite method you code yourself.\\nThis trick of resetting the output stream might be more useful for programs originally\\ncoded with print statements. If you know that output should go to a file to begin with,\\nyou can always call file write methods instead. To redirect the output of a print-based\\nprogram, though, resetting sys.stdout provides a convenient alternative to changing\\nevery print statement or using system shell-based redirection syntax.\\nIn other roles, streams may be reset to objects that display them in pop-up windows in\\nGUIs, colorize then in IDEs like IDLE, and so on. It’s a general technique.\\n\\nAutomatic stream redirection\\nAlthough redirecting printed text by assigning sys.stdout is a useful tool, a potential\\nproblem with the last section’s code is that there is no direct way to restore the original\\noutput  stream  should  you  need  to  switch  back  after  printing  to  a  file.  Because\\n\\n364 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0csys.stdout is just a normal file object, though, you can always save it and restore it if\\nneeded:6\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> import sys\\n>>> temp = sys.stdout                   # Save for restoring later\\n>>> sys.stdout = open(\\'log.txt\\', \\'a\\')   # Redirect prints to a file\\n>>> print(\\'spam\\')                       # Prints go to file, not here\\n>>> print(1, 2, 3)\\n>>> sys.stdout.close()                  # Flush output to disk\\n>>> sys.stdout = temp                   # Restore original stream\\n\\n>>> print(\\'back here\\')                  # Prints show up here again\\nback here\\n>>> print(open(\\'log.txt\\').read())       # Result of earlier prints\\nspam\\n1 2 3\\n\\nAs you can see, though, manual saving and restoring of the original output stream like\\nthis involves quite a bit of extra work. Because this crops up fairly often, a print ex-\\ntension is available to make it unnecessary.\\nIn 3.X, the file keyword allows a single print call to send its text to the write method\\nof a file (or file-like object), without actually resetting sys.stdout. Because the redirec-\\ntion is temporary, normal print calls keep printing to the original output stream. In\\n2.X, a print statement that begins with a >> followed by an output file object (or other\\ncompatible object) has the same effect. For example, the following again sends printed\\ntext to a file named log.txt:\\n\\nlog =  open(\\'log.txt\\', \\'a\\')             # 3.X\\nprint(x, y, z, file=log)                # Print to a file-like object\\nprint(a, b, c)                          # Print to original stdout\\n\\nlog =  open(\\'log.txt\\', \\'a\\')             # 2.X\\nprint >> log, x, y, z                   # Print to a file-like object\\nprint a, b, c                           # Print to original stdout\\n\\nThese redirected forms of print are handy if you need to print to both files and the\\nstandard output stream in the same program. If you use these forms, however, be sure\\nto give them a file object (or an object that has the same write method as a file object),\\nnot a file’s name string. Here is the technique in action:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> log = open(\\'log.txt\\', \\'w\\')\\n>>> print(1, 2, 3, file=log)            # For 2.X: print >> log, 1, 2, 3\\n>>> print(4, 5, 6, file=log)\\n>>> log.close()\\n>>> print(7, 8, 9)                      # For 2.X: print 7, 8, 9\\n\\n6. In both 2.X and 3.X you may also be able to use the __stdout__ attribute in the sys module, which refers\\nto the original value sys.stdout had at program startup time. You still need to restore sys.stdout to\\nsys.__stdout__ to go back to this original stream value, though. See the sys module documentation for\\nmore details.\\n\\nPrint Operations\\n\\n| 365\\n\\n\\x0c7 8 9\\n>>> print(open(\\'log.txt\\').read())\\n1 2 3\\n4 5 6\\n\\nThese extended forms of print are also commonly used to print error messages to the\\nstandard  error  stream,  available  to  your  script  as  the  preopened  file  object\\nsys.stderr. You can either use its file write methods and format the output manually,\\nor print with redirection syntax:\\n\\n>>> import sys\\n>>> sys.stderr.write((\\'Bad!\\' * 8) + \\'\\\\n\\')\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\n\\n>>> print(\\'Bad!\\' * 8, file=sys.stderr)     # In 2.X: print >> sys.stderr, \\'Bad!\\' * 8\\nBad!Bad!Bad!Bad!Bad!Bad!Bad!Bad!\\n\\nNow that you know all about print redirections, the equivalence between printing and\\nfile write methods should be fairly obvious. The following interaction prints both ways\\nin 3.X, then redirects the output to an external file to verify that the same text is printed:\\n\\n>>> X = 1; Y = 2\\n>>> print(X, Y)                                            # Print: the easy way\\n1 2\\n>>> import sys                                             # Print: the hard way\\n>>> sys.stdout.write(str(X) + \\' \\' + str(Y) + \\'\\\\n\\')\\n1 2\\n4\\n>>> print(X, Y, file=open(\\'temp1\\', \\'w\\'))                   # Redirect text to file\\n\\n>>> open(\\'temp2\\', \\'w\\').write(str(X) + \\' \\' + str(Y) + \\'\\\\n\\') # Send to file manually\\n4\\n>>> print(open(\\'temp1\\', \\'rb\\').read())                      # Binary mode for bytes\\nb\\'1 2\\\\r\\\\n\\'\\n>>> print(open(\\'temp2\\', \\'rb\\').read())\\nb\\'1 2\\\\r\\\\n\\'\\n\\nAs you can see, unless you happen to enjoy typing, print operations are usually the best\\noption for displaying text. For another example of the equivalence between prints and\\nfile writes, watch for a 3.X print function emulation example in Chapter 18; it uses this\\ncode pattern to provide a general 3.X print function equivalent for use in Python 2.X.\\n\\nVersion-Neutral Printing\\nFinally, if you need your prints to work on both Python lines, you have some options.\\nThis is true whether you’re writing 2.X code that strives for 3.X compatibility, or 3.X\\ncode that aims to support 2.X too.\\n\\n2to3 converter\\nFor one, you can code 2.X print statements and let 3.X’s 2to3 conversion script translate\\nthem to 3.X function calls automatically. See the Python 3.X manuals for more details\\n\\n366 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cabout this script; it attempts to translate 2.X code to run under 3.X—a useful tool, but\\nperhaps more than you want to make just your print operations version-neutral. A\\nrelated tool named 3to2 attempts to do the inverse: convert 3.X code to run on 2.X; see\\nAppendix C for more information.\\n\\nImporting from __future__\\nAlternatively, you can code 3.X print function calls in code to be run by 2.X, by enabling\\nthe function call variant with a statement like the following coded at the top of a script,\\nor anywhere in an interactive session:\\n\\nfrom __future__ import print_function\\n\\nThis statement changes 2.X to support 3.X’s print functions exactly. This way, you\\ncan use 3.X print features and won’t have to change your prints if you later migrate to\\n3.X. Two usage notes here:\\n\\n• This statement is simply ignored if it appears in code run by 3.X—it doesn’t hurt\\n\\nif included in 3.X code for 2.X compatibility.\\n\\n• This statement must appear at the top of each file that prints in 2.X—because it\\nmodifies that parser for a single file only, it’s not enough to import another file that\\nincludes this statement.\\n\\nNeutralizing display differences with code\\nAlso keep in mind that simple prints, like those in the first row of Table 11-5, work in\\neither version of Python—because any expression may be enclosed in parentheses, we\\ncan always pretend to be calling a 3.X print function in 2.X by adding outer parenthe-\\nses. The main downside to this is that it makes a tuple out of your printed objects if\\nthere are more than one, or none—they will print with extra enclosing parentheses. In\\n3.X, for example, any number of objects may be listed in the call’s parentheses:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> print(\\'spam\\')                       # 3.X print function call syntax\\nspam\\n>>> print(\\'spam\\', \\'ham\\', \\'eggs\\')        # These are multiple arguments\\nspam ham eggs\\n\\nThe first of these works the same in 2.X, but the second generates a tuple in the output:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> print(\\'spam\\')                       # 2.X print statement, enclosing parens\\nspam\\n>>> print(\\'spam\\', \\'ham\\', \\'eggs\\')        # This is really a tuple object!\\n(\\'spam\\', \\'ham\\', \\'eggs\\')\\n\\nThe same applies when there are no objects printed to force a line-feed: 2.X shows a\\ntuple, unless you print an empty string:\\n\\nc:\\\\code> py −2\\n>> print()                              # This is just a line-feed on 3.X\\n\\nPrint Operations\\n\\n| 367\\n\\n\\x0c()\\n>>> print(\\'\\')                           # This is a line-feed in both 2.X and 3.X\\n\\nStrictly speaking, outputs may in some cases differ in more than just extra enclosing\\nparentheses in 2.X. If you look closely at the preceding results, you’ll notice that the\\nstrings also print with enclosing quotes in 2.X only. This is because objects may print\\ndifferently when nested in another object than they do as top-level items. Technically,\\nnested appearances display with repr and top-level objects with str—the two alterna-\\ntive display formats we noted in Chapter 5.\\nHere this just means extra quotes around strings nested in the tuple that is created for\\nprinting multiple parenthesized items in 2.X. Displays of nested objects can differ much\\nmore for other object types, though, and especially for class objects that define alter-\\nnative displays with operator overloading—a topic we’ll cover in Part VI in general and\\nChapter 30 in particular.\\nTo be truly portable without enabling 3.X prints everywhere, and to sidestep display\\ndifference for nested appearances, you can always format the print string as a single\\nobject  to  unify  displays  across  versions,  using  the  string  formatting  expression  or\\nmethod call, or other string tools that we studied in Chapter 7:\\n\\n>>> print(\\'%s %s %s\\' % (\\'spam\\', \\'ham\\', \\'eggs\\'))\\nspam ham eggs\\n>>> print(\\'{0} {1} {2}\\'.format(\\'spam\\', \\'ham\\', \\'eggs\\'))\\nspam ham eggs\\n>>> print(\\'answer: \\' + str(42))\\nanswer: 42\\n\\nOf course, if you can use 3.X exclusively you can forget such mappings entirely, but\\nmany Python programmers will at least encounter, if not write, 2.X code and systems\\nfor some time to come. We’ll use both __future__ and version-neutral code to achieve\\n2.X/3.X portability in many examples in this book.\\n\\nI use Python 3.X print function calls throughout this book. I’ll often\\nmake prints version-neutral, and will usually warn you when the results\\nmay differ in 2.X, but I sometimes don’t, so please consider this note a\\nblanket warning. If you see extra parentheses in your printed text in 2.X,\\neither drop the parentheses in your print statements, import 3.X prints\\nfrom  the  __future__,  recode  your  prints  using  the  version-neutral\\nscheme outlined here, or learn to love superfluous text.\\n\\nWhy You Will Care: print and stdout\\n\\nThe equivalence between the print operation and writing to sys.stdout is important.\\nIt makes it possible to reassign sys.stdout to any user-defined object that provides the\\nsame  write  method  as  files.  Because  the  print  statement  just  sends  text  to  the\\nsys.stdout.write method, you can capture printed text in your programs by assigning\\nsys.stdout to an object whose write method processes the text in arbitrary ways.\\n\\n368 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cFor  instance,  you  can  send  printed  text  to  a  GUI  window,  or  tee  it  off  to  multiple\\ndestinations, by defining an object with a write method that does the required routing.\\nYou’ll see an example of this trick when we study classes in Part VI of this book, but\\nabstractly, it looks like this:\\n\\nclass FileFaker:\\n    def write(self, string):\\n        # Do something with printed text in string\\n\\nimport sys\\nsys.stdout = FileFaker()\\nprint(someObjects)              # Sends to class write method\\n\\nThis works because print is what we will call in the next part of this book a polymor-\\nphic  operation—it  doesn’t  care  what  sys.stdout  is,  only  that  it  has  a  method  (i.e.,\\ninterface) called write. This redirection to objects is made even simpler with the file\\nkeyword argument in 3.X and the >> extended form of print in 2.X, because we don’t\\nneed to reset sys.stdout explicitly—normal prints will still be routed to the stdout\\nstream:\\n\\nmyobj = FileFaker()             # 3.X: Redirect to object for one print\\nprint(someObjects, file=myobj)  # Does not reset sys.stdout\\n\\nmyobj = FileFaker()             # 2.X: same effect\\nprint >> myobj, someObjects     # Does not reset sys.stdout\\n\\nPython’s  3.X’s  built-in  input  function  (named  raw_input  in  2.X)  reads  from  the\\nsys.stdin file, so you can intercept read requests in a similar way, using classes that\\nimplement file-like read methods instead. See the  input and while loop example in\\nChapter 10 for more background on this function.\\nNotice that because printed text goes to the stdout stream, it’s also the way to print\\nHTML reply pages in CGI scripts used on the Web, and enables you to redirect Python\\nscript input and output at the operating system’s shell command line as usual:\\n\\npython script.py < inputfile > outputfile\\npython script.py | filterProgram\\n\\nPython’s print operation redirection tools are essentially pure-Python alternatives to\\nthese shell syntax forms. See other resources for more on CGI scripts and shell syntax.\\n\\nChapter Summary\\nIn this chapter, we began our in-depth look at Python statements by exploring assign-\\nments, expressions, and print operations. Although these are generally simple to use,\\nthey have some alternative forms that, while optional, are often convenient in practice\\n—augmented assignment statements and the redirection form of print operations, for\\nexample, allow us to avoid some manual coding work. Along the way, we also studied\\nthe syntax of variable names, stream redirection techniques, and a variety of common\\nmistakes to avoid, such as assigning the result of an append method call back to a vari-\\nable.\\n\\nChapter Summary | 369\\n\\n\\x0cIn the next chapter, we’ll continue our statement tour by filling in details about the\\nif statement, Python’s main selection tool; there, we’ll also revisit Python’s syntax\\nmodel in more depth and look at the behavior of Boolean expressions. Before we move\\non, though, the end-of-chapter quiz will test your knowledge of what you’ve learned\\nhere.\\n\\nTest Your Knowledge: Quiz\\n1. Name three ways that you can assign three variables to the same value.\\n2. Why might you need to care when assigning three variables to a mutable object?\\n3. What’s wrong with saying L = L.sort()?\\n4. How might you use the print operation to send text to an external file?\\n\\nTest Your Knowledge: Answers\\n1. You can use multiple-target assignments (A = B = C = 0), sequence assignment\\n(A, B, C = 0, 0, 0), or multiple assignment statements on three separate lines (A\\n= 0, B = 0, and C = 0). With the latter technique, as introduced in Chapter 10, you\\ncan also string the three separate statements together on the same line by separating\\nthem with semicolons (A = 0; B = 0; C = 0).\\n\\n2. If you assign them this way:\\n\\nA = B = C = []\\n\\nall three names reference the same object, so changing it in place from one (e.g.,\\nA.append(99)) will affect the others. This is true only for in-place changes to mu-\\ntable objects like lists and dictionaries; for immutable objects such as numbers and\\nstrings, this issue is irrelevant.\\n\\n3. The list sort method is like append in that it makes an in-place change to the subject\\nlist—it returns None, not the list it changes. The assignment back to L sets L to\\nNone, not to the sorted list. As discussed both earlier and later in this book (e.g.,\\nChapter 8), a newer built-in function, sorted, sorts any sequence and returns a new\\nlist with the sorting result; because this is not an in-place change, its result can be\\nmeaningfully assigned to a name.\\n\\n4. To print to a file for a single print operation, you can use 3.X’s print(X, file=F)\\ncall  form,  use  2.X’s  extended  print  >>  file,  X  statement  form,  or  assign\\nsys.stdout to a manually opened file before the print and restore the original after.\\nYou can also redirect all of a program’s printed text to a file with special syntax in\\nthe system shell, but this is outside Python’s scope.\\n\\n370 | Chapter 11:\\u2002Assignments, Expressions, and Prints\\n\\n\\x0cCHAPTER 12\\nif Tests and Syntax Rules\\n\\nThis chapter presents the Python if statement, which is the main statement used for\\nselecting from alternative actions based on test results. Because this is our first in-depth\\nlook at compound statements—statements that embed other statements—we will also\\nexplore the general concepts behind the Python statement syntax model here in more\\ndetail than we did in the introduction in Chapter 10. Because the if statement intro-\\nduces the notion of tests, this chapter will also deal with Boolean expressions, cover\\nthe “ternary” if expression, and fill in some details on truth tests in general.\\n\\nif Statements\\nIn simple terms, the Python if statement selects actions to perform. Along with its\\nexpression counterpart, it’s the primary selection tool in Python and represents much\\nof the logic a Python program possesses. It’s also our first compound statement. Like\\nall compound Python statements, the if statement may contain other statements, in-\\ncluding other ifs. In fact, Python lets you combine statements in a program sequentially\\n(so that they execute one after another), and in an arbitrarily nested fashion (so that\\nthey execute only under certain conditions such as selections and loops).\\n\\nGeneral Format\\nThe Python if statement is typical of if statements in most procedural languages. It\\ntakes the form of an if test, followed by one or more optional elif (“else if”) tests and\\na final optional else block. The tests and the else part each have an associated block\\nof nested statements, indented under a header line. When the if statement runs, Python\\nexecutes the block of code associated with the first test that evaluates to true, or the\\nelse block if all tests prove false. The general form of an if statement looks like this:\\n\\nif test1:                 # if test\\n    statements1           # Associated block\\nelif test2:               # Optional elifs\\n    statements2\\n\\n371\\n\\n\\x0celse:                     # Optional else\\n    statements3\\n\\nBasic Examples\\nTo demonstrate, let’s look at a few simple examples of the if statement at work. All\\nparts are optional, except the initial if test and its associated statements. Thus, in the\\nsimplest case, the other parts are omitted:\\n\\n>>> if 1:\\n...     print(\\'true\\')\\n...\\ntrue\\n\\nNotice how the prompt changes to ... for continuation lines when you’re typing in-\\nteractively in the basic interface used here; in IDLE, you’ll simply drop down to an\\nindented line instead (hit Backspace to back up). A blank line (which you can get by\\npressing Enter twice) terminates and runs the entire statement. Remember that 1 is\\nBoolean true (as we’ll see later, the word True is its equivalent), so this statement’s test\\nalways succeeds. To handle a false result, code the else:\\n\\n>>> if not 1:\\n...     print(\\'true\\')\\n... else:\\n...     print(\\'false\\')\\n...\\nfalse\\n\\nMultiway Branching\\nNow here’s an example of a more complex if statement, with all its optional parts\\npresent:\\n\\n>>> x = \\'killer rabbit\\'\\n>>> if x == \\'roger\\':\\n...     print(\"shave and a haircut\")\\n... elif x == \\'bugs\\':\\n...     print(\"what\\'s up doc?\")\\n... else:\\n...     print(\\'Run away! Run away!\\')\\n...\\nRun away! Run away!\\n\\nThis multiline statement extends from the if line through the block nested under the\\nelse. When it’s run, Python executes the statements nested under the first test that is\\ntrue, or the else part if all tests are false (in this example, they are). In practice, both\\nthe elif and else parts may be omitted, and there may be more than one statement\\nnested in each section. Note that the words if, elif, and else are associated by the fact\\nthat they line up vertically, with the same indentation.\\n\\n372 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cIf you’ve used languages like C or Pascal, you might be interested to know that there\\nis no switch or case statement in Python that selects an action based on a variable’s\\nvalue. Instead, you usually code multiway branching as a series of if/elif tests, as in\\nthe prior example, and occasionally by indexing dictionaries or searching lists. Because\\ndictionaries and lists can be built at runtime dynamically, they are sometimes more\\nflexible than hardcoded if logic in your script:\\n\\n>>> choice = \\'ham\\'\\n>>> print({\\'spam\\':  1.25,         # A dictionary-based \\'switch\\'\\n...        \\'ham\\':   1.99,         # Use has_key or get for default\\n...        \\'eggs\\':  0.99,\\n...        \\'bacon\\': 1.10}[choice])\\n1.99\\n\\nAlthough it may take a few moments for this to sink in the first time you see it, this\\ndictionary is a multiway branch—indexing on the key choice branches to one of a set\\nof values, much like a switch in C. An almost equivalent but more verbose Python if\\nstatement might look like the following:\\n\\n>>> if choice == \\'spam\\':          # The equivalent if statement\\n...     print(1.25)\\n... elif choice == \\'ham\\':\\n...     print(1.99)\\n... elif choice == \\'eggs\\':\\n...     print(0.99)\\n... elif choice == \\'bacon\\':\\n...     print(1.10)\\n... else:\\n...     print(\\'Bad choice\\')\\n...\\n1.99\\n\\nThough it’s perhaps more readable, the potential downside of an if like this is that,\\nshort of constructing it as a string and running it with tools like the prior chapter’s\\neval or exec, you cannot construct it at runtime as easily as a dictionary. In more dy-\\nnamic programs, data structures offer added flexibility.\\n\\nHandling switch defaults\\nNotice the else clause on the if here to handle the default case when no key matches.\\nAs we saw in Chapter 8, dictionary defaults can be coded with in expressions, get\\nmethod calls, or exception catching with the try statement introduced in the preceding\\nchapter.  All  of  the  same  techniques  can  be  used  here  to  code  a  default  action  in  a\\ndictionary-based multiway branch. As a review in the context of this use case, here’s\\nthe get scheme at work with defaults:\\n\\n>>> branch = {\\'spam\\': 1.25,\\n...           \\'ham\\':  1.99,\\n...           \\'eggs\\': 0.99}\\n\\n>>> print(branch.get(\\'spam\\', \\'Bad choice\\'))\\n1.25\\n\\nif Statements\\n\\n| 373\\n\\n\\x0c>>> print(branch.get(\\'bacon\\', \\'Bad choice\\'))\\nBad choice\\n\\nAn in membership test in an if statement can have the same default effect:\\n\\n>>> choice = \\'bacon\\'\\n>>> if choice in branch:\\n...     print(branch[choice])\\n... else:\\n...     print(\\'Bad choice\\')\\n...\\nBad choice\\n\\nAnd the try statement is a general way to handle defaults by catching and handling the\\nexceptions they’d otherwise trigger (for more on exceptions, see Chapter 11’s overview\\nand Part VII’s full treatment):\\n\\n>>> try:\\n...     print(branch[choice])\\n... except KeyError:\\n...     print(\\'Bad choice\\')\\n...\\nBad choice\\n\\nHandling larger actions\\nDictionaries are good for associating values with keys, but what about the more com-\\nplicated actions you can code in the statement blocks associated with if statements?\\nIn Part IV, you’ll learn that dictionaries can also contain functions to represent more\\ncomplex branch actions and implement general jump tables. Such functions appear as\\ndictionary values, they may be coded as function names or inline lambdas, and they are\\ncalled by adding parentheses to trigger their actions. Here’s an abstract sampler, but\\nstay tuned for a rehash of this topic in Chapter 19 after we’ve learned more about\\nfunction definition:\\n\\ndef function(): ...\\ndef default(): ...\\n\\nbranch = {\\'spam\\': lambda: ...,             # A table of callable function objects\\n          \\'ham\\':  function,\\n          \\'eggs\\': lambda: ...}\\n\\nbranch.get(choice, default)()\\n\\nAlthough dictionary-based multiway branching is useful in programs that deal with\\nmore dynamic data, most programmers will probably find that coding an if statement\\nis the most straightforward way to perform multiway branching. As a rule of thumb in\\ncoding, when in doubt, err on the side of simplicity and readability; it’s the “Pythonic” \\nway.\\n\\n374 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cPython Syntax Revisited\\nI introduced Python’s syntax model in Chapter 10. Now that we’re stepping up to larger\\nstatements like if, this section reviews and expands on the syntax ideas introduced\\nearlier. In general, Python has a simple, statement-based syntax. However, there are a\\nfew properties you need to know about:\\n\\n• Statements execute one after another, until you say otherwise. Python nor-\\nmally  runs  statements  in  a  file  or  nested  block  in  order  from  first  to  last  as  a\\nsequence, but statements like if (as well as loops and exceptions) cause the inter-\\npreter to jump around in your code. Because Python’s path through a program is\\ncalled the control flow, statements such as if that affect it are often called control-\\nflow statements.\\n\\n• Block and statement boundaries are detected automatically. As we’ve seen,\\nthere are no braces or “begin/end” delimiters around blocks of code in Python;\\ninstead, Python uses the indentation of statements under a header to group the\\nstatements in a nested block. Similarly, Python statements are not normally ter-\\nminated with semicolons; rather, the end of a line usually marks the end of the\\nstatement coded on that line. As a special case, statements can span lines and be\\ncombined on a line with special syntax.\\n\\n• Compound statements = header + “:” + indented statements. All Python com-\\npound  statements—those  with  nested  statements—follow  the  same  pattern:  a \\nheader line terminated with a colon, followed by one or more nested statements,\\nusually indented under the header. The indented statements are called a block (or\\nsometimes, a suite). In the if statement, the elif and else clauses are part of the\\nif, but they are also header lines with nested blocks of their own. As a special case,\\nblocks can show up on the same line as the header if they are simple noncompound\\ncode.\\n\\n• Blank lines, spaces, and comments are usually ignored. Blank lines are both\\noptional and ignored in files (but not at the interactive prompt, when they termi-\\nnate compound statements). Spaces inside statements and expressions are almost\\nalways ignored (except in string literals, and when used for indentation). Com-\\nments are always ignored: they start with a # character (not inside a string literal)\\nand extend to the end of the current line.\\n\\n• Docstrings are ignored but are saved and displayed by tools. Python supports\\nan additional comment form called documentation strings (docstrings for short), \\nwhich, unlike # comments, are retained at runtime for inspection. Docstrings are\\nsimply strings that show up at the top of program files and some statements. Python\\nignores their contents, but they are automatically attached to objects at runtime\\nand may be displayed with documentation tools like PyDoc. Docstrings are part\\nof Python’s larger documentation strategy and are covered in the last chapter in\\nthis part of the book.\\n\\nPython Syntax Revisited | 375\\n\\n\\x0cFigure 12-1. Nested blocks of code: a nested block starts with a statement indented further to the right\\nand ends with either a statement that is indented less, or the end of the file.\\n\\nAs you’ve seen, there are no variable type declarations in Python; this fact alone makes\\nfor a much simpler language syntax than what you may be used to. However, for most\\nnew users the lack of the braces and semicolons used to mark blocks and statements\\nin many other languages seems to be the most novel syntactic feature of Python, so let’s\\nexplore what this means in more detail.\\n\\nBlock Delimiters: Indentation Rules\\nAs introduced in Chapter 10, Python detects block boundaries automatically, by line\\nindentation—that is, the empty space to the left of your code. All statements indented\\nthe same distance to the right belong to the same block of code. In other words, the\\nstatements within a block line up vertically, as in a column. The block ends when the\\nend of the file or a lesser-indented line is encountered, and more deeply nested blocks\\nare simply indented further to the right than the statements in the enclosing block.\\nCompound statement bodies can appear on the header’s line in some cases we’ll explore\\nlater, but most are indented under it.\\nFor instance, Figure 12-1 demonstrates the block structure of the following code:\\n\\nx = 1\\nif x:\\n    y = 2\\n    if y:\\n        print(\\'block2\\')\\n    print(\\'block1\\')\\nprint(\\'block0\\')\\n\\nThis code contains three blocks: the first (the top-level code of the file) is not indented\\nat all, the second (within the outer if statement) is indented four spaces, and the third\\n(the print statement under the nested if) is indented eight spaces.\\n\\n376 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cIn general, top-level (unnested) code must start in column 1. Nested blocks can start\\nin any column; indentation may consist of any number of spaces and tabs, as long as\\nit’s the same for all the statements in a given single block. That is, Python doesn’t care\\nhow you indent your code; it only cares that it’s done consistently. Four spaces or one\\ntab per indentation level are common conventions, but there is no absolute standard\\nin the Python world.\\nIndenting code is quite natural in practice. For example, the following (arguably silly)\\ncode snippet demonstrates common indentation errors in Python code:\\n\\n  x = \\'SPAM\\'                        # Error: first line indented\\nif \\'rubbery\\' in \\'shrubbery\\':\\n    print(x * 8)\\n        x += \\'NI\\'                   # Error: unexpected indentation\\n        if x.endswith(\\'NI\\'):\\n                x *= 2\\n            print(x)                # Error: inconsistent indentation\\n\\nThe properly indented version of this code looks like the following—even for an arti-\\nficial example like this, proper indentation makes the code’s intent much more appa-\\nrent:\\n\\nx = \\'SPAM\\'\\nif \\'rubbery\\' in \\'shrubbery\\':\\n    print(x * 8)                    # Prints 8 \"SPAM\"\\n    x += \\'NI\\'\\n    if x.endswith(\\'NI\\'):\\n        x *= 2\\n        print(x)                    # Prints \"SPAMNISPAMNI\"\\n\\nIt’s important to know that the only major place in Python where whitespace matters\\nis where it’s used to the left of your code, for indentation; in most other contexts, space\\ncan be coded or not. However, indentation is really part of Python syntax, not just a\\nstylistic suggestion: all the statements within any given single block must be indented\\nto the same level, or Python reports a syntax error. This is intentional—because you\\ndon’t need to explicitly mark the start and end of a nested block of code, some of the\\nsyntactic clutter found in other languages is unnecessary in Python.\\nAs described in Chapter 10, making indentation part of the syntax model also enforces\\nconsistency, a crucial component of readability in structured programming languages\\nlike Python. Python’s syntax is sometimes described as “what you see is what you get”\\n—the indentation of each line of code unambiguously tells readers what it is associated\\nwith. This uniform and consistent appearance makes Python code easier to maintain\\nand reuse.\\nIndentation is simpler in practice than its details might initially imply, and it makes\\nyour  code  reflect  its  logical  structure.  Consistently  indented  code  always  satisfies\\nPython’s rules. Moreover, most text editors (including IDLE) make it easy to follow\\nPython’s indentation model by automatically indenting code as you type it.\\n\\nPython Syntax Revisited | 377\\n\\n\\x0cAvoid mixing tabs and spaces: New error checking in 3.X\\nOne rule of thumb: although you can use spaces or tabs to indent, it’s usually not a\\ngood idea to mix the two within a block—use one or the other. Technically, tabs count\\nfor enough spaces to move the current column number up to a multiple of 8, and your\\ncode will work if you mix tabs and spaces consistently. However, such code can be\\ndifficult to change. Worse, mixing tabs and spaces makes your code difficult to read\\ncompletely apart from Python’s syntax rules—tabs may look very different in the next\\nprogrammer’s editor than they do in yours.\\nIn fact, Python 3.X issues an error, for these very reasons, when a script mixes tabs and\\nspaces for indentation inconsistently within a block (that is, in a way that makes it\\ndependent on a tab’s equivalent in spaces). Python 2.X allows such scripts to run, but\\nit has a -t command-line flag that will warn you about inconsistent tab usage and a\\n-tt flag that will issue errors for such code (you can use these switches in a command\\nline like python –t main.py in a system shell window). Python 3.X’s error case is equiv-\\nalent to 2.X’s -tt switch.\\n\\nStatement Delimiters: Lines and Continuations\\nA statement in Python normally ends at the end of the line on which it appears. When\\na statement is too long to fit on a single line, though, a few special rules may be used\\nto make it span multiple lines:\\n\\n• Statements may span multiple lines if you’re continuing an open syntactic\\npair. Python lets you continue typing a statement on the next line if you’re coding\\nsomething enclosed in a (), {}, or [] pair. For instance, expressions in parentheses\\nand dictionary and list literals can span any number of lines; your statement doesn’t\\nend until the Python interpreter reaches the line on which you type the closing part\\nof the pair (a ), }, or ]). Continuation lines—lines 2 and beyond of the statement\\n—can start at any indentation level you like, but you should try to make them align\\nvertically for readability if possible. This open pairs rule also covers set and dic-\\ntionary comprehensions in Python 3.X and 2.7.\\n\\n• Statements may span multiple lines if they end in a backslash. This is a some-\\nwhat outdated feature that’s not generally recommended, but if a statement needs\\nto span multiple lines, you can also add a backslash (a \\\\ not embedded in a string\\nliteral or comment) at the end of the prior line to indicate you’re continuing on the\\nnext line. Because you can also continue by adding parentheses around most con-\\nstructs, backslashes are rarely used today. This approach is also error-prone: ac-\\ncidentally forgetting a \\\\ usually generates a syntax error and might even cause the\\nnext line to be silently mistaken (i.e., without warning) for a new statement, with\\nunexpected results.\\n\\n• Special rules for string literals. As we learned in Chapter 7, triple-quoted string\\nblocks are designed to span multiple lines normally. We also learned in  Chap-\\nter  7  that  adjacent  string  literals  are  implicitly  concatenated;  when  it’s  used  in\\n\\n378 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cconjunction with the open pairs rule mentioned earlier, wrapping this construct in\\nparentheses allows it to span multiple lines.\\n\\n• Other rules. There are a few other points to mention with regard to statement\\ndelimiters. Although it is uncommon, you can terminate a statement with a semi-\\ncolon—this convention is sometimes used to squeeze more than one simple (non-\\ncompound) statement onto a single line. Also, comments and blank lines can ap-\\npear anywhere in a file; comments (which begin with a # character) terminate at\\nthe end of the line on which they appear.\\n\\nA Few Special Cases\\nHere’s what a continuation line looks like using the open syntactic pairs rule just de-\\nscribed. Delimited constructs, such as lists in square brackets, can span across any\\nnumber of lines:\\nL = [\"Good\",\\n     \"Bad\",\\n     \"Ugly\"]                     # Open pairs may span lines\\n\\nThis also works for anything in parentheses (expressions, function arguments, function\\nheaders, tuples, and generator expressions), as well as anything in curly braces (dic-\\ntionaries and, in 3.X and 2.7, set literals and set and dictionary comprehensions). Some\\nof these are tools we’ll study in later chapters, but this rule naturally covers most con-\\nstructs that span lines in practice.\\nIf you like using backslashes to continue lines, you can, but it’s not common practice\\nin Python:\\n\\nif a == b and c == d and   \\\\\\n   d == e and f == g:\\n   print(\\'olde\\')                 # Backslashes allow continuations...\\n\\nBecause any expression can be enclosed in parentheses, you can usually use the open\\npairs technique instead if you need your code to span multiple lines—simply wrap a\\npart of your statement in parentheses:\\n\\nif (a == b and c == d and\\n    d == e and e == f):\\n    print(\\'new\\')                 # But parentheses usually do too, and are obvious\\n\\nIn  fact,  backslashes  are  generally  frowned  on  by  most  Python  developers,  because\\nthey’re too easy to not notice and too easy to omit altogether. In the following, x is\\nassigned 10 with the backslash, as intended; if the backslash is accidentally omitted,\\nthough, x is assigned 6 instead, and no error is reported (the +4 is a valid expression\\nstatement by itself).\\nIn a real program with a more complex assignment, this could be the source of a very\\nnasty bug:1\\n\\nx = 1 + 2 + 3 \\\\                  # Omitting the \\\\ makes this very different!\\n+4\\n\\nPython Syntax Revisited | 379\\n\\n\\x0cAs  another  special  case,  Python  allows  you  to  write  more  than  one  noncompound\\nstatement (i.e., statements without nested statements) on the same line, separated by\\nsemicolons. Some coders use this form to save program file real estate, but it usually\\nmakes for more readable code if you stick to one statement per line for most of your\\nwork:\\n\\nx = 1; y = 2; print(x)           # More than one simple statement\\n\\nAs we learned in Chapter 7, triple-quoted string literals span lines too. In addition, if\\ntwo string literals appear next to each other, they are concatenated as if a + had been\\nadded between them—when used in conjunction with the open pairs rule, wrapping\\nin parentheses allows this form to span multiple lines. For example, the first of the\\nfollowing  inserts  newline  characters  at  line  breaks  and  assigns  S  to  \\'\\\\naaaa\\\\nbbbb\\n\\\\ncccc\\', and the second implicitly concatenates and assigns S to \\'aaaabbbbcccc\\'; as we\\nalso saw in Chapter 7, # comments are ignored in the second form, but included in the\\nstring in the first:\\n\\nS = \"\"\"\\naaaa\\nbbbb\\ncccc\"\"\"\\n\\nS = (\\'aaaa\\'\\n     \\'bbbb\\'                      # Comments here are ignored\\n     \\'cccc\\')\\n\\nFinally, Python lets you move a compound statement’s body up to the header line,\\nprovided the body contains just simple (noncompound) statements. You’ll most often\\nsee this used for simple if statements with a single test and action, as in the interactive\\nloops we coded in Chapter 10:\\n\\nif 1: print(\\'hello\\')             # Simple statement on header line\\n\\nYou can combine some of these special cases to write code that is difficult to read, but\\nI don’t recommend it; as a rule of thumb, try to keep each statement on a line of its\\nown, and indent all but the simplest of blocks. Six months down the road, you’ll be\\nhappy you did.\\n\\nTruth Values and Boolean Tests\\nThe notions of comparison, equality, and truth values were introduced in Chapter 9.\\nBecause the if statement is the first statement we’ve looked at that actually uses test\\n\\n1. Candidly, it was a bit surprising that backslash continuations were not removed in Python 3.0, given the\\nbroad scope of its other changes! See the 3.0 changes tables in Appendix C for a list of 3.0 removals; some\\nseem fairly innocuous in comparison with the dangers inherent in backslash continuations. Then again,\\nthis book’s goal is Python instruction, not populist outrage, so the best advice I can give is simply: don’t\\ndo this. You should generally avoid backslash continuations in new Python code, even if you developed\\nthe habit in your C programming days.\\n\\n380 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cresults, we’ll expand on some of these ideas here. In particular, Python’s Boolean oper-\\nators are a bit different from their counterparts in languages like C. In Python:\\n\\n• All objects have an inherent Boolean true or false value.\\n• Any nonzero number or nonempty object is true.\\n• Zero numbers, empty objects, and the special object None are considered false.\\n• Comparisons and equality tests are applied recursively to data structures.\\n• Comparisons and equality tests return True or False (custom versions of 1 and 0).\\n• Boolean and and or operators return a true or false operand object.\\n• Boolean operators stop evaluating (“short circuit”) as soon as a result is known.\\n\\nThe if statement takes action on truth values, but Boolean operators are used to com-\\nbine the results of other tests in richer ways to produce new truth values. More formally,\\nthere are three Boolean expression operators in Python:\\n\\nX and Y\\n\\nIs true if both X and Y are true\\n\\nX or Y\\n\\nIs true if either X or Y is true\\n\\nnot X\\n\\nIs true if X is false (the expression returns True or False)\\n\\nHere, X and Y may be any truth value, or any expression that returns a truth value (e.g.,\\nan equality test, range comparison, and so on). Boolean operators are typed out as\\nwords in Python (instead of C’s &&, ||, and !). Also, Boolean and and or operators return\\na true or false object in Python, not the values True or False. Let’s look at a few examples\\nto see how this works:\\n\\n>>> 2 < 3, 3 < 2        # Less than: return True or False (1 or 0)\\n(True, False)\\n\\nMagnitude comparisons such as these return True or False as their truth results, which,\\nas we learned in Chapter 5 and Chapter 9, are really just custom versions of the integers\\n1 and 0 (they print themselves differently but are otherwise the same).\\nOn the other hand, the and and or operators always return an object—either the object\\non the left side of the operator or the object on the right. If we test their results in if or\\nother statements, they will be as expected (remember, every object is inherently true\\nor false), but we won’t get back a simple True or False.\\nFor or tests, Python evaluates the operand objects from left to right and returns the first\\none that is true. Moreover, Python stops at the first true operand it finds. This is usually\\ncalled short-circuit evaluation, as determining a result short-circuits (terminates) the\\nrest of the expression as soon as the result is known:\\n\\n>>> 2 or 3, 3 or 2      # Return left operand if true\\n(2, 3)                  # Else, return right operand (true or false)\\n\\nTruth Values and Boolean Tests\\n\\n| 381\\n\\n\\x0c>>> [] or 3\\n3\\n>>> [] or {}\\n{}\\n\\nIn the first line of the preceding example, both operands (2 and 3) are true (i.e., are\\nnonzero), so Python always stops and returns the one on the left—it determines the\\nresult because true or anything is always true. In the other two tests, the left operand\\nis false (an empty object), so Python simply evaluates and returns the object on the\\nright—which may happen to have either a true or a false value when tested.\\nPython and operations also stop as soon as the result is known; however, in this case\\nPython evaluates the operands from left to right and stops if the left operand is a false\\nobject because it determines the result—false and anything is always false:\\n\\n>>> 2 and 3, 3 and 2    # Return left operand if false\\n(3, 2)                  # Else, return right operand (true or false)\\n>>> [] and {}\\n[]\\n>>> 3 and []\\n[]\\n\\nHere, both operands are true in the first line, so Python evaluates both sides and returns\\nthe object on the right. In the second test, the left operand is false ([]), so Python stops\\nand returns it as the test result. In the last test, the left side is true (3), so Python evaluates\\nand returns the object on the right—which happens to be a false [].\\nThe end result of all this is the same as in C and most other languages—you get a value\\nthat is logically true or false if tested in an if or while according to the normal definitions\\nof or and and. However, in Python Booleans return either the left or the right object,\\nnot a simple integer flag.\\nThis behavior of and and or may seem esoteric at first glance, but see this chapter’s\\nsidebar “Why You Will Care: Booleans” on page 384 for examples of how it is some-\\ntimes used to advantage in coding by Python programmers. The next section also shows\\na common way to leverage this behavior, and its more mnemonic replacement in recent\\nversions of Python.\\n\\nThe if/else Ternary Expression\\nOne common role for the prior section’s Boolean operators is to code an expression\\nthat runs the same as an if statement. Consider the following statement, which sets\\nA to either Y or Z, based on the truth value of X:\\n\\nif X:\\n    A = Y\\nelse:\\n    A = Z\\n\\n382 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cSometimes, though, the items involved in such a statement are so simple that it seems\\nlike overkill to spread them across four lines. At other times, we may want to nest such\\na construct in a larger statement instead of assigning its result to a variable. For these\\nreasons (and, frankly, because the C language has a similar tool), Python 2.5 introduced\\na new expression format that allows us to say the same thing in one expression:\\n\\nA = Y if X else Z\\n\\nThis expression has the exact same effect as the preceding four-line if statement, but\\nit’s simpler to code. As in the statement equivalent, Python runs expression Y only if\\nX turns out to be true, and runs expression Z only if X turns out to be false. That is, it\\nshort-circuits, just like the Boolean operators described in the prior section, running\\njust Y or Z but not both. Here are some examples of it in action:\\n\\n>>> A = \\'t\\' if \\'spam\\' else \\'f\\'      # For strings, nonempty means true\\n>>> A\\n\\'t\\'\\n>>> A = \\'t\\' if \\'\\' else \\'f\\'\\n>>> A\\n\\'f\\'\\n\\nPrior to Python 2.5 (and after 2.5, if you insist), the same effect can often be achieved\\nby a careful combination of the and and or operators, because they return either the\\nobject on the left side or the object on the right as the preceding section described:\\n\\nA = ((X and Y) or Z)\\n\\nThis works, but there is a catch—you have to be able to assume that Y will be Boolean\\ntrue. If that is the case, the effect is the same: the and runs first and returns Y if X is true;\\nif X if false the and skips Y, and the or simply returns Z. In other words, we get “if X then\\nY else Z.” This is equivalent to the ternary form:\\n\\nA = Y if X else Z\\n\\nThe  and/or combination form also seems to require a “moment of great clarity” to\\nunderstand  the  first  time  you  see  it,  and  it’s  no  longer  required  as  of  2.5—use  the\\nequivalent and more robust and mnemonic if/else expression when you need this\\nstructure, or use a full if statement if the parts are nontrivial.\\nAs a side note, using the following expression in Python is similar because the bool\\nfunction will translate X into the equivalent of integer 1 or 0, which can then be used as\\noffsets to pick true and false values from a list:\\n\\nA = [Z, Y][bool(X)]\\n\\nFor example:\\n\\n>>> [\\'f\\', \\'t\\'][bool(\\'\\')]\\n\\'f\\'\\n>>> [\\'f\\', \\'t\\'][bool(\\'spam\\')]\\n\\'t\\'\\n\\nHowever, this isn’t exactly the same, because Python will not short-circuit—it will al-\\nways run both Z and Y, regardless of the value of X. Because of such complexities, you’re\\n\\nThe if/else Ternary Expression | 383\\n\\n\\x0cbetter off using the simpler and more easily understood if/else expression as of Python\\n2.5 and later. Again, though, you should use even that sparingly, and only if its parts\\nare all fairly simple; otherwise, you’re better off coding the full if statement form to\\nmake changes easier in the future. Your coworkers will be happy you did.\\nStill, you may see the and/or version in code written prior to 2.5 (and in Python code\\nwritten by ex–C programmers who haven’t quite let go of their dark coding pasts).2\\n\\nWhy You Will Care: Booleans\\n\\nOne common way to use the somewhat unusual behavior of Python Boolean operators\\nis to select from a set of objects with an or. A statement such as this:\\n\\nX = A or B or C or None\\n\\nassigns X to the first nonempty (that is, true) object among A, B, and C, or to None if all\\nof them are empty. This works because the or operator returns one of its two objects,\\nand it turns out to be a fairly common coding paradigm in Python: to select a nonempty\\nobject from among a fixed-size set, simply string them together in an or expression. In\\nsimpler form, this is also commonly used to designate a default—the following sets X\\nto A if A is true (or nonempty), and to default otherwise:\\n\\nX = A or default\\n\\nIt’s also important to understand the short-circuit evaluation of Boolean operators and\\nthe if/else, because it may prevent actions from running. Expressions on the right of\\na Boolean operator, for example, might call functions that perform substantial or im-\\nportant work, or have side effects that won’t happen if the short-circuit rule takes effect:\\n\\nif f1() or f2(): ...\\n\\nHere, if f1 returns a true (or nonempty) value, Python will never run f2. To guarantee\\nthat both functions will be run, call them before the or:\\n\\ntmp1, tmp2 = f1(), f2()\\nif tmp1 or tmp2: ...\\n\\nYou’ve already seen another application of this behavior in this chapter: because of the\\nway Booleans work, the expression ((A and B) or C) can be used to emulate an if\\nstatement—almost (see this chapter’s discussion of this form for details).\\n\\nWe met additional Boolean use cases in prior chapters. As we saw in Chapter 9, because\\nall objects are inherently true or false, it’s common and easier in Python to test an object\\ndirectly (if X:) than to compare it to an empty value (if X != \\'\\':). For a string, the\\ntwo tests are equivalent. As we also saw in Chapter 5, the preset Boolean values True\\nand False are the same as the integers 1 and 0 and are useful for initializing variables\\n\\n2. In fact, Python’s Y if X else Z has a slightly different order than C’s X ? Y : Z, and uses more readable\\nwords. Its differing order was reportedly chosen in response to analysis of common usage patterns in\\nPython code. According to the Python folklore, this order was also chosen in part to discourage ex–C\\nprogrammers from overusing it! Remember, simple is better than complex, in Python and elsewhere. If\\nyou have to work at packing logic into expressions like this, statements are probably your better bet.\\n\\n384 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0c(X = False), for loop tests (while True:), and for displaying results at the interactive\\nprompt.\\n\\nAlso watch for related discussion in operator overloading in Part VI: when we define\\nnew  object  types  with  classes,  we  can  specify  their  Boolean  nature  with  either  the\\n__bool__ or __len__ methods (__bool__ is named __nonzero__ in 2.7). The latter of these\\nis tried if the former is absent and designates false by returning a length of zero—an\\nempty object is considered false.\\nFinally, and as a preview, other tools in Python have roles similar to the or chains at\\nthe start of this sidebar: the filter call and list comprehensions we’ll meet later can be\\nused to select true values when the set of candidates isn’t known until runtime (though\\nthey evaluate all values and return all that are true), and the any and all built-ins can\\nbe used to test if any or all items in a collection are true (though they don’t select an\\nitem):\\n\\n>>> L = [1, 0, 2, 0, \\'spam\\', \\'\\', \\'ham\\', []]\\n>>> list(filter(bool, L))                    # Get true values\\n[1, 2, \\'spam\\', \\'ham\\']\\n>>> [x for x in L if x]                      # Comprehensions\\n[1, 2, \\'spam\\', \\'ham\\']\\n>>> any(L), all(L)                           # Aggregate truth\\n(True, False)\\n\\nAs seen in Chapter 9, the bool function here simply returns its argument’s true or false\\nvalue,  as  though  it  were  tested  in  an  if.  Watch  for  more  on  these  related  tools  in\\nChapter 14, Chapter 19, and Chapter 20.\\n\\nChapter Summary\\nIn this chapter, we studied the Python if statement. Additionally, because this was our\\nfirst compound and logical statement, we reviewed Python’s general syntax rules and\\nexplored the operation of truth values and tests in more depth than we were able to\\npreviously.  Along  the  way,  we  also  looked  at  how  to  code  multiway  branching  in\\nPython, learned about the if/else expression introduced in Python 2.5, and explored\\nsome common ways that Boolean values crop up in code.\\nThe next chapter continues our look at procedural statements by expanding on the\\nwhile and for loops. There, we’ll learn about alternative ways to code loops in Python,\\nsome of which may be better than others. Before that, though, here is the usual chapter\\nquiz.\\n\\nTest Your Knowledge: Quiz\\n1. How might you code a multiway branch in Python?\\n2. How can you code an if/else statement as an expression in Python?\\n3. How can you make a single statement span many lines?\\n\\nTest Your Knowledge: Quiz | 385\\n\\n\\x0c4. What do the words True and False mean?\\n\\nTest Your Knowledge: Answers\\n1. An if statement with multiple elif clauses is often the most straightforward way\\nto code a multiway branch, though not necessarily the most concise or flexible.\\nDictionary indexing can often achieve the same result, especially if the dictionary\\ncontains callable functions coded with def statements or lambda expressions.\\n\\n2. In Python 2.5 and later, the expression form Y if X else Z returns Y if X is true, or\\nZ  otherwise;  it’s  the  same  as  a  four-line  if  statement.  The  and/or  combination\\n(((X and Y) or Z)) can work the same way, but it’s more obscure and requires that\\nthe Y part be true.\\n\\n3. Wrap up the statement in an open syntactic pair ((), [], or {}), and it can span as\\nmany lines as you like; the statement ends when Python sees the closing (right) half\\nof the pair, and lines 2 and beyond of the statement can begin at any indentation\\nlevel. Backslash continuations work too, but are broadly discouraged in the Python\\nworld.\\n\\n4. True and False are just custom versions of the integers 1 and 0, respectively: they\\nalways stand for Boolean true and false values in Python. They’re available for use\\nin truth tests and variable initialization, and are printed for expression results at\\nthe interactive prompt. In all these roles, they serve as a more mnemonic and hence\\nreadable alternative to 1 and 0.\\n\\n386 | Chapter 12:\\u2002if Tests and Syntax Rules\\n\\n\\x0cCHAPTER 13\\nwhile and for Loops\\n\\nThis chapter concludes our tour of Python procedural statements by presenting the\\nlanguage’s two main looping constructs—statements that repeat an action over and\\nover. The first of these, the while statement, provides a way to code general loops. The\\nsecond, the for statement, is designed for stepping through the items in a sequence or\\nother iterable object and running a block of code for each.\\nWe’ve seen both of these informally already, but we’ll fill in additional usage details\\nhere. While we’re at it, we’ll also study a few less prominent statements used within\\nloops, such as break and continue, and cover some built-ins commonly used with loops,\\nsuch as range, zip, and map.\\nAlthough the while and for statements covered here are the primary syntax provided\\nfor coding repeated actions, there are additional looping operations and concepts in\\nPython. Because of that, the iteration story is continued in the next chapter, where we’ll\\nexplore the related ideas of Python’s iteration protocol (used by the for loop) and list\\ncomprehensions (a close cousin to the for loop). Later chapters explore even more exotic\\niteration tools such as generators, filter, and reduce. For now, though, let’s keep things\\nsimple.\\n\\nwhile Loops\\nPython’s while statement is the most general iteration construct in the language. In\\nsimple terms, it repeatedly executes a block of (normally indented) statements as long\\nas a test at the top keeps evaluating to a true value. It is called a “loop” because control\\nkeeps looping back to the start of the statement until the test becomes false. When the\\ntest becomes false, control passes to the statement that follows the while block. The\\nnet effect is that the loop’s body is executed repeatedly while the test at the top is true.\\nIf the test is false to begin with, the body never runs and the while statement is skipped.\\n\\n387\\n\\n\\x0cGeneral Format\\nIn its most complex form, the while statement consists of a header line with a test\\nexpression,  a  body  of  one  or  more  normally  indented  statements,  and  an  optional\\nelse part that is executed if control exits the loop without a  break statement being\\nencountered. Python keeps evaluating the test at the top and executing the statements\\nnested in the loop body until the test returns a false value:\\n\\nwhile test:                     # Loop test\\n    statements                  # Loop body\\nelse:                           # Optional else\\n    statements                  # Run if didn\\'t exit loop with break\\n\\nExamples\\nTo illustrate, let’s look at a few simple while loops in action. The first, which consists\\nof a print statement nested in a while loop, just prints a message forever. Recall that\\nTrue is just a custom version of the integer 1 and always stands for a Boolean true value;\\nbecause the test is always true, Python keeps executing the body forever, or until you\\nstop its execution. This sort of behavior is usually called an infinite loop—it’s not really\\nimmortal, but you may need a Ctrl-C key combination to forcibly terminate one:\\n\\n>>> while True:\\n...    print(\\'Type Ctrl-C to stop me!\\')\\n\\nThe next example keeps slicing off the first character of a string until the string is empty\\nand hence false. It’s typical to test an object directly like this instead of using the more\\nverbose equivalent (while x != \\'\\':). Later in this chapter, we’ll see other ways to step\\nthrough the items in a string more easily with a for loop.\\n\\n>>> x = \\'spam\\'\\n>>> while x:                  # While x is not empty\\n...     print(x, end=\\' \\')     # In 2.X use print x,\\n...     x = x[1:]             # Strip first character off x\\n...\\nspam pam am m\\n\\nNote the end=\\' \\' keyword argument used here to place all outputs on the same line\\nseparated by a space; see Chapter 11 if you’ve forgotten why this works as it does. This\\nmay leave your input prompt in an odd state at the end of your output; type Enter to\\nreset. Python 2.X readers: also remember to use a trailing comma instead of end in the\\nprints like this.\\nThe following code counts from the value of a up to, but not including, b. We’ll also\\nsee an easier way to do this with a Python for loop and the built-in range function later:\\n\\n>>> a=0; b=10\\n>>> while a < b:              # One way to code counter loops\\n...     print(a, end=\\' \\')\\n...     a += 1                # Or, a = a + 1\\n\\n388 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0c...\\n0 1 2 3 4 5 6 7 8 9\\n\\nFinally, notice that Python doesn’t have what some languages call a “do until” loop\\nstatement. However, we can simulate one with a test and break at the bottom of the\\nloop body, so that the loop’s body is always run at least once:\\n\\nwhile True:\\n    ...loop body...\\n    if exitTest(): break\\n\\nTo fully understand how this structure works, we need to move on to the next section\\nand learn more about the break statement.\\n\\nbreak, continue, pass, and the Loop else\\nNow that we’ve seen a few Python loops in action, it’s time to take a look at two simple\\nstatements  that  have  a  purpose  only  when  nested  inside  loops—the  break  and  con\\ntinue statements. While we’re looking at oddballs, we will also study the loop else\\nclause here because it is intertwined with break, and Python’s empty placeholder state-\\nment, pass (which is not tied to loops per se, but falls into the general category of simple\\none-word statements). In Python:\\n\\nbreak\\n\\nJumps out of the closest enclosing loop (past the entire loop statement)\\n\\ncontinue\\n\\nJumps to the top of the closest enclosing loop (to the loop’s header line)\\n\\npass\\n\\nDoes nothing at all: it’s an empty statement placeholder\\n\\nLoop else block\\n\\nRuns if and only if the loop is exited normally (i.e., without hitting a break)\\n\\nGeneral Loop Format\\nFactoring in break and continue statements, the general format of the while loop looks\\nlike this:\\n\\nwhile test:\\n    statements\\n    if test: break                 # Exit loop now, skip else if present\\n    if test: continue              # Go to top of loop now, to test1\\nelse:\\n    statements                     # Run if we didn\\'t hit a \\'break\\'\\n\\nbreak and continue statements can appear anywhere inside the while (or for) loop’s\\nbody, but they are usually coded further nested in an if test to take action in response\\nto some condition.\\n\\nbreak, continue, pass, and the Loop else | 389\\n\\n\\x0cLet’s  turn  to  a  few  simple  examples  to  see  how  these  statements  come  together  in\\npractice.\\n\\npass\\nSimple things first: the pass statement is a no-operation placeholder that is used when\\nthe syntax requires a statement, but you have nothing useful to say. It is often used to\\ncode an empty body for a compound statement. For instance, if you want to code an\\ninfinite loop that does nothing each time through, do it with a pass:\\n\\nwhile True: pass                   # Type Ctrl-C to stop me!\\n\\nBecause the body is just an empty statement, Python gets stuck in this loop. pass is\\nroughly to statements as None is to objects—an explicit nothing. Notice that here the\\nwhile loop’s body is on the same line as the header, after the colon; as with if state-\\nments, this only works if the body isn’t a compound statement.\\nThis example does nothing forever. It probably isn’t the most useful Python program\\never written (unless you want to warm up your laptop computer on a cold winter’s\\nday!); frankly, though, I couldn’t think of a better pass example at this point in the book.\\nWe’ll see other places where pass makes more sense later—for instance, to ignore ex-\\nceptions caught by try statements, and to define empty class objects with attributes\\nthat behave like “structs” and “records” in other languages. A pass is also sometime\\ncoded to mean “to be filled in later,” to stub out the bodies of functions temporarily:\\n\\ndef func1():\\n    pass                           # Add real code here later\\n\\ndef func2():\\n    pass\\n\\nWe can’t leave the body empty without getting a syntax error, so we say pass instead.\\n\\nVersion  skew  note:  Python  3.X  (but  not  2.X)  allows  ellipses  coded\\nas ... (literally, three consecutive dots) to appear any place an expres-\\nsion can. Because ellipses do nothing by themselves, this can serve as\\nan alternative to the pass statement, especially for code to be filled in\\nlater—a sort of Python “TBD”:\\n\\ndef func1():\\n    ...                   # Alternative to pass\\n\\ndef func2():\\n    ...\\n\\nfunc1()                   # Does nothing if called\\n\\nEllipses can also appear on the same line as a statement header and may\\nbe used to initialize variable names if no specific type is required:\\n\\ndef func1(): ...          # Works on same line too\\ndef func2(): ...\\n\\n390 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0c>>> X = ...               # Alternative to None\\n>>> X\\nEllipsis\\n\\nThis notation is new in Python 3.X—and goes well beyond the original\\nintent of ... in slicing extensions—so time will tell if it becomes wide-\\nspread enough to challenge pass and None in these roles.\\n\\ncontinue\\nThe continue statement causes an immediate jump to the top of a loop. It also some-\\ntimes lets you avoid statement nesting. The next example uses continue to skip odd\\nnumbers. This code prints all even numbers less than 10 and greater than or equal to\\n0. Remember, 0 means false and % is the remainder of division (modulus) operator, so\\nthis loop counts down to 0, skipping numbers that aren’t multiples of 2—it prints 8 6\\n4 2 0:\\n\\nx = 10\\nwhile x:\\n    x = x−1                        # Or, x -= 1\\n    if x % 2 != 0: continue        # Odd? -- skip print\\n    print(x, end=\\' \\')\\n\\nBecause continue jumps to the top of the loop, you don’t need to nest the print state-\\nment here inside an if test; the print is only reached if the continue is not run. If this\\nsounds similar to a “go to” in other languages, it should. Python has no “go to” state-\\nment, but because continue lets you jump about in a program, many of the warnings\\nabout readability and maintainability you may have heard about “go to” apply. con\\ntinue should probably be used sparingly, especially when you’re first getting started\\nwith Python. For instance, the last example might be clearer if the print were nested\\nunder the if:\\n\\nx = 10\\nwhile x:\\n    x = x−1\\n    if x % 2 == 0:                 # Even? -- print\\n        print(x, end=\\' \\')\\n\\nLater in this book, we’ll also learn that raised and caught exceptions can also emulate\\n“go to” statements in limited and structured ways; stay tuned for more on this technique\\nin Chapter 36 where we will learn how to use it to break out of multiple nested loops,\\na feat not possible with the next section’s topic alone.\\n\\nbreak\\nThe break statement causes an immediate exit from a loop. Because the code that fol-\\nlows it in the loop is not executed if the break is reached, you can also sometimes avoid\\nnesting by including a break. For example, here is a simple interactive loop (a variant\\n\\nbreak, continue, pass, and the Loop else | 391\\n\\n\\x0cof a larger example we studied in Chapter 10) that inputs data with input (known as\\nraw_input in Python 2.X) and exits when the user enters “stop” for the name request:\\n\\n>>> while True:\\n...     name = input(\\'Enter name:\\')           # Use raw_input() in 2.X\\n...     if name == \\'stop\\': break\\n...     age  = input(\\'Enter age: \\')\\n...     print(\\'Hello\\', name, \\'=>\\', int(age) ** 2)\\n...\\nEnter name:bob\\nEnter age: 40\\nHello bob => 1600\\nEnter name:sue\\nEnter age: 30\\nHello sue => 900\\nEnter name:stop\\n\\nNotice how this code converts the age input to an integer with int before raising it to\\nthe second power; as you’ll recall, this is necessary because input returns user input as\\na string. In Chapter 36, you’ll see that input also raises an exception at end-of-file (e.g.,\\nif the user types Ctrl-Z on Windows or Ctrl-D on Unix); if this matters, wrap input in\\ntry statements.\\n\\nLoop else\\nWhen combined with the loop else clause, the break statement can often eliminate the\\nneed for the search status flags used in other languages. For instance, the following\\npiece of code determines whether a positive integer y is prime by searching for factors\\ngreater than 1:\\n\\nx = y // 2                                # For some y > 1\\nwhile x > 1:\\n    if y % x == 0:                        # Remainder\\n        print(y, \\'has factor\\', x)\\n        break                             # Skip else\\n    x -= 1\\nelse:                                     # Normal exit\\n    print(y, \\'is prime\\')\\n\\nRather than setting a flag to be tested when the loop is exited, it inserts a break where\\na factor is found. This way, the loop else clause can assume that it will be executed\\nonly if no factor is found; if you don’t hit the break, the number is prime. Trace through\\nthis code to see how this works.\\nThe loop else clause is also run if the body of the loop is never executed, as you don’t\\nrun a break in that event either; in a while loop, this happens if the test in the header\\nis false to begin with. Thus, in the preceding example you still get the “is prime” message\\nif x is initially less than or equal to 1 (for instance, if y is 2).\\n\\n392 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cThis example determines primes, but only informally so. Numbers less\\nthan 2 are not considered prime by the strict mathematical definition.\\nTo be really picky, this code also fails for negative numbers and succeeds\\nfor floating-point numbers with no decimal digits. Also note that its\\ncode must use // instead of / in Python 3.X because of the migration\\nof / to “true division,” as described in Chapter 5 (we need the initial\\ndivision to truncate remainders, not retain them!). If you want to ex-\\nperiment  with  this  code,  be  sure  to  see  the  exercise  at  the  end  of\\nPart IV, which wraps it in a function for reuse.\\n\\nMore on the loop else\\nBecause the loop else clause is unique to Python, it tends to perplex some newcomers\\n(and go unused by some veterans; I’ve met some who didn’t even know there was an\\nelse on loops!). In general terms, the loop else simply provides explicit syntax for a\\ncommon coding scenario—it is a coding structure that lets us catch the “other” way\\nout of a loop, without setting and checking flags or conditions.\\nSuppose, for instance, that we are writing a loop to search a list for a value, and we\\nneed to know whether the value was found after we exit the loop. We might code such\\na task this way (this code is intentionally abstract and incomplete; x is a sequence and\\nmatch is a tester function to be defined):\\n\\nfound = False\\nwhile x and not found:\\n    if match(x[0]):                  # Value at front?\\n        print(\\'Ni\\')\\n        found = True\\n    else:\\n        x = x[1:]                    # Slice off front and repeat\\nif not found:\\n    print(\\'not found\\')\\n\\nHere, we initialize, set, and later test a flag to determine whether the search succeeded\\nor not. This is valid Python code, and it does work; however, this is exactly the sort of\\nstructure that the loop else clause is there to handle. Here’s an else equivalent:\\n\\nwhile x:                             # Exit when x empty\\n    if match(x[0]):\\n        print(\\'Ni\\')\\n        break                        # Exit, go around else\\n    x = x[1:]\\nelse:\\n    print(\\'Not found\\')               # Only here if exhausted x\\n\\nThis version is more concise. The flag is gone, and we’ve replaced the if test at the loop\\nend with an else (lined up vertically with the word while). Because the break inside the\\nmain part of the while exits the loop and goes around the else, this serves as a more\\nstructured way to catch the search-failure case.\\n\\nbreak, continue, pass, and the Loop else | 393\\n\\n\\x0cSome readers might have noticed that the prior example’s else clause could be replaced\\nwith a test for an empty x after the loop (e.g., if not x:). Although that’s true in this\\nexample, the else provides explicit syntax for this coding pattern (it’s more obviously\\na search-failure clause here), and such an explicit empty test may not apply in some\\ncases. The loop else becomes even more useful when used in conjunction with the\\nfor loop—the topic of the next section—because sequence iteration is not under your \\ncontrol.\\n\\nWhy You Will Care: Emulating C while Loops\\n\\nThe section on expression statements in Chapter 11 stated that Python doesn’t allow\\nstatements such as assignments to appear in places where it expects an expression. That\\nis, each statement must generally appear on a line by itself, not nested in a larger con-\\nstruct. That means this common C language coding pattern won’t work in Python:\\n\\nwhile ((x = next(obj)) != NULL) {...process x...}\\n\\nC assignments return the value assigned, but Python assignments are just statements,\\nnot expressions. This eliminates a notorious class of C errors: you can’t accidentally\\ntype = in Python when you mean ==. If you need similar behavior, though, there are at\\nleast three ways to get the same effect in Python while loops without embedding as-\\nsignments in loop tests. You can move the assignment into the loop body with a break:\\n\\nwhile True:\\n    x = next(obj)\\n    if not x: break\\n    ...process x...\\n\\nor move the assignment into the loop with tests:\\n\\nx = True\\nwhile x:\\n    x = next(obj)\\n    if x:\\n        ...process x...\\n\\nor move the first assignment outside the loop:\\n\\nx = next(obj)\\nwhile x:\\n    ...process x...\\n    x = next(obj)\\n\\nOf these three coding patterns, the first may be considered by some to be the least\\nstructured, but it also seems to be the simplest and is the most commonly used. A simple\\nPython for loop may replace such C loops as well and be more Pythonic, but C doesn’t\\nhave a directly analogous tool:\\n\\nfor x in obj: ...process x...\\n\\n394 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cfor Loops\\nThe for loop is a generic iterator in Python: it can step through the items in any ordered\\nsequence or other iterable object. The for statement works on strings, lists, tuples, and\\nother built-in iterables, as well as new user-defined objects that we’ll learn how to create\\nlater with classes. We met for briefly in Chapter 4 and in conjunction with sequence\\nobject types; let’s expand on its usage more formally here.\\n\\nGeneral Format\\nThe Python for loop begins with a header line that specifies an assignment target (or\\ntargets), along with the object you want to step through. The header is followed by a\\nblock of (normally indented) statements that you want to repeat:\\nfor target in object:                 # Assign object items to target\\n    statements                        # Repeated loop body: use target\\nelse:                                 # Optional else part\\n    statements                        # If we didn\\'t hit a \\'break\\'\\n\\nWhen Python runs a for loop, it assigns the items in the iterable object to the target\\none by one and executes the loop body for each. The loop body typically uses the\\nassignment target to refer to the current item in the sequence as though it were a cursor\\nstepping through the sequence.\\nThe name used as the assignment target in a for header line is usually a (possibly new)\\nvariable in the scope where the for statement is coded. There’s not much unique about\\nthis name; it can even be changed inside the loop’s body, but it will automatically be\\nset to the next item in the sequence when control returns to the top of the loop again.\\nAfter the loop this variable normally still refers to the last item visited, which is the last\\nitem in the sequence unless the loop exits with a break statement.\\nThe for statement also supports an optional else block, which works exactly as it does\\nin a while loop—it’s executed if the loop exits without running into a break statement\\n(i.e., if all items in the sequence have been visited). The break and continue statements\\nintroduced earlier also work the same in a for loop as they do in a while. The for loop’s\\ncomplete format can be described this way:\\n\\nfor target in object:                 # Assign object items to target\\n    statements\\n    if test: break                    # Exit loop now, skip else\\n    if test: continue                 # Go to top of loop now\\nelse:\\n    statements                        # If we didn\\'t hit a \\'break\\'\\n\\nExamples\\nLet’s type a few for loops interactively now, so you can see how they are used in practice.\\n\\nfor Loops\\n\\n| 395\\n\\n\\x0cBasic usage\\nAs mentioned earlier, a for loop can step across any kind of sequence object. In our\\nfirst example, for instance, we’ll assign the name x to each of the three items in a list in\\nturn, from left to right, and the print statement will be executed for each. Inside the\\nprint statement (the loop body), the name x refers to the current item in the list:\\n\\n>>> for x in [\"spam\", \"eggs\", \"ham\"]:\\n...     print(x, end=\\' \\')\\n...\\nspam eggs ham\\n\\nThe next two examples compute the sum and product of all the items in a list. Later in\\nthis chapter and later in the book we’ll meet tools that apply operations such as + and\\n* to items in a list automatically, but it’s often just as easy to use a for:\\n\\n>>> sum = 0\\n>>> for x in [1, 2, 3, 4]:\\n...     sum = sum + x\\n...\\n>>> sum\\n10\\n>>> prod = 1\\n>>> for item in [1, 2, 3, 4]: prod *= item\\n...\\n>>> prod\\n24\\n\\nOther data types\\nAny sequence works in a for, as it’s a generic tool. For example, for loops work on\\nstrings and tuples:\\n\\n>>> S = \"lumberjack\"\\n>>> T = (\"and\", \"I\\'m\", \"okay\")\\n\\n>>> for x in S: print(x, end=\\' \\')     # Iterate over a string\\n...\\nl u m b e r j a c k\\n\\n>>> for x in T: print(x, end=\\' \\')     # Iterate over a tuple\\n...\\nand I\\'m okay\\n\\nIn fact, as we’ll learn in the next chapter when we explore the notion of “iterables,”\\nfor loops can even work on some objects that are not sequences—files and dictionaries\\nwork, too.\\n\\nTuple assignment in for loops\\nIf you’re iterating through a sequence of tuples, the loop target itself can actually be a\\ntuple of targets. This is just another case of the tuple-unpacking assignment we studied\\n\\n396 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cin Chapter 11 at work. Remember, the for loop assigns items in the sequence object\\nto the target, and assignment works the same everywhere:\\n\\n>>> T = [(1, 2), (3, 4), (5, 6)]\\n>>> for (a, b) in T:                   # Tuple assignment at work\\n...     print(a, b)\\n...\\n1 2\\n3 4\\n5 6\\n\\nHere, the first time through the loop is like writing (a,b) = (1,2), the second time is\\nlike writing (a,b) = (3,4), and so on. The net effect is to automatically unpack the\\ncurrent tuple on each iteration.\\nThis form is commonly used in conjunction with the zip call we’ll meet later in this\\nchapter to implement parallel traversals. It also makes regular appearances in conjunc-\\ntion with SQL databases in Python, where query result tables are returned as sequences\\nof sequences like the list used here—the outer list is the database table, the nested tuples\\nare the rows within the table, and tuple assignment extracts columns.\\nTuples  in  for  loops  also  come  in  handy  to  iterate  through  both  keys  and  values  in\\ndictionaries using the items method, rather than looping through the keys and indexing\\nto fetch the values manually:\\n\\n>>> D = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> for key in D:\\n...    print(key, \\'=>\\', D[key])             # Use dict keys iterator and index\\n...\\na => 1\\nc => 3\\nb => 2\\n\\n>>> list(D.items())\\n[(\\'a\\', 1), (\\'c\\', 3), (\\'b\\', 2)]\\n\\n>>> for (key, value) in D.items():\\n...    print(key, \\'=>\\', value)              # Iterate over both keys and values\\n...\\na => 1\\nc => 3\\nb => 2\\n\\nIt’s important to note that tuple assignment in for loops isn’t a special case; any as-\\nsignment target works syntactically after the word for. We can always assign manually\\nwithin the loop to unpack:\\n\\n>>> T\\n[(1, 2), (3, 4), (5, 6)]\\n\\n>>> for both in T:\\n...     a, b = both                         # Manual assignment equivalent\\n...     print(a, b)                         # 2.X: prints with enclosing tuple \"()\"\\n...\\n\\nfor Loops\\n\\n| 397\\n\\n\\x0c1 2\\n3 4\\n5 6\\n\\nBut tuples in the loop header save us an extra step when iterating through sequences\\nof sequences. As suggested in Chapter 11, even nested structures may be automatically\\nunpacked this way in a for:\\n\\n>>> ((a, b), c) = ((1, 2), 3)               # Nested sequences work too\\n>>> a, b, c\\n(1, 2, 3)\\n\\n>>> for ((a, b), c) in [((1, 2), 3), ((4, 5), 6)]: print(a, b, c)\\n...\\n1 2 3\\n4 5 6\\n\\nEven this is not a special case, though—the for loop simply runs the sort of assignment\\nwe ran just before it, on each iteration. Any nested sequence structure may be unpacked\\nthis way, simply because sequence assignment is so generic:\\n\\n>>> for ((a, b), c) in [([1, 2], 3), [\\'XY\\', 6]]: print(a, b, c)\\n...\\n1 2 3\\nX Y 6\\n\\nPython 3.X extended sequence assignment in for loops\\nIn fact, because the loop variable in a for loop can be any assignment target, we can\\nalso use Python 3.X’s extended sequence-unpacking assignment syntax here to extract\\nitems and sections of sequences within sequences. Really, this isn’t a special case either,\\nbut simply a new assignment form in 3.X, as discussed in Chapter 11; because it works\\nin assignment statements, it automatically works in for loops.\\nConsider the tuple assignment form introduced in the prior section. A tuple of values\\nis assigned to a tuple of names on each iteration, exactly like a simple assignment state-\\nment:\\n\\n>>> a, b, c = (1, 2, 3)                               # Tuple assignment\\n>>> a, b, c\\n(1, 2, 3)\\n\\n>>> for (a, b, c) in [(1, 2, 3), (4, 5, 6)]:          # Used in for loop\\n...     print(a, b, c)\\n...\\n1 2 3\\n4 5 6\\n\\nIn Python 3.X, because a sequence can be assigned to a more general set of names with\\na starred name to collect multiple items, we can use the same syntax to extract parts of\\nnested sequences in the for loop:\\n\\n>>> a, *b, c = (1, 2, 3, 4)                           # Extended seq assignment\\n>>> a, b, c\\n\\n398 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0c(1, [2, 3], 4)\\n\\n>>> for (a, *b, c) in [(1, 2, 3, 4), (5, 6, 7, 8)]:\\n...     print(a, b, c)\\n...\\n1 [2, 3] 4\\n5 [6, 7] 8\\n\\nIn practice, this approach might be used to pick out multiple columns from rows of\\ndata represented as nested sequences. In Python 2.X starred names aren’t allowed, but\\nyou can achieve similar effects by slicing. The only difference is that slicing returns a\\ntype-specific result, whereas starred names always are assigned lists:\\n\\n>>> for all in [(1, 2, 3, 4), (5, 6, 7, 8)]:          # Manual slicing in 2.X\\n...     a, b, c = all[0], all[1:3], all[3]\\n...     print(a, b, c)\\n...\\n1 (2, 3) 4\\n5 (6, 7) 8\\n\\nSee Chapter 11 for more on this assignment form.\\n\\nNested for loops\\nNow let’s look at a for loop that’s a bit more sophisticated than those we’ve seen so\\nfar. The next example illustrates statement nesting and the loop else clause in a for.\\nGiven a list of objects (items) and a list of keys (tests), this code searches for each key\\nin the objects list and reports on the search’s outcome:\\n\\n>>> items = [\"aaa\", 111, (4, 5), 2.01]      # A set of objects\\n>>> tests = [(4, 5), 3.14]                  # Keys to search for\\n>>>\\n>>> for key in tests:                       # For all keys\\n...     for item in items:                  # For all items\\n...         if item == key:                 # Check for match\\n...             print(key, \"was found\")\\n...             break\\n...     else:\\n...         print(key, \"not found!\")\\n...\\n(4, 5) was found\\n3.14 not found!\\n\\nBecause the nested if runs a break when a match is found, the loop else clause can\\nassume that if it is reached, the search has failed. Notice the nesting here. When this\\ncode runs, there are two loops going at the same time: the outer loop scans the keys\\nlist, and the inner loop scans the items list for each key. The nesting of the loop else\\nclause is critical; it’s indented to the same level as the header line of the inner for loop,\\nso it’s associated with the inner loop, not the if or the outer for.\\nThis example is illustrative, but it may be easier to code if we employ the in operator\\nto test membership. Because in implicitly scans an object looking for a match (at least\\nlogically), it replaces the inner loop:\\n\\nfor Loops\\n\\n| 399\\n\\n\\x0c>>> for key in tests:                       # For all keys\\n...     if key in items:                    # Let Python check for a match\\n...         print(key, \"was found\")\\n...     else:\\n...         print(key, \"not found!\")\\n...\\n(4, 5) was found\\n3.14 not found!\\n\\nIn general, it’s a good idea to let Python do as much of the work as possible (as in this\\nsolution) for the sake of brevity and performance.\\nThe next example is similar, but builds a list as it goes for later use instead of printing.\\nIt performs a typical data-structure task with a for—collecting common items in two\\nsequences (strings)—and serves as a rough set intersection routine. After the loop runs,\\nres refers to a list that contains all the items found in seq1 and seq2:\\n\\n>>> seq1 = \"spam\"\\n>>> seq2 = \"scam\"\\n>>>\\n>>> res = []                                # Start empty\\n>>> for x in seq1:                          # Scan first sequence\\n...     if x in seq2:                       # Common item?\\n...         res.append(x)                   # Add to result end\\n...\\n>>> res\\n[\\'s\\', \\'a\\', \\'m\\']\\n\\nUnfortunately, this code is equipped to work only on two specific variables: seq1 and\\nseq2. It would be nice if this loop could somehow be generalized into a tool you could\\nuse more than once. As you’ll see, that simple idea leads us to functions, the topic of\\nthe next part of the book.\\nThis code also exhibits the classic list comprehension pattern—collecting a results list\\nwith an iteration and optional filter test—and could be coded more concisely too:\\n\\n>>> [x for x in seq1 if x in seq2]          # Let Python collect results\\n[\\'s\\', \\'a\\', \\'m\\']\\n\\nBut you’ll have to read on to the next chapter for the rest of this story.\\n\\nWhy You Will Care: File Scanners\\n\\nIn general, loops come in handy anywhere you need to repeat an operation or process\\nsomething more than once. Because files contain multiple characters and lines, they are\\none of the more typical use cases for loops. To load a file’s contents into a string all at\\nonce, you simply call the file object’s read method:\\n\\nfile = open(\\'test.txt\\', \\'r\\')    # Read contents into a string\\nprint(file.read())\\n\\nBut to load a file in smaller pieces, it’s common to code either a while loop with breaks\\non end-of-file, or a for loop. To read by characters, either of the following codings will\\nsuffice:\\n\\n400 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cfile = open(\\'test.txt\\')\\nwhile True:\\n    char = file.read(1)         # Read by character\\n    if not char: break          # Empty string means end-of-file\\n    print(char)\\n\\nfor char in open(\\'test.txt\\').read():\\n    print(char)\\n\\nThe for loop here also processes each character, but it loads the file into memory all at\\nonce (and assumes it fits!). To read by lines or blocks instead, you can use while loop\\ncode like this:\\n\\nfile = open(\\'test.txt\\')\\nwhile True:\\n    line = file.readline()      # Read line by line\\n    if not line: break\\n    print(line.rstrip())        # Line already has a \\\\n\\n\\nfile = open(\\'test.txt\\', \\'rb\\')\\nwhile True:\\n    chunk = file.read(10)       # Read byte chunks: up to 10 bytes\\n    if not chunk: break\\n    print(chunk)\\n\\nYou typically read binary data in blocks. To read text files line by line, though, the\\nfor loop tends to be easiest to code and the quickest to run:\\n\\nfor line in open(\\'test.txt\\').readlines():\\n    print(line.rstrip())\\n\\nfor line in open(\\'test.txt\\'):   # Use iterators: best for text input\\n    print(line.rstrip())\\n\\nBoth of these versions work in both Python 2.X and 3.X. The first uses the file read\\nlines method to load a file all at once into a line-string list, and the last example here\\nrelies on file iterators to automatically read one line on each loop iteration.\\n\\nThe last example is also generally the best option for text files—besides its simplicity,\\nit works for arbitrarily large files because it doesn’t load the entire file into memory all\\nat once. The iterator version may also be the quickest, though I/O performance may\\nvary per Python line and release.\\nFile readlines calls can still be useful, though—to reverse a file’s lines, for example,\\nassuming its content can fit in memory. The reversed built-in accepts a sequence, but\\nnot an arbitrary iterable that generates values; in other words, a list works, but a file\\nobject doesn’t:\\n\\nfor line in reversed(open(\\'test.txt\\').readlines()): ...\\n\\nIn some 2.X Python code, you may also see the name open replaced with file and the\\nfile object’s older xreadlines method used to achieve the same effect as the file’s auto-\\nmatic line iterator (it’s like readlines but doesn’t load the file into memory all at once).\\nBoth file and xreadlines are removed in Python 3.X, because they are redundant. You\\nshould generally avoid them in new 2.X code too—use file iterators and open call in\\nrecent 2.X releases—but they may pop up in older code and resources.\\n\\nfor Loops\\n\\n| 401\\n\\n\\x0cSee the library manual for more on the calls used here, and Chapter 14 for more on file\\nline iterators. Also watch for the sidebar “Why You Will Care: Shell Commands and\\nMore”  on  page  411  in  this  chapter;  it  applies  these  same  file  tools  to  the  os.popen\\ncommand-line  launcher  to  read  program  output.  There’s  more  on  reading  files  in\\nChapter 37 too; as we’ll see there, text and binary files have slightly different semantics\\nin 3.X.\\n\\nLoop Coding Techniques\\nThe for loop we just studied subsumes most counter-style loops. It’s generally simpler\\nto code and often quicker to run than a while, so it’s the first tool you should reach for\\nwhenever you need to step through a sequence or other iterable. In fact, as a general\\nrule, you should resist the temptation to count things in Python—its iteration tools au-\\ntomate much of the work you do to loop over collections in lower-level languages like\\nC.\\nStill, there are situations where you will need to iterate in more specialized ways. For\\nexample, what if you need to visit every second or third item in a list, or change the list\\nalong the way? How about traversing more than one sequence in parallel, in the same\\nfor loop? What if you need indexes too?\\nYou can always code such unique iterations with a while loop and manual indexing,\\nbut Python provides a set of built-ins that allow you to specialize the iteration in a for:\\n\\n• The built-in range function (available since Python 0.X) produces a series of suc-\\n\\ncessively higher integers, which can be used as indexes in a for.\\n\\n• The built-in zip function (available since Python 2.0) returns a series of parallel-\\n\\nitem tuples, which can be used to traverse multiple sequences in a for.\\n\\n• The built-in enumerate function (available since Python 2.3) generates both the\\n\\nvalues and indexes of items in an iterable, so we don’t need to count manually.\\n\\n• The built-in map function (available since Python 1.0) can have a similar effect to\\n\\nzip in Python 2.X, though this role is removed in 3.X.\\n\\nBecause for loops may run quicker than while-based counter loops, though, it’s to your\\nadvantage to use tools like these that allow you to use for whenever possible. Let’s look\\nat each of these built-ins in turn, in the context of common use cases. As we’ll see, their\\nusage may differ slightly between 2.X and 3.X, and some of their applications are more\\nvalid than others.\\n\\nCounter Loops: range\\nOur first loop-related function, range, is  really a general tool that can be used in a\\nvariety of contexts. We met it briefly in Chapter 4. Although it’s used most often to\\ngenerate indexes in a for, you can use it anywhere you need a series of integers. In\\n\\n402 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cPython 2.X range creates a physical list; in 3.X, range is an iterable that generates items\\non demand, so we need to wrap it in a list call to display its results all at once in 3.X\\nonly:\\n\\n>>> list(range(5)), list(range(2, 5)), list(range(0, 10, 2))\\n([0, 1, 2, 3, 4], [2, 3, 4], [0, 2, 4, 6, 8])\\n\\nWith one argument, range generates a list of integers from zero up to but not including\\nthe argument’s value. If you pass in two arguments, the first is taken as the lower bound.\\nAn optional third argument can give a step; if it is used, Python adds the step to each\\nsuccessive integer in the result (the step defaults to +1). Ranges can also be nonpositive\\nand nonascending, if you want them to be:\\n\\n>>> list(range(−5, 5))\\n[−5, −4, −3, −2, −1, 0, 1, 2, 3, 4]\\n\\n>>> list(range(5, −5, −1))\\n[5, 4, 3, 2, 1, 0, −1, −2, −3, −4]\\n\\nWe’ll get more formal about iterables like this one in Chapter 14. There, we’ll also see\\nthat Python 2.X has a cousin named xrange, which is like its range but doesn’t build\\nthe result list in memory all at once. This is a space optimization, which is subsumed\\nin 3.X by the generator behavior of its range.\\nAlthough such range results may be useful all by themselves, they tend to come in most\\nhandy within for loops. For one thing, they provide a simple way to repeat an action\\na specific number of times. To print three lines, for example, use a range to generate\\nthe appropriate number of integers:\\n\\n>>> for i in range(3):\\n...     print(i, \\'Pythons\\')\\n...\\n0 Pythons\\n1 Pythons\\n2 Pythons\\n\\nNote that for loops force results from range automatically in 3.X, so we don’t need to\\nuse a list wrapper here in 3.X (in 2.X we get a temporary list unless we call xrange\\ninstead).\\n\\nSequence Scans: while and range Versus for\\nThe range call is also sometimes used to iterate over a sequence indirectly, though it’s\\noften not the best approach in this role. The easiest and generally fastest way to step\\nthrough a sequence exhaustively is always with a simple for, as Python handles most\\nof the details for you:\\n\\n>>> X = \\'spam\\'\\n>>> for item in X: print(item, end=\\' \\')           # Simple iteration\\n...\\ns p a m\\n\\nLoop Coding Techniques\\n\\n| 403\\n\\n\\x0cInternally, the for loop handles the details of the iteration automatically when used\\nthis way. If you really need to take over the indexing logic explicitly, you can do it with\\na while loop:\\n>>> i = 0\\n>>> while i < len(X):                             # while loop iteration\\n...     print(X[i], end=\\' \\')\\n...     i += 1\\n...\\ns p a m\\n\\nYou can also do manual indexing with a for, though, if you use range to generate a list\\nof indexes to iterate through. It’s a multistep process, but it’s sufficient to generate\\noffsets, rather than the items at those offsets:\\n\\n>>> X\\n\\'spam\\'\\n>>> len(X)                                        # Length of string\\n4\\n>>> list(range(len(X)))                           # All legal offsets into X\\n[0, 1, 2, 3]\\n>>>\\n>>> for i in range(len(X)): print(X[i], end=\\' \\')  # Manual range/len iteration\\n...\\ns p a m\\n\\nNote that because this example is stepping over a list of offsets into X, not the actual\\nitems of X, we need to index back into X within the loop to fetch each item. If this seems\\nlike overkill, though, it’s because it is: there’s really no reason to work this hard in this\\nexample.\\nAlthough the range/len combination suffices in this role, it’s probably not the best\\noption. It may run slower, and it’s also more work than we need to do. Unless you have\\na special indexing requirement, you’re better off using the simple  for loop form in\\nPython:\\n\\n>>> for item in X: print(item, end=\\' \\')           # Use simple iteration if you can\\n\\nAs a general rule, use for instead of while whenever possible, and don’t use range calls\\nin for loops except as a last resort. This simpler solution is almost always better. Like\\nevery good rule, though, there are plenty of exceptions—as the next section demon-\\nstrates.\\n\\nSequence Shufflers: range and len\\nThough not ideal for simple sequence scans, the coding pattern used in the prior ex-\\nample does allow us to do more specialized sorts of traversals when required. For ex-\\nample, some algorithms can make use of sequence reordering—to generate alternatives\\nin searches, to test the effect of different value orderings, and so on. Such cases may\\nrequire offsets in order to pull sequences apart and put them back together, as in the\\n\\n404 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cfollowing; the range’s integers provide a repeat count in the first, and a position for\\nslicing in the second:\\n\\n>>> S = \\'spam\\'\\n>>> for i in range(len(S)):       # For repeat counts 0..3\\n...     S = S[1:] + S[:1]         # Move front item to end\\n...     print(S, end=\\' \\')\\n...\\npams amsp mspa spam\\n\\n>>> S\\n\\'spam\\'\\n>>> for i in range(len(S)):       # For positions 0..3\\n...     X = S[i:] + S[:i]         # Rear part + front part\\n...     print(X, end=\\' \\')\\n...\\nspam pams amsp mspa\\n\\nTrace through these one iteration at a time if they seem confusing. The second creates\\nthe same results as the first, though in a different order, and doesn’t change the original\\nvariable as it goes. Because both slice to obtain parts to concatenate, they also work on\\nany type of sequence, and return sequences of the same type as that being shuffled—\\nif you shuffle a list, you create reordered lists:\\n\\n>>> L = [1, 2, 3]\\n>>> for i in range(len(L)):\\n...     X = L[i:] + L[:i]         # Works on any sequence type\\n...     print(X, end=\\' \\')\\n...\\n[1, 2, 3] [2, 3, 1] [3, 1, 2]\\n\\nWe’ll make use of code like this to test functions with different argument orderings in\\nChapter 18, and will extend it to functions, generators, and more complete permuta-\\ntions in Chapter 20—it’s a widely useful tool.\\n\\nNonexhaustive Traversals: range Versus Slices\\nCases like that of the prior section are valid applications for the range/len combination.\\nWe might also use this technique to skip items as we go:\\n\\n>>> S = \\'abcdefghijk\\'\\n>>> list(range(0, len(S), 2))\\n[0, 2, 4, 6, 8, 10]\\n\\n>>> for i in range(0, len(S), 2): print(S[i], end=\\' \\')\\n...\\na c e g i k\\n\\nHere, we visit every second item in the string S by stepping over the generated range\\nlist. To visit every third item, change the third range argument to be 3, and so on. In\\neffect, using range this way lets you skip items in loops while still retaining the simplicity\\nof the for loop construct.\\n\\nLoop Coding Techniques\\n\\n| 405\\n\\n\\x0cIn most cases, though, this is also probably not the “best practice” technique in Python\\ntoday. If you really mean to skip items in a sequence, the extended three-limit form of\\nthe slice expression, presented in Chapter 7, provides a simpler route to the same goal.\\nTo visit every second character in S, for example, slice with a stride of 2:\\n\\n>>> S = \\'abcdefghijk\\'\\n>>> for c in S[::2]: print(c, end=\\' \\')\\n...\\na c e g i k\\n\\nThe result is the same, but substantially easier for you to write and for others to read.\\nThe potential advantage to using range here instead is space: slicing makes a copy of\\nthe string in both 2.X and 3.X, while range in 3.X and xrange in 2.X do not create a list;\\nfor very large strings, they may save memory.\\n\\nChanging Lists: range Versus Comprehensions\\nAnother common place where you may use the range/len combination with for is in\\nloops that change a list as it is being traversed. Suppose, for example, that you need to\\nadd  1  to  every  item  in  a  list  (maybe  you’re  giving  everyone  a  raise  in  an  employee\\ndatabase list). You can try this with a simple for loop, but the result probably won’t\\nbe exactly what you want:\\n>>> L = [1, 2, 3, 4, 5]\\n\\n>>> for x in L:\\n...     x += 1                       # Changes x, not L\\n...\\n>>> L\\n[1, 2, 3, 4, 5]\\n>>> x\\n6\\n\\nThis doesn’t quite work—it changes the loop variable x, not the list L. The reason is\\nsomewhat subtle. Each time through the loop, x refers to the next integer already pulled\\nout of the list. In the first iteration, for example, x is integer 1. In the next iteration, the\\nloop body sets x to a different object, integer 2, but it does not update the list where 1\\noriginally came from; it’s a piece of memory separate from the list.\\nTo really change the list as we march across it, we need to use indexes so we can assign\\nan updated value to each position as we go. The range/len combination can produce\\nthe required indexes for us:\\n>>> L = [1, 2, 3, 4, 5]\\n\\n>>> for i in range(len(L)):          # Add one to each item in L\\n...     L[i] += 1                    # Or L[i] = L[i] + 1\\n...\\n>>> L\\n[2, 3, 4, 5, 6]\\n\\n406 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cWhen coded this way, the list is changed as we proceed through the loop. There is no\\nway to do the same with a simple for x in L:–style loop, because such a loop iterates\\nthrough actual items, not list positions. But what about the equivalent while loop? Such\\na loop requires a bit more work on our part, and might run more slowly depending on\\nyour Python (it does on 2.7 and 3.3, though less so on 3.3—we’ll see how to verify this\\nin Chapter 21):\\n\\n>>> i = 0\\n>>> while i < len(L):\\n...     L[i] += 1\\n...     i += 1\\n...\\n>>> L\\n[3, 4, 5, 6, 7]\\n\\nHere again, though, the range solution may not be ideal either. A list comprehension\\nexpression of the form:\\n\\n[x + 1 for x in L]\\n\\nlikely runs faster today and would do similar work, albeit without changing the original\\nlist in place (we could assign the expression’s new list object result back to L, but this\\nwould not update any other references to the original list). Because this is such a central\\nlooping concept, we’ll save a complete exploration of list comprehensions for the next\\nchapter, and continue this story there.\\n\\nParallel Traversals: zip and map\\nOur next loop coding technique extends a loop’s scope. As we’ve seen, the range built-\\nin allows us to traverse sequences with for in a nonexhaustive fashion. In the same\\nspirit, the built-in zip function allows us to use for loops to visit multiple sequences\\nin parallel—not overlapping in time, but during the same loop. In basic operation,\\nzip takes one or more sequences as arguments and returns a series of tuples that pair\\nup parallel items taken from those sequences. For example, suppose we’re working\\nwith two lists (a list of names and addresses paired by position, perhaps):\\n\\n>>> L1 = [1,2,3,4]\\n>>> L2 = [5,6,7,8]\\n\\nTo combine the items in these lists, we can use zip to create a list of tuple pairs. Like\\nrange, zip is a list in Python 2.X, but an iterable object in 3.X where we must wrap it\\nin a list call to display all its results at once (again, there’s more on iterables coming\\nup in the next chapter):\\n\\n>>> zip(L1, L2)\\n<zip object at 0x026523C8>\\n>>> list(zip(L1, L2))                       # list() required in 3.X, not 2.X\\n[(1, 5), (2, 6), (3, 7), (4, 8)]\\n\\nSuch a result may be useful in other contexts as well, but when wedded with the for\\nloop, it supports parallel iterations:\\n\\nLoop Coding Techniques\\n\\n| 407\\n\\n\\x0c>>> for (x, y) in zip(L1, L2):\\n...     print(x, y, \\'--\\', x+y)\\n...\\n1 5 -- 6\\n2 6 -- 8\\n3 7 -- 10\\n4 8 -- 12\\n\\nHere, we step over the result of the zip call—that is, the pairs of items pulled from the\\ntwo lists. Notice that this for loop again uses the tuple assignment form we met earlier\\nto unpack each tuple in the zip result. The first time through, it’s as though we ran the\\nassignment statement (x, y) = (1, 5).\\nThe net effect is that we scan both L1 and L2 in our loop. We could achieve a similar\\neffect with a while loop that handles indexing manually, but it would require more\\ntyping and would likely run more slowly than the for/zip approach.\\nStrictly speaking, the zip function is more general than this example suggests. For in-\\nstance, it accepts any type of sequence (really, any iterable object, including files), and\\nit accepts more than two arguments. With three arguments, as in the following exam-\\nple, it builds a list of three-item tuples with items from each sequence, essentially pro-\\njecting by columns (technically, we get an N-ary tuple for N arguments):\\n\\n>>> T1, T2, T3 = (1,2,3), (4,5,6), (7,8,9)\\n>>> T3\\n(7, 8, 9)\\n>>> list(zip(T1, T2, T3))                   # Three tuples for three arguments\\n[(1, 4, 7), (2, 5, 8), (3, 6, 9)]\\n\\nMoreover, zip truncates result tuples at the length of the shortest sequence when the\\nargument lengths differ. In the following, we zip together two strings to pick out char-\\nacters in parallel, but the result has only as many tuples as the length of the shortest\\nsequence:\\n\\n>>> S1 = \\'abc\\'\\n>>> S2 = \\'xyz123\\'\\n>>>\\n>>> list(zip(S1, S2))                       # Truncates at len(shortest)\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\')]\\n\\nmap equivalence in Python 2.X\\nIn Python 2.X only, the related built-in map function pairs items from sequences in a\\nsimilar fashion when passed  None for its function argument, but it pads shorter se-\\nquences with None if the argument lengths differ instead of truncating to the shortest\\nlength:\\n\\n>>> S1 = \\'abc\\'\\n>>> S2 = \\'xyz123\\'\\n\\n>>> map(None, S1, S2)                        # 2.X only: pads to len(longest)\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\'), (None, \\'1\\'), (None, \\'2\\'), (None,\\'3\\')]\\n\\n408 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cThis example is using a degenerate form of the map built-in, which is no longer supported\\nin 3.X. Normally, map takes a function and one or more sequence arguments and collects\\nthe results of calling the function with parallel items taken from the sequence(s).\\nWe’ll study map in detail in Chapter 19 and Chapter 20, but as a brief example, the\\nfollowing maps the built-in ord function across each item in a string and collects the\\nresults (like zip, map is a value generator in 3.X and so must be passed to list to collect\\nall its results at once in 3.X only):\\n\\n>>> list(map(ord, \\'spam\\'))\\n[115, 112, 97, 109]\\n\\nThis  works  the  same  as  the  following  loop  statement,  but  map  is  often  quicker,  as\\nChapter 21 will show:\\n\\n>>> res = []\\n>>> for c in \\'spam\\': res.append(ord(c))\\n>>> res\\n[115, 112, 97, 109]\\n\\nVersion skew note: The degenerate form of map using a function argu-\\nment of None is no longer supported in Python 3.X, because it largely\\noverlaps with zip (and was, frankly, a bit at odds with map’s function-\\napplication purpose). In 3.X, either use zip or write loop code to pad\\nresults yourself. In fact, we’ll see how to write such loop code in Chap-\\nter 20, after we’ve had a chance to study some additional iteration con-\\ncepts.\\n\\nDictionary construction with zip\\nLet’s look at another zip use case. Chapter 8 suggested that the zip call used here can\\nalso be handy for generating dictionaries when the sets of keys and values must be\\ncomputed at runtime. Now that we’re becoming proficient with zip, let’s explore more\\nfully how it relates to dictionary construction. As you’ve learned, you can always create\\na dictionary by coding a dictionary literal, or by assigning to keys over time:\\n\\n>>> D1 = {\\'spam\\':1, \\'eggs\\':3, \\'toast\\':5}\\n>>> D1\\n{\\'eggs\\': 3, \\'toast\\': 5, \\'spam\\': 1}\\n\\n>>> D1 = {}\\n>>> D1[\\'spam\\']  = 1\\n>>> D1[\\'eggs\\']  = 3\\n>>> D1[\\'toast\\'] = 5\\n\\nWhat  to  do,  though,  if  your  program  obtains  dictionary  keys  and  values  in  lists  at\\nruntime, after you’ve coded your script? For example, say you had the following keys\\nand values lists, collected from a user, parsed from a file, or obtained from another\\ndynamic source:\\n\\nLoop Coding Techniques\\n\\n| 409\\n\\n\\x0c>>> keys = [\\'spam\\', \\'eggs\\', \\'toast\\']\\n>>> vals = [1, 3, 5]\\n\\nOne solution for turning those lists into a dictionary would be to zip the lists and step\\nthrough them in parallel with a for loop:\\n\\n>>> list(zip(keys, vals))\\n[(\\'spam\\', 1), (\\'eggs\\', 3), (\\'toast\\', 5)]\\n\\n>>> D2 = {}\\n>>> for (k, v) in zip(keys, vals): D2[k] = v\\n...\\n>>> D2\\n{\\'eggs\\': 3, \\'toast\\': 5, \\'spam\\': 1}\\n\\nIt turns out, though, that in Python 2.2 and later you can skip the for loop altogether\\nand simply pass the zipped keys/values lists to the built-in dict constructor call:\\n\\n>>> keys = [\\'spam\\', \\'eggs\\', \\'toast\\']\\n>>> vals = [1, 3, 5]\\n\\n>>> D3 = dict(zip(keys, vals))\\n>>> D3\\n{\\'eggs\\': 3, \\'toast\\': 5, \\'spam\\': 1}\\n\\nThe built-in name dict is really a type name in Python (you’ll learn more about type\\nnames, and subclassing them, in Chapter 32). Calling it achieves something like a list-\\nto-dictionary conversion, but it’s really an object construction request.\\nIn the next chapter we’ll explore the related but richer concept, the list comprehension,\\nwhich builds lists in a single expression; we’ll also revisit Python 3.X and 2.7 dictionary\\ncomprehensions, an alternative to the dict call for zipped key/value pairs:\\n\\n>>> {k: v for (k, v) in zip(keys, vals)}\\n{\\'eggs\\': 3, \\'toast\\': 5, \\'spam\\': 1}\\n\\nGenerating Both Offsets and Items: enumerate\\nOur final loop helper function is designed to support dual usage modes. Earlier, we\\ndiscussed using range to generate the offsets of items in a string, rather than the items\\nat those offsets. In some programs, though, we need both: the item to use, plus an offset\\nas we go. Traditionally, this was coded with a simple for loop that also kept a counter\\nof the current offset:\\n\\n>>> S = \\'spam\\'\\n>>> offset = 0\\n>>> for item in S:\\n...     print(item, \\'appears at offset\\', offset)\\n...     offset += 1\\n...\\ns appears at offset 0\\np appears at offset 1\\na appears at offset 2\\nm appears at offset 3\\n\\n410 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cThis works, but in all recent Python 2.X and 3.X releases (since 2.3) a new built-in\\nnamed enumerate does the job for us—its net effect is to give loops a counter “for free,”\\nwithout sacrificing the simplicity of automatic iteration:\\n\\n>>> S = \\'spam\\'\\n>>> for (offset, item) in enumerate(S):\\n...     print(item, \\'appears at offset\\', offset)\\n...\\ns appears at offset 0\\np appears at offset 1\\na appears at offset 2\\nm appears at offset 3\\n\\nThe enumerate function returns a generator object—a kind of object that supports the\\niteration protocol that we will study in the next chapter and will discuss in more detail\\nin the next part of the book. In short, it has a method called by the next built-in function,\\nwhich  returns  an  (index,  value)  tuple  each  time  through  the  loop.  The  for  steps\\nthrough these tuples automatically, which allows us to unpack their values with tuple\\nassignment, much as we did for zip:\\n\\n>>> E = enumerate(S)\\n>>> E\\n<enumerate object at 0x0000000002A8B900>\\n>>> next(E)\\n(0, \\'s\\')\\n>>> next(E)\\n(1, \\'p\\')\\n>>> next(E)\\n(2, \\'a\\')\\n\\nWe don’t normally see this machinery because all iteration contexts—including list\\ncomprehensions, the subject of Chapter 14—run the iteration protocol automatically:\\n\\n>>> [c * i for (i, c) in enumerate(S)]\\n[\\'\\', \\'p\\', \\'aa\\', \\'mmm\\']\\n\\n>>> for (i, l) in enumerate(open(\\'test.txt\\')):\\n...     print(\\'%s) %s\\' % (i, l.rstrip()))\\n...\\n0) aaaaaa\\n1) bbbbbb\\n2) cccccc\\n\\nTo fully understand iteration concepts like enumerate, zip, and list comprehensions,\\nthough, we need to move on to the next chapter for a more formal dissection.\\n\\nWhy You Will Care: Shell Commands and More\\n\\nAn earlier sidebar showed loops applied to files. As briefly noted in Chapter 9, Python’s\\nrelated os.popen call also gives a file-like interface, for reading the outputs of spawned\\nshell commands. Now that we’ve studied looping statements in full, here’s an example\\nof this tool in action—to run a shell command and read its standard output text, pass\\nthe command as a string to os popen, and read text from the file-like object it returns\\n\\nLoop Coding Techniques\\n\\n| 411\\n\\n\\x0c(if this triggers a Unicode encoding issue on your computer, Chapter 25’s discussion\\nof currency symbols may apply):\\n\\n>>> import os\\n>>> F = os.popen(\\'dir\\')               # Read line by line\\n>>> F.readline()\\n\\' Volume in drive C has no label.\\\\n\\'\\n>>> F = os.popen(\\'dir\\')               # Read by sized blocks\\n>>> F.read(50)\\n\\' Volume in drive C has no label.\\\\n Volume Serial Nu\\'\\n\\n>>> os.popen(\\'dir\\').readlines()[0]    # Read all lines: index\\n\\' Volume in drive C has no label.\\\\n\\'\\n>>> os.popen(\\'dir\\').read()[:50]       # Read all at once: slice\\n\\' Volume in drive C has no label.\\\\n Volume Serial Nu\\'\\n\\n>>> for line in os.popen(\\'dir\\'):      # File line iterator loop\\n...     print(line.rstrip())\\n...\\n Volume in drive C has no label.\\n Volume Serial Number is D093-D1F7\\n...and so on...\\n\\nThis runs a dir directory listing on Windows, but any program that can be started with\\na command line can be launched this way. We might use this scheme, for example, to\\ndisplay the output of the windows systeminfo command—os.system simply runs a shell\\ncommand, but os.popen also connects to its streams; both of the following show the\\nshell command’s output in a simple console window, but the first might not in a GUI\\ninterface such as IDLE:\\n\\n>>> os.system(\\'systeminfo\\')\\n...output in console, popup in IDLE...\\n0\\n>>> for line in os.popen(\\'systeminfo\\'): print(line.rstrip())\\n\\nHost Name:                 MARK-VAIO\\nOS Name:                   Microsoft Windows 7 Professional\\nOS Version:                6.1.7601 Service Pack 1 Build 7601\\n...lots of system information text...\\n\\nAnd once we have a command’s output in text form, any string processing tool or\\ntechnique applies—including display formatting and content parsing:\\n\\n# Formatted, limited display\\n>>> for (i, line) in enumerate(os.popen(\\'systeminfo\\')):\\n...     if i == 4: break\\n...     print(\\'%05d) %s\\' % (i, line.rstrip()))\\n...\\n00000)\\n00001) Host Name:                 MARK-VAIO\\n00002) OS Name:                   Microsoft Windows 7 Professional\\n00003) OS Version:                6.1.7601 Service Pack 1 Build 7601\\n\\n# Parse for specific lines, case neutral\\n>>> for line in os.popen(\\'systeminfo\\'):\\n...    parts = line.split(\\':\\')\\n...    if parts and parts[0].lower() == \\'system type\\':\\n...        print(parts[1].strip())\\n\\n412 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0c...\\nx64-based PC\\n\\nWe’ll see os.popen in action again in Chapter 21, where we’ll deploy it to read the results\\nof a constructed command line that times code alternatives, and in Chapter 25, where\\nit will be used to compare outputs of scripts being tested.\\nTools like os.popen and os.system (and the subprocess module not shown here) allow\\nyou to leverage every command-line program on your computer, but you can also write\\nemulators with in-process code. For example, simulating the Unix awk utility’s ability\\nto strip columns out of text files is almost trivial in Python, and can become a reusable\\nfunction in the process:\\n\\n# awk emulation: extract column 7 from whitespace-delimited file\\nfor val in [line.split()[6] for line in open(\\'input.txt\\')]:\\n    print(val)\\n\\n# Same, but more explicit code that retains result\\ncol7 = []\\nfor line in open(\\'input.txt\\'):\\n    cols = line.split()\\n    col7.append(cols[6])\\nfor item in col7:  print(item)\\n\\n# Same, but a reusable function (see next part of book)\\ndef awker(file, col):\\n    return [line.rstrip().split()[col-1] for line in open(file)]\\n\\nprint(awker(\\'input.txt\\', 7))             # List of strings\\nprint(\\',\\'.join(awker(\\'input.txt\\', 7)))   # Put commas between\\n\\nBy itself, though, Python provides file-like access to a wide variety of data—including\\nthe text returned by websites and their pages identified by URL, though we’ll have to\\ndefer to Part V for more on the package import used here, and other resources for more\\non  such  tools  in  general  (e.g.,  this  works  in  2.X,  but  uses  urllib  instead  of\\nurlib.request, and returns text strings):\\n\\n>>> from urllib.request import urlopen\\n>>> for line in urlopen(\\'http://home.rmi.net/~lutz\\'):\\n...     print(line)\\n...\\nb\\'<HTML>\\\\n\\'\\nb\\'\\\\n\\'\\nb\\'<HEAD>\\\\n\\'\\nb\"<TITLE>Mark Lutz\\'s Book Support Site</TITLE>\\\\n\"\\n...etc...\\n\\nChapter Summary\\nIn this chapter, we explored Python’s looping statements as well as some concepts\\nrelated to looping in Python. We looked at the while and for loop statements in depth,\\nand we learned about their associated  else clauses. We also studied the  break and\\ncontinue statements, which have meaning only inside loops, and met several built-in\\n\\nChapter Summary | 413\\n\\n\\x0ctools commonly used in for loops, including range, zip, map, and enumerate, although\\nsome of the details regarding their roles as iterables in Python 3.X were intentionally\\ncut short.\\nIn the next chapter, we continue the iteration story by discussing list comprehensions\\nand the iteration protocol in Python—concepts strongly related to for loops. There,\\nwe’ll also give the rest of the picture behind the iterable tools we met here, such as\\nrange and zip, and study some of the subtleties of their operation. As always, though,\\nbefore moving on let’s exercise what you’ve picked up here with a quiz.\\n\\nTest Your Knowledge: Quiz\\n1. What are the main functional differences between a while and a for?\\n2. What’s the difference between break and continue?\\n3. When is a loop’s else clause executed?\\n4. How can you code a counter-based loop in Python?\\n5. What can a range be used for in a for loop?\\n\\nTest Your Knowledge: Answers\\n1. The while loop is a general looping statement, but the for is designed to iterate\\nacross items in a sequence or other iterable. Although the while can imitate the\\nfor with counter loops, it takes more code and might run slower.\\n\\n2. The  break  statement  exits  a  loop  immediately  (you  wind  up  below  the  entire\\nwhile or for loop statement), and continue jumps back to the top of the loop (you\\nwind up positioned just before the test in while or the next item fetch in for).\\n\\n3. The else clause in a while or for loop will be run once as the loop is exiting, if the\\nloop exits normally (without running into a break statement). A break exits the\\nloop immediately, skipping the else part on the way out (if there is one).\\n\\n4. Counter loops can be coded with a while statement that keeps track of the index\\nmanually, or with a for loop that uses the range built-in function to generate suc-\\ncessive integer offsets. Neither is the preferred way to work in Python, if you need\\nto simply step across all the items in a sequence. Instead, use a simple for loop\\ninstead, without range or counters, whenever possible; it will be easier to code and\\nusually quicker to run.\\n\\n5. The range built-in can be used in a for to implement a fixed number of repetitions,\\nto scan by offsets instead of items at offsets, to skip successive items as you go, and\\nto change a list while stepping across it. None of these roles requires range, and\\nmost have alternatives—scanning actual items, three-limit slices, and list compre-\\nhensions are often better solutions today (despite the natural inclinations of ex–C\\nprogrammers to want to count things!).\\n\\n414 | Chapter 13:\\u2002while and for Loops\\n\\n\\x0cCHAPTER 14\\nIterations and Comprehensions\\n\\nIn the prior chapter we met Python’s two looping statements, while and for. Although\\nthey can handle most repetitive tasks programs need to perform, the need to iterate\\nover sequences is so common and pervasive that Python provides additional tools to\\nmake it simpler and more efficient. This chapter begins our exploration of these tools.\\nSpecifically, it presents the related concepts of Python’s iteration protocol, a method-\\ncall model used by the for loop, and fills in some details on list comprehensions, which\\nare a close cousin to the for loop that applies an expression to items in an iterable.\\nBecause these tools are related to both the for loop and functions, we’ll take a two-pass\\napproach to covering them in this book, along with a postscript:\\n\\n• This  chapter  introduces  their  basics  in  the  context  of  looping  tools,  serving  as\\n\\nsomething of a continuation of the prior chapter.\\n\\n• Chapter 20 revisits them in the context of function-based tools, and extends the\\n\\ntopic to include built-in and user-defined generators.\\n\\n• Chapter 30 also provides a shorter final installment in this story, where we’ll learn\\n\\nabout user-defined iterable objects coded with classes.\\n\\nIn this chapter, we’ll also sample additional iteration tools in Python, and touch on the\\nnew iterables available in Python 3.X—where the notion of iterables grows even more\\npervasive.\\nOne note up front: some of the concepts presented in these chapters may seem ad-\\nvanced at first glance. With practice, though, you’ll find that these tools are useful and\\npowerful. Although never strictly required, because they’ve become commonplace in\\nPython code, a basic understanding can also help if you must read programs written\\nby others.\\n\\n415\\n\\n\\x0cIterations: A First Look\\nIn the preceding chapter, I mentioned that the for loop can work on any sequence type\\nin Python, including lists, tuples, and strings, like this:\\n\\n>>> for x in [1, 2, 3, 4]: print(x ** 2, end=\\' \\')            # In 2.X: print x ** 2,\\n...\\n1 4 9 16\\n\\n>>> for x in (1, 2, 3, 4): print(x ** 3, end=\\' \\')\\n...\\n1 8 27 64\\n\\n>>> for x in \\'spam\\': print(x * 2, end=\\' \\')\\n...\\nss pp aa mm\\n\\nActually, the for loop turns out to be even more generic than this—it works on any\\niterable object. In fact, this is true of all iteration tools that scan objects from left to right\\nin Python, including for loops, the list comprehensions we’ll study in this chapter, in\\nmembership tests, the map built-in function, and more.\\nThe  concept  of  “iterable  objects”  is  relatively  recent  in  Python,  but  it  has  come  to\\npermeate the language’s design. It’s essentially a generalization of the notion of se-\\nquences—an object is considered iterable if it is either a physically stored sequence, or\\nan object that produces one result at a time in the context of an iteration tool like a\\nfor loop. In a sense, iterable objects include both physical sequences and virtual se-\\nquences computed on demand.\\n\\nTerminology in this topic tends to be a bit loose. The terms “iterable”\\nand “iterator” are sometimes used interchangeably to refer to an object\\nthat supports iteration in general. For clarity, this book has a very strong\\npreference for using the term iterable to refer to an object that supports\\nthe iter call, and iterator to refer to an object returned by an iterable on\\niter that supports the next(I) call. Both these calls are defined ahead.\\n\\nThat convention is not universal in either the Python world or this book,\\nthough; “iterator” is also sometimes used for tools that iterate. Chap-\\nter 20 extends this category with the term “generator”—which refers to\\nobjects that automatically support the iteration protocol, and hence are\\niterable—even though all iterables generate results!\\n\\nThe Iteration Protocol: File Iterators\\nOne of the easiest ways to understand the iteration protocol is to see how it works with\\na built-in type such as the file. In this chapter, we’ll be using the following input file to\\ndemonstrate:\\n\\n>>> print(open(\\'script2.py\\').read())\\nimport sys\\n\\n416 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0cprint(sys.path)\\nx = 2\\nprint(x ** 32)\\n\\n>>> open(\\'script2.py\\').read()\\n\\'import sys\\\\nprint(sys.path)\\\\nx = 2\\\\nprint(x ** 32)\\\\n\\'\\n\\nRecall from Chapter 9 that open file objects have a method called readline, which reads\\none line of text from a file at a time—each time we call the readline method, we advance\\nto the next line. At the end of the file, an empty string is returned, which we can detect\\nto break out of the loop:\\n\\n>>> f = open(\\'script2.py\\')     # Read a four-line script file in this directory\\n>>> f.readline()               # readline loads one line on each call\\n\\'import sys\\\\n\\'\\n>>> f.readline()\\n\\'print(sys.path)\\\\n\\'\\n>>> f.readline()\\n\\'x = 2\\\\n\\'\\n>>> f.readline()               # Last lines may have a \\\\n or not\\n\\'print(x ** 32)\\\\n\\'\\n>>> f.readline()               # Returns empty string at end-of-file\\n\\'\\'\\n\\nHowever, files also have a method named __next__ in 3.X (and next in 2.X) that has a\\nnearly identical effect—it returns the next line from a file each time it is called. The\\nonly noticeable difference is that __next__ raises a built-in StopIteration exception at\\nend-of-file instead of returning an empty string:\\n\\n>>> f = open(\\'script2.py\\')     # __next__ loads one line on each call too\\n>>> f.__next__()               # But raises an exception at end-of-file\\n\\'import sys\\\\n\\'\\n>>> f.__next__()               # Use f.next() in 2.X, or next(f) in 2.X or 3.X\\n\\'print(sys.path)\\\\n\\'\\n>>> f.__next__()\\n\\'x = 2\\\\n\\'\\n>>> f.__next__()\\n\\'print(x ** 32)\\\\n\\'\\n>>> f.__next__()\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nStopIteration\\n\\nThis interface is most of what we call the iteration protocol in Python. Any object with\\na __next__ method to advance to a next result, which raises StopIteration at the end\\nof the series of results, is considered an iterator in Python. Any such object may also\\nbe stepped through with a for loop or other iteration tool, because all iteration tools\\nnormally work internally by calling __next__ on each iteration and catching the StopIt\\neration exception to determine when to exit. As we’ll see in a moment, for some objects\\nthe full protocol includes an additional first step to call iter, but this isn’t required for\\nfiles.\\n\\nIterations: A First Look | 417\\n\\n\\x0cThe net effect of this magic is that, as mentioned in Chapter 9 and Chapter 13, the best\\nway to read a text file line by line today is to not read it at all—instead, allow the for\\nloop to automatically call __next__ to advance to the next line on each iteration. The\\nfile object’s iterator will do the work of automatically loading lines as you go. The\\nfollowing, for example, reads a file line by line, printing the uppercase version of each\\nline along the way, without ever explicitly reading from the file at all:\\n\\n>>> for line in open(\\'script2.py\\'):       # Use file iterators to read by lines\\n...     print(line.upper(), end=\\'\\')       # Calls __next__, catches StopIteration\\n...\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(X ** 32)\\n\\nNotice that the print uses end=\\'\\' here to suppress adding a \\\\n, because line strings\\nalready have one (without this, our output would be double-spaced; in 2.X, a trailing\\ncomma works the same as the end). This is considered the best way to read text files\\nline by line today, for three reasons: it’s the simplest to code, might be the quickest to\\nrun, and is the best in terms of memory usage. The older, original way to achieve the\\nsame effect with a for loop is to call the file readlines method to load the file’s content\\ninto memory as a list of line strings:\\n\\n>>> for line in open(\\'script2.py\\').readlines():\\n...     print(line.upper(), end=\\'\\')\\n...\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(X ** 32)\\n\\nThis readlines technique still works but is not considered the best practice today and\\nperforms poorly in terms of memory usage. In fact, because this version really does load\\nthe entire file into memory all at once, it will not even work for files too big to fit into\\nthe memory space available on your computer. By contrast, because it reads one line\\nat a time, the iterator-based version is immune to such memory-explosion issues. The\\niterator version might run quicker too, though this can vary per release\\nAs  mentioned  in  the  prior  chapter’s  sidebar,  “Why  You  Will  Care:  File  Scan-\\nners” on page 400, it’s also possible to read a file line by line with a while loop:\\n\\n>>> f = open(\\'script2.py\\')\\n>>> while True:\\n...     line = f.readline()\\n...     if not line: break\\n...     print(line.upper(), end=\\'\\')\\n...\\n...same output...\\n\\nHowever, this may run slower than the iterator-based for loop version, because itera-\\ntors run at C language speed inside Python, whereas the while loop version runs Python\\nbyte code through the Python virtual machine. Anytime we trade Python code for C\\n\\n418 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0ccode, speed tends to increase. This is not an absolute truth, though, especially in Python\\n3.X; we’ll see timing techniques later in Chapter 21 for measuring the relative speed of\\nalternatives like these.1\\n\\nVersion  skew  note:  In  Python  2.X,  the  iteration  method  is  named\\nX.next()  instead  of  X.__next__().  For  portability,  a  next(X)  built-in\\nfunction is also available in both Python 3.X and 2.X (2.6 and later), and\\ncalls  X.__next__()  in  3.X  and  X.next()  in  2.X.  Apart  from  method\\nnames, iteration works the same in 2.X and 3.X in all other ways. In 2.6\\nand 2.7, simply use X.next() or next(X) for manual iterations instead of\\n3.X’s X.__next__(); prior to 2.6, use X.next() calls instead of next(X).\\n\\nManual Iteration: iter and next\\nTo simplify manual iteration code, Python 3.X also provides a built-in function, next,\\nthat automatically calls an object’s __next__ method. Per the preceding note, this call\\nalso is supported on Python 2.X for portability. Given an iterator object  X, the call\\nnext(X) is the same as X.__next__() on 3.X (and X.next() on 2.X), but is noticeably\\nsimpler and more version-neutral. With files, for instance, either form may be used:\\n\\n>>> f = open(\\'script2.py\\')\\n>>> f.__next__()                   # Call iteration method directly\\n\\'import sys\\\\n\\'\\n>>> f.__next__()\\n\\'print(sys.path)\\\\n\\'\\n\\n>>> f = open(\\'script2.py\\')\\n>>> next(f)                        # The next(f) built-in calls f.__next__() in 3.X\\n\\'import sys\\\\n\\'\\n>>> next(f)                        # next(f) => [3.X: f.__next__()], [2.X: f.next()]\\n\\'print(sys.path)\\\\n\\'\\n\\nTechnically, there is one more piece to the iteration protocol alluded to earlier. When\\nthe for loop begins, it first obtains an iterator from the iterable object by passing it to\\nthe iter built-in function; the object returned by iter in turn has the required next\\nmethod. The iter function internally runs the __iter__ method, much like next and\\n__next__.\\n\\n1. Spoiler alert: the file iterator still appears to be slightly faster than readlines and at least 30% faster than\\nthe while loop in both 2.7 and 3.3 on tests I’ve run with this chapter’s code on a 1,000-line file (while is\\ntwice as slow on 2.7). The usual benchmarking caveats apply—this is true only for my Pythons, my\\ncomputer, and my test file, and Python 3.X complicates such analyses by rewriting I/O libraries to support\\nUnicode text and be less system-dependent. Chapter 21 covers tools and techniques you can use to time\\nthese loop statements on your own.\\n\\nIterations: A First Look | 419\\n\\n\\x0cThe full iteration protocol\\nAs a more formal definition, Figure 14-1 sketches this full iteration protocol, used by\\nevery iteration tool in Python, and supported by a wide variety of object types. It’s really\\nbased on two objects, used in two distinct steps by iteration tools:\\n\\n• The iterable object you request iteration for, whose __iter__ is run by iter\\n• The iterator object returned by the iterable that actually produces values during\\nthe iteration, whose __next__ is run by next and raises StopIteration when finished\\nproducing results\\n\\nThese steps are orchestrated automatically by iteration tools in most cases, but it helps\\nto understand these two objects’ roles. For example, in some cases these two objects\\nare the same when only a single scan is supported (e.g., files), and the iterator object is\\noften temporary, used internally by the iteration tool.\\nMoreover, some objects are both an iteration context tool (they iterate) and an iterable\\nobject (their results are iterable)—including Chapter 20’s generator expressions, and\\nmap and zip in Python 3.X. As we’ll see ahead, more tools become iterables in 3.X—\\nincluding map, zip, range, and some dictionary methods—to avoid constructing result\\nlists in memory all at once.\\n\\nFigure 14-1. The Python iteration protocol, used by for loops, comprehensions, maps, and more, and\\nsupported  by  files,  lists,  dictionaries,  Chapter  20’s  generators,  and  more.  Some  objects  are  both\\niteration context and iterable object, such as generator expressions and 3.X’s flavors of some tools\\n(such as map and zip). Some objects are both iterable and iterator, returning themselves for the iter()\\ncall, which is then a no-op.\\n\\nIn actual code, the protocol’s first step becomes obvious if we look at how for loops\\ninternally process built-in sequence types such as lists:\\n\\n>>> L = [1, 2, 3]\\n>>> I = iter(L)                    # Obtain an iterator object from an iterable\\n>>> I.__next__()                   # Call iterator\\'s next to advance to next item\\n1\\n\\n420 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0c>>> I.__next__()                   # Or use I.next() in 2.X, next(I) in either line\\n2\\n>>> I.__next__()\\n3\\n>>> I.__next__()\\n...error text omitted...\\nStopIteration\\n\\nThis initial step is not required for files, because a file object is its own iterator. Because\\nthey support just one iteration (they can’t seek backward to support multiple active\\nscans), files have their own __next__ method and do not need to return a different object\\nthat does:\\n\\n>>> f = open(\\'script2.py\\')\\n>>> iter(f) is f\\nTrue\\n>>> iter(f) is f.__iter__()\\nTrue\\n>>> f.__next__()\\n\\'import sys\\\\n\\'\\n\\nLists and many other built-in objects, though, are not their own iterators because they\\ndo support multiple open iterations—for example, there may be multiple iterations in\\nnested loops all at different positions. For such objects, we must call iter to start iter-\\nating:\\n\\n>>> L = [1, 2, 3]\\n>>> iter(L) is L\\nFalse\\n>>> L.__next__()\\nAttributeError: \\'list\\' object has no attribute \\'__next__\\'\\n\\n>>> I = iter(L)\\n>>> I.__next__()\\n1\\n>>> next(I)                     # Same as I.__next__()\\n2\\n\\nManual iteration\\nAlthough Python iteration tools call these functions automatically, we can use them to\\napply the iteration protocol manually, too. The following interaction demonstrates the\\nequivalence between automatic and manual iteration:2\\n\\n>>> L = [1, 2, 3]\\n>>>\\n>>> for X in L:                 # Automatic iteration\\n...     print(X ** 2, end=\\' \\')  # Obtains iter, calls __next__, catches exceptions\\n...\\n1 4 9\\n\\n2. Technically speaking, the for loop calls the internal equivalent of I.__next__, instead of the next(I) used\\nhere, though there is rarely any difference between the two. Your manual iterations can generally use\\neither call scheme.\\n\\nIterations: A First Look | 421\\n\\n\\x0c>>> I = iter(L)                 # Manual iteration: what for loops usually do\\n>>> while True:\\n...     try:                    # try statement catches exceptions\\n...         X = next(I)         # Or call I.__next__ in 3.X\\n...     except StopIteration:\\n...         break\\n...     print(X ** 2, end=\\' \\')\\n...\\n1 4 9\\n\\nTo understand this code, you need to know that try statements run an action and catch\\nexceptions that occur while the action runs (we met exceptions briefly in Chapter 11\\nbut will explore them in depth in Part VII). I should also note that for loops and other\\niteration contexts can sometimes work differently for user-defined classes, repeatedly\\nindexing an object instead of running the iteration protocol, but prefer the iteration\\nprotocol if it’s used. We’ll defer that story until we study class operator overloading in\\nChapter 30.\\n\\nOther Built-in Type Iterables\\nBesides files and physical sequences like lists, other types have useful iterators as well.\\nThe classic way to step through the keys of a dictionary, for example, is to request its\\nkeys list explicitly:\\n\\n>>> D = {\\'a\\':1, \\'b\\':2, \\'c\\':3}\\n>>> for key in D.keys():\\n...     print(key, D[key])\\n...\\na 1\\nb 2\\nc 3\\n\\nIn recent versions of Python, though, dictionaries are iterables with an iterator that\\nautomatically returns one key at a time in an iteration context:\\n\\n>>> I = iter(D)\\n>>> next(I)\\n\\'a\\'\\n>>> next(I)\\n\\'b\\'\\n>>> next(I)\\n\\'c\\'\\n>>> next(I)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nStopIteration\\n\\nThe net effect is that we no longer need to call the keys method to step through dic-\\ntionary keys—the for loop will use the iteration protocol to grab one key each time\\nthrough:\\n\\n422 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0c>>> for key in D:\\n...     print(key, D[key])\\n...\\na 1\\nb 2\\nc 3\\n\\nWe can’t delve into their details here, but other Python object types also support the\\niteration protocol and thus may be used in for loops too. For instance, shelves (an\\naccess-by-key filesystem for Python objects) and the results from os.popen (a tool for\\nreading the output of shell commands, which we met in the preceding chapter) are\\niterable as well:\\n>>> import os\\n>>> P = os.popen(\\'dir\\')\\n>>> P.__next__()\\n\\' Volume in drive C has no label.\\\\n\\'\\n>>> P.__next__()\\n\\' Volume Serial Number is D093-D1F7\\\\n\\'\\n>>> next(P)\\nTypeError: _wrap_close object is not an iterator\\n\\nNotice that popen objects themselves support a P.next() method in Python 2.X. In 3.X,\\nthey support the P.__next__() method, but not the next(P) built-in. Since the latter is\\ndefined to call the former, this may seem unusual, though both calls work correctly if\\nwe use the full iteration protocol employed automatically by for loops and other iter-\\nation contexts, with its top-level iter call (this performs internal steps required to also\\nsupport next calls for this object):\\n\\n>>> P = os.popen(\\'dir\\')\\n>>> I = iter(P)\\n>>> next(I)\\n\\' Volume in drive C has no label.\\\\n\\'\\n>>> I.__next__()\\n\\' Volume Serial Number is D093-D1F7\\\\n\\'\\n\\nAlso in the systems domain, the standard directory walker in Python, os.walk, is sim-\\nilarly iterable, but we’ll save an example until Chapter 20’s coverage of this tool’s basis\\n—generators and yield.\\nThe  iteration  protocol  also  is  the  reason  that  we’ve  had  to  wrap  some  results  in  a\\nlist call to see their values all at once. Objects that are iterable return results one at a\\ntime, not in a physical list:\\n\\n>>> R = range(5)\\n>>> R                            # Ranges are iterables in 3.X\\nrange(0, 5)\\n>>> I = iter(R)                  # Use iteration protocol to produce results\\n>>> next(I)\\n0\\n>>> next(I)\\n1\\n>>> list(range(5))               # Or use list to collect all results at once\\n[0, 1, 2, 3, 4]\\n\\nIterations: A First Look | 423\\n\\n\\x0cNote that the list call here is not required in 2.X (where range builds a real list), and\\nis not needed in 3.X for contexts where iteration happens automatically (such as within\\nfor loops). It is needed for displaying values here in 3.X, though, and may also be\\nrequired when list-like behavior or multiple scans are required for objects that produce\\nresults on demand in 2.X or 3.X (more on this ahead).\\nNow that you have a better understanding of this protocol, you should be able to see\\nhow it explains why the enumerate tool introduced in the prior chapter works the way\\nit does:\\n\\n>>> E = enumerate(\\'spam\\')        # enumerate is an iterable too\\n>>> E\\n<enumerate object at 0x00000000029B7678>\\n>>> I = iter(E)\\n>>> next(I)                      # Generate results with iteration protocol\\n(0, \\'s\\')\\n>>> next(I)                      # Or use list to force generation to run\\n(1, \\'p\\')\\n>>> list(enumerate(\\'spam\\'))\\n[(0, \\'s\\'), (1, \\'p\\'), (2, \\'a\\'), (3, \\'m\\')]\\n\\nWe don’t normally see this machinery because for loops run it for us automatically to\\nstep through results. In fact, everything that scans left to right in Python employs the\\niteration protocol in the same way—including the topic of the next section.\\n\\nList Comprehensions: A First Detailed Look\\nNow that we’ve seen how the iteration protocol works, let’s turn to one of its most\\ncommon use cases. Together with for loops, list comprehensions are one of the most\\nprominent contexts in which the iteration protocol is applied.\\nIn the previous chapter, we learned how to use range to change a list as we step across\\nit:\\n\\n>>> L = [1, 2, 3, 4, 5]\\n\\n>>> for i in range(len(L)):\\n...     L[i] += 10\\n...\\n>>> L\\n[11, 12, 13, 14, 15]\\n\\nThis works, but as I mentioned there, it may not be the optimal “best practice” approach\\nin Python. Today, the list comprehension expression makes many such prior coding\\npatterns obsolete. Here, for example, we can replace the loop with a single expression\\nthat produces the desired result list:\\n\\n>>> L = [x + 10 for x in L]\\n>>> L\\n[21, 22, 23, 24, 25]\\n\\n424 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0cThe net result is similar, but it requires less coding on our part and is likely to run\\nsubstantially  faster.  The  list  comprehension  isn’t  exactly  the  same  as  the  for  loop \\nstatement version because it makes a new list object (which might matter if there are\\nmultiple references to the original list), but it’s close enough for most applications and\\nis a common and convenient enough approach to merit a closer look here.\\n\\nList Comprehension Basics\\nWe met the list comprehension briefly in Chapter 4. Syntactically, its syntax is derived\\nfrom a construct in set theory notation that applies an operation to each item in a set,\\nbut you don’t have to know set theory to use this tool. In Python, most people find that\\na list comprehension simply looks like a backward for loop.\\nTo get a handle on the syntax, let’s dissect the prior section’s example in more detail:\\n\\nL = [x + 10 for x in L]\\n\\nList comprehensions are written in square brackets because they are ultimately a way\\nto construct a new list. They begin with an arbitrary expression that we make up, which\\nuses a loop variable that we make up (x + 10). That is followed by what you should\\nnow recognize as the header of a  for loop, which names the loop variable, and an\\niterable object (for x in L).\\nTo run the expression, Python executes an iteration across  L inside the interpreter,\\nassigning x to each item in turn, and collects the results of running the items through\\nthe expression on the left side. The result list we get back is exactly what the list com-\\nprehension says—a new list containing x + 10, for every x in L.\\nTechnically speaking, list comprehensions are never really required because we can\\nalways build up a list of expression results manually with for loops that append results\\nas we go:\\n\\n>>> res = []\\n>>> for x in L:\\n...     res.append(x + 10)\\n...\\n>>> res\\n[31, 32, 33, 34, 35]\\n\\nIn fact, this is exactly what the list comprehension does internally.\\nHowever, list comprehensions are more concise to write, and because this code pattern\\nof building up result lists is so common in Python work, they turn out to be very useful\\nin many contexts. Moreover, depending on your Python and code, list comprehensions\\nmight run much faster than manual for loop statements (often roughly twice as fast)\\nbecause their iterations are performed at C language speed inside the interpreter, rather\\nthan with manual Python code. Especially for larger data sets, there is often a major\\nperformance advantage to using this expression.\\n\\nList Comprehensions: A First Detailed Look | 425\\n\\n\\x0cUsing List Comprehensions on Files\\nLet’s work through another common application of list comprehensions to explore\\nthem in more detail. Recall that the file object has a readlines method that loads the\\nfile into a list of line strings all at once:\\n\\n>>> f = open(\\'script2.py\\')\\n>>> lines = f.readlines()\\n>>> lines\\n[\\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\']\\n\\nThis works, but the lines in the result all include the newline character (\\\\n) at the end.\\nFor many programs, the newline character gets in the way—we have to be careful to\\navoid double-spacing when printing, and so on. It would be nice if we could get rid of\\nthese newlines all at once, wouldn’t it?\\nAnytime we start thinking about performing an operation on each item in a sequence,\\nwe’re in the realm of list comprehensions. For example, assuming the variable lines is\\nas it was in the prior interaction, the following code does the job by running each line\\nin the list through the string rstrip method to remove whitespace on the right side (a\\nline[:−1] slice would work, too, but only if we can be sure all lines are properly \\\\n\\nterminated, and this may not always be the case for the last line in a file):\\n\\n>>> lines = [line.rstrip() for line in lines]\\n>>> lines\\n[\\'import sys\\', \\'print(sys.path)\\', \\'x = 2\\', \\'print(x ** 32)\\']\\n\\nThis works as planned. Because list comprehensions are an iteration context just like\\nfor loop statements, though, we don’t even have to open the file ahead of time. If we\\nopen it inside the expression, the list comprehension will automatically use the iteration\\nprotocol we met earlier in this chapter. That is, it will read one line from the file at a\\ntime by calling the file’s next handler method, run the line through the rstrip expres-\\nsion, and add it to the result list. Again, we get what we ask for—the rstrip result of\\na line, for every line in the file:\\n\\n>>> lines = [line.rstrip() for line in open(\\'script2.py\\')]\\n>>> lines\\n[\\'import sys\\', \\'print(sys.path)\\', \\'x = 2\\', \\'print(x ** 32)\\']\\n\\nThis expression does a lot implicitly, but we’re getting a lot of work for free here—\\nPython scans the file by lines and builds a list of operation results automatically. It’s\\nalso an efficient way to code this operation: because most of this work is done inside\\nthe Python interpreter, it may be faster than an equivalent for statement, and won’t\\nload a file into memory all at once like some other techniques. Again, especially for\\nlarge files, the advantages of list comprehensions can be significant.\\nBesides  their  efficiency,  list  comprehensions  are  also  remarkably  expressive.  In  our\\nexample, we can run any string operation on a file’s lines as we iterate. To illustrate,\\nhere’s the list comprehension equivalent to the file iterator uppercase example we met\\nearlier, along with a few other representative operations:\\n\\n426 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0c>>> [line.upper() for line in open(\\'script2.py\\')]\\n[\\'IMPORT SYS\\\\n\\', \\'PRINT(SYS.PATH)\\\\n\\', \\'X = 2\\\\n\\', \\'PRINT(X ** 32)\\\\n\\']\\n\\n>>> [line.rstrip().upper() for line in open(\\'script2.py\\')]\\n[\\'IMPORT SYS\\', \\'PRINT(SYS.PATH)\\', \\'X = 2\\', \\'PRINT(X ** 32)\\']\\n\\n>>> [line.split() for line in open(\\'script2.py\\')]\\n[[\\'import\\', \\'sys\\'], [\\'print(sys.path)\\'], [\\'x\\', \\'=\\', \\'2\\'], [\\'print(x\\', \\'**\\', \\'32)\\']]\\n\\n>>> [line.replace(\\' \\', \\'!\\') for line in open(\\'script2.py\\')]\\n[\\'import!sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x!=!2\\\\n\\', \\'print(x!**!32)\\\\n\\']\\n\\n>>> [(\\'sys\\' in line, line[:5]) for line in open(\\'script2.py\\')]\\n[(True, \\'impor\\'), (True, \\'print\\'), (False, \\'x = 2\\'), (False, \\'print\\')]\\n\\nRecall that the method chaining in the second of these examples works because string\\nmethods return a new string, to which we can apply another string method. The last\\nof these shows how we can also collect multiple results, as long as they’re wrapped in\\na collection like a tuple or list.\\n\\nOne fine point here: recall from Chapter 9 that file objects close them-\\nselves automatically when garbage-collected if still open. Hence, these\\nlist  comprehensions  will  also  automatically  close  the  file  when  their\\ntemporary  file  object  is  garbage-collected  after  the  expression  runs.\\nOutside CPython, though, you may want to code these to close man-\\nually if this is run in a loop, to ensure that file resources are freed im-\\nmediately. See Chapter 9 for more on file close calls if you need a re-\\nfresher on this.\\n\\nExtended List Comprehension Syntax\\nIn fact, list comprehensions can be even richer in practice, and even constitute a sort\\nof iteration mini-language in their fullest forms. Let’s take a quick look at their syntax\\ntools here.\\n\\nFilter clauses: if\\nAs one particularly useful extension, the for loop nested in a comprehension expression\\ncan have an associated if clause to filter out of the result items for which the test is not\\ntrue.\\nFor example, suppose we want to repeat the prior section’s file-scanning example, but\\nwe need to collect only lines that begin with the letter p (perhaps the first character on\\neach line is an action code of some sort). Adding an if filter clause to our expression\\ndoes the trick:\\n\\n>>> lines = [line.rstrip() for line in open(\\'script2.py\\') if line[0] == \\'p\\']\\n>>> lines\\n[\\'print(sys.path)\\', \\'print(x ** 32)\\']\\n\\nList Comprehensions: A First Detailed Look | 427\\n\\n\\x0cHere, the if clause checks each line read from the file to see whether its first character\\nis p; if not, the line is omitted from the result list. This is a fairly big expression, but it’s\\neasy to understand if we translate it to its simple for loop statement equivalent. In\\ngeneral, we can always translate a list comprehension to a for statement by appending\\nas we go and further indenting each successive part:\\n\\n>>> res = []\\n>>> for line in open(\\'script2.py\\'):\\n...     if line[0] == \\'p\\':\\n...         res.append(line.rstrip())\\n...\\n>>> res\\n[\\'print(sys.path)\\', \\'print(x ** 32)\\']\\n\\nThis for statement equivalent works, but it takes up four lines instead of one and may\\nrun slower. In fact, you can squeeze a substantial amount of logic into a list compre-\\nhension when you need to—the following works like the prior but selects only lines\\nthat end in a digit (before the newline at the end), by filtering with a more sophisticated\\nexpression on the right side:\\n\\n>>> [line.rstrip() for line in open(\\'script2.py\\') if line.rstrip()[-1].isdigit()]\\n[\\'x = 2\\']\\n\\nAs another if filter example, the first result in the following gives the total lines in a\\ntext file, and the second strips whitespace on both ends to omit blank links in the tally\\nin just one line of code (this file, not included, contains lines describing typos found in\\nthe first draft of this book by my proofreader):\\n\\n>>> fname = r\\'d:\\\\books\\\\5e\\\\lp5e\\\\draft1typos.txt\\'\\n>>> len(open(fname).readlines())                                  # All lines\\n263\\n>>> len([line for line in open(fname) if line.strip() != \\'\\'])     # Nonblank lines\\n185\\n\\nNested loops: for\\nList comprehensions can become even more complex if we need them to—for instance,\\nthey may contain nested loops, coded as a series of for clauses. In fact, their full syntax\\nallows for any number of for clauses, each of which can have an optional associated\\nif clause.\\nFor example, the following builds a list of the concatenation of x + y for every x in one\\nstring and every y in another. It effectively collects all the ordered combinations of the\\ncharacters in two strings:\\n\\n>>> [x + y for x in \\'abc\\' for y in \\'lmn\\']\\n[\\'al\\', \\'am\\', \\'an\\', \\'bl\\', \\'bm\\', \\'bn\\', \\'cl\\', \\'cm\\', \\'cn\\']\\n\\nAgain, one way to understand this expression is to convert it to statement form by\\nindenting its parts. The following is an equivalent, but likely slower, alternative way to\\nachieve the same effect:\\n\\n428 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0c>>> res = []\\n>>> for x in \\'abc\\':\\n...     for y in \\'lmn\\':\\n...         res.append(x + y)\\n...\\n>>> res\\n[\\'al\\', \\'am\\', \\'an\\', \\'bl\\', \\'bm\\', \\'bn\\', \\'cl\\', \\'cm\\', \\'cn\\']\\n\\nBeyond this complexity level, though, list comprehension expressions can often be-\\ncome too compact for their own good. In general, they are intended for simple types\\nof iterations; for more involved work, a simpler for statement structure will probably\\nbe easier to understand and modify in the future. As usual in programming, if something\\nis difficult for you to understand, it’s probably not a good idea.\\nBecause comprehensions are generally best taken in multiple doses, we’ll cut this story\\nshort here for now. We’ll revisit list comprehensions in Chapter 20 in the context of\\nfunctional programming tools, and will define their syntax more formally and explore\\nadditional examples there. As we’ll find, comprehensions turn out to be just as related\\nto functions as they are to looping statements.\\n\\nA blanket qualification for all performance claims in this book, list com-\\nprehension or other: the relative speed of code depends much on the\\nexact code tested and Python used, and is prone to change from release\\nto release.\\n\\nFor example, in CPython 2.7 and 3.3 today, list comprehensions can\\nstill be twice as fast as corresponding for loops on some tests, but just\\nmarginally quicker on others, and perhaps even slightly slower on some\\nwhen if filter clauses are used.\\n\\nWe’ll see how to time code in Chapter 21, and will learn how to interpret\\nthe file listcomp-speed.txt in the book examples package, which times\\nthis chapter’s code. For now, keep in mind that absolutes in perfor-\\nmance benchmarks are as elusive as consensus in open source projects!\\n\\nOther Iteration Contexts\\nLater in the book, we’ll see that user-defined classes can implement the iteration pro-\\ntocol too. Because of this, it’s sometimes important to know which built-in tools make\\nuse of it—any tool that employs the iteration protocol will automatically work on any\\nbuilt-in type or user-defined class that provides it.\\nSo far, I’ve been demonstrating iterators in the context of the for loop statement, be-\\ncause  this  part  of  the  book  is  focused  on  statements.  Keep  in  mind,  though,  that\\nevery built-in tool that scans from left to right across objects uses the iteration protocol.\\nThis includes the for loops we’ve seen:\\n\\n>>> for line in open(\\'script2.py\\'):         # Use file iterators\\n...     print(line.upper(), end=\\'\\')\\n\\nOther Iteration Contexts\\n\\n| 429\\n\\n\\x0c...\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(X ** 32)\\n\\nBut also much more. For instance, list comprehensions and the map built-in function\\nuse the same protocol as their for loop cousin. When applied to a file, they both leverage\\nthe file object’s iterator automatically to scan line by line, fetching an iterator with\\n__iter__ and calling __next__ each time through:\\n\\n>>> uppers = [line.upper() for line in open(\\'script2.py\\')]\\n>>> uppers\\n[\\'IMPORT SYS\\\\n\\', \\'PRINT(SYS.PATH)\\\\n\\', \\'X = 2\\\\n\\', \\'PRINT(X ** 32)\\\\n\\']\\n\\n>>> map(str.upper, open(\\'script2.py\\'))      # map is itself an iterable in 3.X\\n<map object at 0x00000000029476D8>\\n>>> list(map(str.upper, open(\\'script2.py\\')))\\n[\\'IMPORT SYS\\\\n\\', \\'PRINT(SYS.PATH)\\\\n\\', \\'X = 2\\\\n\\', \\'PRINT(X ** 32)\\\\n\\']\\n\\nWe introduced the map call used here briefly in the preceding chapter (and in passing\\nin Chapter 4); it’s a built-in that applies a function call to each item in the passed-in\\niterable object. map is similar to a list comprehension but is more limited because it\\nrequires a function instead of an arbitrary expression. It also returns an iterable object\\nitself in Python 3.X, so we must wrap it in a list call to force it to give us all its values\\nat once; more on this change later in this chapter. Because map, like the list compre-\\nhension, is related to both for loops and functions, we’ll also explore both again in\\nChapter 19 and Chapter 20.\\nMany of Python’s other built-ins process iterables, too. For example, sorted sorts items\\nin an iterable; zip combines items from iterables; enumerate pairs items in an iterable\\nwith relative positions; filter selects items for which a function is true; and reduce\\nruns pairs of items in an iterable through a function. All of these accept iterables, and\\nzip, enumerate, and filter also return an iterable in Python 3.X, like map. Here they are\\nin action running the file’s iterator automatically to read line by line:\\n\\n>>> sorted(open(\\'script2.py\\'))\\n[\\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'print(x ** 32)\\\\n\\', \\'x = 2\\\\n\\']\\n\\n>>> list(zip(open(\\'script2.py\\'), open(\\'script2.py\\')))\\n[(\\'import sys\\\\n\\', \\'import sys\\\\n\\'), (\\'print(sys.path)\\\\n\\', \\'print(sys.path)\\\\n\\'),\\n(\\'x = 2\\\\n\\', \\'x = 2\\\\n\\'), (\\'print(x ** 32)\\\\n\\', \\'print(x ** 32)\\\\n\\')]\\n\\n>>> list(enumerate(open(\\'script2.py\\')))\\n[(0, \\'import sys\\\\n\\'), (1, \\'print(sys.path)\\\\n\\'), (2, \\'x = 2\\\\n\\'),\\n(3, \\'print(x ** 32)\\\\n\\')]\\n\\n>>> list(filter(bool, open(\\'script2.py\\')))   # nonempty=True\\n[\\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\']\\n\\n>>> import functools, operator\\n>>> functools.reduce(operator.add, open(\\'script2.py\\'))\\n\\'import sys\\\\nprint(sys.path)\\\\nx = 2\\\\nprint(x ** 32)\\\\n\\'\\n\\n430 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0cAll of these are iteration tools, but they have unique roles. We met zip and enumerate\\nin the prior chapter; filter and reduce are in Chapter 19’s functional programming\\ndomain, so we’ll defer their details for now; the point to notice here is their use of the\\niteration protocol for files and other iterables.\\nWe first saw the sorted function used here at work in, and we used it for dictionaries\\nin Chapter 8. sorted is a built-in that employs the iteration protocol—it’s like the orig-\\ninal list sort method, but it returns the new sorted list as a result and runs on any iterable\\nobject. Notice that, unlike map and others, sorted returns an actual list in Python 3.X\\ninstead of an iterable.\\nInterestingly, the iteration protocol is even more pervasive in Python today than the\\nexamples so far have demonstrated—essentially everything in Python’s built-in toolset\\nthat scans an object from left to right is defined to use the iteration protocol on the\\nsubject object. This even includes tools such as the list and tuple built-in functions \\n(which build new objects from iterables), and the string join method (which makes a\\nnew string by putting a substring between strings contained in an iterable). Conse-\\nquently, these will also work on an open file and automatically read one line at a time:\\n\\n>>> list(open(\\'script2.py\\'))\\n[\\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\']\\n\\n>>> tuple(open(\\'script2.py\\'))\\n(\\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\')\\n\\n>>> \\'&&\\'.join(open(\\'script2.py\\'))\\n\\'import sys\\\\n&&print(sys.path)\\\\n&&x = 2\\\\n&&print(x ** 32)\\\\n\\'\\n\\nEven some tools you might not expect fall into this category. For example, sequence\\nassignment, the in membership test, slice assignment, and the list’s extend method also\\nleverage the iteration protocol to scan, and thus read a file by lines automatically:\\n\\n>>> a, b, c, d = open(\\'script2.py\\')         # Sequence assignment\\n>>> a, d\\n(\\'import sys\\\\n\\', \\'print(x ** 32)\\\\n\\')\\n\\n>>> a, *b = open(\\'script2.py\\')              # 3.X extended form\\n>>> a, b\\n(\\'import sys\\\\n\\', [\\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\'])\\n\\n>>> \\'y = 2\\\\n\\' in open(\\'script2.py\\')         # Membership test\\nFalse\\n>>> \\'x = 2\\\\n\\' in open(\\'script2.py\\')\\nTrue\\n\\n>>> L = [11, 22, 33, 44]                    # Slice assignment\\n>>> L[1:3] = open(\\'script2.py\\')\\n>>> L\\n[11, \\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\', 44]\\n\\n>>> L = [11]\\n>>> L.extend(open(\\'script2.py\\'))            # list.extend method\\n\\nOther Iteration Contexts\\n\\n| 431\\n\\n\\x0c>>> L\\n[11, \\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\']\\n\\nPer Chapter 8 extend iterates automatically, but append does not—use the latter (or\\nsimilar) to add an iterable to a list without iterating, with the potential to be iterated\\nacross later:\\n\\n>>> L = [11]\\n>>> L.append(open(\\'script2.py\\'))            # list.append does not iterate\\n>>> L\\n[11, <_io.TextIOWrapper name=\\'script2.py\\' mode=\\'r\\' encoding=\\'cp1252\\'>]\\n>>> list(L[1])\\n[\\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\', \\'print(x ** 32)\\\\n\\']\\n\\nIteration is a broadly supported and powerful model. Earlier, we saw that the built-in\\ndict call accepts an iterable zip result, too (see Chapter 8 and Chapter 13). For that\\nmatter, so does the set call, as well as the newer set and dictionary comprehension\\nexpressions in Python 3.X and 2.7, which we met in Chapter 4, Chapter 5, and Chap-\\nter 8:\\n\\n>>> set(open(\\'script2.py\\'))\\n{\\'print(x ** 32)\\\\n\\', \\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\'}\\n\\n>>> {line for line in open(\\'script2.py\\')}\\n{\\'print(x ** 32)\\\\n\\', \\'import sys\\\\n\\', \\'print(sys.path)\\\\n\\', \\'x = 2\\\\n\\'}\\n\\n>>> {ix: line for ix, line in enumerate(open(\\'script2.py\\'))}\\n{0: \\'import sys\\\\n\\', 1: \\'print(sys.path)\\\\n\\', 2: \\'x = 2\\\\n\\', 3: \\'print(x ** 32)\\\\n\\'}\\n\\nIn fact, both set and dictionary comprehensions support the extended syntax of list\\ncomprehensions we met earlier in this chapter, including if tests:\\n\\n>>> {line for line in open(\\'script2.py\\') if line[0] == \\'p\\'}\\n{\\'print(x ** 32)\\\\n\\', \\'print(sys.path)\\\\n\\'}\\n>>> {ix: line for (ix, line) in enumerate(open(\\'script2.py\\')) if line[0] == \\'p\\'}\\n{1: \\'print(sys.path)\\\\n\\', 3: \\'print(x ** 32)\\\\n\\'}\\n\\nLike the list comprehension, both of these scan the file line by line and pick out lines\\nthat begin with the letter p. They also happen to build sets and dictionaries in the end,\\nbut  we  get  a  lot  of  work  “for  free”  by  combining  file  iteration  and  comprehension\\nsyntax. Later in the book we’ll meet a relative of comprehensions—generator expres-\\nsions—that deploys the same syntax and works on iterables too, but is also iterable\\nitself:\\n\\n>>> list(line.upper() for line in open(\\'script2.py\\'))          # See Chapter 20\\n[\\'IMPORT SYS\\\\n\\', \\'PRINT(SYS.PATH)\\\\n\\', \\'X = 2\\\\n\\', \\'PRINT(X ** 32)\\\\n\\']\\n\\nOther built-in functions support the iteration protocol as well, but frankly, some are\\nharder to cast in interesting examples related to files! For example, the sum call computes\\nthe sum of all the numbers in any iterable; the any and all built-ins return True if any\\nor all items in an iterable are True, respectively; and max and min return the largest and\\nsmallest item in an iterable, respectively. Like reduce, all of the tools in the following\\n\\n432 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0cexamples accept any iterable as an argument and use the iteration protocol to scan it,\\nbut return a single result:\\n\\n>>> sum([3, 2, 4, 1, 5, 0])                  # sum expects numbers only\\n15\\n>>> any([\\'spam\\', \\'\\', \\'ni\\'])\\nTrue\\n>>> all([\\'spam\\', \\'\\', \\'ni\\'])\\nFalse\\n>>> max([3, 2, 5, 1, 4])\\n5\\n>>> min([3, 2, 5, 1, 4])\\n1\\n\\nStrictly speaking, the max and min functions can be applied to files as well—they auto-\\nmatically use the iteration protocol to scan the file and pick out the lines with the highest\\nand lowest string values, respectively (though I’ll leave valid use cases to your imagi-\\nnation):\\n\\n>>> max(open(\\'script2.py\\'))                  # Line with max/min string value\\n\\'x = 2\\\\n\\'\\n>>> min(open(\\'script2.py\\'))\\n\\'import sys\\\\n\\'\\n\\nThere’s one last iteration context that’s worth mentioning, although it’s mostly a pre-\\nview: in Chapter 18, we’ll learn that a special *arg form can be used in function calls\\nto unpack a collection of values into individual arguments. As you can probably predict\\nby now, this accepts any iterable, too, including files (see Chapter 18 for more details\\non this call syntax; Chapter 20 for a section that extends this idea to generator expres-\\nsions; and Chapter 11 for tips on using the following’s 3.X print in 2.X as usual):\\n\\n>>> def f(a, b, c, d): print(a, b, c, d, sep=\\'&\\')\\n...\\n>>> f(1, 2, 3, 4)\\n1&2&3&4\\n>>> f(*[1, 2, 3, 4])                   # Unpacks into arguments\\n1&2&3&4\\n>>>\\n>>> f(*open(\\'script2.py\\'))             # Iterates by lines too!\\nimport sys\\n&print(sys.path)\\n&x = 2\\n&print(x ** 32)\\n\\nIn fact, because this argument-unpacking syntax in calls accepts iterables, it’s also pos-\\nsible to use the zip built-in to unzip zipped tuples, by making prior or nested zip results\\narguments for another zip call (warning: you probably shouldn’t read the following\\nexample if you plan to operate heavy machinery anytime soon!):\\n\\n>>> X = (1, 2)\\n>>> Y = (3, 4)\\n>>>\\n>>> list(zip(X, Y))                    # Zip tuples: returns an iterable\\n[(1, 3), (2, 4)]\\n\\nOther Iteration Contexts\\n\\n| 433\\n\\n\\x0c>>>\\n>>> A, B = zip(*zip(X, Y))             # Unzip a zip!\\n>>> A\\n(1, 2)\\n>>> B\\n(3, 4)\\n\\nStill  other  tools  in  Python,  such  as  the  range  built-in  and  dictionary  view  objects,\\nreturn iterables instead of processing them. To see how these have been absorbed into\\nthe iteration protocol in Python 3.X as well, we need to move on to the next section.\\n\\nNew Iterables in Python 3.X\\nOne of the fundamental distinctions of Python 3.X is its stronger emphasis on iterators\\nthan 2.X. This, along with its Unicode model and mandated new-style classes, is one\\nof 3.X’s most sweeping changes.\\nSpecifically, in addition to the iterators associated with built-in types such as files and\\ndictionaries, the dictionary methods keys, values, and items return iterable objects in\\nPython 3.X, as do the built-in functions range, map, zip, and filter. As shown in the\\nprior section, the last three of these functions both return iterables and process them.\\nAll of these tools produce results on demand in Python 3.X, instead of constructing\\nresult lists as they do in 2.X.\\n\\nImpacts on 2.X Code: Pros and Cons\\nAlthough this saves memory space, it can impact your coding styles in some contexts.\\nIn various places in this book so far, for example, we’ve had to wrap up some function\\nand method call results in a list(...) call in order to force them to produce all their\\nresults at once for display:\\n\\n>>> zip(\\'abc\\', \\'xyz\\')                  # An iterable in Python 3.X (a list in 2.X)\\n<zip object at 0x000000000294C308>\\n\\n>>> list(zip(\\'abc\\', \\'xyz\\'))            # Force list of results in 3.X to display\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\')]\\n\\nA similar conversion is required if we wish to apply list or sequence operations to most\\niterables that generate items on demand—to index, slice, or concatenate the iterable\\nitself, for example. The list results for these tools in 2.X support such operations di-\\nrectly:\\n\\n>>> Z = zip((1, 2), (3, 4))            # Unlike 2.X lists, cannot index, etc.\\n>>> Z[0]\\nTypeError: \\'zip\\' object is not subscriptable\\n\\nAs we’ll see in more detail in Chapter 20, conversion to lists may also be more subtly\\nrequired to support multiple iterations for newly iterable tools that support just one\\n\\n434 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0cscan such as map and zip—unlike their 2.X list forms, their values in 3.X are exhausted\\nafter a single pass:\\n\\n>>> M = map(lambda x: 2 ** x, range(3))\\n>>> for i in M: print(i)\\n...\\n1\\n2\\n4\\n>>> for i in M: print(i)               # Unlike 2.X lists, one pass only (zip too)\\n...\\n>>>\\n\\nSuch conversion isn’t required in 2.X, because functions like zip return lists of results.\\nIn 3.X, though, they return iterable objects, producing results on demand. This may\\nbreak 2.X code, and means extra typing is required to display the results at the inter-\\nactive prompt (and possibly in some other contexts), but it’s an asset in larger programs\\n—delayed evaluation like this conserves memory and avoids pauses while large result\\nlists are computed. Let’s take a quick look at some of the new 3.X iterables in action.\\n\\nThe range Iterable\\nWe studied the range built-in’s basic behavior in the preceding chapter. In 3.X, it returns\\nan iterable that generates numbers in the range on demand, instead of building the\\nresult list in memory. This subsumes the older 2.X xrange (see the upcoming version\\nskew note), and you must use list(range(...)) to force an actual range list if one is\\nneeded (e.g., to display results):\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> R = range(10)                # range returns an iterable, not a list\\n>>> R\\nrange(0, 10)\\n\\n>>> I = iter(R)                  # Make an iterator from the range iterable\\n>>> next(I)                      # Advance to next result\\n0                                # What happens in for loops, comprehensions, etc.\\n>>> next(I)\\n1\\n>>> next(I)\\n2\\n\\n>>> list(range(10))              # To force a list if required\\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\\n\\nUnlike the list returned by this call in 2.X, range objects in 3.X support only iteration,\\nindexing, and the len function. They do not support any other sequence operations\\n(use list(...) if you require more list tools):\\n\\n>>> len(R)                       # range also does len and indexing, but no others\\n10\\n>>> R[0]\\n0\\n\\nNew Iterables in Python 3.X | 435\\n\\n\\x0c>>> R[-1]\\n9\\n\\n>>> next(I)                      # Continue taking from iterator, where left off\\n3\\n>>> I.__next__()                 # .next() becomes .__next__(), but use new next()\\n4\\n\\nVersion skew note: As first mentioned in the preceding chapter, Python\\n2.X also has a built-in called xrange, which is like range but produces\\nitems on demand instead of building a list of results in memory all at\\nonce. Since this is exactly what the new iterator-based range does in\\nPython 3.X, xrange is no longer available in 3.X—it has been subsumed.\\nYou may still both see and use it in 2.X code, though, especially since\\nrange builds result lists there and so is not as efficient in its memory\\nusage.\\n\\nAs noted in the prior chapter, the file.xreadlines() method used to\\nminimize memory use in 2.X has been dropped in Python 3.X for similar\\nreasons, in favor of file iterators.\\n\\nThe map, zip, and filter Iterables\\nLike range, the map, zip, and filter built-ins also become iterables in 3.X to conserve\\nspace, rather than producing a result list all at once in memory. All three not only\\nprocess iterables, as in 2.X, but also return iterable results in 3.X. Unlike range, though,\\nthey are their own iterators—after you step through their results once, they are ex-\\nhausted. In other words, you can’t have multiple iterators on their results that maintain\\ndifferent positions in those results.\\nHere is the case for the map built-in we met in the prior chapter. As with other iterables,\\nyou can force a list with list(...) if you really need one, but the default behavior can\\nsave substantial space in memory for large result sets:\\n\\n>>> M = map(abs, (-1, 0, 1))            # map returns an iterable, not a list\\n>>> M\\n<map object at 0x00000000029B75C0>\\n>>> next(M)                             # Use iterator manually: exhausts results\\n1                                       # These do not support len() or indexing\\n>>> next(M)\\n0\\n>>> next(M)\\n1\\n>>> next(M)\\nStopIteration\\n\\n>>> for x in M: print(x)                # map iterator is now empty: one pass only\\n...\\n\\n>>> M = map(abs, (-1, 0, 1))            # Make a new iterable/iterator to scan again\\n>>> for x in M: print(x)                # Iteration contexts auto call next()\\n\\n436 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0c...\\n1\\n0\\n1\\n>>> list(map(abs, (-1, 0, 1)))          # Can force a real list if needed\\n[1, 0, 1]\\n\\nThe zip built-in, introduced in the prior chapter, is an iteration context itself, but also\\nreturns an iterable with an iterator that works the same way:\\n\\n>>> Z = zip((1, 2, 3), (10, 20, 30))    # zip is the same: a one-pass iterator\\n>>> Z\\n<zip object at 0x0000000002951108>\\n\\n>>> list(Z)\\n[(1, 10), (2, 20), (3, 30)]\\n\\n>>> for pair in Z: print(pair)          # Exhausted after one pass\\n...\\n\\n>>> Z = zip((1, 2, 3), (10, 20, 30))\\n>>> for pair in Z: print(pair)          # Iterator used automatically or manually\\n...\\n(1, 10)\\n(2, 20)\\n(3, 30)\\n\\n>>> Z = zip((1, 2, 3), (10, 20, 30))    # Manual iteration (iter() not needed)\\n>>> next(Z)\\n(1, 10)\\n>>> next(Z)\\n(2, 20)\\n\\nThe filter built-in, which we met briefly in Chapter 12 and will study in the next part\\nof this book, is also analogous. It returns items in an iterable for which a passed-in\\nfunction returns True (as we’ve learned, in Python True includes nonempty objects, and\\nbool returns an object’s truth value):\\n\\n>>> filter(bool, [\\'spam\\', \\'\\', \\'ni\\'])\\n<filter object at 0x00000000029B7B70>\\n>>> list(filter(bool, [\\'spam\\', \\'\\', \\'ni\\']))\\n[\\'spam\\', \\'ni\\']\\n\\nLike most of the tools discussed in this section, filter both accepts an iterable to process\\nand returns an iterable to generate results in 3.X. It can also generally be emulated by\\nextended list comprehension syntax that automatically tests truth values:\\n\\n>>> [x for x in [\\'spam\\', \\'\\', \\'ni\\'] if bool(x)]\\n[\\'spam\\', \\'ni\\']\\n>>> [x for x in [\\'spam\\', \\'\\', \\'ni\\'] if x]\\n[\\'spam\\', \\'ni\\']\\n\\nNew Iterables in Python 3.X | 437\\n\\n\\x0cMultiple Versus Single Pass Iterators\\nIt’s important to see how the range object differs from the built-ins described in this\\nsection—it supports len and indexing, it is not its own iterator (you make one with\\niter when iterating manually), and it supports multiple iterators over its result that\\nremember their positions independently:\\n\\n>>> R = range(3)                           # range allows multiple iterators\\n>>> next(R)\\nTypeError: range object is not an iterator\\n\\n>>> I1 = iter(R)\\n>>> next(I1)\\n0\\n>>> next(I1)\\n1\\n>>> I2 = iter(R)                           # Two iterators on one range\\n>>> next(I2)\\n0\\n>>> next(I1)                               # I1 is at a different spot than I2\\n2\\n\\nBy contrast, in 3.X zip, map, and filter do not support multiple active iterators on the\\nsame result; because of this the iter call is optional for stepping through such objects’\\nresults—their iter is themselves (in 2.X these built-ins return multiple-scan lists so the\\nfollowing does not apply):\\n\\n>>> Z = zip((1, 2, 3), (10, 11, 12))\\n>>> I1 = iter(Z)\\n>>> I2 = iter(Z)                           # Two iterators on one zip\\n>>> next(I1)\\n(1, 10)\\n>>> next(I1)\\n(2, 11)\\n>>> next(I2)                               # (3.X) I2 is at same spot as I1!\\n(3, 12)\\n\\n>>> M = map(abs, (-1, 0, 1))               # Ditto for map (and filter)\\n>>> I1 = iter(M); I2 = iter(M)\\n>>> print(next(I1), next(I1), next(I1))\\n1 0 1\\n>>> next(I2)                               # (3.X) Single scan is exhausted!\\nStopIteration\\n\\n>>> R = range(3)                           # But range allows many iterators\\n>>> I1, I2 = iter(R), iter(R)\\n>>> [next(I1), next(I1), next(I1)]\\n[0 1 2]\\n>>> next(I2)                               # Multiple active scans, like 2.X lists\\n0\\n\\nWhen we code our own iterable objects with classes later in the book (Chapter 30),\\nwe’ll see that multiple iterators are usually supported by returning new objects for the\\niter call; a single iterator generally means an object returns itself. In Chapter 20, we’ll\\n\\n438 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0calso find that generator functions and expressions behave like map and zip instead of\\nrange in this regard, supporting just a single active iteration scan. In that chapter, we’ll\\nsee some subtle implications of one-shot iterators in loops that attempt to scan multiple\\ntimes—code that formerly treated these as lists may fail without manual list conver-\\nsions.\\n\\nDictionary View Iterables\\nFinally, as we saw briefly in Chapter 8, in Python 3.X the dictionary keys, values, and\\nitems methods return iterable view objects that generate result items one at a time,\\ninstead of producing result lists all at once in memory. Views are also available in 2.7\\nas an option, but under special method names to avoid impacting existing code. View\\nitems maintain the same physical ordering as that of the dictionary and reflect changes\\nmade to the underlying dictionary. Now that we know more about iterables here’s the\\nrest of this story—in Python 3.3 (your key order may vary):\\n\\n>>> D = dict(a=1, b=2, c=3)\\n>>> D\\n{\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n\\n>>> K = D.keys()                              # A view object in 3.X, not a list\\n>>> K\\ndict_keys([\\'a\\', \\'b\\', \\'c\\'])\\n\\n>>> next(K)                                   # Views are not iterators themselves\\nTypeError: dict_keys object is not an iterator\\n\\n>>> I = iter(K)                               # View iterables have an iterator,\\n>>> next(I)                                   # which can be used manually,\\n\\'a\\'                                           # but does not support len(), index\\n>>> next(I)\\n\\'b\\'\\n\\n>>> for k in D.keys(): print(k, end=\\' \\')      # All iteration contexts use auto\\n...\\na b c\\n\\nAs for all iterables that produce values on request, you can always force a 3.X dictionary\\nview to build a real list by passing it to the list built-in. However, this usually isn’t\\nrequired except to display results interactively or to apply list operations like indexing:\\n\\n>>> K = D.keys()\\n>>> list(K)                              # Can still force a real list if needed\\n[\\'a\\', \\'b\\', \\'c\\']\\n\\n>>> V = D.values()                       # Ditto for values() and items() views\\n>>> V\\ndict_values([1, 2, 3])\\n>>> list(V)                              # Need list() to display or index as list\\n[1, 2, 3]\\n\\n>>> V[0]\\n\\nNew Iterables in Python 3.X | 439\\n\\n\\x0cTypeError: \\'dict_values\\' object does not support indexing\\n>>> list(V)[0]\\n1\\n\\n>>> list(D.items())\\n[(\\'a\\', 1), (\\'b\\', 2), (\\'c\\', 3)]\\n\\n>>> for (k, v) in D.items(): print(k, v, end=\\' \\')\\n...\\na 1 b 2 c 3\\n\\nIn addition, 3.X dictionaries still are iterables themselves, with an iterator that returns\\nsuccessive keys. Thus, it’s not often necessary to call keys directly in this context:\\n\\n>>> D                                    # Dictionaries still produce an iterator\\n{\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}                 # Returns next key on each iteration\\n>>> I = iter(D)\\n>>> next(I)\\n\\'a\\'\\n>>> next(I)\\n\\'b\\'\\n\\n>>> for key in D: print(key, end=\\' \\')    # Still no need to call keys() to iterate\\n...                                      # But keys is an iterable in 3.X too!\\na b c\\n\\nFinally, remember again that because keys no longer returns a list, the traditional coding\\npattern for scanning a dictionary by sorted keys won’t work in 3.X. Instead, convert\\nkeys views first with a list call, or use the sorted call on either a keys view or the\\ndictionary itself, as follows. We saw this in Chapter 8, but it’s important enough to 2.X\\nprogrammers making the switch to demonstrate again:\\n\\n>>> D\\n{\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> for k in sorted(D.keys()): print(k, D[k], end=\\' \\')\\n...\\na 1 b 2 c 3\\n>>> for k in sorted(D): print(k, D[k], end=\\' \\')    # \"Best practice\" key sorting\\n...\\na 1 b 2 c 3\\n\\nOther Iteration Topics\\nAs mentioned in this chapter’s introduction, there is more coverage of both list com-\\nprehensions and iterables in Chapter 20, in conjunction with functions, and again in\\nChapter 30 when we study classes. As you’ll see later:\\n\\n• User-defined  functions  can  be  turned  into  iterable  generator  functions,  with\\n\\nyield statements.\\n\\n• List  comprehensions  morph  into  iterable  generator  expressions  when  coded  in\\n\\nparentheses.\\n\\n440 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0c• User-defined classes are made iterable with __iter__ or __getitem__ operator over-\\n\\nloading.\\n\\nIn particular, user-defined iterables defined with classes allow arbitrary objects and\\noperations to be used in any of the iteration contexts we’ve met in this chapter. By\\nsupporting just a single operation—iteration—objects may be used in a wide variety of\\ncontexts and tools.\\n\\nChapter Summary\\nIn this chapter, we explored concepts related to looping in Python. We took our first\\nsubstantial look at the iteration protocol in Python—a way for nonsequence objects to\\ntake part in iteration loops—and at list comprehensions. As we saw, a list comprehen-\\nsion is an expression similar to a for loop that applies another expression to all the\\nitems in any iterable object. Along the way, we also saw other built-in iteration tools\\nat work and studied recent iteration additions in Python 3.X.\\nThis wraps up our tour of specific procedural statements and related tools. The next\\nchapter closes out this part of the book by discussing documentation options for Python\\ncode. Though a bit of a diversion from the more detailed aspects of coding, documen-\\ntation is also part of the general syntax model, and it’s an important component of well-\\nwritten programs. In the next chapter, we’ll also dig into a set of exercises for this part\\nof the book before we turn our attention to larger structures such as functions. As usual,\\nthough, let’s first exercise what we’ve learned here with a quiz.\\n\\nTest Your Knowledge: Quiz\\n1. How are for loops and iterable objects related?\\n2. How are for loops and list comprehensions related?\\n3. Name four iteration contexts in the Python language.\\n4. What is the best way to read line by line from a text file today?\\n5. What sort of weapons would you expect to see employed by the Spanish Inquisi-\\n\\ntion?\\n\\nTest Your Knowledge: Answers\\n1. The for loop uses the iteration protocol to step through items in the iterable object\\nacross which it is iterating. It first fetches an iterator from the iterable by passing\\nthe object to iter, and then calls this iterator object’s __next__ method in 3.X on\\neach iteration and catches the StopIteration exception to determine when to stop\\nlooping. The method is named next in 2.X, and is run by the next built-in function\\nin both 3.x and 2.X. Any object that supports this model works in a for loop and\\n\\nTest Your Knowledge: Answers\\n\\n| 441\\n\\n\\x0cin all other iteration contexts. For some objects that are their own iterator, the\\ninitial iter call is extraneous but harmless.\\n\\n2. Both are iteration tools and contexts. List comprehensions are a concise and often\\nefficient way to perform a common for loop task: collecting the results of applying\\nan expression to all items in an iterable object. It’s always possible to translate a\\nlist comprehension to a for loop, and part of the list comprehension expression\\nlooks like the header of a for loop syntactically.\\n\\n3. Iteration contexts in Python include the for loop; list comprehensions; the map\\nbuilt-in function; the in membership test expression; and the built-in functions\\nsorted, sum, any, and all. This category also includes the list and tuple built-ins,\\nstring join methods, and sequence assignments, all of which use the iteration pro-\\ntocol (see answer #1) to step across iterable objects one item at a time.\\n\\n4. The best way to read lines from a text file today is to not read it explicitly at all:\\ninstead, open the file within an iteration context tool such as a for loop or list\\ncomprehension, and let the iteration tool automatically scan one line at a time by\\nrunning the file’s next handler method on each iteration. This approach is generally\\nbest in terms of coding simplicity, memory space, and possibly execution speed\\nrequirements.\\n\\n5. I’ll accept any of the following as correct answers: fear, intimidation, nice red uni-\\n\\nforms, a comfy chair, and soft pillows.\\n\\n442 | Chapter 14:\\u2002Iterations and Comprehensions\\n\\n\\x0cCHAPTER 15\\nThe Documentation Interlude\\n\\nThis part of the book concludes with a look at techniques and tools used for docu-\\nmenting Python code. Although Python code is designed to be readable, a few well-\\nplaced human-accessible comments can do much to help others understand the work-\\nings of your programs. As we’ll see, Python includes both syntax and tools to make\\ndocumentation easier. In particular, the PyDoc system covered here can render a mod-\\nule’s internal documentation as either plain text in a shell, or HTML in a web browser.\\nAlthough this is something of a tools-related concept, this topic is presented here partly\\nbecause it involves Python’s syntax model, and partly as a resource for readers strug-\\ngling to understand Python’s toolset. For the latter purpose, I’ll also expand here on\\ndocumentation pointers first given in Chapter 4. As usual, because this chapter closes\\nout its part, it also ends with some warnings about common pitfalls and a set of exercises\\nfor this part of the text, in addition to its chapter quiz.\\n\\nPython Documentation Sources\\nBy this point in the book, you’re probably starting to realize that Python comes with\\nan amazing amount of prebuilt functionality—built-in functions and exceptions, pre-\\ndefined object attributes and methods, standard library modules, and more. And we’ve\\nreally only scratched the surface of each of these categories.\\nOne of the first questions that bewildered beginners often ask is: how do I find infor-\\nmation on all the built-in tools? This section provides hints on the various documen-\\ntation sources available in Python. It also presents documentation strings (docstrings)\\nand the PyDoc system that makes use of them. These topics are somewhat peripheral\\nto the core language itself, but they become essential knowledge as soon as your code\\nreaches the level of the examples and exercises in this part of the book.\\nAs summarized in Table 15-1, there are a variety of places to look for information on\\nPython, with generally increasing verbosity. Because documentation is such a crucial\\ntool in practical programming, we’ll explore each of these categories in the sections\\nthat follow.\\n\\n443\\n\\n\\x0cTable 15-1. Python documentation sources\\n\\nForm\\n# comments\\nThe dir function\\nDocstrings: __doc__\\nPyDoc: the help function\\nPyDoc: HTML reports\\nSphinx third-party tool\\nThe standard manual set\\nWeb resources\\nPublished books\\n\\nRole\\nIn-file documentation\\nLists of attributes available in objects\\nIn-file documentation attached to objects\\nInteractive help for objects\\nModule documentation in a browser\\nRicher documentation for larger projects\\nOfficial language and library descriptions\\nOnline tutorials, examples, and so on\\nCommercially polished reference texts\\n\\n# Comments\\nAs we’ve learned, hash-mark comments are the most basic way to document your code.\\nPython simply ignores all the text following a # (as long as it’s not inside a string literal),\\nso you can follow this character with any words and descriptions meaningful to pro-\\ngrammers. Such comments are accessible only in your source files, though; to code\\ncomments that are more widely available, you’ll need to use docstrings.\\nIn fact, current best practice generally dictates that docstrings are best for larger func-\\ntional documentation (e.g., “my file does this”), and # comments are best limited to\\nsmaller code documentation (e.g., “this strange expression does that”) and are best\\nlimited in scope to a statement or small group of statements within a script or function.\\nMore on docstrings in a moment; first, let’s see how to explore objects.\\n\\nThe dir Function\\nAs we’ve also seen, the built-in  dir function is an easy way to grab a list of all the\\nattributes available inside an object (i.e., its methods and simpler data items). It can be\\ncalled with no arguments to list variables in the caller’s scope. More usefully, it can also\\nbe called on any object that has attributes, including imported modules and built-in\\ntypes, as well as the name of a data type. For example, to find out what’s available in\\na module such as the standard library’s sys, import it and pass it to dir:\\n\\n>>> import sys\\n>>> dir(sys)\\n[\\'__displayhook__\\', ...more names omitted..., \\'winver\\']\\n\\nThese results are from Python 3.3, and I’m omitting most returned names because they\\nvary slightly elsewhere; run this on your own for a better look. In fact, there are currently\\n78 attributes in sys, though we generally care only about the 69 that do not have leading\\ndouble  underscores  (two  usually  means  interpreter-related)  or  the  62  that  have  no\\n\\n444 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cleading underscore at all (one underscore usually means informal implementation pri-\\nvate)—a prime example of the preceding chapter’s list comprehension at work:\\n\\n>>> len(dir(sys))                                             # Number names in sys\\n78\\n>>> len([x for x in dir(sys) if not x.startswith(\\'__\\')])      # Non __X names only\\n69\\n>>> len([x for x in dir(sys) if not x[0] == \\'_\\'])             # Non underscore names\\n62\\n\\nTo find out what attributes are provided in objects of built-in types, run dir on a literal\\nor an existing instance of the desired type. For example, to see list and string attributes,\\nyou can pass empty objects:\\n\\n>>> dir([])\\n[\\'__add__\\', \\'__class__\\', \\'__contains__\\', ...more..., \\'append\\', \\'clear\\', \\'copy\\',\\n\\'count\\', \\'extend\\', \\'index\\', \\'insert\\', \\'pop\\', \\'remove\\', \\'reverse\\', \\'sort\\']\\n\\n>>> dir(\\'\\')\\n[\\'__add__\\', \\'__class__\\', \\'__contains__\\', ...more..., \\'split\\', \\'splitlines\\',\\n\\'startswith\\',\\'strip\\', \\'swapcase\\', \\'title\\', \\'translate\\', \\'upper\\', \\'zfill\\']\\n\\nThe dir results for any built-in type include a set of attributes that are related to the\\nimplementation of that type (technically, operator overloading methods); much as in\\nmodules they all begin and end with double underscores to make them distinct, and\\nyou  can  safely  ignore  them  at  this  point  in  the  book  (they  are  used  for  OOP).  For\\ninstance, there are 45 list attributes, but only 11 that correspond to named methods:\\n\\n>>> len(dir([])), len([x for x in dir([]) if not x.startswith(\\'__\\')])\\n(45, 11)\\n>>> len(dir(\\'\\')), len([x for x in dir(\\'\\') if not x.startswith(\\'__\\')])\\n(76, 44)\\n\\nIn fact, to filter out double-underscored items that are not of common program interest,\\nrun the same list comprehensions but print the attributes. For instance, here are the\\nnamed attributes in lists and dictionaries in Python 3.3:\\n\\n>>> [a for a in dir(list) if not a.startswith(\\'__\\')]\\n[\\'append\\', \\'clear\\', \\'copy\\', \\'count\\', \\'extend\\', \\'index\\', \\'insert\\', \\'pop\\',\\n\\'remove\\', \\'reverse\\', \\'sort\\']\\n\\n>>> [a for a in dir(dict) if not a.startswith(\\'__\\')]\\n[\\'clear\\', \\'copy\\', \\'fromkeys\\', \\'get\\', \\'items\\', \\'keys\\', \\'pop\\', \\'popitem\\',\\n\\'setdefault\\', \\'update\\', \\'values\\']\\n\\nThis may seem like a lot to type to get an attribute list, but beginning in the next chapter\\nwe’ll learn how to wrap such code in an importable and reusable function so we don’t\\nneed to type it again:\\n\\n>>> def dir1(x): return [a for a in dir(x) if not a.startswith(\\'__\\')]  # See Part IV\\n...\\n>>> dir1(tuple)\\n[\\'count\\', \\'index\\']\\n\\nPython Documentation Sources\\n\\n| 445\\n\\n\\x0cNotice that you can list built-in type attributes by passing a type name to dir instead\\nof a literal:\\n\\n>>> dir(str) == dir(\\'\\')           # Same result, type name or literal\\nTrue\\n>>> dir(list) == dir([])\\nTrue\\n\\nThis works because names like str and list that were once type converter functions\\nare actually names of types in Python today; calling one of these invokes its constructor\\nto generate an instance of that type. Part VI will have more to say about constructors\\nand operator overloading methods when we discuss classes.\\nThe dir function serves as a sort of memory-jogger—it provides a list of attribute names,\\nbut it does not tell you anything about what those names mean. For such extra infor-\\nmation, we need to move on to the next documentation source.\\n\\nSome IDEs for Python work, including IDLE, have features that list at-\\ntributes on objects automatically within their GUIs, and can be viewed\\nas alternatives to dir. IDLE, for example, will list an object’s attributes\\nin a pop-up selection window when you type a period after the object’s\\nname and pause or press Tab. This is mostly meant as an autocomplete\\nfeature,  though,  not  an  information  source.  Chapter  3  has  more  on\\nIDLE.\\n\\nDocstrings: __doc__\\nBesides # comments, Python supports documentation that is automatically attached to\\nobjects and retained at runtime for inspection. Syntactically, such comments are coded\\nas strings at the tops of module files and function and class statements, before any other\\nexecutable code (# comments, including Unix-stye #! lines are OK before them). Python\\nautomatically stuffs the text of these strings, known informally as docstrings, into the\\n__doc__ attributes of the corresponding objects.\\n\\nUser-defined docstrings\\nFor  example,  consider  the  following  file,  docstrings.py.  Its  docstrings  appear  at  the\\nbeginning of the file and at the start of a function and a class within it. Here, I’ve used\\ntriple-quoted block strings for multiline comments in the file and the function, but any\\nsort of string will work; single- or double-quoted one-liners like those in the class are\\nfine, but don’t allow multiple-line text. We haven’t studied the def or class statements\\nin detail yet, so ignore everything about them here except the strings at their tops:\\n\\n\"\"\"\\nModule documentation\\nWords Go Here\\n\"\"\"\\n\\n446 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cspam = 40\\n\\ndef square(x):\\n    \"\"\"\\n    function documentation\\n    can we have your liver then?\\n    \"\"\"\\n    return x ** 2          # square\\n\\nclass Employee:\\n    \"class documentation\"\\n    pass\\n\\nprint(square(4))\\nprint(square.__doc__)\\n\\nThe whole point of this documentation protocol is that your comments are retained\\nfor inspection in __doc__ attributes after the file is imported. Thus, to display the doc-\\nstrings associated with the module and its objects, we simply import the file and print\\ntheir __doc__ attributes, where Python has saved the text:\\n\\n>>> import docstrings\\n16\\n\\n    function documentation\\n    can we have your liver then?\\n\\n>>> print(docstrings.__doc__)\\n\\nModule documentation\\nWords Go Here\\n\\n>>> print(docstrings.square.__doc__)\\n\\n    function documentation\\n    can we have your liver then?\\n\\n>>> print(docstrings.Employee.__doc__)\\n    class documentation\\n\\nNote that you will generally want to use print to print docstrings; otherwise, you’ll get\\na single string with embedded \\\\n newline characters.\\nYou can also attach docstrings to methods of classes (covered in Part VI), but because\\nthese are just def statements nested in class statements, they’re not a special case. To\\nfetch the docstring of a method function inside a class within a module, you would\\nsimply extend the path to go through the class: module.class.method.__doc__ (we’ll see\\nan example of method docstrings in Chapter 29).\\n\\nDocstring standards and priorities\\nAs mentioned earlier, common practice today recommends hash-mark comments for\\nonly smaller-scale documentation about an expression, statement, or small group of\\n\\nPython Documentation Sources\\n\\n| 447\\n\\n\\x0cstatements. Docstrings are better used for higher-level and broader functional docu-\\nmentation for a file, function, or class, and have become an expected part of Python\\nsoftware. Beyond these guidelines, though, you still must decide what to write.\\nAlthough some companies have internal standards, there is no broad standard about\\nwhat should go into the text of a docstring. There have been various markup language\\nand template proposals (e.g., HTML or XML), but they don’t seem to have caught on\\nin the Python world. Frankly, convincing Python programmers to document their code\\nusing handcoded HTML is probably not going to happen in our lifetimes. That may\\nbe too much to ask, but this doesn’t apply to documenting code in general.\\nDocumentation  tends  to  have  a  lower  priority  among  some  programmers  than  it\\nshould. Too often, if you get any comments in a file at all, you count yourself lucky\\n(and even better if it’s accurate and up to date). I strongly encourage you to document\\nyour code liberally—it really is an important part of well-written programs. When you\\ndo, though, there is presently no standard on the structure of docstrings; if you want\\nto use them, anything goes today. Just as for writing code itself, it’s up to you to create\\ndocumentation content and keep it up to date, but common sense is probably your\\nbest ally on this task too.\\n\\nBuilt-in docstrings\\nAs it turns out, built-in modules and objects in Python use similar techniques to attach\\ndocumentation above and beyond the attribute lists returned by dir. For example, to\\nsee an actual human-readable description of a built-in module, import it and print its\\n__doc__ string:\\n\\n>>> import sys\\n>>> print(sys.__doc__)\\nThis module provides access to some objects used or maintained by the\\ninterpreter and to functions that interact strongly with the interpreter.\\n\\nDynamic objects:\\n\\nargv -- command line arguments; argv[0] is the script pathname if known\\npath -- module search path; path[0] is the script directory, else \\'\\'\\nmodules -- dictionary of loaded modules\\n...more text omitted...\\n\\nFunctions, classes, and methods within built-in modules have attached descriptions in\\ntheir __doc__ attributes as well:\\n\\n>>> print(sys.getrefcount.__doc__)\\ngetrefcount(object) -> integer\\n\\nReturn the reference count of object.  The count returned is generally\\none higher than you might expect, because it includes the (temporary)\\nreference as an argument to getrefcount().\\n\\nYou can also read about built-in functions via their docstrings:\\n\\n448 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0c>>> print(int.__doc__)\\nint(x[, base]) -> integer\\n\\nConvert a string or number to an integer, if possible.  A floating\\npoint argument will be truncated towards zero (this does not include a\\n...more text omitted...\\n\\n>>> print(map.__doc__)\\nmap(func, *iterables) --> map object\\n\\nMake an iterator that computes the function using arguments from\\neach of the iterables.  Stops when the shortest iterable is exhausted.\\n\\nYou can get a wealth of information about built-in tools by inspecting their docstrings\\nthis way, but you don’t have to—the help function, the topic of the next section, does\\nthis automatically for you.\\n\\nPyDoc: The help Function\\nThe docstring technique proved to be so useful that Python eventually added a tool\\nthat makes docstrings even easier to display. The standard PyDoc tool is Python code\\nthat knows how to extract docstrings and associated structural information and format\\nthem into nicely arranged reports of various types. Additional tools for extracting and\\nformatting docstrings are available in the open source domain (including tools that may\\nsupport structured text—search the Web for pointers), but Python ships with PyDoc\\nin its standard library.\\nThere are a variety of ways to launch PyDoc, including command-line script options\\nthat can save the resulting documentation for later viewing (described both ahead and\\nin the Python library manual). Perhaps the two most prominent PyDoc interfaces are\\nthe built-in help function and the PyDoc GUI- and web-based HTML report interfaces.\\nWe met the help function briefly in Chapter 4; it invokes PyDoc to generate a simple\\ntextual report for any Python object. In this mode, help text looks much like a “man-\\npage” on Unix-like systems, and in fact pages the same way as a Unix “more” outside\\nGUIs like IDLE when there are multiple pages of text—press the space bar to move to\\nthe next page, Enter to go to the next line, and Q to quit:\\n\\n>>> import sys\\n>>> help(sys.getrefcount)\\nHelp on built-in function getrefcount in module sys:\\n\\ngetrefcount(...)\\n    getrefcount(object) -> integer\\n\\n    Return the reference count of object.  The count returned is generally\\n    one higher than you might expect, because it includes the (temporary)\\n    reference as an argument to getrefcount().\\n\\nNote that you do not have to import sys in order to call help, but you do have to import\\nsys to get help on sys this way; it expects an object reference to be passed in. In Pythons\\n\\nPython Documentation Sources\\n\\n| 449\\n\\n\\x0c3.3  and  2.7,  you  can  get  help  for  a  module  you  have  not  imported  by  quoting  the\\nmodule’s  name  as  a  string—for  example,  help(\\'re\\'),  help(\\'email.message\\')—but\\nsupport for this and other modes may differ across Python versions.\\nFor larger objects such as modules and classes, the help display is broken down into\\nmultiple sections, the preambles of which are shown here. Run this interactively to see\\nthe full report (I’m running this on 3.3):\\n\\n>>> help(sys)\\nHelp on built-in module sys:\\n\\nNAME\\n    sys\\n\\nMODULE REFERENCE\\n    http://docs.python.org/3.3/library/sys\\n    ...more omitted...\\n\\nDESCRIPTION\\n    This module provides access to some objects used or maintained by the\\n    interpreter and to functions that interact strongly with the interpreter.\\n    ...more omitted...\\n\\nFUNCTIONS\\n    __displayhook__ = displayhook(...)\\n        displayhook(object) -> None\\n    ...more omitted...\\n\\nDATA\\n    __stderr__ = <_io.TextIOWrapper name=\\'<stderr>\\' mode=\\'w\\' encoding=\\'cp4...\\n    __stdin__ = <_io.TextIOWrapper name=\\'<stdin>\\' mode=\\'r\\' encoding=\\'cp437...\\n    __stdout__ = <_io.TextIOWrapper name=\\'<stdout>\\' mode=\\'w\\' encoding=\\'cp4...\\n    ...more omitted...\\n\\nFILE\\n    (built-in)\\n\\nSome of the information in this report is docstrings, and some of it (e.g., function call\\npatterns) is structural information that PyDoc gleans automatically by inspecting ob-\\njects’ internals, when available.\\nBesides modules, you can also use help on built-in functions, methods, and types. Usage\\nvaries slightly across Python versions, but to get help for a built-in type, try either the\\ntype name (e.g., dict for dictionary, str for string, list for list); an actual object of the\\ntype (e.g., {}, \\'\\', []); or a method of an actual object or type name (e.g., str.join,\\n\\n450 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0c\\'s\\'.join).1 You’ll get a large display that describes all the methods available for that\\ntype or the usage of that method:\\n\\n>>> help(dict)\\nHelp on class dict in module builtins:\\n\\nclass dict(object)\\n |  dict() -> new empty dictionary.\\n |  dict(mapping) -> new dictionary initialized from a mapping object\\'s\\n ...more omitted...\\n\\n>>> help(str.replace)\\nHelp on method_descriptor:\\n\\nreplace(...)\\n    S.replace (old, new[, count]) -> str\\n\\n    Return a copy of S with all occurrences of substring\\n    ...more omitted...\\n\\n>>> help(\\'\\'.replace)\\n...similar to prior result...\\n\\n>>> help(ord)\\nHelp on built-in function ord in module builtins:\\n\\nord(...)\\n    ord(c) -> integer\\n\\n    Return the integer ordinal of a one-character string.\\n\\nFinally, the help function works just as well on your modules as it does on built-ins.\\nHere it is reporting on the docstrings.py file we coded earlier. Again, some of this is\\ndocstrings, and some is information automatically extracted by inspecting objects’ \\nstructures:\\n\\n>>> import docstrings\\n>>> help(docstrings.square)\\nHelp on function square in module docstrings:\\n\\nsquare(x)\\n    function documentation\\n    can we have your liver then?\\n\\n>>> help(docstrings.Employee)\\nHelp on class Employee in module docstrings:\\n\\n1. Note that asking for help on an actual string object directly (e.g., help(\\'\\')) doesn’t work in recent Pythons:\\nyou usually get no help, because strings are interpreted specially—as a request for help on an unimported\\nmodule, for instance (see earlier). You must use the str type name in this context, though both other\\ntypes  of  actual  objects  (help([]))  and  string  method  names  referenced  through  actual  objects\\n(help(\\'\\'.join)) work fine (at least in Python 3.3—this has been prone to change over time). There is also\\nan interactive help mode, which you start by typing just help().\\n\\nPython Documentation Sources\\n\\n| 451\\n\\n\\x0cclass Employee(builtins.object)\\n |  class documentation\\n |\\n...more omitted...\\n\\n>>> help(docstrings)\\nHelp on module docstrings:\\n\\nNAME\\n    docstrings\\n\\nDESCRIPTION\\n    Module documentation\\n    Words Go Here\\n\\nCLASSES\\n    builtins.object\\n        Employee\\n\\n    class Employee(builtins.object)\\n     |  class documentation\\n     |\\n     ...more omitted...\\n\\nFUNCTIONS\\n    square(x)\\n        function documentation\\n        can we have your liver then?\\n\\nDATA\\n    spam = 40\\n\\nFILE\\n    c:\\\\code\\\\docstrings.py\\n\\nPyDoc: HTML Reports\\nThe text displays of the help function are adequate in many contexts, especially at the\\ninteractive prompt. To readers who’ve grown accustomed to richer presentation me-\\ndiums, though, they may seem a bit primitive. This section presents the HTML-based\\nflavor of PyDoc, which renders module documentation more graphically for viewing\\nin a web browser, and can even open one automatically for you. The way this is run\\nhas changed as of Python 3.3:\\n\\n• Prior to 3.3, Python ships with a simple GUI desktop client for submitting search\\nrequests. This client launches a web browser to view documentation produced by\\nan automatically started local server.\\n\\n• As of 3.3, the former GUI client is replaced by an all-browser interface scheme,\\nwhich combines both search and display in a web page that communicates with\\nan automatically started local server.\\n\\n452 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0c• Python 3.2 straddles this fence, supporting both the original GUI client scheme, as\\n\\nwell as the newer all-browser mode mandated as of 3.3.\\n\\nBecause  this  book’s  audience  is  both  users  of  the  latest-and-greatest  as  well  as  the\\nmasses still using older tried-and-true Pythons, we’ll explore both schemes here. As we\\ndo, keep in mind that the way these schemes differ pertains only to the top level of their\\nuser interfaces. Their documentation displays are nearly identical, and under either\\nregime PyDoc can also be used to generate both text in a console, and HTML files for\\nlater viewing in whatever manner you wish.\\n\\nPython 3.2 and later: PyDoc’s all-browser mode\\nAs of Python 3.3 the original GUI client mode of PyDoc, present in 2.X and earlier 3.X\\nreleases,  is  no  longer  available.  This  mode  is  present  through  Python  3.2  with  the\\n“Module Docs” Start button entry on Windows 7 and earlier, and via the pydoc -g\\ncommand line. This GUI mode was reportedly deprecated in 3.2, though you had to\\nlook closely to notice—it works fine and without warning on 3.2 on my machine.\\nIn 3.3, though, this mode goes away altogether, and is replaced with a pydoc -b com-\\nmand line, which instead spawns both a locally running documentation server, as well\\nas a web browser that functions as both search engine client and page display. The\\nbrowser is initially opened on a module index page with enhanced functionality. There\\nare additional ways to use PyDoc (e.g., to save the HTML page to a file for later viewing,\\nas described ahead), so this is a relatively minor operational change.\\nTo launch the newer browser-only mode of PyDoc in Python 3.2 and later, a command-\\nline like any of the following suffice: they all use the –m Python command-line argument\\nfor convenience to locate PyDoc’s module file on your module import search path. The\\nfirst assumes Python is on your system path; the second employs Python 3.3’s new\\nWindows launcher; and the third gives the full path to your Python if the other two\\nschemes won’t work. See Appendix A for more on –m, and Appendix B for coverage of\\nthe Windows launcher.\\n\\nc:\\\\code> python -m pydoc -b\\nServer ready at http://localhost:62135/\\nServer commands: [b]rowser, [q]uit\\nserver> q\\nServer stopped\\n\\nc:\\\\code> py −3 -m pydoc -b\\nServer ready at http://localhost:62144/\\nServer commands: [b]rowser, [q]uit\\nserver> q\\nServer stopped\\n\\nc:\\\\code> C:\\\\python33\\\\python -m pydoc -b\\nServer ready at http://localhost:62153/\\nServer commands: [b]rowser, [q]uit\\nserver> q\\nServer stopped\\n\\nPython Documentation Sources\\n\\n| 453\\n\\n\\x0cFigure 15-1. The top-level index start page of the all-browser PyDoc HTML interface in Python 3.2\\nand later, which as of 3.3 replaces the former GUI client in earlier Pythons.\\n\\nHowever you run this command line, the effect is to start PyDoc as a locally running\\nweb server on a dedicated (but by default arbitrary unused) port, and pop up a web\\nbrowser to act as client, displaying a page giving links to documentation for all the\\nmodules importable on your module search path (including the directory where PyDoc\\nis launched). PyDoc’s top-level web page interface is captured in Figure 15-1.\\nBesides the module index, PyDoc’s web page also includes input fields at the top to\\nrequest a specific module’s documentation page (Get) and search for related entries\\n(Search), which stand in for the prior interface’s GUI client fields. You can also click\\non this page’s links to go to the Module Index (the start page), Topics (general Python\\nsubjects), and Keywords (overviews of statements and some expressions).\\nNotice that the index page in Figure 15-1 lists both modules and top-level scripts in the\\ncurrent directory—the book’s C:\\\\code, where PyDoc was started by the earlier com-\\nmand lines. PyDoc is mostly intended for documenting importable modules, but can\\nsometimes  be  used  to  show  documentation  for  scripts  too.  A  selected  file  must  be\\n\\n454 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cimported in order to render its documentation, and as we’ve learned, importing runs\\na file’s code. Modules normally just define tools when run, so this is usually irrelevant.\\nIf you ask for documentation for a top-level script file, though, the shell window where\\nyou launched PyDoc serves as the script’s standard input and output for any user in-\\nteraction. The net effect is that the documentation page for a script will appear after it\\nruns, and after its printed output shows up in the shell window. This may work better\\nfor some scripts than others, though; interactive input, for example, may interleave\\noddly with PyDoc’s own server command prompts.\\nOnce you get past the new start page in  Figure 15-1, the documentation pages for\\nspecific modules are essentially the same in both the newer all-browser mode and the\\nearlier GUI-client scheme, apart from the additional input fields at the top of page in\\nthe former. For instance, Figure 15-2 shows the new documentation display pages—\\nopened on two user-defined modules we’ll be writing in the next part of this book, as\\npart of Chapter 21’s benchmarking case study. In either scheme, documentation pages\\ncontain automatically created hyperlinks that allow you to click your way through the\\ndocumentation of related components in your application. For instance, you’ll find\\nlinks to open imported modules’ pages too.\\nBecause of the similarity in their display pages, the next section on pre-3.2 PyDoc and\\nits screen shots largely apply after 3.2 too, so be sure to read ahead for additional notes\\neven if you’re using more recent Python. In effect, 3.3’s PyDoc simply cuts out the\\npre-3.2 GUI client “middleman,” while retaining its browser and server.\\nPyDoc in Python 3.3 also still supports other former usage modes. For instance, pydoc\\n–p port can be used to set its PyDoc server port, and  pydoc -w module still writes a\\nmodule’s HTML documentation to a file named module.html for later viewing. Only\\nthe pydoc -g GUI client mode is removed and replaced by pydoc -b. You can also run\\nPyDoc to generate a plain-text form of the documentation (its Unix “manpage” flavor\\nshown earlier in this chapter)—the following command line is equivalent to the help\\ncall at an interactive Python prompt:\\n\\nc:\\\\code> py −3 -m pydoc timeit            # Command-line text help\\n\\nc:\\\\code> py −3\\n>>> help(\"timeit\")                        # Interactive prompt text help\\n\\nAs an interactive system, your best bet is to take PyDoc’s web-based interface for a test\\ndrive, so we’ll cut its usage details short here; see Python’s manuals for additional details\\nand command-line options. Also note that PyDoc’s server and browser functionality\\ncome largely “for free” from tools that automate such utility in the portable modules\\nof Python’s standard library (e.g., webbrowser, http.server). Consult PyDoc’s Python\\ncode in the standard library file pydoc.py for additional details and inspiration.\\n\\nPython Documentation Sources\\n\\n| 455\\n\\n\\x0cFigure  15-2.  PyDoc’s  module  display  page  in  Python  3.2  and  later  with  input  fields  at  the  top,\\ndisplaying two modules we will be coding in the next part of this book (Chapter 21).\\n\\nChanging PyDoc’s Colors\\n\\nYou won’t be able to tell in the paper version of this book, but if you have an ebook or\\nstart PyDoc live, you’ll notice that it chooses colors that may or may not be to your\\nliking. Unfortunately, there presently is no easy way to customize PyDoc’s colors. They\\nare hardcoded deep in its source code, and can’t be passed in as arguments to functions\\nor command lines, or changed in configuration files or global variables in the PyDoc\\nmodule itself.\\n\\nExcept that, in an open source system, you can always change the code—PyDoc lives\\nin the file pydoc.py in Python’s standard library, which is directory C:\\\\Python33\\\\Lib on\\nWindows for Python 3.3. Its colors are hardcoded RGB value hex strings embedded\\nthroughout its code. For instance, its string \\'#eeaa77\\' specifies 2-byte (16-bit) values\\nfor red, green, and blue levels (decimal 238, 170, and 119), yielding a shade of orange\\nfor function banners. The string \\'#ee77aa\\' similarly renders the dark pinkish color used\\nin nine places, including class and index page banners.\\n\\n456 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cTo tailor, search for these color value strings and replace them with your preferences.\\nIn  IDLE,  an  Edit/Find  for  regular  expression  #\\\\w{6}  will  locate  color  strings  (this\\nmatches six alphanumeric characters after a # per Python’s re module pattern syntax;\\nsee the library manual for details).\\n\\nTo pick colors, in most programs with color selection dialogs you can map to and from\\nRGB values; the book’s examples include a GUI script setcolor.py that does the same.\\nIn my copy of PyDoc, I replaced all #ee77aa with #008080 (teal) to banish the dark pink.\\nReplacing #ffc8d8 with #c0c0c0 (grey) does similar for the light pink background of\\nclass docstrings.\\n\\nSuch surgery isn’t for the faint of heart—PyDoc’s file is currently 2,600 lines long—but\\nmakes for a fair exercise in code maintenance. Be cautious when replacing colors like\\n#ffffff and  #000000 (white and black), and be sure to make a backup copy of  py-\\ndoc.py first so you have a fallback. This file uses tools we haven’t yet met, but you can\\nsafely ignore the rest of its code while you make your tactical changes.\\n\\nBe sure to watch for PyDoc changes on the configurations front; this seems a prime\\ncandidate for improvement. In fact, there already is an effort under way: issue 10716\\non the Python developers’ list seeks to make PyDoc more user-customizable by chang-\\ning it to support CSS style sheets. If successful, this may allow users to make color and\\nother display choices in external CSS files instead of PyDoc’s source code.\\n\\nOn the other hand, this is currently not planned to appear until Python 3.4, and will\\nrequire PyDoc’s users to also be proficient with CSS code—which unfortunately has a\\nnontrivial structure all its own that many people using Python may not understand well\\nenough to change. As I write this, for example, the proposed PyDoc CSS file is already\\n234 lines of code that probably won’t mean much to people not already familiar with\\nweb development (and it hardly seems reasonable to ask them to learn a web develop-\\nment tool just to tailor PyDoc!).\\n\\nToday’s PyDoc in 3.3 already supports a CSS style sheet that offers some customization\\noptions, but only half-heartedly, and ships with one that is empty. Until this is hashed\\nout, code changes seem the best option. In any event, CSS style sheets are well beyond\\nthis Python book’s scope—see the Web for details, and check future Python release\\nnotes for PyDoc developments.\\n\\nPython 3.2 and earlier: GUI client\\nThis section documents the original GUI client mode of PyDoc, for readers using 3.2\\nand earlier, and gives some addition PyDoc context in general. It builds on the basics\\ncovered in the prior section, which aren’t repeated here, so be sure to at least scan the\\nprior section if you’re using an older Python.\\nAs mentioned, through Python 3.2, PyDoc provides a top-level GUI interface—a simple\\nbut portable Python/tkinter script for submitting requests—as well as a documentation\\nserver. Requests in the client are routed to the server, which produces reports displayed\\nin a popped-up web browser. Apart from your having to submit search requests, this\\nprocess is largely automatic.\\n\\nPython Documentation Sources\\n\\n| 457\\n\\n\\x0cFigure 15-3. The PyDoc top-level search engine GUI client in 3.2 and earlier: type the name of a\\nmodule you want documentation for, press Enter, select the module, and then press “go to selected”\\n(or omit the module name and press “open browser” to see all available modules).\\n\\nTo start PyDoc in this mode, you generally first launch the search engine GUI captured\\nin Figure 15-3. You can start this either by selecting the Module Docs item in Python’s\\nStart button menu on Windows 7 and earlier, or by launching the pydoc.py script in\\nPython’s standard library directory with a -g command-line argument: it lives in Lib\\non Windows, but you can use Python’s –m flag to avoid typing script paths here too:\\n\\nc:\\\\code> c:\\\\python32\\\\python -m pydoc -g        # Explicit Python path\\nc:\\\\code> py −3.2 -m pydoc -g                   # Windows 3.3+ launcher version\\n\\nEnter the name of a module you’re interested in, and press the Enter key; PyDoc will\\nmarch down your module import search path (sys.path), looking for the requested\\nmodule and references to it.\\nOnce you’ve found a promising entry, select it and click “go to selected.” PyDoc will\\nspawn a web browser on your machine to display the report rendered in HTML format.\\nFigure 15-4 shows the information PyDoc displays for the built-in glob module. Notice\\nthe hyperlinks in the Modules section of this page—you can click these to jump to the\\nPyDoc pages for related (imported) modules. For larger pages, PyDoc also generates\\nhyperlinks to sections within the page.\\nLike the help function interface, the GUI interface works on user-defined modules as\\nwell as built-ins. Figure 15-5 shows the page generated for our docstrings.py module\\nfile coded earlier.\\nMake sure that the directory containing your module is on your module import search\\npath—as mentioned, PyDoc must be able to import a file to render its documentation.\\nThis includes the current working directory—PyDoc might not check the directory it\\nwas launched from (which is probably meaningless when started from the Windows\\nStart button anyhow), so you may need to extend your PYTHONPATH setting to get this to\\n\\n458 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cFigure 15-4. When you find a module in the Figure 15-3 GUI (such as this built-in standard library\\nmodule) and press “go to selected,” the module’s documentation is rendered in HTML and displayed\\nin a web browser window like this one.\\n\\nwork. On Pythons 3.2 and 2.7, I had to add “.” to my PYTHONPATH to get PyDoc’s GUI\\nclient mode to look in the directory it was started from by command line:\\n\\nc:\\\\code> set PYTHONPATH=.;%PYTYONPATH%\\nc:\\\\code> py −3.2 -m pydoc -g\\n\\nThis setting was also required to see the current directory for the new all-browser pydoc\\n-b mode in 3.2. However, Python 3.3 automatically includes “.” in its index list, so no\\npath setting is required to view files in the directory where PyDoc is started—a minor\\nbut noteworthy improvement.\\nPyDoc can be customized and launched in various ways we won’t cover here; see its\\nentry in Python’s standard library manual for more details. The main thing to take away\\nfrom this section is that PyDoc essentially gives you implementation reports “for free”\\n—if you are good about using docstrings in your files, PyDoc does all the work of\\ncollecting and formatting them for display. PyDoc helps only for objects like functions\\nand modules, but it provides an easy way to access a middle level of documentation for\\nsuch tools—its reports are more useful than raw attribute lists, and less exhaustive than\\nthe standard manuals.\\n\\nPython Documentation Sources\\n\\n| 459\\n\\n\\x0cFigure 15-5. PyDoc can serve up documentation pages for both built-in and user-coded modules on\\nthe module search path. Here is the page for a user-defined module, showing all its documentation\\nstrings (docstrings) extracted from the source file.\\n\\nPyDoc can also be run to save the HTML documentation for a module in a file for later\\nviewing or printing; see the preceding section for pointers. Also, note that PyDoc might\\nnot work well if run on scripts that read from standard input—PyDoc imports the target\\nmodule to inspect its contents, and there may be no connection for standard input text\\nwhen it is run in GUI mode, especially if run from the Windows Start button. Modules\\nthat can be imported without immediate input requirements will always work under\\nPyDoc, though. See also the preceding section’s notes regarding scripts in PyDoc’s -b\\nmode in 3.2 and later; launching PyDoc’s GUI mode by command line works the same\\n—you interact in the launch window.\\n\\n460 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cPyDoc GUI client trick of the day: If you press the “open browser” button\\nin Figure 15-3’s window, PyDoc will produce an index page containing\\na hyperlink to every module you can possibly import on your computer.\\nThis includes Python standard library modules, modules of installed\\nthird-party  extensions,  user-defined  modules  on  your  import  search\\npath,  and  even  statically  or  dynamically  linked-in  C-coded  modules.\\nSuch information is hard to come by otherwise without writing code\\nthat inspects all module sources. On Python 3.2, you’ll want to do this\\nimmediately after the GUI opens, as it may not fully work after searches.\\nAlso note that in PyDoc’s all-browser –b interface in 3.2 and later, you\\nget the same index functionality on its top-level start page of Figure 15-1.\\n\\nBeyond docstrings: Sphinx\\nIf you’re looking for a way to document your Python system in a more sophisticated\\nway, you may wish to check out Sphinx (currently at http://sphinx-doc.org). Sphinx is\\nused by the standard Python documentation described in the next section, and many\\nother projects. It uses simple reStructuredText as its markup language, and inherits\\nmuch from the Docutils suite of reStructuredText parsing and translating tools.\\nAmong other things, Sphinx supports a variety of output formats (HTML including\\nWindows HTML Help, LaTeX for printable PDF versions, manual pages, and plain\\ntext); extensive and automatic cross-references; hierarchical structure with automatic\\nlinks to relatives; automatic indexes; automatic code highlighting using Pygments (itself\\na notable Python tool); and more. This is probably overkill for smaller programs where\\ndocstrings and PyDoc may suffice, but can yield professional-grade documentation for\\nlarge projects. See the Web for more details on Sphinx and its related tools.\\n\\nThe Standard Manual Set\\nFor  the  complete  and  most  up-to-date  description  of  the  language  and  its  toolset,\\nPython’s standard manuals stand ready to serve. Python’s manuals ship in HTML and\\nother formats, and they are installed with the Python system on Windows—they are\\navailable in your Start button’s menu for Python on Windows 7 and earlier, and they\\ncan also be opened from the Help menu within IDLE. You can also fetch the manual\\nset separately from http://www.python.org in a variety of formats, or read it online at\\nthat site (follow the Documentation link). On Windows, the manuals are a compiled\\nhelp file to support searches, and the online versions at the Python website include a\\nweb-based search page.\\nWhen opened, the Windows format of the manuals displays a root page like that in\\nFigure 15-6, showing the local copy on Windows. The two most important entries here\\nare most likely the Library Reference (which documents built-in types, functions, ex-\\nceptions, and standard library modules) and the Language Reference (which provides\\n\\nPython Documentation Sources\\n\\n| 461\\n\\n\\x0cFigure 15-6. Python’s standard manual set, available online at http://www.python.org, from IDLE’s\\nHelp  menu,  and  in  the  Windows  7  and  earlier  Start  button  menu.  It’s  a  searchable  help  file  on\\nWindows, and there is a search engine for the online version. Of these, the Library Reference is the\\none you’ll want to use most of the time.\\n\\na  formal  description  of  language-level  details).  The  tutorial  listed  on  this  page  also\\nprovides a brief introduction for newcomers, which you’re probably already beyond.\\nOf notable interest, the What’s New documents in this standard manual set chronicle\\nPython changes made in each release beginning with Python 2.0, which came out in\\nlate 2000—useful for those porting older Python code, or older Python skills. These\\ndocuments are especially useful for uncovering additional details on the differences in\\nthe Python 2.X and 3.X language lines covered in this book, as well as in their standard\\nlibraries.\\n\\nWeb Resources\\nAt  the  official  Python  website  (http://www.python.org),  you’ll  find  links  to  various\\nPython resources, some of which cover special topics or domains. Click the Documen-\\ntation link to access an online tutorial and the Beginners Guide to Python. The site also\\nlists non-English Python resources, and introductions scaled to different target audi-\\nences.\\nToday you will also find numerous Python wikis, blogs, websites, and a host of other\\nresources on the Web at large. To sample the online community, try searching for a\\n\\n462 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cterm like “Python programming” in Google, or search on any topic of interest; chances\\nare good you’ll find ample material to browse.\\n\\nPublished Books\\nAs a final resource, you can choose from a collection of professionally edited and pub-\\nlished reference books for Python. Bear in mind that books tend to lag behind the\\ncutting edge of Python changes, partly because of the work involved in writing, and\\npartly because of the natural delays built into the publishing cycle. Usually, by the time\\na book comes out, it’s three or more months behind the current Python state (trust me\\non that—my books have a nasty habit of falling out of date in minor ways between the\\ntime I write them and the time they hit the shelves!). Unlike standard manuals, books\\nare also generally not free.\\nStill, for many, the convenience and quality of a professionally published text is worth\\nthe cost. Moreover, Python changes so slowly that books are usually still relevant years\\nafter they are published, especially if their authors post updates on the Web. See the\\npreface for pointers to other Python books.\\n\\nCommon Coding Gotchas\\nBefore the programming exercises for this part of the book, let’s run through some of\\nthe most common mistakes beginners make when coding Python statements and pro-\\ngrams. Many of these are warnings I’ve thrown out earlier in this part of the book,\\ncollected here for ease of reference. You’ll learn to avoid these pitfalls once you’ve\\ngained a bit of Python coding experience, but a few words now might help you avoid\\nfalling into some of these traps initially:\\n\\n• Don’t forget the colons. Always remember to type a : at the end of compound\\nstatement headers—the first line of an if, while, for, etc. You’ll probably forget at\\nfirst (I did, and so have most of my roughly 4,000 Python students over the years),\\nbut you can take some comfort from the fact that it will soon become an uncon-\\nscious habit.\\n\\n• Start in column 1. Be sure to start top-level (unnested) code in column 1. That\\nincludes unnested code typed into module files, as well as unnested code typed at\\nthe interactive prompt.\\n\\n• Blank lines matter at the interactive prompt. Blank lines in compound state-\\nments are always irrelevant and ignored in module files, but when you’re typing\\ncode at the interactive prompt, they end the statement. In other words, blank lines\\ntell the interactive command line that you’ve finished a compound statement; if\\nyou want to continue, don’t hit the Enter key at the ... prompt (or in IDLE) until\\nyou’re really done. This also means you can’t paste multiline code at this prompt;\\nit must run one full statement at a time.\\n\\nCommon Coding Gotchas\\n\\n| 463\\n\\n\\x0c• Indent consistently. Avoid mixing tabs and spaces in the indentation of a block,\\nunless you know what your text editor does with tabs. Otherwise, what you see in\\nyour editor may not be what Python sees when it counts tabs as a number of spaces.\\nThis is true in any block-structured language, not just Python—if the next pro-\\ngrammer has tabs set differently, it will be difficult or impossible to understand the\\nstructure of your code. It’s safer to use all tabs or all spaces for each block.\\n\\n• Don’t code C in Python. A reminder for C/C++ programmers: you don’t need to\\ntype parentheses around tests in if and while headers (e.g., if (X==1):). You can,\\nif you like (any expression can be enclosed in parentheses), but they are fully su-\\nperfluous in this context. Also, do not terminate all your statements with semico-\\nlons; it’s technically legal to do this in Python as well, but it’s totally useless unless\\nyou’re placing more than one statement on a single line (the end of a line normally\\nterminates a statement). And remember, don’t embed assignment statements in\\nwhile loop tests, and don’t use {} around blocks (indent your nested code blocks\\nconsistently instead).\\n\\n• Use  simple  for  loops  instead  of  while  or  range.  Another  reminder:  a  simple\\nfor loop (e.g., for x in seq:) is almost always simpler to code and often quicker\\nto run than a while- or range-based counter loop. Because Python handles indexing\\ninternally for a simple for, it can sometimes be faster than the equivalent while,\\nthough this can vary per code and Python. For code simplicity alone, though, avoid\\nthe temptation to count things in Python!\\n\\n• Beware of mutables in assignments. I mentioned this in Chapter 11: you need\\nto be careful about using mutables in a multiple-target assignment (a = b = []),\\nas  well  as  in  an  augmented  assignment  (a  +=  [1,  2]).  In  both  cases,  in-place\\nchanges may impact other variables. See Chapter 11 for details if you’ve forgotten\\nwhy this is true.\\n\\n• Don’t  expect  results  from  functions  that  change  objects  in  place.  We  en-\\ncountered this one earlier, too: in-place change operations like the list.append and\\nlist.sort  methods  introduced  in  Chapter  8  do  not  return  values  (other  than\\nNone), so you should call them without assigning the result. It’s not uncommon for\\nbeginners to say something like mylist = mylist.append(X) to try to get the result\\nof an append, but what this actually does is assign mylist to None, not to the modified\\nlist (in fact, you’ll lose your reference to the list altogether).\\nA more devious example of this pops up in Python 2.X code when trying to step\\nthrough dictionary items in a sorted fashion. It’s fairly common to see code like\\nfor k in D.keys().sort():. This almost works—the keys method builds a keys\\nlist, and the sort method orders it—but because the sort method returns None, the\\nloop fails because it is ultimately a loop over None (a nonsequence). This fails even\\nsooner in Python 3.X, because dictionary keys are views, not lists! To code this\\ncorrectly, either use the newer sorted built-in function, which returns the sorted\\nlist,  or  split  the  method  calls  out  to  statements:  Ks  =  list(D.keys()),  then\\nKs.sort(), and finally, for k in Ks:. This, by the way, is one case where you may\\n\\n464 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cstill want to call the keys method explicitly for looping, instead of relying on the\\ndictionary iterators—iterators do not sort.\\n\\n• Always use parentheses to call a function. You must add parentheses after a\\nfunction name to call it, whether it takes arguments or not (e.g., use function(),\\nnot function). In the next part of this book, we’ll learn that functions are simply\\nobjects that have a special operation—a call that you trigger with the parentheses.\\nThey can be referenced like any other object without triggering a call.\\nIn classes, this problem seems to occur most often with files; it’s common to see\\nbeginners type file.close to close a file, rather than file.close(). Because it’s\\nlegal to reference a function without calling it, the first version with no parentheses\\nsucceeds silently, but it does not close the file!\\n\\n• Don’t use extensions or paths in imports and reloads. Omit directory paths\\nand file extensions in import statements—say import mod, not import mod.py. We\\ndiscussed  module  basics  in  Chapter  3  and  will  continue  studying  modules  in\\nPart V. Because modules may have other extensions besides .py (.pyc, for instance),\\nhardcoding a particular extension is not only illegal syntax, it doesn’t make sense.\\nPython picks an extension automatically, and any platform-specific directory path\\nsyntax comes from module search path settings, not the import statement.\\n\\n• And other pitfalls in other parts. Be sure to also see the built-in type warnings\\nat the end of the prior part, as they may qualify as coding issues too. There are\\nadditional “gotchas” that crop up commonly in Python coding—losing a built-in\\nfunction by reassigning its name, hiding a library module by using its name for one\\nof your own, changing mutable argument defaults, and so on—but we don’t have\\nenough background to cover them yet. To learn more about both what you should\\nand shouldn’t do in Python, you’ll have to read on; later parts extend the set of\\n“gotchas” and fixes we’ve added to here.\\n\\nChapter Summary\\nThis chapter took us on a tour of program documentation—both documentation we\\nwrite ourselves for our own programs, and documentation available for tools we use.\\nWe met docstrings, explored the online and manual resources for Python reference,\\nand learned how PyDoc’s help function and web page interfaces provide extra sources\\nof documentation. Because this is the last chapter in this part of the book, we also\\nreviewed common coding mistakes to help you avoid them.\\nIn the next part of this book, we’ll start applying what we already know to larger pro-\\ngram constructs. Specifically, the next part takes up the topic of functions—a tool used\\nto group statements for reuse. Before moving on, however, be sure to work through\\nthe set of lab exercises for this part of the book that appear at the end of this chapter.\\nAnd even before that, let’s run through this chapter’s quiz.\\n\\nChapter Summary | 465\\n\\n\\x0cTest Your Knowledge: Quiz\\n1. When should you use documentation strings instead of hash-mark comments?\\n2. Name three ways you can view documentation strings.\\n3. How can you obtain a list of the available attributes in an object?\\n4. How can you get a list of all available modules on your computer?\\n5. Which Python book should you purchase after this one?\\n\\nTest Your Knowledge: Answers\\n1. Documentation strings (docstrings) are considered best for larger, functional doc-\\numentation, describing the use of modules, functions, classes, and methods in your\\ncode. Hash-mark comments are today best limited to smaller-scale documentation\\nabout arcane expressions or statements at strategic points on your code. This is\\npartly because docstrings are easier to find in a source file, but also because they\\ncan be extracted and displayed by the PyDoc system.\\n\\n2. You can see docstrings by printing an object’s __doc__ attribute, by passing it to\\nPyDoc’s help function, and by selecting modules in PyDoc’s HTML-based user\\ninterfaces—either the -g GUI client mode in Python 3.2 and earlier, or the -b all-\\nbrowser mode in Python 3.2 and later (and required as of 3.3). Both run a client/\\nserver system that displays documentation in a popped-up web browser. PyDoc\\ncan also be run to save a module’s documentation in an HTML file for later viewing\\nor printing.\\n\\n3. The built-in dir(X) function returns a list of all the attributes attached to any object.\\nA  list  comprehension  of  the  form  [a  for  a  in  dir(X)  if  not  a.starts\\nwith(\\'__\\')] can be used to filter out internals names with underscores (we’ll learn\\nhow to wrap this in a function in the next part of the book to make it easier to use).\\n4. In Python 3.2 and earlier, you can run the PyDoc GUI interface, and select “open\\nbrowser”; this opens a web page containing a link to every module available to\\nyour programs. This GUI mode no longer works as of Python 3.3. In Python 3.2\\nand later, you get the same functionality by running PyDoc’s newer all-browser\\nmode with a -b command-line switch; the top-level start page displayed in a web\\nbrowser in this newer mode has the same index page listing all available modules.\\n5. Mine, of course. (Seriously, there are hundreds today; the preface lists a few rec-\\nommended follow-up books, both for reference and for application tutorials, and\\nyou should browse for books that fit your needs.)\\n\\n466 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0cTest Your Knowledge: Part III Exercises\\nNow that you know how to code basic program logic, the following exercises will ask\\nyou to implement some simple tasks with statements. Most of the work is in exercise\\n4, which lets you explore coding alternatives. There are always many ways to arrange\\nstatements, and part of learning Python is learning which arrangements work better\\nthan  others.  You’ll  eventually  gravitate  naturally  toward  what  experienced  Python\\nprogrammers call “best practice,” but best practice takes practice.\\nSee Part III in Appendix D for the solutions.\\n\\n1. Coding basic loops. This exercise asks you to experiment with for loops.\\n\\na. Write a for loop that prints the ASCII code of each character in a string named\\nS. Use the built-in function ord(character) to convert each character to an\\nASCII  integer.  This  function  technically  returns  a  Unicode  code  point  in\\nPython 3.X, but if you restrict its content to ASCII characters, you’ll get back\\nASCII codes. (Test it interactively to see how it works.)\\n\\nb. Next,  change  your  loop  to  compute  the  sum  of  the  ASCII  codes  of  all  the\\n\\ncharacters in a string.\\n\\nc. Finally, modify your code again to return a new list that contains the ASCII\\ncodes of each character in the string. Does the expression map(ord, S) have a\\nsimilar effect? How about [ord(c) for c in S]? Why? (Hint: see Chapter 14.)\\n2. Backslash characters. What happens on your machine when you type the following\\n\\ncode interactively?\\n\\nfor i in range(50):\\n    print(\\'hello %d\\\\n\\\\a\\' % i)\\n\\nBeware that if it’s run outside of the IDLE interface this example may beep at you,\\nso you may not want to run it in a crowded room! IDLE prints odd characters\\ninstead of beeping—spoiling much of the joke (see the backslash escape characters\\nin Table 7-2).\\n\\n3. Sorting dictionaries. In Chapter 8, we saw that dictionaries are unordered collec-\\ntions. Write a for loop that prints a dictionary’s items in sorted (ascending) order.\\n(Hint: use the dictionary keys and list sort methods, or the newer sorted built-in\\nfunction.)\\n\\n4. Program logic alternatives. Consider the following code, which uses a while loop\\nand found flag to search a list of powers of 2 for the value of 2 raised to the fifth\\npower (32). It’s stored in a module file called power.py.\\n\\nL = [1, 2, 4, 8, 16, 32, 64]\\nX = 5\\n\\nfound = False\\ni = 0\\nwhile not found and i < len(L):\\n\\nTest Your Knowledge: Part III Exercises\\n\\n| 467\\n\\n\\x0c   if 2 ** X == L[i]:\\n       found = True\\n   else:\\n       i = i+1\\n\\nif found:\\n    print(\\'at index\\', i)\\nelse:\\n    print(X, \\'not found\\')\\n\\nC:\\\\book\\\\tests> python power.py\\nat index 5\\n\\nAs is, the example doesn’t follow normal Python coding techniques. Follow the\\nsteps outlined here to improve it (for all the transformations, you may either type\\nyour code interactively or store it in a script file run from the system command line\\n—using a file makes this exercise much easier):\\n\\na. First, rewrite this code with a while loop else clause to eliminate the found flag\\n\\nand final if statement.\\n\\nb. Next, rewrite the example to use a for loop with an else clause, to eliminate\\nthe explicit list-indexing logic. (Hint: to get the index of an item, use the list\\nindex method—L.index(X) returns the offset of the first X in list L.)\\n\\nc. Next, remove the loop completely by rewriting the example with a simple in\\noperator membership expression. (See Chapter 8 for more details, or type this\\nto test: 2 in [1,2,3].)\\n\\nd. Finally, use a for loop and the list append method to generate the powers-of-2\\n\\nlist (L) instead of hardcoding a list literal.\\n\\nDeeper thoughts:\\n\\ne. Do you think it would improve performance to move the 2 ** X expression\\n\\noutside the loops? How would you code that?\\n\\nf. As we saw in exercise 1, Python includes a map(function, list) tool that can\\ngenerate a powers-of-2 list, too: map(lambda x: 2 ** x, range(7)). Try typing\\nthis code interactively; we’ll meet lambda more formally in the next part of this\\nbook, especially in Chapter 19. Would a list comprehension help here (see\\nChapter 14)?\\n\\n5. Code maintenance. If you haven’t already done so, experiment with making the\\ncode  changes  suggested  in  this  chapter’s  sidebar  “Changing  PyDoc’s  Col-\\nors” on page 456. Much of the work of real software development is in changing\\nexisting code, so the sooner you begin doing so, the better. For reference, my edited\\ncopy of PyDoc is in the book’s examples package, named mypydoc.py; to see how\\nit differs, you can run a file compare (fc on Windows) with the original pydoc.py\\nin 3.3 (also included, lest it change radically in 3.4 as the sidebar describes). If\\nPyDoc is more easily customized by the time you read these words, customize\\n\\n468 | Chapter 15:\\u2002The Documentation Interlude\\n\\n\\x0ccolors per its current convention instead; if this involves changing a CSS file, let’s\\nhope the procedure will be well documented in Python’s manuals.\\n\\nTest Your Knowledge: Part III Exercises\\n\\n| 469\\n\\n\\x0c\\x0cPART IV\\nFunctions and Generators\\n\\n\\x0c\\x0cCHAPTER 16\\nFunction Basics\\n\\nIn Part III, we studied basic procedural statements in Python. Here, we’ll move on to\\nexplore a set of additional statements and expressions that we can use to create func-\\ntions of our own.\\nIn simple terms, a function is a device that groups a set of statements so they can be run\\nmore than once in a program—a packaged procedure invoked by name. Functions also\\ncan compute a result value and let us specify parameters that serve as function inputs\\nand may differ each time the code is run. Coding an operation as a function makes it\\na generally useful tool, which we can use in a variety of contexts.\\nMore fundamentally, functions are the alternative to programming by cutting and past-\\ning—rather than having multiple redundant copies of an operation’s code, we can fac-\\ntor it into a single function. In so doing, we reduce our future work radically: if the\\noperation must be changed later, we have only one copy to update in the function, not\\nmany scattered throughout the program.\\nFunctions are also the most basic program structure Python provides for maximizing\\ncode reuse, and lead us to the larger notions of program design. As we’ll see, functions\\nlet us split complex systems into manageable parts. By implementing each part as a\\nfunction, we make it both reusable and easier to code.\\nTable 16-1 previews the primary function-related tools we’ll study in this part of the\\nbook—a  set  that  includes  call  expressions,  two  ways  to  make  functions  (def  and\\nlambda), two ways to manage scope visibility (global and nonlocal), and two ways to\\nsend results back to callers (return and yield).\\n\\nTable 16-1. Function-related statements and expressions\\n\\nStatement or expression\\nCall expressions\\ndef\\n\\nreturn\\n\\nExamples\\nmyfunc(\\'spam\\', \\'eggs\\', meat=ham, *rest)\\n\\ndef printer(messge):\\n    print(\\'Hello \\' + message)\\ndef adder(a, b=1, *c):\\n    return a + b + c[0]\\n\\n473\\n\\n\\x0cStatement or expression\\nglobal\\n\\nnonlocal (3.X)\\n\\nyield\\n\\nlambda\\n\\nExamples\\nx = \\'old\\'\\ndef changer():\\n    global x; x = \\'new\\'\\ndef outer():\\n    x = \\'old\\'\\n    def changer():\\n        nonlocal x; x = \\'new\\'\\ndef squares(x):\\n    for i in range(x): yield i ** 2\\nfuncs = [lambda x: x**2, lambda x: x**3]\\n\\nWhy Use Functions?\\nBefore we get into the details, let’s establish a clear picture of what functions are all\\nabout.  Functions  are  a  nearly  universal  program-structuring  device.  You  may  have\\ncome across them before in other languages, where they may have been called subrou-\\ntines or procedures. As a brief introduction, functions serve two primary development\\nroles:\\n\\nMaximizing code reuse and minimizing redundancy\\n\\nAs  in  most  programming  languages,  Python  functions  are  the  simplest  way  to\\npackage logic you may wish to use in more than one place and more than one time.\\nUp until now, all the code we’ve been writing has run immediately. Functions allow\\nus to group and generalize code to be used arbitrarily many times later. Because\\nthey allow us to code an operation in a single place and use it in many places,\\nPython functions are the most basic factoring tool in the language: they allow us\\nto reduce code redundancy in our programs, and thereby reduce maintenance ef-\\nfort.\\n\\nProcedural decomposition\\n\\nFunctions also provide a tool for splitting systems into pieces that have well-defined\\nroles. For instance, to make a pizza from scratch, you would start by mixing the\\ndough, rolling it out, adding toppings, baking it, and so on. If you were program-\\nming a pizza-making robot, functions would help you divide the overall “make\\npizza” task into chunks—one function for each subtask in the process. It’s easier\\nto implement the smaller tasks in isolation than it is to implement the entire process\\nat once. In general, functions are about procedure—how to do something, rather\\nthan what you’re doing it to. We’ll see why this distinction matters in Part VI, when\\nwe start making new objects with classes.\\n\\nIn this part of the book, we’ll explore the tools used to code functions in Python: func-\\ntion basics, scope rules, and argument passing, along with a few related concepts such\\nas generators and functional tools. Because its importance begins to become more ap-\\nparent at this level of coding, we’ll also revisit the notion of polymorphism, which was\\n\\n474 | Chapter 16:\\u2002Function Basics\\n\\n\\x0cintroduced earlier in the book. As you’ll see, functions don’t imply much new syntax,\\nbut they do lead us to some bigger programming ideas.\\n\\nCoding Functions\\nAlthough it wasn’t made very formal, we’ve already used some functions in earlier\\nchapters. For instance, to make a file object, we called the built-in open function; sim-\\nilarly, we used the len built-in function to ask for the number of items in a collection\\nobject.\\nIn this chapter, we will explore how to write new functions in Python. Functions we\\nwrite behave the same way as the built-ins we’ve already seen: they are called in ex-\\npressions, are passed values, and return results. But writing new functions requires the\\napplication of a few additional ideas that haven’t yet been introduced. Moreover, func-\\ntions behave very differently in Python than they do in compiled languages like C. Here\\nis a brief introduction to the main concepts behind Python functions, all of which we\\nwill study in this part of the book:\\n\\n• def is executable code. Python functions are written with a new statement, the\\ndef. Unlike functions in compiled languages such as C, def is an executable state-\\nment—your function does not exist until Python reaches and runs the def. In fact,\\nit’s legal (and even occasionally useful) to nest def statements inside if statements,\\nwhile loops, and even other defs. In typical operation, def statements are coded in\\nmodule files and are naturally run to generate functions when the module file they\\nreside in is first imported.\\n\\n• def creates an object and assigns it to a name. When Python reaches and runs\\na def statement, it generates a new function object and assigns it to the function’s\\nname. As with all assignments, the function name becomes a reference to the func-\\ntion object. There’s nothing magic about the name of a function—as you’ll see,\\nthe function object can be assigned to other names, stored in a list, and so on.\\nFunction objects may also have arbitrary user-defined attributes attached to them\\nto record data.\\n\\n• lambda creates an object but returns it as a result. Functions may also be created\\nwith the lambda expression, a feature that allows us to in-line function definitions\\nin places where a def statement won’t work syntactically. This is a more advanced\\nconcept that we’ll defer until Chapter 19.\\n\\n• return sends a result object back to the caller. When a function is called, the\\ncaller stops until the function finishes its work and returns control to the caller.\\nFunctions that compute a value send it back to the caller with a return statement;\\nthe returned value becomes the result of the function call. A return without a value\\nsimply returns to the caller (and sends back None, the default result).\\n\\n• yield sends a result object back to the caller, but remembers where it left\\noff. Functions known as generators may also use the yield statement to send back\\n\\nCoding Functions\\n\\n| 475\\n\\n\\x0ca value and suspend their state such that they may be resumed later, to produce a\\nseries of results over time. This is another advanced topic covered later in this part\\nof the book.\\n\\n• global declares module-level variables that are to be assigned. By default, all\\nnames assigned in a function are local to that function and exist only while the\\nfunction runs. To assign a name in the enclosing module, functions need to list it\\nin a global statement. More generally, names are always looked up in scopes—\\nplaces where variables are stored—and assignments bind names to scopes.\\n\\n• nonlocal declares enclosing function variables that are to be assigned. Simi-\\nlarly, the nonlocal statement added in Python 3.X allows a function to assign a\\nname that exists in the scope of a syntactically enclosing def statement. This allows\\nenclosing functions to serve as a place to retain state—information remembered\\nbetween function calls—without using shared global names.\\n\\n• Arguments are passed by assignment (object reference). In Python, arguments\\nare passed to functions by assignment (which, as we’ve learned, means by object\\nreference). As you’ll see, in Python’s model the caller and function share objects\\nby references, but there is no name aliasing. Changing an argument name within\\na function does not also change the corresponding name in the caller, but changing\\npassed-in mutable objects in place can change objects shared by the caller, and\\nserve as a function result.\\n\\n• Arguments are passed by position, unless you say otherwise. Values you pass\\nin a function call match argument names in a function’s definition from left to right\\nby default. For flexibility, function calls can also pass arguments by name with\\nname=value keyword syntax, and unpack arbitrarily many arguments to send with\\n*pargs and **kargs starred-argument notation. Function definitions use the same\\ntwo forms to specify argument defaults, and collect arbitrarily many arguments\\nreceived.\\n\\n• Arguments, return values, and variables are not declared. As with everything\\nin Python, there are no type constraints on functions. In fact, nothing about a\\nfunction needs to be declared ahead of time: you can pass in arguments of any type,\\nreturn any kind of object, and so on. As one consequence, a single function can\\noften be applied to a variety of object types—any objects that sport a compatible\\ninterface (methods and expressions) will do, regardless of their specific types.\\n\\nIf some of the preceding words didn’t sink in, don’t worry—we’ll explore all of these\\nconcepts with real code in this part of the book. Let’s get started by expanding on some\\nof these ideas and looking at a few examples.\\n\\ndef Statements\\nThe def statement creates a function object and assigns it to a name. Its general format\\nis as follows:\\n\\n476 | Chapter 16:\\u2002Function Basics\\n\\n\\x0cdef name(arg1, arg2,... argN):\\n    statements\\n\\nAs with all compound Python statements, def consists of a header line followed by a\\nblock  of  statements,  usually  indented  (or  a  simple  statement  after  the  colon).  The\\nstatement block becomes the function’s body—that is, the code Python executes each\\ntime the function is later called.\\nThe def header line specifies a function name that is assigned the function object, along\\nwith a list of zero or more arguments (sometimes called parameters) in parentheses.\\nThe argument names in the header are assigned to the objects passed in parentheses at\\nthe point of call.\\nFunction bodies often contain a return statement:\\n\\ndef name(arg1, arg2,... argN):\\n    ...\\n    return value\\n\\nThe Python return statement can show up anywhere in a function body; when reached,\\nit ends the function call and sends a result back to the caller. The return statement\\nconsists of an optional object value expression that gives the function’s result. If the\\nvalue is omitted, return sends back a None.\\nThe return statement itself is optional too; if it’s not present, the function exits when\\nthe control flow falls off the end of the function body. Technically, a function without\\na return statement also returns the None object automatically, but this return value is\\nusually ignored at the call.\\nFunctions may also contain yield statements, which are designed to produce a series\\nof values over time, but we’ll defer discussion of these until we survey generator topics\\nin Chapter 20.\\n\\ndef Executes at Runtime\\nThe Python def is a true executable statement: when it runs, it creates a new function\\nobject and assigns it to a name. (Remember, all we have in Python is runtime; there is\\nno such thing as a separate compile time.) Because it’s a statement, a def can appear\\nanywhere a statement can—even nested in other statements. For instance, although\\ndefs normally are run when the module enclosing them is imported, it’s also completely\\nlegal to nest a function def inside an if statement to select between alternative defini-\\ntions:\\n\\nif test:\\n    def func():            # Define func this way\\n        ...\\nelse:\\n    def func():            # Or else this way\\n        ...\\n...\\nfunc()                     # Call the version selected and built\\n\\nCoding Functions\\n\\n| 477\\n\\n\\x0cOne way to understand this code is to realize that the def is much like an = statement:\\nit simply assigns a name at runtime. Unlike in compiled languages such as C, Python\\nfunctions do not need to be fully defined before the program runs. More generally,\\ndefs are not evaluated until they are reached and run, and the code inside defs is not\\nevaluated until the functions are later called.\\nBecause  function  definition  happens  at  runtime,  there’s  nothing  special  about  the\\nfunction name. What’s important is the object to which it refers:\\n\\nothername = func           # Assign function object\\nothername()                # Call func again\\n\\nHere, the function was assigned to a different name and called through the new name.\\nLike everything else in Python, functions are just objects; they are recorded explicitly\\nin memory at program execution time. In fact, besides calls, functions allow arbitrary\\nattributes to be attached to record information for later use:\\n\\ndef func(): ...            # Create function object\\nfunc()                     # Call object\\nfunc.attr = value          # Attach attributes\\n\\nA First Example: Definitions and Calls\\nApart from such runtime concepts (which tend to seem most unique to programmers\\nwith backgrounds in traditional compiled languages), Python functions are straight-\\nforward to use. Let’s code a first real example to demonstrate the basics. As you’ll see,\\nthere are two sides to the function picture: a definition (the def that creates a function)\\nand a call (an expression that tells Python to run the function’s body).\\n\\nDefinition\\nHere’s a definition typed interactively that defines a function called times, which re-\\nturns the product of its two arguments:\\n\\n>>> def times(x, y):       # Create and assign function\\n...     return x * y       # Body executed when called\\n...\\n\\nWhen Python reaches and runs this def, it creates a new function object that packages\\nthe function’s code and assigns the object to the name times. Typically, such a state-\\nment is coded in a module file and runs when the enclosing file is imported; for some-\\nthing this small, though, the interactive prompt suffices.\\n\\nCalls\\nThe def statement makes a function but does not call it. After the def has run, you can\\ncall (run) the function in your program by adding parentheses after the function’s name.\\n\\n478 | Chapter 16:\\u2002Function Basics\\n\\n\\x0cThe parentheses may optionally contain one or more object arguments, to be passed\\n(assigned) to the names in the function’s header:\\n\\n>>> times(2, 4)            # Arguments in parentheses\\n8\\n\\nThis expression passes two arguments to times. As mentioned previously, arguments\\nare passed by assignment, so in this case the name x in the function header is assigned\\nthe value 2, y is assigned the value 4, and the function’s body is run. For this function,\\nthe body is just a return statement that sends back the result as the value of the call\\nexpression. The returned object was printed here interactively (as in most languages,\\n2 * 4 is 8 in Python), but if we needed to use it later we could instead assign it to a\\nvariable. For example:\\n\\n>>> x = times(3.14, 4)     # Save the result object\\n>>> x\\n12.56\\n\\nNow, watch what happens when the function is called a third time, with very different\\nkinds of objects passed in:\\n\\n>>> times(\\'Ni\\', 4)         # Functions are \"typeless\"\\n\\'NiNiNiNi\\'\\n\\nThis time, our function means something completely different (Monty Python reference\\nagain intended). In this third call, a string and an integer are passed to x and y, instead\\nof two numbers. Recall that * works on both numbers and sequences; because we never\\ndeclare  the  types  of  variables,  arguments,  or  return  values  in  Python,  we  can  use\\ntimes to either multiply numbers or repeat sequences.\\nIn other words, what our times function means and does depends on what we pass into\\nit. This is a core idea in Python (and perhaps the key to using the language well), which\\nmerits a bit of expansion here.\\n\\nPolymorphism in Python\\nAs we just saw, the very meaning of the expression x * y in our simple times function\\ndepends completely upon the kinds of objects that x and y are—thus, the same function\\ncan perform multiplication in one instance and repetition in another. Python leaves it\\nup to the objects to do something reasonable for the syntax. Really, * is just a dispatch\\nmechanism that routes control to the objects being processed.\\nThis sort of type-dependent behavior is known as polymorphism, a term we first met\\nin Chapter 4 that essentially means that the meaning of an operation depends on the\\nobjects being operated upon. Because it’s a dynamically typed language, polymorphism\\nruns rampant in Python. In fact, every operation is a polymorphic operation in Python:\\nprinting, indexing, the * operator, and much more.\\nThis is deliberate, and it accounts for much of the language’s conciseness and flexibility.\\nA single function, for instance, can generally be applied to a whole category of object\\n\\nA First Example: Definitions and Calls\\n\\n| 479\\n\\n\\x0ctypes  automatically.  As  long  as  those  objects  support  the  expected  interface  (a.k.a.\\nprotocol), the function can process them. That is, if the objects passed into a function\\nhave the expected methods and expression operators, they are plug-and-play compat-\\nible with the function’s logic.\\nEven in our simple times function, this means that any two objects that support a * will\\nwork, no matter what they may be, and no matter when they are coded. This function\\nwill work on two numbers (performing multiplication), or a string and a number (per-\\nforming repetition), or any other combination of objects supporting the expected in-\\nterface—even class-based objects we have not even imagined yet.\\nMoreover, if the objects passed in do not support this expected interface, Python will\\ndetect the error when the * expression is run and raise an exception automatically. It’s\\ntherefore usually pointless to code error checking ourselves. In fact, doing so would\\nlimit our function’s utility, as it would be restricted to work only on objects whose types\\nwe test for.\\nThis turns out to be a crucial philosophical difference between Python and statically\\ntyped languages like C++ and Java: in Python, your code is not supposed to care about\\nspecific data types. If it does, it will be limited to working on just the types you antici-\\npated when you wrote it, and it will not support other compatible object types that\\nmay be coded in the future. Although it is possible to test for types with tools like the\\ntype built-in function, doing so breaks your code’s flexibility. By and large, we code to \\nobject interfaces in Python, not data types.1\\nOf course, some programs have unique requirements, and this polymorphic model of\\nprogramming means we have to test our code to detect errors, rather than providing\\ntype declarations a compiler can use to detect some types of errors for us ahead of time.\\nIn exchange for an initial bit of testing, though, we radically reduce the amount of code\\nwe have to write and radically increase our code’s flexibility. As you’ll learn, it’s a net\\nwin in practice.\\n\\nA Second Example: Intersecting Sequences\\nLet’s look at a second function example that does something a bit more useful than\\nmultiplying arguments and further illustrates function basics.\\nIn Chapter 13, we coded a for loop that collected items held in common in two strings.\\nWe noted there that the code wasn’t as useful as it could be because it was set up to\\nwork only on specific variables and could not be rerun later. Of course, we could copy\\n\\n1. This polymorphic behavior has in recent years come to also be known as duck typing—the essential idea\\nbeing that your code is not supposed to care if an object is a duck, only that it quacks. Anything that\\nquacks will do, duck or not, and the implementation of quacks is up to the object, a principle which will\\nbecome even more apparent when we study classes in Part VI. Graphic metaphor to be sure, though this\\nis really just a new label for an older idea, and use cases for quacking software would seem limited in the\\ntangible world (he says, bracing for emails from militant ornithologists...).\\n\\n480 | Chapter 16:\\u2002Function Basics\\n\\n\\x0cthe code and paste it into each place where it needs to be run, but this solution is neither\\ngood  nor  general—we’d  still  have  to  edit  each  copy  to  support  different  sequence\\nnames, and changing the algorithm would then require changing multiple copies.\\n\\nDefinition\\nBy now, you can probably guess that the solution to this dilemma is to package the\\nfor loop inside a function. Doing so offers a number of advantages:\\n\\n• Putting the code in a function makes it a tool that you can run as many times as\\n\\nyou like.\\n\\n• Because callers can pass in arbitrary arguments, functions are general enough to\\n\\nwork on any two sequences (or other iterables) you wish to intersect.\\n\\n• When the logic is packaged in a function, you have to change code in only one\\n\\nplace if you ever need to change the way the intersection works.\\n\\n• Coding the function in a module file means it can be imported and reused by any\\n\\nprogram run on your machine.\\n\\nIn effect, wrapping the code in a function makes it a general intersection utility:\\n\\ndef intersect(seq1, seq2):\\n    res = []                     # Start empty\\n    for x in seq1:               # Scan seq1\\n        if x in seq2:            # Common item?\\n            res.append(x)        # Add to end\\n    return res\\n\\nThe transformation from the simple code of Chapter 13 to this function is straightfor-\\nward; we’ve just nested the original logic under a def header and made the objects on\\nwhich it operates passed-in parameter names. Because this function computes a result,\\nwe’ve also added a return statement to send a result object back to the caller.\\n\\nCalls\\nBefore you can call a function, you have to make it. To do this, run its def statement,\\neither by typing it interactively or by coding it in a module file and importing the file.\\nOnce you’ve run the def, you can call the function by passing any two sequence objects\\nin parentheses:\\n\\n>>> s1 = \"SPAM\"\\n>>> s2 = \"SCAM\"\\n>>> intersect(s1, s2)            # Strings\\n[\\'S\\', \\'A\\', \\'M\\']\\n\\nHere, we’ve passed in two strings, and we get back a list containing the characters in\\ncommon. The algorithm the function uses is simple: “for every item in the first argu-\\nment, if that item is also in the second argument, append the item to the result.” It’s a\\nlittle shorter to say that in Python than in English, but it works out the same.\\n\\nA Second Example: Intersecting Sequences\\n\\n| 481\\n\\n\\x0cTo be fair, our intersect function is fairly slow (it executes nested loops), isn’t really\\nmathematical intersection (there may be duplicates in the result), and isn’t required at\\nall (as we’ve seen, Python’s set data type provides a built-in intersection operation).\\nIndeed, the function could be replaced with a single list comprehension expression, as\\nit exhibits the classic loop collector code pattern:\\n\\n>>> [x for x in s1 if x in s2]\\n[\\'S\\', \\'A\\', \\'M\\']\\n\\nAs a function basics example, though, it does the job—this single piece of code can\\napply  to  an  entire  range  of  object  types,  as  the  next  section  explains.  In  fact,  we’ll\\nimprove and extend this to support arbitrarily many operands in Chapter 18, after we\\nlearn more about argument passing modes.\\n\\nPolymorphism Revisited\\nLike all good functions in Python, intersect is polymorphic. That is, it works on ar-\\nbitrary types, as long as they support the expected object interface:\\n\\n>>> x = intersect([1, 2, 3], (1, 4))      # Mixed types\\n>>> x                                     # Saved result object\\n[1]\\n\\nThis time, we passed in different types of objects to our function—a list and a tuple\\n(mixed types)—and it still picked out the common items. Because you don’t have to\\nspecify the types of arguments ahead of time, the intersect function happily iterates\\nthrough any kind of sequence objects you send it, as long as they support the expected\\ninterfaces.\\nFor intersect, this means that the first argument has to support the for loop, and the\\nsecond has to support the in membership test. Any two such objects will work, re-\\ngardless of their specific types—that includes physically stored sequences like strings\\nand lists; all the iterable objects we met in Chapter 14, including files and dictionaries;\\nand even any class-based objects we code that apply operator overloading techniques\\nwe’ll discuss later in the book.2\\nHere again, if we pass in objects that do not support these interfaces (e.g., numbers),\\nPython will automatically detect the mismatch and raise an exception for us—which\\nis exactly what we want, and the best we could do on our own if we coded explicit type\\n\\n2. This code will always work if we intersect files’ contents obtained with file.readlines(). It may not work\\nto intersect lines in open input files directly, though, depending on the file object’s implementation of\\nthe in operator or general iteration. Files must generally be rewound (e.g., with a file.seek(0) or another\\nopen)  after  they  have  been  read  to  end-of-file  once,  and  so  are  single-pass  iterators.  As  we’ll  see  in\\nChapter 30 when we study operator overloading, objects implement the in operator either by providing\\nthe specific __contains__ method or by supporting the general iteration protocol with the __iter__ or\\nolder __getitem__ methods; classes can code these methods arbitrarily to define what iteration means for\\ntheir data.\\n\\n482 | Chapter 16:\\u2002Function Basics\\n\\n\\x0ctests. By not coding type tests and allowing Python to detect the mismatches for us, we\\nboth reduce the amount of code we need to write and increase our code’s flexibility.\\n\\nLocal Variables\\nProbably the most interesting part of this example, though, is its names. It turns out\\nthat the variable res inside intersect is what in Python is called a local variable—a\\nname that is visible only to code inside the function def and that exists only while the\\nfunction  runs.  In  fact,  because  all  names  assigned  in  any  way  inside  a  function  are\\nclassified as local variables by default, nearly all the names in intersect are local vari-\\nables:\\n\\n• res is obviously assigned, so it is a local variable.\\n• Arguments are passed by assignment, so seq1 and seq2 are, too.\\n• The for loop assigns items to a variable, so the name x is also local.\\n\\nAll these local variables appear when the function is called and disappear when the\\nfunction  exits—the  return  statement  at  the  end  of  intersect  sends  back  the  result\\nobject, but the name res goes away. Because of this, a function’s variables won’t re-\\nmember values between calls; although the object returned by a function lives on, re-\\ntaining  other  sorts  of  state  information  requires  other  sorts  of  techniques.  To  fully\\nexplore the notion of locals and state, though, we need to move on to the scopes \\ncoverage of Chapter 17.\\n\\nChapter Summary\\nThis chapter introduced the core ideas behind function definition—the syntax and\\noperation of the def and return statements, the behavior of function call expressions,\\nand the notion and benefits of polymorphism in Python functions. As we saw, a def\\nstatement is executable code that creates a function object at runtime; when the func-\\ntion  is  later  called,  objects  are  passed  into  it  by  assignment  (recall  that  assignment\\nmeans object reference in Python, which, as we learned in Chapter 6, really means\\npointer internally), and computed values are sent back by return. We also began ex-\\nploring the concepts of local variables and scopes in this chapter, but we’ll save all the\\ndetails on those topics for Chapter 17. First, though, a quick quiz.\\n\\nTest Your Knowledge: Quiz\\n1. What is the point of coding functions?\\n2. At what time does Python create a function?\\n3. What does a function return if it has no return statement in it?\\n4. When does the code nested inside the function definition statement run?\\n\\nTest Your Knowledge: Quiz | 483\\n\\n\\x0c5. What’s wrong with checking the types of objects passed into a function?\\n\\nTest Your Knowledge: Answers\\n1. Functions are the most basic way of avoiding code redundancy in Python—factor-\\ning code into functions means that we have only one copy of an operation’s code\\nto update in the future. Functions are also the basic unit of code reuse in Python\\n—wrapping code in functions makes it a reusable tool, callable in a variety of pro-\\ngrams. Finally, functions allow us to divide a complex system into manageable\\nparts, each of which may be developed individually.\\n\\n2. A function is created when Python reaches and runs the def statement; this state-\\nment creates a function object and assigns it the function’s name. This normally\\nhappens when the enclosing module file is imported by another module (recall that\\nimports run the code in a file from top to bottom, including any defs), but it can\\nalso occur when a def is typed interactively or nested in other statements, such as\\nifs.\\n\\n3. A function returns the None object by default if the control flow falls off the end of\\nthe function body without running into a return statement. Such functions are\\nusually called with expression statements, as assigning their None results to vari-\\nables is generally pointless. A return statement with no expression in it also returns\\nNone.\\n\\n4. The function body (the code nested inside the function definition statement) is run\\nwhen the function is later called with a call expression. The body runs anew each\\ntime the function is called.\\n\\n5. Checking the types of objects passed into a function effectively breaks the func-\\ntion’s flexibility, constraining the function to work on specific types only. Without\\nsuch checks, the function would likely be able to process an entire range of object\\ntypes—any objects that support the interface expected by the function will work.\\n(The term interface means the set of methods and expression operators the func-\\ntion’s code runs.)\\n\\n484 | Chapter 16:\\u2002Function Basics\\n\\n\\x0cCHAPTER 17\\nScopes\\n\\nChapter 16 introduced basic function definitions and calls. As we saw, Python’s core\\nfunction model is simple to use, but even simple function examples quickly led us to\\nquestions about the meaning of variables in our code. This chapter moves on to present\\nthe details behind Python’s scopes—the places where variables are defined and looked\\nup. Like module files, scopes help prevent name clashes across your program’s code:\\nnames defined in one program unit don’t interfere with names in another.\\nAs we’ll see, the place where a name is assigned in our code is crucial to determining\\nwhat the name means. We’ll also find that scope usage can have a major impact on\\nprogram maintenance effort; overuse of globals, for example, is a generally bad thing.\\nOn the plus side, we’ll learn that scopes can provide a way to retain state information\\nbetween function calls, and offer an alternative to classes in some roles.\\n\\nPython Scope Basics\\nNow that you’re ready to start writing your own functions, we need to get more formal\\nabout what names mean in Python. When you use a name in a program, Python creates,\\nchanges, or looks up the name in what is known as a namespace—a place where names\\nlive. When we talk about the search for a name’s value in relation to code, the term\\nscope refers to a namespace: that is, the location of a name’s assignment in your source\\ncode determines the scope of the name’s visibility to your code.\\nJust about everything related to names, including scope classification, happens at as-\\nsignment time in Python. As we’ve seen, names in Python spring into existence when\\nthey are first assigned values, and they must be assigned before they are used. Because\\nnames are not declared ahead of time, Python uses the location of the assignment of a\\nname to associate it with (i.e., bind it to) a particular namespace. In other words, the\\nplace where you assign a name in your source code determines the namespace it will\\nlive in, and hence its scope of visibility.\\nBesides packaging code for reuse, functions add an extra namespace layer to your pro-\\ngrams to minimize the potential for collisions among variables of the same name—by\\n\\n485\\n\\n\\x0cdefault, all names assigned inside a function are associated with that function’s namespace,\\nand no other. This rule means that:\\n\\n• Names assigned inside a def can only be seen by the code within that def. You\\n\\ncannot even refer to such names from outside the function.\\n\\n• Names assigned inside a def do not clash with variables outside the def, even if the\\nsame names are used elsewhere. A name X assigned outside a given def (i.e., in a\\ndifferent def or at the top level of a module file) is a completely different variable\\nfrom a name X assigned inside that def.\\n\\nIn all cases, the scope of a variable (where it can be used) is always determined by where\\nit is assigned in your source code and has nothing to do with which functions call which.\\nIn fact, as we’ll learn in this chapter, variables may be assigned in three different places,\\ncorresponding to three different scopes:\\n\\n• If a variable is assigned inside a def, it is local to that function.\\n• If a variable is assigned in an enclosing def, it is nonlocal to nested functions.\\n• If a variable is assigned outside all defs, it is global to the entire file.\\n\\nWe call this lexical scoping because variable scopes are determined entirely by the lo-\\ncations of the variables in the source code of your program files, not by function calls.\\nFor example, in the following module file, the X = 99 assignment creates a global vari-\\nable  named  X  (visible  everywhere  in  this  file),  but  the  X  =  88  assignment  creates  a\\nlocal variable X (visible only within the def statement):\\n\\nX = 99                     # Global (module) scope X\\n\\ndef func():\\n    X = 88                 # Local (function) scope X: a different variable\\n\\nEven though both variables are named X, their scopes make them different. The net\\neffect is that function scopes help to avoid name clashes in your programs and help to\\nmake functions more self-contained program units—their code need not be concerned\\nwith names used elsewhere.\\n\\nScope Details\\nBefore we started writing functions, all the code we wrote was at the top level of a\\nmodule (i.e., not nested in a def), so the names we used either lived in the module itself\\nor were built-ins predefined by Python (e.g., open). Technically, the interactive prompt\\nis a module named __main__ that prints results and doesn’t save its code; in all other\\nways, though, it’s like the top level of a module file.\\nFunctions, though, provide nested namespaces (scopes) that localize the names they\\nuse, such that names inside a function won’t clash with those outside it (in a module\\nor  another  function).  Functions  define  a  local  scope  and  modules  define  a  global\\nscope with the following properties:\\n\\n486 | Chapter 17:\\u2002Scopes\\n\\n\\x0c• The enclosing module is a global scope. Each module is a global scope—that\\nis, a namespace in which variables created (assigned) at the top level of the module\\nfile live. Global variables become attributes of a module object to the outside world\\nafter imports but can also be used as simple variables within the module file itself.\\n• The global scope spans a single file only. Don’t be fooled by the word “global”\\nhere—names at the top level of a file are global to code within that single file only.\\nThere is really no notion of a single, all-encompassing global file-based scope in\\nPython. Instead, names are partitioned into modules, and you must always import\\na module explicitly if you want to be able to use the names its file defines. When\\nyou hear “global” in Python, think “module.”\\n\\n• Assigned names are local unless declared global or nonlocal. By default, all\\nthe  names  assigned  inside  a  function  definition  are  put  in  the  local  scope  (the\\nnamespace associated with the function call). If you need to assign a name that\\nlives at the top level of the module enclosing the function, you can do so by de-\\nclaring it in a global statement inside the function. If you need to assign a name\\nthat lives in an enclosing def, as of Python 3.X you can do so by declaring it in a\\nnonlocal statement.\\n\\n• All other names are enclosing function locals, globals, or built-ins. Names\\nnot assigned a value in the function definition are assumed to be enclosing scope\\nlocals, defined in a physically surrounding def statement; globals that live in the\\nenclosing  module’s  namespace;  or  built-ins  in  the  predefined  built-ins  module\\nPython provides.\\n\\n• Each call to a function creates a new local scope. Every time you call a function,\\nyou create a new local scope—that is, a namespace in which the names created\\ninside that function will usually live. You can think of each def statement (and\\nlambda expression) as defining a new local scope, but the local scope actually cor-\\nresponds to a function call. Because Python allows functions to call themselves to\\nloop—an advanced technique known as recursion and noted briefly in Chapter 9\\nwhen  we  explored  comparisons—each  active  call  receives  its  own  copy  of  the\\nfunction’s local variables. Recursion is useful in functions we write as well, to pro-\\ncess structures whose shapes can’t be predicted ahead of time; we’ll explore it more\\nfully in Chapter 19.\\n\\nThere are a few subtleties worth underscoring here. First, keep in mind that code typed\\nat the interactive command prompt lives in a module, too, and follows the normal scope\\nrules: they are global variables, accessible to the entire interactive session. You’ll learn\\nmore about modules in the next part of this book.\\nAlso note that any type of assignment within a function classifies a name as local. This\\nincludes = statements, module names in import, function names in def, function argu-\\nment names, and so on. If you assign a name in any way within a def, it will become a\\nlocal to that function by default.\\n\\nPython Scope Basics\\n\\n| 487\\n\\n\\x0cConversely, in-place changes to objects do not classify names as locals; only actual name\\nassignments do. For instance, if the name L is assigned to a list at the top level of a\\nmodule, a statement L = X within a function will classify L as a local, but L.append(X)\\nwill not. In the latter case, we are changing the list object that L references, not L itself\\n—L is found in the global scope as usual, and Python happily modifies it without re-\\nquiring a global (or nonlocal) declaration. As usual, it helps to keep the distinction\\nbetween names and objects clear: changing an object is not an assignment to a name.\\n\\nName Resolution: The LEGB Rule\\nIf the prior section sounds confusing, it really boils down to three simple rules. With a\\ndef statement:\\n\\n• Name assignments create or change local names by default.\\n• Name references search at most four scopes: local, then enclosing functions (if any),\\n\\nthen global, then built-in.\\n\\n• Names declared in global and nonlocal statements map assigned names to en-\\n\\nclosing module and function scopes, respectively.\\n\\nIn other words, all names assigned inside a function def statement (or a lambda, an\\nexpression we’ll meet later) are locals by default. Functions can freely use names as-\\nsigned in syntactically enclosing functions and the global scope, but they must declare\\nsuch nonlocals and globals in order to change them.\\nPython’s name-resolution scheme is sometimes called the LEGB rule, after the scope\\nnames:\\n\\n• When you use an unqualified name inside a function, Python searches up to four\\nscopes—the local (L) scope, then the local scopes of any enclosing (E) defs and\\nlambdas, then the global (G) scope, and then the built-in (B) scope—and stops at\\nthe first place the name is found. If the name is not found during this search, Python\\nreports an error.\\n\\n• When you assign a name in a function (instead of just referring to it in an expres-\\nsion), Python always creates or changes the name in the local scope, unless it’s\\ndeclared to be global or nonlocal in that function.\\n\\n• When you assign a name outside any function (i.e., at the top level of a module\\nfile, or at the interactive prompt), the local scope is the same as the global scope—\\nthe module’s namespace.\\n\\nBecause  names  must  be  assigned  before  they  can  be  used  (as  we  learned  in  Chap-\\nter 6), there are no automatic components in this model: assignments always determine\\nname scopes unambiguously. Figure 17-1 illustrates Python’s four scopes. Note that\\nthe second scope lookup layer, E—the scopes of enclosing defs or lambdas—can tech-\\nnically correspond to more than one lookup level. This case only comes into play when\\nyou nest functions within functions, and is enhanced by the nonlocal statement in 3.X.1\\n\\n488 | Chapter 17:\\u2002Scopes\\n\\n\\x0cFigure 17-1. The LEGB scope lookup rule. When a variable is referenced, Python searches for it in\\nthis order: in the local scope, in any enclosing functions’ local scopes, in the global scope, and finally\\nin the built-in scope. The first occurrence wins. The place in your code where a variable is assigned\\nusually determines its scope. In Python 3.X, nonlocal declarations can also force names to be mapped\\nto enclosing function scopes, whether assigned or not.\\n\\nAlso keep in mind that these rules apply only to simple variable names (e.g., spam). In\\nParts V and VI, we’ll see that qualified attribute names (e.g., object.spam) live in par-\\nticular objects and follow a completely different set of lookup rules than those covered\\nhere. References to attribute names following periods (.) search one or more objects,\\nnot  scopes,  and  in  fact  may  invoke  something  called  inheritance  in  Python’s  OOP\\nmodel; more on this in Part VI of this book.\\n\\nOther Python scopes: Preview\\nThough obscure at this point in the book, there are technically three more scopes in\\nPython—temporary loop variables in some comprehensions, exception reference vari-\\nables in some try handlers, and local scopes in class statements. The first two of these\\nare special cases that rarely impact real code, and the third falls under the LEGB um-\\nbrella rule.\\nMost statement blocks and other constructs do not localize the names used within\\nthem, with the following version-specific exceptions (whose variables are not available\\nto, but also will not clash with, surrounding code, and which involve topics covered in\\nfull later):\\n\\n1. The scope lookup rule was called the “LGB rule” in the first edition of this book. The enclosing def “E”\\nlayer was added later in Python to obviate the task of passing in enclosing scope names explicitly with\\ndefault arguments—a topic usually of marginal interest to Python beginners that we’ll defer until later in\\nthis chapter. Since this scope is now addressed by the nonlocal statement in Python 3.X, the lookup rule\\nmight be better named “LNGB” today, but backward compatibility matters in books, too. The present\\nform of this acronym also does not account for the newer obscure scopes of some comprehensions and\\nexception handlers, but acronyms longer than four letters tend to defeat their purpose!\\n\\nPython Scope Basics\\n\\n| 489\\n\\n\\x0c• Comprehension variables—the variable X used to refer to the current iteration item\\nin a comprehension expression such as [X for X in I]. Because they might clash\\nwith other names and reflect internal state in generators, in 3.X, such variables are\\nlocal to the expression itself in all comprehension forms: generator, list, set, and\\ndictionary. In 2.X, they are local to generator expressions and set and dictionary\\ncompressions, but not to list comprehensions that map their names to the scope\\noutside the expression. By contrast, for loop statements never localize their vari-\\nables to the statement block in any Python. See Chapter 20 for more details and\\nexamples.\\n\\n• Exception  variables—the  variable  X  used  to  reference  the  raised  exception  in  a\\ntry statement handler clause such as except E as X. Because they might defer \\ngarbage  collection’s  memory  recovery,  in  3.X,  such  variables  are  local  to  that\\nexcept block, and in fact are removed when the block is exited (even if you’ve used\\nit earlier in your code!). In 2.X, these variables live on after the try statement. See\\nChapter 34 for additional information.\\n\\nThese contexts augment the LEGB rule, rather than modifying it. Variables assigned\\nin a comprehension, for example, are simply bound to a further nested and special-case\\nscope; other names referenced within these expressions follow the usual LEGB lookup\\nrules.\\nIt’s also worth noting that the  class statement we’ll meet in Part VI creates a new\\nlocal scope too for the names assigned inside the top level of its block. As for def, names\\nassigned inside a class don’t clash with names elsewhere, and follow the LEGB lookup\\nrule, where the class block is the “L” level. Like modules and imports, these names\\nalso morph into class object attributes after the class statements ends.\\nUnlike functions, though, class names are not created per call: class object calls gen-\\nerate instances, which inherit names assigned in the class and record per-object state\\nas attributes. As we’ll also learn in Chapter 29, although the LEGB rule is used to resolve\\nnames used in both the top level of a class itself as well as the top level of method\\nfunctions  nested  within  it,  classes  themselves  are  skipped  by  scope  lookups—their\\nnames must be fetched as object attributes. Because Python searches enclosing func-\\ntions for referenced names, but not enclosing classes, the LEGB rule still applies to\\nOOP code.\\n\\nScope Example\\nLet’s step through a larger example that demonstrates scope ideas. Suppose we wrote\\nthe following code in a module file:\\n\\n# Global scope\\nX = 99                # X and func assigned in module: global\\n\\ndef func(Y):          # Y and Z assigned in function: locals\\n    # Local scope\\n    Z = X + Y         # X is a global\\n\\n490 | Chapter 17:\\u2002Scopes\\n\\n\\x0c    return Z\\n\\nfunc(1)               # func in module: result=100\\n\\nThis module and the function it contains use a number of names to do their business.\\nUsing Python’s scope rules, we can classify the names as follows:\\n\\nGlobal names: X, func\\n\\nX is global because it’s assigned at the top level of the module file; it can be refer-\\nenced inside the function as a simple unqualified variable without being declared\\nglobal. func is global for the same reason; the def statement assigns a function\\nobject to the name func at the top level of the module.\\n\\nLocal names: Y, Z\\n\\nY and Z are local to the function (and exist only while the function runs) because\\nthey are both assigned values in the function definition: Z by virtue of the = state-\\nment, and Y because arguments are always passed by assignment.\\n\\nThe underlying rationale for this name-segregation scheme is that local variables serve\\nas temporary names that you need only while a function is running. For instance, in\\nthe preceding example, the argument Y and the addition result Z exist only inside the\\nfunction; these names don’t interfere with the enclosing module’s namespace (or any\\nother function, for that matter). In fact, local variables are removed from memory when\\nthe function call exits, and objects they reference may be garbage-collected if not ref-\\nerenced elsewhere. This is an automatic, internal step, but it helps minimize memory\\nrequirements.\\nThe local/global distinction also makes functions easier to understand, as most of the\\nnames a function uses appear in the function itself, not at some arbitrary place in a\\nmodule. Also, because you can be sure that local names will not be changed by some\\nremote function in your program, they tend to make programs easier to debug and\\nmodify. Functions are self-contained units of software.\\n\\nThe Built-in Scope\\nWe’ve been talking about the built-in scope in the abstract, but it’s a bit simpler than\\nyou may think. Really, the built-in scope is just a built-in module called builtins, but\\nyou have to import builtins to query built-ins because the name builtins is not itself\\nbuilt in...\\nNo, I’m serious! The built-in scope is implemented as a standard library module named\\nbuiltins in 3.X, but that name itself is not placed in the built-in scope, so you have to\\nimport it in order to inspect it. Once you do, you can run a dir call to see which names\\nare predefined. In Python 3.3 (see ahead for 2.X usage):\\n\\n>>> import builtins\\n>>> dir(builtins)\\n[\\'ArithmeticError\\', \\'AssertionError\\', \\'AttributeError\\', \\'BaseException\\',\\n\\'BlockingIOError\\', \\'BrokenPipeError\\', \\'BufferError\\', \\'BytesWarning\\',\\n\\nPython Scope Basics\\n\\n| 491\\n\\n\\x0c...many more names omitted...\\n\\'ord\\', \\'pow\\', \\'print\\', \\'property\\', \\'quit\\', \\'range\\', \\'repr\\', \\'reversed\\',\\n\\'round\\', \\'set\\', \\'setattr\\', \\'slice\\', \\'sorted\\', \\'staticmethod\\', \\'str\\', \\'sum\\',\\n\\'super\\', \\'tuple\\', \\'type\\', \\'vars\\', \\'zip\\']\\n\\nThe names in this list constitute the built-in scope in Python; roughly the first half are\\nbuilt-in exceptions, and the second half are built-in functions. Also in this list are the\\nspecial names None, True, and False, though they are treated as reserved words in 3.X.\\nBecause Python automatically searches this module last in its LEGB lookup, you get\\nall the names in this list “for free”—that is, you can use them without importing any\\nmodules. Thus, there are really two ways to refer to a built-in function—by taking\\nadvantage of the LEGB rule, or by manually importing the builtins module:\\n\\n>>> zip                         # The normal way\\n<class \\'zip\\'>\\n\\n>>> import builtins             # The hard way: for customizations\\n>>> builtins.zip\\n<class \\'zip\\'>\\n\\n>>> zip is builtins.zip         # Same object, different lookups\\nTrue\\n\\nThe second of these approaches is sometimes useful in advanced ways we’ll meet in\\nthis chapter’s sidebars.\\n\\nRedefining built-in names: For better or worse\\nThe careful reader might also notice that because the LEGB lookup procedure takes\\nthe  first  occurrence  of  a  name  that  it  finds,  names  in  the  local  scope  may  override\\nvariables of the same name in both the global and built-in scopes, and global names\\nmay override built-ins. A function can, for instance, create a local variable called open\\nby assigning to it:\\n\\ndef hider():\\n    open = \\'spam\\'              # Local variable, hides built-in here\\n    ...\\n    open(\\'data.txt\\')           # Error: this no longer opens a file in this scope!\\n\\nHowever, this will hide the built-in function called open that lives in the built-in (outer)\\nscope, such that the name open will no longer work within the function to open files—\\nit’s now a string, not the opener function. This isn’t a problem if you don’t need to\\nopen files in this function, but triggers an error if you attempt to open through this\\nname.\\nThis can even occur more simply at the interactive prompt, which works as a global,\\nmodule scope:\\n\\n>>> open = 99                   # Assign in global scope, hides built-in here too\\n\\nNow, there is nothing inherently wrong with using a built-in name for variables of your\\nown, as long as you don’t need the original built-in version. After all, if these were truly\\n\\n492 | Chapter 17:\\u2002Scopes\\n\\n\\x0coff limits, we would need to memorize the entire built-in names list and treat all its\\nnames as reserved. With over 140 names in this module in 3.3, that would be far too\\nrestrictive and daunting:\\n\\n>>> len(dir(builtins)), len([x for x in dir(builtins) if not x.startswith(\\'__\\')])\\n(148, 142)\\n\\nIn fact, there are times in advanced programming where you may really want to replace\\na built-in name by redefining it in your code—to define a custom open that verifies\\naccess  attempts,  for  instance  (see  this  chapter’s  sidebar  “Breaking  the  Universe  in\\nPython 2.X” on page 494 for more on this thread).\\nStill, redefining a built-in name is often a bug, and a nasty one at that, because Python\\nwill not issue a warning message about it. Tools like PyChecker (see the Web) can warn\\nyou of such mistakes, but knowledge may be your best defense on this point: don’t\\nredefine a built-in name you need. If you accidentally reassign a built-in name at the\\ninteractive prompt this way, you can either restart your session or run a del name state-\\nment to remove the redefinition from your scope, thereby restoring the original in the\\nbuilt-in scope.\\nNote that functions can similarly hide global variables of the same name with locals,\\nbut this is more broadly useful, and in fact is much of the point of local scopes—because\\nthey minimize the potential for name clashes, your functions are self-contained name-\\nspace scopes:\\n\\nX = 88                         # Global X\\n\\ndef func():\\n    X = 99                     # Local X: hides global, but we want this here\\n\\nfunc()\\nprint(X)                       # Prints 88: unchanged\\n\\nHere, the assignment within the function creates a local X that is a completely different\\nvariable from the global X in the module outside the function. As one consequence,\\nthough, there is no way to change a name outside a function without adding a global\\n(or nonlocal) declaration to the def, as described in the next section.\\n\\nVersion skew note: Actually, the tongue twisting gets a bit worse. The\\nPython 3.X builtins module used here is named __builtin__ in Python\\n2.X. In addition, the name __builtins__ (with the s) is preset in most\\nglobal scopes, including the interactive session, to reference the module\\nknown as builtins in 3.X and __builtin__ in 2.X, so you can often use\\n__builtins__ without an import but cannot run an import on that name\\nitself—it’s a preset variable, not a module’s name.\\n\\nThat is, in 3.X builtins is __builtins__ is True after you import buil\\ntins, and in 2.X __builtin__ is __builtins__ is True after you import\\n__builtin__. The upshot is that we can usually inspect the built-in scope\\nby simply running dir(__builtins__) with no import in both 3.X and\\n\\nPython Scope Basics\\n\\n| 493\\n\\n\\x0c2.X, but we are advised to use builtins for real work and customization\\nin 3.X, and __builtin__ for the same in 2.X. Who said documenting this\\nstuff was easy?\\n\\nBreaking the Universe in Python 2.X\\n\\nHere’s another thing you can do in Python that you probably shouldn’t—because the\\nnames True and False in 2.X are just variables in the built-in scope and are not reserved,\\nit’s possible to reassign them with a statement like True = False. Don’t worry: you\\nwon’t actually break the logical consistency of the universe in so doing! This statement\\nmerely  redefines  the  word  True  for  the  single  scope  in  which  it  appears  to  return\\nFalse. All other scopes still find the originals in the built-in scope.\\nFor more fun, though, in Python 2.X you could say __builtin__.True = False, to reset\\nTrue to False for the entire Python process. This works because there is only one built-\\nin scope module in a program, shared by all its clients. Alas, this type of assignment\\nhas been disallowed in Python 3.X, because True and False are treated as actual reserved\\nwords, just like None. In 2.X, though, it sends IDLE into a strange panic state that resets\\nthe user code process (in other words, don’t try this at home, kids).\\n\\nThis technique can be useful, however, both to illustrate the underlying namespace\\nmodel,  and  for  tool  writers  who  must  change  built-ins  such  as  open  to  customized\\nfunctions. By reassigning a function’s name in the built-in scope, you reset it to your\\ncustomization for every module in the process. If you do, you’ll probably also need to\\nremember the original version to call from your customization—in fact, we’ll see one\\nway to achieve this for a custom open in the sidebar “Why You Will Care: Customizing\\nopen” on page 517 after we’ve had a chance to explore nested scope closures and state\\nretention options.\\n\\nAlso, note again that third-party tools such as PyChecker, and others such as PyLint,\\nwill warn about common programming mistakes, including accidental assignment to\\nbuilt-in names (this is usually known as “shadowing” a built-in in such tools). It’s not\\na bad idea to run your first few Python programs through tools like these to see what\\nthey point out.\\n\\nThe global Statement\\nThe global statement and its nonlocal 3.X cousin are the only things that are remotely\\nlike declaration statements in Python. They are not type or size declarations, though;\\nthey are namespace declarations. The global statement tells Python that a function plans\\nto change one or more global names—that is, names that live in the enclosing module’s\\nscope (namespace).\\nWe’ve talked about global in passing already. Here’s a summary:\\n\\n• Global names are variables assigned at the top level of the enclosing module file.\\n\\n494 | Chapter 17:\\u2002Scopes\\n\\n\\x0c• Global names must be declared only if they are assigned within a function.\\n• Global names may be referenced within a function without being declared.\\n\\nIn other words, global allows us to change names that live outside a def at the top level\\nof a module file. As we’ll see later, the nonlocal statement is almost identical but applies\\nto names in the enclosing def’s local scope, rather than names in the enclosing module.\\nThe global statement consists of the keyword global, followed by one or more names\\nseparated by commas. All the listed names will be mapped to the enclosing module’s\\nscope when assigned or referenced within the function body. For instance:\\n\\nX = 88                         # Global X\\n\\ndef func():\\n    global X\\n    X = 99                     # Global X: outside def\\n\\nfunc()\\nprint(X)                       # Prints 99\\n\\nWe’ve added a global declaration to the example here, such that the X inside the def\\nnow refers to the X outside the def; they are the same variable this time, so changing\\nX inside the function changes the X outside it. Here is a slightly more involved example\\nof global at work:\\n\\ny, z = 1, 2                    # Global variables in module\\ndef all_global():\\n    global x                   # Declare globals assigned\\n    x = y + z                  # No need to declare y, z: LEGB rule\\n\\nHere, x, y, and z are all globals inside the function all_global. y and z are global because\\nthey aren’t assigned in the function; x is global because it was listed in a global statement\\nto map it to the module’s scope explicitly. Without the global here, x would be con-\\nsidered local by virtue of the assignment.\\nNotice that y and z are not declared global; Python’s LEGB lookup rule finds them in\\nthe module automatically. Also, notice that x does not even exist in the enclosing mod-\\nule before the function runs; in this case, the first assignment in the function creates\\nx in the module.\\n\\nProgram Design: Minimize Global Variables\\nFunctions in general, and global variables in particular, raise some larger design ques-\\ntions. How should our functions communicate? Although some of these will become\\nmore apparent when you begin writing larger functions of your own, a few guidelines\\nup front might spare you from problems later. In general, functions should rely on\\narguments and return values instead of globals, but I need to explain why.\\nBy default, names assigned in functions are locals, so if you want to change names\\noutside functions you have to write extra code (e.g., global statements). This is delib-\\n\\nThe global Statement\\n\\n| 495\\n\\n\\x0cerate—as is common in Python, you have to say more to do the potentially “wrong”\\nthing. Although there are times when globals are useful, variables assigned in a def are\\nlocal by default because that is normally the best policy. Changing globals can lead to\\nwell-known software engineering problems: because the variables’ values are depen-\\ndent on the order of calls to arbitrarily distant functions, programs can become difficult\\nto debug, or to understand at all.\\nConsider this module file, for example, which is presumably imported and used else-\\nwhere:\\n\\nX = 99\\ndef func1():\\n    global X\\n    X = 88\\n\\ndef func2():\\n    global X\\n    X = 77\\n\\nNow, imagine that it is your job to modify or reuse this code. What will the value of\\nX be here? Really, that question has no meaning unless it’s qualified with a point of\\nreference in time—the value of X is timing-dependent, as it depends on which function\\nwas called last (something we can’t tell from this file alone).\\nThe net effect is that to understand this code, you have to trace the flow of control\\nthrough the entire program. And, if you need to reuse or modify the code, you have to\\nkeep the entire program in your head all at once. In this case, you can’t really use one\\nof these functions without bringing along the other. They are dependent on—that is,\\ncoupled with—the global variable. This is the problem with globals: they generally make\\ncode  more  difficult  to  understand  and  reuse  than  code  consisting  of  self-contained\\nfunctions that rely on locals.\\nOn the other hand, short of using tools like nested scope closures or object-oriented\\nprogramming with classes, global variables are probably the most straightforward way\\nin  Python  to  retain  shared  state  information—information  that  a  function  needs  to\\nremember for use the next time it is called. Local variables disappear when the function\\nreturns, but globals do not. As we’ll see later, other techniques can achieve this, too,\\nand allow for multiple copies of the retained information, but they are generally more\\ncomplex than pushing values out to the global scope for retention in simple use cases\\nwhere this applies.\\nMoreover, some programs designate a single module to collect globals; as long as this\\nis expected, it is not as harmful. Programs that use multithreading to do parallel pro-\\ncessing in Python also commonly depend on global variables—they become shared\\nmemory between functions running in parallel threads, and so act as a communication\\ndevice.2\\nFor now, though, especially if you are relatively new to programming, avoid the temp-\\ntation to use globals whenever you can—they tend to make programs difficult to un-\\n\\n496 | Chapter 17:\\u2002Scopes\\n\\n\\x0cderstand and reuse, and won’t work for cases where one copy of saved data is not\\nenough. Try to communicate with passed-in arguments and return values instead. Six\\nmonths from now, both you and your coworkers may be happy you did.\\n\\nProgram Design: Minimize Cross-File Changes\\nHere’s another scope-related design issue: although we can change variables in another\\nfile directly, we usually shouldn’t. Module files were introduced in Chapter 3 and are\\ncovered in more depth in the next part of this book. To illustrate their relationship to\\nscopes, consider these two module files:\\n\\n# first.py\\nX = 99                    # This code doesn\\'t know about second.py\\n\\n# second.py\\nimport first\\nprint(first.X)            # OK: references a name in another file\\nfirst.X = 88              # But changing it can be too subtle and implicit\\n\\nThe first defines a variable X, which the second prints and then changes by assignment.\\nNotice that we must import the first module into the second file to get to its variable\\nat all—as we’ve learned, each module is a self-contained namespace (package of vari-\\nables), and we must import one module to see inside it from another. That’s the main\\npoint  about  modules:  by  segregating  variables  on  a  per-file  basis,  they  avoid  name\\ncollisions across files, in much the same way that local variables avoid name clashes\\nacross functions.\\nReally, though, in terms of this chapter’s topic, the global scope of a module file be-\\ncomes the attribute namespace of the module object once it is imported—importers\\nautomatically have access to all of the file’s global variables, because a file’s global scope\\nmorphs into an object’s attribute namespace when it is imported.\\nAfter importing the first module, the second module prints its variable and then assigns\\nit a new value. Referencing the module’s variable to print it is fine—this is how modules\\nare linked together into a larger system normally. The problem with the assignment to\\nfirst.X, however, is that it is far too implicit: whoever’s charged with maintaining or\\nreusing the first module probably has no clue that some arbitrarily far-removed module\\non the import chain can change X out from under him or her at runtime. In fact, the\\n\\n2. Multithreading runs function calls in parallel with the rest of the program and is supported by Python’s\\nstandard library modules _thread, threading, and queue (thread, threading, and Queue in Python 2.X).\\nBecause all threaded functions run in the same process, global scopes often serve as one form of shared\\nmemory between them (threads may share both names in global scopes, as well as objects in a process’s\\nmemory space). Threading is commonly used for long-running tasks in GUIs, to implement nonblocking\\noperations in general and to maximize CPU capacity. It is also beyond this book’s scope; see the Python\\nlibrary  manual,  as  well  as  the  follow-up  texts  listed  in  the  preface  (such  as  O’Reilly’s  Programming\\nPython), for more details.\\n\\nThe global Statement\\n\\n| 497\\n\\n\\x0csecond module may be in a completely different directory, and so difficult to notice at\\nall.\\nAlthough such cross-file variable changes are always possible in Python, they are usually\\nmuch more subtle than you will want. Again, this sets up too strong a coupling between\\nthe  two  files—because  they  are  both  dependent  on  the  value  of  the  variable  X,  it’s\\ndifficult to understand or reuse one file without the other. Such implicit cross-file de-\\npendencies can lead to inflexible code at best, and outright bugs at worst.\\nHere again, the best prescription is generally to not do this—the best way to commu-\\nnicate across file boundaries is to call functions, passing in arguments and getting back\\nreturn values. In this specific case, we would probably be better off coding an accessor\\nfunction to manage the change:\\n\\n# first.py\\nX = 99\\n\\ndef setX(new):            # Accessor make external changes explit\\n    global X              # And can manage access in a single place\\n    X = new\\n\\n# second.py\\nimport first\\nfirst.setX(88)            # Call the function instead of changing directly\\n\\nThis requires more code and may seem like a trivial change, but it makes a huge dif-\\nference in terms of readability and maintainability—when a person reading the first\\nmodule by itself sees a function, that person will know that it is a point of interface and\\nwill expect the change to the X. In other words, it removes the element of surprise that\\nis  rarely  a  good  thing  in  software  projects.  Although  we  cannot  prevent  cross-file\\nchanges from happening, common sense dictates that they should be minimized unless\\nwidely accepted across the program.\\n\\nWhen we meet classes in Part VI, we’ll see similar techniques for coding\\nattribute accessors. Unlike modules, classes can also intercept attribute\\nfetches automatically with operator overloading, even when accessors\\naren’t used by their clients.\\n\\nOther Ways to Access Globals\\nInterestingly,  because  global-scope  variables  morph  into  the  attributes  of  a  loaded\\nmodule object, we can emulate the global statement by importing the enclosing module\\nand assigning to its attributes, as in the following example module file. Code in this file\\nimports the enclosing module, first by name, and then by indexing the sys.modules\\nloaded modules table (more on this table in Chapter 22 and Chapter 25):\\n\\n# thismod.py\\n\\nvar = 99                              # Global variable == module attribute\\n\\n498 | Chapter 17:\\u2002Scopes\\n\\n\\x0cdef local():\\n    var = 0                           # Change local var\\n\\ndef glob1():\\n    global var                        # Declare global (normal)\\n    var += 1                          # Change global var\\n\\ndef glob2():\\n    var = 0                           # Change local var\\n    import thismod                    # Import myself\\n    thismod.var += 1                  # Change global var\\n\\ndef glob3():\\n    var = 0                           # Change local var\\n    import sys                        # Import system table\\n    glob = sys.modules[\\'thismod\\']     # Get module object (or use __name__)\\n    glob.var += 1                     # Change global var\\n\\ndef test():\\n    print(var)\\n    local(); glob1(); glob2(); glob3()\\n    print(var)\\n\\nWhen run, this adds 3 to the global variable (only the first function does not impact it):\\n\\n>>> import thismod\\n>>> thismod.test()\\n99\\n102\\n>>> thismod.var\\n102\\n\\nThis works, and it illustrates the equivalence of globals to module attributes, but it’s\\nmuch more work than using the global statement to make your intentions explicit.\\nAs we’ve seen, global allows us to change names in a module outside a function. It has\\na close relative named nonlocal that can be used to change names in enclosing func-\\ntions, too—but to understand how that can be useful, we first need to explore enclosing\\nfunctions in general.\\n\\nScopes and Nested Functions\\nSo far, I’ve omitted one part of Python’s scope rules on purpose, because it’s relatively\\nuncommon to encounter it in practice. However, it’s time to take a deeper look at the\\nletter E in the LEGB lookup rule. The E layer was added in Python 2.2; it takes the form\\nof the local scopes of any and all enclosing function’s local scopes. Enclosing scopes\\nare sometimes also called statically nested scopes. Really, the nesting is a lexical one—\\nnested scopes correspond to physically and syntactically nested code structures in your\\nprogram’s source code text.\\n\\nScopes and Nested Functions\\n\\n| 499\\n\\n\\x0cNested Scope Details\\nWith the addition of nested function scopes, variable lookup rules become slightly more\\ncomplex. Within a function:\\n\\n• A reference (X) looks for the name X first in the current local scope (function); then\\nin the local scopes of any lexically enclosing functions in your source code, from\\ninner to outer; then in the current global scope (the module file); and finally in the\\nbuilt-in scope (the module builtins). global declarations make the search begin\\nin the global (module file) scope instead.\\n\\n• An assignment (X = value) creates or changes the name X in the current local\\nscope, by default. If X is declared global within the function, the assignment creates\\nor changes the name X in the enclosing module’s scope instead. If, on the other\\nhand,  X  is  declared  nonlocal  within  the  function  in  3.X  (only),  the  assignment\\nchanges the name X in the closest enclosing function’s local scope.\\n\\nNotice that the global declaration still maps variables to the enclosing module. When\\nnested functions are present, variables in enclosing functions may be referenced, but\\nthey require 3.X nonlocal declarations to be changed.\\n\\nNested Scope Examples\\nTo clarify the prior section’s points, let’s illustrate with some real code. Here is what\\nan enclosing function scope looks like (type this into a script file or at the interactive\\nprompt to run it live):\\n\\nX = 99                   # Global scope name: not used\\n\\ndef f1():\\n    X = 88               # Enclosing def local\\n    def f2():\\n        print(X)         # Reference made in nested def\\n    f2()\\n\\nf1()                     # Prints 88: enclosing def local\\n\\nFirst off, this is legal Python code: the def is simply an executable statement, which can\\nappear anywhere any other statement can—including nested in another def. Here, the\\nnested def runs while a call to the function f1 is running; it generates a function and\\nassigns it to the name f2, a local variable within f1’s local scope. In a sense, f2 is a\\ntemporary function that lives only during the execution of (and is visible only to code\\nin) the enclosing f1.\\nBut notice what happens inside f2: when it prints the variable X, it refers to the X that\\nlives in the enclosing f1 function’s local scope. Because functions can access names in\\nall physically enclosing def statements, the X in f2 is automatically mapped to the X in\\nf1, by the LEGB lookup rule.\\n\\n500 | Chapter 17:\\u2002Scopes\\n\\n\\x0cThis enclosing scope lookup works even if the enclosing function has already returned.\\nFor example, the following code defines a function that makes and returns another\\nfunction, and represents a more common usage pattern:\\n\\ndef f1():\\n    X = 88\\n    def f2():\\n        print(X)         # Remembers X in enclosing def scope\\n    return f2            # Return f2 but don\\'t call it\\n\\naction = f1()            # Make, return function\\naction()                 # Call it now: prints 88\\n\\nIn this code, the call to action is really running the function we named f2 when f1 ran.\\nThis works because functions are objects in Python like everything else, and can be\\npassed back as return values from other functions. Most importantly, f2 remembers\\nthe enclosing scope’s X in f1, even though f1 is no longer active—which leads us to the\\nnext topic.\\n\\nFactory Functions: Closures\\nDepending on whom you ask, this sort of behavior is also sometimes called a closure\\nor a factory function—the former describing a functional programming technique, and\\nthe latter denoting a design pattern. Whatever the label, the function object in question\\nremembers  values  in  enclosing  scopes  regardless  of  whether  those  scopes  are  still\\npresent in memory. In effect, they have attached packets of memory (a.k.a. state re-\\ntention), which are local to each copy of the nested function created, and often provide\\na simple alternative to classes in this role.\\n\\nA simple function factory\\nFactory functions (a.k.a. closures) are sometimes used by programs that need to gen-\\nerate  event  handlers  on  the  fly  in  response  to  conditions  at  runtime.  For  instance,\\nimagine a GUI that must define actions according to user inputs that cannot be antici-\\npated when the GUI is built. In such cases, we need a function that creates and returns\\nanother function, with information that may vary per function made.\\nTo illustrate this in simple terms, consider the following function, typed at the inter-\\nactive prompt (and shown here without the “...” continuation-line prompts, per the\\npresentation note ahead):\\n\\n>>> def maker(N):\\n        def action(X):                    # Make and return action\\n            return X ** N                 # action retains N from enclosing scope\\n        return action\\n\\nThis defines an outer function that simply generates and returns a nested function,\\nwithout calling it—maker makes action, but simply returns action without running it.\\nIf we call the outer function:\\n\\nScopes and Nested Functions\\n\\n| 501\\n\\n\\x0c>>> f = maker(2)                          # Pass 2 to argument N\\n>>> f\\n<function maker.<locals>.action at 0x0000000002A4A158>\\n\\nwhat we get back is a reference to the generated nested function—the one created when\\nthe nested def runs. If we now call what we got back from the outer function:\\n\\n>>> f(3)                                  # Pass 3 to X, N remembers 2: 3 ** 2\\n9\\n>>> f(4)                                  # 4 ** 2\\n16\\n\\nwe invoke the nested function—the one called action within maker. In other words,\\nwe’re calling the nested function that maker created and passed back.\\nPerhaps the most unusual part of this, though, is that the nested function remembers\\ninteger 2, the value of the variable N in maker, even though maker has returned and exited\\nby the time we call action. In effect, N from the enclosing local scope is retained as state\\ninformation attached to the generated action, which is why we get back its argument\\nsquared when it is later called.\\nJust as important, if we now call the outer function again, we get back a new nested\\nfunction with different state information attached. That is, we get the argument cubed\\ninstead of squared when calling the new function, but the original still squares as before:\\n\\n>>> g = maker(3)                          # g remembers 3, f remembers 2\\n>>> g(4)                                  # 4 ** 3\\n64\\n>>> f(4)                                  # 4 ** 2\\n16\\n\\nThis works because each call to a factory function like this gets its own set of state\\ninformation. In our case, the function we assign to name g remembers 3, and f remem-\\nbers 2, because each has its own state information retained by the variable N in maker.\\nThis is a somewhat advanced technique that you may not see very often in most code,\\nand may be popular among programmers with backgrounds in functional program-\\nming  languages.  On  the  other  hand,  enclosing  scopes  are  often  employed  by  the\\nlambda function-creation expressions we’ll expand on later in this chapter—because\\nthey  are  expressions,  they  are  almost  always  nested  within  a  def.  For  example,  a\\nlambda would serve in place of a def in our example:\\n\\n>>> def maker(N):\\n        return lambda X: X ** N           # lambda functions retain state too\\n\\n>>> h = maker(3)\\n>>> h(4)                                  # 4 ** 3 again\\n64\\n\\nFor a more tangible example of closures at work, see the upcoming sidebar “Why You\\nWill Care: Customizing open” on page 517. It uses similar techniques to store infor-\\nmation for later use in an enclosing scope.\\n\\n502 | Chapter 17:\\u2002Scopes\\n\\n\\x0cPresentation note: In this chapter, I’ve started listing interactive exam-\\nples without the “...” continuation-line prompts that may or may not\\nappear in your interface (they do at the shell, but not in IDLE). This\\nconvention will be followed from this point on to make larger code ex-\\namples a bit easier to cut and paste from an ebook or other. I’m assuming\\nthat by now you understand indentation rules and have had your fair\\nshare of typing Python code, and some functions and classes ahead may\\nbe too large for rote input.\\n\\nI’m  also  listing  more  and  more  code  alone  or  in  files,  and  switching\\nbetween these and interactive input arbitrarily; when you see a “>>>”\\nprompt, the code is typed interactively, and can generally be cut and\\npasted into your Python shell if you omit the “>>>” itself. If this fails,\\nyou can still run by pasting line by line, or editing in a file.\\n\\nClosures versus classes, round 1\\nTo some, classes, described in full in Part VI of this book, may seem better at state\\nretention like this, because they make their memory more explicit with attribute as-\\nsignments. Classes also directly support additional tools that closure functions do not,\\nsuch as customization by inheritance and operator overloading, and more naturally\\nimplement multiple behaviors in the form of methods. Because of such distinctions,\\nclasses may be better at implementing more complete objects.\\nStill, closure functions often provide a lighter-weight and viable alternative when re-\\ntaining state is the only goal. They provide for per-call localized storage for data required\\nby a single nested function. This is especially true when we add the 3.X nonlocal state-\\nment described ahead to allow enclosing scope state changes (in 2.X, enclosing scopes\\nare read-only, and so have more limited uses).\\nFrom a broader perspective, there are multiple ways for Python functions to retain state\\nbetween calls. Although the values of normal local variables go away when a function\\nreturns, values can be retained from call to call in global variables; in class instance\\nattributes; in the enclosing scope references we’ve met here; and in argument defaults\\nand function attributes. Some might include mutable default arguments to this list too\\n(though others may wish they didn’t).\\nWe’ll preview class-based alternatives and meet function attributes later in this chapter,\\nand get the full story on arguments and defaults in Chapter 18. To help us judge how\\ndefaults compete on state retention, though, the next section gives enough of an in-\\ntroduction to get us started.\\n\\nScopes and Nested Functions\\n\\n| 503\\n\\n\\x0cClosures can also be created when a class is nested in a def: the values\\nof the enclosing function’s local names are retained by references within\\nthe class, or one of its method functions. See Chapter 29 for more on\\nnested classes. As we’ll see in later examples (e.g., Chapter 39’s deco-\\nrators), the outer def in such code serves a similar role: it becomes a\\nclass factory, and provides state retention for the nested class.\\n\\nRetaining Enclosing Scope State with Defaults\\nIn early versions of Python (prior to 2.2), the sort of code in the prior section failed\\nbecause nested defs did not do anything about scopes—a reference to a variable within\\nf2 in the following would search only the local (f2), then global (the code outside f1),\\nand then built-in scopes. Because it skipped the scopes of enclosing functions, an error\\nwould result. To work around this, programmers typically used default argument val-\\nues to pass in and remember the objects in an enclosing scope:\\n\\ndef f1():\\n    x = 88\\n    def f2(x=x):                # Remember enclosing scope X with defaults\\n        print(x)\\n    f2()\\n\\nf1()                            # Prints 88\\n\\nThis coding style works in all Python releases, and you’ll still see this pattern in some\\nexisting Python code. In fact, it’s still required for loop variables, as we’ll see in a mo-\\nment, which is why it remains worth studying today. In short, the syntax arg=val in a\\ndef header means that the argument arg will default to the value val if no real value is\\npassed to arg in a call. This syntax is used here to explicitly assign enclosing scope state\\nto be retained.\\nSpecifically, in the modified f2 here, the x=x means that the argument x will default to\\nthe value of x in the enclosing scope—because the second x is evaluated before Python\\nsteps into the nested def, it still refers to the x in f1. In effect, the default argument\\nremembers what x was in f1: the object 88.\\nThat’s fairly complex, and it depends entirely on the timing of default value evaluations.\\nIn fact, the nested scope lookup rule was added to Python to make defaults unnecessary\\nfor this role—today, Python automatically remembers any values required in the en-\\nclosing scope for use in nested defs.\\nOf course, the best prescription for much code is simply to avoid nesting defs within\\ndefs, as it will make your programs much simpler—in the Pythonic view, flat is generally\\nbetter than nested. The following is an equivalent of the prior example that avoids\\nnesting altogether. Notice the forward reference in this code—it’s OK to call a function\\ndefined after the function that calls it, as long as the second def runs before the first\\nfunction is actually called. Code inside a def is never evaluated until the function is\\nactually called:\\n\\n504 | Chapter 17:\\u2002Scopes\\n\\n\\x0c>>> def f1():\\n        x = 88                  # Pass x along instead of nesting\\n        f2(x)                   # Forward reference OK\\n\\n>>> def f2(x):\\n        print(x)                # Flat is still often better than nested!\\n\\n>>> f1()\\n88\\n\\nIf you avoid nesting this way, you can almost forget about the nested scopes concept\\nin Python. On the other hand, the nested functions of closure (factory) functions are\\nfairly common in modern Python code, as are lambda functions—which almost natu-\\nrally appear nested in defs and often rely on the nested scopes layer, as the next section\\nexplains.\\n\\nNested scopes, defaults, and lambdas\\nAlthough they see increasing use in defs these days, you may be more likely to care\\nabout nested function scopes when you start coding or reading lambda expressions.\\nWe’ve met lambda briefly and won’t cover it in depth until Chapter 19, but in short, it’s\\nan expression that generates a new function to be called later, much like a def statement.\\nBecause it’s an expression, though, it can be used in places that def cannot, such as\\nwithin list and dictionary literals.\\nLike a def, a lambda expression also introduces a new local scope for the function it\\ncreates. Thanks to the enclosing scopes lookup layer, lambdas can see all the variables\\nthat live in the functions in which they are coded. Thus, the following code—a variation\\non  the  factory  we  saw  earlier—works,  but  only  because  the  nested  scope  rules  are\\napplied:\\n\\ndef func():\\n    x = 4\\n    action = (lambda n: x ** n)          # x remembered from enclosing def\\n    return action\\n\\nx = func()\\nprint(x(2))                              # Prints 16, 4 ** 2\\n\\nPrior to the introduction of nested function scopes, programmers used defaults to pass\\nvalues from an enclosing scope into lambdas, just as for defs. For instance, the following\\nworks on all Pythons:\\n\\ndef func():\\n    x = 4\\n    action = (lambda n, x=x: x ** n)     # Pass x in manually\\n    return action\\n\\nBecause lambdas are expressions, they naturally (and even normally) nest inside en-\\nclosing defs. Hence, they were perhaps the biggest initial beneficiaries of the addition\\n\\nScopes and Nested Functions\\n\\n| 505\\n\\n\\x0cof enclosing function scopes in the lookup rules; in most cases, it is no longer necessary\\nto pass values into lambdas with defaults.\\n\\nLoop variables may require defaults, not scopes\\nThere is one notable exception to the rule I just gave (and a reason why I’ve shown you\\nthe otherwise dated default argument technique we just saw): if a lambda or def defined\\nwithin a function is nested inside a loop, and the nested function references an enclosing\\nscope variable that is changed by that loop, all functions generated within the loop will\\nhave the same value—the value the referenced variable had in the last loop iteration.\\nIn such cases, you must still use defaults to save the variable’s current value instead.\\nThis may seem a fairly obscure case, but it can come up in practice more often than\\nyou may think, especially in code that generates callback handler functions for a num-\\nber of widgets in a GUI—for instance, handlers for button-clicks for all the buttons in\\na row. If these are created in a loop, you may need to be careful to save state with\\ndefaults, or all your buttons’ callbacks may wind up doing the same thing.\\nHere’s an illustration of this phenomenon reduced to simple code: the following at-\\ntempts to build up a list of functions that each remember the current variable i from\\nthe enclosing scope:\\n\\n>>> def makeActions():\\n        acts = []\\n        for i in range(5):                       # Tries to remember each i\\n            acts.append(lambda x: i ** x)        # But all remember same last i!\\n        return acts\\n\\n>>> acts = makeActions()\\n>>> acts[0]\\n<function makeActions.<locals>.<lambda> at 0x0000000002A4A400>\\n\\nThis doesn’t quite work, though—because the enclosing scope variable is looked up\\nwhen the nested functions are later called, they all effectively remember the same value:\\nthe value the loop variable had on the last loop iteration. That is, when we pass a power\\nargument of 2 in each of the following calls, we get back 4 to the power of 2 for each\\nfunction in the list, because i is the same in all of them—4:\\n\\n>>> acts[0](2)                                   # All are 4 ** 2, 4=value of last i\\n16\\n>>> acts[1](2)                                   # This should be 1 ** 2 (1)\\n16\\n>>> acts[2](2)                                   # This should be 2 ** 2 (4)\\n16\\n>>> acts[4](2)                                   # Only this should be 4 ** 2 (16)\\n16\\n\\nThis is the one case where we still have to explicitly retain enclosing scope values with\\ndefault arguments, rather than enclosing scope references. That is, to make this sort of\\ncode work, we must pass in the current value of the enclosing scope’s variable with a\\n\\n506 | Chapter 17:\\u2002Scopes\\n\\n\\x0cdefault. Because defaults are evaluated when the nested function is created (not when\\nit’s later called), each remembers its own value for i:\\n\\n>>> def makeActions():\\n        acts = []\\n        for i in range(5):                       # Use defaults instead\\n            acts.append(lambda x, i=i: i ** x)   # Remember current i\\n        return acts\\n\\n>>> acts = makeActions()\\n>>> acts[0](2)                                   # 0 ** 2\\n0\\n>>> acts[1](2)                                   # 1 ** 2\\n1\\n>>> acts[2](2)                                   # 2 ** 2\\n4\\n>>> acts[4](2)                                   # 4 ** 2\\n16\\n\\nThis seems an implementation artifact that is prone to change, and may become more\\nimportant  as  you  start  writing  larger  programs.  We’ll  talk  more  about  defaults  in\\nChapter 18 and lambdas in Chapter 19, so you may also want to return and review this\\nsection later.3\\n\\nArbitrary scope nesting\\nBefore ending this discussion, we should note that scopes may nest arbitrarily, but only\\nenclosing function def statements (not classes, described in Part VI) are searched when\\nnames are referenced:\\n\\n>>> def f1():\\n        x = 99\\n        def f2():\\n            def f3():\\n                print(x)        # Found in f1\\'s local scope!\\n            f3()\\n        f2()\\n\\n>>> f1()\\n99\\n\\nPython will search the local scopes of all enclosing defs, from inner to outer, after the\\nreferencing function’s local scope and before the module’s global scope or built-ins.\\nHowever, this sort of code is even less likely to pop up in practice. Again, in Python,\\nwe say flat is better than nested, and this still holds generally true even with the addition\\n\\n3. In the section “Function Gotchas” on page 656, we’ll also see that there is a similar issue with using\\nmutable objects like lists and dictionaries for default arguments (e.g., def f(a=[]))—because defaults are\\nimplemented as single objects attached to functions, mutable defaults retain state from call to call, rather\\nthen being initialized anew on each call. Depending on whom you ask, this is either considered a feature\\nthat supports another way to implement state retention, or a strange corner of the language; more on this\\nat the end of Chapter 21.\\n\\nScopes and Nested Functions\\n\\n| 507\\n\\n\\x0cof nested scope closures. Except in limited contexts, your life (and the lives of your\\ncoworkers) will generally be better if you minimize nested function definitions.\\n\\nThe nonlocal Statement in 3.X\\nIn the prior section we explored the way that nested functions can reference variables\\nin an enclosing function’s scope, even if that function has already returned. It turns out\\nthat, in Python 3.X (though not in 2.X), we can also change such enclosing scope vari-\\nables, as long as we declare them in nonlocal statements. With this statement, nested\\ndefs can have both read and write access to names in enclosing functions. This makes\\nnested scope closures more useful, by providing changeable state information.\\nThe nonlocal statement is similar in both form and role to global, covered earlier. Like\\nglobal, nonlocal declares that a name will be changed in an enclosing scope. Unlike\\nglobal, though, nonlocal applies to a name in an enclosing function’s scope, not the\\nglobal module scope outside all defs. Also unlike global, nonlocal names must already\\nexist in the enclosing function’s scope when declared—they can exist only in enclosing\\nfunctions and cannot be created by a first assignment in a nested def.\\nIn other words, nonlocal both allows assignment to names in enclosing function scopes\\nand limits scope lookups for such names to enclosing defs. The net effect is a more\\ndirect and reliable implementation of changeable state information, for contexts that\\ndo not desire or need classes with attributes, inheritance, and multiple behaviors.\\n\\nnonlocal Basics\\nPython 3.X introduces a new nonlocal statement, which has meaning only inside a\\nfunction:\\n\\ndef func():\\n    nonlocal name1, name2, ...            # OK here\\n\\n>>> nonlocal X\\nSyntaxError: nonlocal declaration not allowed at module level\\n\\nThis statement allows a nested function to change one or more names defined in a\\nsyntactically enclosing function’s scope. In Python 2.X, when one function def is nested\\nin another, the nested function can reference any of the names defined by assignment\\nin the enclosing def’s scope, but it cannot change them. In 3.X, declaring the enclosing\\nscopes’ names in a  nonlocal statement enables nested functions to assign and thus\\nchange such names as well.\\nThis provides a way for enclosing functions to provide writeable state information,\\nremembered  when  the  nested  function  is  later  called.  Allowing  the  state  to  change\\nmakes it more useful to the nested function (imagine a counter in the enclosing scope,\\nfor instance). In 2.X, programmers usually achieve similar goals by using classes or\\n\\n508 | Chapter 17:\\u2002Scopes\\n\\n\\x0cother schemes. Because nested functions have become a more common coding pattern\\nfor state retention, though, nonlocal makes it more generally applicable.\\nBesides allowing names in enclosing defs to be changed, the nonlocal statement also\\nforces  the  issue  for  references—much  like  the  global  statement,  nonlocal  causes\\nsearches for the names listed in the statement to begin in the enclosing defs’ scopes,\\nnot in the local scope of the declaring function. That is, nonlocal also means “skip my\\nlocal scope entirely.”\\nIn fact, the names listed in a nonlocal must have been previously defined in an enclosing\\ndef when the nonlocal is reached, or an error is raised. The net effect is much like global:\\nglobal means the names reside in the enclosing module, and nonlocal means they reside\\nin an enclosing def. nonlocal is even more strict, though—scope search is restricted to\\nonly enclosing defs. That is, nonlocal names can appear only in enclosing defs, not in\\nthe module’s global scope or built-in scopes outside the defs.\\nThe addition of nonlocal does not alter name reference scope rules in general; they still\\nwork as before, per the “LEGB” rule described earlier. The nonlocal statement mostly\\nserves to allow names in enclosing scopes to be changed rather than just referenced.\\nHowever, both  global and  nonlocal statements do tighten up and even restrict the\\nlookup rules somewhat, when coded in a function:\\n\\n• global  makes  scope  lookup  begin  in  the  enclosing  module’s  scope  and  allows\\nnames there to be assigned. Scope lookup continues on to the built-in scope if the\\nname does not exist in the module, but assignments to global names always create\\nor change them in the module’s scope.\\n\\n• nonlocal restricts scope lookup to just enclosing defs, requires that the names al-\\nready exist there, and allows them to be assigned. Scope lookup does not continue\\non to the global or built-in scopes.\\n\\nIn Python 2.X, references to enclosing def scope names are allowed, but not assignment.\\nHowever, you can still use classes with explicit attributes to achieve the same change-\\nable state information effect as nonlocals (and you may be better off doing so in some\\ncontexts); globals and function attributes can sometimes accomplish similar goals as\\nwell. More on this in a moment; first, let’s turn to some working code to make this\\nmore concrete.\\n\\nnonlocal in Action\\nOn to some examples, all run in 3.X. References to enclosing def scopes work in 3X as\\nthey do in 2.X—in the following, tester builds and returns the function nested, to be\\ncalled later, and the state reference in nested maps the local scope of tester using the\\nnormal scope lookup rules:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n\\n>>> def tester(start):\\n\\nThe nonlocal Statement in 3.X | 509\\n\\n\\x0c        state = start             # Referencing nonlocals works normally\\n        def nested(label):\\n            print(label, state)   # Remembers state in enclosing scope\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'spam\\')\\nspam 0\\n>>> F(\\'ham\\')\\nham 0\\n\\nChanging a name in an enclosing def’s scope is not allowed by default, though; this is\\nthe normal case in 2.X as well:\\n\\n>>> def tester(start):\\n        state = start\\n        def nested(label):\\n            print(label, state)\\n            state += 1            # Cannot change by default (never in 2.X)\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'spam\\')\\nUnboundLocalError: local variable \\'state\\' referenced before assignment\\n\\nUsing nonlocal for changes\\nNow, under 3.X, if we declare state in the tester scope as nonlocal within nested, we\\nget to change it inside the nested function, too. This works even though tester has\\nreturned and exited by the time we call the returned nested function through the name\\nF:\\n\\n>>> def tester(start):\\n        state = start             # Each call gets its own state\\n        def nested(label):\\n            nonlocal state        # Remembers state in enclosing scope\\n            print(label, state)\\n            state += 1            # Allowed to change it if nonlocal\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'spam\\')                     # Increments state on each call\\nspam 0\\n>>> F(\\'ham\\')\\nham 1\\n>>> F(\\'eggs\\')\\neggs 2\\n\\nAs usual with enclosing scope references, we can call the tester factory (closure) func-\\ntion multiple times to get multiple copies of its state in memory. The state object in\\nthe enclosing scope is essentially attached to the nested function object returned; each\\ncall makes a new, distinct state object, such that updating one function’s state won’t\\nimpact the other. The following continues the prior listing’s interaction:\\n\\n510 | Chapter 17:\\u2002Scopes\\n\\n\\x0c>>> G = tester(42)                # Make a new tester that starts at 42\\n>>> G(\\'spam\\')\\nspam 42\\n\\n>>> G(\\'eggs\\')                     # My state information updated to 43\\neggs 43\\n\\n>>> F(\\'bacon\\')                    # But F\\'s is where it left off: at 3\\nbacon 3                           # Each call has different state information\\n\\nIn this sense, Python’s nonlocals are more functional than function locals typical in\\nsome other languages: in a closure function, nonlocals are per-call, multiple copy data.\\n\\nBoundary cases\\nThough useful, nonlocals come with some subtleties to be aware of. First, unlike the\\nglobal statement, nonlocal names really must have previously been assigned in an en-\\nclosing def’s scope when a nonlocal is evaluated, or else you’ll get an error—you cannot\\ncreate them dynamically by assigning them anew in the enclosing scope. In fact, they\\nare checked at function definition time before either an enclosing or nested function is\\ncalled:\\n\\n>>> def tester(start):\\n        def nested(label):\\n            nonlocal state        # Nonlocals must already exist in enclosing def!\\n            state = 0\\n            print(label, state)\\n        return nested\\n\\nSyntaxError: no binding for nonlocal \\'state\\' found\\n\\n>>> def tester(start):\\n        def nested(label):\\n            global state          # Globals don\\'t have to exist yet when declared\\n            state = 0             # This creates the name in the module now\\n            print(label, state)\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'abc\\')\\nabc 0\\n>>> state\\n0\\n\\nSecond, nonlocal restricts the scope lookup to just enclosing defs; nonlocals are not\\nlooked  up  in  the  enclosing  module’s  global  scope  or  the  built-in  scope  outside  all\\ndefs, even if they are already there:\\n\\n>>> spam = 99\\n>>> def tester():\\n        def nested():\\n            nonlocal spam         # Must be in a def, not the module!\\n            print(\\'Current=\\', spam)\\n            spam += 1\\n\\nThe nonlocal Statement in 3.X | 511\\n\\n\\x0c        return nested\\n\\nSyntaxError: no binding for nonlocal \\'spam\\' found\\n\\nThese restrictions make sense once you realize that Python would not otherwise gen-\\nerally know which enclosing scope to create a brand-new name in. In the prior listing,\\nshould spam be assigned in tester, or the module outside? Because this is ambiguous,\\nPython must resolve nonlocals at function creation time, not function call time.\\n\\nWhy nonlocal? State Retention Options\\nGiven the extra complexity of nested functions, you might wonder what the fuss is\\nabout. Although it’s difficult to see in our small examples, state information becomes\\ncrucial in many programs. While functions can return results, their local variables won’t\\nnormally retain other values that must live on between calls. Moreover, many appli-\\ncations require such values to differ per context of use.\\nAs mentioned earlier, there are a variety of ways to “remember” information across\\nfunction and method calls in Python. While there are tradeoffs for all, nonlocal does\\nimprove this story for enclosing scope references—the nonlocal statement allows mul-\\ntiple copies of changeable state to be retained in memory. It addresses simple state-\\nretention needs where classes may not be warranted and global variables do not apply,\\nthough function attributes can often serve similar roles more portably. Let’s review the\\noptions to see how they stack up.\\n\\nState with nonlocal: 3.X only\\nAs  we  saw  in  the  prior  section,  the  following  code  allows  state  to  be  retained  and\\nmodified in an enclosing scope. Each call to tester creates a self-contained package of\\nchangeable information, whose names do not clash with any other part of the program:\\n\\n>>> def tester(start):\\n        state = start                  # Each call gets its own state\\n        def nested(label):\\n            nonlocal state             # Remembers state in enclosing scope\\n            print(label, state)\\n            state += 1                 # Allowed to change it if nonlocal\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'spam\\')                          # State visible within closure only\\nspam 0\\n>>> F.state\\nAttributeError: \\'function\\' object has no attribute \\'state\\'\\n\\nWe need to declare variables nonlocal only if they must be changed (other enclosing\\nscope name references are automatically retained as usual), and nonlocal names are\\nstill not visible outside the enclosing function.\\n\\n512 | Chapter 17:\\u2002Scopes\\n\\n\\x0cUnfortunately, this code works in Python 3.X only. If you are using Python 2.X, other\\noptions are available, depending on your goals. The next three sections present some\\nalternatives. Some of the code in these sections uses tools we haven’t covered yet and\\nis intended partially as preview, but we’ll keep the examples simple here so that you\\ncan compare and contrast along the way.\\n\\nState with Globals: A Single Copy Only\\nOne common prescription for achieving the  nonlocal effect in 2.X and earlier is to\\nsimply move the state out to the global scope (the enclosing module):\\n\\n>>> def tester(start):\\n        global state                   # Move it out to the module to change it\\n        state = start                  # global allows changes in module scope\\n        def nested(label):\\n            global state\\n            print(label, state)\\n            state += 1\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'spam\\')                          # Each call increments shared global state\\nspam 0\\n>>> F(\\'eggs\\')\\neggs 1\\n\\nThis works in this case, but it requires global declarations in both functions and is\\nprone to name collisions in the global scope (what if “state” is already being used?). A\\nworse, and more subtle, problem is that it only allows for a single shared copy of the\\nstate information in the module scope—if we call tester again, we’ll wind up resetting\\nthe module’s state variable, such that prior calls will see their state overwritten:\\n\\n>>> G = tester(42)                     # Resets state\\'s single copy in global scope\\n>>> G(\\'toast\\')\\ntoast 42\\n\\n>>> G(\\'bacon\\')\\nbacon 43\\n\\n>>> F(\\'ham\\')                           # But my counter has been overwritten!\\nham 44\\n\\nAs shown earlier, when you are using nonlocal and nested function closures instead of\\nglobal, each call to tester remembers its own unique copy of the state object.\\n\\nState with Classes: Explicit Attributes (Preview)\\nThe other prescription for changeable state information in 2.X and earlier is to use\\nclasses with attributes to make state information access more explicit than the implicit\\nmagic of scope lookup rules. As an added benefit, each instance of a class gets a fresh\\n\\nWhy nonlocal? State Retention Options\\n\\n| 513\\n\\n\\x0ccopy of the state information, as a natural byproduct of Python’s object model. Classes\\nalso support inheritance, multiple behaviors, and other tools.\\nWe haven’t explored classes in detail yet, but as a brief preview for comparison, the\\nfollowing is a reformulation of the earlier tester/nested functions as a class, which\\nrecords state in objects explicitly as they are created. To make sense of this code, you\\nneed to know that a def within a class like this works exactly like a normal def, except\\nthat the function’s self argument automatically receives the implied subject of the call\\n(an instance object created by calling the class itself). The function named __init__ is\\nrun automatically when the class is called:\\n\\n>>> class tester:                          # Class-based alternative (see Part VI)\\n        def __init__(self, start):         # On object construction,\\n            self.state = start             # save state explicitly in new object\\n        def nested(self, label):\\n            print(label, self.state)       # Reference state explicitly\\n            self.state += 1                # Changes are always allowed\\n\\n>>> F = tester(0)                          # Create instance, invoke __init__\\n>>> F.nested(\\'spam\\')                       # F is passed to self\\nspam 0\\n>>> F.nested(\\'ham\\')\\nham 1\\n\\nIn classes, we save every attribute explicitly, whether it’s changed or just referenced,\\nand they are available outside the class. As for nested functions and nonlocal, the class\\nalternative supports multiple copies of the retained data:\\n\\n>>> G = tester(42)                         # Each instance gets new copy of state\\n>>> G.nested(\\'toast\\')                      # Changing one does not impact others\\ntoast 42\\n>>> G.nested(\\'bacon\\')\\nbacon 43\\n\\n>>> F.nested(\\'eggs\\')                       # F\\'s state is where it left off\\neggs 2\\n>>> F.state                                # State may be accessed outside class\\n3\\n\\nWith just slightly more magic—which we’ll delve into later in this book—we could\\nalso make our class objects look like callable functions using operator overloading.\\n__call__ intercepts direct calls on an instance, so we don’t need to call a named method:\\n\\n>>> class tester:\\n        def __init__(self, start):\\n            self.state = start\\n        def __call__(self, label):         # Intercept direct instance calls\\n            print(label, self.state)       # So .nested() not required\\n            self.state += 1\\n\\n>>> H = tester(99)\\n>>> H(\\'juice\\')                             # Invokes __call__\\njuice 99\\n\\n514 | Chapter 17:\\u2002Scopes\\n\\n\\x0c>>> H(\\'pancakes\\')\\npancakes 100\\n\\nDon’t sweat the details in this code too much at this point in the book; it’s mostly a\\npreview, intended for general comparison to closures only. We’ll explore classes in\\ndepth in Part VI, and will look at specific operator overloading tools like __call__ in\\nChapter 30. The point to notice here is that classes can make state information more\\nobvious, by leveraging explicit attribute assignment instead of implicit scope lookups.\\nIn addition, class attributes are always changeable and don’t require a nonlocal state-\\nment, and classes are designed to scale up to implementing richer objects with many\\nattributes and behaviors.\\nWhile using classes for state information is generally a good rule of thumb to follow,\\nthey might also be overkill in cases like this, where state is a single counter. Such trivial\\nstate cases are more common than you might think; in such contexts, nested defs are\\nsometimes more lightweight than coding classes, especially if you’re not familiar with\\nOOP yet. Moreover, there are some scenarios in which nested defs may actually work\\nbetter  than  classes—stay  tuned  for  the  description  of  method  decorators  in  Chap-\\nter 39 for an example that is far beyond this chapter’s already well-stretched scope!\\n\\nState with Function Attributes: 3.X and 2.X\\nAs a portable and often simpler state-retention option, we can also sometimes achieve\\nthe same effect as nonlocals with function attributes—user-defined names attached to\\nfunctions directly. When you attach user-defined attributes to nested functions gener-\\nated by enclosing factory functions, they can also serve as per-call, multiple copy, and\\nwriteable state, just like nonlocal scope closures and class attributes. Such user-defined\\nattribute names won’t clash with names Python creates itself, and as for nonlocal, need\\nbe used only for state variables that must be changed; other scope references are retained\\nand work normally.\\nCrucially, this scheme is portable—like classes, but unlike nonlocal, function attributes\\nwork in both Python 3.X and 2.X. In fact, they’ve been available since 2.1, much longer\\nthan 3.X’s nonlocal. Because factory functions make a new function on each call any-\\nhow, this does not require extra objects—the new function’s attributes become per-\\ncall state in much the same way as nonlocals, and are similarly associated with the\\ngenerated function in memory.\\nMoreover, function attributes allow state variables to be accessed outside the nested\\nfunction, like class attributes; with nonlocal, state variables can be seen directly only\\nwithin the nested def. If you need to access a call counter externally, it’s a simple func-\\ntion attribute fetch in this model.\\nHere’s a final version of our example based on this technique—it replaces a nonlocal\\nwith an attribute attached to the nested function. This scheme may not seem as intuitive\\nto some at first glance; you access state though the function’s name instead of as simple\\n\\nWhy nonlocal? State Retention Options\\n\\n| 515\\n\\n\\x0cvariables, and must initialize after the nested def. Still, it’s far more portable, allows\\nstate to be accessed externally, and saves a line by not requiring a nonlocal declaration:\\n\\n>>> def tester(start):\\n        def nested(label):\\n            print(label, nested.state)     # nested is in enclosing scope\\n            nested.state += 1              # Change attr, not nested itself\\n        nested.state = start               # Initial state after func defined\\n        return nested\\n\\n>>> F = tester(0)\\n>>> F(\\'spam\\')                              # F is a \\'nested\\' with state attached\\nspam 0\\n>>> F(\\'ham\\')\\nham 1\\n>>> F.state                                # Can access state outside functions too\\n2\\n\\nBecause each call to the outer function produces a new nested function object, this\\nscheme supports multiple copy per-call changeable data just like nonlocal closures and\\nclasses—a usage mode that global variables cannot provide:\\n\\n>>> G = tester(42)                         # G has own state, doesn\\'t overwrite F\\'s\\n>>> G(\\'eggs\\')\\neggs 42\\n>>> F(\\'ham\\')\\nham 2\\n\\n>>> F.state                                # State is accessible and per-call\\n3\\n>>> G.state\\n43\\n>>> F is G                                 # Different function objects\\nFalse\\n\\nThis code relies on the fact that the function name nested is a local variable in the\\ntester scope enclosing nested; as such, it can be referenced freely inside nested. This\\ncode also relies on the fact that changing an object in place is not an assignment to a\\nname; when it increments nested.state, it is changing part of the object nested refer-\\nences, not the name  nested itself. Because we’re not really assigning a name in the\\nenclosing scope, no nonlocal declaration is required.\\nFunction  attributes  are  supported  in  both  Python  3.X  and  2.X;  we’ll  explore  them\\nfurther in Chapter 19. Importantly, we’ll see there that Python uses naming conventions\\nin both 2.X and 3.X that ensure that the arbitrary names you assign as function at-\\ntributes won’t clash with names related to internal implementation, making the name-\\nspace equivalent to a scope. Subjective factors aside, function attributes’ utility does\\noverlap with the newer nonlocal in 3.X, making the latter technically redundant and\\nfar less portable.\\n\\n516 | Chapter 17:\\u2002Scopes\\n\\n\\x0cState with mutables: Obscure ghost of Pythons past?\\nOn a related note, it’s also possible to change a mutable object in the enclosing scope\\nin 2.X and 3.X without declaring its name nonlocal. The following, for example, works\\nthe same as the previous version, is just as portable, and provides changeable per-call\\nstate:\\n\\ndef tester(start):\\n    def nested(label):\\n        print(label, state[0])             # Leverage in-place mutable change\\n        state[0] += 1                      # Extra syntax, deep magic?\\n    state = [start]\\n    return nested\\n\\nThis leverages the mutability of lists, and like function attributes, relies on the fact that\\nin-place object changes do not classify a name as local. This is perhaps more obscure\\nthan either function attributes or 3.X’s nonlocal, though—a technique that predates\\neven function attributes, and seems to lie today somewhere on the spectrum from clever\\nhack to dark magic! You’re probably better off using named function attributes than\\nlists and numeric offsets this way, though this may show up in code you must use.\\nTo summarize: globals, nonlocals, classes, and function attributes all offer changeable\\nstate-retention options. Globals support only single-copy shared data; nonlocals can\\nbe changed in 3.X only; classes require a basic knowledge of OOP; and both classes\\nand function attributes provide portable solutions that allow state to be accessed di-\\nrectly from outside the stateful callable object itself. As usual, the best tool for your\\nprogram depends upon your program’s goals.\\nWe’ll revisit all the state options introduced here in Chapter 39 in a more realistic\\ncontext—decorators, a tool that by nature involves multilevel state retention. State\\noptions have additional selection factors (e.g., performance), which we’ll have to leave\\nunexplored here for space (we’ll learn how to time code speed in Chapter 21). For now,\\nit’s time to move on to explore argument passing modes.\\n\\nWhy You Will Care: Customizing open\\n\\nFor another example of closures at work, consider changing the built-in open call to a\\ncustom version, as suggested in this chapter’s earlier sidebar “Breaking the Universe in\\nPython 2.X” on page 494 If the custom version needs to call the original, it must save\\nit  before  changing  it,  and  retain  it  for  later  use—a  classic  state  retention  scenario.\\nMoreover, if we wish to support multiple customizations to the same function, globals\\nwon’t do: we need per-customizer state.\\n\\nThe following, coded for Python 3.X in file makeopen.py, is one way to achieve this (in\\n2.X, change the built-in scope name and prints). It uses a nested scope closure to re-\\nmember a value for later use, without relying on global variables—which can clash and\\nallow just one value, and without using a class—that may require more code than is\\nwarranted here:\\n\\nimport builtins\\n\\nWhy nonlocal? State Retention Options\\n\\n| 517\\n\\n\\x0cdef makeopen(id):\\n    original = builtins.open\\n    def custom(*kargs, **pargs):\\n        print(\\'Custom open call %r:\\' % id , kargs, pargs)\\n        return original(*kargs, **pargs)\\n    builtins.open = custom\\n\\nTo change open for every module in a process, this code reassigns it in the built-in scope\\nto a custom version coded with a nested def, after it saving the original in the enclosing\\nscope so the customization can call it later. This code is also partially preview, as it\\nrelies on starred-argument forms to collect and later unpack arbitrary positional and\\nkeyword arguments meant for open—a topic coming up in the next chapter. Much of\\nthe magic here, though, is nested scope closures: the custom open found by the scope\\nlookup rules retains the original for later use:\\n\\n>>> F = open(\\'script2.py\\')           # Call built-in open in builtins\\n>>> F.read()\\n\\'import sys\\\\nprint(sys.path)\\\\nx = 2\\\\nprint(x ** 32)\\\\n\\'\\n\\n>>> from makeopen import makeopen    # Import open resetter function\\n>>> makeopen(\\'spam\\')                 # Custom open calls built-in open\\n\\n>>> F = open(\\'script2.py\\')           # Call custom open in builtins\\nCustom open call \\'spam\\': (\\'script2.py\\',) {}\\n>>> F.read()\\n\\'import sys\\\\nprint(sys.path)\\\\nx = 2\\\\nprint(x ** 32)\\\\n\\'\\n\\nBecause each customization remembers the former built-in scope version in its own\\nenclosing scope, they can even be nested naturally in ways that global variables cannot\\nsupport—each call to the makeopen closure function remembers its own versions of id\\nand original, so multiple customizations may be run:\\n\\n>>> makeopen(\\'eggs\\')                 # Nested customizers work too!\\n>>> F = open(\\'script2.py\\')           # Because each retains own state\\nCustom open call \\'eggs\\': (\\'script2.py\\',) {}\\nCustom open call \\'spam\\': (\\'script2.py\\',) {}\\n>>> F.read()\\n\\'import sys\\\\nprint(sys.path)\\\\nx = 2\\\\nprint(x ** 32)\\\\n\\'\\n\\nAs is, our function simply adds possibly nested call tracing to a built-in function, but\\nthe general technique may have other applications. A class-based equivalent to this may\\nrequire more code because it would need to save the id and original values explicitly\\nin object attributes—but requires more background knowledge than we yet have, so\\nconsider this a Part VI preview only:\\n\\nimport builtins\\n\\nclass makeopen:                # See Part VI: call catches self()\\n    def __init__(self, id):\\n        self.id = id\\n        self.original = builtins.open\\n        builtins.open = self\\n    def __call__(self, *kargs, **pargs):\\n        print(\\'Custom open call %r:\\' % self.id, kargs, pargs)\\n        return self.original(*kargs, **pargs)\\n\\n518 | Chapter 17:\\u2002Scopes\\n\\n\\x0cThe point to notice here is that classes may be more explicit but also may take extra\\ncode when state retention is the only goal. We’ll see additional closure use cases later,\\nespecially when exploring decorators in Chapter 39, where we’ll find the closures are\\nactually preferred to classes in certain roles.\\n\\nChapter Summary\\nIn this chapter, we studied one of two key concepts related to functions: scopes, which\\ndetermine how variables are looked up when used. As we learned, variables are con-\\nsidered local to the function definitions in which they are assigned, unless they are\\nspecifically declared to be global or nonlocal. We also explored some more advanced\\nscope concepts here, including nested function scopes and function attributes. Finally,\\nwe looked at some general design ideas, such as the need to avoid globals and cross-\\nfile changes.\\nIn the next chapter, we’re going to continue our function tour with the second key\\nfunction-related concept: argument passing. As we’ll find, arguments are passed into\\na function by assignment, but Python also provides tools that allow functions to be\\nflexible in how items are passed. Before we move on, let’s take this chapter’s quiz to\\nreview the scope concepts we’ve covered here.\\n\\nTest Your Knowledge: Quiz\\n1. What is the output of the following code, and why?\\n\\n>>> X = \\'Spam\\'\\n>>> def func():\\n        print(X)\\n\\n>>> func()\\n\\n2. What is the output of this code, and why?\\n\\n>>> X = \\'Spam\\'\\n>>> def func():\\n        X = \\'NI!\\'\\n\\n>>> func()\\n>>> print(X)\\n\\n3. What does this code print, and why?\\n\\n>>> X = \\'Spam\\'\\n>>> def func():\\n        X = \\'NI\\'\\n        print(X)\\n\\n>>> func()\\n>>> print(X)\\n\\nTest Your Knowledge: Quiz | 519\\n\\n\\x0c4. What output does this code produce? Why?\\n\\n>>> X = \\'Spam\\'\\n>>> def func():\\n        global X\\n        X = \\'NI\\'\\n\\n>>> func()\\n>>> print(X)\\n\\n5. What about this code—what’s the output, and why?\\n\\n>>> X = \\'Spam\\'\\n>>> def func():\\n        X = \\'NI\\'\\n        def nested():\\n            print(X)\\n        nested()\\n\\n>>> func()\\n>>> X\\n\\n6. How about this example: what is its output in Python 3.X, and why?\\n\\n>>> def func():\\n        X = \\'NI\\'\\n        def nested():\\n            nonlocal X\\n            X = \\'Spam\\'\\n        nested()\\n        print(X)\\n\\n>>> func()\\n\\n7. Name three or more ways to retain state information in a Python function.\\n\\nTest Your Knowledge: Answers\\n1. The output here is \\'Spam\\', because the function references a global variable in the\\nenclosing module (because it is not assigned in the function, it is considered global).\\n2. The output here is \\'Spam\\' again because assigning the variable inside the function\\nmakes it a local and effectively hides the global of the same name. The print state-\\nment finds the variable unchanged in the global (module) scope.\\n\\n3. It prints \\'NI\\' on one line and \\'Spam\\' on another, because the reference to the vari-\\nable within the function finds the assigned local and the reference in the  print\\nstatement finds the global.\\n\\n4. This time it just prints \\'NI\\' because the global declaration forces the variable as-\\n\\nsigned inside the function to refer to the variable in the enclosing global scope.\\n\\n5. The output in this case is again \\'NI\\' on one line and \\'Spam\\' on another, because\\nthe print statement in the nested function finds the name in the enclosing func-\\ntion’s local scope, and the print at the end finds the variable in the global scope.\\n\\n520 | Chapter 17:\\u2002Scopes\\n\\n\\x0c6. This example prints \\'Spam\\', because the nonlocal statement (available in Python\\n3.X but not 2.X) means that the assignment to X inside the nested function changes\\nX in the enclosing function’s local scope. Without this statement, this assignment\\nwould classify X as local to the nested function, making it a different variable; the\\ncode would then print \\'NI\\' instead.\\n\\n7. Although the values of local variables go away when a function returns, you can\\nmake a Python function retain state information by using shared global variables,\\nenclosing function scope references within nested functions, or using default ar-\\ngument values. Function attributes can sometimes allow state to be attached to the\\nfunction itself, instead of looked up in scopes. Another alternative, using classes\\nand OOP, sometimes supports state retention better than any of the scope-based\\ntechniques because it makes it explicit with attribute assignments; we’ll explore\\nthis option in Part VI.\\n\\nTest Your Knowledge: Answers\\n\\n| 521\\n\\n\\x0c\\x0cCHAPTER 18\\nArguments\\n\\nChapter 17 explored the details behind Python’s scopes—the places where variables\\nare defined and looked up. As we learned, the place where a name is defined in our\\ncode determines much of its meaning. This chapter continues the function story by\\nstudying the concepts in Python argument passing—the way that objects are sent to\\nfunctions as inputs. As we’ll see, arguments (a.k.a. parameters) are assigned to names\\nin a function, but they have more to do with object references than with variable scopes.\\nWe’ll also find that Python provides extra tools, such as keywords, defaults, and arbi-\\ntrary argument collectors and extractors that allow for wide flexibility in the way ar-\\nguments are sent to a function, and we’ll put them to work in examples.\\n\\nArgument-Passing Basics\\nEarlier in this part of the book, I noted that arguments are passed by assignment. This\\nhas a few ramifications that aren’t always obvious to newcomers, which I’ll expand on\\nin this section. Here is a rundown of the key points in passing arguments to functions:\\n\\n• Arguments are passed by automatically assigning objects to local variable\\nnames. Function arguments—references to (possibly) shared objects sent by the\\ncaller—are just another instance of Python assignment at work. Because references\\nare implemented as pointers, all arguments are, in effect, passed by pointer. Objects\\npassed as arguments are never automatically copied.\\n\\n• Assigning to argument names inside a function does not affect the caller.\\nArgument names in the function header become new, local names when the func-\\ntion runs, in the scope of the function. There is no aliasing between function ar-\\ngument names and variable names in the scope of the caller.\\n\\n• Changing a mutable object argument in a function may impact the caller.\\nOn the other hand, as arguments are simply assigned to passed-in objects, func-\\ntions can change passed-in mutable objects in place, and the results may affect the\\ncaller. Mutable arguments can be input and output for functions.\\n\\n523\\n\\n\\x0cFor more details on references, see Chapter 6; everything we learned there also applies\\nto function arguments, though the assignment to argument names is automatic and\\nimplicit.\\nPython’s pass-by-assignment scheme isn’t quite the same as C++’s reference parame-\\nters option, but it turns out to be very similar to the argument-passing model of the C\\nlanguage (and others) in practice:\\n\\n• Immutable arguments are effectively passed “by value.” Objects such as in-\\ntegers and strings are passed by object reference instead of by copying, but because\\nyou can’t change immutable objects in place anyhow, the effect is much like making\\na copy.\\n\\n• Mutable arguments are effectively passed “by pointer.” Objects such as lists\\nand dictionaries are also passed by object reference, which is similar to the way C\\npasses arrays as pointers—mutable objects can be changed in place in the function,\\nmuch like C arrays.\\n\\nOf course, if you’ve never used C, Python’s argument-passing mode will seem simpler\\nstill—it involves just the assignment of objects to names, and it works the same whether\\nthe objects are mutable or not.\\n\\nArguments and Shared References\\nTo illustrate argument-passing properties at work, consider the following code:\\n\\n>>> def f(a):                 # a is assigned to (references) the passed object\\n        a = 99                # Changes local variable a only\\n\\n>>> b = 88\\n>>> f(b)                      # a and b both reference same 88 initially\\n>>> print(b)                  # b is not changed\\n88\\n\\nIn this example the variable a is assigned the object 88 at the moment the function is\\ncalled with  f(b), but  a lives only within the called function. Changing  a inside the\\nfunction has no effect on the place where the function is called; it simply resets the local\\nvariable a to a completely different object.\\nThat’s what is meant by a lack of name aliasing—assignment to an argument name\\ninside a function (e.g., a=99) does not magically change a variable like b in the scope of\\nthe function call. Argument names may share passed objects initially (they are essen-\\ntially pointers to those objects), but only temporarily, when the function is first called.\\nAs soon as an argument name is reassigned, this relationship ends.\\nAt least, that’s the case for assignment to argument names themselves. When arguments\\nare passed mutable objects like lists and dictionaries, we also need to be aware that in-\\nplace changes to such objects may live on after a function exits, and hence impact callers.\\nHere’s an example that demonstrates this behavior:\\n\\n524 | Chapter 18:\\u2002Arguments\\n\\n\\x0c>>> def changer(a, b):        # Arguments assigned references to objects\\n        a = 2                 # Changes local name\\'s value only\\n        b[0] = \\'spam\\'         # Changes shared object in place\\n\\n>>> X = 1\\n>>> L = [1, 2]                # Caller:\\n>>> changer(X, L)             # Pass immutable and mutable objects\\n>>> X, L                      # X is unchanged, L is different!\\n(1, [\\'spam\\', 2])\\n\\nIn this code, the changer function assigns values to argument a itself, and to a compo-\\nnent of the object referenced by argument b. These two assignments within the function\\nare only slightly different in syntax but have radically different results:\\n\\n• Because a is a local variable name in the function’s scope, the first assignment has\\nno effect on the caller—it simply changes the local variable a to reference a com-\\npletely different object, and does not change the binding of the name X in the caller’s\\nscope. This is the same as in the prior example.\\n\\n• Argument b is a local variable name, too, but it is passed a mutable object (the list\\nthat L references in the caller’s scope). As the second assignment is an in-place\\nobject change, the result of the assignment to b[0] in the function impacts the value\\nof L after the function returns.\\n\\nReally, the second assignment statement in changer doesn’t change b—it changes part\\nof the object that b currently references. This in-place change impacts the caller only\\nbecause the changed object outlives the function call. The name L hasn’t changed either\\n—it still references the same, changed object—but it seems as though L differs after the\\ncall because the value it references has been modified within the function. In effect, the\\nlist name L serves as both input to and output from the function.\\nFigure 18-1 illustrates the name/object bindings that exist immediately after the func-\\ntion has been called, and before its code has run.\\nIf this example is still confusing, it may help to notice that the effect of the automatic\\nassignments of the passed-in arguments is the same as running a series of simple as-\\nsignment statements. In terms of the first argument, the assignment has no effect on\\nthe caller:\\n\\n>>> X = 1\\n>>> a = X               # They share the same object\\n>>> a = 2               # Resets \\'a\\' only, \\'X\\' is still 1\\n>>> print(X)\\n1\\n\\nThe assignment through the second argument does affect a variable at the call, though,\\nbecause it is an in-place object change:\\n\\n>>> L = [1, 2]\\n>>> b = L               # They share the same object\\n>>> b[0] = \\'spam\\'       # In-place change: \\'L\\' sees the change too\\n>>> print(L)\\n[\\'spam\\', 2]\\n\\nArgument-Passing Basics\\n\\n| 525\\n\\n\\x0cFigure 18-1. References: arguments. Because arguments are passed by assignment, argument names\\nin the function may share objects with variables in the scope of the call. Hence, in-place changes to\\nmutable arguments in a function can impact the caller. Here, a and b in the function initially reference\\nthe objects referenced by variables X and L when the function is first called. Changing the list through\\nvariable b makes L appear different after the call returns.\\n\\nIf you recall our discussions about shared mutable objects in Chapter 6 and Chap-\\nter 9, you’ll recognize the phenomenon at work: changing a mutable object in place\\ncan impact other references to that object. Here, the effect is to make one of the argu-\\nments work like both an input and an output of the function.\\n\\nAvoiding Mutable Argument Changes\\nThis behavior of in-place changes to mutable arguments isn’t a bug—it’s simply the\\nway argument passing works in Python, and turns out to be widely useful in practice.\\nArguments are normally passed to functions by reference because that is what we nor-\\nmally want. It means we can pass large objects around our programs without making\\nmultiple copies along the way, and we can easily update these objects as we go. In fact,\\nas we’ll see in Part VI, Python’s class model depends upon changing a passed-in “self”\\nargument in place, to update object state.\\nIf we don’t want in-place changes within functions to impact objects we pass to them,\\nthough, we can simply make explicit copies of mutable objects, as we learned in Chap-\\nter 6. For function arguments, we can always copy the list at the point of call, with tools\\nlike list, list.copy as of 3.3, or an empty slice:\\n\\nL = [1, 2]\\nchanger(X, L[:])        # Pass a copy, so our \\'L\\' does not change\\n\\nWe can also copy within the function itself, if we never want to change passed-in ob-\\njects, regardless of how the function is called:\\n\\n526 | Chapter 18:\\u2002Arguments\\n\\n\\x0cdef changer(a, b):\\n    b = b[:]            # Copy input list so we don\\'t impact caller\\n    a = 2\\n    b[0] = \\'spam\\'       # Changes our list copy only\\n\\nBoth of these copying schemes don’t stop the function from changing the object—they\\njust prevent those changes from impacting the caller. To really prevent changes, we can\\nalways convert to immutable objects to force the issue. Tuples, for example, raise an\\nexception when changes are attempted:\\n\\nL = [1, 2]\\nchanger(X, tuple(L))    # Pass a tuple, so changes are errors\\n\\nThis scheme uses the built-in tuple function, which builds a new tuple out of all the\\nitems in a sequence (really, any iterable). It’s also something of an extreme—because\\nit forces the function to be written to never change passed-in arguments, this solution\\nmight impose more limitations on the function than it should, and so should generally\\nbe avoided (you never know when changing arguments might come in handy for other\\ncalls in the future). Using this technique will also make the function lose the ability to\\ncall any list-specific methods on the argument, including methods that do not change\\nthe object in place.\\nThe main point to remember here is that functions might update mutable objects like\\nlists and dictionaries passed into them. This isn’t necessarily a problem if it’s expected,\\nand often serves useful purposes. Moreover, functions that change passed-in mutable\\nobjects in place are probably designed and intended to do so—the change is likely part\\nof a well-defined API that you shouldn’t violate by making copies.\\nHowever, you do have to be aware of this property—if objects change out from under\\nyou unexpectedly, check whether a called function might be responsible, and make\\ncopies when objects are passed if needed.\\n\\nSimulating Output Parameters and Multiple Results\\nWe’ve already discussed the return statement and used it in a few examples. Here’s\\nanother way to use this statement: because return can send back any sort of object, it\\ncan return multiple values by packaging them in a tuple or other collection type. In fact,\\nalthough Python doesn’t support what some languages label “call by reference” argu-\\nment passing, we can usually simulate it by returning tuples and assigning the results\\nback to the original argument names in the caller:\\n\\n>>> def multiple(x, y):\\n        x = 2               # Changes local names only\\n        y = [3, 4]\\n        return x, y         # Return multiple new values in a tuple\\n\\n>>> X = 1\\n>>> L = [1, 2]\\n>>> X, L = multiple(X, L)   # Assign results to caller\\'s names\\n\\nArgument-Passing Basics\\n\\n| 527\\n\\n\\x0c>>> X, L\\n(2, [3, 4])\\n\\nIt looks like the code is returning two values here, but it’s really just one—a two-item\\ntuple with the optional surrounding parentheses omitted. After the call returns, we can\\nuse tuple assignment to unpack the parts of the returned tuple. (If you’ve forgotten why\\nthis works, flip back to “Tuples” in Chapter 4 and Chapter 9, and “Assignment State-\\nments” in Chapter 11.) The net effect of this coding pattern is to both send back multiple\\nresults and simulate the output parameters of other languages by explicit assignments.\\nHere, X and L change after the call, but only because the code said so.\\n\\nUnpacking arguments in Python 2.X: The preceding example unpacks a\\ntuple returned by the function with tuple assignment. In Python 2.X,\\nit’s also possible to automatically unpack tuples in arguments passed\\nto a function. In 2.X (only), a function defined by this header:\\n\\ndef f((a, (b, c))):\\n\\ncan be called with tuples that match the expected structure: f((1, (2,\\n3))) assigns a, b, and c to 1, 2, and 3, respectively. Naturally, the passed\\ntuple can also be an object created before the call (f(T)). This def syntax\\nis no longer supported in Python 3.X. Instead, code this function as:\\n\\ndef f(T): (a, (b, c)) = T\\n\\nto unpack in an explicit assignment statement. This explicit form works\\nin both 3.X and 2.X. Argument unpacking is reportedly an obscure and\\nrarely used feature in Python 2.X (except in code that uses it!). More-\\nover, a function header in 2.X supports only the tuple form of sequence\\nassignment; more general sequence assignments (e.g., def f((a, [b,\\nc])):) fail on syntax errors in 2.X as well and require the explicit as-\\nsignment form mandated in 3.X. Conversely, arbitrary sequences in the\\ncall successfully match tuples in the header (e.g., f((1, [2, 3])), f((1,\\n\"ab\"))).\\n\\nTuple unpacking argument syntax is also disallowed by 3.X in lambda\\nfunction  argument  lists:  see  the  Chapter  20  sidebar  “Why  You  Will\\nCare:  List  Comprehensions  and  map”  on  page  590  for  a  lambda  un-\\npacking example. Somewhat asymmetrically, tuple unpacking assign-\\nment is still automatic in 3.X for loops targets; see Chapter 13 for ex-\\namples.\\n\\nSpecial Argument-Matching Modes\\nAs we’ve just seen, arguments are always passed by assignment in Python; names in the\\ndef header are assigned to passed-in objects. On top of this model, though, Python\\nprovides  additional  tools  that  alter  the  way  the  argument  objects  in  a  call  are\\nmatched with argument names in the header prior to assignment. These tools are all\\n\\n528 | Chapter 18:\\u2002Arguments\\n\\n\\x0coptional, but they allow us to write functions that support more flexible calling pat-\\nterns, and you may encounter some libraries that require them.\\nBy default, arguments are matched by position, from left to right, and you must pass\\nexactly as many arguments as there are argument names in the function header. How-\\never, you can also specify matching by name, provide default values, and use collectors\\nfor extra arguments.\\n\\nArgument Matching Basics\\nBefore we go into the syntactic details, I want to stress that these special modes are\\noptional and deal only with matching objects to names; the underlying passing mech-\\nanism after the matching takes place is still assignment. In fact, some of these tools are\\nintended more for people writing libraries than for application developers. But because\\nyou may stumble across these modes even if you don’t code them yourself, here’s a\\nsynopsis of the available tools:\\n\\nPositionals: matched from left to right\\n\\nThe normal case, which we’ve mostly been using so far, is to match passed argu-\\nment values to argument names in a function header by position, from left to right.\\n\\nKeywords: matched by argument name\\n\\nAlternatively, callers can specify which argument in the function is to receive a\\nvalue by using the argument’s name in the call, with the name=value syntax.\\n\\nDefaults: specify values for optional arguments that aren’t passed\\n\\nFunctions themselves can specify default values for arguments to receive if the call\\npasses too few values, again using the name=value syntax.\\n\\nVarargs collecting: collect arbitrarily many positional or keyword arguments\\n\\nFunctions can use special arguments preceded with one or two  * characters to\\ncollect an arbitrary number of possibly extra arguments. This feature is often re-\\nferred to as varargs, after a variable-length argument list tool in the C language; in\\nPython, the arguments are collected in a normal object.\\n\\nVarargs unpacking: pass arbitrarily many positional or keyword arguments\\n\\nCallers can also use the  * syntax to unpack argument collections into separate\\narguments. This is the inverse of a * in a function header—in the header it means\\ncollect arbitrarily many arguments, while in the call it means unpack arbitrarily\\nmany arguments, and pass them individually as discrete values.\\n\\nKeyword-only arguments: arguments that must be passed by name\\n\\nIn Python 3.X (but not 2.X), functions can also specify arguments that must be\\npassed by name with keyword arguments, not by position. Such arguments are\\ntypically used to define configuration options in addition to actual arguments.\\n\\nSpecial Argument-Matching Modes\\n\\n| 529\\n\\n\\x0cArgument Matching Syntax\\nTable 18-1 summarizes the syntax that invokes the special argument-matching modes.\\n\\nTable 18-1. Function argument-matching forms\\n\\nSyntax\\nfunc(value)\\n\\nfunc(name=value)\\n\\nfunc(*iterable)\\n\\nfunc(**dict)\\n\\ndef func(name)\\n\\ndef func(name=value)\\n\\ndef func(*name)\\n\\ndef func(**name)\\n\\ndef func(*other, name)\\n\\ndef func(*, name=value)\\n\\nLocation\\nCaller\\nCaller\\nCaller\\nCaller\\nFunction\\nFunction\\nFunction\\nFunction\\nFunction\\nFunction\\n\\nInterpretation\\nNormal argument: matched by position\\nKeyword argument: matched by name\\nPass all objects in iterable as individual positional arguments\\nPass all key/value pairs in dict as individual keyword arguments\\nNormal argument: matches any passed value by position or name\\nDefault argument value, if not passed in the call\\nMatches and collects remaining positional arguments in a tuple\\nMatches and collects remaining keyword arguments in a dictionary\\nArguments that must be passed by keyword only in calls (3.X)\\nArguments that must be passed by keyword only in calls (3.X)\\n\\nThese special matching modes break down into function calls and definitions as fol-\\nlows:\\n\\n• In a function call (the first four rows of the table), simple values are matched by\\nposition, but using the name=value form tells Python to match by name to argu-\\nments instead; these are called keyword arguments. Using a *iterable or **dict in\\na call allows us to package up arbitrarily many positional or keyword objects in\\nsequences (and other iterables) and dictionaries, respectively, and unpack them as\\nseparate, individual arguments when they are passed to the function.\\n\\n• In a function header (the rest of the table), a simple name is matched by position or\\nname depending on how the caller passes it, but the name=value form specifies a\\ndefault value. The *name form collects any extra unmatched positional arguments\\nin a tuple, and the **name form collects extra keyword arguments in a dictionary.\\nIn Python 3.X, any normal or defaulted argument names following a *name or a\\nbare * are keyword-only arguments and must be passed by keyword in calls.\\n\\nOf these, keyword arguments and defaults are probably the most commonly used in\\nPython code. We’ve informally used both of these earlier in this book:\\n\\n• We’ve already used keywords to specify options to the 3.X print function, but they\\nare more general—keywords allow us to label any argument with its name, to make\\ncalls more informational.\\n\\n• We met defaults earlier, too, as a way to pass in values from the enclosing function’s\\nscope, but they are also more general—they allow us to make any argument op-\\ntional, providing its default value in a function definition.\\n\\n530 | Chapter 18:\\u2002Arguments\\n\\n\\x0cAs we’ll see, the combination of defaults in a function header and keywords in a call\\nfurther allows us to pick and choose which defaults to override.\\nIn short, special argument-matching modes let you be fairly liberal about how many\\narguments must be passed to a function. If a function specifies defaults, they are used\\nif you pass too few arguments. If a function uses the * variable argument list forms, you\\ncan seemingly pass too many arguments; the * names collect the extra arguments in\\ndata structures for processing in the function.\\n\\nThe Gritty Details\\nIf you choose to use and combine the special argument-matching modes, Python will\\nask you to follow these ordering rules among the modes’ optional components:\\n\\n• In a function call, arguments must appear in this order: any positional arguments\\n(value); followed by a combination of any keyword arguments (name=value) and\\nthe *iterable form; followed by the **dict form.\\n\\n• In a function header, arguments must appear in this order: any normal arguments\\n(name); followed by any default arguments (name=value); followed by the *name (or\\n* in 3.X) form; followed by any name or name=value keyword-only arguments (in\\n3.X); followed by the **name form.\\n\\nIn both the call and header, the **args form must appear last if present. If you mix\\narguments in any other order, you will get a syntax error because the combinations can\\nbe ambiguous. The steps that Python internally carries out to match arguments before\\nassignment can roughly be described as follows:\\n\\n1. Assign nonkeyword arguments by position.\\n2. Assign keyword arguments by matching names.\\n3. Assign extra nonkeyword arguments to *name tuple.\\n4. Assign extra keyword arguments to **name dictionary.\\n5. Assign default values to unassigned arguments in header.\\n\\nAfter this, Python checks to make sure each argument is passed just one value; if not,\\nan error is raised. When all matching is complete, Python assigns argument names to\\nthe objects passed to them.\\nThe actual matching algorithm Python uses is a bit more complex (it must also account\\nfor keyword-only arguments in 3.X, for instance), so we’ll defer to Python’s standard\\nlanguage manual for a more exact description. It’s not required reading, but tracing\\nPython’s matching algorithm may help you to understand some convoluted cases, es-\\npecially when modes are mixed.\\n\\nSpecial Argument-Matching Modes\\n\\n| 531\\n\\n\\x0cIn Python 3.X only, argument names in a function header can also have\\nannotation values, specified as name:value (or name:value=default when\\ndefaults are present). This is simply additional syntax for arguments and\\ndoes  not  augment  or  change  the  argument-ordering  rules  described\\nhere. The function itself can also have an annotation value, given as def\\nf()->value. Python attaches annotation values to the function object.\\nSee the discussion of function annotation in Chapter 19 for more details.\\n\\nKeyword and Default Examples\\nThis is all simpler in code than the preceding descriptions may imply. If you don’t use\\nany special matching syntax, Python matches names by position from left to right, like\\nmost other languages. For instance, if you define a function that requires three argu-\\nments, you must call it with three arguments:\\n\\n>>> def f(a, b, c): print(a, b, c)\\n\\n>>> f(1, 2, 3)\\n1 2 3\\n\\nHere, we pass by position—a is matched to 1, b is matched to 2, and so on (this works\\nthe same in Python 3.X and 2.X, but extra tuple parentheses are displayed in 2.X be-\\ncause we’re using 3.X print calls again).\\n\\nKeywords\\nIn Python, though, you can be more specific about what goes where when you call a\\nfunction. Keyword arguments allow us to match by name, instead of by position. Using\\nthe same function:\\n\\n>>> f(c=3, b=2, a=1)\\n1 2 3\\n\\nThe c=3 in this call, for example, means send 3 to the argument named c. More formally,\\nPython matches the name c in the call to the argument named c in the function defi-\\nnition’s header, and then passes the value 3 to that argument. The net effect of this call\\nis the same as that of the prior call, but notice that the left-to-right order of the argu-\\nments no longer matters when keywords are used because arguments are matched by\\nname, not by position. It’s even possible to combine positional and keyword arguments\\nin a single call. In this case, all positionals are matched first from left to right in the\\nheader, before keywords are matched by name:\\n\\n>>> f(1, c=3, b=2)            # a gets 1 by position, b and c passed by name\\n1 2 3\\n\\nWhen most people see this the first time, they wonder why one would use such a tool.\\nKeywords typically have two roles in Python. First, they make your calls a bit more self-\\ndocumenting (assuming that you use better argument names than a, b, and c!). For\\nexample, a call of this form:\\n\\n532 | Chapter 18:\\u2002Arguments\\n\\n\\x0cfunc(name=\\'Bob\\', age=40, job=\\'dev\\')\\n\\nis much more meaningful than a call with three naked values separated by commas,\\nespecially in larger programs—the keywords serve as labels for the data in the call. The\\nsecond major use of keywords occurs in conjunction with defaults, which we turn to\\nnext.\\n\\nDefaults\\nWe talked about defaults in brief earlier, when discussing nested function scopes. In\\nshort, defaults allow us to make selected function arguments optional; if not passed a\\nvalue, the argument is assigned its default before the function runs. For example, here\\nis a function that requires one argument and defaults two:\\n\\n>>> def f(a, b=2, c=3): print(a, b, c)          # a required, b and c optional\\n\\nWhen we call this function, we must provide a value for a, either by position or by\\nkeyword; however, providing values for b and c is optional. If we don’t pass values to\\nb and c, they default to 2 and 3, respectively:\\n\\n>>> f(1)                   # Use defaults\\n1 2 3\\n>>> f(a=1)\\n1 2 3\\n\\nIf we pass two values, only c gets its default, and with three values, no defaults are used:\\n\\n>>> f(1, 4)                # Override defaults\\n1 4 3\\n>>> f(1, 4, 5)\\n1 4 5\\n\\nFinally, here is how the keyword and default features interact. Because they subvert the\\nnormal  left-to-right  positional  mapping,  keywords  allow  us  to  essentially  skip  over\\narguments with defaults:\\n\\n>>> f(1, c=6)              # Choose defaults\\n1 2 6\\n\\nHere, a gets 1 by position, c gets 6 by keyword, and b, in between, defaults to 2.\\nBe  careful  not  to  confuse  the  special  name=value  syntax  in  a  function  header  and  a\\nfunction call; in the call it means a match-by-name keyword argument, while in the\\nheader  it  specifies  a  default  for  an  optional  argument.  In  both  cases,  this  is  not  an\\nassignment statement (despite its appearance); it is special syntax for these two con-\\ntexts, which modifies the default argument-matching mechanics.\\n\\nCombining keywords and defaults\\nHere is a slightly larger example that demonstrates keywords and defaults in action. In\\nthe following, the caller must always pass at least two arguments (to match spam and\\n\\nSpecial Argument-Matching Modes\\n\\n| 533\\n\\n\\x0ceggs), but the other two are optional. If they are omitted, Python assigns toast and\\nham to the defaults specified in the header:\\n\\ndef func(spam, eggs, toast=0, ham=0):   # First 2 required\\n    print((spam, eggs, toast, ham))\\n\\nfunc(1, 2)                              # Output: (1, 2, 0, 0)\\nfunc(1, ham=1, eggs=0)                  # Output: (1, 0, 0, 1)\\nfunc(spam=1, eggs=0)                    # Output: (1, 0, 0, 0)\\nfunc(toast=1, eggs=2, spam=3)           # Output: (3, 2, 1, 0)\\nfunc(1, 2, 3, 4)                        # Output: (1, 2, 3, 4)\\n\\nNotice again that when keyword arguments are used in the call, the order in which the\\narguments are listed doesn’t matter; Python matches by name, not by position. The\\ncaller must supply values for spam and eggs, but they can be matched by position or by\\nname. Again, keep in mind that the form name=value means different things in the call\\nand the def: a keyword in the call and a default in the header.\\n\\nBeware mutable defaults: As footnoted in the prior chapter, if you code\\na default to be a mutable object (e.g.,  def f(a=[])), the same, single\\nmutable object is reused every time the function is later called—even if\\nit is changed in place within the function. The net effect is that the ar-\\ngument’s default retains its value from the prior call, and is not reset to\\nits original value coded in the def header. To reset anew on each call,\\nmove the assignment into the function body instead. Mutable defaults\\nallow state retention, but this is often a surprise. Since this is such a\\ncommon  trap,  we’ll  postpone  further  exploration  until  this  part’s\\n“gotchas” list at the end of Chapter 21.\\n\\nArbitrary Arguments Examples\\nThe last two matching extensions, * and **, are designed to support functions that take\\nany number of arguments. Both can appear in either the function definition or a function\\ncall, and they have related purposes in the two locations.\\n\\nHeaders: Collecting arguments\\nThe first use, in the function definition, collects unmatched positional arguments into\\na tuple:\\n\\n>>> def f(*args): print(args)\\n\\nWhen this function is called, Python collects all the positional arguments into a new\\ntuple and assigns the variable args to that tuple. Because it is a normal tuple object, it\\ncan be indexed, stepped through with a for loop, and so on:\\n\\n>>> f()\\n()\\n>>> f(1)\\n(1,)\\n\\n534 | Chapter 18:\\u2002Arguments\\n\\n\\x0c>>> f(1, 2, 3, 4)\\n(1, 2, 3, 4)\\n\\nThe ** feature is similar, but it only works for keyword arguments—it collects them\\ninto a new dictionary, which can then be processed with normal dictionary tools. In a\\nsense, the ** form allows you to convert from keywords to dictionaries, which you can\\nthen step through with keys calls, dictionary iterators, and the like (this is roughly what\\nthe dict call does when passed keywords, but it returns the new dictionary):\\n\\n>>> def f(**args): print(args)\\n\\n>>> f()\\n{}\\n>>> f(a=1, b=2)\\n{\\'a\\': 1, \\'b\\': 2}\\n\\nFinally, function headers can combine normal arguments, the *, and the ** to imple-\\nment wildly flexible call signatures. For instance, in the following, 1 is passed to a by\\nposition, 2 and 3 are collected into the pargs positional tuple, and x and y wind up in\\nthe kargs keyword dictionary:\\n\\n>>> def f(a, *pargs, **kargs): print(a, pargs, kargs)\\n\\n>>> f(1, 2, 3, x=1, y=2)\\n1 (2, 3) {\\'y\\': 2, \\'x\\': 1}\\n\\nSuch code is rare, but shows up in functions that need to support multiple call patterns\\n(for backward compatibility, for instance). In fact, these features can be combined in\\neven more complex ways that may seem ambiguous at first glance—an idea we will\\nrevisit later in this chapter. First, though, let’s see what happens when * and ** are\\ncoded in function calls instead of definitions.\\n\\nCalls: Unpacking arguments\\nIn all recent Python releases, we can use the * syntax when we call a function, too. In\\nthis context, its meaning is the inverse of its meaning in the function definition—it\\nunpacks a collection of arguments, rather than building a collection of arguments. For\\nexample, we can pass four arguments to a function in a tuple and let Python unpack\\nthem into individual arguments:\\n\\n>>> def func(a, b, c, d): print(a, b, c, d)\\n\\n>>> args = (1, 2)\\n>>> args += (3, 4)\\n>>> func(*args)                            # Same as func(1, 2, 3, 4)\\n1 2 3 4\\n\\nSimilarly, the ** syntax in a function call unpacks a dictionary of key/value pairs into\\nseparate keyword arguments:\\n\\n>>> args = {\\'a\\': 1, \\'b\\': 2, \\'c\\': 3}\\n>>> args[\\'d\\'] = 4\\n\\nSpecial Argument-Matching Modes\\n\\n| 535\\n\\n\\x0c>>> func(**args)                           # Same as func(a=1, b=2, c=3, d=4)\\n1 2 3 4\\n\\nAgain, we can combine normal, positional, and keyword arguments in the call in very\\nflexible ways:\\n\\n>>> func(*(1, 2), **{\\'d\\': 4, \\'c\\': 3})      # Same as func(1, 2, d=4, c=3)\\n1 2 3 4\\n>>> func(1, *(2, 3), **{\\'d\\': 4})           # Same as func(1, 2, 3, d=4)\\n1 2 3 4\\n>>> func(1, c=3, *(2,), **{\\'d\\': 4})        # Same as func(1, 2, c=3, d=4)\\n1 2 3 4\\n>>> func(1, *(2, 3), d=4)                  # Same as func(1, 2, 3, d=4)\\n1 2 3 4\\n>>> func(1, *(2,), c=3, **{\\'d\\':4})         # Same as func(1, 2, c=3, d=4)\\n1 2 3 4\\n\\nThis sort of code is convenient when you cannot predict the number of arguments that\\nwill be passed to a function when you write your script; you can build up a collection\\nof arguments at runtime instead and call the function generically this way. Again, don’t\\nconfuse the */** starred-argument syntax in the function header and the function call\\n—in the header it collects any number of arguments, while in the call it unpacks any\\nnumber of arguments. In both, one star means positionals, and two applies to key-\\nwords.\\n\\nAs we saw in Chapter 14, the *pargs form in a call is an iteration con-\\ntext, so technically it accepts any iterable object, not just tuples or other\\nsequences as shown in the examples here. For instance, a file object\\nworks after the *, and unpacks its lines into individual arguments (e.g.,\\nfunc(*open(\\'fname\\')). Watch for additional examples of this utility in\\nChapter 20, after we study generators.\\n\\nThis generality is supported in both Python 3.X and 2.X, but it holds\\ntrue only for calls—a *pargs in a call allows any iterable, but the same\\nform in a def header always bundles extra arguments into a tuple. This\\nheader behavior is similar in spirit and syntax to the * in Python 3.X\\nextended  sequence  unpacking  assignment  forms  we  met  in  Chap-\\nter 11 (e.g., x, *y = z), though that star usage always creates lists, not\\ntuples.\\n\\nApplying functions generically\\nThe prior section’s examples may seem academic (if not downright esoteric), but they\\nare used more often than you might expect. Some programs need to call arbitrary func-\\ntions in a generic fashion, without knowing their names or arguments ahead of time.\\nIn fact, the real power of the special “varargs” call syntax is that you don’t need to know\\nhow many arguments a function call requires before you write a script. For example,\\nyou can use if logic to select from a set of functions and argument lists, and call any\\nof them generically (functions in some of the following examples are hypothetical):\\n\\n536 | Chapter 18:\\u2002Arguments\\n\\n\\x0cif sometest:\\n    action, args = func1, (1,)             # Call func1 with one arg in this case\\nelse:\\n    action, args = func2, (1, 2, 3)        # Call func2 with three args here\\n...etc...\\naction(*args)                              # Dispatch generically\\n\\nThis leverages both the * form, and the fact that functions are objects that may be both\\nreferenced by, and called through, any variable. More generally, this varargs call syntax\\nis useful anytime you cannot predict the arguments list. If your user selects an arbitrary\\nfunction via a user interface, for instance, you may be unable to hardcode a function\\ncall when writing your script. To work around this, simply build up the arguments list\\nwith sequence operations, and call it with starred-argument syntax to unpack the ar-\\nguments:\\n\\n>>> ...define or import func3...\\n>>> args = (2,3)\\n>>> args += (4,)\\n>>> args\\n(2, 3, 4)\\n>>> func3(*args)\\n\\nBecause the arguments list is passed in as a tuple here, the program can build it at\\nruntime. This technique also comes in handy for functions that test or time other func-\\ntions. For instance, in the following code we support any function with any arguments\\nby passing along whatever arguments were sent in (this is file tracer0.py in the book\\nexamples package):\\n\\ndef tracer(func, *pargs, **kargs):         # Accept arbitrary arguments\\n    print(\\'calling:\\', func.__name__)\\n    return func(*pargs, **kargs)           # Pass along arbitrary arguments\\n\\ndef func(a, b, c, d):\\n    return a + b + c + d\\n\\nprint(tracer(func, 1, 2, c=3, d=4))\\n\\nThis code uses the built-in __name__ attribute attached to every function (as you might\\nexpect, it’s the function’s name string), and uses stars to collect and then unpack the\\narguments intended for the traced function. In other words, when this code is run,\\narguments are intercepted by the tracer and then propagated with varargs call syntax:\\n\\ncalling: func\\n10\\n\\nFor another example of this technique, see the preview near the end of the preceding\\nchapter, where it was used to reset the built-in open function. We’ll code additional\\nexamples of such roles later in this book; see especially the sequence timing examples\\nin Chapter 21 and the various decorator utilities we will code in Chapter 39. It’s a\\ncommon technique in general tools.\\n\\nSpecial Argument-Matching Modes\\n\\n| 537\\n\\n\\x0cThe defunct apply built-in (Python 2.X)\\nPrior to Python 3.X, the effect of the *args and **args varargs call syntax could be\\nachieved with a built-in function named apply. This original technique has been re-\\nmoved in 3.X because it is now redundant (3.X cleans up many such dusty tools that\\nhave  been  subsumed  over  the  years).  It’s  still  available  in  all  Python  2.X  releases,\\nthough, and you may come across it in older 2.X code.\\nIn short, the following are equivalent prior to Python 3.X:\\n\\nfunc(*pargs, **kargs)             # Newer call syntax: func(*sequence, **dict)\\napply(func, pargs, kargs)         # Defunct built-in:  apply(func, sequence, dict)\\n\\nFor example, consider the following function, which accepts any number of positional\\nor keyword arguments:\\n\\n>>> def echo(*args, **kwargs): print(args, kwargs)\\n\\n>>> echo(1, 2, a=3, b=4)\\n(1, 2) {\\'a\\': 3, \\'b\\': 4}\\n\\nIn Python 2.X, we can call it generically with apply, or with the call syntax that is now\\nrequired in 3.X:\\n\\n>>> pargs = (1, 2)\\n>>> kargs = {\\'a\\':3, \\'b\\':4}\\n\\n>>> apply(echo, pargs, kargs)\\n(1, 2) {\\'a\\': 3, \\'b\\': 4}\\n\\n>>> echo(*pargs, **kargs)\\n(1, 2) {\\'a\\': 3, \\'b\\': 4}\\n\\nBoth forms work for built-in functions in 2.X too (notice 2.X’s trailing L for its long\\nintegers):\\n\\n>>> apply(pow, (2, 100))\\n1267650600228229401496703205376L\\n>>> pow(*(2, 100))\\n1267650600228229401496703205376L\\n\\nThe unpacking call syntax form is newer than the apply function, is preferred in general,\\nand is required in 3.X. (Technically, it was added in 2.0, was documented as deprecated\\nin 2.3, is still usable without warning in 2.7, and is gone in 3.0 and later.) Apart from\\nits symmetry with the * collector forms in def headers, and the fact that it requires fewer\\nkeystrokes, the newer call syntax also allows us to pass along additional arguments\\nwithout having to manually extend argument sequences or dictionaries:\\n\\n>>> echo(0, c=5, *pargs, **kargs)      # Normal, keyword, *sequence, **dictionary\\n(0, 1, 2) {\\'a\\': 3, \\'c\\': 5, \\'b\\': 4}\\n\\nThat is, the call syntax form is more general. Since it’s required in 3.X, you should now\\ndisavow all knowledge of apply (unless, of course, it appears in 2.X code you must use\\nor maintain...).\\n\\n538 | Chapter 18:\\u2002Arguments\\n\\n\\x0cPython 3.X Keyword-Only Arguments\\nPython 3.X generalizes the ordering rules in function headers to allow us to specify\\nkeyword-only arguments—arguments that must be passed by keyword only and will\\nnever be filled in by a positional argument. This is useful if we want a function to both\\nprocess any number of arguments and accept possibly optional configuration options.\\nSyntactically, keyword-only arguments are coded as named arguments that may appear\\nafter *args in the arguments list. All such arguments must be passed using keyword\\nsyntax in the call. For example, in the following, a may be passed by name or position,\\nb collects any extra positional arguments, and c must be passed by keyword only. In 3.X:\\n\\n>>> def kwonly(a, *b, c):\\n        print(a, b, c)\\n\\n>>> kwonly(1, 2, c=3)\\n1 (2,) 3\\n>>> kwonly(a=1, c=3)\\n1 () 3\\n>>> kwonly(1, 2, 3)\\nTypeError: kwonly() missing 1 required keyword-only argument: \\'c\\'\\n\\nWe can also use a * character by itself in the arguments list to indicate that a function\\ndoes not accept a variable-length argument list but still expects all arguments following\\nthe * to be passed as keywords. In the next function, a may be passed by position or\\nname again, but b and c must be keywords, and no extra positionals are allowed:\\n\\n>>> def kwonly(a, *, b, c):\\n        print(a, b, c)\\n\\n>>> kwonly(1, c=3, b=2)\\n1 2 3\\n>>> kwonly(c=3, b=2, a=1)\\n1 2 3\\n>>> kwonly(1, 2, 3)\\nTypeError: kwonly() takes 1 positional argument but 3 were given\\n>>> kwonly(1)\\nTypeError: kwonly() missing 2 required keyword-only arguments: \\'b\\' and \\'c\\'\\n\\nYou can still use defaults for keyword-only arguments, even though they appear after\\nthe * in the function header. In the following code, a may be passed by name or position,\\nand b and c are optional but must be passed by keyword if used:\\n\\n>>> def kwonly(a, *, b=\\'spam\\', c=\\'ham\\'):\\n        print(a, b, c)\\n\\n>>> kwonly(1)\\n1 spam ham\\n>>> kwonly(1, c=3)\\n1 spam 3\\n>>> kwonly(a=1)\\n1 spam ham\\n>>> kwonly(c=3, b=2, a=1)\\n1 2 3\\n\\nSpecial Argument-Matching Modes\\n\\n| 539\\n\\n\\x0c>>> kwonly(1, 2)\\nTypeError: kwonly() takes 1 positional argument but 2 were given\\n\\nIn fact, keyword-only arguments with defaults are optional, but those without defaults\\neffectively become required keywords for the function:\\n\\n>>> def kwonly(a, *, b, c=\\'spam\\'):\\n        print(a, b, c)\\n\\n>>> kwonly(1, b=\\'eggs\\')\\n1 eggs spam\\n>>> kwonly(1, c=\\'eggs\\')\\nTypeError: kwonly() missing 1 required keyword-only argument: \\'b\\'\\n>>> kwonly(1, 2)\\nTypeError: kwonly() takes 1 positional argument but 2 were given\\n\\n>>> def kwonly(a, *, b=1, c, d=2):\\n        print(a, b, c, d)\\n\\n>>> kwonly(3, c=4)\\n3 1 4 2\\n>>> kwonly(3, c=4, b=5)\\n3 5 4 2\\n>>> kwonly(3)\\nTypeError: kwonly() missing 1 required keyword-only argument: \\'c\\'\\n>>> kwonly(1, 2, 3)\\nTypeError: kwonly() takes 1 positional argument but 3 were given\\n\\nOrdering rules\\nFinally, note that keyword-only arguments must be specified after a single star, not two\\n—named arguments cannot appear after the **args arbitrary keywords form, and a\\n** can’t appear by itself in the arguments list. Both attempts generate a syntax error:\\n\\n>>> def kwonly(a, **pargs, b, c):\\nSyntaxError: invalid syntax\\n>>> def kwonly(a, **, b, c):\\nSyntaxError: invalid syntax\\n\\nThis means that in a function header, keyword-only arguments must be coded before\\nthe **args arbitrary keywords form and after the *args arbitrary positional form, when\\nboth are present. Whenever an argument name appears before *args, it is a possibly\\ndefault positional argument, not keyword-only:\\n\\n>>> def f(a, *b, **d, c=6): print(a, b, c, d)          # Keyword-only before **!\\nSyntaxError: invalid syntax\\n\\n>>> def f(a, *b, c=6, **d): print(a, b, c, d)          # Collect args in header\\n\\n>>> f(1, 2, 3, x=4, y=5)                               # Default used\\n1 (2, 3) 6 {\\'y\\': 5, \\'x\\': 4}\\n\\n>>> f(1, 2, 3, x=4, y=5, c=7)                          # Override default\\n1 (2, 3) 7 {\\'y\\': 5, \\'x\\': 4}\\n\\n540 | Chapter 18:\\u2002Arguments\\n\\n\\x0c>>> f(1, 2, 3, c=7, x=4, y=5)                          # Anywhere in keywords\\n1 (2, 3) 7 {\\'y\\': 5, \\'x\\': 4}\\n\\n>>> def f(a, c=6, *b, **d): print(a, b, c, d)          # c is not keyword-only here!\\n\\n>>> f(1, 2, 3, x=4)\\n1 (3,) 2 {\\'x\\': 4}\\n\\nIn fact, similar ordering rules hold true in function calls: when keyword-only arguments\\nare passed, they must appear before a **args form. The keyword-only argument can\\nbe coded either before or after the *args, though, and may be included in **args:\\n\\n>>> def f(a, *b, c=6, **d): print(a, b, c, d)          # KW-only between * and **\\n\\n>>> f(1, *(2, 3), **dict(x=4, y=5))                    # Unpack args at call\\n1 (2, 3) 6 {\\'y\\': 5, \\'x\\': 4}\\n\\n>>> f(1, *(2, 3), **dict(x=4, y=5), c=7)               # Keywords before **args!\\nSyntaxError: invalid syntax\\n\\n>>> f(1, *(2, 3), c=7, **dict(x=4, y=5))               # Override default\\n1 (2, 3) 7 {\\'y\\': 5, \\'x\\': 4}\\n\\n>>> f(1, c=7, *(2, 3), **dict(x=4, y=5))               # After or before *\\n1 (2, 3) 7 {\\'y\\': 5, \\'x\\': 4}\\n\\n>>> f(1, *(2, 3), **dict(x=4, y=5, c=7))               # Keyword-only in **\\n1 (2, 3) 7 {\\'y\\': 5, \\'x\\': 4}\\n\\nTrace through these cases on your own, in conjunction with the general argument-\\nordering rules described formally earlier. They may appear to be worst cases in the\\nartificial examples here, but they can come up in real practice, especially for people\\nwho write libraries and tools for other Python programmers to use.\\n\\nWhy keyword-only arguments?\\nSo why care about keyword-only arguments? In short, they make it easier to allow a\\nfunction to accept both any number of positional arguments to be processed, and con-\\nfiguration options passed as keywords. While their use is optional, without keyword-\\nonly arguments extra work may be required to provide defaults for such options and\\nto verify that no superfluous keywords were passed.\\nImagine a function that processes a set of passed-in objects and allows a tracing flag to\\nbe passed:\\n\\nprocess(X, Y, Z)                    # Use flag\\'s default\\nprocess(X, Y, notify=True)          # Override flag default\\n\\nWithout keyword-only arguments we have to use both *args and **args and manually\\ninspect the keywords, but with keyword-only arguments less code is required. The\\nfollowing guarantees that no positional argument will be incorrectly matched against\\nnotify and requires that it be a keyword if passed:\\n\\nSpecial Argument-Matching Modes\\n\\n| 541\\n\\n\\x0cdef process(*args, notify=False): ...\\n\\nSince we’re going to see a more realistic example of this later in this chapter, in “Em-\\nulating the Python 3.X print Function,” I’ll postpone the rest of this story until then.\\nFor an additional example of keyword-only arguments in action, see the iteration op-\\ntions timing case study in Chapter 21. And for additional function definition enhance-\\nments in Python 3.X, stay tuned for the discussion of function annotation syntax in\\nChapter 19.\\n\\nThe min Wakeup Call!\\nOK—it’s  time  for  something  more  realistic.  To  make  this  chapter’s  concepts  more\\nconcrete, let’s work through an exercise that demonstrates a practical application of\\nargument-matching tools.\\nSuppose you want to code a function that is able to compute the minimum value from\\nan arbitrary set of arguments and an arbitrary set of object data types. That is, the\\nfunction should accept zero or more arguments, as many as you wish to pass. Moreover,\\nthe function should work for all kinds of Python object types: numbers, strings, lists,\\nlists of dictionaries, files, and even None.\\nThe first requirement provides a natural example of how the * feature can be put to\\ngood use—we can collect arguments into a tuple and step over each of them in turn\\nwith a simple for loop. The second part of the problem definition is easy: because every\\nobject type supports comparisons, we don’t have to specialize the function per type (an\\napplication of polymorphism); we can simply compare objects blindly and let Python\\nworry about what sort of comparison to perform according to the objects being com-\\npared.\\n\\nFull Credit\\nThe following file shows three ways to code this operation, at least one of which was\\nsuggested by a student in one of my courses (this example is often a group exercise to\\ncircumvent dozing after lunch):\\n\\n• The first function fetches the first argument (args is a tuple) and traverses the rest\\nby slicing off the first (there’s no point in comparing an object to itself, especially\\nif it might be a large structure).\\n\\n• The second version lets Python pick off the first and rest of the arguments auto-\\n\\nmatically, and so avoids an index and slice.\\n\\n• The third converts from a tuple to a list with the built-in list call and employs the\\n\\nlist sort method.\\n\\n542 | Chapter 18:\\u2002Arguments\\n\\n\\x0cThe sort method is coded in C, so it can be quicker than the other approaches at times,\\nbut the linear scans of the first two techniques may make them faster much of the \\ntime.1 The file mins.py contains the code for all three solutions:\\n\\ndef min1(*args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if arg < res:\\n            res = arg\\n    return res\\n\\ndef min2(first, *rest):\\n    for arg in rest:\\n        if arg < first:\\n            first = arg\\n    return first\\n\\ndef min3(*args):\\n    tmp = list(args)            # Or, in Python 2.4+: return sorted(args)[0]\\n    tmp.sort()\\n    return tmp[0]\\n\\nprint(min1(3, 4, 1, 2))\\nprint(min2(\"bb\", \"aa\"))\\nprint(min3([2,2], [1,1], [3,3]))\\n\\nAll three solutions produce the same result when the file is run. Try typing a few calls\\ninteractively to experiment with these on your own:\\n\\n% python mins.py\\n1\\naa\\n[1, 1]\\n\\nNotice that none of these three variants tests for the case where no arguments are passed\\nin. They could, but there’s no point in doing so here—in all three solutions, Python\\nwill automatically raise an exception if no arguments are passed in. The first variant\\nraises an exception when we try to fetch item 0, the second when Python detects an\\nargument list mismatch, and the third when we try to return item 0 at the end.\\nThis is exactly what we want to happen—because these functions support any data\\ntype, there is no valid sentinel value that we could pass back to designate an error, so\\nwe may as well let the exception be raised. There are exceptions to this rule (e.g., you\\n\\n1. Actually, this is fairly complicated. The Python sort routine is coded in C and uses a highly optimized\\nalgorithm that attempts to take advantage of partial ordering in the items to be sorted. It’s named “timsort”\\nafter Tim Peters, its creator, and in its documentation it claims to have “supernatural performance” at\\ntimes (pretty good, for a sort!). Still, sorting is an inherently exponential operation (it must chop up the\\nsequence and put it back together many times), and the other versions simply perform one linear left-to-\\nright scan. The net effect is that sorting is quicker if the arguments are partially ordered, but is likely to\\nbe slower otherwise (this still holds true in test runs in 3.3). Even so, Python performance can change\\nover time, and the fact that sorting is implemented in the C language can help greatly; for an exact analysis,\\nyou should time the alternatives with the time or timeit modules—we’ll see how in Chapter 21.\\n\\nThe min Wakeup Call!\\n\\n| 543\\n\\n\\x0cmight test for errors yourself if you’d rather avoid actions run before reaching the code\\nthat triggers an error automatically), but in general it’s better to assume that arguments\\nwill work in your functions’ code and let Python raise errors for you when they do not.\\n\\nBonus Points\\nYou  can  get  bonus  points  here  for  changing  these  functions  to  compute  the  maxi-\\nmum, rather than minimum, values. This one’s easy: the first two versions only require\\nchanging  <  to  >,  and  the  third  simply  requires  that  we  return  tmp[−1]  instead  of\\ntmp[0]. For an extra point, be sure to set the function name to “max” as well (though\\nthis part is strictly optional).\\nIt’s also possible to generalize a single function to compute either a minimum or a\\nmaximum  value,  by  evaluating  comparison  expression  strings  with  a  tool  like  the\\neval built-in function (see the library manual, and various appearances here, especially\\nin Chapter 10) or passing in an arbitrary comparison function. The file minmax.py\\nshows how to implement the latter scheme:\\n\\ndef minmax(test, *args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if test(arg, res):\\n            res = arg\\n    return res\\n\\ndef lessthan(x, y): return x < y                # See also: lambda, eval\\ndef grtrthan(x, y): return x > y\\n\\nprint(minmax(lessthan, 4, 2, 1, 5, 6, 3))       # Self-test code\\nprint(minmax(grtrthan, 4, 2, 1, 5, 6, 3))\\n\\n% python minmax.py\\n1\\n6\\n\\nFunctions are another kind of object that can be passed into a function like this one.\\nTo make this a max (or other) function, for example, we simply pass in the right sort of\\ntest function. This may seem like extra work, but the main point of generalizing func-\\ntions this way—instead of cutting and pasting to change just a single character—is that\\nwe’ll only have one version to change in the future, not two.\\n\\nThe Punch Line...\\nOf course, all this was just a coding exercise. There’s really no reason to code min or\\nmax functions, because both are built-ins in Python! We met them briefly in  Chap-\\nter 5 in conjunction with numeric tools, and again in Chapter 14 when exploring iter-\\nation contexts. The built-in versions work almost exactly like ours, but they’re coded\\nin C for optimal speed and accept either a single iterable or multiple arguments. Still,\\n\\n544 | Chapter 18:\\u2002Arguments\\n\\n\\x0cthough it’s superfluous in this context, the general coding pattern we used here might\\nbe useful in other scenarios.\\n\\nGeneralized Set Functions\\nLet’s look at a more useful example of special argument-matching modes at work. At\\nthe end of Chapter 16, we wrote a function that returned the intersection of two se-\\nquences (it picked out items that appeared in both). Here is a version that intersects an\\narbitrary  number  of  sequences  (one  or  more)  by  using  the  varargs  matching  form\\n*args to collect all the passed-in arguments. Because the arguments come in as a tuple,\\nwe can process them in a simple for loop. Just for fun, we’ll code a union function that\\nalso accepts an arbitrary number of arguments to collect items that appear in any of\\nthe operands:\\n\\ndef intersect(*args):\\n    res = []\\n    for x in args[0]:                  # Scan first sequence\\n        if x in res: continue          # Skip duplicates\\n        for other in args[1:]:         # For all other args\\n            if x not in other: break   # Item in each one?\\n        else:                          # No: break out of loop\\n            res.append(x)              # Yes: add items to end\\n    return res\\n\\ndef union(*args):\\n    res = []\\n    for seq in args:                   # For all args\\n        for x in seq:                  # For all nodes\\n            if not x in res:\\n                res.append(x)          # Add new items to result\\n    return res\\n\\nBecause these are tools potentially worth reusing (and they’re too big to retype inter-\\nactively), we’ll store the functions in a module file called inter2.py (if you’ve forgotten\\nhow modules and imports work, see the introduction in Chapter 3, or stay tuned for\\nin-depth coverage in Part V). In both functions, the arguments passed in at the call\\ncome  in  as  the  args  tuple.  As  in  the  original  intersect,  both  work  on  any  kind  of\\nsequence. Here, they are processing strings, mixed types, and more than two sequences:\\n\\n% python\\n>>> from inter2 import intersect, union\\n>>> s1, s2, s3 = \"SPAM\", \"SCAM\", \"SLAM\"\\n\\n>>> intersect(s1, s2), union(s1, s2)           # Two operands\\n([\\'S\\', \\'A\\', \\'M\\'], [\\'S\\', \\'P\\', \\'A\\', \\'M\\', \\'C\\'])\\n\\n>>> intersect([1, 2, 3], (1, 4))               # Mixed types\\n[1]\\n\\n>>> intersect(s1, s2, s3)                      # Three operands\\n[\\'S\\', \\'A\\', \\'M\\']\\n\\nGeneralized Set Functions\\n\\n| 545\\n\\n\\x0c>>> union(s1, s2, s3)\\n[\\'S\\', \\'P\\', \\'A\\', \\'M\\', \\'C\\', \\'L\\']\\n\\nTo  test  more  thoroughly,  the  following  codes  a  function  to  apply  the  two  tools  to\\narguments in different orders using a simple shuffling technique that we saw in Chap-\\nter 13—it slices to move the first to the end on each loop, uses a * to unpack arguments,\\nand sorts so results are comparable:\\n\\n>>> def tester(func, items, trace=True):\\n       for i in range(len(items)):\\n           items = items[1:] + items[:1]\\n           if trace: print(items)\\n           print(sorted(func(*items)))\\n\\n>>> tester(intersect, (\\'a\\', \\'abcdefg\\', \\'abdst\\', \\'albmcnd\\'))\\n(\\'abcdefg\\', \\'abdst\\', \\'albmcnd\\', \\'a\\')\\n[\\'a\\']\\n(\\'abdst\\', \\'albmcnd\\', \\'a\\', \\'abcdefg\\')\\n[\\'a\\']\\n(\\'albmcnd\\', \\'a\\', \\'abcdefg\\', \\'abdst\\')\\n[\\'a\\']\\n(\\'a\\', \\'abcdefg\\', \\'abdst\\', \\'albmcnd\\')\\n[\\'a\\']\\n\\n>>> tester(union, (\\'a\\', \\'abcdefg\\', \\'abdst\\', \\'albmcnd\\'), False)\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'l\\', \\'m\\', \\'n\\', \\'s\\', \\'t\\']\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'l\\', \\'m\\', \\'n\\', \\'s\\', \\'t\\']\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'l\\', \\'m\\', \\'n\\', \\'s\\', \\'t\\']\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'l\\', \\'m\\', \\'n\\', \\'s\\', \\'t\\']\\n\\n>>> tester(intersect, (\\'ba\\', \\'abcdefg\\', \\'abdst\\', \\'albmcnd\\'), False)\\n[\\'a\\', \\'b\\']\\n[\\'a\\', \\'b\\']\\n[\\'a\\', \\'b\\']\\n[\\'a\\', \\'b\\']\\n\\nThe  argument  scrambling  here  doesn’t  generate  all  possible  argument  orders  (that\\nwould require a full permutation, and 24 orderings for 4 arguments), but suffices to\\ncheck if argument order impacts results here. If you test these further, you’ll notice that\\nduplicates won’t appear in either intersection or union results, which qualify them as\\nset operations from a mathematical perspective:\\n\\n>>> intersect([1, 2, 1, 3], (1, 1, 4))\\n[1]\\n>>> union([1, 2, 1, 3], (1, 1, 4))\\n[1, 2, 3, 4]\\n>>> tester(intersect, (\\'ababa\\', \\'abcdefga\\', \\'aaaab\\'), False)\\n[\\'a\\', \\'b\\']\\n[\\'a\\', \\'b\\']\\n[\\'a\\', \\'b\\']\\n\\nThese are still far from optimal from an algorithmic perspective, but due to the fol-\\nlowing note, we’ll leave further improvements to this code as suggested exercise. Also\\n\\n546 | Chapter 18:\\u2002Arguments\\n\\n\\x0cnotice that the argument scrambling in our tester function might be a generally useful\\ntool, and the tester would be simpler if we delegated this to another function, one that\\nwould be free to create or generate argument combinations as it saw fit:\\n\\n>>> def tester(func, items, trace=True):\\n        for args in scramble(items):\\n            ...use args...\\n\\nIn fact we will—watch for this example to be revised in Chapter 20 to address this last\\npoint, after we’ve learned how to code user-defined generators. We’ll also recode the\\nset  operations  one  last  time  in  Chapter  32  and  a  solution  to  a  Part  VI  exercise  as\\nclasses that extend the list object with methods.\\n\\nBecause Python now has a set object type (described in Chapter 5), none\\nof the set-processing examples in this book are strictly required any-\\nmore; they are included just as demonstrations of coding techniques,\\nand are today instructional only. Because it’s constantly improving and\\ngrowing, Python has an uncanny way of conspiring to make my book\\nexamples obsolete over time!\\n\\nEmulating the Python 3.X print Function\\nTo round out the chapter, let’s look at one last example of argument matching at work.\\nThe code you’ll see here is intended for use in Python 2.X or earlier (it works in 3.X,\\ntoo, but is pointless there): it uses both the *args arbitrary positional tuple and the\\n**args arbitrary keyword-arguments dictionary to simulate most of what the Python\\n3.X print function does. Python might have offered code like this as an option in 3.X\\nrather than removing the 2.X print entirely, but 3.X chose a clean break with the past\\ninstead.\\nAs we learned in Chapter 11, this isn’t actually required, because 2.X programmers can\\nalways enable the 3.X print function with an import of this form (available in 2.6 and\\n2.7):\\n\\nfrom __future__ import print_function\\n\\nTo demonstrate argument matching in general, though, the following file, print3.py,\\ndoes the same job in a small amount of reusable code, by building up the print string\\nand routing it per configuration arguments:\\n\\n#!python\\n\"\"\"\\nEmulate most of the 3.X print function for use in 2.X (and 3.X).\\nCall signature: print3(*args, sep=\\' \\', end=\\'\\\\n\\', file=sys.stdout)\\n\"\"\"\\nimport sys\\n\\ndef print3(*args, **kargs):\\n    sep  = kargs.get(\\'sep\\', \\' \\')            # Keyword arg defaults\\n\\nEmulating the Python 3.X print Function | 547\\n\\n\\x0c    end  = kargs.get(\\'end\\', \\'\\\\n\\')\\n    file = kargs.get(\\'file\\', sys.stdout)\\n    output = \\'\\'\\n    first  = True\\n    for arg in args:\\n        output += (\\'\\' if first else sep) + str(arg)\\n        first = False\\n    file.write(output + end)\\n\\nTo test it, import this into another file or the interactive prompt, and use it like the 3.X\\nprint function. Here is a test script, testprint3.py (notice that the function must be called\\n“print3”, because “print” is a reserved word in 2.X):\\n\\nfrom print3 import print3\\nprint3(1, 2, 3)\\nprint3(1, 2, 3, sep=\\'\\')                     # Suppress separator\\nprint3(1, 2, 3, sep=\\'...\\')\\nprint3(1, [2], (3,), sep=\\'...\\')             # Various object types\\n\\nprint3(4, 5, 6, sep=\\'\\', end=\\'\\')             # Suppress newline\\nprint3(7, 8, 9)\\nprint3()                                    # Add newline (or blank line)\\n\\nimport sys\\nprint3(1, 2, 3, sep=\\'??\\', end=\\'.\\\\n\\', file=sys.stderr)    # Redirect to file\\n\\nWhen this is run under 2.X, we get the same results as 3.X’s print function:\\n\\nC:\\\\code> c:\\\\python27\\\\python testprint3.py\\n1 2 3\\n123\\n1...2...3\\n1...[2]...(3,)\\n4567 8 9\\n\\n1??2??3.\\n\\nAlthough pointless in 3.X, the results are identical when run there. As usual, the gen-\\nerality of Python’s design allows us to prototype or develop concepts in the Python\\nlanguage itself. In this case, argument-matching tools are as flexible in Python code as\\nthey are in Python’s internal implementation.\\n\\nUsing Keyword-Only Arguments\\nIt’s interesting to notice that this example could be coded with Python 3.X keyword-\\nonly arguments, described earlier in this chapter, to automatically validate configura-\\ntion arguments. The following variant, in the file print3_alt1.py, illustrates:\\n\\n#!python3\\n\"Use 3.X only keyword-only args\"\\nimport sys\\n\\ndef print3(*args, sep=\\' \\', end=\\'\\\\n\\', file=sys.stdout):\\n    output = \\'\\'\\n\\n548 | Chapter 18:\\u2002Arguments\\n\\n\\x0c    first  = True\\n    for arg in args:\\n        output += (\\'\\' if first else sep) + str(arg)\\n        first = False\\n    file.write(output + end)\\n\\nThis version works the same as the original, and it’s a prime example of how keyword-\\nonly arguments come in handy. The original version assumes that all positional argu-\\nments are to be printed, and all keywords are for options only. That’s almost sufficient,\\nbut any extra keyword arguments are silently ignored. A call like the following, for\\ninstance, will generate an exception correctly with the keyword-only form:\\n\\n>>> print3(99, name=\\'bob\\')\\nTypeError: print3() got an unexpected keyword argument \\'name\\'\\n\\nbut will silently ignore the name argument in the original version. To detect superfluous\\nkeywords manually, we could use dict.pop() to delete fetched entries, and check if the\\ndictionary is not empty. The following version, in the file print3_alt2.py, is equivalent\\nto the keyword-only version—it triggers a built-in exception with a raise statement,\\nwhich works just as though Python had done so (we’ll study this in more detail in\\nPart VII):\\n\\n#!python\\n\"Use 2.X/3.X keyword args deletion with defaults\"\\nimport sys\\n\\ndef print3(*args, **kargs):\\n    sep  = kargs.pop(\\'sep\\', \\' \\')\\n    end  = kargs.pop(\\'end\\', \\'\\\\n\\')\\n    file = kargs.pop(\\'file\\', sys.stdout)\\n    if kargs: raise TypeError(\\'extra keywords: %s\\' % kargs)\\n    output = \\'\\'\\n    first  = True\\n    for arg in args:\\n        output += (\\'\\' if first else sep) + str(arg)\\n        first = False\\n    file.write(output + end)\\n\\nThis works as before, but it now catches extraneous keyword arguments, too:\\n\\n>>> print3(99, name=\\'bob\\')\\nTypeError: extra keywords: {\\'name\\': \\'bob\\'}\\n\\nThis version of the function runs under Python 2.X, but it requires four more lines of\\ncode than the keyword-only version. Unfortunately, the extra code is unavoidable in\\nthis case—the keyword-only version works on 3.X only, which negates most of the\\nreason that I wrote this example in the first place: a 3.X emulator that only works on\\n3.X isn’t incredibly useful! In programs written to run on 3.X only, though, keyword-\\nonly arguments can simplify a specific category of functions that accept both arguments\\nand options. For another example of 3.X keyword-only arguments, be sure to see the\\niteration timing case study in Chapter 21.\\n\\nEmulating the Python 3.X print Function | 549\\n\\n\\x0cWhy You Will Care: Keyword Arguments\\n\\nAs you can probably tell, advanced argument-matching modes can be complex. They\\nare also largely optional in your code; you can get by with just simple positional match-\\ning, and it’s probably a good idea to do so when you’re starting out. However, because\\nsome Python tools make use of them, some general knowledge of these modes is im-\\nportant.\\nFor example, keyword arguments play an important role in tkinter, the de facto stan-\\ndard GUI API for Python (this module’s name is Tkinter in Python 2.X). We touch on\\ntkinter only briefly at various points in this book, but in terms of its call patterns,\\nkeyword arguments set configuration options when GUI components are built. For\\ninstance, a call of the form:\\n\\nfrom tkinter import *\\nwidget = Button(text=\"Press me\", command=someFunction)\\n\\ncreates a new button and specifies its text and callback function, using the text and\\ncommand keyword arguments. Since the number of configuration options for a widget\\ncan be large, keyword arguments let you pick and choose which to apply. Without\\nthem, you might have to either list all the possible options by position or hope for a\\njudicious positional argument defaults protocol that would handle every possible op-\\ntion arrangement.\\n\\nMany built-in functions in Python expect us to use keywords for usage-mode options\\nas well, which may or may not have defaults. As we learned in Chapter 8, for instance,\\nthe sorted built-in:\\n\\nsorted(iterable, key=None, reverse=False)\\n\\nexpects us to pass an iterable object to be sorted, but also allows us to pass in optional\\nkeyword arguments to specify a dictionary sort key and a reversal flag, which default\\nto None and False, respectively. Since we normally don’t use these options, they may\\nbe omitted to use defaults.\\nAs we’ve also seen, the dict, str.format, and 3.X print calls accept keywords as well\\n—other usages we had to introduce in earlier chapters because of their forward de-\\npendence  on  argument-passing  modes  we’ve  studied  here  (alas,  those  who  change\\nPython already know Python!).\\n\\nChapter Summary\\nIn this chapter, we studied the second of two key concepts related to functions: argu-\\nments—how objects are passed into a function. As we learned, arguments are passed\\ninto a function by assignment, which means by object reference (which really means\\nby pointer). We also studied some more advanced extensions, including default and\\nkeyword  arguments,  tools  for  using  arbitrarily  many  arguments,  and  keyword-only\\narguments in 3.X. Finally, we saw how mutable arguments can exhibit the same be-\\n\\n550 | Chapter 18:\\u2002Arguments\\n\\n\\x0chavior as other shared references to objects—unless the object is explicitly copied when\\nit’s sent in, changing a passed-in mutable in a function can impact the caller.\\nThe next chapter continues our look at functions by exploring some more advanced\\nfunction-related ideas: function annotations, recursion, lambdas, and functional tools\\nsuch as map and filter. Many of these concepts stem from the fact that functions are\\nnormal objects in Python, and so support some advanced and very flexible processing\\nmodes. Before diving into those topics, however, take this chapter’s quiz to review the\\nargument ideas we’ve studied here.\\n\\nTest Your Knowledge: Quiz\\nIn most of this quiz’s questions, results may vary slightly in 2.X—with enclosing paren-\\ntheses and commas when multiple values are printed. To match the 3.X answers exactly\\nin 2.X, import print_function from __future__ before starting.\\n\\n1. What is the output of the following code, and why?\\n\\n>>> def func(a, b=4, c=5):\\n        print(a, b, c)\\n\\n>>> func(1, 2)\\n\\n2. What is the output of this code, and why?\\n\\n>>> def func(a, b, c=5):\\n        print(a, b, c)\\n\\n>>> func(1, c=3, b=2)\\n\\n3. How about this code: what is its output, and why?\\n\\n>>> def func(a, *pargs):\\n        print(a, pargs)\\n\\n>>> func(1, 2, 3)\\n\\n4. What does this code print, and why?\\n\\n>>> def func(a, **kargs):\\n        print(a, kargs)\\n\\n>>> func(a=1, c=3, b=2)\\n\\n5. What gets printed by this, and why?\\n\\n>>> def func(a, b, c=3, d=4): print(a, b, c, d)\\n\\n>>> func(1, *(5, 6))\\n\\n6. One last time: what is the output of this code, and why?\\n\\n>>> def func(a, b, c): a = 2; b[0] = \\'x\\'; c[\\'a\\'] = \\'y\\'\\n\\n>>> l=1; m=[1]; n={\\'a\\':0}\\n\\nTest Your Knowledge: Quiz | 551\\n\\n\\x0c>>> func(l, m,  n)\\n>>> l, m, n\\n\\nTest Your Knowledge: Answers\\n1. The output here is 1 2 5, because 1 and 2 are passed to a and b by position, and\\n\\nc is omitted in the call and defaults to 5.\\n\\n2. The output this time is 1 2 3: 1 is passed to a by position, and b and c are passed\\n2 and 3 by name (the left-to-right order doesn’t matter when keyword arguments\\nare used like this).\\n\\n3. This code prints 1 (2, 3), because 1 is passed to a and the *pargs collects the\\nremaining positional arguments into a new tuple object. We can step through the\\nextra  positional  arguments  tuple  with  any  iteration  tool  (e.g.,  for  arg  in\\npargs: ...).\\n\\n4. This time the code prints 1 {\\'b\\': 2, \\'c\\': 3}, because 1 is passed to a by name\\nand the **kargs collects the remaining keyword arguments into a dictionary. We\\ncould step through the extra keyword arguments dictionary by key with any iter-\\nation tool (e.g., for key in kargs: ...). Note that the order of the dictionary’s\\nkeys may vary per Python and other variables.\\n\\n5. The output here is 1 5 6 4: the 1 matches a by position, 5 and 6 match b and c by\\n*name positionals (6 overrides c’s default), and d defaults to 4 because it was not\\npassed a value.\\n\\n6. This displays (1, [\\'x\\'], {\\'a\\': \\'y\\'})—the first assignment in the function doesn’t\\nimpact the caller, but the second two do because they change passed-in mutable\\nobjects in place.\\n\\n552 | Chapter 18:\\u2002Arguments\\n\\n\\x0cCHAPTER 19\\nAdvanced Function Topics\\n\\nThis chapter introduces a collection of more advanced function-related topics: recur-\\nsive functions, function attributes and annotations, the lambda expression, and func-\\ntional programming tools such as map and filter. These are all somewhat advanced\\ntools that, depending on your job description, you may not encounter on a regular\\nbasis. Because of their roles in some domains, though, a basic understanding can be\\nuseful; lambdas, for instance, are regular customers in GUIs, and functional program-\\nming techniques are increasingly common in Python code.\\nPart of the art of using functions lies in the interfaces between them, so we will also\\nexplore some general function design principles here. The next chapter continues this\\nadvanced theme with an exploration of generator functions and expressions and a re-\\nvival of list comprehensions in the context of the functional tools we will study here.\\n\\nFunction Design Concepts\\nNow that we’ve had a chance to study function basics in Python, let’s begin this chapter\\nwith a few words of context. When you start using functions in earnest, you’re faced\\nwith choices about how to glue components together—for instance, how to decompose\\na task into purposeful functions (known as cohesion), how your functions should com-\\nmunicate (called coupling), and so on. You also need to take into account concepts such\\nas the size of your functions, because they directly impact code usability. Some of this\\nfalls into the category of structured analysis and design, but it applies to Python code\\nas to any other.\\nWe introduced some ideas related to function and module coupling in Chapter 17 when\\nstudying scopes, but here is a review of a few general guidelines for readers new to\\nfunction design principles:\\n\\n• Coupling: use arguments for inputs and return for outputs. Generally, you\\nshould strive to make a function independent of things outside of it. Arguments\\nand return statements are often the best ways to isolate external dependencies to\\na small number of well-known places in your code.\\n\\n553\\n\\n\\x0c• Coupling: use global variables only when truly necessary. Global variables\\n(i.e., names in the enclosing module) are usually a poor way for functions to com-\\nmunicate. They can create dependencies and timing issues that make programs\\ndifficult to debug, change, and reuse.\\n\\n• Coupling:  don’t  change  mutable  arguments  unless  the  caller  expects  it.\\nFunctions can change parts of passed-in mutable objects, but (as with global vari-\\nables) this creates a tight coupling between the caller and callee, which can make\\na function too specific and brittle.\\n\\n• Cohesion: each function should have a single, unified purpose. When de-\\nsigned well, each of your functions should do one thing—something you can sum-\\nmarize in a simple declarative sentence. If that sentence is very broad (e.g., “this\\nfunction implements my whole program”), or contains lots of conjunctions (e.g.,\\n“this function gives employee raises and submits a pizza order”), you might want\\nto think about splitting it into separate and simpler functions. Otherwise, there is\\nno way to reuse the code behind the steps mixed together in the function.\\n\\n• Size: each function should be relatively small. This naturally follows from the\\npreceding goal, but if your functions start spanning multiple pages on your display,\\nit’s probably time to split them. Especially given that Python code is so concise to\\nbegin with, a long or deeply nested function is often a symptom of design problems.\\nKeep it simple, and keep it short.\\n\\n• Coupling: avoid changing variables in another module file directly. We in-\\ntroduced this concept in Chapter 17, and we’ll revisit it in the next part of the book\\nwhen we focus on modules. For reference, though, remember that changing vari-\\nables across file boundaries sets up a coupling between modules similar to how\\nglobal variables couple functions—the modules become difficult to understand\\nand reuse. Use accessor functions whenever possible, instead of direct assignment\\nstatements.\\n\\nFigure 19-1 summarizes the ways functions can talk to the outside world; inputs may\\ncome from items on the left side, and results may be sent out in any of the forms on the\\nright.  Good  function  designers  prefer  to  use  only  arguments  for  inputs  and  return\\nstatements for outputs, whenever possible.\\n\\nOf course, there are plenty of exceptions to the preceding design rules, including some\\nrelated to Python’s OOP support. As you’ll see in Part VI, Python classes depend on\\nchanging a passed-in mutable object—class functions set attributes of an automatically\\npassed-in  argument  called  self  to  change  per-object  state  information  (e.g.,\\nself.name=\\'bob\\'). Moreover, if classes are not used, global variables are often the most\\nstraightforward way for functions in modules to retain single-copy state between calls.\\nSide effects are usually dangerous only if they’re unexpected.\\nIn general though, you should strive to minimize external dependencies in functions\\nand other program components. The more self-contained a function is, the easier it will\\nbe to understand, reuse, and modify.\\n\\n554 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cFigure 19-1. Function execution environment. Functions may obtain input and produce output in a\\nvariety of ways, though functions are usually easier to understand and maintain if you use arguments\\nfor input and return statements and anticipated mutable argument changes for output. In Python 3.X\\nonly, outputs may also take the form of declared nonlocal names that exist in an enclosing function\\nscope.\\n\\nRecursive Functions\\nWe mentioned recursion in relation to comparisons of core types in Chapter 9. While\\ndiscussing scope rules near the start of Chapter 17, we also briefly noted that Python\\nsupports recursive functions—functions that call themselves either directly or indirectly\\nin order to loop. In this section, we’ll explore what this looks like in our functions’ code.\\nRecursion is a somewhat advanced topic, and it’s relatively rare to see in Python, partly\\nbecause Python’s procedural statements include simpler looping structures. Still, it’s a\\nuseful technique to know about, as it allows programs to traverse structures that have\\narbitrary and unpredictable shapes and depths—planning travel routes, analyzing lan-\\nguage, and crawling links on the Web, for example. Recursion is even an alternative to\\nsimple loops and iterations, though not necessarily the simplest or most efficient one.\\n\\nSummation with Recursion\\nLet’s look at some examples. To sum a list (or other sequence) of numbers, we can\\neither use the built-in sum function or write a more custom version of our own. Here’s\\nwhat a custom summing function might look like when coded with recursion:\\n\\n>>> def mysum(L):\\n        if not L:\\n            return 0\\n        else:\\n            return L[0] + mysum(L[1:])           # Call myself recursively\\n\\nRecursive Functions\\n\\n| 555\\n\\n\\x0c>>> mysum([1, 2, 3, 4, 5])\\n15\\n\\nAt each level, this function calls itself recursively to compute the sum of the rest of the\\nlist, which is later added to the item at the front. The recursive loop ends and zero is\\nreturned when the list becomes empty. When using recursion like this, each open level\\nof call to the function has its own copy of the function’s local scope on the runtime call\\nstack—here, that means L is different in each level.\\nIf this is difficult to understand (and it often is for new programmers), try adding a\\nprint of L to the function and run it again, to trace the current list at each call level:\\n\\n>>> def mysum(L):\\n        print(L)                                 # Trace recursive levels\\n        if not L:                                # L shorter at each level\\n            return 0\\n        else:\\n            return L[0] + mysum(L[1:])\\n\\n>>> mysum([1, 2, 3, 4, 5])\\n[1, 2, 3, 4, 5]\\n[2, 3, 4, 5]\\n[3, 4, 5]\\n[4, 5]\\n[5]\\n[]\\n15\\n\\nAs you can see, the list to be summed grows smaller at each recursive level, until it\\nbecomes empty—the termination of the recursive loop. The sum is computed as the\\nrecursive calls unwind on returns.\\n\\nCoding Alternatives\\nInterestingly,  we  can  use  Python’s  if/else  ternary  expression  (described  in  Chap-\\nter 12) to save some code real estate here. We can also generalize for any summable\\ntype (which is easier if we assume at least one item in the input, as we did in Chap-\\nter 18’s minimum value example) and use Python 3.X’s extended sequence assignment\\nto make the first/rest unpacking simpler (as covered in Chapter 11):\\n\\ndef mysum(L):\\n    return 0 if not L else L[0] + mysum(L[1:])           # Use ternary expression\\n\\ndef mysum(L):\\n    return L[0] if len(L) == 1 else L[0] + mysum(L[1:])  # Any type, assume one\\n\\ndef mysum(L):\\n    first, *rest = L\\n    return first if not rest else first + mysum(rest)    # Use 3.X ext seq assign\\n\\nThe latter two of these fail for empty lists but allow for sequences of any object type\\nthat supports +, not just numbers:\\n\\n556 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0c>>> mysum([1])                              # mysum([]) fails in last 2\\n1\\n>>> mysum([1, 2, 3, 4, 5])\\n15\\n>>> mysum((\\'s\\', \\'p\\', \\'a\\', \\'m\\'))             # But various types now work\\n\\'spam\\'\\n>>> mysum([\\'spam\\', \\'ham\\', \\'eggs\\'])\\n\\'spamhameggs\\'\\n\\nRun these on your own for more insight. If you study these three variants, you’ll find\\nthat:\\n\\n• The latter two also work on a single string argument (e.g., mysum(\\'spam\\')), because\\n\\nstrings are sequences of one-character strings.\\n\\n• The  third  variant  works  on  arbitrary  iterables,  including  open  input  files\\n(mysum(open(name))), but the others do not because they index (Chapter 14 illus-\\ntrates extended sequence assignment on files).\\n\\n• The function header def mysum(first, *rest), although similar to the third var-\\niant, wouldn’t work at all, because it expects individual arguments, not a single\\niterable.\\n\\nKeep in mind that recursion can be direct, as in the examples so far, or indirect, as in\\nthe following (a function that calls another function, which calls back to its caller). The\\nnet effect is the same, though there are two function calls at each level instead of one:\\n\\n>>> def mysum(L):\\n        if not L: return 0\\n        return nonempty(L)                  # Call a function that calls me\\n\\n>>> def nonempty(L):\\n        return L[0] + mysum(L[1:])          # Indirectly recursive\\n\\n>>> mysum([1.1, 2.2, 3.3, 4.4])\\n11.0\\n\\nLoop Statements Versus Recursion\\nThough recursion works for summing in the prior sections’ examples, it’s probably\\noverkill in this context. In fact, recursion is not used nearly as often in Python as in\\nmore esoteric languages like Prolog or Lisp, because Python emphasizes simpler pro-\\ncedural statements like loops, which are usually more natural. The while, for example,\\noften makes things a bit more concrete, and it doesn’t require that a function be defined\\nto allow recursive calls:\\n\\n>>> L = [1, 2, 3, 4, 5]\\n>>> sum = 0\\n>>> while L:\\n        sum += L[0]\\n        L = L[1:]\\n\\nRecursive Functions\\n\\n| 557\\n\\n\\x0c>>> sum\\n15\\n\\nBetter yet, for loops iterate for us automatically, making recursion largely extraneous\\nin many cases (and, in all likelihood, less efficient in terms of memory space and exe-\\ncution time):\\n\\n>>> L = [1, 2, 3, 4, 5]\\n>>> sum = 0\\n>>> for x in L: sum += x\\n\\n>>> sum\\n15\\n\\nWith looping statements, we don’t require a fresh copy of a local scope on the call stack\\nfor each iteration, and we avoid the speed costs associated with function calls in general.\\n(Stay tuned for Chapter 21’s timer case study for ways to compare the execution times\\nof alternatives like these.)\\n\\nHandling Arbitrary Structures\\nOn the other hand, recursion—or equivalent explicit stack-based algorithms we’ll meet\\nshortly—can be required to traverse arbitrarily shaped structures. As a simple example\\nof recursion’s role in this context, consider the task of computing the sum of all the\\nnumbers in a nested sublists structure like this:\\n\\n[1, [2, [3, 4], 5], 6, [7, 8]]                   # Arbitrarily nested sublists\\n\\nSimple looping statements won’t work here because this is not a linear iteration. Nested\\nlooping statements do not suffice either, because the sublists may be nested to arbitrary\\ndepth and in an arbitrary shape—there’s no way to know how many nested loops to\\ncode to handle all cases. Instead, the following code accommodates such general nest-\\ning by using recursion to visit sublists along the way:\\n\\n# file sumtree.py\\n\\ndef sumtree(L):\\n    tot = 0\\n    for x in L:                                  # For each item at this level\\n        if not isinstance(x, list):\\n            tot += x                             # Add numbers directly\\n        else:\\n            tot += sumtree(x)                    # Recur for sublists\\n    return tot\\n\\nL = [1, [2, [3, 4], 5], 6, [7, 8]]               # Arbitrary nesting\\nprint(sumtree(L))                                # Prints 36\\n\\n# Pathological cases\\nprint(sumtree([1, [2, [3, [4, [5]]]]]))          # Prints 15 (right-heavy)\\nprint(sumtree([[[[[1], 2], 3], 4], 5]))          # Prints 15 (left-heavy)\\n\\n558 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cTrace through the test cases at the bottom of this script to see how recursion traverses\\ntheir nested lists.\\n\\nRecursion versus queues and stacks\\nIt  sometimes  helps  to  understand  that  internally,  Python  implements  recursion  by\\npushing information on a call stack at each recursive call, so it remembers where it must\\nreturn and continue later. In fact, it’s generally possible to implement recursive-style\\nprocedures without recursive calls, by using an explicit stack or queue of your own to\\nkeep track of remaining steps.\\nFor instance, the following computes the same sums as the prior example, but uses an\\nexplicit list to schedule when it will visit items in the subject, instead of issuing recursive\\ncalls; the item at the front of the list is always the next to be processed and summed:\\n\\ndef sumtree(L):                                  # Breadth-first, explicit queue\\n    tot = 0\\n    items = list(L)                              # Start with copy of top level\\n    while items:\\n        front = items.pop(0)                     # Fetch/delete front item\\n        if not isinstance(front, list):\\n            tot += front                         # Add numbers directly\\n        else:\\n            items.extend(front)                  # <== Append all in nested list\\n    return tot\\n\\nTechnically, this code traverses the list in breadth-first fashion by levels, because it adds\\nnested lists’ contents to the end of the list, forming a first-in-first-out queue. To emulate\\nthe traversal of the recursive call version more closely, we can change it to perform\\ndepth-first traversal simply by adding the content of nested lists to the front of the list, \\nforming a last-in-first-out stack:\\n\\ndef sumtree(L):                                  # Depth-first, explicit stack\\n    tot = 0\\n    items = list(L)                              # Start with copy of top level\\n    while items:\\n        front = items.pop(0)                     # Fetch/delete front item\\n        if not isinstance(front, list):\\n            tot += front                         # Add numbers directly\\n        else:\\n            items[:0] = front                    # <== Prepend all in nested list\\n    return tot\\n\\nFor more on the last two examples (and another variant), see file sumtree2.py in the\\nbook’s examples. It adds items list tracing so you can watch it grow in both schemes,\\nand can show numbers as they are visited so you see the search order. For instance, the\\nbreadth-first and depth-first variants visit items in the same three test lists used for the\\nrecursive version in the following orders, respectively (sums are shown last):\\n\\nc:\\\\code> sumtree2.py\\n1, 6, 2, 5, 7, 8, 3, 4, 36\\n1, 2, 3, 4, 5, 15\\n\\nRecursive Functions\\n\\n| 559\\n\\n\\x0c5, 4, 3, 2, 1, 15\\n----------------------------------------\\n1, 2, 3, 4, 5, 6, 7, 8, 36\\n1, 2, 3, 4, 5, 15\\n1, 2, 3, 4, 5, 15\\n----------------------------------------\\n\\nIn general, though, once you get the hang of recursive calls, they are more natural than\\nthe explicit scheduling lists they automate, and are generally preferred unless you need\\nto traverse structure in specialized ways. Some programs, for example, perform a best-\\nfirst search that requires an explicit search queue ordered by relevance or other criteria.\\nIf you think of a web crawler that scores pages visited by content, the applications may\\nstart to become clearer.\\n\\nCycles, paths, and stack limits\\nAs is, these programs suffice for our example, but larger recursive applications can\\nsometimes require a bit more infrastructure than shown here: they may need to avoid\\ncycles or repeats, record paths taken for later use, and expand stack space when using\\nrecursive calls instead of explicit queues or stacks.\\nFor instance, neither the recursive call nor the explicit queue/stack examples in this\\nsection do anything about avoiding cycles—visiting a location already visited. That’s\\nnot required here, because we’re traversing strictly hierarchical list object trees. If data\\ncan be a cyclic graph, though, both these schemes will fail: the recursive call version\\nwill fall into an infinite recursive loop (and may run out of call-stack space), and the\\nothers will fall into simple infinite loops, re-adding the same items to their lists (and\\nmay or may not run out of general memory). Some programs also need to avoid repeated\\nprocessing for a state reached more than once, even if that wouldn’t lead to a loop.\\nTo do better, the recursive call version could simply keep and pass a set, dictionary, or\\nlist of states visited so far and check for repeats as it goes. We will use this scheme in\\nlater recursive examples in this book:\\n\\n  if state not in visited:\\n      visited.add(state)          # x.add(state), x[state]=True, or x.append(state)\\n      ...proceed...\\n\\nThe nonrecursive alternatives could similarly avoid adding states already visited with\\ncode like the following. Note that checking for duplicates already on the items list\\nwould avoid scheduling a state twice, but would not prevent revisiting a state traversed\\nearlier and hence removed from that list:\\n\\n  visited.add(front)\\n  ...proceed...\\n  items.extend([x for x in front if x not in visited])\\n\\nThis model doesn’t quite apply to this section’s use case that simply adds numbers in\\nlists, but larger applications will be able to identify repeated states—a URL of a previ-\\n\\n560 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cously visited web page, for instance. In fact, we’ll use such techniques to avoid cycles\\nand repeats in later examples listed in the next section.\\nSome programs may also need to record complete paths for each state followed so they\\ncan  report  solutions  when  finished.  In  such  cases,  each  item  in  the  nonrecursive\\nscheme’s stack or queue may be a full path list that suffices for a record of states visited,\\nand contains the next item to explore at either end.\\nAlso note that standard Python limits the depth of its runtime call stack—crucial to\\nrecursive call programs—to trap infinite recursion errors. To expand it, use the sys\\nmodule:\\n\\n>>> sys.getrecursionlimit()         # 1000 calls deep default\\n1000\\n>>> sys.setrecursionlimit(10000)    # Allow deeper nesting\\n>>> help(sys.setrecursionlimit)     # Read more about it\\n\\nThe maximum allowed setting can vary per platform. This isn’t required for programs\\nthat use stacks or queues to avoid recursive calls and gain more control over the traversal\\nprocess.\\n\\nMore recursion examples\\nAlthough this section’s example is artificial, it is representative of a larger class of pro-\\ngrams; inheritance trees and module import chains, for example, can exhibit similarly\\ngeneral structures, and computing structures such as permutations can require arbi-\\ntrarily many nested loops. In fact, we will use recursion again in such roles in more\\nrealistic examples later in this book:\\n\\n• In Chapter 20’s permute.py, to shuffle arbitrary sequences\\n• In Chapter 25’s reloadall.py, to traverse import chains\\n• In Chapter 29’s classtree.py, to traverse class inheritance trees\\n• In Chapter 31’s lister.py, to traverse class inheritance trees again\\n• In Appendix D’s solutions to two exercises at the end of this part of the book:\\n\\ncountdowns and factorials\\n\\nThe second and third of these will also detect states already visited to avoid cycles and\\nrepeats. Although simple loops should generally be preferred to recursion for linear\\niterations on the grounds of simplicity and efficiency, we’ll find that recursion is es-\\nsential in scenarios like those in these later examples.\\nMoreover, you sometimes need to be aware of the potential of unintended recursion in\\nyour programs. As you’ll also see later in the book, some operator overloading methods\\nin classes such as __setattr__ and __getattribute__ and even __repr__ have the po-\\ntential to recursively loop if used incorrectly. Recursion is a powerful tool, but it tends\\nto be best when both understood and expected!\\n\\nRecursive Functions\\n\\n| 561\\n\\n\\x0cFunction Objects: Attributes and Annotations\\nPython functions are more flexible than you might think. As we’ve seen in this part of\\nthe book, functions in Python are much more than code-generation specifications for\\na compiler—Python functions are full-blown objects, stored in pieces of memory all\\ntheir own. As such, they can be freely passed around a program and called indirectly.\\nThey also support operations that have little to do with calls at all—attribute storage\\nand annotation.\\n\\nIndirect Function Calls: “First Class” Objects\\nBecause Python functions are objects, you can write programs that process them ge-\\nnerically. Function objects may be assigned to other names, passed to other functions,\\nembedded in data structures, returned from one function to another, and more, as if\\nthey were simple numbers or strings. Function objects also happen to support a special\\noperation: they can be called by listing arguments in parentheses after a function ex-\\npression. Still, functions belong to the same general category as other objects.\\nThis is usually called a first-class object model; it’s ubiquitous in Python, and a necessary\\npart of functional programming. We’ll explore this programming mode more fully in\\nthis and the next chapter; because its motif is founded on the notion of applying func-\\ntions, functions must be treated as data.\\nWe’ve seen some of these generic use cases for functions in earlier examples, but a quick\\nreview helps to underscore the object model. For example, there’s really nothing special\\nabout the name used in a def statement: it’s just a variable assigned in the current scope,\\nas if it had appeared on the left of an = sign. After a def runs, the function name is simply\\na reference to an object—you can reassign that object to other names freely and call it\\nthrough any reference:\\n\\n>>> def echo(message):                   # Name echo assigned to function object\\n        print(message)\\n\\n>>> echo(\\'Direct call\\')                  # Call object through original name\\nDirect call\\n\\n>>> x = echo                             # Now x references the function too\\n>>> x(\\'Indirect call!\\')                  # Call object through name by adding ()\\nIndirect call!\\n\\nBecause arguments are passed by assigning objects, it’s just as easy to pass functions to\\nother functions as arguments. The callee may then call the passed-in function just by\\nadding arguments in parentheses:\\n\\n>>> def indirect(func, arg):\\n        func(arg)                        # Call the passed-in object by adding ()\\n\\n>>> indirect(echo, \\'Argument call!\\')     # Pass the function to another function\\nArgument call!\\n\\n562 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cYou can even stuff function objects into data structures, as though they were integers\\nor strings. The following, for example, embeds the function twice in a list of tuples, as\\na sort of actions table. Because Python compound types like these can contain any sort\\nof object, there’s no special case here, either:\\n\\n>>> schedule = [ (echo, \\'Spam!\\'), (echo, \\'Ham!\\') ]\\n>>> for (func, arg) in schedule:\\n        func(arg)                        # Call functions embedded in containers\\n\\nSpam!\\nHam!\\n\\nThis code simply steps through the schedule list, calling the echo function with one\\nargument each time through (notice the tuple-unpacking assignment in the for loop\\nheader, introduced in Chapter 13). As we saw in Chapter 17’s examples, functions can\\nalso be created and returned for use elsewhere—the closure created in this mode also\\nretains state from the enclosing scope:\\n\\n>>> def make(label):                     # Make a function but don\\'t call it\\n        def echo(message):\\n            print(label + \\':\\' + message)\\n        return echo\\n\\n>>> F = make(\\'Spam\\')                     # Label in enclosing scope is retained\\n>>> F(\\'Ham!\\')                            # Call the function that make returned\\nSpam:Ham!\\n>>> F(\\'Eggs!\\')\\nSpam:Eggs!\\n\\nPython’s universal first-class object model and lack of type declarations make for an\\nincredibly flexible programming language.\\n\\nFunction Introspection\\nBecause they are objects, we can also process functions with normal object tools. In\\nfact, functions are more flexible than you might expect. For instance, once we make a\\nfunction, we can call it as usual:\\n\\n>>> def func(a):\\n        b = \\'spam\\'\\n        return b * a\\n\\n>>> func(8)\\n\\'spamspamspamspamspamspamspamspam\\'\\n\\nBut the call expression is just one operation defined to work on function objects. We\\ncan also inspect their attributes generically (the following is run in Python 3.3, but 2.X\\nresults are similar):\\n>>> func.__name__\\n\\'func\\'\\n>>> dir(func)\\n[\\'__annotations__\\', \\'__call__\\', \\'__class__\\', \\'__closure__\\', \\'__code__\\',\\n\\nFunction Objects: Attributes and Annotations\\n\\n| 563\\n\\n\\x0c...more omitted: 34 total...\\n\\'__repr__\\', \\'__setattr__\\', \\'__sizeof__\\', \\'__str__\\', \\'__subclasshook__\\']\\n\\nIntrospection tools allow us to explore implementation details too—functions have\\nattached code objects, for example, which provide details on aspects such as the func-\\ntions’ local variables and arguments:\\n\\n>>> func.__code__\\n<code object func at 0x00000000021A6030, file \"<stdin>\", line 1>\\n\\n>>> dir(func.__code__)\\n[\\'__class__\\', \\'__delattr__\\', \\'__dir__\\', \\'__doc__\\', \\'__eq__\\', \\'__format__\\', \\'__ge__\\',\\n...more omitted: 37 total...\\n\\'co_argcount\\', \\'co_cellvars\\', \\'co_code\\', \\'co_consts\\', \\'co_filename\\',\\n\\'co_firstlineno\\', \\'co_flags\\', \\'co_freevars\\', \\'co_kwonlyargcount\\', \\'co_lnotab\\',\\n\\'co_name\\', \\'co_names\\', \\'co_nlocals\\', \\'co_stacksize\\', \\'co_varnames\\']\\n\\n>>> func.__code__.co_varnames\\n(\\'a\\', \\'b\\')\\n>>> func.__code__.co_argcount\\n1\\n\\nTool writers can make use of such information to manage functions (in fact, we will\\ntoo in Chapter 39, to implement validation of function arguments in decorators).\\n\\nFunction Attributes\\nFunction objects are not limited to the system-defined attributes listed in the prior\\nsection, though. As we learned in Chapter 17, it’s been possible to attach arbitrary user-\\ndefined attributes to them as well since Python 2.1:\\n\\n>>> func\\n<function func at 0x000000000296A1E0>\\n>>> func.count = 0\\n>>> func.count += 1\\n>>> func.count\\n1\\n>>> func.handles = \\'Button-Press\\'\\n>>> func.handles\\n\\'Button-Press\\'\\n>>> dir(func)\\n[\\'__annotations__\\', \\'__call__\\', \\'__class__\\', \\'__closure__\\', \\'__code__\\',\\n...and more: in 3.X all others have double underscores so your names won\\'t clash...\\n__str__\\', \\'__subclasshook__\\', \\'count\\', \\'handles\\']\\n\\nPython’s own implementation-related data stored on functions follows naming con-\\nventions that prevent them from clashing with the more arbitrary attribute names you\\nmight assign yourself. In 3.X, all function internals’ names have leading and trailing\\ndouble underscores (“__X__”); 2.X follows the same scheme, but also assigns some\\nnames that begin with “func_X”:\\n\\nc:\\\\code> py −3\\n>>> def f(): pass\\n\\n564 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0c>>> dir(f)\\n...run on your own to see...\\n>>> len(dir(f))\\n34\\n>>> [x for x in dir(f) if not x.startswith(\\'__\\')]\\n[]\\n\\nc:\\\\code> py −2\\n>>> def f(): pass\\n\\n>>> dir(f)\\n...run on your own to see...\\n>>> len(dir(f))\\n31\\n>>> [x for x in dir(f) if not x.startswith(\\'__\\')]\\n[\\'func_closure\\', \\'func_code\\', \\'func_defaults\\', \\'func_dict\\', \\'func_doc\\',\\n\\'func_globals\\', \\'func_name\\']\\n\\nIf you’re careful not to name attributes the same way, you can safely use the function’s\\nnamespace as though it were your own namespace or scope.\\nAs we saw in that chapter, such attributes can be used to attach state information to\\nfunction objects directly, instead of using other techniques such as globals, nonlocals,\\nand classes. Unlike nonlocals, such attributes are accessible anywhere the function itself\\nis, even from outside its code.\\nIn a sense, this is also a way to emulate “static locals” in other languages—variables\\nwhose names are local to a function, but whose values are retained after a function\\nexits. Attributes are related to objects instead of scopes (and must be referenced through\\nthe function name within its code), but the net effect is similar.\\nMoreover, as we learned in Chapter 17, when attributes are attached to functions gen-\\nerated by other factory functions, they also support multiple copy, per-call, and write-\\nable state retention, much like nonlocal closures and class instance attributes.\\n\\nFunction Annotations in 3.X\\nIn Python 3.X (but not 2.X), it’s also possible to attach annotation information—arbi-\\ntrary user-defined data about a function’s arguments and result—to a function object.\\nPython provides special syntax for specifying annotations, but it doesn’t do anything\\nwith them itself; annotations are completely optional, and when present are simply\\nattached to the function object’s __annotations__ attribute for use by other tools. For\\ninstance, such a tool might use annotations in the context of error testing.\\nWe met Python 3.X’s keyword-only arguments in the preceding chapter; annotations\\ngeneralize function header syntax further. Consider the following nonannotated func-\\ntion, which is coded with three arguments and returns a result:\\n\\n>>> def func(a, b, c):\\n        return a + b + c\\n\\nFunction Objects: Attributes and Annotations\\n\\n| 565\\n\\n\\x0c>>> func(1, 2, 3)\\n6\\n\\nSyntactically, function annotations are coded in def header lines, as arbitrary expres-\\nsions associated with arguments and return values. For arguments, they appear after a\\ncolon immediately following the argument’s name; for return values, they are written\\nafter a -> following the arguments list. This code, for example, annotates all three of\\nthe prior function’s arguments, as well as its return value:\\n\\n>>> def func(a: \\'spam\\', b: (1, 10), c: float) -> int:\\n        return a + b + c\\n\\n>>> func(1, 2, 3)\\n6\\n\\nCalls to an annotated function work as usual, but when annotations are present Python\\ncollects them in a dictionary and attaches it to the function object itself. Argument\\nnames become keys, the return value annotation is stored under key “return” if coded\\n(which suffices because this reserved word can’t be used as an argument name), and\\nthe values of annotation keys are assigned to the results of the annotation expressions:\\n\\n>>> func.__annotations__\\n{\\'c\\': <class \\'float\\'>, \\'b\\': (1, 10), \\'a\\': \\'spam\\', \\'return\\': <class \\'int\\'>}\\n\\nBecause  they  are  just  Python  objects  attached  to  a  Python  object,  annotations  are\\nstraightforward to process. The following annotates just two of three arguments and\\nsteps through the attached annotations generically:\\n\\n>>> def func(a: \\'spam\\', b, c: 99):\\n        return a + b + c\\n\\n>>> func(1, 2, 3)\\n6\\n>>> func.__annotations__\\n{\\'c\\': 99, \\'a\\': \\'spam\\'}\\n\\n>>> for arg in func.__annotations__:\\n       print(arg, \\'=>\\', func.__annotations__[arg])\\n\\nc => 99\\na => spam\\n\\nThere are two fine points to note here. First, you can still use defaults for arguments if\\nyou code annotations—the annotation (and its : character) appear before the default\\n(and its = character). In the following, for example, a: \\'spam\\' = 4 means that argument\\na defaults to 4 and is annotated with the string \\'spam\\':\\n\\n>>> def func(a: \\'spam\\' = 4, b: (1, 10) = 5, c: float = 6) -> int:\\n        return a + b + c\\n\\n>>> func(1, 2, 3)\\n6\\n>>> func()                       # 4 + 5 + 6   (all defaults)\\n15\\n\\n566 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0c>>> func(1, c=10)                # 1 + 5 + 10  (keywords work normally)\\n16\\n>>> func.__annotations__\\n{\\'c\\': <class \\'float\\'>, \\'b\\': (1, 10), \\'a\\': \\'spam\\', \\'return\\': <class \\'int\\'>}\\n\\nSecond, note that the blank spaces in the prior example are all optional—you can use\\nspaces between components in function headers or not, but omitting them might de-\\ngrade your code’s readability to some observers (and probably improve it to others!):\\n\\n>>> def func(a:\\'spam\\'=4, b:(1,10)=5, c:float=6)->int:\\n        return a + b + c\\n\\n>>> func(1, 2)                   # 1 + 2 + 6\\n9\\n>>> func.__annotations__\\n{\\'c\\': <class \\'float\\'>, \\'b\\': (1, 10), \\'a\\': \\'spam\\', \\'return\\': <class \\'int\\'>}\\n\\nAnnotations are a new feature in 3.X, and some of their potential uses remain to be\\nuncovered. It’s easy to imagine annotations being used to specify constraints for argu-\\nment types or values, though, and larger APIs might use this feature as a way to register\\nfunction interface information.\\nIn fact, we’ll see a potential application in Chapter 39, where we’ll look at annotations\\nas an alternative to function decorator arguments—a more general concept in which\\ninformation is coded outside the function header and so is not limited to a single role.\\nLike Python itself, annotation is a tool whose roles are shaped by your imagination.\\nFinally, note that annotations work only in def statements, not lambda expressions,\\nbecause lambda’s syntax already limits the utility of the functions it defines. Coinci-\\ndentally, this brings us to our next topic.\\n\\nAnonymous Functions: lambda\\nBesides  the  def  statement,  Python  also  provides  an  expression  form  that  generates\\nfunction  objects.  Because  of  its  similarity  to  a  tool  in  the  Lisp  language,  it’s  called\\nlambda.1 Like def, this expression creates a function to be called later, but it returns the\\nfunction instead of assigning it to a name. This is why lambdas are sometimes known\\nas anonymous (i.e., unnamed) functions. In practice, they are often used as a way to\\ninline a function definition, or to defer execution of a piece of code.\\n\\n1. The lambda tends to intimidate people more than it should. This reaction seems to stem from the name\\n“lambda” itself—a name that comes from the Lisp language, which got it from lambda calculus, which\\nis a form of symbolic logic. In Python, though, it’s really just a keyword that introduces the expression\\nsyntactically. Obscure mathematical heritage aside, lambda is simpler to use than you may think.\\n\\nAnonymous Functions: lambda | 567\\n\\n\\x0clambda Basics\\nThe lambda’s general form is the keyword lambda, followed by one or more arguments\\n(exactly like the arguments list you enclose in parentheses in a def header), followed\\nby an expression after a colon:\\n\\nlambda argument1, argument2,... argumentN : expression using arguments\\n\\nFunction objects returned by running  lambda expressions work exactly the same as\\nthose created and assigned by defs, but there are a few differences that make lambdas\\nuseful in specialized roles:\\n\\n• lambda is an expression, not a statement. Because of this, a lambda can appear in\\nplaces a def is not allowed by Python’s syntax—inside a list literal or a function\\ncall’s arguments, for example. With def, functions can be referenced by name but\\nmust be created elsewhere. As an expression, lambda returns a value (a new func-\\ntion) that can optionally be assigned a name. In contrast, the def statement always\\nassigns the new function to the name in the header, instead of returning it as a\\nresult.\\n\\n• lambda’s body is a single expression, not a block of statements. The lambda’s\\nbody is similar to what you’d put in a def body’s return statement; you simply type\\nthe result as a naked expression, instead of explicitly returning it. Because it is\\nlimited to an expression, a lambda is less general than a def—you can only squeeze\\nso much logic into a lambda body without using statements such as if. This is by\\ndesign, to limit program nesting: lambda is designed for coding simple functions,\\nand def handles larger tasks.\\n\\nApart from those distinctions, defs and lambdas do the same sort of work. For instance,\\nwe’ve seen how to make a function with a def statement:\\n\\n>>> def func(x, y, z): return x + y + z\\n\\n>>> func(2, 3, 4)\\n9\\n\\nBut you can achieve the same effect with a lambda expression by explicitly assigning its\\nresult to a name through which you can later call the function:\\n\\n>>> f = lambda x, y, z: x + y + z\\n>>> f(2, 3, 4)\\n9\\n\\nHere, f is assigned the function object the lambda expression creates; this is how def\\nworks, too, but its assignment is automatic.\\nDefaults work on lambda arguments, just like in a def:\\n>>> x = (lambda a=\"fee\", b=\"fie\", c=\"foe\": a + b + c)\\n>>> x(\"wee\")\\n\\'weefiefoe\\'\\n\\n568 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cThe code in a lambda body also follows the same scope lookup rules as code inside a\\ndef. lambda expressions introduce a local scope much like a nested def, which auto-\\nmatically sees names in enclosing functions, the module, and the built-in scope (via the\\nLEGB rule, and per Chapter 17):\\n\\n>>> def knights():\\n        title = \\'Sir\\'\\n        action = (lambda x: title + \\' \\' + x)      # Title in enclosing def scope\\n        return action                             # Return a function object\\n\\n>>> act = knights()\\n>>> msg = act(\\'robin\\')                            # \\'robin\\' passed to x\\n>>> msg\\n\\'Sir robin\\'\\n\\n>>> act                                           # act: a function, not its result\\n<function knights.<locals>.<lambda> at 0x00000000029CA488>\\n\\nIn this example, prior to Release 2.2, the value for the name title would typically have\\nbeen passed in as a default argument value instead; flip back to the scopes coverage in\\nChapter 17 if you’ve forgotten why.\\n\\nWhy Use lambda?\\nGenerally speaking, lambda comes in handy as a sort of function shorthand that allows\\nyou to embed a function’s definition within the code that uses it. They are entirely\\noptional—you can always use def instead, and should if your function requires the\\npower of full statements that the lambda’s expression cannot easily provide—but they\\ntend to be simpler coding constructs in scenarios where you just need to embed small\\nbits of executable code inline at the place it is to be used.\\nFor  instance,  we’ll  see  later  that  callback  handlers  are  frequently  coded  as  inline\\nlambda expressions embedded directly in a registration call’s arguments list, instead of\\nbeing defined with a def elsewhere in a file and referenced by name (see the sidebar\\n“Why You Will Care: lambda Callbacks” on page 573 for an example).\\nlambda is also commonly used to code jump tables, which are lists or dictionaries of\\nactions to be performed on demand. For example:\\n\\nL = [lambda x: x ** 2,               # Inline function definition\\n     lambda x: x ** 3,\\n     lambda x: x ** 4]               # A list of three callable functions\\n\\nfor f in L:\\n    print(f(2))                      # Prints 4, 8, 16\\n\\nprint(L[0](3))                       # Prints 9\\n\\nThe lambda expression is most useful as a shorthand for def, when you need to stuff\\nsmall pieces of executable code into places where statements are illegal syntactically.\\nThe preceding code snippet, for example, builds up a list of three functions by embed-\\n\\nAnonymous Functions: lambda | 569\\n\\n\\x0cding lambda expressions inside a list literal; a def won’t work inside a list literal like this\\nbecause it is a statement, not an expression. The equivalent def coding would require\\ntemporary function names (which might clash with others) and function definitions\\noutside the context of intended use (which might be hundreds of lines away):\\n\\ndef f1(x): return x ** 2\\ndef f2(x): return x ** 3             # Define named functions\\ndef f3(x): return x ** 4\\n\\nL = [f1, f2, f3]                     # Reference by name\\n\\nfor f in L:\\n    print(f(2))                      # Prints 4, 8, 16\\n\\nprint(L[0](3))                       # Prints 9\\n\\nMultiway branch switches: The finale\\nIn fact, you can do the same sort of thing with dictionaries and other data structures\\nin Python to build up more general sorts of action tables. Here’s another example to\\nillustrate, at the interactive prompt:\\n\\n>>> key = \\'got\\'\\n>>> {\\'already\\': (lambda: 2 + 2),\\n     \\'got\\':     (lambda: 2 * 4),\\n     \\'one\\':     (lambda: 2 ** 6)}[key]()\\n8\\n\\nHere, when Python makes the temporary dictionary, each of the nested lambdas gen-\\nerates and leaves behind a function to be called later. Indexing by key fetches one of\\nthose functions, and parentheses force the fetched function to be called. When coded\\nthis way, a dictionary becomes a more general multiway branching tool than what I\\ncould fully show you in Chapter 12’s coverage of if statements.\\nTo make this work without lambda, you’d need to instead code three def statements\\nsomewhere else in your file, outside the dictionary in which the functions are to be\\nused, and reference the functions by name:\\n\\n>>> def f1(): return 2 + 2\\n\\n>>> def f2(): return 2 * 4\\n\\n>>> def f3(): return 2 ** 6\\n\\n>>> key = \\'one\\'\\n>>> {\\'already\\': f1, \\'got\\': f2, \\'one\\': f3}[key]()\\n64\\n\\nThis works, too, but your defs may be arbitrarily far away in your file, even if they are\\njust little bits of code. The code proximity that lambdas provide is especially useful for\\nfunctions that will only be used in a single context—if the three functions here are not\\nuseful anywhere else, it makes sense to embed their definitions within the dictionary\\n\\n570 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cas  lambdas.  Moreover,  the  def  form  requires  you  to  make  up  names  for  these  little\\nfunctions that may clash with other names in this file (perhaps unlikely, but always\\npossible).2\\nlambdas also come in handy in function-call argument lists as a way to inline temporary\\nfunction definitions not used anywhere else in your program; we’ll see some examples\\nof such other uses later in this chapter, when we study map.\\n\\nHow (Not) to Obfuscate Your Python Code\\nThe fact that the body of a lambda has to be a single expression (not a series of state-\\nments)  would  seem  to  place  severe  limits  on  how  much  logic  you  can  pack  into  a\\nlambda.  If  you  know  what  you’re  doing,  though,  you  can  code  most  statements  in\\nPython as expression-based equivalents.\\nFor  example,  if  you  want  to  print  from  the  body  of  a  lambda  function,  simply  say\\nprint(X) in Python 3.X where this becomes a call expression instead of a statement, or\\nsay sys.stdout.write(str(X)+\\'\\\\n\\') in either Python 2.X or 3.X to make sure it’s an\\nexpression portably (recall from Chapter 11 that this is what print really does). Simi-\\nlarly, to nest selection logic in a lambda, you can use the if/else ternary expression\\nintroduced in Chapter 12, or the equivalent but trickier and/or combination also de-\\nscribed there. As you learned earlier, the following statement:\\n\\nif a:\\n    b\\nelse:\\n    c\\n\\ncan be emulated by either of these roughly equivalent expressions:\\n\\nb if a else c\\n((a and b) or c)\\n\\nBecause expressions like these can be placed inside a lambda, they may be used to im-\\nplement selection logic within a lambda function:\\n\\n>>> lower = (lambda x, y: x if x < y else y)\\n>>> lower(\\'bb\\', \\'aa\\')\\n\\'aa\\'\\n>>> lower(\\'aa\\', \\'bb\\')\\n\\'aa\\'\\n\\n2. A student once noted that you could skip the dispatch table dictionary in such code if the function name\\nis the same as its string lookup key—run an eval(funcname)() to kick off the call. While true in this case\\nand sometimes useful, as we saw earlier (e.g., Chapter 10), eval is relatively slow (it must compile and\\nrun  code),  and  insecure  (you  must  trust  the  string’s  source).  More  fundamentally,  jump  tables  are\\ngenerally subsumed by polymorphic method dispatch in Python: calling a method does the “right thing”\\nbased on the type of object. To see why, stay tuned for Part VI.\\n\\nAnonymous Functions: lambda | 571\\n\\n\\x0cFurthermore, if you need to perform loops within a lambda, you can also embed things\\nlike map calls and list comprehension expressions—tools we met in earlier chapters and\\nwill revisit in this and the next chapter:\\n\\n>>> import sys\\n>>> showall = lambda x: list(map(sys.stdout.write, x))        # 3.X: must use list\\n>>> t = showall([\\'spam\\\\n\\', \\'toast\\\\n\\', \\'eggs\\\\n\\'])              # 3.X: can use print\\nspam\\ntoast\\neggs\\n>>> showall = lambda x: [sys.stdout.write(line) for line in x]\\n>>> t = showall((\\'bright\\\\n\\', \\'side\\\\n\\', \\'of\\\\n\\', \\'life\\\\n\\'))\\nbright\\nside\\nof\\nlife\\n>>> showall = lambda x: [print(line, end=\\'\\') for line in x]   # Same: 3.X only\\n>>> showall = lambda x: print(*x, sep=\\'\\', end=\\'\\')             # Same: 3.X only\\n\\nThere is a limit to emulating statements with expressions: you can’t directly achieve an\\nassignment statement’s effect, for instance, though tools like the setattr built-in, the\\n__dict__ of namespaces, and methods that change mutable objects in place can some-\\ntimes stand in, and functional programming techniques can take you deep into the dark\\nrealm of convoluted expression.\\nNow that I’ve shown you these tricks, I am required to ask you to please only use them\\nas a last resort. Without due care, they can lead to unreadable (a.k.a. obfuscated) Python\\ncode. In general, simple is better than complex, explicit is better than implicit, and full\\nstatements are better than arcane expressions. That’s why lambda is limited to expres-\\nsions. If you have larger logic to code, use def; lambda is for small pieces of inline code.\\nOn the other hand, you may find these techniques useful in moderation.\\n\\nScopes: lambdas Can Be Nested Too\\nlambdas are the main beneficiaries of nested function scope lookup (the E in the LEGB\\nscope rule we studied in Chapter 17). As a review, in the following the lambda appears\\ninside a def—the typical case—and so can access the value that the name x had in the\\nenclosing function’s scope at the time that the enclosing function was called:\\n\\n>>> def action(x):\\n        return (lambda y: x + y)         # Make and return function, remember x\\n\\n>>> act = action(99)\\n>>> act\\n<function action.<locals>.<lambda> at 0x00000000029CA2F0>\\n>>> act(2)                               # Call what action returned\\n101\\n\\nWhat  wasn’t  illustrated  in  the  prior  discussion  of  nested  function  scopes  is  that  a\\nlambda also has access to the names in any enclosing lambda. This case is somewhat\\nobscure, but imagine if we recoded the prior def with a lambda:\\n\\n572 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0c>>> action = (lambda x: (lambda y: x + y))\\n>>> act = action(99)\\n>>> act(3)\\n102\\n>>> ((lambda x: (lambda y: x + y))(99))(4)\\n103\\n\\nHere, the nested lambda structure makes a function that makes a function when called.\\nIn both cases, the nested lambda’s code has access to the variable x in the enclosing\\nlambda. This works, but it seems fairly convoluted code; in the interest of readability,\\nnested lambdas are generally best avoided.\\n\\nWhy You Will Care: lambda Callbacks\\n\\nAnother very common application of lambda is to define inline callback functions for\\nPython’s tkinter GUI API (this module is named Tkinter in Python 2.X). For example,\\nthe following creates a button that prints a message on the console when pressed, as-\\nsuming tkinter is available on your computer (it is by default on Windows, Mac, Linux,\\nand other OSs):\\n\\nimport sys\\nfrom tkinter import Button, mainloop  # Tkinter in 2.X\\nx = Button(\\n        text=\\'Press me\\',\\n        command=(lambda:sys.stdout.write(\\'Spam\\\\n\\')))  # 3.X: print()\\nx.pack()\\nmainloop() # This may be optional in console mode\\n\\nHere, we register the callback handler by passing a function generated with a lambda to\\nthe command keyword argument. The advantage of lambda over def here is that the code\\nthat handles a button press is right here, embedded in the button-creation call.\\nIn effect, the lambda defers execution of the handler until the event occurs: the write\\ncall happens on button presses, not when the button is created, and effectively “knows”\\nthe string it should write when the event occurs.\\nBecause the nested function scope rules apply to lambdas as well, they are also easier to\\nuse as callback handlers, as of Python 2.2—they automatically see names in the func-\\ntions in which they are coded and no longer require passed-in defaults in most cases.\\nThis is especially handy for accessing the special self instance argument that is a local\\nvariable in enclosing class method functions (more on classes in Part VI):\\n\\nclass MyGui:\\n    def makewidgets(self):\\n        Button(command=(lambda: self.onPress(\"spam\")))\\n    def onPress(self, message):\\n        ...use message...\\n\\nIn early versions of Python, even self had to be passed in to a lambda with defaults. As\\nwe’ll see later, class objects with __call__ and bound methods often serve in callback\\nroles too—watch for coverage of these in Chapter 30 and Chapter 31.\\n\\nAnonymous Functions: lambda | 573\\n\\n\\x0cFunctional Programming Tools\\nBy most definitions, today’s Python blends support for multiple programming para-\\ndigms: procedural (with its basic statements), object-oriented (with its classes), and\\nfunctional. For the latter of these, Python includes a set of built-ins used for functional\\nprogramming—tools that apply functions to sequences and other iterables. This set\\nincludes tools that call functions on an iterable’s items (map); filter out items based on\\na  test  function  (filter);  and  apply  functions  to  pairs  of  items  and  running  results\\n(reduce).\\nThough the boundaries are sometimes a bit grey, by most definitions Python’s func-\\ntional programming arsenal also includes the first-class object model explored earlier,\\nthe nested scope closures and anonymous function lambdas we met earlier in this part\\nof  the  book,  the  generators  and  comprehensions  we’ll  be  expanding  on  in  the  next\\nchapter, and perhaps the function and class decorators of this book’s final part. For our\\npurposes here, let’s wrap up this chapter with a quick survey of built-in functions that\\napply other functions to iterables automatically.\\n\\nMapping Functions over Iterables: map\\nOne of the more common things programs do with lists and other sequences is apply\\nan operation to each item and collect the results—selecting columns in database tables,\\nincrementing pay fields of employees in a company, parsing email attachments, and so\\non. Python has multiple tools that make such collection-wide operations easy to code.\\nFor instance, updating all the counters in a list can be done easily with a for loop:\\n\\n>>> counters = [1, 2, 3, 4]\\n>>>\\n>>> updated = []\\n>>> for x in counters:\\n        updated.append(x + 10)                 # Add 10 to each item\\n\\n>>> updated\\n[11, 12, 13, 14]\\n\\nBut because this is such a common operation, Python also provides built-ins that do\\nmost of the work for you. The map function applies a passed-in function to each item\\nin an iterable object and returns a list containing all the function call results. For ex-\\nample:\\n\\n>>> def inc(x): return x + 10                  # Function to be run\\n\\n>>> list(map(inc, counters))                   # Collect results\\n[11, 12, 13, 14]\\n\\nWe met map briefly in Chapter 13 and Chapter 14, as a way to apply a built-in function\\nto items in an iterable. Here, we make more general use of it by passing in a  user-\\ndefined function to be applied to each item in the list—map calls inc on each list item\\nand collects all the return values into a new list. Remember that map is an iterable in\\n\\n574 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cPython 3.X, so a list call is used to force it to produce all its results for display here;\\nthis isn’t necessary in 2.X (see Chapter 14 if you’ve forgotten this requirement).\\nBecause map expects a function to be passed in and applied, it also happens to be one\\nof the places where lambda commonly appears:\\n\\n>>> list(map((lambda x: x + 3), counters))     # Function expression\\n[4, 5, 6, 7]\\n\\nHere, the function adds 3 to each item in the counters list; as this little function isn’t\\nneeded elsewhere, it was written inline as a lambda. Because such uses of map are equiv-\\nalent to for loops, with a little extra code you can always code a general mapping utility\\nyourself:\\n\\n>>> def mymap(func, seq):\\n        res = []\\n        for x in seq: res.append(func(x))\\n        return res\\n\\nAssuming the function inc is still as it was when it was shown previously, we can map\\nit across a sequence (or other iterable) with either the built-in or our equivalent:\\n\\n>>> list(map(inc, [1, 2, 3]))             # Built-in is an iterable\\n[11, 12, 13]\\n>>> mymap(inc, [1, 2, 3])                 # Ours builds a list (see generators)\\n[11, 12, 13]\\n\\nHowever, as map is a built-in, it’s always available, always works the same way, and has\\nsome performance benefits (as we’ll prove in Chapter 21, it’s faster than a manually\\ncoded for loop in some usage modes). Moreover, map can be used in more advanced\\nways than shown here. For instance, given multiple sequence arguments, it sends items\\ntaken from sequences in parallel as distinct arguments to the function:\\n\\n>>> pow(3, 4)                             # 3**4\\n81\\n>>> list(map(pow, [1, 2, 3], [2, 3, 4]))  # 1**2, 2**3, 3**4\\n[1, 8, 81]\\n\\nWith multiple sequences, map expects an N-argument function for N sequences. Here,\\nthe pow function takes two arguments on each call—one from each sequence passed to\\nmap. It’s not much extra work to simulate this multiple-sequence generality in code,\\ntoo, but we’ll postpone doing so until later in the next chapter, after we’ve met some\\nadditional iteration tools.\\nThe  map  call  is  similar  to  the  list  comprehension  expressions  we  studied  in  Chap-\\nter 14 and will revisit in the next chapter from a functional perspective:\\n\\n>>> list(map(inc, [1, 2, 3, 4]))\\n[11, 12, 13, 14]\\n>>> [inc(x) for x in [1, 2, 3, 4]]        # Use () parens to generate items instead\\n[11, 12, 13, 14]\\n\\nIn some cases, map may be faster to run than a list comprehension (e.g., when mapping\\na built-in function), and it may also require less coding. On the other hand, because\\n\\nFunctional Programming Tools\\n\\n| 575\\n\\n\\x0cmap applies a function call to each item instead of an arbitrary expression, it is a somewhat\\nless general tool, and often requires extra helper functions or lambdas. Moreover, wrap-\\nping a comprehension in parentheses instead of square brackets creates an object that\\ngenerates values on request to save memory and increase responsiveness, much like\\nmap in 3.X—a topic we’ll take up in the next chapter.\\n\\nSelecting Items in Iterables: filter\\nThe map function is a primary and relatively straightforward representative of Python’s\\nfunctional programming toolset. Its close relatives, filter and reduce, select an itera-\\nble’s items based on a test function and apply functions to item pairs, respectively.\\nBecause it also returns an iterable, filter (like range) requires a list call to display all\\nits results in 3.X. For example, the following filter call picks out items in a sequence\\nthat are greater than zero:\\n\\n>>> list(range(−5, 5))                                   # An iterable in 3.X\\n[−5, −4, −3, −2, −1, 0, 1, 2, 3, 4]\\n\\n>>> list(filter((lambda x: x > 0), range(−5, 5)))        # An iterable in 3.X\\n[1, 2, 3, 4]\\n\\nWe met filter briefly earlier in a Chapter 12 sidebar, and while exploring 3.X iterables\\nin Chapter 14. Items in the sequence or iterable for which the function returns a true\\nresult are added to the result list. Like map, this function is roughly equivalent to a for\\nloop, but it is built-in, concise, and often fast:\\n\\n>>> res = []\\n>>> for x in range(−5, 5):                               # The statement equivalent\\n        if x > 0:\\n            res.append(x)\\n\\n>>> res\\n[1, 2, 3, 4]\\n\\nAlso like map, filter can be emulated by list comprehension syntax with often-simpler\\nresults (especially when it can avoid creating a new function), and with a similar gen-\\nerator expression when delayed production of results is desired—though we’ll save the\\nrest of this story for the next chapter:\\n\\n>>> [x for x in range(−5, 5) if x > 0]                   # Use () to generate items\\n[1, 2, 3, 4]\\n\\nCombining Items in Iterables: reduce\\nThe functional reduce call, which is a simple built-in function in 2.X but lives in the\\nfunctools module in 3.X, is more complex. It accepts an iterable to process, but it’s not\\nan iterable itself—it returns a single result. Here are two reduce calls that compute the\\nsum and product of the items in a list:\\n\\n576 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0c>>> from functools import reduce                         # Import in 3.X, not in 2.X\\n>>> reduce((lambda x, y: x + y), [1, 2, 3, 4])\\n10\\n>>> reduce((lambda x, y: x * y), [1, 2, 3, 4])\\n24\\n\\nAt each step, reduce passes the current sum or product, along with the next item from\\nthe list, to the passed-in  lambda function. By default, the first item in the sequence\\ninitializes the starting value. To illustrate, here’s the for loop equivalent to the first of\\nthese calls, with the addition hardcoded inside the loop:\\n\\n>>> L = [1,2,3,4]\\n>>> res = L[0]\\n>>> for x in L[1:]:\\n        res = res + x\\n\\n>>> res\\n10\\n\\nCoding your own version of reduce is actually fairly straightforward. The following\\nfunction emulates most of the built-in’s behavior and helps demystify its operation in\\ngeneral:\\n\\n>>> def myreduce(function, sequence):\\n        tally = sequence[0]\\n        for next in sequence[1:]:\\n            tally = function(tally, next)\\n        return tally\\n\\n>>> myreduce((lambda x, y: x + y), [1, 2, 3, 4, 5])\\n15\\n>>> myreduce((lambda x, y: x * y), [1, 2, 3, 4, 5])\\n120\\n\\nThe built-in reduce also allows an optional third argument placed before the items in\\nthe sequence to serve as a default result when the sequence is empty, but we’ll leave\\nthis extension as a suggested exercise.\\nIf this coding technique has sparked your interest, you might also be interested in the\\nstandard library operator module, which provides functions that correspond to built-\\nin expressions and so comes in handy for some uses of functional tools (see Python’s\\nlibrary manual for more details on this module):\\n\\n>>> import operator, functools\\n>>> functools.reduce(operator.add, [2, 4, 6])        # Function-based +\\n12\\n>>> functools.reduce((lambda x, y: x + y), [2, 4, 6])\\n12\\n\\nTogether, map, filter, and reduce support powerful functional programming techni-\\nques. As mentioned, many observers would also extend the functional programming\\ntoolset in Python to include nested function scope closures (a.k.a. factory functions)\\nand the anonymous function lambda—both discussed earlier—as well as generators and\\ncomprehensions, topics we will return to in the next chapter.\\n\\nFunctional Programming Tools\\n\\n| 577\\n\\n\\x0cChapter Summary\\nThis chapter took us on a tour of advanced function-related concepts: recursive func-\\ntions; function annotations; lambda expression functions; functional tools such as map,\\nfilter, and reduce; and general function design ideas. The next chapter continues the\\nadvanced  topics  motif  with  a  look  at  generators  and  a  reprisal  of  iterables  and  list\\ncomprehensions—tools that are just as related to functional programming as to looping\\nstatements.  Before  you  move  on,  though,  make  sure  you’ve  mastered  the  concepts\\ncovered here by working through this chapter’s quiz.\\n\\nTest Your Knowledge: Quiz\\n1. How are lambda expressions and def statements related?\\n2. What’s the point of using lambda?\\n3. Compare and contrast map, filter, and reduce.\\n4. What are function annotations, and how are they used?\\n5. What are recursive functions, and how are they used?\\n6. What are some general design guidelines for coding functions?\\n7. Name three or more ways that functions can communicate results to a caller.\\n\\nTest Your Knowledge: Answers\\n1. Both lambda and def create function objects to be called later. Because lambda is an\\nexpression, though, it returns a function object instead of assigning it to a name,\\nand it can be used to nest a function definition in places where a def will not work\\nsyntactically. A lambda allows for only a single implicit return value expression,\\nthough; because it does not support a block of statements, it is not ideal for larger\\nfunctions.\\n\\n2. lambdas allow us to “inline” small units of executable code, defer its execution, and\\nprovide it with state in the form of default arguments and enclosing scope variables.\\nUsing a lambda is never required; you can always code a def instead and reference\\nthe function by name. lambdas come in handy, though, to embed small pieces of\\ndeferred code that are unlikely to be used elsewhere in a program. They commonly\\nappear in callback-based programs such as GUIs, and they have a natural affinity\\nwith functional tools like map and filter that expect a processing function.\\n\\n3. These three built-in functions all apply another function to items in a sequence (or\\nother iterable) object and collect results. map passes each item to the function and\\ncollects all results, filter collects items for which the function returns a True value,\\nand reduce computes a single value by applying the function to an accumulator\\n\\n578 | Chapter 19:\\u2002Advanced Function Topics\\n\\n\\x0cand successive items. Unlike the other two, reduce is available in the functools\\nmodule in 3.X, not the built-in scope; reduce is a built-in in 2.X.\\n\\n4. Function annotations, available in 3.X (3.0 and later), are syntactic embellishments\\nof a function’s arguments and result, which are collected into a dictionary assigned\\nto the function’s __annotations__ attribute. Python places no semantic meaning\\non these annotations, but simply packages them for potential use by other tools.\\n5. Recursive functions call themselves either directly or indirectly in order to loop.\\nThey may be used to traverse arbitrarily shaped structures, but they can also be\\nused for iteration in general (though the latter role is often more simply and effi-\\nciently coded with looping statements). Recursion can often be simulated or re-\\nplaced by code that uses explicit stacks or queues to have more control over tra-\\nversals.\\n\\n6. Functions should generally be small and as self-contained as possible, have a single\\nunified purpose, and communicate with other components through input argu-\\nments and return values. They may use mutable arguments to communicate results\\ntoo if changes are expected, and some types of programs imply other communi-\\ncation mechanisms.\\n\\n7. Functions can send back results with return statements, by changing passed-in\\nmutable arguments, and by setting global variables. Globals are generally frowned\\nupon (except for very special cases, like multithreaded programs) because they can\\nmake code more difficult to understand and use. return statements are usually\\nbest, but changing mutables is fine (and even useful), if expected. Functions may\\nalso communicate results with system devices such as files and sockets, but these\\nare beyond our scope here.\\n\\nTest Your Knowledge: Answers\\n\\n| 579\\n\\n\\x0c\\x0cCHAPTER 20\\nComprehensions and Generations\\n\\nThis chapter continues the advanced function topics theme, with a reprisal of the com-\\nprehension and iteration concepts previewed in Chapter 4 and introduced in Chap-\\nter 14. Because comprehensions are as much related to the prior chapter’s functional\\ntools (e.g., map and filter) as they are to for loops, we’ll revisit them in this context\\nhere. We’ll also take a second look at iterables in order to study generator functions and\\ntheir generator expression relatives—user-defined ways to produce results on demand.\\nIteration in Python also encompasses user-defined classes, but we’ll defer that final part\\nof this story until Part VI, when we study operator overloading. As this is the last pass\\nwe’ll make over built-in iteration tools, though, we will summarize the various tools\\nwe’ve met thus far. The next chapter continues this thread by timing the relative per-\\nformance of these tools as a larger case study. Before that, though, let’s continue the\\ncomprehensions and iterations story, and extend it to include value generators.\\n\\nList Comprehensions and Functional Tools\\nAs mentioned early in this book, Python supports the procedural, object-oriented, and\\nfunction programming paradigms. In fact, Python has a host of tools that most would\\nconsidered functional in nature, which we enumerated in the preceding chapter—clo-\\nsures, generators, lambdas, comprehensions, maps, decorators, function objects, and\\nmore. These tools allow us to apply and combine functions in powerful ways, and often\\noffer state retention and coding solutions that are alternatives to classes and OOP.\\nFor instance, the prior chapter explored tools such as map and filter—key members\\nof Python’s early functional programming toolset inspired by the Lisp language—that\\nmap operations over iterables and collect results. Because this is such a common task\\nin Python coding, Python eventually sprouted a new expression—the list comprehen-\\nsion—that is even more flexible than the tools we just studied.\\nPer Python history, list comprehensions were originally inspired by a similar tool in the\\nfunctional programming language Haskell, around the time of Python 2.0. In short, list\\ncomprehensions apply an arbitrary expression to items in an iterable, rather than ap-\\n\\n581\\n\\n\\x0cplying a function. Accordingly, they can be more general tools. In later releases, the\\ncomprehension was extended to other roles—sets, dictionaries, and even the value\\ngenerator expressions we’ll explore in this chapter. It’s not just for lists anymore.\\nWe first met list comprehensions in Chapter 4’s preview, and studied them further in\\nChapter 14, in conjunction with looping statements. Because they’re also related to\\nfunctional programming tools like the map and filter calls, though, we’ll resurrect the\\ntopic here for one last look. Technically, this feature is not tied to functions—as we’ll\\nsee, list comprehensions can be a more general tool than map and filter—but it is\\nsometimes best understood by analogy to function-based alternatives.\\n\\nList Comprehensions Versus map\\nLet’s  work  through  an  example  that  demonstrates  the  basics.  As  we  saw  in  Chap-\\nter 7, Python’s built-in ord function returns the integer code point of a single character\\n(the chr built-in is the converse—it returns the character for an integer code point).\\nThese happen to be ASCII codes if your characters fall into the ASCII character set’s 7-\\nbit code point range:\\n\\n>>> ord(\\'s\\')\\n115\\n\\nNow, suppose we wish to collect the ASCII codes of all characters in an entire string.\\nPerhaps the most straightforward approach is to use a simple for loop and append the\\nresults to a list:\\n>>> res = []\\n>>> for x in \\'spam\\':\\n        res.append(ord(x))                # Manual results collection\\n\\n>>> res\\n[115, 112, 97, 109]\\n\\nNow that we know about map, though, we can achieve similar results with a single\\nfunction call without having to manage list construction in the code:\\n\\n>>> res = list(map(ord, \\'spam\\'))          # Apply function to sequence (or other)\\n>>> res\\n[115, 112, 97, 109]\\n\\nHowever, we can get the same results from a list comprehension expression—while\\nmap maps a function over an iterable, list comprehensions map an expression over a\\nsequence or other iterable:\\n\\n>>> res = [ord(x) for x in \\'spam\\']        # Apply expression to sequence (or other)\\n>>> res\\n[115, 112, 97, 109]\\n\\nList comprehensions collect the results of applying an arbitrary expression to an iterable\\nof values and return them in a new list. Syntactically, list comprehensions are enclosed\\nin square brackets—to remind you that they construct lists. In their simple form, within\\n\\n582 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cthe brackets you code an expression that names a variable followed by what looks like\\na for loop header that names the same variable. Python then collects the expression’s\\nresults for each iteration of the implied loop.\\nThe effect of the preceding example is similar to that of the manual for loop and the\\nmap call. List comprehensions become more convenient, though, when we wish to apply\\nan arbitrary expression to an iterable instead of a function:\\n\\n>>> [x ** 2 for x in range(10)]\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\\n\\nHere, we’ve collected the squares of the numbers 0 through 9 (we’re just letting the\\ninteractive prompt print the resulting list object; assign it to a variable if you need to\\nretain it). To do similar work with a map call, we would probably need to invent a little\\nfunction to implement the square operation. Because we won’t need this function else-\\nwhere, we’d typically (but not necessarily) code it inline, with a lambda, instead of using\\na def statement elsewhere:\\n\\n>>> list(map((lambda x: x ** 2), range(10)))\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\\n\\nThis does the same job, and it’s only a few keystrokes longer than the equivalent list\\ncomprehension. It’s also only marginally more complex (at least, once you understand\\nthe lambda). For more advanced kinds of expressions, though, list comprehensions will\\noften require considerably less typing. The next section shows why.\\n\\nAdding Tests and Nested Loops: filter\\nList comprehensions are even more general than shown so far. For instance, as we\\nlearned in Chapter 14, you can code an if clause after the for to add selection logic.\\nList comprehensions with if clauses can be thought of as analogous to the filter built-\\nin discussed in the preceding chapter—they skip an iterable’s items for which the if\\nclause is not true.\\nTo demonstrate, following are both schemes picking up even numbers from 0 to 4; like\\nthe map list comprehension alternative of the prior section, the filter version here must\\ninvent a little lambda function for the test expression. For comparison, the equivalent\\nfor loop is shown here as well:\\n\\n>>> [x for x in range(5) if x % 2 == 0]\\n[0, 2, 4]\\n\\n>>> list(filter((lambda x: x % 2 == 0), range(5)))\\n[0, 2, 4]\\n\\n>>> res = []\\n>>> for x in range(5):\\n        if x % 2 == 0:\\n            res.append(x)\\n\\nList Comprehensions and Functional Tools\\n\\n| 583\\n\\n\\x0c>>> res\\n[0, 2, 4]\\n\\nAll of these use the modulus (remainder of division) operator, %, to detect even numbers:\\nif there is no remainder after dividing a number by 2, it must be even. The filter call\\nhere is not much longer than the list comprehension either. However, we can combine\\nan if clause and an arbitrary expression in our list comprehension, to give it the effect\\nof a filter and a map, in a single expression:\\n\\n>>> [x ** 2 for x in range(10) if x % 2 == 0]\\n[0, 4, 16, 36, 64]\\n\\nThis time, we collect the squares of the even numbers from 0 through 9: the for loop\\nskips numbers for which the attached if clause on the right is false, and the expression\\non the left computes the squares. The equivalent map call would require a lot more work\\non our part—we would have to combine filter selections with map iteration, making\\nfor a noticeably more complex expression:\\n\\n>>> list( map((lambda x: x**2), filter((lambda x: x % 2 == 0), range(10))) )\\n[0, 4, 16, 36, 64]\\n\\nFormal comprehension syntax\\nIn fact, list comprehensions are more general still. In their simplest form, you must\\nalways code an accumulation expression and a single for clause:\\n\\n[ expression for target in iterable ]\\n\\nThough all other parts are optional, they allow richer iterations to be expressed—you\\ncan code any number of nested for loops in a list comprehension, and each may have\\nan optional associated if test to act as a filter. The general structure of list compre-\\nhensions looks like this:\\n\\n[ expression for target1 in iterable1 if condition1\\n             for target2 in iterable2 if condition2 ...\\n             for targetN in iterableN if conditionN ]\\n\\nThis  same  syntax  is  inherited  by  set  and  dictionary  comprehensions  as  well  as  the\\ngenerator expressions coming up, though these use different enclosing characters (curly\\nbraces or often-optional parentheses), and the dictionary comprehension begins with\\ntwo expressions separated by a colon (for key and value).\\nWe experimented with the if filter clause in the previous section. When for clauses\\nare nested within a list comprehension, they work like equivalent nested for loop state-\\nments. For example:\\n\\n>>> res = [x + y for x in [0, 1, 2] for y in [100, 200, 300]]\\n>>> res\\n[100, 200, 300, 101, 201, 301, 102, 202, 302]\\n\\nThis has the same effect as this substantially more verbose equivalent:\\n\\n>>> res = []\\n>>> for x in [0, 1, 2]:\\n\\n584 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c        for y in [100, 200, 300]:\\n            res.append(x + y)\\n\\n>>> res\\n[100, 200, 300, 101, 201, 301, 102, 202, 302]\\n\\nAlthough list comprehensions construct list results, remember that they can iterate over\\nany sequence or other iterable type. Here’s a similar bit of code that traverses strings\\ninstead of lists of numbers, and so collects concatenation results:\\n\\n>>> [x + y for x in \\'spam\\' for y in \\'SPAM\\']\\n[\\'sS\\', \\'sP\\', \\'sA\\', \\'sM\\', \\'pS\\', \\'pP\\', \\'pA\\', \\'pM\\',\\n\\'aS\\', \\'aP\\', \\'aA\\', \\'aM\\', \\'mS\\', \\'mP\\', \\'mA\\', \\'mM\\']\\n\\nEach for clause can have an associated if filter, no matter how deeply the loops are\\nnested—though use cases for the following sort of code, apart from perhaps multidi-\\nmensional arrays, start to become more and more difficult to imagine at this level:\\n\\n>>> [x + y for x in \\'spam\\' if x in \\'sm\\' for y in \\'SPAM\\' if y in (\\'P\\', \\'A\\')]\\n[\\'sP\\', \\'sA\\', \\'mP\\', \\'mA\\']\\n\\n>>> [x + y + z for x in \\'spam\\' if x in \\'sm\\'\\n               for y in \\'SPAM\\' if y in (\\'P\\', \\'A\\')\\n               for z in \\'123\\'  if z > \\'1\\']\\n[\\'sP2\\', \\'sP3\\', \\'sA2\\', \\'sA3\\', \\'mP2\\', \\'mP3\\', \\'mA2\\', \\'mA3\\']\\n\\nFinally, here is a similar list comprehension that illustrates the effect of attached if\\nselections on nested for clauses applied to numeric objects rather than strings:\\n\\n>>> [(x, y) for x in range(5) if x % 2 == 0 for y in range(5) if y % 2 == 1]\\n[(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]\\n\\nThis expression combines even numbers from 0 through 4 with odd numbers from 0\\nthrough 4. The if clauses filter out items in each iteration. Here is the equivalent state-\\nment-based code:\\n\\n>>> res = []\\n>>> for x in range(5):\\n        if x % 2 == 0:\\n            for y in range(5):\\n                if y % 2 == 1:\\n                    res.append((x, y))\\n\\n>>> res\\n[(0, 1), (0, 3), (2, 1), (2, 3), (4, 1), (4, 3)]\\n\\nRecall that if you’re confused about what a complex list comprehension does, you can\\nalways nest the list comprehension’s for and if clauses inside each other like this—\\nindenting each clause successively further to the right—to derive the equivalent state-\\nments. The result is longer, but perhaps clearer in intent to some human readers on\\nfirst glance, especially those more familiar with basic statements.\\n\\nList Comprehensions and Functional Tools\\n\\n| 585\\n\\n\\x0cThe map and filter equivalent of this last example would be wildly complex and deeply\\nnested, so I won’t even try showing it here. I’ll leave its coding as an exercise for Zen\\nmasters, ex–Lisp programmers, and the criminally insane!\\n\\nExample: List Comprehensions and Matrixes\\nNot all list comprehensions are so artificial, of course. Let’s look at one more applica-\\ntion to stretch a few synapses. As we saw in Chapter 4 and Chapter 8, one basic way\\nto code matrixes (a.k.a. multidimensional arrays) in Python is with nested list struc-\\ntures. The following, for example, defines two 3 × 3 matrixes as lists of nested lists:\\n\\n>>> M = [[1, 2, 3],\\n         [4, 5, 6],\\n         [7, 8, 9]]\\n\\n>>> N = [[2, 2, 2],\\n         [3, 3, 3],\\n         [4, 4, 4]]\\n\\nGiven this structure, we can always index rows, and columns within rows, using normal\\nindex operations:\\n\\n>>> M[1]              # Row 2\\n[4, 5, 6]\\n\\n>>> M[1][2]           # Row 2, item 3\\n6\\n\\nList comprehensions are powerful tools for processing such structures, though, because\\nthey automatically scan rows and columns for us. For instance, although this structure\\nstores the matrix by rows, to collect the second column we can simply iterate across the\\nrows and pull out the desired column, or iterate through positions in the rows and\\nindex as we go:\\n\\n>>> [row[1] for row in M]                          # Column 2\\n[2, 5, 8]\\n\\n>>> [M[row][1] for row in (0, 1, 2)]               # Using offsets\\n[2, 5, 8]\\n\\nGiven positions, we can also easily perform tasks such as pulling out a diagonal. The\\nfirst of the following expressions uses  range to generate the list of offsets and then\\nindexes with the row and column the same, picking out M[0][0], then M[1][1], and so\\non. The second scales the column index to fetch M[0][2], M[1][1], etc. (we assume the\\nmatrix has the same number of rows and columns):\\n\\n>>> [M[i][i] for i in range(len(M))]               # Diagonals\\n[1, 5, 9]\\n>>> [M[i][len(M)-1-i] for i in range(len(M))]\\n[3, 5, 7]\\n\\n586 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cChanging such a matrix in place requires assignment to offsets (use range twice if shapes\\ndiffer):\\n\\n>>> L = [[1, 2, 3], [4, 5, 6]]\\n>>> for i in range(len(L)):\\n        for j in range(len(L[i])):                 # Update in place\\n            L[i][j] += 10\\n\\n>>> L\\n[[11, 12, 13], [14, 15, 16]]\\n\\nWe can’t really do the same with list comprehensions, as they make new lists, but we\\ncould always assign their results to the original name for a similar effect. For example,\\nwe can apply an operation to every item in a matrix, producing results in either a simple\\nvector or a matrix of the same shape:\\n\\n>>> [col + 10 for row in M for col in row]         # Assign to M to retain new value\\n[11, 12, 13, 14, 15, 16, 17, 18, 19]\\n\\n>>> [[col + 10 for col in row] for row in M]\\n[[11, 12, 13], [14, 15, 16], [17, 18, 19]]\\n\\nTo understand these, translate to their simple statement form equivalents that follow\\n—indent parts that are further to the right in the expression (as in the first loop in the\\nfollowing), and make a new list when comprehensions are nested on the left (like the\\nsecond loop in the following). As its statement equivalent makes clearer, the second\\nexpression in the preceding works because the row iteration is an outer loop: for each\\nrow, it runs the nested column iteration to build up one row of the result matrix:\\n\\n>>> res = []\\n>>> for row in M:                                  # Statement equivalents\\n        for col in row:                            # Indent parts further right\\n            res.append(col + 10)\\n\\n>>> res\\n[11, 12, 13, 14, 15, 16, 17, 18, 19]\\n\\n>>> res = []\\n>>> for row in M:\\n        tmp = []                                   # Left-nesting starts new list\\n        for col in row:\\n            tmp.append(col + 10)\\n        res.append(tmp)\\n\\n>>> res\\n[[11, 12, 13], [14, 15, 16], [17, 18, 19]]\\n\\nFinally, with a bit of creativity, we can also use list comprehensions to combine values\\nof multiple matrixes. The following first builds a flat list that contains the result of\\nmultiplying the matrixes pairwise, and then builds a nested list structure having the\\nsame values by nesting list comprehensions again:\\n\\n>>> M\\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\\n\\nList Comprehensions and Functional Tools\\n\\n| 587\\n\\n\\x0c>>> N\\n[[2, 2, 2], [3, 3, 3], [4, 4, 4]]\\n\\n>>> [M[row][col] * N[row][col] for row in range(3) for col in range(3)]\\n[2, 4, 6, 12, 15, 18, 28, 32, 36]\\n\\n>>> [[M[row][col] * N[row][col] for col in range(3)] for row in range(3)]\\n[[2, 4, 6], [12, 15, 18], [28, 32, 36]]\\n\\nThis last expression works because the row iteration is an outer loop again; it’s equiv-\\nalent to this statement-based code:\\n\\nres = []\\nfor row in range(3):\\n    tmp = []\\n    for col in range(3):\\n        tmp.append(M[row][col] * N[row][col])\\n    res.append(tmp)\\n\\nAnd for more fun, we can use zip to pair items to be multiplied—the following com-\\nprehension and loop statement forms both produce the same list-of-lists pairwise mul-\\ntiplication result as the last preceding example (and because zip is a generator of values\\nin 3.X, this isn’t as inefficient as it may seem):\\n\\n[[col1 * col2 for (col1, col2) in zip(row1, row2)] for (row1, row2) in zip(M, N)]\\n\\nres = []\\nfor (row1, row2) in zip(M, N):\\n    tmp = []\\n    for (col1, col2) in zip(row1, row2):\\n        tmp.append(col1 * col2)\\n    res.append(tmp)\\n\\nCompared to their statement equivalents, the list comprehension versions here require\\nonly one line of code, might run substantially faster for large matrixes, and just might\\nmake your head explode! Which brings us to the next section.\\n\\nDon’t Abuse List Comprehensions: KISS\\nWith such generality, list comprehensions can quickly become, well, incomprehensi-\\nble, especially when nested. Some programming tasks are inherently complex, and we\\ncan’t sugarcoat them to make them any simpler than they are (see the upcoming per-\\nmutations for a prime example). Tools like comprehensions are powerful solutions\\nwhen used wisely, and there’s nothing inherently wrong with using them in your scripts.\\nAt the same time, code like that of the prior section may push the complexity envelope\\nmore than it should—and, frankly, tends to disproportionately pique the interest of\\nthose holding the darker and misguided assumption that code obfuscation somehow\\nimplies talent. Because such tools tend to appeal to some people more than they prob-\\nably should, I need to be clear about their scope here.\\n\\n588 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cThis book demonstrates advanced comprehensions to teach, but in the real world,\\nusing complicated and tricky code where not warranted is both bad engineering and\\nbad software citizenship. To repurpose a line from the first chapter: programming is\\nnot about being clever and obscure—it’s about how clearly your program communi-\\ncates its purpose.\\nOr, to quote from Python’s import this motto:\\n\\nSimple is better than complex.\\n\\nWriting complicated comprehension code may be a fun academic recreation, but it\\ndoesn’t have a place in programs that others will someday need to understand.\\nConsequently, my advice is to use simple for loops when getting started with Python,\\nand comprehensions or map in isolated cases where they are easy to apply. The “keep\\nit simple” rule applies here as always: code conciseness is a much less important goal\\nthan code readability. If you have to translate code to statements to understand it, it\\nshould probably be statements in the first place. In other words, the age-old acronym\\nKISS still applies: Keep It Simple—followed either by a word that is today too sexist\\n(Sir), or another that is too colorful for a family-oriented book like this...\\n\\nOn the other hand: performance, conciseness, expressiveness\\nHowever, in this case, there is currently a substantial performance advantage to the\\nextra complexity: based on tests run under Python today, map calls can be twice as fast\\nas equivalent for loops, and list comprehensions are often faster than map calls. This\\nspeed difference can vary per usage pattern and Python, but is generally due to the fact\\nthat map and list comprehensions run at C language speed inside the interpreter, which\\nis often much faster than stepping through Python for loop bytecode within the PVM.\\nIn addition, list comprehensions offer a code conciseness that’s compelling and even\\nwarranted when that reduction in size doesn’t also imply a reduction in meaning for\\nthe next programmer. Moreover, many find the expressiveness of comprehensions to\\nbe a powerful ally. Because map and list comprehensions are both expressions, they also\\ncan show up syntactically in places that for loop statements cannot, such as in the\\nbodies of lambda functions, within list and dictionary literals, and more.\\nBecause of this, list comprehensions and map calls are worth knowing and using for\\nsimpler kinds of iterations, especially if your application’s speed is an important con-\\nsideration. Still, because for loops make logic more explicit, they are generally recom-\\nmended on the grounds of simplicity, and often make for more straightforward code.\\nWhen used, you should try to keep your map calls and list comprehensions simple; for\\nmore complex tasks, use full statements instead.\\n\\nList Comprehensions and Functional Tools\\n\\n| 589\\n\\n\\x0cAs I’ve stated before, performance generalizations like those just given\\nhere can depend on call patterns, as well as changes and optimizations\\nin Python itself. Recent Python releases have sped up the simple for loop\\nstatement, for example. On some code, though, list comprehensions are\\nstill substantially faster than for loops and even faster than map, though\\nmap can still win when the alternatives must apply a function call, built-\\nin functions or otherwise. At least until this story changes arbitrarily—\\nto time these alternatives yourself, see tools in the standard library’s\\ntime module or in the newer timeit module added in Release 2.4, or\\nstay tuned for the extended coverage of both of these in the next chapter,\\nwhere we’ll prove the prior paragraph’s claims.\\n\\nWhy You Will Care: List Comprehensions and map\\n\\nHere are some more realistic examples of list comprehensions and map in action. We\\nsolved the first with list comprehensions in Chapter 14, but we’ll revive it here to add\\nmap alternatives. Recall that the file readlines method returns lines with \\\\n end-of-line\\ncharacters at the ends (the following assumes a 3-line text file in the current directory):\\n\\n>>> open(\\'myfile\\').readlines()\\n[\\'aaa\\\\n\\', \\'bbb\\\\n\\', \\'ccc\\\\n\\']\\n\\nIf you don’t want the end-of-line characters, you can slice them off all the lines in a\\nsingle step with a list comprehension or a map call (map results are iterables in Python\\n3.X, so we must run them through list to display all their results at once):\\n\\n>>> [line.rstrip() for line in open(\\'myfile\\').readlines()]\\n[\\'aaa\\', \\'bbb\\', \\'ccc\\']\\n\\n>>> [line.rstrip() for line in open(\\'myfile\\')]\\n[\\'aaa\\', \\'bbb\\', \\'ccc\\']\\n\\n>>> list(map((lambda line: line.rstrip()), open(\\'myfile\\')))\\n[\\'aaa\\', \\'bbb\\', \\'ccc\\']\\n\\nThe last two of these make use of file iterators; as we saw in Chapter 14, this means\\nthat you don’t need a method call to read lines in iteration contexts such as these. The\\nmap call is slightly longer than the list comprehension, but neither has to manage result\\nlist construction explicitly.\\n\\nA  list  comprehension  can  also  be  used  as  a  sort  of  column  projection  operation.\\nPython’s standard SQL database API returns query results as a sequence of sequences\\nlike the following—the list is the table, tuples are rows, and items in tuples are column\\nvalues:\\n\\n>>> listoftuple = [(\\'bob\\', 35, \\'mgr\\'), (\\'sue\\', 40, \\'dev\\')]\\n\\nA for loop could pick up all the values from a selected column manually, but map and\\nlist comprehensions can do it in a single step, and faster:\\n\\n>>> [age for (name, age, job) in listoftuple]\\n[35, 40]\\n\\n590 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c>>> list(map((lambda row: row[1]), listoftuple))\\n[35, 40]\\n\\nThe first of these makes use of tuple assignment to unpack row tuples in the list, and\\nthe second uses indexing. In Python 2.X (but not in 3.X—see the note on 2.X argument\\nunpacking in Chapter 18), map can use tuple unpacking on its argument, too:\\n\\n# 2.X only\\n>>> list(map((lambda (name, age, job): age), listoftuple))\\n[35, 40]\\n\\nSee other books and resources for more on Python’s database API.\\n\\nBesides the distinction between running functions versus expressions, the biggest dif-\\nference between map and list comprehensions in Python 3.X is that map is an iterable,\\ngenerating results on demand. To achieve the same memory economy and execution\\ntime division, list comprehensions must be coded as generator expressions—a major\\ntopic of this chapter.\\n\\nGenerator Functions and Expressions\\nPython today supports procrastination much more than it did in the past—it provides\\ntools that produce results only when needed, instead of all at once. We’ve seen this at\\nwork in built-in tools: files that read lines on request, and functions like map and zip\\nthat produce items on demand in 3.X. Such laziness isn’t confined to Python itself,\\nthough. In particular, two language constructs delay result creation whenever possible\\nin user-defined operations:\\n\\n• Generator functions (available since 2.3) are coded as normal def statements, but\\nuse yield statements to return results one at a time, suspending and resuming their\\nstate between each.\\n\\n• Generator expressions (available since 2.4) are similar to the list comprehensions\\nof the prior section, but they return an object that produces results on demand\\ninstead of building a result list.\\n\\nBecause neither constructs a result list all at once, they save memory space and allow\\ncomputation time to be split across result requests. As we’ll see, both of these ultimately\\nperform their delayed-results magic by implementing the iteration protocol we studied\\nin Chapter 14.\\nThese features are not new (generator expressions were available as an option as early\\nas Python 2.2), and are fairly common in Python code today. Python’s notion of gen-\\nerators owes much to other programming languages, especially Icon. Though they may\\ninitially seem unusual if you’re accustomed to simpler programming models, you’ll\\nprobably find generators to be a powerful tool where applicable. Moreover, because\\nthey are a natural extension to the function, comprehension, and iteration ideas we’ve\\n\\nGenerator Functions and Expressions\\n\\n| 591\\n\\n\\x0calready explored, you already know more about coding generators than you might\\nexpect.\\n\\nGenerator Functions: yield Versus return\\nIn this part of the book, we’ve learned about coding normal functions that receive input\\nparameters and send back a single result immediately. It is also possible, however, to\\nwrite functions that may send back a value and later be resumed, picking up where they\\nleft off. Such functions, available in both Python 2.X and 3.X, are known as generator\\nfunctions because they generate a sequence of values over time.\\nGenerator functions are like normal functions in most respects, and in fact are coded\\nwith normal def statements. However, when created, they are compiled specially into\\nan object that supports the iteration protocol. And when called, they don’t return a\\nresult: they return a result generator that can appear in any iteration context. We stud-\\nied iterables in Chapter 14, and Figure 14-1 gave a formal and graphic summary of their\\noperation. Here, we’ll revisit them to see how they relate to generators.\\n\\nState suspension\\nUnlike normal functions that return a value and exit, generator functions automatically\\nsuspend and resume their execution and state around the point of value generation.\\nBecause of that, they are often a useful alternative to both computing an entire series\\nof values up front and manually saving and restoring state in classes. The state that\\ngenerator functions retain when they are suspended includes both their code location,\\nand their entire local scope. Hence, their local variables retain information between\\nresults, and make it available when the functions are resumed.\\nThe chief code difference between generator and normal functions is that a generator\\nyields a value, rather than returning one—the yield statement suspends the function\\nand sends a value back to the caller, but retains enough state to enable the function to\\nresume from where it left off. When resumed, the function continues execution im-\\nmediately after the last yield run. From the function’s perspective, this allows its code\\nto produce a series of values over time, rather than computing them all at once and\\nsending them back in something like a list.\\n\\nIteration protocol integration\\nTo truly understand generator functions, you need to know that they are closely bound\\nup with the notion of the iteration protocol in Python. As we’ve seen, iterator objects\\ndefine a __next__ method (next in 2.X), which either returns the next item in the iter-\\nation, or raises the special StopIteration exception to end the iteration. An iterable\\nobject’s iterator is fetched initially with the iter built-in function, though this step is a\\nno-op for objects that are their own iterator.\\n\\n592 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cPython for loops, and all other iteration contexts, use this iteration protocol to step\\nthrough a sequence or value generator, if the protocol is supported (if not, iteration\\nfalls back on repeatedly indexing sequences instead). Any object that supports this\\ninterface works in all iteration tools.\\nTo support this protocol, functions containing a yield statement are compiled specially\\nas generators—they are not normal functions, but rather are built to return an object\\nwith the expected iteration protocol methods. When later called, they return a gener-\\nator object that supports the iteration interface with an automatically created method\\nnamed __next__ to start or resume execution.\\nGenerator functions may also have a return statement that, along with falling off the\\nend of the def block, simply terminates the generation of values—technically, by raising \\na StopIteration exception after any normal function exit actions. From the caller’s\\nperspective, the generator’s __next__ method resumes the function and runs until either\\nthe next yield result is returned or a StopIteration is raised.\\nThe net effect is that generator functions, coded as def statements containing yield\\nstatements, are automatically made to support the iteration object protocol and thus\\nmay be used in any iteration context to produce results over time and on demand.\\n\\nAs noted in Chapter 14, in Python 2.X, iterator objects define a method\\nnamed next instead of __next__. This includes the generator objects we\\nare using here. In 3.X this method is renamed to __next__. The next\\nbuilt-in  function  is  provided  as  a  convenience  and  portability  tool:\\nnext(I) is the same as I.__next__() in 3.X and I.next() in 2.6 and 2.7.\\nPrior to 2.6, programs simply call I.next() instead to iterate manually.\\n\\nGenerator functions in action\\nTo illustrate generator basics, let’s turn to some code. The following code defines a\\ngenerator function that can be used to generate the squares of a series of numbers over\\ntime:\\n\\n>>> def gensquares(N):\\n        for i in range(N):\\n            yield i ** 2        # Resume here later\\n\\nThis function yields a value, and so returns to its caller, each time through the loop;\\nwhen it is resumed, its prior state is restored, including the last values of its variables\\ni and N, and control picks up again immediately after the yield statement. For example,\\nwhen it’s used in the body of a for loop, the first iteration starts the function and gets\\nits first result; thereafter, control returns to the function after its yield statement each\\ntime through the loop:\\n\\n>>> for i in gensquares(5):     # Resume the function\\n        print(i, end=\\' : \\')     # Print last yielded value\\n\\nGenerator Functions and Expressions\\n\\n| 593\\n\\n\\x0c0 : 1 : 4 : 9 : 16 :\\n>>>\\n\\nTo end the generation of values, functions either use a return statement with no value\\nor simply allow control to fall off the end of the function body.\\nTo most people, this process seems a bit implicit (if not magical) on first encounter.\\nIt’s actually quite tangible, though. If you really want to see what is going on inside the\\nfor, call the generator function directly:\\n\\n>>> x = gensquares(4)\\n>>> x\\n<generator object gensquares at 0x000000000292CA68>\\n\\nYou get back a generator object that supports the iteration protocol we met in Chap-\\nter 14—the generator function was compiled to return this automatically. The returned\\ngenerator object in turn has a __next__ method that starts the function or resumes it\\nfrom where it last yielded a value, and raises a StopIteration exception when the end\\nof  the  series  of  values  is  reached  and  the  function  returns.  For  convenience,  the\\nnext(X) built-in calls an object’s X.__next__() method for us in 3.X (and X.next() in\\n2.X):\\n\\n>>> next(x)                     # Same as x.__next__() in 3.X\\n0\\n>>> next(x)                     # Use x.next() or next() in 2.X\\n1\\n>>> next(x)\\n4\\n>>> next(x)\\n9\\n>>> next(x)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nStopIteration\\n\\nAs we learned in Chapter 14, for loops (and other iteration contexts) work with gen-\\nerators in the same way—by calling the __next__ method repeatedly, until an exception\\nis caught. For a generator, the result is to produce yielded values over time. If the object\\nto be iterated over does not support this protocol, for loops instead use the indexing\\nprotocol to iterate.\\nNotice that the top-level iter call of the iteration protocol isn’t required here because\\ngenerators are their own iterator, supporting just one active iteration scan. To put that\\nanother way generators return themselves for iter, because they support next directly.\\nThis also holds true in the generator expressions we’ll meet later in this chapter (more\\non this ahead):\\n\\n>>> y = gensquares(5)           # Returns a generator which is its own iterator\\n>>> iter(y) is y                # iter() is not required: a no-op here\\nTrue\\n>>> next(y)                     # Can run next()immediately\\n0\\n\\n594 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cWhy generator functions?\\nGiven the simple examples we’re using to illustrate fundamentals, you might be won-\\ndering just why you’d ever care to code a generator at all. In this section’s example, for\\ninstance, we could also simply build the list of yielded values all at once:\\n\\n>>> def buildsquares(n):\\n        res = []\\n        for i in range(n): res.append(i ** 2)\\n        return res\\n\\n>>> for x in buildsquares(5): print(x, end=\\' : \\')\\n\\n0 : 1 : 4 : 9 : 16 :\\n\\nFor that matter, we could use any of the for loop, map, or list comprehension techniques:\\n\\n>>> for x in [n ** 2 for n in range(5)]:\\n        print(x, end=\\' : \\')\\n\\n0 : 1 : 4 : 9 : 16 :\\n\\n>>> for x in map((lambda n: n ** 2), range(5)):\\n        print(x, end=\\' : \\')\\n\\n0 : 1 : 4 : 9 : 16 :\\n\\nHowever, generators can be better in terms of both memory use and performance in\\nlarger programs. They allow functions to avoid doing all the work up front, which is\\nespecially useful when the result lists are large or when it takes a lot of computation to\\nproduce each value. Generators distribute the time required to produce the series of\\nvalues among loop iterations.\\nMoreover,  for  more  advanced  uses,  generators  can  provide  a  simpler  alternative  to\\nmanually saving the state between iterations in class objects—with generators, vari-\\nables accessible in the function’s scopes are saved and restored automatically.1 We’ll\\ndiscuss class-based iterables in more detail in Part VI.\\nGenerator functions are also much more broadly focused than implied so far. They can\\noperate on and return any type of object, and as iterables may appear in any of Chap-\\nter 14’s iteration contexts, including tuple calls, enumerations, and dictionary com-\\nprehensions:\\n\\n1. Interestingly,  generator  functions  are  also  something  of  a  “poor  man’s”  multithreading  device—they\\ninterleave  a  function’s  work  with  that  of  its  caller,  by  dividing  its  operation  into  steps  run  between\\nyields. Generators are not threads, though: the program is explicitly directed to and from the function\\nwithin  a  single  thread  of  control.  In  one  sense,  threading  is  more  general  (producers  can  run  truly\\nindependently and post results to a queue), but generators may be simpler to code. See the footnote in\\nChapter 17 for a brief introduction to Python multithreading tools. Note that because control is routed\\nexplicitly at yield and next calls, generators are also not backtracking, but are more strongly related to\\ncoroutines—formal concepts that are both beyond this chapter’s scope.\\n\\nGenerator Functions and Expressions\\n\\n| 595\\n\\n\\x0c>>> def ups(line):\\n        for sub in line.split(\\',\\'):               # Substring generator\\n            yield sub.upper()\\n\\n>>> tuple(ups(\\'aaa,bbb,ccc\\'))                     # All iteration contexts\\n(\\'AAA\\', \\'BBB\\', \\'CCC\\')\\n\\n>>> {i: s for (i, s) in enumerate(ups(\\'aaa,bbb,ccc\\'))}\\n{0: \\'AAA\\', 1: \\'BBB\\', 2: \\'CCC\\'}\\n\\nIn a moment we’ll see the same assets for generator expressions—a tool that trades\\nfunction flexibility for comprehension conciseness. Later in this chapter we’ll also see\\nthat generators can sometimes make the impossible possible, by producing compo-\\nnents of result sets that would be far too large to create all at once. First, though, let’s\\nexplore some advanced generator function features.\\n\\nExtended generator function protocol: send versus next\\nIn Python 2.5, a send method was added to the generator function protocol. The send\\nmethod advances to the next item in the series of results, just like __next__, but also\\nprovides a way for the caller to communicate with the generator, to affect its operation.\\nTechnically, yield is now an expression form that returns the item passed to send, not\\na statement (though it can be called either way—as yield X, or A = (yield X)). The\\nexpression must be enclosed in parentheses unless it’s the only item on the right side\\nof the assignment statement. For example, X = yield Y is OK, as is X = (yield Y) + 42.\\nWhen  this  extra  protocol  is  used,  values  are  sent  into  a  generator  G  by  calling\\nG.send(value). The generator’s code is then resumed, and the yield expression in the\\ngenerator returns the value passed to send. If the regular G.__next__() method (or its\\nnext(G) equivalent) is called to advance, the yield simply returns None. For example:\\n\\n>>> def gen():\\n       for i in range(10):\\n           X = yield i\\n           print(X)\\n\\n>>> G = gen()\\n>>> next(G)              # Must call next() first, to start generator\\n0\\n>>> G.send(77)           # Advance, and send value to yield expression\\n77\\n1\\n>>> G.send(88)\\n88\\n2\\n>>> next(G)              # next() and X.__next__() send None\\nNone\\n3\\n\\n596 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cThe send method can be used, for example, to code a generator that its caller can ter-\\nminate by sending a termination code, or redirect by passing a new position in data\\nbeing processed inside the generator.\\nIn addition, generators in 2.5 and later also support a throw(type) method to raise an\\nexception inside the generator at the latest yield, and a close method that raises a\\nspecial GeneratorExit exception inside the generator to terminate the iteration entirely.\\nThese are advanced features that we won’t delve into in more detail here; see reference\\ntexts and Python’s standard manuals for more information, and watch for more on\\nexceptions in Part VII.\\nNote  that  while  Python  3.X  provides  a  next(X)  convenience  built-in  that  calls  the\\nX.__next__() method of an object, other generator methods, like send, must be called\\nas methods of generator objects directly (e.g., G.send(X)). This makes sense if you re-\\nalize  that  these  extra  methods  are  implemented  on  built-in  generator  objects  only,\\nwhereas the __next__ method applies to all iterable objects—both built-in types and\\nuser-defined classes.\\nAlso note that Python 3.3 introduces an extension to yield—a from clause—that allows\\ngenerators to delegate to nested generators. Since this is an extension to what is already\\na fairly advanced topic, we’ll delegate this topic itself to a sidebar, and move on here\\nto a tool that’s close enough to be called a twin.\\n\\nGenerator Expressions: Iterables Meet Comprehensions\\nBecause  the  delayed  evaluation  of  generator  functions  was  so  useful,  it  eventually\\nspread to other tools. In both Python 2.X and 3.X, the notions of iterables and list\\ncomprehensions are combined in a new tool: generator expressions. Syntactically, gen-\\nerator expressions are just like normal list comprehensions, and support all their syntax\\n—including if filters and loop nesting—but they are enclosed in parentheses instead\\nof square brackets (like tuples, their enclosing parentheses are often optional):\\n\\n>>> [x ** 2 for x in range(4)]          # List comprehension: build a list\\n[0, 1, 4, 9]\\n\\n>>> (x ** 2 for x in range(4))          # Generator expression: make an iterable\\n<generator object <genexpr> at 0x00000000029A8288>\\n\\nIn fact, at least on a functionality basis, coding a list comprehension is essentially the\\nsame as wrapping a generator expression in a list built-in call to force it to produce\\nall its results in a list at once:\\n\\n>>> list(x ** 2 for x in range(4))      # List comprehension equivalence\\n[0, 1, 4, 9]\\n\\nOperationally, however, generator expressions are very different: instead of building\\nthe  result  list  in  memory,  they  return  a  generator  object—an  automatically  created\\niterable. This iterable object in turn supports the iteration protocol to yield one piece\\nof the result list at a time in any iteration context. The iterable object also retains gen-\\n\\nGenerator Functions and Expressions\\n\\n| 597\\n\\n\\x0cerator state while active—the variable x in the preceding expressions, along with the\\ngenerator’s code location.\\nThe net effect is much like that of generator functions, but in the context of a compre-\\nhension expression: we get back an object that remembers where it left off after each\\npart of its result is returned. Also like generator functions, looking under the hood at\\nthe protocol that these objects automatically support can help demystify them; the\\niter call is again not required at the top here, for reasons we’ll expand on ahead:\\n\\n>>> G = (x ** 2 for x in range(4))\\n>>> iter(G) is G                           # iter(G) optional: __iter__ returns self\\nTrue\\n>>> next(G)                                # Generator objects: automatic methods\\n0\\n>>> next(G)\\n1\\n>>> next(G)\\n4\\n>>> next(G)\\n9\\n>>> next(G)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nStopIteration\\n\\n>>> G\\n<generator object <genexpr> at 0x00000000029A8318>\\n\\nAgain, we don’t typically see the next iterator machinery under the hood of a generator\\nexpression like this because for loops trigger it for us automatically:\\n\\n>>> for num in (x ** 2 for x in range(4)):          # Calls next() automatically\\n        print(\\'%s, %s\\' % (num, num / 2.0))\\n\\n0, 0.0\\n1, 0.5\\n4, 2.0\\n9, 4.5\\n\\nAs we’ve already learned, every iteration context does this—including for loops; the\\nsum, map, and sorted built-in functions; list comprehensions; and other iteration con-\\ntexts we learned about in Chapter 14, such as the any, all, and list built-in functions.\\nAs iterables, generator expressions can appear in any of these iteration contexts, just\\nlike the result of a generator function call.\\nFor example, the following deploys generator expressions in the string join method\\ncall and tuple assignment, iteration contexts both. In the first test here, join runs the\\ngenerator and joins the substrings it produces with nothing between—to simply con-\\ncatenate:\\n\\n>>> \\'\\'.join(x.upper() for x in \\'aaa,bbb,ccc\\'.split(\\',\\'))\\n\\'AAABBBCCC\\'\\n\\n>>> a, b, c = (x + \\'\\\\n\\' for x in \\'aaa,bbb,ccc\\'.split(\\',\\'))\\n\\n598 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c>>> a, c\\n(\\'aaa\\\\n\\', \\'ccc\\\\n\\')\\n\\nNotice how the join call in the preceding doesn’t require extra parentheses around the\\ngenerator. Syntactically, parentheses are not required around a generator expression\\nthat is the sole item already enclosed in parentheses used for other purposes—like those\\nof a function call. Parentheses are required in all other cases, however, even if they seem\\nextra, as in the second call to sorted that follows:\\n\\n>>> sum(x ** 2 for x in range(4))                           # Parens optional\\n14\\n>>> sorted(x ** 2 for x in range(4))                        # Parens optional\\n[0, 1, 4, 9]\\n>>> sorted((x ** 2 for x in range(4)), reverse=True)        # Parens required\\n[9, 4, 1, 0]\\n\\nLike the often-optional parentheses in tuples, there is no widely accepted rule on this,\\nthough a generator expression does not have as clear a role as a fixed collection of other\\nobjects as a tuple, making extra parentheses seem perhaps more spurious here.\\n\\nWhy generator expressions?\\nJust like generator functions, generator expressions are a memory-space optimization\\n—they do not require the entire result list to be constructed all at once, as the square-\\nbracketed list comprehension does. Also like generator functions, they divide the work\\nof results production into smaller time slices—they yield results in piecemeal fashion,\\ninstead of making the caller wait for the full set to be created in a single call.\\nOn the other hand, generator expressions may also run slightly slower than list com-\\nprehensions in practice, so they are probably best used only for very large result sets,\\nor applications that cannot wait for full results generation. A more authoritative state-\\nment about performance, though, will have to await the timing scripts we’ll code in the\\nnext chapter.\\nThough more subjective, generator expressions offer coding advantages too—as the\\nnext sections show.\\n\\nGenerator expressions versus map\\nOne way to see the coding benefits of generator expressions is to compare them to other\\nfunctional tools, as we did for list comprehensions. For example, generator expressions\\noften are equivalent to 3.X map calls, because both generate result items on request. Like\\nlist comprehensions, though, generator expressions may be simpler to code when the\\noperation applied is not a function call. In 2.X, map makes temporary lists and generator\\nexpressions do not, but the same coding comparisons apply:\\n\\n>>> list(map(abs, (−1, −2, 3, 4)))                          # Map function on tuple\\n[1, 2, 3, 4]\\n>>> list(abs(x) for x in (−1, −2, 3, 4))                    # Generator expression\\n[1, 2, 3, 4]\\n\\nGenerator Functions and Expressions\\n\\n| 599\\n\\n\\x0c>>> list(map(lambda x: x * 2, (1, 2, 3, 4)))                # Nonfunction case\\n[2, 4, 6, 8]\\n>>> list(x * 2 for x in (1, 2, 3, 4))                       # Simpler as generator?\\n[2, 4, 6, 8]\\n\\nThe same holds true for text-processing use cases like the join call we saw earlier—a\\nlist comprehension makes an extra temporary list of results, which is completely point-\\nless in this context because the list is not retained, and map loses simplicity points com-\\npared to generator expression syntax when the operation being applied is not a call:\\n\\n>>> line = \\'aaa,bbb,ccc\\'\\n>>> \\'\\'.join([x.upper() for x in line.split(\\',\\')])           # Makes a pointless list\\n\\'AAABBBCCC\\'\\n\\n>>> \\'\\'.join(x.upper() for x in line.split(\\',\\'))             # Generates results\\n\\'AAABBBCCC\\'\\n>>> \\'\\'.join(map(str.upper, line.split(\\',\\')))                # Generates results\\n\\'AAABBBCCC\\'\\n\\n>>> \\'\\'.join(x * 2 for x in line.split(\\',\\'))                 # Simpler as generator?\\n\\'aaaaaabbbbbbcccccc\\'\\n>>> \\'\\'.join(map(lambda x: x * 2, line.split(\\',\\')))\\n\\'aaaaaabbbbbbcccccc\\'\\n\\nBoth map and generator expressions can also be arbitrarily nested, which supports gen-\\neral use in programs, and requires a list call or other iteration context to start the\\nprocess of producing results. For example, the list comprehension in the following\\nproduces the same result as the 3.X map and generator equivalents that follow it, but\\nmakes two physical lists; the others generate just one integer at a time with nested\\ngenerators, and the generator expression form may more clearly reflect its intent:\\n>>> [x * 2 for x in [abs(x) for x in (−1, −2, 3, 4)]]       # Nested comprehensions\\n[2, 4, 6, 8]\\n\\n>>> list(map(lambda x: x * 2, map(abs, (−1, −2, 3, 4))))    # Nested maps\\n[2, 4, 6, 8]\\n\\n>>> list(x * 2 for x in (abs(x) for x in (−1, −2, 3, 4)))   # Nested generators\\n[2, 4, 6, 8]\\n\\nAlthough the effect of all three of these is to combine operations, the generators do so\\nwithout  making  multiple  temporary  lists.  In  3.X,  the  next  example  both  nests  and\\ncombines generators—the nested generator expression is activated by map, which in\\nturn is only activated by list.\\n\\n>>> import math\\n>>> list(map(math.sqrt, (x ** 2 for x in range(4))))        # Nested combinations\\n[0.0, 1.0, 2.0, 3.0]\\n\\nTechnically speaking, the range on the right in the preceding is a value generator in 3.X\\ntoo, activated by the generator expression itself—three levels of value generation, which\\nproduce individual values from inner to outer only on request, and which “just works”\\n\\n600 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cbecause of Python’s iteration tools and protocol. In fact, generator nestings can be\\narbitrarily mixed and deep, though some may be more valid than others:\\n\\n>>> list(map(abs, map(abs, map(abs, (−1, 0, 1)))))          # Nesting gone bad?\\n[1, 0, 1]\\n>>> list(abs(x) for x in (abs(x) for x in (abs(x) for x in (−1, 0, 1))))\\n[1, 0, 1]\\n\\nThese last examples illustrate how general generators can be, but are also coded in an\\nintentionally complex form to underscore that generator expressions have the same\\npotential for abuse as the list comprehensions discussed earlier—as usual, you should\\nkeep them simple unless they must be complex, a theme we’ll revisit later in this chap-\\nter.\\nWhen  used  well,  though,  generator  expressions  combine  the  expressiveness  of  list\\ncomprehensions with the space and time benefits of other iterables. Here, for example,\\nnonnested approaches provide simpler solutions but still leverage generators’ strengths\\n—per a Python motto, flat is generally better than nested:\\n\\n>>> list(abs(x) * 2 for x in (−1, −2, 3, 4))                # Unnested equivalents\\n[2, 4, 6, 8]\\n>>> list(math.sqrt(x ** 2) for x in range(4))               # Flat is often better\\n[0.0, 1.0, 2.0, 3.0]\\n>>> list(abs(x) for x in (−1, 0, 1))\\n[1, 0, 1]\\n\\nGenerator expressions versus filter\\nGenerator expressions also support all the usual list comprehension syntax—including\\nif clauses, which work like the filter call we met earlier. Because filter is an iterable\\nin 3.X that generates its results on request, a generator expression with an if clause is\\noperationally equivalent (in 2.X, filter produces a temporary list that the generator\\ndoes  not,  but  the  code  comparisons  again  apply).  Again,  the  join  in  the  following\\nsuffices to force all forms to produce their results:\\n\\n>>> line = \\'aa bbb c\\'\\n>>> \\'\\'.join(x for x in line.split() if len(x) > 1)          # Generator with \\'if\\'\\n\\'aabbb\\'\\n>>> \\'\\'.join(filter(lambda x: len(x) > 1, line.split()))     # Similar to filter\\n\\'aabbb\\'\\n\\nThe generator seems marginally simpler than the filter here. As for list comprehen-\\nsions, though, adding processing steps to filter results requires a map too, which makes\\nfilter noticeably more complex than a generator expression:\\n\\n>>> \\'\\'.join(x.upper() for x in line.split() if len(x) > 1)\\n\\'AABBB\\'\\n>>> \\'\\'.join(map(str.upper, filter(lambda x: len(x) > 1, line.split())))\\n\\'AABBB\\'\\n\\nIn effect, generator expressions do for 3.X iterables like map and filter what list com-\\nprehensions do for the 2.X list-builder flavors of these calls—they provide more general\\n\\nGenerator Functions and Expressions\\n\\n| 601\\n\\n\\x0ccoding structures that do not rely on functions, but still delay results production. Also\\nlike list comprehensions, there is always a statement-based equivalent to a generator\\nexpression, though it sometimes renders substantially more code:\\n\\n>>> \\'\\'.join(x.upper() for x in line.split() if len(x) > 1)\\n\\'AABBB\\'\\n\\n>>> res = \\'\\'\\n>>> for x in line.split():                                   # Statement equivalent?\\n        if len(x) > 1:                                       # This is also a join\\n            res += x.upper()\\n\\n>>> res\\n\\'AABBB\\'\\n\\nIn this case, though, the statement form isn’t quite the same—it cannot produce items\\none at a time, and it’s also emulating the effect of the join that forces results to be\\nproduced all at once. The true equivalent to a generator expression would be a generator\\nfunction with a yield, as the next section shows.\\n\\nGenerator Functions Versus Generator Expressions\\nLet’s recap what we’ve covered so far in this section:\\n\\nGenerator functions\\n\\nA function def statement that contains a yield statement is turned into a generator\\nfunction. When called, it returns a new generator object with automatic retention\\nof local scope and code position; an automatically created __iter__ method that\\nsimply returns itself; and an automatically created __next__ method (next in 2.X)\\nthat starts the function or resumes it where it last left off, and raises StopItera\\ntion when finished producing results.\\n\\nGenerator expressions\\n\\nA comprehension expression enclosed in parentheses is known as a generator ex-\\npression. When run, it returns a new generator object with the same automatically\\ncreated method interface and state retention as a generator function call’s results\\n—with  an  __iter__  method  that  simply  returns  itself;  and  a  _next__  method\\n(next in 2.X) that starts the implied loop or resumes it where it last left off, and\\nraises StopIteration when finished producing results.\\n\\nThe net effect is to produce results on demand in iteration contexts that employ these\\ninterfaces automatically.\\nAs implied by some of the preceding sections, the same iteration can often be coded\\nwith either a generator function or a generator expression. The following generator\\nexpression, for example, repeats each character in a string four times:\\n\\n>>> G = (c * 4 for c in \\'SPAM\\')           # Generator expression\\n>>> list(G)                               # Force generator to produce all results\\n[\\'SSSS\\', \\'PPPP\\', \\'AAAA\\', \\'MMMM\\']\\n\\n602 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cThe equivalent generator function requires slightly more code, but as a multiple-state-\\nment function it will be able to code more logic and use more state information if\\nneeded.  In  fact,  this  is  essentially  the  same  as  the  prior  chapter’s  tradeoff  between\\nlambda and def—expression conciseness versus statement power:\\n\\n>>> def timesfour(S):                     # Generator function\\n        for c in S:\\n            yield c * 4\\n\\n>>> G = timesfour(\\'spam\\')\\n>>> list(G)                               # Iterate automatically\\n[\\'ssss\\', \\'pppp\\', \\'aaaa\\', \\'mmmm\\']\\n\\nTo clients, the two are more similar than different. Both expressions and functions\\nsupport both automatic and manual iteration—the prior list call iterates automati-\\ncally, and the following iterate manually:\\n\\n>>> G = (c * 4 for c in \\'SPAM\\')\\n>>> I = iter(G)                           # Iterate manually (expression)\\n>>> next(I)\\n\\'SSSS\\'\\n>>> next(I)\\n\\'PPPP\\'\\n\\n>>> G = timesfour(\\'spam\\')\\n>>> I = iter(G)                           # Iterate manually (function)\\n>>> next(I)\\n\\'ssss\\'\\n>>> next(I)\\n\\'pppp\\'\\n\\nIn either case, Python automatically creates a generator object, which has both the\\nmethods  required  by  the  iteration  protocol,  and  state  retention  for  variables  in  the\\ngenerator’s code and its current code location. Notice how we make new generators\\nhere to iterate again—as explained in the next section, generators are one-shot iterators.\\nFirst, though, here’s the true statement-based equivalent of expression at the end of\\nthe prior section: a function that yields values—though the difference is irrelevant if\\nthe code using it produces all results with a tool like join:\\n\\n>>> line = \\'aa bbb c\\'\\n\\n>>> \\'\\'.join(x.upper() for x in line.split() if len(x) > 1)     # Expression\\n\\'AABBB\\'\\n\\n>>> def gensub(line):                                          # Function\\n        for x in line.split():\\n            if len(x) > 1:\\n                yield x.upper()\\n\\n>>> \\'\\'.join(gensub(line))                                      # But why generate?\\n\\'AABBB\\'\\n\\nGenerator Functions and Expressions\\n\\n| 603\\n\\n\\x0cThough generators have valid roles, in cases like this the use of generators over the\\nsimple statement equivalent shown earlier may be difficult to justify, except on stylistic\\ngrounds. On the other hand, trading four lines for one may to many seem fairly com-\\npelling stylistic grounds!\\n\\nGenerators Are Single-Iteration Objects\\nA subtle but important point: both generator functions and generator expressions are\\ntheir own iterators and thus support just one active iteration—unlike some built-in\\ntypes, you can’t have multiple iterators of either positioned at different locations in the\\nset of results. Because of this, a generator’s iterator is the generator itself; in fact, as\\nsuggested earlier, calling iter on a generator expression or function is an optional no-\\nop:\\n\\n>>> G = (c * 4 for c in \\'SPAM\\')\\n>>> iter(G) is G                          # My iterator is myself: G has __next__\\nTrue\\n\\nIf you iterate over the results stream manually with multiple iterators, they will all point\\nto the same position:\\n\\n>>> G = (c * 4 for c in \\'SPAM\\')           # Make a new generator\\n>>> I1 = iter(G)                          # Iterate manually\\n>>> next(I1)\\n\\'SSSS\\'\\n>>> next(I1)\\n\\'PPPP\\'\\n>>> I2 = iter(G)                          # Second iterator at same position!\\n>>> next(I2)\\n\\'AAAA\\'\\n\\nMoreover, once any iteration runs to completion, all are exhausted—we have to make\\na new generator to start again:\\n\\n>>> list(I1)                              # Collect the rest of I1\\'s items\\n[\\'MMMM\\']\\n>>> next(I2)                              # Other iterators exhausted too\\nStopIteration\\n\\n>>> I3 = iter(G)                          # Ditto for new iterators\\n>>> next(I3)\\nStopIteration\\n\\n>>> I3 = iter(c * 4 for c in \\'SPAM\\')      # New generator to start over\\n>>> next(I3)\\n\\'SSSS\\'\\n\\nThe same holds true for generator functions—the following def statement-based equiv-\\nalent supports just one active iterator and is exhausted after one pass:\\n\\n>>> def timesfour(S):\\n        for c in S:\\n            yield c * 4\\n\\n604 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c>>> G = timesfour(\\'spam\\')                 # Generator functions work the same way\\n>>> iter(G) is G\\nTrue\\n>>> I1, I2 = iter(G), iter(G)\\n>>> next(I1)\\n\\'ssss\\'\\n>>> next(I1)\\n\\'pppp\\'\\n>>> next(I2)                              # I2 at same position as I1\\n\\'aaaa\\'\\n\\nThis is different from the behavior of some built-in types, which support multiple iter-\\nators and passes and reflect their in-place changes in active iterators:\\n\\n>>> L = [1, 2, 3, 4]\\n>>> I1, I2 = iter(L), iter(L)\\n>>> next(I1)\\n1\\n>>> next(I1)\\n2\\n>>> next(I2)                              # Lists support multiple iterators\\n1\\n>>> del L[2:]                             # Changes reflected in iterators\\n>>> next(I1)\\nStopIteration\\n\\nThough not readily apparent in these simple examples, this can matter in your code: if\\nyou wish to scan a generator’s values multiple times, you must either create a new\\ngenerator for each scan or build a rescannable list out of its values—a single generator’s\\nvalues will be consumed and exhausted after a single pass. See this chapter’s sidebar\\n“Why You Will Care: One-Shot Iterations” on page 621 for a prime example of the\\nsort of code that must accommodate this generator property.\\nWhen we begin coding class-based iterables in Part VI, we’ll also see that it’s up to us\\nto decide how many iterations we wish to support for our objects, if any. In general,\\nobjects that wish to support multiple scans will return supplemental class objects in-\\nstead of themselves. The next section previews more of this model.\\n\\nThe Python 3.3 yield from Extension\\n\\nPython 3.3 introduces extended syntax for the yield statement that allows delegation\\nto a subgenerator with a from generator clause. In simple cases, it’s the equivalent to a\\nyielding for loop—the list here in the following forces the generator to produce all its\\nvalues, and the comprehension in parentheses is a generator expression, covered in this\\nchapter:\\n\\n>>> def both(N):\\n        for i in range(N): yield i\\n        for i in (x ** 2 for x in range(N)): yield i\\n\\n>>> list(both(5))\\n[0, 1, 2, 3, 4, 0, 1, 4, 9, 16]\\n\\nGenerator Functions and Expressions\\n\\n| 605\\n\\n\\x0cThe new 3.3 syntax makes this arguably more concise and explicit, and supports all\\nthe usual generator usage contexts:\\n\\n>>> def both(N):\\n        yield from range(N)\\n        yield from (x ** 2 for x in range(N))\\n\\n>>> list(both(5))\\n[0, 1, 2, 3, 4, 0, 1, 4, 9, 16]\\n\\n>>> \\' : \\'.join(str(i) for i in both(5))\\n\\'0 : 1 : 2 : 3 : 4 : 0 : 1 : 4 : 9 : 16\\'\\n\\nIn more advanced roles, however, this extension allows subgenerators to receive sent\\nand thrown values directly from the calling scope, and return a final value to the outer\\ngenerator. The net effect is to allow such generators to be split into multiple subgen-\\nerators much as a single function can be split into multiple subfunctions.\\n\\nSince this is only available in 3.3 and later, and is beyond this chapter’s generator cov-\\nerage in general, we’ll defer to Python 3.3’s manuals for additional details. For an ad-\\nditional yield from example, also see the solution to this part’s Exercise 11 described\\nat the end of Chapter 21.\\n\\nGeneration in Built-in Types, Tools, and Classes\\nFinally, although we’ve focused on coding value generators ourselves in this section,\\ndon’t  forget  that  many  built-in  types  behave  in  similar  ways—as  we  saw  in  Chap-\\nter 14, for example, dictionaries are iterables with iterators that produce keys on each\\niteration:\\n\\n>>> D = {\\'a\\':1, \\'b\\':2, \\'c\\':3}\\n>>> x = iter(D)\\n>>> next(x)\\n\\'c\\'\\n>>> next(x)\\n\\'b\\'\\n\\nLike the values produced by handcoded generators, dictionary keys may be iterated\\nover both manually and with automatic iteration tools including for loops, map calls,\\nlist comprehensions, and the many other contexts we met in Chapter 14:\\n\\n>>> for key in D:\\n        print(key, D[key])\\n\\nc 3\\nb 2\\na 1\\n\\nAs we’ve also seen, for file iterators, Python simply loads lines from the file on demand:\\n\\n>>> for line in open(\\'temp.txt\\'):\\n        print(line, end=\\'\\')\\n\\n606 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cTis but\\na flesh wound.\\n\\nWhile built-in type iterables are bound to a specific type of value generation, the con-\\ncept is similar to the multipurpose generators we code with expressions and functions.\\nIteration contexts like for loops accept any iterable that has the expected methods,\\nwhether user-defined or built-in.\\n\\nGenerators and library tools: Directory walkers\\nThough beyond this book’s scope, many Python standard library tools generate values\\ntoday too, including email parsers, and the standard directory walker—which at each\\nlevel of a tree yields a tuple of the current directory, its subdirectories, and its files:\\n\\n>>> import os\\n>>> for (root, subs, files) in os.walk(\\'.\\'):         # Directory walk generator\\n        for name in files:                           # A Python \\'find\\' operation\\n            if name.startswith(\\'call\\'):\\n                print(root, name)\\n\\n. callables.py\\n.\\\\dualpkg callables.py\\n\\nIn fact, os.walk is coded as a recursive function in Python in its os.py standard library\\nfile, in C:\\\\Python33\\\\Lib on Windows. Because it uses  yield (and in 3.3  yield from\\ninstead of a for loop) to return results, it’s a normal generator function, and hence an\\niterable object:\\n\\n>>> G = os.walk(r\\'C:\\\\code\\\\pkg\\')\\n>>> iter(G) is G                     # Single-scan iterator: iter(G) optional\\nTrue\\n>>> I = iter(G)\\n>>> next(I)\\n(\\'C:\\\\\\\\code\\\\\\\\pkg\\', [\\'__pycache__\\'], [\\'eggs.py\\', \\'eggs.pyc\\', \\'main.py\\', ...etc...])\\n>>> next(I)\\n(\\'C:\\\\\\\\code\\\\\\\\pkg\\\\\\\\__pycache__\\', [], [\\'eggs.cpython-33.pyc\\', ...etc...])\\n>>> next(I)\\nStopIteration\\n\\nBy yielding results as it goes, the walker does not require its clients to wait for an entire\\ntree to be scanned. See Python’s manuals and follow-up books such as Programming\\nPython for more on this tool. Also see Chapter 14 and others for os.popen—a related\\niterable used to run a shell command and read its output.\\n\\nGenerators and function application\\nIn Chapter 18, we noted that starred arguments can unpack an iterable into individual\\narguments. Now that we’ve seen generators, we can also see what this means in code.\\nIn both 3.X and 2.X (though 2.X’s range is a list):\\n\\n>>> def f(a, b, c): print(\\'%s, %s, and %s\\' % (a, b, c))\\n\\n>>> f(0, 1, 2)                       # Normal positionals\\n\\nGenerator Functions and Expressions\\n\\n| 607\\n\\n\\x0c0, 1, and 2\\n>>> f(*range(3))                     # Unpack range values: iterable in 3.X\\n0, 1, and 2\\n>>> f(*(i for i in range(3)))        # Unpack generator expression values\\n0, 1, and 2\\n\\nThis applies to dictionaries and views too (though dict.values is also a list in 2.X, and\\norder is arbitrary when passing values by position):\\n\\n>>> D = dict(a=\\'Bob\\', b=\\'dev\\', c=40.5); D\\n{\\'b\\': \\'dev\\', \\'c\\': 40.5, \\'a\\': \\'Bob\\'}\\n>>> f(a=\\'Bob\\', b=\\'dev\\', c=40.5)      # Normal keywords\\nBob, dev, and 40.5\\n>>> f(**D)                           # Unpack dict: key=value\\nBob, dev, and 40.5\\n>>> f(*D)                            # Unpack keys iterator\\nb, c, and a\\n>>> f(*D.values())                   # Unpack view iterator: iterable in 3.X\\ndev, 40.5, and Bob\\n\\nBecause the built-in print function in 3.X prints all its variable number of arguments,\\nthis also makes the following three forms equivalent—the latter using a * to unpack\\nthe results forced from a generator expression (though the second also creates a list of\\nreturn values, and the first may leave your cursor at the end of the output line in some\\nshells, but not in the IDLE GUI):\\n\\n>>> for x in \\'spam\\': print(x.upper(), end=\\' \\')\\nS P A M\\n\\n>>> list(print(x.upper(), end=\\' \\') for x in \\'spam\\')\\nS P A M [None, None, None, None]\\n\\n>>> print(*(x.upper() for x in \\'spam\\'))\\nS P A M\\n\\nSee Chapter 14 for an additional example that unpacks a file’s lines by iterator into\\narguments.\\n\\nPreview: User-defined iterables in classes\\nAlthough beyond the scope of this chapter, it is also possible to implement arbitrary\\nuser-defined generator objects with classes that conform to the iteration protocol. Such\\nclasses define a special __iter__ method run by the iter built-in function, which in\\nturn returns an object having a __next__ method (next in 2.X) run by the next built-in \\nfunction:\\n\\nclass SomeIterable:\\n    def __init__(...): ...     # On iter(): return self or supplemental object\\n    def __next__(...): ...     # On next(): coded here, or in another class\\n\\nAs the prior section suggested, these classes usually return their objects directly for\\nsingle-iteration behavior, or a supplemental object with scan-specific state for multiple-\\nscan support.\\n\\n608 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cAlternatively,  a  user-defined  iterable  class’s  method  functions  can  sometimes  use\\nyield  to  transform  themselves  into  generators,  with  an  automatically  created\\n__next__ method—a common application of yield we’ll meet in Chapter 30 that is\\nboth  wildly  implicit  and  potentially  useful!  A  __getitem__  indexing  method  is  also\\navailable as a fallback option for iteration, though this is often not as flexible as the\\n__iter__ and __next__ scheme (but has advantages for coding sequences).\\nThe instance objects created from such a class are considered iterable and may be used\\nin for loops and all other iteration contexts. With classes, though, we have access to\\nricher  logic  and  data  structuring  options,  such  as  inheritance,  that  other  generator\\nconstructs cannot offer by themselves. By coding methods, classes also can make iter-\\nation behavior much more explicit than the “magic” generator objects associated with\\nbuilt-in  types  and  generator  functions  and  expressions  (though  classes  wield  some\\nmagic of their own).\\nHence, the iterator and generator story won’t really be complete until we’ve seen how\\nit maps to classes, too. For now, we’ll have to settle for postponing its conclusion—\\nand its final sequel—until we study class-based iterables in Chapter 30.\\n\\nExample: Generating Scrambled Sequences\\nTo demonstrate the power of iteration tools in action, let’s turn to some more complete\\nuse case examples. In Chapter 18, we wrote a testing function that scrambled the order\\nof arguments used to test generalized intersection and union functions. There, I noted\\nthat this might be better coded as a generator of values. Now that we’ve learned how\\nto write generators, this serves to illustrate a practical application.\\nOne note up front: because they slice and concatenate objects, all the examples in the\\nsection (including the permutations at the end) work only on sequences like strings and\\nlist, not on arbitrary iterables like files, maps, and other generators. That is, some of\\nthese examples will be generators themselves, producing values on request, but they\\ncannot process generators as their inputs. Generalization for broader categories is left\\nas an open issue, though the code here will suffice unchanged if you wrap nonsequence\\ngenerators in list calls before passing them in.\\n\\nScrambling sequences\\nAs coded in Chapter 18, we can reorder a sequence with slicing and concatenation,\\nmoving the front item to the end on each loop; slicing instead of indexing the item\\nallows + to work for arbitrary sequence types:\\n\\n>>> L, S = [1, 2, 3], \\'spam\\'\\n>>> for i in range(len(S)):            # For repeat counts 0..3\\n        S = S[1:] + S[:1]              # Move front item to the end\\n        print(S, end=\\' \\')\\n\\npams amsp mspa spam\\n\\nGenerator Functions and Expressions\\n\\n| 609\\n\\n\\x0c>>> for i in range(len(L)):\\n        L = L[1:] + L[:1]              # Slice so any sequence type works\\n        print(L, end=\\' \\')\\n\\n[2, 3, 1] [3, 1, 2] [1, 2, 3]\\n\\nAlternatively, as we saw in Chapter 13, we get the same results by moving an entire\\nfront section to the end, though the order of the results varies slightly:\\n\\n>>> for i in range(len(S)):            # For positions 0..3\\n        X = S[i:] + S[:i]              # Rear part + front part (same effect)\\n        print(X, end=\\' \\')\\n\\nspam pams amsp mspa\\n\\nSimple functions\\nAs is, this code works on specific named variables only. To generalize, we can turn it\\ninto a simple function to work on any object passed to its argument and return a result;\\nsince the first of these exhibits the classic list comprehension pattern, we can save some\\nwork by coding it as such in the second:\\n\\n>>> def scramble(seq):\\n        res = []\\n        for i in range(len(seq)):\\n            res.append(seq[i:] + seq[:i])\\n        return res\\n\\n>>> scramble(\\'spam\\')\\n[\\'spam\\', \\'pams\\', \\'amsp\\', \\'mspa\\']\\n\\n>>> def scramble(seq):\\n        return [seq[i:] + seq[:i] for i in range(len(seq))]\\n\\n>>> scramble(\\'spam\\')\\n[\\'spam\\', \\'pams\\', \\'amsp\\', \\'mspa\\']\\n\\n>>> for x in scramble((1, 2, 3)):\\n        print(x, end=\\' \\')\\n\\n(1, 2, 3) (2, 3, 1) (3, 1, 2)\\n\\nWe could use recursion here as well, but it’s probably overkill in this context.\\n\\nGenerator functions\\nThe preceding section’s simple approach works, but must build an entire result list in\\nmemory all at once (not great on memory usage if it’s massive), and requires the caller\\nto wait until the entire list is complete (less than ideal if this takes a substantial amount\\nof time). We can do better on both fronts by translating this to a generator function that\\nyields one result at a time, using either coding scheme:\\n\\n>>> def scramble(seq):\\n        for i in range(len(seq)):\\n\\n610 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c            seq = seq[1:] + seq[:1]              # Generator function\\n            yield seq                            # Assignments work here\\n\\n>>> def scramble(seq):\\n        for i in range(len(seq)):                # Generator function\\n            yield seq[i:] + seq[:i]              # Yield one item per iteration\\n\\n>>> list(scramble(\\'spam\\'))                       # list()generates all results\\n[\\'spam\\', \\'pams\\', \\'amsp\\', \\'mspa\\']\\n>>> list(scramble((1, 2, 3)))                    # Any sequence type works\\n[(1, 2, 3), (2, 3, 1), (3, 1, 2)]\\n>>>\\n>>> for x in scramble((1, 2, 3)):                # for loops generate results\\n        print(x, end=\\' \\')\\n\\n(1, 2, 3) (2, 3, 1) (3, 1, 2)\\n\\nGenerator functions retain their local scope state while active, minimize memory space\\nrequirements, and divide the work into shorter time slices. As full functions, they are\\nalso  very  general.  Importantly,  for  loops  and  other  iteration  tools  work  the  same\\nwhether stepping through a real list or a generator of values—the function can select\\nbetween the two schemes freely, and even change strategies in the future.\\n\\nGenerator expressions\\nAs  we’ve  seen,  generator  expressions—comprehensions  in  parentheses  instead  of\\nsquare brackets—also generate values on request and retain their local state. They’re\\nnot as flexible as full functions, but because they yield their values automatically, ex-\\npressions can often be more concise in specific use cases like this:\\n\\n>>> S\\n\\'spam\\'\\n>>> G = (S[i:] + S[:i] for i in range(len(S)))   # Generator expression equivalent\\n>>> list(G)\\n[\\'spam\\', \\'pams\\', \\'amsp\\', \\'mspa\\']\\n\\nNotice that we can’t use the assignment statement of the first generator function version\\nhere, because generator expressions cannot contain statements. This makes them a bit\\nnarrower in scope; in many cases, though, expressions can do similar work, as shown\\nhere. To generalize a generator expression for an arbitrary subject, wrap it in a simple\\nfunction that takes an argument and returns a generator that uses it:\\n\\n>>> F = lambda seq: (seq[i:] + seq[:i] for i in range(len(seq)))\\n>>> F(S)\\n<generator object <genexpr> at 0x00000000029883F0>\\n>>>\\n>>> list(F(S))\\n[\\'spam\\', \\'pams\\', \\'amsp\\', \\'mspa\\']\\n>>> list(F([1, 2, 3]))\\n[[1, 2, 3], [2, 3, 1], [3, 1, 2]]\\n\\n>>> for x in F((1, 2, 3)):\\n        print(x, end=\\' \\')\\n\\nGenerator Functions and Expressions\\n\\n| 611\\n\\n\\x0c(1, 2, 3) (2, 3, 1) (3, 1, 2)\\n\\nTester client\\nFinally, we can use either the generator function or its expression equivalent in Chap-\\nter 18’s tester to produce scrambled arguments—the sequence scrambling function\\nbecomes a tool we can use in other contexts:\\n\\n# file scramble.py\\n\\ndef scramble(seq):\\n    for i in range(len(seq)):                # Generator function\\n        yield seq[i:] + seq[:i]              # Yield one item per iteration\\n\\nscramble2 = lambda seq: (seq[i:] + seq[:i] for i in range(len(seq)))\\n\\nAnd by moving the values generation out to an external tool, the tester becomes simpler:\\n\\n>>> from scramble import scramble\\n>>> from inter2 import intersect, union\\n>>>\\n>>> def tester(func, items, trace=True):\\n        for args in scramble(items):         # Use generator (or: scramble2(items))\\n            if trace: print(args)\\n            print(sorted(func(*args)))\\n\\n>>> tester(intersect, (\\'aab\\', \\'abcde\\', \\'ababab\\'))\\n(\\'aab\\', \\'abcde\\', \\'ababab\\')\\n[\\'a\\', \\'b\\']\\n(\\'abcde\\', \\'ababab\\', \\'aab\\')\\n[\\'a\\', \\'b\\']\\n(\\'ababab\\', \\'aab\\', \\'abcde\\')\\n[\\'a\\', \\'b\\']\\n\\n>>> tester(intersect, ([1, 2], [2, 3, 4], [1, 6, 2, 7, 3]), False)\\n[2]\\n[2]\\n[2]\\n\\nPermutations: All possible combinations\\nThese techniques have many other real-world applications—consider generating at-\\ntachments in an email message or points to be plotted in a GUI. Moreover, other types\\nof sequence scrambles serve central roles in other applications, from searches to math-\\nematics. As is, our sequence scrambler is a simple reordering, but some programs war-\\nrant the more exhaustive set of all possible orderings we get from permutations—pro-\\nduced using recursive functions in both list-builder and generator forms by the follow-\\ning module file:\\n\\n# File permute.py\\n\\ndef permute1(seq):\\n    if not seq:                               # Shuffle any sequence: list\\n\\n612 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c        return [seq]                          # Empty sequence\\n    else:\\n        res = []\\n        for i in range(len(seq)):\\n            rest = seq[:i] + seq[i+1:]        # Delete current node\\n            for x in permute1(rest):          # Permute the others\\n                res.append(seq[i:i+1] + x)    # Add node at front\\n        return res\\n\\ndef permute2(seq):\\n    if not seq:                               # Shuffle any sequence: generator\\n        yield seq                             # Empty sequence\\n    else:\\n        for i in range(len(seq)):\\n            rest = seq[:i] + seq[i+1:]        # Delete current node\\n            for x in permute2(rest):          # Permute the others\\n                yield seq[i:i+1] + x          # Add node at front\\n\\nBoth of these functions produce the same results, though the second defers much of its\\nwork until it is asked for a result. This code is a bit advanced, especially the second of\\nthese functions (and to some Python newcomers might even be categorized as cruel\\nand inhumane punishment!). Still, as I’ll explain in a moment, there are cases where\\nthe generator approach can be highly useful.\\nStudy and test this code for more insight, and add prints to trace if it helps. If it’s still\\na mystery, try to make sense of the first version first; remember that generator functions\\nsimply return objects with methods that handle next operations run by for loops at\\neach level, and don’t produce any results until iterated; and trace through some of the\\nfollowing examples to see how they’re handled by this code.\\nPermutations produce more orderings than the original shuffler—for N items, we get\\nN! (factorial) results instead of just N (24 for 4: 4 * 3 * 2 * 1). In fact, that’s why we need\\nrecursion here: the number of nested loops is arbitrary, and depends on the length of\\nthe sequence permuted:\\n\\n>>> from scramble import scramble\\n>>> from permute import permute1, permute2\\n\\n>>> list(scramble(\\'abc\\'))                            # Simple scrambles: N\\n[\\'abc\\', \\'bca\\', \\'cab\\']\\n\\n>>> permute1(\\'abc\\')                                  # Permutations larger: N!\\n[\\'abc\\', \\'acb\\', \\'bac\\', \\'bca\\', \\'cab\\', \\'cba\\']\\n>>> list(permute2(\\'abc\\'))                            # Generate all combinations\\n[\\'abc\\', \\'acb\\', \\'bac\\', \\'bca\\', \\'cab\\', \\'cba\\']\\n\\n>>> G = permute2(\\'abc\\')                              # Iterate (iter() not needed)\\n>>> next(G)\\n\\'abc\\'\\n>>> next(G)\\n\\'acb\\'\\n>>> for x in permute2(\\'abc\\'): print(x)               # Automatic iteration\\n...prints six lines...\\n\\nGenerator Functions and Expressions\\n\\n| 613\\n\\n\\x0cThe list and generator versions’ results are the same, though the generator minimizes\\nboth space usage and delays for results. For larger items, the set of all permutations is\\nmuch larger than the simpler scrambler’s:\\n\\n>>> permute1(\\'spam\\') == list(permute2(\\'spam\\'))\\nTrue\\n>>> len(list(permute2(\\'spam\\'))), len(list(scramble(\\'spam\\')))\\n(24, 4)\\n\\n>>> list(scramble(\\'spam\\'))\\n[\\'spam\\', \\'pams\\', \\'amsp\\', \\'mspa\\']\\n>>> list(permute2(\\'spam\\'))\\n[\\'spam\\', \\'spma\\', \\'sapm\\', \\'samp\\', \\'smpa\\', \\'smap\\', \\'psam\\', \\'psma\\', \\'pasm\\', \\'pams\\',\\n \\'pmsa\\', \\'pmas\\', \\'aspm\\', \\'asmp\\', \\'apsm\\', \\'apms\\', \\'amsp\\', \\'amps\\', \\'mspa\\', \\'msap\\',\\n \\'mpsa\\', \\'mpas\\', \\'masp\\', \\'maps\\']\\n\\nPer Chapter 19, there are nonrecursive alternatives here too, using explicit stacks or\\nqueues, and other sequence orderings are common (e.g., fixed-size subsets and com-\\nbinations that filter out duplicates of differing order), but these require coding exten-\\nsions we’ll forgo here. See the book Programming Python for more on this theme, or\\nexperiment further on your own.\\n\\nDon’t Abuse Generators: EIBTI\\nGenerators are a somewhat advanced tool, and might be better treated as an optional\\ntopic, but for the fact that they permeate the Python language, especially in 3.X. In fact,\\nthey seem less optional to this book’s audience than Unicode (which was exiled to\\nPart  VIII).  As  we’ve  seen,  fundamental  built-in  tools  such  as  range,  map,  dictionary\\nkeys, and even files are now generators, so you must be familiar with the concept even\\nif you don’t write new generators of your own. Moreover, user-defined generators are\\nincreasingly common in Python code that you might come across today—in the Python\\nstandard library, for instance.\\nIn general, the same cautions I gave for list comprehensions apply here as well: don’t\\ncomplicate your code with user-defined generators if they are not warranted. Especially\\nfor smaller programs and data sets, there may be no good reason to use these tools. In\\nsuch  cases,  simple  lists  of  results  will  suffice,  will  be  easier  to  understand,  will  be\\ngarbage-collected automatically, and may be produced quicker (and they are today: see\\nthe next chapter). Advanced tools like generators that rely on implicit “magic” can be\\nfun to experiment with, but they have no place in real code that must be used by others\\nexcept when clearly justified.\\nOr, to quote from Python’s import this motto again:\\n\\nExplicit is better than implicit.\\n\\nThe acronym for this, EIBTI, is one of Python’s core guidelines, and for good reason:\\nthe more explicit your code is about its behavior, the more likely it is that the next\\nprogrammer will be able to understand it. This applies directly to generators, whose\\n\\n614 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cimplicit behavior may very well be more difficult for some to grasp than less obscure\\nalternatives. Always: keep it simple unless it must be complicated!\\n\\nOn the other hand: Space and time, conciseness, expressiveness\\nThat being said, there are specific use cases that generators can address well. They can\\nreduce memory footprint in some programs, reduce delays in others, and can occa-\\nsionally make the impossible possible. Consider, for example, a program that must\\nproduce all possible permutations of a nontrivial sequence. Since the number of com-\\nbinations is a factorial that explodes exponentially, the preceding permute1 recursive\\nlist-builder function will either introduce a noticeable and perhaps interminable pause\\nor fail completely due to memory requirements, whereas the permute2 recursive gen-\\nerator will not—it returns each individual result quickly, and can handle very large\\nresult sets:\\n\\n>>> import math\\n>>> math.factorial(10)               # 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2 * 1\\n3628800\\n>>> from permute import permute1, permute2\\n>>> seq = list(range(10))\\n>>> p1 = permute1(seq)               # 37 seconds on a 2GHz quad-core machine\\n                                     # Creates a list of 3.6M numbers\\n>>> len(p1), p1[0], p1[1]\\n(3628800, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 9, 8])\\n\\nIn this case, the list builder pauses for 37 seconds on my computer to build a 3.6-million-\\nitem list, but the generator can begin returning results immediately:\\n\\n>>> p2 = permute2(seq)               # Returns generator immediately\\n>>> next(p2)                         # And produces each result quickly on request\\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\\n>>> next(p2)\\n[0, 1, 2, 3, 4, 5, 6, 7, 9, 8]\\n\\n>>> p2 = list(permute2(seq))         # About 28 seconds, though still impractical\\n>>> p1 == p2                         # Same set of results generated\\nTrue\\n\\nNaturally, we might be able to optimize the list builder’s code to run quicker (e.g., an\\nexplicit stack instead of recursion might change its performance), but for larger se-\\nquences, it’s not an option at all—at just 50 items, the number of permutations pre-\\ncludes building a results list, and would take far too long for mere mortals like us (and\\nlarger values will overflow the preset recursion stack depth limit: see the preceding\\nchapter). The generator, however, is still viable—it is able to produce individual results\\nimmediately:\\n\\n>>> math.factorial(50)\\n30414093201713378043612608166064768844377641568960512000000000000\\n>>> p3 = permute2(list(range(50)))\\n>>> next(p3)                         # permute1 is not an option here!\\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\\n\\nGenerator Functions and Expressions\\n\\n| 615\\n\\n\\x0c23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\\n44, 45, 46, 47, 48, 49]\\n\\nFor more fun—and to yield results that are more variable and less obviously determin-\\nistic—we could also use Python’s random module of Chapter 5 to randomly shuffle the\\nsequence to be permuted before the permuter begins its work. (In fact, we might be\\nable to use the random shuffler as a permutation generator in general, as long as we\\neither can assume that it won’t repeat shuffles during the time we consume them, or\\ntest its results against prior shuffles to avoid repeats—and hope that we do not live in\\nthe strange universe where a random sequence repeats the same result an infinite num-\\nber of times!). In the following, each permute2 and next call returns immediately as\\nbefore, but a permute1 hangs:\\n\\n>>> import random\\n>>> math.factorial(20)               # permute1 is not an option here\\n2432902008176640000\\n>>> seq = list(range(20))\\n\\n>>> random.shuffle(seq)              # Shuffle sequence randomly first\\n>>> p = permute2(seq)\\n>>> next(p)\\n[10, 17, 4, 14, 11, 3, 16, 19, 12, 8, 6, 5, 2, 15, 18, 7, 1, 0, 13, 9]\\n>>> next(p)\\n[10, 17, 4, 14, 11, 3, 16, 19, 12, 8, 6, 5, 2, 15, 18, 7, 1, 0, 9, 13]\\n\\n>>> random.shuffle(seq)\\n>>> p = permute2(seq)\\n>>> next(p)\\n[16, 1, 5, 14, 15, 12, 0, 2, 6, 19, 10, 17, 11, 18, 13, 7, 4, 9, 8, 3]\\n>>> next(p)\\n[16, 1, 5, 14, 15, 12, 0, 2, 6, 19, 10, 17, 11, 18, 13, 7, 4, 9, 3, 8]\\n\\nThe main point here is that generators can sometimes produce results from large sol-\\nution sets when list builders cannot. Then again, it’s not clear how common such use\\ncases may be in the real world, and this doesn’t necessarily justify the implicit flavor of\\nvalue generation that we get with generator functions and expressions. As we’ll see in\\nPart VI, value generation can also be coded as iterable objects with classes. Class-based\\niterables can produce items on request too, and are far more explicit than the magic\\nobjects and methods produced for generator functions and expressions.\\nPart of programming is finding a balance among tradeoffs like these, and there are no\\nabsolute rules here. While the benefits of generators may sometimes justify their use,\\nmaintainability should always be a top priority too. Like comprehensions, generators\\nalso offer an expressiveness and code economy that’s hard to resist if you understand\\nhow they work—but you’ll want to weigh this against the frustration of coworkers who \\nmight not.\\n\\n616 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cExample: Emulating zip and map with Iteration Tools\\nTo help you evaluate their roles further, let’s take a quick look at one more example of\\ngenerators in action that illustrates just how expressive they can be. Once you know\\nabout comprehensions, generators, and other iteration tools, it turns out that emulating\\nmany of Python’s functional built-ins is both straightforward and instructive. For ex-\\nample, we’ve already seen how the built-in zip and map functions combine iterables and\\nproject  functions  across  them,  respectively.  With  multiple  iterable  arguments,  map\\nprojects the function across items taken from each iterable in much the same way that\\nzip pairs them up:\\n>>> S1 = \\'abc\\'\\n>>> S2 = \\'xyz123\\'\\n>>> list(zip(S1, S2))                          # zip pairs items from iterables\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\')]\\n\\n# zip pairs items, truncates at shortest\\n>>> list(zip([−2, −1, 0, 1, 2]))               # Single sequence: 1-ary tuples\\n[(−2,), (−1,), (0,), (1,), (2,)]\\n>>> list(zip([1, 2, 3], [2, 3, 4, 5]))         # N sequences: N-ary tuples\\n[(1, 2), (2, 3), (3, 4)]\\n\\n# map passes paired items to function, truncates\\n>>> list(map(abs, [−2, −1, 0, 1, 2]))          # Single sequence: 1-ary function\\n[2, 1, 0, 1, 2]\\n>>> list(map(pow, [1, 2, 3], [2, 3, 4, 5]))    # N sequences: N-ary function\\n[1, 8, 81]\\n\\n# map and zip accept arbitrary iterables\\n>>> map(lambda x, y: x + y, open(\\'script2.py\\'), open(\\'script2.py\\'))\\n[\\'import sys\\\\nimport sys\\\\n\\', \\'print(sys.path)\\\\nprint(sys.path)\\\\n\\', ...etc...]\\n\\n>>> [x + y for (x, y) in zip(open(\\'script2.py\\'), open(\\'script2.py\\'))]\\n[\\'import sys\\\\nimport sys\\\\n\\', \\'print(sys.path)\\\\nprint(sys.path)\\\\n\\', ...etc...]\\n\\nThough they’re being used for different purposes, if you study these examples long\\nenough,  you  might  notice  a  relationship  between  zip  results  and  mapped  function\\narguments that our next example can exploit.\\n\\nCoding your own map(func, ...)\\nAlthough the map and zip built-ins are fast and convenient, it’s always possible to em-\\nulate them in code of our own. In the preceding chapter, for example, we saw a function\\nthat emulated the map built-in for a single sequence (or other iterable) argument. It\\ndoesn’t take much more work to allow for multiple sequences, as the built-in does:\\n\\n# map(func, seqs...) workalike with zip\\n\\ndef mymap(func, *seqs):\\n    res = []\\n    for args in zip(*seqs):\\n        res.append(func(*args))\\n\\nGenerator Functions and Expressions\\n\\n| 617\\n\\n\\x0c    return res\\n\\nprint(mymap(abs, [-2, −1, 0, 1, 2]))\\nprint(mymap(pow, [1, 2, 3], [2, 3, 4, 5]))\\n\\nThis version relies heavily upon the special *args argument-passing syntax—it collects\\nmultiple sequence (really, iterable) arguments, unpacks them as zip arguments to com-\\nbine, and then unpacks the paired zip results as arguments to the passed-in function.\\nThat is, we’re using the fact that the zipping is essentially a nested operation in mapping.\\nThe test code at the bottom applies this to both one and two sequences to produce this\\noutput—the same we would get with the built-in map (this code is in file mymap.py in\\nthe book’s examples if you want to run it live):\\n\\n[2, 1, 0, 1, 2]\\n[1, 8, 81]\\n\\nReally, though, the prior version exhibits the classic list comprehension pattern, building\\na list of operation results within a for loop. We can code our map more concisely as\\nan equivalent one-line list comprehension:\\n\\n# Using a list comprehension\\n\\ndef mymap(func, *seqs):\\n    return [func(*args) for args in zip(*seqs)]\\n\\nprint(mymap(abs, [−2, −1, 0, 1, 2]))\\nprint(mymap(pow, [1, 2, 3], [2, 3, 4, 5]))\\n\\nWhen this is run the result is the same as before, but the code is more concise and might\\nrun  faster  (more  on  performance  in  the  section  “Timing  Iteration  Alterna-\\ntives” on page 629). Both of the preceding mymap versions build result lists all at once,\\nthough, and this can waste memory for larger lists. Now that we know about generator\\nfunctions and expressions, it’s simple to recode both these alternatives to produce results\\non demand instead:\\n\\n# Using generators: yield and (...)\\n\\ndef mymap(func, *seqs):\\n    res = []\\n    for args in zip(*seqs):\\n        yield func(*args)\\n\\ndef mymap(func, *seqs):\\n    return (func(*args) for args in zip(*seqs))\\n\\nThese versions produce the same results but return generators designed to support the\\niteration protocol—the first yields one result at a time, and the second returns a gen-\\nerator expression’s result to do the same. They produce the same results if we wrap\\nthem in list calls to force them to produce their values all at once:\\n\\nprint(list(mymap(abs, [−2, −1, 0, 1, 2])))\\nprint(list(mymap(pow, [1, 2, 3], [2, 3, 4, 5])))\\n\\n618 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cNo work is really done here until the list calls force the generators to run, by activating\\nthe iteration protocol. The generators returned by these functions themselves, as well\\nas that returned by the Python 3.X flavor of the zip built-in they use, produce results\\nonly on demand.\\n\\nCoding your own zip(...) and map(None, ...)\\nOf course, much of the magic in the examples shown so far lies in their use of the zip\\nbuilt-in to pair arguments from multiple sequences or iterables. Our map workalikes are\\nalso really emulating the behavior of the Python 3.X map—they truncate at the length\\nof the shortest argument, and they do not support the notion of padding results when\\nlengths differ, as map does in Python 2.X with a None argument:\\n\\nC:code> c:\\\\python27\\\\python\\n>>> map(None, [1, 2, 3], [2, 3, 4, 5])\\n[(1, 2), (2, 3), (3, 4), (None, 5)]\\n>>> map(None, \\'abc\\', \\'xyz123\\')\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\'), (None, \\'1\\'), (None, \\'2\\'), (None, \\'3\\')]\\n\\nUsing iteration tools, we can code workalikes that emulate both truncating zip and\\n2.X’s padding map—these turn out to be nearly the same in code:\\n\\n# zip(seqs...) and 2.X map(None, seqs...) workalikes\\n\\ndef myzip(*seqs):\\n    seqs = [list(S) for S in seqs]\\n    res  = []\\n    while all(seqs):\\n        res.append(tuple(S.pop(0) for S in seqs))\\n    return res\\n\\ndef mymapPad(*seqs, pad=None):\\n    seqs = [list(S) for S in seqs]\\n    res  = []\\n    while any(seqs):\\n        res.append(tuple((S.pop(0) if S else pad) for S in seqs))\\n    return res\\n\\nS1, S2 = \\'abc\\', \\'xyz123\\'\\nprint(myzip(S1, S2))\\nprint(mymapPad(S1, S2))\\nprint(mymapPad(S1, S2, pad=99))\\n\\nBoth of the functions coded here work on any type of iterable object, because they run\\ntheir arguments through the list built-in to force result generation (e.g., files would\\nwork as arguments, in addition to sequences like strings). Notice the use of the all and\\nany built-ins here—these return True if all and any items in an iterable are True (or\\nequivalently, nonempty), respectively. These built-ins are used to stop looping when\\nany or all of the listified arguments become empty after deletions.\\nAlso note the use of the Python 3.X keyword-only argument, pad; unlike the 2.X map,\\nour  version  will  allow  any  pad  object  to  be  specified  (if  you’re  using  2.X,  use  a\\n\\nGenerator Functions and Expressions\\n\\n| 619\\n\\n\\x0c**kargs form to support this option instead; see Chapter 18 for details). When these\\nfunctions are run, the following results are printed—a zip, and two padding maps:\\n\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\')]\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\'), (None, \\'1\\'), (None, \\'2\\'), (None, \\'3\\')]\\n[(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\'), (99, \\'1\\'), (99, \\'2\\'), (99, \\'3\\')]\\n\\nThese functions aren’t amenable to list comprehension translation because their loops\\nare too specific. As before, though, while our zip and map workalikes currently build\\nand return result lists, it’s just as easy to turn them into generators with yield so that\\nthey each return one piece of their result set at a time. The results are the same as before,\\nbut we need to use list again to force the generators to yield their values for display:\\n\\n# Using generators: yield\\n\\ndef myzip(*seqs):\\n    seqs = [list(S) for S in seqs]\\n    while all(seqs):\\n        yield tuple(S.pop(0) for S in seqs)\\n\\ndef mymapPad(*seqs, pad=None):\\n    seqs = [list(S) for S in seqs]\\n    while any(seqs):\\n        yield tuple((S.pop(0) if S else pad) for S in seqs)\\n\\nS1, S2 = \\'abc\\', \\'xyz123\\'\\nprint(list(myzip(S1, S2)))\\nprint(list(mymapPad(S1, S2)))\\nprint(list(mymapPad(S1, S2, pad=99)))\\n\\nFinally, here’s an alternative implementation of our zip and map emulators—rather than\\ndeleting arguments from lists with the pop method, the following versions do their job\\nby  calculating  the  minimum  and  maximum  argument  lengths.  Armed  with  these\\nlengths, it’s easy to code nested list comprehensions to step through argument index\\nranges:\\n\\n# Alternate implementation with lengths\\n\\ndef myzip(*seqs):\\n    minlen = min(len(S) for S in seqs)\\n    return [tuple(S[i] for S in seqs) for i in range(minlen)]\\n\\ndef mymapPad(*seqs, pad=None):\\n    maxlen = max(len(S) for S in seqs)\\n    index  = range(maxlen)\\n    return [tuple((S[i] if len(S) > i else pad) for S in seqs) for i in index]\\n\\nS1, S2 = \\'abc\\', \\'xyz123\\'\\nprint(myzip(S1, S2))\\nprint(mymapPad(S1, S2))\\nprint(mymapPad(S1, S2, pad=99))\\n\\nBecause these use len and indexing, they assume that arguments are sequences or sim-\\nilar, not arbitrary iterables, much like our earlier sequence scramblers and permuters.\\n\\n620 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cThe outer comprehensions here step through argument index ranges, and the inner\\ncomprehensions (passed to tuple) step through the passed-in sequences to pull out\\narguments in parallel. When they’re run, the results are as before.\\nMost strikingly, generators and iterators seem to run rampant in this example. The\\narguments passed to min and max are generator expressions, which run to completion\\nbefore the nested comprehensions begin iterating. Moreover, the nested list compre-\\nhensions employ two levels of delayed evaluation—the Python 3.X range built-in is an\\niterable, as is the generator expression argument to tuple.\\nIn fact, no results are produced here until the square brackets of the list comprehensions\\nrequest values to place in the result list—they force the comprehensions and generators\\nto run. To turn these functions themselves into generators instead of list builders, use\\nparentheses instead of square brackets again. Here’s the case for our zip:\\n\\n# Using generators: (...)\\n\\ndef myzip(*seqs):\\n    minlen = min(len(S) for S in seqs)\\n    return (tuple(S[i] for S in seqs) for i in range(minlen))\\n\\nS1, S2 = \\'abc\\', \\'xyz123\\'\\nprint(list(myzip(S1, S2)))         # Go!... [(\\'a\\', \\'x\\'), (\\'b\\', \\'y\\'), (\\'c\\', \\'z\\')]\\n\\nIn this case, it takes a list call to activate the generators and other iterables to produce\\ntheir results. Experiment with these on your own for more details. Developing further\\ncoding alternatives is left as a suggested exercise (see also the sidebar “Why You Will\\nCare: One-Shot Iterations” on page 621 for investigation of one such option).\\n\\nWatch for more yield examples in Chapter 30, where we’ll use it in\\nconjunction with the __iter__ operator overloading method to imple-\\nment user-defined iterable objects in an automated fashion. The state\\nretention of local variables in this role serves as an alternative to class\\nattributes in the same spirit as the closure functions of Chapter 17; as\\nwe’ll see, though, this technique combines classes and functional tools\\ninstead of posing a paradigm alternative.\\n\\nWhy You Will Care: One-Shot Iterations\\n\\nIn Chapter 14, we saw how some built-ins (like map) support only a single traversal and\\nare empty after it occurs, and I promised to show you an example of how that can\\nbecome subtle but important in practice. Now that we’ve studied a few more iteration\\ntopics, I can make good on this promise. Consider the following clever alternative cod-\\ning for this chapter’s zip emulation examples, adapted from one in Python’s manuals\\nat the time I wrote these words:\\n\\ndef myzip(*args):\\n    iters = map(iter, args)\\n    while iters:\\n\\nGenerator Functions and Expressions\\n\\n| 621\\n\\n\\x0c        res = [next(i) for i in iters]\\n        yield tuple(res)\\n\\nBecause this code uses iter and next, it works on any type of iterable. Note that there\\nis no reason to catch the StopIteration raised by the next(it) inside the comprehension\\nhere when any one of the arguments’ iterators is exhausted—allowing it to pass ends\\nthis generator function and has the same effect that a return statement would. The\\nwhile iters: suffices to loop if at least one argument is passed, and avoids an infinite\\nloop otherwise (the list comprehension would always return an empty list).\\n\\nThis code works fine in Python 2.X as is:\\n\\n>>> list(myzip(\\'abc\\', \\'lmnop\\'))\\n[(\\'a\\', \\'l\\'), (\\'b\\', \\'m\\'), (\\'c\\', \\'n\\')]\\n\\nBut it falls into an infinite loop and fails in Python 3.X, because the 3.X map returns a\\none-shot iterable object instead of a list as in 2.X. In 3.X, as soon as we’ve run the list\\ncomprehension inside the loop once, iters will be exhausted but still True (and res will\\nbe []) forever. To make this work in 3.X, we need to use the list built-in function to\\ncreate an object that can support multiple iterations:\\n\\ndef myzip(*args):\\n    iters = list(map(iter, args))       # Allow multiple scans\\n    ...rest as is...\\n\\nRun this on your own to trace its operation. The lesson here: wrapping map calls in\\nlist calls in 3.X is not just for display!\\n\\nComprehension Syntax Summary\\nWe’ve been focusing on list comprehensions and generators in this chapter, but keep\\nin mind that there are two other comprehension expression forms available in both 3.X\\nand 2.7: set and dictionary comprehensions. We met these briefly in Chapter 5 and\\nChapter 8, but with our new knowledge of comprehensions and generators, you should\\nnow be able to grasp these extensions in full:\\n\\n• For sets, the new literal form {1, 3, 2} is equivalent to set([1, 3, 2]), and the\\nnew set comprehension syntax {f(x) for x in S if P(x)} is like the generator\\nexpression set(f(x) for x in S if P(x)), where f(x) is an arbitrary expression.\\n• For dictionaries, the new dictionary comprehension syntax {key: val for (key,\\nval) in zip(keys, vals)} works like the form dict(zip(keys, vals)), and {x:\\nf(x) for x in items} is like the generator expression dict((x, f(x)) for x in\\nitems).\\n\\nHere’s a summary of all the comprehension alternatives in 3.X and 2.7. The last two\\nare new and are not available in 2.6 and earlier:\\n\\n>>> [x * x for x in range(10)]            # List comprehension: builds list\\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]      # Like list(generator expr)\\n\\n622 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c>>> (x * x for x in range(10))            # Generator expression: produces items\\n<generator object at 0x009E7328>          # Parens are often optional\\n\\n>>> {x * x for x in range(10)}            # Set comprehension, 3.X and 2.7\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}      # {x, y} is a set in these versions too\\n\\n>>> {x: x * x for x in range(10)}         # Dictionary comprehension, 3.X and 2.7\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\n\\nScopes and Comprehension Variables\\nNow that we’ve seen all comprehension forms, be sure to also review Chapter 17’s\\noverview of the localization of loop variables in these expressions. Python 3.X localizes\\nloop variables in all four forms—temporary loop variable names in generator, set, dic-\\ntionary, and list comprehensions are local to the expression. They don’t clash with\\nnames outside, but are also not available there, and work differently than the for loop\\niteration statement:\\n\\nc:\\\\code> py −3\\n>>> (X for X in range(5))\\n<generator object <genexpr> at 0x00000000028E4798>\\n>>> X\\nNameError: name \\'X\\' is not defined\\n\\n>>> X = 99\\n>>> [X for X in range(5)]         # 3.X: generator, set, dict, and list localize\\n[0, 1, 2, 3, 4]\\n>>> X\\n99\\n\\n>>> Y = 99\\n>>> for Y in range(5): pass       # But loop statements do not localize names\\n\\n>>> Y\\n4\\n\\nAs mentioned in Chapter 17, 3.X variables assigned in a comprehension are really a\\nfurther nested special-case scope; other names referenced within these expressions fol-\\nlow the usual LEGB rules. In the following generator, for example, Z is localized in the\\ncomprehension, but Y and X are found in the enclosing local and global scopes as usual:\\n\\n>>> X = \\'aaa\\'\\n>>> def func():\\n        Y = \\'bbb\\'\\n        print(\\'\\'.join(Z for Z in X + Y))       # Z comprehension, Y local, X global\\n\\n>>> func()\\naaabbb\\n\\nPython 2.X is the same in this regard, except that list comprehension variables are not\\nlocalized—they work just like for loops and keep their last iteration values, but are also\\n\\nComprehension Syntax Summary | 623\\n\\n\\x0copen to unexpected clashes with outside names. Generator, set, and dictionary forms\\nlocalize names as in 3.X:\\n\\nc:\\\\code> py −2\\n>>> (X for X in range(5))\\n<generator object <genexpr> at 0x0000000002147EE8>\\n>>> X\\nNameError: name \\'X\\' is not defined\\n\\n>>> X = 99\\n>>> [X for X in range(5)]         # 2.X: List does not localize its names, like for\\n[0, 1, 2, 3, 4]\\n>>> X\\n4\\n\\n>>> Y = 99\\n>>> for Y in range(5): pass       # for loops do not localize names in 2.X or 3.X\\n\\n>>> Y\\n4\\n\\nIf you care about version portability, and symmetry with the for loop statement, use\\nunique names for variables in comprehension expressions as a rule of thumb. The 2.X\\nbehavior makes sense given that a generator object is discarded after it finishes pro-\\nducing results, but a list comprehension is equivalent to a for loop—though this anal-\\nogy doesn’t hold for the set and dictionary forms that localize their names in both\\nPythons, and are, somewhat coincidentally, the topic of the next section.\\n\\nComprehending Set and Dictionary Comprehensions\\nIn a sense, set and dictionary comprehensions are just syntactic sugar for passing gen-\\nerator expressions to the type names. Because both accept any iterable, a generator\\nworks well here:\\n\\n>>> {x * x for x in range(10)}                # Comprehension\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}\\n>>> set(x * x for x in range(10))             # Generator and type name\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}\\n\\n>>> {x: x * x for x in range(10)}\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\n>>> dict((x, x * x) for x in range(10))\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\n\\n>>> x                                         # Loop variable localized in 2.X + 3.X\\nNameError: name \\'x\\' is not defined\\n\\nAs for list comprehensions, though, we can always build the result objects with manual\\ncode,  too.  Here  are  statement-based  equivalents  of  the  last  two  comprehensions\\n(though they differ in that name localization):\\n\\n>>> res = set()\\n>>> for x in range(10):                        # Set comprehension equivalent\\n\\n624 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0c        res.add(x * x)\\n\\n>>> res\\n{0, 1, 4, 81, 64, 9, 16, 49, 25, 36}\\n\\n>>> res = {}\\n>>> for x in range(10):                        # Dict comprehension equivalent\\n        res[x] = x * x\\n\\n>>> res\\n{0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\\n\\n>>> x   # Localized in comprehension expressions, but not in loop statements\\n9\\n\\nNotice that although both set and dictionary comprehensions accept and scan iterables,\\nthey have no notion of generating results on demand—both forms build complete ob-\\njects all at once. If you mean to produce keys and values upon request, a generator\\nexpression is more appropriate:\\n\\n>>> G = ((x, x * x) for x in range(10))\\n>>> next(G)\\n(0, 0)\\n>>> next(G)\\n(1, 1)\\n\\nExtended Comprehension Syntax for Sets and Dictionaries\\nLike list comprehensions and generator expressions, both set and dictionary compre-\\nhensions  support  nested  associated  if  clauses  to  filter  items  out  of  the  result—the\\nfollowing collect squares of even items (i.e., items having no remainder for division by\\n2) in a range:\\n\\n>>> [x * x for x in range(10) if x % 2 == 0]           # Lists are ordered\\n[0, 4, 16, 36, 64]\\n>>> {x * x for x in range(10) if x % 2 == 0}           # But sets are not\\n{0, 16, 4, 64, 36}\\n>>> {x: x * x for x in range(10) if x % 2 == 0}        # Neither are dict keys\\n{0: 0, 8: 64, 2: 4, 4: 16, 6: 36}\\n\\nNested for loops work as well, though the unordered and no-duplicates nature of both\\ntypes of objects can make the results a bit less straightforward to decipher:\\n>>> [x + y for x in [1, 2, 3] for y in [4, 5, 6]]      # Lists keep duplicates\\n[5, 6, 7, 6, 7, 8, 7, 8, 9]\\n>>> {x + y for x in [1, 2, 3] for y in [4, 5, 6]}      # But sets do not\\n{8, 9, 5, 6, 7}\\n>>> {x: y for x in [1, 2, 3] for y in [4, 5, 6]}       # Neither do dict keys\\n{1: 6, 2: 6, 3: 6}\\n\\nLike list comprehensions, the set and dictionary varieties can also iterate over any type\\nof iterable—lists, strings, files, ranges, and anything else that supports the iteration\\nprotocol:\\n\\nComprehension Syntax Summary | 625\\n\\n\\x0c>>> {x + y for x in \\'ab\\' for y in \\'cd\\'}\\n{\\'ac\\', \\'bd\\', \\'bc\\', \\'ad\\'}\\n\\n>>> {x + y: (ord(x), ord(y)) for x in \\'ab\\' for y in \\'cd\\'}\\n{\\'ac\\': (97, 99), \\'bd\\': (98, 100), \\'bc\\': (98, 99), \\'ad\\': (97, 100)}\\n\\n>>> {k * 2 for k in [\\'spam\\', \\'ham\\', \\'sausage\\'] if k[0] == \\'s\\'}\\n{\\'sausagesausage\\', \\'spamspam\\'}\\n\\n>>> {k.upper(): k * 2 for k in [\\'spam\\', \\'ham\\', \\'sausage\\'] if k[0] == \\'s\\'}\\n{\\'SAUSAGE\\': \\'sausagesausage\\', \\'SPAM\\': \\'spamspam\\'}\\n\\nFor more details, experiment with these tools on your own. They may or may not have\\na performance advantage over the generator or for loop alternatives, but we would\\nhave to time their performance explicitly to be sure—which seems a natural segue to\\nthe next chapter.\\n\\nChapter Summary\\nThis chapter wrapped up our coverage of built-in comprehension and iteration tools.\\nIt explored list comprehensions in the context of functional tools, and presented gen-\\nerator functions and expressions as additional iteration protocol tools. As a finale, we\\nalso summarized the four forms of comprehension in Python today—list, generator,\\nset, and dictionary. Though we’ve now seen all the built-in iteration tools, the subject\\nwill resurface when we study user-defined iterable class objects in Chapter 30.\\nThe next chapter is something of a continuation of the theme of this one—it rounds\\nout this part of the book with a case study that times the performance of the tools we’ve\\nstudied here, and serves as a more realistic example at the midpoint in this book. Before\\nwe move ahead to benchmarking comprehensions and generators, though, this chap-\\nter’s quizzes give you a chance to review what you’ve learned about them here.\\n\\nTest Your Knowledge: Quiz\\n1. What is the difference between enclosing a list comprehension in square brackets\\n\\nand parentheses?\\n\\n2. How are generators and iterators related?\\n3. How can you tell if a function is a generator function?\\n4. What does a yield statement do?\\n5. How are map calls and list comprehensions related? Compare and contrast the two.\\n\\nTest Your Knowledge: Answers\\n1. List comprehensions in square brackets produce the result list all at once in mem-\\nory. When they are enclosed in parentheses instead, they are actually generator\\n\\n626 | Chapter 20:\\u2002Comprehensions and Generations\\n\\n\\x0cexpressions—they have a similar meaning but do not produce the result list all at\\nonce. Instead, generator expressions return a generator object, which yields one\\nitem in the result at a time when used in an iteration context.\\n\\n2. Generators are iterable objects that support the iteration protocol automatically—\\nthey have an iterator with a __next__ method (next in 2.X) that repeatedly advances\\nto the next item in a series of results and raises an exception at the end of the series.\\nIn Python, we can code generator functions with def and yield, generator expres-\\nsions with parenthesized comprehensions, and generator objects with classes that\\ndefine a special method named __iter__ (discussed later in the book).\\n\\n3. A  generator  function  has  a  yield  statement  somewhere  in  its  code.  Generator\\nfunctions are otherwise identical to normal functions syntactically, but they are\\ncompiled specially by Python so as to return an iterable generator object when\\ncalled. That object retains state and code location between values.\\n\\n4. When present, this statement makes Python compile the function specially as a\\ngenerator; when called, the function returns a generator object that supports the\\niteration protocol. When the yield statement is run, it sends a result back to the\\ncaller and suspends the function’s state; the function can then be resumed after the\\nlast yield statement, in response to a next built-in or __next__ method call issued\\nby the caller. In more advanced roles, the generator send method similarly resumes\\nthe generator, but can also pass a value that shows up as the yield expression’s\\nvalue. Generator functions may also have a return statement, which terminates the\\ngenerator.\\n\\n5. The map call is similar to a list comprehension—both produce a series of values, by\\ncollecting the results of applying an operation to each item in a sequence or other\\niterable, one item at a time. The primary difference is that map applies a function\\ncall to each item, and list comprehensions apply arbitrary expressions. Because of\\nthis, list comprehensions are more general; they can apply a function call expres-\\nsion like map, but map requires a function to apply other kinds of expressions. List\\ncomprehensions also support extended syntax such as nested  for loops and if\\nclauses that subsume the filter built-in. In Python 3.X, map also differs in that it\\nproduces a generator of values; the list comprehension materializes the result list\\nin memory all at once. In 2.X, both tools create result lists.\\n\\nTest Your Knowledge: Answers\\n\\n| 627\\n\\n\\x0c\\x0cCHAPTER 21\\nThe Benchmarking Interlude\\n\\nNow that we know about coding functions and iteration tools, we’re going to take a\\nshort side trip to put both of them to work. This chapter closes out the function part\\nof this book with a larger case study that times the relative performance of the iteration\\ntools we’ve met so far.\\nAlong the way, this case study surveys Python’s code timing tools, discusses bench-\\nmarking techniques in general, and allows us to explore code that’s a bit more realistic\\nand useful than most of what we’ve seen up to this point. We’ll also measure the speed\\nof current Python implementations—a data point that may or may not be significant,\\ndepending on the type of code you write.\\nFinally, because this is the last chapter in this part of the book, we’ll close with the\\nusual sets of “gotchas” and exercises to help you start coding the ideas you’ve read\\nabout. First, though, let’s have some fun with a tangible Python application.\\n\\nTiming Iteration Alternatives\\nWe’ve met quite a few iteration alternatives in this book. Like much in programming,\\nthey represent tradeoffs—in terms of both subjective factors like expressiveness, and\\nmore objective criteria such as performance. Part of your job as a programmer and\\nengineer is selecting tools based on factors like these.\\nIn terms of performance, I’ve mentioned a few times that list comprehensions some-\\ntimes have a speed advantage over for loop statements, and that map calls can be faster\\nor slower than both depending on call patterns. The generator functions and expres-\\nsions of the preceding chapter tend to be slightly slower than list comprehensions,\\nthough they minimize memory space requirements and don’t delay result generation.\\nAll that is generally true today, but relative performance can vary over time because\\nPython’s internals are constantly being changed and optimized, and code structure can\\ninfluence speed arbitrarily. If you want to verify their performance for yourself, you\\nneed to time these alternatives on your own computer and your own version of Python.\\n\\n629\\n\\n\\x0cTiming Module: Homegrown\\nLuckily, Python makes it easy to time code. For example, to get the total time taken to\\nrun multiple calls to a function with arbitrary positional arguments, the following first-\\ncut function might suffice:\\n\\n# File timer0.py\\nimport time\\ndef timer(func, *args):                 # Simplistic timing function\\n    start = time.clock()\\n    for i in range(1000):\\n        func(*args)\\n    return time.clock() - start         # Total elapsed time in seconds\\n\\nThis works—it fetches time values from Python’s time module, and subtracts the sys-\\ntem start time from the stop time after running 1,000 calls to the passed-in function\\nwith the passed-in arguments. On my computer in Python 3.3:\\n\\n>>> from timer0 import timer\\n>>> timer(pow, 2, 1000)                 # Time to call pow(2, 1000) 1000 times\\n0.00296260674205626\\n>>> timer(str.upper, \\'spam\\')            # Time to call \\'spam\\'.upper() 1000 times\\n0.0005165746166859719\\n\\nThough simple, this timer is also fairly limited, and deliberately exhibits some classic\\nmistakes in both function design and benchmarking. Among these, it:\\n\\n• Doesn’t support keyword arguments in the tested function call\\n• Hardcodes the repetitions count\\n• Charges the cost of range to the tested function’s time\\n• Always uses time.clock, which might not be best outside Windows\\n• Doesn’t give callers a way to verify that the tested function actually worked\\n• Only gives total time, which might fluctuate on some heavily loaded machines\\n\\nIn other words, timing code is more complex than you might expect! To be more general\\nand accurate, let’s expand this into still simple but more useful timer utility functions\\nwe can use both to see how iteration alternative options stack up now, and apply to\\nother timing needs in the future. These functions are coded in a module file so they can\\nbe used in a variety of programs, and have docstrings giving some basic details that\\nPyDoc can display on request—see Figure 15-2 in Chapter 15 for a screenshot of the\\ndocumentation pages rendered for the timing modules we’re coding here:\\n\\n# File timer.py\\n\"\"\"\\nHomegrown timing tools for function calls.\\nDoes total time, best-of time, and best-of-totals time\\n\"\"\"\\n\\nimport time, sys\\ntimer = time.clock if sys.platform[:3] == \\'win\\' else time.time\\n\\n630 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cdef total(reps, func, *pargs, **kargs):\\n    \"\"\"\\n    Total time to run func() reps times.\\n    Returns (total time, last result)\\n    \"\"\"\\n    repslist = list(range(reps))                 # Hoist out, equalize 2.x, 3.x\\n    start = timer()                              # Or perf_counter/other in 3.3+\\n    for i in repslist:\\n        ret = func(*pargs, **kargs)\\n    elapsed = timer() - start\\n    return (elapsed, ret)\\n\\ndef bestof(reps, func, *pargs, **kargs):\\n    \"\"\"\\n    Quickest func() among reps runs.\\n    Returns (best time, last result)\\n    \"\"\"\\n    best = 2 ** 32                               # 136 years seems large enough\\n    for i in range(reps):                        # range usage not timed here\\n        start = timer()\\n        ret = func(*pargs, **kargs)\\n        elapsed = timer() - start                # Or call total() with reps=1\\n        if elapsed < best: best = elapsed        # Or add to list and take min()\\n    return (best, ret)\\n\\ndef bestoftotal(reps1, reps2, func, *pargs, **kargs):\\n    \"\"\"\\n    Best of totals:\\n    (best of reps1 runs of (total of reps2 runs of func))\\n    \"\"\"\\n    return bestof(reps1, total, reps2, func, *pargs, **kargs)\\n\\nOperationally, this module implements both total time and best time calls, and a nested\\nbest of totals that combines the other two. In each, it times a call to any function with\\nany positional and keyword arguments passed individually, by fetching the start time,\\ncalling the function, and subtracting the start time from the stop time. Points to notice\\nabout how this version addresses the shortcomings of its predecessor:\\n\\n• Python’s time module gives access to the current time, with precision that varies\\nper platform. On Windows its clock function is claimed to give microsecond gran-\\nularity and so is very accurate. Because the time function may be better on Unix,\\nthis script selects between them automatically based on the platform string in the\\nsys module; it starts with “win” if running in Windows. See also the sidebar “New\\nTimer Calls in 3.3” on page 633 on other time options in 3.3 and later not used\\nhere for portability; we will also be timing Python 2.X where these newer calls are\\nnot available, and their results on Windows appear similar in 3.3 in any event.\\n\\n• The range call is hoisted out of the timing loop in the total function, so its con-\\nstruction cost is not charged to the timed function in Python 2.X. In 3.X range is\\nan iterable, so this step is neither required nor harmful, but we still run the result\\nthrough list so its traversal cost is the same in both 2.X and 3.X. This doesn’t\\napply to the bestof function, since no range factors are charged to the test’s time.\\n\\nTiming Iteration Alternatives\\n\\n| 631\\n\\n\\x0c• The reps count is passed in as an argument, before the test function and its argu-\\n\\nments, to allow repetition to vary per call.\\n\\n• Any number of both positional and keyword arguments are collected with starred-\\nargument syntax, so they must be sent individually, not in a sequence or dictionary.\\nIf needed, callers can unpack argument collections into individual arguments with\\nstars in the call, as done by the bestoftotal function at the end. See Chapter 18 for\\na refresher if this code doesn’t make sense.\\n\\n• The first function in this module returns total elapsed time for all calls in a tuple,\\nalong with the timed function’s final return value so callers can verify its operation.\\n• The second function does similar, but returns the best (minimum) time among all\\ncalls instead of the total—more useful if you wish to filter out the impacts of other\\nactivity on your computer, but less for tests that run too quickly to produce sub-\\nstantial runtimes.\\n\\n• To address the prior point, the last function in this file runs nested total tests within\\na best-of test, to get the best-of-totals time. The nested total operation can make\\nruntimes more useful, but we still get the best-of filter. This function’s code may\\nbe easier to understand if you remember that every function is a passable object,\\neven the testing functions themselves.\\n\\nFrom a larger perspective, because these functions are coded in a module file, they\\nbecome generally useful tools anywhere we wish to import them. Modules and imports\\nwere introduced in Chapter 3, and you’ll learn more about them in the next part of this\\nbook; for now, simply import the module and call the function to use one of this file’s\\ntimers. In simple usage, this module is similar to its predecessor, but will be more robust\\nin larger contexts. In Python 3.3 again:\\n\\n>>> import timer\\n>>> timer.total(1000, pow, 2, 1000)[0]          # Compare to timer0 results above\\n0.0029542985410557776\\n>>> timer.total(1000, str.upper, \\'spam\\')        # Returns (time, last call\\'s result)\\n(0.000504845391709686, \\'SPAM\\')\\n\\n>>> timer.bestof(1000, str.upper, \\'spam\\')       # 1/1000 as long as total time\\n(4.887177027512735e-07, \\'SPAM\\')\\n>>> timer.bestof(1000, pow, 2, 1000000)[0]\\n0.00393515497972885\\n\\n>>> timer.bestof(50, timer.total, 1000, str.upper, \\'spam\\')\\n(0.0005468751145372153, (0.0005004469323637295, \\'SPAM\\'))\\n>>> timer.bestoftotal(50, 1000, str.upper, \\'spam\\')\\n(0.000566912540591602, (0.0005195069228989269, \\'SPAM\\'))\\n\\nThe last two calls here calculate the best-of-totals times—the lowest time among 50\\nruns, each of which computes the total time to call str.upper 1,000 times (roughly\\ncorresponding to the total times at the start of this listing). The function used in the\\nlast call is really just a convenience that maps to the call form preceding it; both return\\nthe best-of tuple, which embeds the last total call’s result tuple.\\n\\n632 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cCompare these last two results to the following generator-based alternative:\\n\\n>>> min(timer.total(1000, str.upper, \\'spam\\') for i in range(50))\\n(0.0005155971812769167, \\'SPAM\\')\\n\\nTaking the min of an iteration of total results this way has a similar effect because the\\ntimes in the result tuples dominate comparisons made by min (they are leftmost in the\\ntuple). We could use this in our module too (and will in later variations); it varies slightly\\nby omitting a very small overhead in the best-of function’s code and not nesting result\\ntuples, though either result suffices for relative comparisons. As is, the best-of function\\nmust pick a high initial lowest time value—though 136 years is probably longer than\\nmost of the tests you’re likely to run!\\n\\n>>> ((((2 ** 32) / 60) / 60) / 24) / 365           # Plus a few extra days\\n136.19251953323186\\n>>> ((((2 ** 32) // 60) // 60) // 24) // 365       # Floor: see Chapter 5\\n136\\n\\nNew Timer Calls in 3.3\\n\\nThis section uses the time module’s clock and time calls because they apply to all readers\\nof this book. Python 3.3 introduces new interfaces in this module that are designed to\\nbe more portable. Specifically, the behavior of this module’s clock and time calls varies\\nper platform, but its new perf_counter and process_time functions have well-defined\\nand platform-neutral semantics:\\n\\n• time.perf_counter()  returns  the  value  in  fractional  seconds  of  a  performance\\ncounter, defined as a clock with the highest available resolution to measure a short\\nduration. It includes time elapsed during sleep states and is system-wide.\\n\\n• time.process_time() returns the value in fractional seconds of the sum of the sys-\\ntem and user CPU time of the current process. It does not include time elapsed\\nduring sleep, and is process-wide by definition.\\n\\nFor both of these calls, the reference point of the returned value is undefined, so that\\nonly the difference between the results of consecutive calls is valid. The perf_counter\\ncall can be thought of as wall time, and as of Python 3.3 is used by default for bench-\\nmarking in the timeit module discussed ahead; process_time gives CPU time portably.\\nThe time.clock call is still usable on Windows today, as shown in this book. It is doc-\\numented as being deprecated in 3.3’s manuals, but issues no warning when used there\\n—meaning it may or may not become officially deprecated in later releases. If needed,\\nyou can detect a Python 3.3 or later with code like this, which I opted to not use for\\nthe sake of brevity and timer comparability:\\n\\nif sys.version_info[0] >= 3 and sys.version_info[1] >= 3:\\n    timer = time.perf_counter     # or process_time\\nelse:\\n    timer = time.clock if sys.platform[:3] == \\'win\\' else time.time\\n\\nAlternatively,  the  following  code  would  also  add  portability  and  insulate  you  from\\nfuture deprecations, though it depends on exception topics we haven’t studied in full\\n\\nTiming Iteration Alternatives\\n\\n| 633\\n\\n\\x0cyet, and its choices may also make cross-version speed comparisons invalid—timers\\nmay differ in resolution!\\n\\ntry:\\n    timer = time.perf_counter     # or process_time\\nexcept AttributeError:\\n    timer = time.clock if sys.platform[:3] == \\'win\\' else time.time\\n\\nIf I were writing this book for Python 3.3+ readers only, I’d use the new and apparently\\nimproved calls here, and you should in your work too if they apply to you. The newer\\ncalls won’t work for users of any other Pythons, though, and that’s still the majority of\\nthe Python world today. It would be easier to pretend that the past doesn’t matter, but\\nthat would not only be evasive of reality, it might also be just plain rude.\\n\\nTiming Script\\nNow, to time iteration tool speed (our original goal), run the following script—it uses\\nthe timer module we wrote to time the relative speeds of the list construction techniques\\nwe’ve studied:\\n\\n# File timeseqs.py\\n\"Test the relative speed of iteration tool alternatives.\"\\n\\nimport sys, timer                                # Import timer functions\\nreps = 10000\\nrepslist = list(range(reps))                     # Hoist out, list in both 2.X/3.X\\n\\ndef forLoop():\\n    res = []\\n    for x in repslist:\\n        res.append(abs(x))\\n    return res\\n\\ndef listComp():\\n    return [abs(x) for x in repslist]\\n\\ndef mapCall():\\n    return list(map(abs, repslist))              # Use list() here in 3.X only!\\n  # return map(abs, repslist)\\n\\ndef genExpr():\\n    return list(abs(x) for x in repslist)        # list() required to force results\\n\\ndef genFunc():\\n    def gen():\\n        for x in repslist:\\n            yield abs(x)\\n    return list(gen())                           # list() required to force results\\n\\nprint(sys.version)\\nfor test in (forLoop, listComp, mapCall, genExpr, genFunc):\\n    (bestof, (total, result)) = timer.bestoftotal(5, 1000, test)\\n\\n634 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0c    print (\\'%-9s: %.5f => [%s...%s]\\' %\\n           (test.__name__, bestof, result[0], result[-1]))\\n\\nThis script tests five alternative ways to build lists of results. As shown, its reported\\ntimes reflect on the order of 10 million steps for each of the five test functions—each\\nbuilds a list of 10,000 items 1,000 times. This process is repeated 5 times to get the\\nbest-of time for each of the 5 test functions, yielding a whopping 250 million total steps\\nfor the script at large (impressive but reasonable on most machines these days).\\nNotice how we have to run the results of the generator expression and function through\\nthe built-in list call to force them to yield all of their values; if we did not, in both 2.X\\nand 3.X we would just produce generators that never do any real work. In Python 3.X\\nonly we must do the same for the map result, since it is now an iterable object as well;\\nfor 2.X, the list around map must be removed manually to avoid charging an extra list\\nconstruction overhead per test (though its impact seems negligible in most tests).\\nIn a similar way, the inner loops’ range result is hoisted out to the top of the module\\nto remove its construction cost from total time, and wrapped in a list call so that its\\ntraversal cost isn’t skewed by being a generator in 3.X only (much as we did in the timer\\nmodule too). This may be overshadowed by the cost of the inner iterations loop, but\\nit’s best to remove as many variables as we can.\\nAlso notice how the code at the bottom steps through a tuple of five function objects\\nand prints the __name__ of each: as we’ve seen, this is a built-in attribute that gives a \\nfunction’s name.1\\n\\nTiming Results\\nWhen the script of the prior section is run under Python 3.3, I get these results on my\\nWindows 7 laptop—map is slightly faster than list comprehensions, both are quicker\\nthan for loops, and generator expressions and functions place in the middle (times here\\nare total time in seconds):\\n\\nC:\\\\code> c:\\\\python33\\\\python timeseqs.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\nforLoop  : 1.33290 => [0...9999]\\nlistComp : 0.69658 => [0...9999]\\nmapCall  : 0.56483 => [0...9999]\\ngenExpr  : 1.08457 => [0...9999]\\ngenFunc  : 1.07623 => [0...9999]\\n\\nIf you study this code and its output long enough, you’ll notice that generator expres-\\nsions run slower than list comprehensions today. Although wrapping a generator ex-\\n\\n1. A  preview:  notice  how  we  must  pass  functions  into  the  timer  manually  here.  In  Chapter  39  and\\nChapter 40 we’ll see decorator-based timer alternatives with which timed functions are called normally,\\nbut require extra “@” syntax where defined. Decorators may be more useful to instrument functions with\\ntiming logic when they are already being used within a larger system, and don’t as easily support the more\\nisolated test call patterns assumed here—when decorated, every call to the function runs the timing logic,\\nwhich is either a plus or minus depending on your goals.\\n\\nTiming Iteration Alternatives\\n\\n| 635\\n\\n\\x0cpression in a list call makes it functionally equivalent to a square-bracketed list com-\\nprehension,  the  internal  implementations  of  the  two  expressions  appear  to  differ\\n(though we’re also effectively timing the list call for the generator test):\\n\\nreturn [abs(x) for x in repslist]            # 0.69 seconds\\nreturn list(abs(x) for x in repslist)        # 1.08 seconds: differs internally\\n\\nThough the exact cause would require deeper analysis (and possibly source code study),\\nthis seems to make sense given that the generator expression must do extra work to\\nsave and restore its state during value production; the list comprehension does not, and\\nruns quicker by a small constant here and in later tests.\\nInterestingly, when I ran this on Windows Vista under Python 3.0 for the fourth edition\\nof this book, and on Windows XP with Python 2.5 for the third, the results were rela-\\ntively similar—list comprehensions were nearly twice as fast as equivalent for loop\\nstatements, and map was slightly quicker than list comprehensions when mapping a\\nfunction such as the abs (absolute value) built-in this way. Python 2.5’s absolute times\\nwere roughly four to five times slower than the current 3.3 output, but this likely reflects\\nquicker laptops much more than any improvements in Python.\\nIn fact, most of the Python 2.7 results for this script are slightly quicker than 3.3 on this\\nsame machine today—I removed the list call from the map test in the following to avoid\\ncreating the results list twice in that test, though it adds only a very small constant time\\nif left in:\\n\\nc:\\\\code> c:\\\\python27\\\\python timeseqs.py\\n2.7.3 (default, Apr 10 2012, 23:24:47) [MSC v.1500 64 bit (AMD64)]\\nforLoop  : 1.24902 => [0...9999]\\nlistComp : 0.66970 => [0...9999]\\nmapCall  : 0.57018 => [0...9999]\\ngenExpr  : 0.90339 => [0...9999]\\ngenFunc  : 0.90542 => [0...9999]\\n\\nFor comparison, following are the same tests’ speed results under the current PyPy, the\\noptimized Python implementation discussed in Chapter 2, whose current 1.9 release\\nimplements the Python 2.7 language. PyPy is roughly 10X (an order of magnitude)\\nquicker here; it will do even better when we revisit Python version comparisons later\\nin this chapter using tools with different code structures (though it will lose on a few\\nother tests as well):\\n\\nc:\\\\code> c:\\\\PyPy\\\\pypy-1.9\\\\pypy.exe timeseqs.py\\n2.7.2 (341e1e3821ff, Jun 07 2012, 15:43:00)\\n[PyPy 1.9.0 with MSC v.1500 32 bit]\\nforLoop  : 0.10106 => [0...9999]\\nlistComp : 0.05629 => [0...9999]\\nmapCall  : 0.10022 => [0...9999]\\ngenExpr  : 0.17234 => [0...9999]\\ngenFunc  : 0.17519 => [0...9999]\\n\\n636 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cOn PyPy alone, list comprehensions beat map in this test, but the fact that all of PyPy’s\\nresults are so much quicker today seems the larger point here. On CPython, map is still\\nquickest so far.\\n\\nThe impact of function calls: map\\nWatch what happens, though, if we change this script to perform an inline operation\\non each iteration, such as addition, instead of calling a built-in function like abs (the\\nomitted parts of the following file are the same as before, and I put list back in around\\nmap for testing on 3.3 only):\\n\\n# File timeseqs2.py (differing parts)\\n...\\ndef forLoop():\\n    res = []\\n    for x in repslist:\\n        res.append(x + 10)\\n    return res\\n\\ndef listComp():\\n    return [x + 10 for x in repslist]\\n\\ndef mapCall():\\n    return list(map((lambda x: x + 10), repslist))          # list() in 3.X only\\n\\ndef genExpr():\\n    return list(x + 10 for x in repslist)                   # list() in 2.X + 3.X\\n\\ndef genFunc():\\n    def gen():\\n        for x in repslist:\\n            yield x + 10\\n    return list(gen())                                      # list in 2.X + 3.X\\n...\\n\\nNow the need to call a user-defined function for the map call makes it slower than the\\nfor loop statements, despite the fact that the looping statements version is larger in\\nterms of code—or equivalently, the removal of function calls may make the others\\nquicker (more on this in an upcoming note). On Python 3.3:\\n\\nc:\\\\code> c:\\\\python33\\\\python timeseqs2.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\nforLoop  : 1.35136 => [10...10009]\\nlistComp : 0.73730 => [10...10009]\\nmapCall  : 1.68588 => [10...10009]\\ngenExpr  : 1.10963 => [10...10009]\\ngenFunc  : 1.11074 => [10...10009]\\n\\nThese results have also been consistent in CPython. The prior edition’s Python 3.0\\nresults on a slower machine were again relatively similar, though about twice as slow\\ndue to test machine differences (Python 2.5 results on an even slower machine were\\nagain four to five times as slow as the current results).\\n\\nTiming Iteration Alternatives\\n\\n| 637\\n\\n\\x0cBecause the interpreter optimizes so much internally, performance analysis of Python\\ncode like this is a very tricky affair. Without numbers, though, it’s virtually impossible\\nto guess which method will perform the best—the best you can do is time your own\\ncode, on your computer, with your version of Python.\\nIn this case, what we can say for certain is that on this Python, using a user-defined\\nfunction in map calls seems to slow performance substantially (though + may also be\\nslower than a trivial abs), and that list comprehensions run quickest in this case (though\\nslower than map in some others). List comprehensions seem consistently twice as fast\\nas for loops, but even this must be qualified—the list comprehension’s relative speed\\nmight be affected by its extra syntax (e.g., if filters), Python changes, and usage modes\\nwe did not time here.\\nAs I’ve mentioned before, however, performance should not be your primary concern\\nwhen writing Python code—the first thing you should do to optimize Python code is\\nto not optimize Python code! Write for readability and simplicity first, then optimize\\nlater, if and only if needed. It could very well be that any of the five alternatives is quick\\nenough for the data sets your program needs to process; if so, program clarity should\\nbe the chief goal.\\n\\nFor deeper truth, change this code to apply a simple user-defined func-\\ntion  in  all  five  iteration  techniques  timed.  For  instance  (from  time-\\nseqs2B.py of the book’s examples):\\n\\ndef F(x): return x\\ndef listComp():\\n    return [F(x) for x in repslist]\\ndef mapCall():\\n    return list(map(F, repslist))\\n\\nThe results, in file timeseqs-results.txt, are then relatively similar to using\\na built-in function like abs—at least in CPython, map is quickest. More\\ngenerally, among the five iteration techniques, map is fastest today if all\\nfive call any function, built in or not, but slowest when the others do not.\\n\\nThat  is,  map  appears  to  be  slower  simply  because  it  requires  function\\ncalls, and function calls are relatively slow in general. Since map can’t\\navoid calling functions, it can lose simply by association! The other iter-\\nation tools win because they can operate without function calls. We’ll\\nprove this finding in tests run under the timeit module ahead.\\n\\nTiming Module Alternatives\\nThe timing module of the preceding section works, but it could be a bit more user-\\nfriendly. Most obviously, its functions require passing in a repetitions count as a first\\nargument, and provide no default for it—a minor point, perhaps, but less than ideal in\\na general-purpose tool. We could also leverage the min technique we saw earlier to\\nsimplify the return value slightly and remove a minor overhead charge.\\n\\n638 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cThe following implements an alternative timer module that addresses these points,\\nallowing the repeat count to be passed in as a keyword argument named _reps:\\n\\n# File timer2.py (2.X and 3.X)\\n\"\"\"\\ntotal(spam, 1, 2, a=3, b=4, _reps=1000) calls and times spam(1, 2, a=3, b=4)\\n_reps times, and returns total time for all runs, with final result.\\n\\nbestof(spam, 1, 2, a=3, b=4, _reps=5) runs best-of-N timer to attempt to\\nfilter out system load variation, and returns best time among _reps tests.\\n\\nbestoftotal(spam 1, 2, a=3, b=4, _rep1=5, reps=1000) runs best-of-totals\\ntest, which takes the best among _reps1 runs of (the total of _reps runs);\\n\"\"\"\\n\\nimport time, sys\\ntimer = time.clock if sys.platform[:3] == \\'win\\' else time.time\\n\\ndef total(func, *pargs, **kargs):\\n    _reps = kargs.pop(\\'_reps\\', 1000)    # Passed-in or default reps\\n    repslist = list(range(_reps))       # Hoist range out for 2.X lists\\n    start = timer()\\n    for i in repslist:\\n        ret = func(*pargs, **kargs)\\n    elapsed = timer() - start\\n    return (elapsed, ret)\\n\\ndef bestof(func, *pargs, **kargs):\\n    _reps = kargs.pop(\\'_reps\\', 5)\\n    best = 2 ** 32\\n    for i in range(_reps):\\n        start = timer()\\n        ret = func(*pargs, **kargs)\\n        elapsed = timer() - start\\n        if elapsed < best: best = elapsed\\n    return (best, ret)\\n\\ndef bestoftotal(func, *pargs, **kargs):\\n    _reps1 = kargs.pop(\\'_reps1\\', 5)\\n    return min(total(func, *pargs, **kargs) for i in range(_reps1))\\n\\nThis module’s docstring at the top of the file describes its intended usage. It uses dic-\\ntionary pop operations to remove the _reps argument from arguments intended for the\\ntest function and provide it with a default (it has an unusual name to avoid clashing\\nwith real keyword arguments meant for the function being timed).\\nNotice how the best of totals here uses the min and generator scheme we saw earlier\\ninstead of nested calls, in part because this simplifies results and avoids a minor time\\noverhead in the prior version (whose code fetches best of time after total time has been\\ncomputed), but also because it must support two distinct repetition keywords with\\ndefaults—total and bestof can’t both use the same argument name. Add argument\\nprints in the code if it would help to trace its operation.\\n\\nTiming Iteration Alternatives\\n\\n| 639\\n\\n\\x0cTo test with this new timer module, you can change the timing scripts as follows, or\\nuse the precoded version in the book’s examples file timeseqs_timer2.py; the results are\\nessentially the same as before (this is primarily just an API change), so I won’t list them\\nagain here:\\n\\nimport sys, timer2\\n...\\nfor test in (forLoop, listComp, mapCall, genExpr, genFunc):\\n    (total, result) = timer2.bestoftotal(test, _reps1=5, _reps=1000)\\n\\n# Or:\\n#   (total, result) = timer2.bestoftotal(test)\\n#   (total, result) = timer2.bestof(test, _reps=5)\\n#   (total, result) = timer2.total(test, _reps=1000)\\n#   (bestof, (total, result)) = timer2.bestof(timer2.total, test, _reps=5)\\n\\n    print (\\'%-9s: %.5f => [%s...%s]\\' %\\n           (test.__name__, total, result[0], result[-1]))\\n\\nYou can also run a few interactive tests as we did for the original version—the results\\nare again essentially the same as before, but we pass in the repetition counts as keywords\\nthat provide defaults if omitted; in Python 3.3:\\n\\n>>> from timer2 import total, bestof, bestoftotal\\n>>> total(pow, 2, 1000)[0]                                 # 2 ** 1000, 1K dflt reps\\n0.0029562534118596773\\n>>> total(pow, 2, 1000, _reps=1000)[0]                     # 2 ** 1000, 1K reps\\n0.0029733585316193967\\n>>> total(pow, 2, 1000, _reps=1000000)[0]                  # 2 ** 1000, 1M reps\\n1.2451676814889865\\n\\n>>> bestof(pow, 2, 100000)[0]                              # 2 ** 100K, 5 dflt reps\\n0.0007550688578703557\\n>>> bestof(pow, 2, 1000000, _reps=30)[0]                   # 2 ** 1M, best of 30\\n0.004040229286800923\\n\\n>>> bestoftotal(str.upper, \\'spam\\', _reps1=30, _reps=1000)  # Best of 30, tot of 1K\\n(0.0004945823198454491, \\'SPAM\\')\\n>>> bestof(total, str.upper, \\'spam\\', _reps=30)             # Nested calls work too\\n(0.0005463863968202531, (0.0004994694969298052, \\'SPAM\\'))\\n\\nTo see how keywords are supported now, define a function with more arguments and\\npass some by name:\\n\\n>>> def spam(a, b, c, d): return a + b + c + d\\n\\n>>> total(spam, 1, 2, c=3, d=4, _reps=1000)\\n(0.0009730369554290519, 10)\\n>>> bestof(spam, 1, 2, c=3, d=4, _reps=1000)\\n(9.774353202374186e-07, 10)\\n>>> bestoftotal(spam, 1, 2, c=3, d=4, _reps1=1000, _reps=1000)\\n(0.00037289161070930277, 10)\\n>>> bestoftotal(spam, *(1, 2), _reps1=1000, _reps=1000, **dict(c=3, d=4))\\n(0.00037289161070930277, 10)\\n\\n640 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cUsing keyword-only arguments in 3.X\\nOne last point on this thread: we can also make use of Python 3.X keyword-only argu-\\nments here to simplify the timer module’s code. As we learned in Chapter 18, keyword-\\nonly arguments are ideal for configuration options such as our functions’ _reps argu-\\nment. They must be coded after a * and before a ** in the function header, and in a\\nfunction call they must be passed by keyword and appear before the ** if used. The\\nfollowing is a keyword-only-based alternative to the prior module. Though simpler, it\\ncompiles and runs under Python 3.X only, not 2.X:\\n\\n# File timer3.py (3.X only)\\n\"\"\"\\nSame usage as timer2.py, but uses 3.X keyword-only default arguments\\ninstead of dict pops for simpler code.  No need to hoist range() out\\nof tests in 3.X: always a generator in 3.X, and this can\\'t run on 2.X.\\n\"\"\"\\nimport time, sys\\ntimer = time.clock if sys.platform[:3] == \\'win\\' else time.time\\n\\ndef total(func, *pargs, _reps=1000, **kargs):\\n    start = timer()\\n    for i in range(_reps):\\n        ret = func(*pargs, **kargs)\\n    elapsed = timer() - start\\n    return (elapsed, ret)\\n\\ndef bestof(func, *pargs, _reps=5, **kargs):\\n    best = 2 ** 32\\n    for i in range(_reps):\\n        start = timer()\\n        ret = func(*pargs, **kargs)\\n        elapsed = timer() - start\\n        if elapsed < best: best = elapsed\\n    return (best, ret)\\n\\ndef bestoftotal(func, *pargs, _reps1=5, **kargs):\\n    return min(total(func, *pargs, **kargs) for i in range(_reps1))\\n\\nThis version is used the same way as the prior version and produces identical results,\\nso I won’t relist its outputs on the same tests here; experiment on your own as you\\nwish. If you do, pay attention to the argument ordering rules in calls. A former bes\\ntof that ran total, for instance, called like this:\\n\\n (elapsed, ret) = total(func, *pargs, _reps=1, **kargs)\\n\\nSee Chapter 18 for more on keyword-only arguments in 3.X; they can simplify code for\\nconfigurable tools like this one but are not backward compatible with 2.X Pythons. If\\nyou want to compare 2.X and 3.X speed, or support programmers using either Python\\nline, the prior version is likely a better choice.\\nAlso keep in mind that for trivial functions like some of those tested for the prior version,\\nthe costs of the timer’s code may sometimes be as significant as those of a simple timed\\nfunction, so you should not take timer results too absolutely. The timer’s results can\\n\\nTiming Iteration Alternatives\\n\\n| 641\\n\\n\\x0chelp you judge relative speeds of coding alternatives, though, and may be more mean-\\ningful for operations that run longer or are repeated often.\\n\\nOther Suggestions\\nFor more insight, try modifying the repetition counts used by these modules, or explore\\nthe alternative timeit module in Python’s standard library, which automates timing of\\ncode, supports command-line usage modes, and finesses some platform-specific issues\\n—in fact, we’ll put it to work in the next section.\\nYou might also want to look at the profile standard library module for a complete\\nsource code profiler tool. We’ll learn more about it in Chapter 36 in the context of\\ndevelopment tools for large projects. In general, you should profile code to isolate bot-\\ntlenecks before recoding and timing alternatives as we’ve done here.\\nYou might try modifying or emulating the timing script to measure the speed of the 3.X\\nand 2.7 set and dictionary comprehensions shown in the preceding chapter, and their\\nfor loop equivalents. Using them is less common in Python programs than building\\nlists of results, so we’ll leave this task in the suggested exercise column (please, no\\nwagering...); the next section will partly spoil the surprise.\\nFinally, keep the timing module we wrote here filed away for future reference—we’ll\\nrepurpose it to measure performance of alternative numeric square root operations in\\nan exercise at the end of this chapter. If you’re interested in pursuing this topic further,\\nwe’ll also experiment with techniques for timing dictionary comprehensions versus\\nfor loops interactively in the exercises.\\n\\nTiming Iterations and Pythons with timeit\\nThe preceding section used homegrown timing functions to compare code speed. As\\nmentioned there, the standard library also ships with a module named timeit that can\\nbe used in similar ways, but offers added flexibility and may better insulate clients from\\nsome platform differences.\\nAs usual in Python, it’s important to understand fundamental principles like those\\nillustrated in the prior section. Python’s “batteries included” approach means you’ll\\nusually find precoded options as well, though you still need to know the ideas under-\\nlying them to use them properly. Indeed, this module is a prime example of this—it\\nseems to have had a history of being misused by people who don’t yet understand the\\nprinciples it embodies. Now that we’ve learned the basics, though, let’s move ahead to\\na tool that can automate much of our work.\\n\\n642 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cBasic timeit Usage\\nLet’s start with this module’s fundamentals before leveraging them in larger scripts.\\nWith timeit, tests are specified by either callable objects or statement strings; the latter\\ncan hold multiple statements if they use ; separators or \\\\n characters for line breaks,\\nand spaces or tabs to indent statements in nested blocks (e.g., \\\\n\\\\t). Tests may also\\ngive setup actions, and can be launched from both command lines and API calls, and\\nfrom both scripts and the interactive prompt.\\n\\nInteractive usage and API calls\\nFor example, the timeit module’s repeat call returns a list giving the total time taken\\nto run a test a number of times, for each of repeat runs—the min of this list yields the\\nbest time among the runs, and helps filter out system load fluctuations that can other-\\nwise skew timing results artificially high.\\nThe following shows this call in action, timing a list comprehension on two versions\\nof  CPython  and  the  optimized  PyPy  implementation  of  Python  described  in  Chap-\\nter 2 (it currently supports Python 2.7 code). The results here give the best total time\\nin seconds among 5 runs that each execute the code string 1,000 times; the code string\\nitself constructs a 1,000-item list of integers each time through (see Appendix B for the\\nWindows launcher used for variety in the first two of these commands):\\n\\nc:\\\\code> py −3\\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit...\\n>>> import timeit\\n>>> min(timeit.repeat(stmt=\"[x ** 2 for x in range(1000)]\", number=1000, repeat=5))\\n0.5062382371756811\\n\\nc:\\\\code> py −2\\nPython 2.7.3 (default, Apr 10 2012, 23:24:47) [MSC v.1500 64 bit (AMD64)] on win32\\n>>> import timeit\\n>>> min(timeit.repeat(stmt=\"[x ** 2 for x in range(1000)]\", number=1000, repeat=5))\\n0.0708020004193198\\n\\nc:\\\\code> c:\\\\pypy\\\\pypy-1.9\\\\pypy.exe\\nPython 2.7.2 (341e1e3821ff, Jun 07 2012, 15:43:00)\\n[PyPy 1.9.0 with MSC v.1500 32 bit] on win32\\n>>>> import timeit\\n>>>> min(timeit.repeat(stmt=\"[x ** 2 for x in range(1000)]\", number=1000, repeat=5))\\n0.0059330329674303905\\n\\nYou’ll notice that PyPy checks in at 10X faster than CPython 2.7 here, and a whopping\\n100X faster than CPython 3.3, despite the fact that PyPy is a potentially slower 32-bit\\nbuild.  This  is  a  small  artificial  benchmark,  of  course,  but  seems  arguably  stunning\\nnonetheless, and reflects a relative speed ranking that is generally supported by other\\ntests run in this book (though as we’ll see, CPython still beats PyPy on some types of\\ncode).\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 643\\n\\n\\x0cThis particular test measures the speed of both a list comprehension and integer math.\\nThe latter varies between lines: CPython 3.X has a single integer type, and CPython\\n2.X has both short and long integers. This may explain part of the size of the difference,\\nbut the results are valid nonetheless. Noninteger tests yield similar rankings (e.g., a\\nfloating-point test in the solutions to this part’s exercises), and integer math matters—\\nthe one and two order of magnitude (power of 10) speedups here will be realized by\\nmany real programs, because integers and iterations are ubiquitous in Python code.\\nThese results also differ from the preceding section’s relative version speeds, where\\nCPython 2.7 was slightly quicker than 3.3, and PyPy was 10X quicker overall, a figure\\naffirmed by most other tests in this book too. Apart from the different type of code\\nbeing timed here, the different coding structure inside timeit may have an effect too—\\nfor code strings like those tested here, timeit builds, compiles, and executes a function\\ndef statement string that embeds the test string, thereby avoiding a function call per\\ninner  loop.  As  we’ll  see  in  the  next  section,  though,  this  appears  irrelevant  from  a\\nrelative-speed perspective.\\n\\nCommand-line usage\\nThe timeit module has reasonable defaults and can be also run as a script, either by\\nexplicit filename or automatically located on the module search path with Python’s\\n–m flag (see Appendix A). All the following run Python (a.k.a. CPython) 3.3. In this\\nmode timeit reports the average time for a single –n loop, in either microseconds (la-\\nbeled “usec”), milliseconds (“msec”), or seconds (“sec”); to compare results here to\\nthe total time values reported by other tests, multiply by the number of loops run—\\n500 usec here * 1,000 loops is 500 msec, or half a second in total time:\\n\\nc:\\\\code> C:\\\\python33\\\\Lib\\\\timeit.py -n 1000 \"[x ** 2 for x in range(1000)]\"\\n1000 loops, best of 3: 506 usec per loop\\n\\nc:\\\\code> python -m timeit -n 1000 \"[x ** 2 for x in range(1000)]\"\\n1000 loops, best of 3: 504 usec per loop\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 5 \"[x ** 2 for x in range(1000)]\"\\n1000 loops, best of 5: 505 usec per loop\\n\\nAs an example, we can use command lines to verify that choice of timer call doesn’t\\nimpact cross-version speed comparisons run in this chapter so far—3.3 uses its new\\ncalls by default, and that might matter if timer precision differs widely. To prove that\\nthis is irrelevant, the following uses the -c flag to force timeit to use time.clock in all \\nversions, an option that 3.3’s manuals call deprecated, but required to even the score\\nwith prior versions (I’m setting my system path to include PyPy here for command\\nbrevity):\\n\\nc:\\\\code> set PATH=%PATH%;C:\\\\pypy\\\\pypy-1.9\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 5 -c \"[x ** 2 for x in range(1000)]\"\\n1000 loops, best of 5: 502 usec per loop\\nc:\\\\code> py −2 -m timeit -n 1000 -r 5 -c \"[x ** 2 for x in range(1000)]\"\\n\\n644 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0c1000 loops, best of 5: 70.6 usec per loop\\nc:\\\\code> pypy -m timeit -n 1000 -r 5 -c  \"[x ** 2 for x in range(1000)]\"\\n1000 loops, best of 5: 5.44 usec per loop\\n\\nC:\\\\code> py −3 -m timeit -n 1000 -r 5 -c \"[abs(x) for x in range(10000)]\"\\n1000 loops, best of 5: 815 usec per loop\\nC:\\\\code> py −2 -m timeit -n 1000 -r 5 -c \"[abs(x) for x in range(10000)]\"\\n1000 loops, best of 5: 700 usec per loop\\nC:\\\\code> pypy -m timeit -n 1000 -r 5 -c  \"[abs(x) for x in range(10000)]\"\\n1000 loops, best of 5: 61.7 usec per loop\\n\\nThese results are essentially the same as those for earlier tests in this chapter on the\\nsame types of code. When applying x ** 2, CPython 2.7 and PyPy are again 10X and\\n100X faster than CPython 3.3, respectively, showing that timer choice isn’t a factor.\\nFor the abs(x) we timed under the homegrown timer earlier (timeseqs.py), these two\\nPythons are faster than 3.3 by a small constant and 10X just as before, implying that\\ntimeit’s different code structure doesn’t impact relative comparisons—the type of code\\nbeing tested fully determines the size of speed differences.\\nSubtle point: notice that the results of the last three of these tests, which mimic tests\\nrun for the homegrown timer earlier, are basically the same as before, but seem to incur\\na small net overhead for range usage differences—it was a prebuilt list formerly, but\\nhere is either a 3.X generator or a 2.X list built anew on each inner total loop. In other\\nwords, we’re not timing the exact same thing, but the relative speeds of the Pythons\\ntested are the same.\\n\\nTiming multiline statements\\nTo time larger multiline sections of code in API call mode, use line breaks and tabs or\\nspaces to satisfy Python’s syntax; code read from a source file already will. Because you\\npass Python string objects to a Python function in this mode, there are no shell con-\\nsiderations, though be careful to escape nested quotes if needed. The following, for\\ninstance, times Chapter 13 loop alternatives in Python 3.3; you can use the same pattern\\nto time the file-line-reader alternatives in Chapter 14:\\n\\nc:\\\\code> py −3\\n>>> import timeit\\n>>> min(timeit.repeat(number=10000, repeat=3,\\n        stmt=\"L = [1, 2, 3, 4, 5]\\\\nfor i in range(len(L)): L[i] += 1\"))\\n0.01397292797131814\\n\\n>>> min(timeit.repeat(number=10000, repeat=3,\\n        stmt=\"L = [1, 2, 3, 4, 5]\\\\ni=0\\\\nwhile i < len(L):\\\\n\\\\tL[i] += 1\\\\n\\\\ti += 1\"))\\n0.015452276471516813\\n\\n>>> min(timeit.repeat(number=10000, repeat=3,\\n        stmt=\"L = [1, 2, 3, 4, 5]\\\\nM = [x + 1 for x in L]\"))\\n0.009464995838568635\\n\\nTo run multiline statements like these in command-line mode, appease your shell by\\npassing each statement line as a separate argument, with whitespace for indentation—\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 645\\n\\n\\x0ctimeit concatenates all the lines together with a newline character between them, and\\nlater reindents for its own statement nesting purposes. Leading spaces may work better\\nfor indentation than tabs in this mode, and be sure to quote the code arguments if\\nrequired by your shell:\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 3 \"L = [1,2,3,4,5]\" \"i=0\" \"while i < len(L):\"\\n \"    L[i] += 1\" \"    i += 1\"\\n1000 loops, best of 3: 1.54 usec per loop\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 3 \"L = [1,2,3,4,5]\" \"M = [x + 1 for x in L]\"\\n1000 loops, best of 3: 0.959 usec per loop\\n\\nOther usage modes: Setup, totals, and objects\\nThe timeit module also allows you to provide setup code that is run in the main state-\\nment’s scope, but whose time is not charged to the main statement’s total—potentially\\nuseful for initialization code you wish to exclude from total time, such as imports of\\nrequired modules, test function definition, and test data creation. Because they’re run\\nin  the  same  scope,  any  names  created  by  setup  code  are  available  to  the  main  test\\nstatement; names defined in the interactive shell generally are not.\\nTo specify setup code, use a –s in command-line mode (or many of these for multiline\\nsetups) and a setup argument string in API call mode. This can focus tests more sharply,\\nas in the following, which splits list initialization off to a setup statement to time just\\niteration. As a rule of thumb, though, the more code you include in a test statement,\\nthe more applicable its results will generally be to realistic code:\\n\\nc:\\\\code> python -m timeit -n 1000 -r 3 \"L = [1,2,3,4,5]\" \"M = [x + 1 for x in L]\"\\n1000 loops, best of 3: 0.956 usec per loop\\n\\nc:\\\\code> python -m timeit -n 1000 -r 3 -s \"L = [1,2,3,4,5]\" \"M = [x + 1 for x in L]\"\\n1000 loops, best of 3: 0.775 usec per loop\\n\\nHere’s a setup example in API call mode: I used the following type of code to time the\\nsort-based option in Chapter 18’s minimum value example—ordered ranges sort much\\nfaster than random numbers, and are faster sorted than scanned linearly in the exam-\\nple’s code under 3.3 (adjacent strings are concatenated here):\\n\\n>>> from timeit import repeat\\n\\n>>> min(repeat(number=1000, repeat=3,\\nsetup=\\'from mins import min1, min2, min3\\\\n\\'\\n      \\'vals=list(range(1000))\\',\\nstmt= \\'min3(*vals)\\'))\\n0.0387865921275079\\n\\n>>> min(repeat(number=1000, repeat=3,\\nsetup=\\'from mins import min1, min2, min3\\\\n\\'\\n      \\'import random\\\\nvals=[random.random() for i in range(1000)]\\',\\nstmt= \\'min3(*vals)\\'))\\n0.275656482278373\\n\\n646 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cWith  timeit, you can also ask for just total time, use the module’s class API, time\\ncallable objects instead of strings, accept automatic loop counts, and use class-based\\ntechniques and additional command-line switches and API argument options we don’t\\nhave space to show here—consult Python’s library manual for more details:\\n\\nc:\\\\code> py −3\\n>>> import timeit\\n>>> timeit.timeit(stmt=\\'[x ** 2 for x in range(1000)]\\', number=1000)  # Total time\\n0.5238125259325834\\n\\n>>> timeit.Timer(stmt=\\'[x ** 2 for x in range(1000)]\\').timeit(1000)   # Class API\\n0.5282652329644009\\n\\n>>> timeit.repeat(stmt=\\'[x ** 2 for x in range(1000)]\\', number=1000, repeat=3)\\n[0.5299034147194845, 0.5082454007998365, 0.5095136232504416]\\n\\n>>> def testcase():\\n        y = [x ** 2 for x in range(1000)]     # Callable objects or code strings\\n\\n>>> min(timeit.repeat(stmt=testcase, number=1000, repeat=3))\\n0.5073828140463377\\n\\nBenchmark Module and Script: timeit\\nRather than go into more details on this module, let’s study a program that deploys it\\nto time both coding alternatives and Python versions. The following file, pybench.py,\\nis set up to time a set of statements coded in scripts that import and use it, under either\\nthe version running its code or all Python versions named in a list. It uses some appli-\\ncation-level tools described ahead. Because it mostly applies ideas we’ve already learned\\nand is amply documented, though, I’m going to list this as mostly self-study material,\\nand an exercise in reading Python code.\\n\\n\"\"\"\\npybench.py: Test speed of one or more Pythons on a set of simple\\ncode-string benchmarks.  A function, to allow stmts to vary.\\nThis system itself runs on both 2.X and 3.X, and may spawn both.\\n\\nUses timeit to test either the Python running this script by API\\ncalls, or a set of Pythons by reading spawned command-line outputs\\n(os.popen) with Python\\'s -m flag to find timeit on module search path.\\n\\nReplaces $listif3 with a list() around generators for 3.X and an\\nempty string for 2.X, so 3.X does same work as 2.X.  In command-line\\nmode only, must split multiline statements into one separate quoted\\nargument per line so all will be run (else might run/time first line\\nonly), and replace all \\\\t in indentation with 4 spaces for uniformity.\\n\\nCaveats: command-line mode (only) may fail if test stmt embeds double\\nquotes, quoted stmt string is incompatible with shell in general, or\\ncommand-line exceeds a length limit on platform\\'s shell--use API call\\nmode or homegrown timer; does not yet support a setup statement: as is,\\ntime of all statements in the test stmt are charged to the total time.\\n\"\"\"\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 647\\n\\n\\x0cimport sys, os, timeit\\ndefnum, defrep= 1000, 5   # May vary per stmt\\n\\ndef runner(stmts, pythons=None, tracecmd=False):\\n    \"\"\"\\n    Main logic: run tests per input lists, caller handles usage modes.\\n    stmts:   [(number?, repeat?, stmt-string)], replaces $listif3 in stmt\\n    pythons: None=this python only, or [(ispy3?, python-executable-path)]\\n    \"\"\"\\n    print(sys.version)\\n    for (number, repeat, stmt) in stmts:\\n        number = number or defnum\\n        repeat = repeat or defrep  # 0=default\\n\\n        if not pythons:\\n            # Run stmt on this python: API call\\n            # No need to split lines or quote here\\n            ispy3 = sys.version[0] == \\'3\\'\\n            stmt  = stmt.replace(\\'$listif3\\', \\'list\\' if ispy3 else \\'\\')\\n            best  = min(timeit.repeat(stmt=stmt, number=number, repeat=repeat))\\n            print(\\'%.4f  [%r]\\' % (best, stmt[:70]))\\n\\n        else:\\n            # Run stmt on all pythons: command line\\n            # Split lines into quoted arguments\\n            print(\\'-\\' * 80)\\n            print(\\'[%r]\\' % stmt)\\n            for (ispy3, python) in pythons:\\n                stmt1 = stmt.replace(\\'$listif3\\', \\'list\\' if ispy3 else \\'\\')\\n                stmt1 = stmt1.replace(\\'\\\\t\\', \\' \\' * 4)\\n                lines = stmt1.split(\\'\\\\n\\')\\n                args  = \\' \\'.join(\\'\"%s\"\\' % line for line in lines)\\n                cmd = \\'%s -m timeit -n %s -r %s %s\\' % (python, number, repeat, args)\\n                print(python)\\n                if tracecmd: print(cmd)\\n                print(\\'\\\\t\\' + os.popen(cmd).read().rstrip())\\n\\nThis file is really only half the picture, though. Testing scripts use this module’s func-\\ntion, passing in concrete though variable lists of statements and Pythons to be tested,\\nas  appropriate  for  the  usage  mode  desired.  For  example,  the  following  script,  py-\\nbench_cases.py, tests a handful of statements and Pythons, and allows command-line\\narguments to determine part of its operation: –a tests all listed Pythons instead of just\\none, and an added –t traces constructed command lines so you can see how multiline\\nstatements and indentation are handled per the command-line formats shown earlier\\n(see both files’ docstrings for details):\\n\\n\"\"\"\\npybench_cases.py: Run pybench on a set of pythons and statements.\\n\\nSelect modes by editing this script or using command-line arguments (in\\nsys.argv): e.g., run a \"C:\\\\python27\\\\python pybench_cases.py\" to test just\\none specific version on stmts, \"pybench_cases.py -a\" to test all pythons\\nlisted, or a \"py −3 pybench_cases.py -a -t\" to trace command lines too.\\n\\n648 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0c\"\"\"\\n\\nimport pybench, sys\\n\\npythons = [                                                         # (ispy3?, path)\\n    (1, \\'C:\\\\python33\\\\python\\'),\\n    (0, \\'C:\\\\python27\\\\python\\'),\\n    (0, \\'C:\\\\pypy\\\\pypy-1.9\\\\pypy\\')\\n]\\n\\nstmts = [                                                           # (num,rpt,stmt)\\n    (0, 0, \"[x ** 2 for x in range(1000)]\"),                        # Iterations\\n    (0, 0, \"res=[]\\\\nfor x in range(1000): res.append(x ** 2)\"),     # \\\\n=multistmt\\n    (0, 0, \"$listif3(map(lambda x: x ** 2, range(1000)))\"),         # \\\\n\\\\t=indent\\n    (0, 0, \"list(x ** 2 for x in range(1000))\"),                    # $=list or \\'\\'\\n    (0, 0, \"s = \\'spam\\' * 2500\\\\nx = [s[i] for i in range(10000)]\"),  # String ops\\n    (0, 0, \"s = \\'?\\'\\\\nfor i in range(10000): s += \\'?\\'\"),\\n]\\n\\ntracecmd = \\'-t\\' in sys.argv                           # -t: trace command lines?\\npythons  = pythons if \\'-a\\' in sys.argv else None      # -a: all in list, else one?\\npybench.runner(stmts, pythons, tracecmd)\\n\\nBenchmark Script Results\\nHere is this script’s output when run to test a specific version (the Python running the\\nscript)—this mode uses direct API calls, not command lines, with total time listed in\\nthe left column, and the statement tested on the right. I’m again using the 3.3 Windows\\nlauncher in the first two of these tests to time CPython 3.3 and 2.7, and am running\\nrelease 1.9 of the PyPy implementation in the third:\\n\\nc:\\\\code> py −3 pybench_cases.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\n0.5015  [\\'[x ** 2 for x in range(1000)]\\']\\n0.5655  [\\'res=[]\\\\nfor x in range(1000): res.append(x ** 2)\\']\\n0.6044  [\\'list(map(lambda x: x ** 2, range(1000)))\\']\\n0.5425  [\\'list(x ** 2 for x in range(1000))\\']\\n0.8746  [\"s = \\'spam\\' * 2500\\\\nx = [s[i] for i in range(10000)]\"]\\n2.8060  [\"s = \\'?\\'\\\\nfor i in range(10000): s += \\'?\\'\"]\\n\\nc:\\\\code> py −2 pybench_cases.py\\n2.7.3 (default, Apr 10 2012, 23:24:47) [MSC v.1500 64 bit (AMD64)]\\n0.0696  [\\'[x ** 2 for x in range(1000)]\\']\\n0.1285  [\\'res=[]\\\\nfor x in range(1000): res.append(x ** 2)\\']\\n0.1636  [\\'(map(lambda x: x ** 2, range(1000)))\\']\\n0.0952  [\\'list(x ** 2 for x in range(1000))\\']\\n0.6143  [\"s = \\'spam\\' * 2500\\\\nx = [s[i] for i in range(10000)]\"]\\n2.0657  [\"s = \\'?\\'\\\\nfor i in range(10000): s += \\'?\\'\"]\\n\\nc:\\\\code> c:\\\\pypy\\\\pypy-1.9\\\\pypy pybench_cases.py\\n2.7.2 (341e1e3821ff, Jun 07 2012, 15:43:00)\\n[PyPy 1.9.0 with MSC v.1500 32 bit]\\n0.0059  [\\'[x ** 2 for x in range(1000)]\\']\\n0.0102  [\\'res=[]\\\\nfor x in range(1000): res.append(x ** 2)\\']\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 649\\n\\n\\x0c0.0099  [\\'(map(lambda x: x ** 2, range(1000)))\\']\\n0.0156  [\\'list(x ** 2 for x in range(1000))\\']\\n0.1298  [\"s = \\'spam\\' * 2500\\\\nx = [s[i] for i in range(10000)]\"]\\n5.5242  [\"s = \\'?\\'\\\\nfor i in range(10000): s += \\'?\\'\"]\\n\\nThe following shows this script’s output when run to test multiple Python versions for\\neach statement string. In this mode the script itself is run by Python 3.3, but it launches \\nshell command lines that start other Pythons to run the  timeit module on the test\\nstatement strings. This mode must split, format, and quote multiline statements for\\nuse in command lines according to timeit expectations and shell requirements.\\nThis  mode  also  relies  on  the  -m  Python  command-line  flag  to  locate  timeit  on  the\\nmodule search path and run it as a script, and the os.popen and sys.argv standard \\nlibrary tools to run a shell command and inspect command-line arguments, respec-\\ntively. See Python manuals and other sources for more on these calls; os.popen is also\\nmentioned briefly in the files coverage of Chapter 9, and demonstrated in the loops\\ncoverage in Chapter 13. Run with a –t flag to watch the command lines run:\\n\\nc:\\\\code> py −3 pybench_cases.py -a\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\n--------------------------------------------------------------------------------\\n[\\'[x ** 2 for x in range(1000)]\\']\\nC:\\\\python33\\\\python\\n        1000 loops, best of 5: 499 usec per loop\\nC:\\\\python27\\\\python\\n        1000 loops, best of 5: 71.4 usec per loop\\nC:\\\\pypy\\\\pypy-1.9\\\\pypy\\n        1000 loops, best of 5: 5.71 usec per loop\\n--------------------------------------------------------------------------------\\n[\\'res=[]\\\\nfor x in range(1000): res.append(x ** 2)\\']\\nC:\\\\python33\\\\python\\n        1000 loops, best of 5: 562 usec per loop\\nC:\\\\python27\\\\python\\n        1000 loops, best of 5: 130 usec per loop\\nC:\\\\pypy\\\\pypy-1.9\\\\pypy\\n        1000 loops, best of 5: 9.81 usec per loop\\n--------------------------------------------------------------------------------\\n[\\'$listif3(map(lambda x: x ** 2, range(1000)))\\']\\nC:\\\\python33\\\\python\\n        1000 loops, best of 5: 599 usec per loop\\nC:\\\\python27\\\\python\\n        1000 loops, best of 5: 161 usec per loop\\nC:\\\\pypy\\\\pypy-1.9\\\\pypy\\n        1000 loops, best of 5: 9.45 usec per loop\\n--------------------------------------------------------------------------------\\n[\\'list(x ** 2 for x in range(1000))\\']\\nC:\\\\python33\\\\python\\n        1000 loops, best of 5: 540 usec per loop\\nC:\\\\python27\\\\python\\n        1000 loops, best of 5: 92.3 usec per loop\\nC:\\\\pypy\\\\pypy-1.9\\\\pypy\\n        1000 loops, best of 5: 15.1 usec per loop\\n--------------------------------------------------------------------------------\\n[\"s = \\'spam\\' * 2500\\\\nx = [s[i] for i in range(10000)]\"]\\n\\n650 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cC:\\\\python33\\\\python\\n        1000 loops, best of 5: 873 usec per loop\\nC:\\\\python27\\\\python\\n        1000 loops, best of 5: 614 usec per loop\\nC:\\\\pypy\\\\pypy-1.9\\\\pypy\\n        1000 loops, best of 5: 118 usec per loop\\n--------------------------------------------------------------------------------\\n[\"s = \\'?\\'\\\\nfor i in range(10000): s += \\'?\\'\"]\\nC:\\\\python33\\\\python\\n        1000 loops, best of 5: 2.81 msec per loop\\nC:\\\\python27\\\\python\\n        1000 loops, best of 5: 1.94 msec per loop\\nC:\\\\pypy\\\\pypy-1.9\\\\pypy\\n        1000 loops, best of 5: 5.68 msec per loop\\n\\nAs you can see, in most of these tests, CPython 2.7 is still quicker than CPython 3.3,\\nand PyPy is noticeably faster than both of them—except on the last test where PyPy is\\ntwice as slow as CPython, presumably due to memory management differences. On\\nthe other hand, timing results are often relative at best. In addition to other general\\ntiming caveats mentioned in this chapter:\\n\\n• timeit may skew results in ways beyond our scope to explore here (e.g., garbage\\n\\ncollection).\\n\\n• There is a baseline overhead, which differs per Python version, that is ignored here\\n\\n(but appears trivial).\\n\\n• This script runs very small statements that may or may not reflect real-world code\\n\\n(but are still valid).\\n\\n• Results may occasionally vary in ways that seem random (using process time may\\n\\nhelp here).\\n\\n• All results here are highly prone to change over time (in each new Python release,\\n\\nin fact!).\\n\\nIn other words, you should draw your own conclusions from these numbers, and run\\nthese tests on your Pythons and machines for results more relevant to your needs. To\\ntime the baseline overhead of each Python, run timeit with no statement argument, or\\nequivalently, with a pass statement.\\n\\nMore Fun with Benchmarks\\nFor more insight, try running the script on other Python versions and other statement\\ntest strings. The file pybench_cases2.py in this book’s examples distribution adds more\\ntests to see how CPython 3.3 compares to 3.2, how PyPy’s 2.0 beta stacks up against\\nits current release, and how additional use cases fare.\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 651\\n\\n\\x0cA win for map and a rare loss for PyPy\\nFor example, the following tests in pybench_cases2.py measure the impact of charging\\nother iteration operations with a function call, which improves map’s chances of winning\\nthe day per this chapter’s earlier note—map usually loses by its association with function\\ncalls in general:\\n\\n# pybench_cases2.py\\n\\npythons += [\\n    (1, \\'C:\\\\python32\\\\python\\'),\\n    (0, \\'C:\\\\pypy\\\\pypy-2.0-beta1\\\\pypy\\')]\\n\\nstmts += [\\n# Use function calls: map wins\\n    (0, 0, \"[ord(x) for x in \\'spam\\' * 2500]\"),\\n    (0, 0, \"res=[]\\\\nfor x in \\'spam\\' * 2500: res.append(ord(x))\"),\\n    (0, 0, \"$listif3(map(ord, \\'spam\\' * 2500))\"),\\n    (0, 0, \"list(ord(x) for x in \\'spam\\' * 2500)\"),\\n# Set and dicts\\n    (0, 0, \"{x ** 2 for x in range(1000)}\"),\\n    (0, 0, \"s=set()\\\\nfor x in range(1000): s.add(x ** 2)\"),\\n    (0, 0, \"{x: x ** 2 for x in range(1000)}\"),\\n    (0, 0, \"d={}\\\\nfor x in range(1000): d[x] = x ** 2\"),\\n# Pathological: 300k digits\\n    (1, 1, \"len(str(2**1000000))\")]  # Pypy loses on this today\\n\\nHere  is  the  script’s  results  on  these  statement  tests  on  CPython  3.X,  showing  how\\nmap is quickest when function calls level the playing field (it lost earlier when the other\\ntests ran an inline x ** 2):\\n\\nc:\\\\code> py −3 pybench_cases2.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\n0.7237  [\"[ord(x) for x in \\'spam\\' * 2500]\"]\\n1.3471  [\"res=[]\\\\nfor x in \\'spam\\' * 2500: res.append(ord(x))\"]\\n0.6160  [\"list(map(ord, \\'spam\\' * 2500))\"]\\n1.1244  [\"list(ord(x) for x in \\'spam\\' * 2500)\"]\\n0.5446  [\\'{x ** 2 for x in range(1000)}\\']\\n0.6053  [\\'s=set()\\\\nfor x in range(1000): s.add(x ** 2)\\']\\n0.5278  [\\'{x: x ** 2 for x in range(1000)}\\']\\n0.5414  [\\'d={}\\\\nfor x in range(1000): d[x] = x ** 2\\']\\n1.8933  [\\'len(str(2**1000000))\\']\\n\\nAs before, on these tests today 2.X clocks in faster than 3.X and PyPy is faster still on\\nall of these tests but the last—which it loses by a full order of magnitude (10X), though\\nit wins all the other tests here by the same degree. However, if you run file tests precoded\\nin pybench_cases2.py you’ll see that PyPy also loses to CPython when reading files line\\nby line, as for the following test tuple on the stmts list:\\n\\n    (0, 0, \"f=open(\\'C:/Python33/Lib/pdb.py\\')\\\\nfor line in f: x=line\\\\nf.close()\"),\\n\\nThis test opens and reads a 60K, 1,675-line text file line by line using file iterators. Its\\ninput loop presumably dominates overall test time. On this test, CPython 2.7 is twice\\nas fast as 3.3, but PyPy is again an order of magnitude slower than CPython in general.\\n\\n652 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cYou can find this case in the pybench_cases2 results files, or verify interactively or by\\ncommand line (this is just what pybench does internally):\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 5 \"f=open(\\'C:/Python33/Lib/pdb.py\\')\"\\n \"for line in f: x=line\" \"f.close()\"\\n\\n>>> import timeit\\n>>> min(timeit.repeat(number=1000, repeat=5,\\n    stmt=\"f=open(\\'C:/Python33/Lib/pdb.py\\')\\\\nfor line in f: x=line\\\\nf.close()\"))\\n\\nFor another example that measures both list comprehensions and PyPy’s current file\\nspeed, see the file listcomp-speed.txt in the book examples package; it uses direct PyPy\\ncommand lines to run code from Chapter 14 with similar results: PyPy’s line input is\\nslower today by roughly a factor of 10.\\nI’ll omit other Pythons’ output here both for space and because these findings could\\nvery well change by the time you read these words. As usual, different types of code\\ncan exhibit different types of performance. While PyPy may optimize much algorithmic\\ncode, it may or may not optimize yours. You can find additional results in the book’s\\nexamples package, but you may be better served by running these tests on your own\\nto verify these findings today or observe their possibly different results in the future.\\n\\nThe impact of function calls revisited\\nAs suggested earlier, map also wins for added user-defined functions—the following tests\\nprove the earlier note’s claim that map wins the race in CPython if any function must\\nbe applied by its alternatives:\\n\\nstmts = [\\n    (0, 0, \"def f(x): return x\\\\n[f(x) for x in \\'spam\\' * 2500]\"),\\n    (0, 0, \"def f(x): return x\\\\nres=[]\\\\nfor x in \\'spam\\' * 2500: res.append(f(x))\"),\\n    (0, 0, \"def f(x): return x\\\\n$listif3(map(f, \\'spam\\' * 2500))\"),\\n    (0, 0, \"def f(x): return x\\\\nlist(f(x) for x in \\'spam\\' * 2500)\")]\\n\\nc:\\\\code> py −3 pybench_cases2.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\n1.5400  [\"def f(x): return x\\\\n[f(x) for x in \\'spam\\' * 2500]\"]\\n2.0506  [\"def f(x): return x\\\\nres=[]\\\\nfor x in \\'spam\\' * 2500: res.append(f(x))\"]\\n1.2489  [\"def f(x): return x\\\\nlist(map(f, \\'spam\\' * 2500))\"]\\n1.6526  [\"def f(x): return x\\\\nlist(f(x) for x in \\'spam\\' * 2500)\"]\\n\\nCompare this with the preceding section’s ord tests; though user-defined functions may\\nbe slower than built-ins, the larger speed hit today seems to be functions in general,\\nwhether they are built-in or not. Notice that the total time here includes the cost of\\nmaking a helper function, though only one for every 10,000 inner loop repetitions—a\\nnegligible factor per both common sense and additional tests run.\\n\\nComparing techniques: Homegrown versus batteries\\nFor perspective, let’s see how this section’s timeit-based results compare to the home-\\ngrown-based timer results of the prior section, by running the file timeseqs3.py in this\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 653\\n\\n\\x0cbook’s examples package—it uses the homegrown timer but performs the same x **\\n2 operation and uses the same repetition counts as pybench_cases.py:\\n\\nc:\\\\code> py −3 timeseqs3.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\nforLoop  : 0.55022 => [0...998001]\\nlistComp : 0.48787 => [0...998001]\\nmapCall  : 0.59499 => [0...998001]\\ngenExpr  : 0.52773 => [0...998001]\\ngenFunc  : 0.52603 => [0...998001]\\n\\nc:\\\\code> py −3 pybench_cases.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\n0.5015  [\\'[x ** 2 for x in range(1000)]\\']\\n0.5657  [\\'res=[]\\\\nfor x in range(1000): res.append(x ** 2)\\']\\n0.6025  [\\'list(map(lambda x: x ** 2, range(1000)))\\']\\n0.5404  [\\'list(x ** 2 for x in range(1000))\\']\\n0.8711  [\"s = \\'spam\\' * 2500\\\\nx = [s[i] for i in range(10000)]\"]\\n2.8009  [\"s = \\'?\\'\\\\nfor i in range(10000): s += \\'?\\'\"]\\n\\nThe homegrown timer results are very similar to the pybench-based results of this sec-\\ntion that use timeit, though it’s not entirely apples-to-apples—the homegrown timer-\\nbased timeseqs3.py incurs a function call per its middle totals loop and a slight overhead\\nin best of logic of the timer itself, but also uses a prebuilt list instead of a 3.X range\\ngenerator in its inner loop, which seems to make it slightly net faster on comparable\\ntests (and I’d call this example a “sanity check,” but I’m not sure the term applies in\\nbenchmarking!).\\n\\nRoom for improvement: Setup\\nLike most software, this section’s program is open-ended and could be expanded ar-\\nbitrarily. As one example, the files pybench2.py and pybench2_cases.py in the book’s\\nexamples package add support for timeit’s setup statement option described earlier,\\nin both API call and command-line modes.\\nThis feature was omitted initially for brevity, and frankly, because my tests didn’t seem\\nto require it—timing more code gives a more complete picture when comparing Py-\\nthons, and setup actions cost the same when timing alternatives on a single Python.\\nEven so, it’s sometimes useful to provide setup code that is run once in the tested code’s\\nscope, but whose time is not charged to the statement’s total—a module import, object\\ninitialization, or helper function definition, for example.\\nI won’t list these two files in whole, but here are their important varying bits as an\\nexample of software evolution at work—as for the test statement, the setup code state-\\nment is passed as is in API call mode, but is split and space-indented in command-line\\nmode and passed with one -s argument per line (“$listif3” isn’t used because setup\\ncode is not timed):\\n\\n# pybench2.py\\n...\\ndef runner(stmts, pythons=None, tracecmd=False):\\n\\n654 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0c    for (number, repeat, setup, stmt) in stmts:\\n        if not pythons:\\n            ...\\n            best = min(timeit.repeat(\\n                              setup=setup, stmt=stmt, number=number, repeat=repeat))\\n        else:\\n            setup = setup.replace(\\'\\\\t\\', \\' \\' * 4)\\n            setup = \\' \\'.join(\\'-s \"%s\"\\' % line for line in setup.split(\\'\\\\n\\'))\\n            ...\\n            for (ispy3, python) in pythons:\\n                ...\\n                cmd = \\'%s -m timeit -n %s -r %s %s %s\\' %\\n                              (python, number, repeat, setup, args)\\n\\n# pybench2_cases.py\\nimport pybench2, sys\\n...\\nstmts = [                                                     # (num,rpt,setup,stmt)\\n    (0, 0, \"\", \"[x ** 2 for x in range(1000)]\"),\\n    (0, 0, \"\", \"res=[]\\\\nfor x in range(1000): res.append(x ** 2)\"),\\n\\n    (0, 0, \"def f(x):\\\\n\\\\treturn x\",\\n           \"[f(x) for x in \\'spam\\' * 2500]\"),\\n    (0, 0, \"def f(x):\\\\n\\\\treturn x\",\\n           \"res=[]\\\\nfor x in \\'spam\\' * 2500:\\\\n\\\\tres.append(f(x))\"),\\n\\n    (0, 0, \"L = [1, 2, 3, 4, 5]\", \"for i in range(len(L)): L[i] += 1\"),\\n    (0, 0, \"L = [1, 2, 3, 4, 5]\", \"i=0\\\\nwhile i < len(L):\\\\n\\\\tL[i] += 1\\\\n\\\\ti += 1\")]\\n...\\npybench2.runner(stmts, pythons, tracecmd)\\n\\nRun this script with the –a and –t command-line flags to see how command lines are\\nconstructed for setup code. For instance, the following test specification tuple generates\\nthe command line that follows it for 3.3—not nice to look at, perhaps, but sufficient\\nto pass lines from Windows to timeit, to be concatenated with line breaks between\\nand inserted into a generated timing function with appropriate reindentation:\\n\\n    (0, 0, \"def f(x):\\\\n\\\\treturn x\",\\n           \"res=[]\\\\nfor x in \\'spam\\' * 2500:\\\\n\\\\tres.append(f(x))\")\\n\\nC:\\\\python33\\\\python -m timeit -n 1000 -r 5 -s \"def f(x):\" -s \"    return x\" \"res=[]\"\\n \"for x in \\'spam\\' * 2500:\" \"    res.append(f(x))\"\\n\\nIn API call mode, code strings are passed unchanged, because there’s no need to placate\\na shell, and embedded tabs and end-of-line characters suffice. Experiment on your own\\nto uncover more about Python code alternatives’ speed. You may eventually run into\\nshell limitations for larger sections of code in command-line mode, but both our home-\\ngrown timer and pybench’s timeit-based API call mode support more arbitrary code.\\nBenchmarks can be great sport, but we’ll have to leave future improvements as sug-\\ngested exercises.\\n\\nTiming Iterations and Pythons with timeit\\n\\n| 655\\n\\n\\x0cOther Benchmarking Topics: pystones\\nThis chapter has focused on code timing fundamentals that you can use on your own\\ncode, that apply to Python benchmarking in general, and that served as a common use\\ncase for developing larger examples for this book. Benchmarking Python is a broader\\nand richer domain than so far implied, though. If you’re interested in pursuing this\\ntopic further, search the Web for links. Among the topics you’ll find:\\n\\n• pystone.py—a program designed for measuring Python speed across a range of code\\n\\nthat ships with Python in its Lib\\\\test directory\\n\\n• http://speed.python.org—a project site for coordinating work on common Python\\n\\nbenchmarks\\n\\n• http://speed.pypy.org—the  PyPy  benchmarking  site  that  the  preceding  bullet  is\\n\\npartially emulating\\n\\nThe pystone test, for example, is based on a C language benchmark program that was\\ntranslated to Python by Python original creator Guido van Rossum. It provides another\\nway to measure the relative speeds of Python implementations, and seems to generally\\nsupport our findings here:\\n\\nc:\\\\Python33\\\\Lib\\\\test> cd C:\\\\python33\\\\lib\\\\test\\nc:\\\\Python33\\\\Lib\\\\test> py −3 pystone.py\\nPystone(1.1) time for 50000 passes = 0.685303\\nThis machine benchmarks at 72960.4 pystones/second\\n\\nc:\\\\Python33\\\\Lib\\\\test> cd c:\\\\python27\\\\lib\\\\test\\nc:\\\\Python27\\\\Lib\\\\test> py −2 pystone.py\\nPystone(1.1) time for 50000 passes = 0.463547\\nThis machine benchmarks at 107864 pystones/second\\n\\nc:\\\\Python27\\\\Lib\\\\test> c:\\\\pypy\\\\pypy-1.9\\\\pypy pystone.py\\nPystone(1.1) time for 50000 passes = 0.099975\\nThis machine benchmarks at 500125 pystones/second\\n\\nSince it’s time to wrap up this chapter, this will have to suffice as independent confir-\\nmation of our tests’ results. Analyzing the meaning of pystone’s results is left as sug-\\ngested exercise; its code is not identical across 3.X and 2.X, but appears to differ today\\nonly in terms of print operations and an initialization of a global. Also keep in mind\\nthat benchmarking is just one of many aspects of Python code analysis; for pointers on\\noptions in related domains (e.g., testing), see Chapter 36’s review of Python develop-\\nment tools.\\n\\nFunction Gotchas\\nNow that we’ve reached the end of the function story, let’s review some common pit-\\nfalls. Functions have some jagged edges that you might not expect. They’re all relatively\\n\\n656 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cobscure, and a few have started to fall away from the language completely in recent\\nreleases, but most have been known to trip up new users.\\n\\nLocal Names Are Detected Statically\\nAs you know, Python classifies names assigned in a function as locals by default; they\\nlive in the function’s scope and exist only while the function is running. What you may\\nnot realize is that Python detects locals statically, when it compiles the def’s code, rather\\nthan by noticing assignments as they happen at runtime. This leads to one of the most\\ncommon oddities posted on the Python newsgroup by beginners.\\nNormally, a name that isn’t assigned in a function is looked up in the enclosing module:\\n\\n>>> X = 99\\n\\n>>> def selector():       # X used but not assigned\\n        print(X)          # X found in global scope\\n\\n>>> selector()\\n99\\n\\nHere, the X in the function resolves to the X in the module. But watch what happens if\\nyou add an assignment to X after the reference:\\n\\n>>> def selector():\\n        print(X)          # Does not yet exist!\\n        X = 88            # X classified as a local name (everywhere)\\n                          # Can also happen for \"import X\", \"def X\"...\\n>>> selector()\\nUnboundLocalError: local variable \\'X\\' referenced before assignment\\n\\nYou get the name usage error shown here, but the reason is subtle. Python reads and\\ncompiles this code when it’s typed interactively or imported from a module. While\\ncompiling, Python sees the assignment to X and decides that X will be a local name\\neverywhere in the function. But when the function is actually run, because the assign-\\nment hasn’t yet happened when the print executes, Python says you’re using an un-\\ndefined name. According to its name rules, it should say this; the local X is used before\\nbeing assigned. In fact, any assignment in a function body makes a name local. Imports,\\n=, nested defs, nested classes, and so on are all susceptible to this behavior.\\nThe problem occurs because assigned names are treated as locals everywhere in a func-\\ntion, not just after the statements where they’re assigned. Really, the previous example\\nis ambiguous: was the intention to print the global X and create a local X, or is this a\\nreal programming error? Because Python treats X as a local everywhere, it’s seen as an\\nerror; if you mean to print the global X, you need to declare it in a global statement:\\n\\n>>> def selector():\\n        global X                # Force X to be global (everywhere)\\n        print(X)\\n        X = 88\\n\\nFunction Gotchas\\n\\n| 657\\n\\n\\x0c>>> selector()\\n99\\n\\nRemember, though, that this means the assignment also changes the global X, not a\\nlocal X. Within a function, you can’t use both local and global versions of the same\\nsimple name. If you really meant to print the global and then set a local of the same\\nname, you’d need to import the enclosing module and use module attribute notation\\nto get to the global version:\\n\\n>>> X = 99\\n>>> def selector():\\n        import __main__         # Import enclosing module\\n        print(__main__.X)       # Qualify to get to global version of name\\n        X = 88                  # Unqualified X classified as local\\n        print(X)                # Prints local version of name\\n\\n>>> selector()\\n99\\n88\\n\\nQualification (the .X part) fetches a value from a namespace object. The interactive\\nnamespace is a module called __main__, so __main__.X reaches the global version of X.\\nIf that isn’t clear, check out Chapter 17.\\nIn recent versions Python has improved on this story somewhat by issuing for this case\\nthe more specific “unbound local” error message shown in the example listing (it used\\nto simply raise a generic name error); this gotcha is still present in general, though.\\n\\nDefaults and Mutable Objects\\nAs noted briefly in Chapter 17 and Chapter 18, mutable values for default arguments\\ncan retain state between calls, though this is often unexpected. In general, default ar-\\ngument values are evaluated and saved once when a def statement is run, not each time\\nthe resulting function is later called. Internally, Python saves one object per default\\nargument attached to the function itself.\\nThat’s usually what you want—because defaults are evaluated at def time, it lets you\\nsave  values  from  the  enclosing  scope,  if  needed  (functions  defined  within  loops  by\\nfactories may even depend on this behavior—see ahead). But because a default retains\\nan object between calls, you have to be careful about changing mutable defaults. For\\ninstance, the following function uses an empty list as a default value, and then changes\\nit in place each time the function is called:\\n\\n>>> def saver(x=[]):               # Saves away a list object\\n        x.append(1)                # Changes same object each time!\\n        print(x)\\n\\n>>> saver([2])                     # Default not used\\n[2, 1]\\n>>> saver()                        # Default used\\n[1]\\n\\n658 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0c>>> saver()                        # Grows on each call!\\n[1, 1]\\n>>> saver()\\n[1, 1, 1]\\n\\nSome see this behavior as a feature—because mutable default arguments retain their\\nstate between function calls, they can serve some of the same roles as static local func-\\ntion variables in the C language. In a sense, they work much like global variables, but\\ntheir names are local to the functions and so will not clash with names elsewhere in a\\nprogram.\\nTo other observers, though, this seems like a gotcha, especially the first time they run\\ninto it. There are better ways to retain state between calls in Python (e.g., using the\\nnested scope closures we met in this part and the classes we will study in Part VI).\\nMoreover, mutable defaults are tricky to remember (and to understand at all). They\\ndepend upon the timing of default object construction. In the prior example, there is\\njust one list object for the default value—the one created when the def is executed. You\\ndon’t get a new list every time the function is called, so the list grows with each new\\nappend; it is not reset to empty on each call.\\nIf that’s not the behavior you want, simply make a copy of the default at the start of\\nthe function body, or move the default value expression into the function body. As long\\nas the value resides in code that’s actually executed each time the function runs, you’ll\\nget a new object each time through:\\n\\n>>> def saver(x=None):\\n        if x is None:             # No argument passed?\\n            x = []                # Run code to make a new list each time\\n        x.append(1)               # Changes new list object\\n        print(x)\\n\\n>>> saver([2])\\n[2, 1]\\n>>> saver()                       # Doesn\\'t grow here\\n[1]\\n>>> saver()\\n[1]\\n\\nBy the way, the if statement in this example could almost be replaced by the assignment\\nx = x or [], which takes advantage of the fact that Python’s  or returns one of its\\noperand objects: if no argument was passed, x would default to None, so the or would\\nreturn the new empty list on the right.\\nHowever, this isn’t exactly the same. If an empty list were passed in, the or expression\\nwould cause the function to extend and return a newly created list, rather than ex-\\ntending and returning the passed-in list like the if version. (The expression becomes\\n[] or [], which evaluates to the new empty list on the right; see the section “Truth\\nTests” if you don’t recall why.) Real program requirements may call for either behavior.\\n\\nFunction Gotchas\\n\\n| 659\\n\\n\\x0cToday, another way to achieve the value retention effect of mutable defaults in a pos-\\nsibly less confusing way is to use the function attributes we discussed in Chapter 19:\\n\\n>>> def saver():\\n        saver.x.append(1)\\n        print(saver.x)\\n\\n>>> saver.x = []\\n>>> saver()\\n[1]\\n>>> saver()\\n[1, 1]\\n>>> saver()\\n[1, 1, 1]\\n\\nThe function name is global to the function itself, but it need not be declared because\\nit isn’t changed directly within the function. This isn’t used in exactly the same way,\\nbut when coded like this, the attachment of an object to the function is much more\\nexplicit (and arguably less magical).\\n\\nFunctions Without returns\\nIn  Python  functions,  return  (and  yield)  statements  are  optional.  When  a  function\\ndoesn’t return a value explicitly, the function exits when control falls off the end of the\\nfunction body. Technically, all functions return a value; if you don’t provide a return\\nstatement, your function returns the None object automatically:\\n\\n>>> def proc(x):\\n        print(x)                 # No return is a None return\\n\\n>>> x = proc(\\'testing 123...\\')\\ntesting 123...\\n>>> print(x)\\nNone\\n\\nFunctions such as this without a  return are Python’s equivalent of what are called\\n“procedures” in some languages. They’re usually invoked as statements, and the None\\nresults are ignored, as they do their business without computing a useful result.\\nThis is worth knowing, because Python won’t tell you if you try to use the result of a\\nfunction that doesn’t return one. As we noted in Chapter 11, for instance, assigning\\nthe result of a list append method won’t raise an error, but you’ll get back None, not the\\nmodified list:\\n\\n>>> list = [1, 2, 3]\\n>>> list = list.append(4)        # append is a \"procedure\"\\n>>> print(list)                  # append changes list in place\\nNone\\n\\nChapter 15’s section “Common Coding Gotchas” on page 463 discusses this more\\nbroadly. In general, any functions that do their business as a side effect are usually\\ndesigned to be run as statements, not expressions.\\n\\n660 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cMiscellaneous Function Gotchas\\nHere  are  two  additional  function-related  gotchas—mostly  reviews,  but  common\\nenough to reiterate.\\n\\nEnclosing scopes and loop variables: Factory functions\\nWe described this gotcha in Chapter 17’s discussion of enclosing function scopes, but\\nas a reminder: when coding factory functions (a.k.a. closures), be careful about relying\\non enclosing function scope lookup for variables that are changed by enclosing loops\\n—when a generated function is later called, all such references will remember the value\\nof the last loop iteration in the enclosing function’s scope. In this case, you must use\\ndefaults to save loop variable values instead of relying on automatic lookup in enclosing\\nscopes. See “Loop variables may require defaults, not scopes” on page 506 in Chap-\\nter 17 for more details on this topic.\\n\\nHiding built-ins by assignment: Shadowing\\nAlso in Chapter 17, we saw how it’s possible to reassign built-in names in a closer local\\nor global scope; the reassignment effectively hides and replaces that built-in’s name for\\nthe remainder of the scope where the assignment occurs. This means you won’t be able\\nto use the original built-in value for the name. As long as you don’t need the built-in\\nvalue of the name you’re assigning, this isn’t an issue—many names are built in, and\\nthey may be freely reused. However, if you reassign a built-in name your code relies\\non, you may have problems. So either don’t do that, or use tools like PyChecker that \\ncan warn you if you do. The good news is that the built-ins you commonly use will\\nsoon become second nature, and Python’s error trapping will alert you early in testing\\nif your built-in name is not what you think it is.\\n\\nChapter Summary\\nThis chapter rounded out our look at functions and built-in iteration tools with a larger\\ncase study that measured the performance of iteration alternatives and Pythons, and\\nclosed with a review of common function-related mistakes to help you avoid pitfalls.\\nThe iteration story has one last sequel in Part VI, where we’ll learn how to code user-\\ndefined  iterable  objects  that  generate  values  with  classes  and  __iter__,  in  Chap-\\nter 30’s operator overloading coverage.\\nThis concludes the functions part of this book. In the next part, we will expand on what\\nwe already know about modules—files of tools that form the topmost organizational\\nunit in Python, and the structure in which our functions always live. After that, we will\\nexplore classes, tools that are largely packages of functions with special first arguments.\\nAs we’ll see, user-defined classes can implement objects that tap into the iteration pro-\\ntocol, just like the generators and iterables we met here. In fact, everything we have\\n\\nChapter Summary | 661\\n\\n\\x0clearned in this part of the book will apply when functions pop up later in the context\\nof class methods.\\nBefore moving on to modules, though, be sure to work through this chapter’s quiz and\\nthe exercises for this part of the book, to practice what we’ve learned about functions\\nhere.\\n\\nTest Your Knowledge: Quiz\\n1. What  conclusions  can  you  draw  from  this  chapter  about  the  relative  speed  of\\n\\nPython iteration tools?\\n\\n2. What conclusions can you draw from this chapter about the relative speed of the\\n\\nPythons timed?\\n\\nTest Your Knowledge: Answers\\n1. In general, list comprehensions are usually the quickest of the bunch; map beats list\\ncomprehensions in Python only when all tools must call functions; for loops tend\\nto be slower than comprehensions; and generator functions and expressions are\\nslower than comprehensions by a constant factor. Under PyPy, some of these find-\\nings differ; map often turns in a different relative performance, for example, and list\\ncomprehensions seem always quickest, perhaps due to function-level optimiza-\\ntions.\\nAt least that’s the case today on the Python versions tested, on the test machine\\nused, and for the type of code timed—these results may vary if any of these three\\nvariables differ. Use the homegrown timer or standard library timeit to test your\\nuse cases for more relevant results. Also keep in mind that iteration is just one\\ncomponent of a program’s time: more code gives a more complete picture.\\n\\n2. In general, PyPy 1.9 (implementing Python 2.7) is typically faster than CPython\\n2.7, and CPython 2.7 is often faster than CPython 3.3. In most cases timed, PyPy\\nis some 10X faster than CPython, and CPython 2.7 is often a small constant faster\\nthan CPython 3.3. In cases that use integer math, CPython 2.7 can be 10X faster\\nthan CPython 3.3, and PyPy can be 100X faster than 3.3. In other cases (e.g., string\\noperations and file iterators), PyPy can be slower than CPython by 10X, though\\ntimeit  and  memory  management  differences  may  influence  some  results.  The\\npystone benchmark confirms these relative rankings, though the sizes of the dif-\\nferences it reports differ due to the code timed.\\nAt least that’s the case today on the Python versions tested, on the test machine\\nused, and for the type of code timed—these results may vary if any of these three\\nvariables differ. Use the homegrown timer or standard library timeit to test your\\nuse  cases  for  more  relevant  results.  This  is  especially  true  when  timing  Python\\nimplementations, which may be arbitrarily optimized in each new release.\\n\\n662 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0cTest Your Knowledge: Part IV Exercises\\nIn these exercises, you’re going to start coding more sophisticated programs. Be sure\\nto check the solutions in Part IV in Appendix D, and be sure to start writing your code\\nin module files. You won’t want to retype these exercises if you make a mistake.\\n\\n1. The basics. At the Python interactive prompt, write a function that prints its single\\nargument to the screen and call it interactively, passing a variety of object types:\\nstring, integer, list, dictionary. Then, try calling it without passing any argument.\\nWhat happens? What happens when you pass two arguments?\\n\\n2. Arguments. Write a function called adder in a Python module file. The function\\nshould accept two arguments and return the sum (or concatenation) of the two.\\nThen, add code at the bottom of the file to call the adder function with a variety of\\nobject types (two strings, two lists, two floating points), and run this file as a script\\nfrom the system command line. Do you have to print the call statement results to\\nsee results on your screen?\\n\\n3. varargs. Generalize the adder function you wrote in the last exercise to compute\\nthe sum of an arbitrary number of arguments, and change the calls to pass more\\nor fewer than two arguments. What type is the return value sum? (Hints: a slice\\nsuch as S[:0] returns an empty sequence of the same type as S, and the type built-\\nin  function  can  test  types;  but  see  the  manually  coded  min  examples  in  Chap-\\nter 18 for a simpler approach.) What happens if you pass in arguments of different\\ntypes? What about passing in dictionaries?\\n\\n4. Keywords. Change the adder function from exercise 2 to accept and sum/concat-\\nenate three arguments: def adder(good, bad, ugly). Now, provide default values\\nfor  each  argument,  and  experiment  with  calling  the  function  interactively.  Try\\npassing  one,  two,  three,  and  four  arguments.  Then,  try  passing  keyword  argu-\\nments. Does the call adder(ugly=1, good=2) work? Why? Finally, generalize the\\nnew adder to accept and sum/concatenate an arbitrary number of keyword argu-\\nments. This is similar to what you did in exercise 3, but you’ll need to iterate over\\na dictionary, not a tuple. (Hint: the dict.keys method returns a list you can step\\nthrough with a for or while, but be sure to wrap it in a list call to index it in 3.X;\\ndict.values may help here too.)\\n\\n5. Dictionary tools. Write a function called copyDict(dict) that copies its dictionary\\nargument. It should return a new dictionary containing all the items in its argu-\\nment. Use the dictionary keys method to iterate (or, in Python 2.2 and later, step\\nover a dictionary’s keys without calling  keys). Copying sequences is easy (X[:]\\nmakes a top-level copy); does this work for dictionaries, too? As explained in this\\nexercise’s solution, because dictionaries now come with similar tools, this and the\\nnext  exercise  are  just  coding  exercises  but  still  serve  as  representative  function\\nexamples.\\n\\n6. Dictionary tools. Write a function called addDict(dict1, dict2) that computes the\\nunion of two dictionaries. It should return a new dictionary containing all the items\\n\\nTest Your Knowledge: Part IV Exercises\\n\\n| 663\\n\\n\\x0cin both its arguments (which are assumed to be dictionaries). If the same key ap-\\npears in both arguments, feel free to pick a value from either. Test your function\\nby writing it in a file and running the file as a script. What happens if you pass lists\\ninstead of dictionaries? How could you generalize your function to handle this case,\\ntoo? (Hint: see the type built-in function used earlier.) Does the order of the argu-\\nments passed in matter?\\n\\n7. More argument-matching examples. First, define the following six functions (either\\n\\ninteractively or in a module file that can be imported):\\n\\ndef f1(a, b): print(a, b)            # Normal args\\ndef f2(a, *b): print(a, b)           # Positional varargs\\n\\ndef f3(a, **b): print(a, b)          # Keyword varargs\\n\\ndef f4(a, *b, **c): print(a, b, c)   # Mixed modes\\n\\ndef f5(a, b=2, c=3): print(a, b, c)  # Defaults\\n\\ndef f6(a, b=2, *c): print(a, b, c)   # Defaults and positional varargs\\n\\nNow, test the following calls interactively, and try to explain each result; in some\\ncases, you’ll probably need to fall back on the matching algorithm shown in Chap-\\nter 18. Do you think mixing matching modes is a good idea in general? Can you\\nthink of cases where it would be useful?\\n\\n>>> f1(1, 2)\\n>>> f1(b=2, a=1)\\n\\n>>> f2(1, 2, 3)\\n>>> f3(1, x=2, y=3)\\n>>> f4(1, 2, 3, x=2, y=3)\\n\\n>>> f5(1)\\n>>> f5(1, 4)\\n\\n>>> f6(1)\\n>>> f6(1, 3, 4)\\n\\n8. Primes revisited. Recall the following code snippet from Chapter 13, which sim-\\n\\nplistically determines whether a positive integer is prime:\\n\\nx = y // 2                          # For some y > 1\\nwhile x > 1:\\n    if y % x == 0:                  # Remainder\\n      print(y, \\'has factor\\', x)\\n      break                         # Skip else\\n    x -= 1\\nelse:                               # Normal exit\\n    print(y, \\'is prime\\')\\n\\nPackage this code as a reusable function in a module file (y should be a passed-in\\nargument), and add some calls to the function at the bottom of your file. While\\nyou’re at it, experiment with replacing the first line’s // operator with / to see how\\n\\n664 | Chapter 21:\\u2002The Benchmarking Interlude\\n\\n\\x0ctrue division changes the / operator in Python 3.X and breaks this code (refer back\\nto Chapter 5 if you need a reminder). What can you do about negatives, and the\\nvalues 0 and 1? How about speeding this up? Your outputs should look something\\nlike this:\\n\\n13 is prime\\n13.0 is prime\\n15 has factor 5\\n15.0 has factor 5.0\\n\\n9. Iterations and comprehensions. Write code to build a new list containing the square\\nroots of all the numbers in this list: [2, 4, 9, 16, 25]. Code this as a for loop first,\\nthen as a map call, then as a list comprehension, and finally as a generator expres-\\nsion. Use the sqrt function in the built-in math module to do the calculation (i.e.,\\nimport math and say math.sqrt(x)). Of the four, which approach do you like best?\\n10. Timing  tools.  In  Chapter  5,  we  saw  three  ways  to  compute  square  roots:\\nmath.sqrt(X), X ** .5, and pow(X, .5). If your programs run a lot of these, their\\nrelative performance might become important. To see which is quickest, repurpose\\nthe timerseqs.py script we wrote in this chapter to time each of these three tools.\\nUse the bestof or bestoftotal functions in one of this chapter’s timer modules to\\ntest (you can use either the original, the 3.X-only keyword-only variant, or the 2.X/\\n3.X version, and may use Python’s timeit module as well). You might also want\\nto repackage the testing code in this script for better reusability—by passing a test\\nfunctions tuple to a general tester function, for example (for this exercise a copy-\\nand-modify approach is fine). Which of the three square root tools seems to run\\nfastest on your machine and Python in general? Finally, how might you go about\\ninteractively timing the speed of dictionary comprehensions versus for loops?\\n\\n11. Recursive functions. Write a simple recursion function named countdown that prints\\nnumbers as it counts down to zero. For example, a call countdown(5) will print: 5\\n4 3 2 1 stop. There’s no obvious reason to code this with an explicit stack or\\nqueue, but what about a nonfunction approach? Would a generator make sense\\nhere?\\n\\n12. Computing factorials. Finally, a computer science classic (but demonstrative none-\\ntheless). We employed the notion of factorials in Chapter 20’s coverage of permu-\\ntations: N!, computed as N*(N-1)*(N-2)*...1. For instance, 6! is 6*5*4*3*2*1, or\\n720. Code and time four functions that, for a call fact(N), each return N!. Code\\nthese four functions (1) as a recursive countdown per Chapter 19; (2) using the\\nfunctional reduce call per Chapter 19; (3) with a simple iterative counter loop per\\nChapter 13; and (4) using the  math.factorial library tool per  Chapter 20. Use\\nChapter 21’s timeit to time each of your functions. What conclusions can you\\ndraw from your results?\\n\\nTest Your Knowledge: Part IV Exercises\\n\\n| 665\\n\\n\\x0c\\x0cPART V\\nModules and Packages\\n\\n\\x0c\\x0cCHAPTER 22\\nModules: The Big Picture\\n\\nThis chapter begins our in-depth look at the Python module—the highest-level program\\norganization unit, which packages program code and data for reuse, and provides self-\\ncontained namespaces that minimize variable name clashes across your programs. In\\nconcrete terms, modules typically correspond to Python program files. Each file is a\\nmodule, and modules import other modules to use the names they define. Modules\\nmight also correspond to extensions coded in external languages such as C, Java, or\\nC#, and even to directories in package imports. Modules are processed with two state-\\nments and one important function:\\n\\nimport\\n\\nLets a client (importer) fetch a module as a whole\\n\\nfrom\\n\\nAllows clients to fetch particular names from a module\\n\\nimp.reload (reload in 2.X)\\n\\nProvides a way to reload a module’s code without stopping Python\\n\\nChapter 3 introduced module fundamentals, and we’ve been using them ever since.\\nThe goal here is to expand on the core module concepts you’re already familiar with,\\nand move on to explore more advanced module usage. This first chapter reviews mod-\\nule basics, and offers a general look at the role of modules in overall program structure.\\nIn the chapters that follow, we’ll dig into the coding details behind the theory.\\nAlong the way, we’ll flesh out module details omitted so far—you’ll learn about reloads,\\nthe __name__ and __all__ attributes, package imports, relative import syntax, 3.3 name-\\nspace packages, and so on. Because modules and classes are really just glorified name-\\nspaces, we’ll formalize namespace concepts here as well.\\n\\nWhy Use Modules?\\nIn short, modules provide an easy way to organize components into a system by serving\\nas self-contained packages of variables known as namespaces. All the names defined at\\n\\n669\\n\\n\\x0cthe top level of a module file become attributes of the imported module object. As we\\nsaw in the last part of this book, imports give access to names in a module’s global\\nscope. That is, the module file’s global scope morphs into the module object’s attribute\\nnamespace when it is imported. Ultimately, Python’s modules allow us to link indi-\\nvidual files into a larger program system.\\nMore specifically, modules have at least three roles:\\n\\nCode reuse\\n\\nAs discussed in Chapter 3, modules let you save code in files permanently. Unlike\\ncode you type at the Python interactive prompt, which goes away when you exit\\nPython, code in module files is persistent—it can be reloaded and rerun as many\\ntimes as needed. Just as importantly, modules are a place to define names, known\\nas attributes, which may be referenced by multiple external clients. When used\\nwell, this supports a modular program design that groups functionality into reus-\\nable units.\\n\\nSystem namespace partitioning\\n\\nModules are also the highest-level program organization unit in Python. Although\\nthey are fundamentally just packages of names, these packages are also self-con-\\ntained—you can never see a name in another file, unless you explicitly import that\\nfile. Much like the local scopes of functions, this helps avoid name clashes across\\nyour programs. In fact, you can’t avoid this feature—everything “lives” in a mod-\\nule, both the code you run and the objects you create are always implicitly enclosed\\nin modules. Because of that, modules are natural tools for grouping system com-\\nponents.\\n\\nImplementing shared services or data\\n\\nFrom an operational perspective, modules are also useful for implementing com-\\nponents that are shared across a system and hence require only a single copy. For\\ninstance, if you need to provide a global object that’s used by more than one func-\\ntion or file, you can code it in a module that can then be imported by many clients.\\n\\nAt least that’s the abstract story—for you to truly understand the role of modules in a\\nPython system, we need to digress for a moment and explore the general structure of\\na Python program.\\n\\nPython Program Architecture\\nSo  far  in  this  book,  I’ve  sugarcoated  some  of  the  complexity  in  my  descriptions  of\\nPython programs. In practice, programs usually involve more than just one file. For all\\nbut the simplest scripts, your programs will take the form of multifile systems—as the\\ncode timing programs of the preceding chapter illustrate. Even if you can get by with\\ncoding a single file yourself, you will almost certainly wind up using external files that\\nsomeone else has already written.\\n\\n670 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0cThis section introduces the general architecture of Python programs—the way you di-\\nvide a program into a collection of source files (a.k.a. modules) and link the parts into\\na whole. As we’ll see, Python fosters a modular program structure that groups func-\\ntionality into coherent and reusable units, in ways that are natural, and almost auto-\\nmatic. Along the way, we’ll also explore the central concepts of Python modules, im-\\nports, and object attributes.\\n\\nHow to Structure a Program\\nAt a base level, a Python program consists of text files containing Python statements,\\nwith one main top-level file, and zero or more supplemental files known as modules.\\nHere’s how this works. The top-level (a.k.a. script) file contains the main flow of control\\nof your program—this is the file you run to launch your application. The module files\\nare libraries of tools used to collect components used by the top-level file, and possibly\\nelsewhere. Top-level files use tools defined in module files, and modules use tools de-\\nfined in other modules.\\nAlthough they are files of code too, module files generally don’t do anything when run\\ndirectly; rather, they define tools intended for use in other files. A file imports a module\\nto gain access to the tools it defines, which are known as its attributes—variable names\\nattached to objects such as functions. Ultimately, we import modules and access their\\nattributes to use their tools.\\n\\nImports and Attributes\\nLet’s make this a bit more concrete. Figure 22-1 sketches the structure of a Python\\nprogram composed of three files: a.py, b.py, and c.py. The file a.py is chosen to be the\\ntop-level file; it will be a simple text file of statements, which is executed from top to\\nbottom when launched. The files b.py and c.py are modules; they are simple text files\\nof statements as well, but they are not usually launched directly. Instead, as explained\\npreviously, modules are normally imported by other files that wish to use the tools the\\nmodules define.\\nFor instance, suppose the file b.py in Figure 22-1 defines a function called spam, for\\nexternal use. As we learned when studying functions in Part IV, b.py will contain a\\nPython def statement to generate the function, which you can later run by passing zero\\nor more values in parentheses after the function’s name:\\n\\ndef spam(text):                # File b.py\\n    print(text, \\'spam\\')\\n\\nNow, suppose a.py wants to use spam. To this end, it might contain Python statements\\nsuch as the following:\\n\\nimport b                       # File a.py\\nb.spam(\\'gumby\\')                # Prints \"gumby spam\"\\n\\nPython Program Architecture | 671\\n\\n\\x0cFigure 22-1. Program architecture in Python. A program is a system of modules. It has one top-level\\nscript file (launched to run the program), and multiple module files (imported libraries of tools). Scripts\\nand  modules  are  both  text  files  containing  Python  statements,  though  the  statements  in  modules\\nusually just create objects to be used later. Python’s standard library provides a collection of precoded\\nmodules.\\n\\nThe first of these, a Python import statement, gives the file a.py access to everything\\ndefined by top-level code in the file b.py. The code import b roughly means:\\n\\nLoad the file b.py (unless it’s already loaded), and give me access to all its attributes\\nthrough the name b.\\n\\nTo satisfy such goals, import (and, as you’ll see later, from) statements execute and load\\nother files on request. More formally, in Python, cross-file module linking is not re-\\nsolved until such import statements are executed at runtime; their net effect is to assign\\nmodule names—simple variables like b—to loaded module objects. In fact, the module\\nname used in an import statement serves two purposes: it identifies the external file to\\nbe loaded, but it also becomes a variable assigned to the loaded module.\\nSimilarly,  objects  defined  by  a  module  are  also  created  at  runtime,  as  the  import  is\\nexecuting: import literally runs statements in the target file one at a time to create its\\ncontents. Along the way, every name assigned at the top-level of the file becomes an\\nattribute of the module, accessible to importers. For example, the second of the state-\\nments in a.py calls the function spam defined in the module b—created by running its\\ndef statement during the import—using object attribute notation. The code  b.spam\\nmeans:\\n\\nFetch the value of the name spam that lives within the object b.\\n\\nThis happens to be a callable function in our example, so we pass a string in parentheses\\n(\\'gumby\\'). If you actually type these files, save them, and run a.py, the words “gumby\\nspam” will be printed.\\nAs we’ve seen, the object.attribute notation appears throughout Python code—most\\nobjects have useful attributes that are fetched with the “.” operator. Some reference\\ncallable objects like functions that take action (e.g., a salary computer), and others are\\n\\n672 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0csimple  data  values  that  denote  more  static  objects  and  properties  (e.g.,  a  person’s\\nname).\\nThe notion of importing is also completely general throughout Python. Any file can\\nimport tools from any other file. For instance, the file a.py may import b.py to call its\\nfunction, but b.py might also import c.py to leverage different tools defined there. Im-\\nport chains can go as deep as you like: in this example, the module a can import b,\\nwhich can import c, which can import b again, and so on.\\nBesides serving as the highest organizational structure, modules (and module packages,\\ndescribed in Chapter 24) are also the highest level of code reuse in Python. Coding\\ncomponents in module files makes them useful in your original program, and in any\\nother programs you may write later. For instance, if after coding the program in Fig-\\nure 22-1 we discover that the function b.spam is a general-purpose tool, we can reuse\\nit in a completely different program; all we have to do is import the file b.py again from\\nthe other program’s files.\\n\\nStandard Library Modules\\nNotice the rightmost portion of Figure 22-1. Some of the modules that your programs\\nwill import are provided by Python itself and are not files you will code.\\nPython automatically comes with a large collection of utility modules known as the\\nstandard library. This collection, over 200 modules large at last count, contains plat-\\nform-independent support for common programming tasks: operating system inter-\\nfaces, object persistence, text pattern matching, network and Internet scripting, GUI\\nconstruction, and much more. None of these tools are part of the Python language\\nitself, but you can use them by importing the appropriate modules on any standard\\nPython installation. Because they are standard library modules, you can also be rea-\\nsonably sure that they will be available and will work portably on most platforms on\\nwhich you will run Python.\\nThis book’s examples employ a few of the standard library’s modules—timeit, sys,\\nand os in last chapter’s code, for instance—but we’ll really only scratch the surface of\\nthe libraries story here. For a complete look, you should browse the standard Python\\nlibrary reference manual, available either online at http://www.python.org, or with your\\nPython installation (via IDLE or Python’s Start button menu on some Windows). The\\nPyDoc tool discussed in Chapter 15 is another way to explore standard library modules.\\nBecause there are so many modules, this is really the only way to get a feel for what\\ntools are available. You can also find tutorials on Python library tools in commercial\\nbooks  that  cover  application-level  programming,  such  as  O’Reilly’s  Programming\\nPython, but the manuals are free, viewable in any web browser (in HTML format),\\nviewable in other formats (e.g., Windows help), and updated each time Python is re-\\nreleased. See Chapter 15 for more pointers.\\n\\nPython Program Architecture | 673\\n\\n\\x0cHow Imports Work\\nThe prior section talked about importing modules without really explaining what hap-\\npens when you do so. Because imports are at the heart of program structure in Python,\\nthis section goes into more formal detail on the import operation to make this process\\nless abstract.\\nSome  C  programmers  like  to  compare  the  Python  module  import  operation  to  a  C\\n#include, but they really shouldn’t—in Python, imports are not just textual insertions\\nof one file into another. They are really runtime operations that perform three distinct\\nsteps the first time a program imports a given file:\\n\\n1. Find the module’s file.\\n2. Compile it to byte code (if needed).\\n3. Run the module’s code to build the objects it defines.\\n\\nTo better understand module imports, we’ll explore these steps in turn. Bear in mind\\nthat all three of these steps are carried out only the first time a module is imported\\nduring  a  program’s  execution;  later  imports  of  the  same  module  in  a  program  run\\nbypass all of these steps and simply fetch the already loaded module object in memory.\\nTechnically,  Python  does  this  by  storing  loaded  modules  in  a  table  named  sys.mod\\nules and checking there at the start of an import operation. If the module is not present,\\na three-step process begins.\\n\\n1. Find It\\nFirst, Python must locate the module file referenced by an import statement. Notice\\nthat the import statement in the prior section’s example names the file without a .py\\nextension and without its directory path: it just says import b, instead of something\\nlike import c:\\\\dir1\\\\b.py. Path and extension details are omitted on purpose; instead,\\nPython uses a standard module search path and known file types to locate the module\\nfile corresponding to an import statement.1 Because this is the main part of the import\\noperation that programmers must know about, we’ll return to this topic in a moment.\\n\\n1. It’s syntactically illegal to include path and extension details in a standard import. However, package\\nimports, which we’ll discuss in Chapter 24, allow import statements to include part of the directory path\\nleading to a file as a set of period-separated names. Package imports, though, still rely on the normal\\nmodule search path to locate the leftmost directory in a package path (i.e., they are relative to a directory\\nin the search path). They also cannot make use of any platform-specific directory syntax in the import\\nstatements; such syntax only works on the search path. Also, note that module file search path issues are\\nnot as relevant when you run frozen executables (discussed in Chapter 2), which typically embed byte\\ncode in the binary image.\\n\\n674 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0c2. Compile It (Maybe)\\nAfter finding a source code file that matches an  import statement by traversing the\\nmodule search path, Python next compiles it to byte code, if necessary. We discussed\\nbyte code briefly in Chapter 2, but it’s a bit richer than explained there. During an\\nimport operation Python checks both file modification times and the byte code’s Python\\nversion number to decide how to proceed. The former uses file “timestamps,” and the\\nlatter uses either a “magic” number embedded in the byte code or a filename, depending\\non the Python release being used. This step chooses an action as follows:\\n\\nCompile\\n\\nIf the byte code file is older than the source file (i.e., if you’ve changed the source)\\nor was created by a different Python version, Python automatically regenerates the\\nbyte code when the program is run.\\nAs discussed ahead, this model is modified somewhat in Python 3.2 and later—\\nbyte code files are segregated in a __pycache__ subdirectory and named with their\\nPython version to avoid contention and recompiles when multiple Pythons are\\ninstalled. This obviates the need to check version numbers in the byte code, but\\nthe timestamp check is still used to detect changes in the source.\\n\\nDon’t compile\\n\\nIf, on the other hand, Python finds a .pyc byte code file that is not older than the \\ncorresponding .py source file and was created by the same Python version, it skips\\nthe source-to-byte-code compile step.\\nIn addition, if Python finds only a byte code file on the search path and no source,\\nit simply loads the byte code directly; this means you can ship a program as just\\nbyte code files and avoid sending source. In other words, the compile step is by-\\npassed if possible to speed program startup.\\n\\nNotice that compilation happens when a file is being imported. Because of this, you\\nwill not usually see a .pyc byte code file for the top-level file of your program, unless it\\nis also imported elsewhere—only imported files leave behind .pyc files on your ma-\\nchine. The byte code of top-level files is used internally and discarded; byte code of\\nimported files is saved in files to speed future imports.\\nTop-level files are often designed to be executed directly and not imported at all. Later,\\nwe’ll see that it is possible to design a file that serves both as the top-level code of a\\nprogram and as a module of tools to be imported. Such a file may be both executed\\nand imported, and thus does generate a .pyc. To learn how this works, watch for the\\ndiscussion of the special __name__ attribute and __main__ in Chapter 25.\\n\\n3. Run It\\nThe final step of an import operation executes the byte code of the module. All state-\\nments in the file are run in turn, from top to bottom, and any assignments made to\\nnames during this step generate attributes of the resulting module object. This is how\\n\\nHow Imports Work | 675\\n\\n\\x0cthe tools defined by the module’s code are created. For instance, def statements in a\\nfile are run at import time to create functions and assign attributes within the module\\nto those functions. The functions can then be called later in the program by the file’s\\nimporters.\\nBecause this last import step actually runs the file’s code, if any top-level code in a\\nmodule file does real work, you’ll see its results at import time. For example, top-level\\nprint statements in a module show output when the file is imported. Function def\\nstatements simply define objects for later use.\\nAs you can see, import operations involve quite a bit of work—they search for files,\\npossibly run a compiler, and run Python code. Because of this, any given module is\\nimported only once per process by default. Future imports skip all three import steps\\nand reuse the already loaded module in memory. If you need to import a file again after\\nit has already been loaded (for example, to support dynamic end-user customizations),\\nyou have to force the issue with an  imp.reload call—a tool we’ll meet in the next \\nchapter.2\\n\\nByte Code Files: __pycache__ in Python 3.2+\\nAs mentioned briefly, the way that Python stores files to retain the byte code that results\\nfrom compiling your source has changed in Python 3.2 and later. First of all, if Python\\ncannot write a file to save this on your computer for any reason, your program still runs\\nfine—Python simply creates and uses the byte code in memory and discards it on exit.\\nTo speed startups, though, it will try to save byte code in a file in order to skip the\\ncompile step next time around. The way it does this varies per Python version:\\n\\nIn Python 3.1 and earlier (including all of Python 2.X)\\n\\nByte code is stored in files in the same directory as the corresponding source files,\\nnormally with the filename extension .pyc (e.g., module.pyc). Byte code files are\\nalso stamped internally with the version of Python that created them (known as a\\n“magic” field to developers) so Python knows to recompile when this differs in the\\nversion of Python running your program. For instance, if you upgrade to a new\\nPython whose byte code differs, all your byte code files will be recompiled auto-\\nmatically due to a version number mismatch, even if you haven’t changed your\\nsource code.\\n\\nIn Python 3.2 and later\\n\\nByte code is instead stored in files in a subdirectory named __pycache__, which\\nPython creates if needed, and which is located in the directory containing the cor-\\nresponding source files. This helps avoid clutter in your source directories by seg-\\nregating the byte code files in their own directory. In addition, although byte code\\n\\n2. As described earlier, Python keeps already imported modules in the built-in sys.modules dictionary so it\\ncan keep track of what’s been loaded. In fact, if you want to see which modules are loaded, you can import\\nsys and print list(sys.modules.keys()). There’s more on other uses for this internal table in Chapter 25.\\n\\n676 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0cfiles still get the .pyc extension as before, they are given more descriptive names\\nthat include text identifying the version of Python that created them (e.g., mod-\\nule.cpython-32.pyc). This avoids contention and recompiles: because each version\\nof Python installed can have its own uniquely named version of byte code files in\\nthe __pycache__ subdirectory, running under a given version doesn’t overwrite the\\nbyte code of another, and doesn’t require recompiles. Technically, byte code file-\\nnames also include the name of the Python that created them, so CPython, Jython,\\nand other implementations mentioned in the preface and Chapter 2 can coexist on\\nthe same machine without stepping on each other’s work (once they support this\\nmodel).\\n\\nIn both models, Python always recreates the byte code file if you’ve changed the source\\ncode file since the last compile, but version differences are handled differently—by\\nmagic numbers and replacement prior to 3.2, and by filenames that allow for multiple\\ncopies in 3.2 and later.\\n\\nByte Code File Models in Action\\nThe following is a quick example of these two models in action under 2.X and 3.3. I’ve\\nomitted much of the text displayed by the dir directory listing on Windows here to\\nsave space, and the script used here isn’t listed because it is not relevant to this discus-\\nsion (it’s from Chapter 2, and simply prints two values). Prior to 3.2, byte code files\\nshow up alongside their source files after being created by import operations:\\n\\nc:\\\\code\\\\py2x> dir\\n10/31/2012  10:58 AM                39 script0.py\\n\\nc:\\\\code\\\\py2x> C:\\\\python27\\\\python\\n>>> import script0\\nhello world\\n1267650600228229401496703205376\\n>>> ^Z\\n\\nc:\\\\code\\\\py2x> dir\\n10/31/2012  10:58 AM                39 script0.py\\n10/31/2012  11:00 AM               154 script0.pyc\\n\\nHowever, in 3.2 and later byte code files are saved in the __pycache__ subdirectory and\\ninclude versions and Python implementation details in their names to avoid clutter and\\ncontention among the Pythons on your computer:\\n\\nc:\\\\code\\\\py2x> cd ..\\\\py3x\\nc:\\\\code\\\\py3x> dir\\n10/31/2012  10:58 AM                39 script0.py\\n\\nc:\\\\code\\\\py3x> C:\\\\python33\\\\python\\n>>> import script0\\nhello world\\n1267650600228229401496703205376\\n>>> ^Z\\n\\nByte Code Files: __pycache__ in Python 3.2+ | 677\\n\\n\\x0cc:\\\\code\\\\py3x> dir\\n10/31/2012  10:58 AM                39 script0.py\\n10/31/2012  11:00 AM    <DIR>          __pycache__\\n\\nc:\\\\code\\\\py3x> dir __pycache__\\n10/31/2012  11:00 AM               184 script0.cpython-33.pyc\\n\\nCrucially, under the model used in 3.2 and later, importing the same file with a different\\nPython creates a different byte code file, instead of overwriting the single file as done\\nby the pre-3.2 model—in the newer model, each Python version and implementation\\nhas its own byte code files, ready to be loaded on the next program run (earlier Pythons\\nwill happily continue using their scheme on the same machine):\\n\\nc:\\\\code\\\\py3x> C:\\\\python32\\\\python\\n>>> import script0\\nhello world\\n1267650600228229401496703205376\\n>>> ^Z\\n\\nc:\\\\code\\\\py3x> dir __pycache__\\n10/31/2012  12:28 PM               178 script0.cpython-32.pyc\\n10/31/2012  11:00 AM               184 script0.cpython-33.pyc\\n\\nPython 3.2’s newer byte code file model is probably superior, as it avoids recompiles\\nwhen there is more than one Python on your machine—a common case in today’s\\nmixed 2.X/3.X world. On the other hand, it is not without potential incompatibilities\\nin programs that rely on the prior file and directory structure. This may be a compati-\\nbility  issue  in  some  tools  programs,  for  instance,  though  most  well-behaved  tools\\nshould work as before. See Python 3.2’s “What’s New?” document for details on po-\\ntential impacts.\\nAlso keep in mind that this process is completely automatic—it’s a side effect of running\\nprograms—and most programmers probably won’t care about or even notice the dif-\\nference, apart from faster startups due to fewer recompiles.\\n\\nThe Module Search Path\\nAs mentioned earlier, the part of the import procedure that most programmers will\\nneed to care about is usually the first—locating the file to be imported (the “find it”\\npart). Because you may need to tell Python where to look to find files to import, you\\nneed to know how to tap into its search path in order to extend it.\\nIn many cases, you can rely on the automatic nature of the module import search path\\nand won’t need to configure this path at all. If you want to be able to import user-\\ndefined files across directory boundaries, though, you will need to know how the search\\npath works in order to customize it. Roughly, Python’s module search path is composed\\nof the concatenation of these major components, some of which are preset for you and\\nsome of which you can tailor to tell Python where to look:\\n\\n678 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0c1. The home directory of the program\\n2. PYTHONPATH directories (if set)\\n3. Standard library directories\\n4. The contents of any .pth files (if present)\\n5. The site-packages home of third-party extensions\\n\\nUltimately, the concatenation of these four components becomes sys.path, a mutable\\nlist of directory name strings that I’ll expand upon later in this section. The first and\\nthird elements of the search path are defined automatically. Because Python searches\\nthe  concatenation  of  these  components  from  first  to  last,  though,  the  second  and\\nfourth elements can be used to extend the path to include your own source code di-\\nrectories. Here is how Python uses each of these path components:\\n\\nHome directory (automatic)\\n\\nPython first looks for the imported file in the home directory. The meaning of this\\nentry  depends  on  how  you  are  running  the  code.  When  you’re  running  a  pro-\\ngram, this entry is the directory containing your program’s top-level script file.\\nWhen you’re working interactively, this entry is the directory in which you are\\nworking (i.e., the current working directory).\\nBecause this directory is always searched first, if a program is located entirely in a\\nsingle directory, all of its imports will work automatically with no path configura-\\ntion required. On the other hand, because this directory is searched first, its files\\nwill also override modules of the same name in directories elsewhere on the path;\\nbe careful not to accidentally hide library modules this way if you need them in\\nyour program, or use package tools we’ll meet later that can partially sidestep this\\nissue.\\n\\nPYTHONPATH directories (configurable)\\n\\nNext, Python searches all directories listed in your PYTHONPATH environment vari-\\nable setting, from left to right (assuming you have set this at all: it’s not preset for\\nyou).  In  brief,  PYTHONPATH  is  simply  a  list  of  user-defined  and  platform-specific\\nnames of directories that contain Python code files. You can add all the directories\\nfrom which you wish to be able to import, and Python will extend the module\\nsearch path to include all the directories your PYTHONPATH lists.\\nBecause Python searches the home directory first, this setting is only important\\nwhen importing files across directory boundaries—that is, if you need to import a\\nfile that is stored in a different directory from the file that imports it. You’ll probably\\nwant to set your PYTHONPATH variable once you start writing substantial programs,\\nbut when you’re first starting out, as long as you save all your module files in the\\ndirectory in which you’re working (i.e., the home directory, like the C:\\\\code used\\nin this book) your imports will work without you needing to worry about this\\nsetting at all.\\n\\nThe Module Search Path | 679\\n\\n\\x0cStandard library directories (automatic)\\n\\nNext,  Python  automatically  searches  the  directories  where  the  standard  library\\nmodules are installed on your machine. Because these are always searched, they\\nnormally do not need to be added to your  PYTHONPATH or included in path files\\n(discussed next).\\n\\n.pth path file directories (configurable)\\n\\nNext, a lesser-used feature of Python allows users to add directories to the module\\nsearch path by simply listing them, one per line, in a text file whose name ends\\nwith a .pth suffix (for “path”). These path configuration files are a somewhat ad-\\nvanced installation-related feature; we won’t cover them fully here, but they pro-\\nvide an alternative to PYTHONPATH settings.\\nIn short, text files of directory names dropped in an appropriate directory can serve\\nroughly the same role as the PYTHONPATH environment variable setting. For instance,\\nif  you’re  running  Windows  and  Python  3.3,  a  file  named  myconfig.pth  may  be\\nplaced at the top level of the Python install directory (C:\\\\Python33) or in the site-\\npackages  subdirectory  of  the  standard  library  there  (C:\\\\Python33\\\\Lib\\\\site-pack-\\nages) to extend the module search path. On Unix-like systems, this file might be\\nlocated in usr/local/lib/python3.3/site-packages or /usr/local/lib/site-python instead.\\nWhen such a file is present, Python will add the directories listed on each line of\\nthe file, from first to last, near the end of the module search path list—currently,\\nafter  PYTHONPATH  and  standard  libraries,  but  before  the  site-packages  directory\\nwhere third-party extensions are often installed. In fact, Python will collect the\\ndirectory names in all the .pth path files it finds and will filter out any duplicates\\nand nonexistent directories. Because they are files rather than shell settings, path\\nfiles can apply to all users of an installation, instead of just one user or shell. More-\\nover, for some users and applications, text files may be simpler to code than envi-\\nronment settings.\\nThis feature is more sophisticated than I’ve described here. For more details, con-\\nsult the Python library manual, and especially its documentation for the standard\\nlibrary module site—this module allows the locations of Python libraries and path\\nfiles to be configured, and its documentation describes the expected locations of\\npath files in general. I recommend that beginners use PYTHONPATH or perhaps a sin-\\ngle .pth file, and then only if you must import across directories. Path files are used\\nmore often by third-party libraries, which commonly install a path file in Python’s\\nsite-packages, described next.\\n\\nThe Lib\\\\site-packages directory of third-party extensions (automatic)\\n\\nFinally, Python automatically adds the site-packages subdirectory of its standard\\nlibrary to the module search path. By convention, this is the place that most third-\\nparty  extensions  are  installed,  often  automatically  by  the  distutils  utility  de-\\nscribed in an upcoming sidebar. Because their install directory is always part of the\\nmodule search path, clients can import the modules of such extensions without\\nany path settings.\\n\\n680 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0cConfiguring the Search Path\\nThe net effect of all of this is that both the PYTHONPATH and path file components of the\\nsearch path allow you to tailor the places where imports look for files. The way you set\\nenvironment variables and where you store path files varies per platform. For instance,\\non Windows, you might use your Control Panel’s System icon to set PYTHONPATH to a\\nlist of directories separated by semicolons, like this:\\n\\nc:\\\\pycode\\\\utilities;d:\\\\pycode\\\\package1\\n\\nOr you might instead create a text file called C:\\\\Python33\\\\pydirs.pth, which looks like\\nthis:\\n\\nc:\\\\pycode\\\\utilities\\nd:\\\\pycode\\\\package1\\n\\nThese settings are analogous on other platforms, but the details can vary too widely for\\nus to cover in this chapter. See Appendix A for pointers on extending your module\\nsearch path with PYTHONPATH or .pth files on various platforms.\\n\\nSearch Path Variations\\nThis description of the module search path is accurate, but generic; the exact config-\\nuration of the search path is prone to changing across platforms, Python releases, and\\neven Python implementations. Depending on your platform, additional directories may\\nautomatically be added to the module search path as well.\\nFor instance, some Pythons may add an entry for the current working directory—the\\ndirectory  from  which  you  launched  your  program—in  the  search  path  before  the\\nPYTHONPATH  directories.  When  you’re  launching  from  a  command  line,  the  current\\nworking directory may not be the same as the home directory of your top-level file (i.e.,\\nthe directory where your program file resides), which is always added. Because the\\ncurrent  working  directory  can  vary  each  time  your  program  runs,  you  normally\\nshouldn’t depend on its value for import purposes. See Chapter 3 for more on launching\\nprograms from command lines.3\\nTo see how your Python configures the module search path on your platform, you can\\nalways inspect sys.path—the topic of the next section.\\n\\nThe sys.path List\\nIf you want to see how the module search path is truly configured on your machine,\\nyou can always inspect the path as Python knows it by printing the built-in sys.path\\n\\n3. Also watch for Chapter 24’s discussion of the new relative import syntax and search rules in Python 3.X;\\nthey modify the search path for from statements in files inside packages when “.” characters are used (e.g.,\\nfrom . import string). By default, a package’s own directory is not automatically searched by imports\\nin Python 3.X, unless such relative imports are used by files in the package itself.\\n\\nThe Module Search Path | 681\\n\\n\\x0clist (that is, the path attribute of the standard library module sys). This list of directory\\nname strings is the actual search path within Python; on imports, Python searches each\\ndirectory in this list from left to right, and uses the first file match it finds.\\nReally, sys.path is the module search path. Python configures it at program startup,\\nautomatically merging the home directory of the top-level file (or an empty string to\\ndesignate the current working directory), any PYTHONPATH directories, the contents of\\nany .pth file paths you’ve created, and all the standard library directories. The result is\\na list of directory name strings that Python searches on each import of a new file.\\nPython exposes this list for two good reasons. First, it provides a way to verify the search\\npath settings you’ve made—if you don’t see your settings somewhere in this list, you\\nneed to recheck your work. For example, here is what my module search path looks\\nlike  on  Windows  under  Python  3.3,  with  my  PYTHONPATH  set  to  C:\\\\code  and  a  C:\\n\\\\Python33\\\\mypath.pth path file that lists C:\\\\Users\\\\mark. The empty string at the front\\nmeans current directory, and my two settings are merged in; the rest are standard library\\ndirectories and files and the site-packages home for third-party extensions:\\n\\n>>> import sys\\n>>> sys.path\\n[\\'\\', \\'C:\\\\\\\\code\\', \\'C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\python33.zip\\', \\'C:\\\\\\\\Python33\\\\\\\\DLLs\\',\\n\\'C:\\\\\\\\Python33\\\\\\\\lib\\', \\'C:\\\\\\\\Python33\\', \\'C:\\\\\\\\Users\\\\\\\\mark\\',\\n\\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\site-packages\\']\\n\\nSecond, if you know what you’re doing, this list provides a way for scripts to tailor their\\nsearch  paths  manually.  As  you’ll  see  by  example  later  in  this  part  of  the  book,  by\\nmodifying the sys.path list, you can modify the search path for all future imports made\\nin a program’s run. Such changes last only for the duration of the script, however;\\nPYTHONPATH and .pth files offer more permanent ways to modify the path—the first per\\nuser, and the second per installation.\\nOn the other hand, some programs really do need to change sys.path. Scripts that run\\non web servers, for example, often run as the user “nobody” to limit machine access.\\nBecause such scripts cannot usually depend on “nobody” to have set PYTHONPATH in any\\nparticular way, they often set sys.path manually to include required source directories,\\nprior to running any import statements. A sys.path.append or sys.path.insert will\\noften suffice, though will endure for a single program run only.\\n\\nModule File Selection\\nKeep in mind that filename extensions (e.g., .py) are omitted from import statements\\nintentionally. Python chooses the first file it can find on the search path that matches\\nthe imported name. In fact, imports are the point of interface to a host of external\\ncomponents—source code, multiple flavors of byte code, compiled extensions, and\\nmore. Python automatically selects any type that matches a module’s name.\\n\\n682 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0cModule sources\\nFor example, an import statement of the form import b might today load or resolve to:\\n\\n• A source code file named b.py\\n• A byte code file named b.pyc\\n• An optimized byte code file named b.pyo (a less common format)\\n• A directory named b, for package imports (described in Chapter 24)\\n• A compiled extension module, coded in C, C++, or another language, and dy-\\nnamically linked when imported (e.g., b.so on Linux, or b.dll or b.pyd on Cygwin\\nand Windows)\\n\\n• A compiled built-in module coded in C and statically linked into Python\\n• A ZIP file component that is automatically extracted when imported\\n• An in-memory image, for frozen executables\\n• A Java class, in the Jython version of Python\\n• A .NET component, in the IronPython version of Python\\n\\nC extensions, Jython, and package imports all extend imports beyond simple files. To\\nimporters, though, differences in the loaded file type are completely irrelevant, both\\nwhen importing and when fetching module attributes. Saying import b gets whatever\\nmodule b is, according to your module search path, and b.attr fetches an item in the\\nmodule, be it a Python variable or a linked-in C function. Some standard modules we\\nwill use in this book are actually coded in C, not Python; because they look just like\\nPython-coded module files, their clients don’t have to care.\\n\\nSelection priorities\\nIf you have both a b.py and a b.so in different directories, Python will always load the\\none found in the first (leftmost) directory of your module search path during the left-\\nto-right search of sys.path. But what happens if it finds both a b.py and a b.so in the\\nsame directory? In this case, Python follows a standard picking order, though this order\\nis not guaranteed to stay the same over time or across implementations. In general, you\\nshould not depend on which type of file Python will choose within a given directory—\\nmake your module names distinct, or configure your module search path to make your\\nmodule selection preferences explicit.\\n\\nImport hooks and ZIP files\\nNormally, imports work as described in this section—they find and load files on your\\nmachine. However, it is possible to redefine much of what an import operation does\\nin Python, using what are known as import hooks. These hooks can be used to make\\nimports do various useful things, such as loading files from archives, performing de-\\ncryption, and so on.\\n\\nThe Module Search Path | 683\\n\\n\\x0cIn fact, Python itself makes use of these hooks to enable files to be directly imported\\nfrom  ZIP  archives:  archived  files  are  automatically  extracted  at  import  time  when\\na .zip file is selected from the module import search path. One of the standard library\\ndirectories in the earlier sys.path display, for example, is a .zip file today. For more\\ndetails,  see  the  Python  standard  library  manual’s  description  of  the  built-in\\n__import__ function, the customizable tool that import statements actually run.\\n\\nAlso see Python 3.3’s “What’s New?” document for updates on this\\nfront that we’ll mostly omit here for space. In short, in this version and\\nlater,  the  __import__  function \\nimplemented  by  impor\\ntlib.__import__,  in  part  to  unify  and  more  clearly  expose  its  imple-\\nmentation.\\n\\nis  now \\n\\nThe latter of these calls is also wrapped by importlib.import_module—\\na tool that, per Python’s current manuals, is generally preferred over\\n__import__ for direct calls to import by name string, a technique dis-\\ncussed  in  Chapter  25.  Both  calls  still  work  today,  though  the\\n__import__ function supports customizing imports by replacement in\\nthe built-in scope (see Chapter 17), and other techniques support similar\\nroles. See the Python library manuals for more details.\\n\\nOptimized byte code files\\nFinally, Python also supports the notion of .pyo optimized byte code files, created and\\nrun with the -O Python command-line flag, and automatically generated by some install\\ntools. Because these run only slightly faster than normal .pyc files (typically 5 percent\\nfaster),  however,  they  are  infrequently  used.  The  PyPy  system  (see  Chapter  2  and\\nChapter 21), for example, provides more substantial speedups. See Appendix A and\\nChapter 36 for more on .pyo files.\\n\\nThird-Party Software: distutils\\n\\nThis chapter’s description of module search path settings is targeted mainly at user-\\ndefined source code that you write on your own. Third-party extensions for Python\\ntypically use the distutils tools in the standard library to automatically install them-\\nselves, so no path configuration is required to use their code.\\nSystems that use distutils generally come with a setup.py script, which is run to install\\nthem; this script imports and uses distutils modules to place such systems in a direc-\\ntory that is automatically part of the module search path (usually in the Lib\\\\site-pack-\\nages subdirectory of the Python install tree, wherever that resides on the target ma-\\nchine).\\nFor more details on distributing and installing with distutils, see the Python standard\\nmanual set; its use is beyond the scope of this book (for instance, it also provides ways\\nto automatically compile C-coded extensions on the target machine). Also check out\\nthe third-party open source eggs system, which adds dependency checking for installed\\nPython software.\\n\\n684 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0cNote: as this fifth edition is being written, there is some talk of deprecating distutils\\nand replacing it with a newer distutils2 package in the Python standard library. The\\nstatus of this is unclear—it was anticipated in 3.3 but did not appear—so be sure to\\nsee Python’s “What’s New” documents for updates on this front that may emerge after\\nthis book is released.\\n\\nChapter Summary\\nIn this chapter, we covered the basics of modules, attributes, and imports and explored\\nthe operation of import statements. We learned that imports find the designated file on\\nthe module search path, compile it to byte code, and execute all of its statements to\\ngenerate its contents. We also learned how to configure the search path to be able to\\nimport from directories other than the home directory and the standard library direc-\\ntories, primarily with PYTHONPATH settings.\\nAs this chapter demonstrated, the import operation and modules are at the heart of\\nprogram architecture in Python. Larger programs are divided into multiple files, which\\nare linked together at runtime by imports. Imports in turn use the module search path\\nto locate files, and modules define attributes for external use.\\nOf course, the whole point of imports and modules is to provide a structure to your\\nprogram, which divides its logic into self-contained software components. Code in one\\nmodule is isolated from code in another; in fact, no file can ever see the names defined\\nin another, unless explicit import statements are run. Because of this, modules minimize\\nname collisions between different parts of your program.\\nYou’ll see what this all means in terms of actual statements and code in the next chapter.\\nBefore we move on, though, let’s run through the chapter quiz.\\n\\nTest Your Knowledge: Quiz\\n1. How does a module source code file become a module object?\\n2. Why might you have to set your PYTHONPATH environment variable?\\n3. Name the five major components of the module import search path.\\n4. Name four file types that Python might load in response to an import operation.\\n5. What is a namespace, and what does a module’s namespace contain?\\n\\nTest Your Knowledge: Answers\\n1. A module’s source code file automatically becomes a module object when that\\nmodule is imported. Technically, the module’s source code is run during the im-\\n\\nTest Your Knowledge: Answers\\n\\n| 685\\n\\n\\x0cport, one statement at a time, and all the names assigned in the process become\\nattributes of the module object.\\n\\n2. You only need to set PYTHONPATH to import from directories other than the one in\\nwhich you are working (i.e., the current directory when working interactively, or\\nthe directory containing your top-level file). In practice, this will be a common case\\nfor nontrivial programs.\\n\\n3. The five major components of the module import search path are the top-level\\nscript’s home directory (the directory containing it), all directories listed in the\\nPYTHONPATH environment variable, the standard library directories, all directories\\nlisted in .pth path files located in standard places, and the site-packages root di-\\nrectory for third-party extension installs. Of these, programmers can customize\\nPYTHONPATH and .pth files.\\n\\n4. Python might load a source code (.py) file, a byte code (.pyc or .pyo) file, a C ex-\\ntension module (e.g., a .so file on Linux or a .dll or .pyd file on Windows), or a\\ndirectory of the same name for package imports. Imports may also load more exotic\\nthings  such  as  ZIP  file  components,  Java  classes  under  the  Jython  version  of\\nPython, .NET components under IronPython, and statically linked C extensions\\nthat have no files present at all. In fact, with import hooks, imports can load arbi-\\ntrary items.\\n\\n5. A  namespace  is  a  self-contained  package  of  variables,  which  are  known  as  the\\nattributes of the namespace object. A module’s namespace contains all the names\\nassigned  by  code  at  the  top  level  of  the  module  file  (i.e.,  not  nested  in  def  or\\nclass statements). Technically, a module’s global scope morphs into the module\\nobject’s attributes namespace. A module’s namespace may also be altered by as-\\nsignments from other files that import it, though this is generally frowned upon\\n(see Chapter 17 for more on the downsides of cross-file changes).\\n\\n686 | Chapter 22:\\u2002Modules: The Big Picture\\n\\n\\x0cCHAPTER 23\\nModule Coding Basics\\n\\nNow that we’ve looked at the larger ideas behind modules, let’s turn to some examples\\nof modules in action. Although some of the early topics in this chapter will be review\\nfor linear readers who have already applied them in previous chapters’ examples, we’ll\\nfind that they quickly lead us to further details surrounding Python’s modules that we\\nhaven’t yet met, such as nesting, reloads, scopes, and more.\\nPython modules are easy to create; they’re just files of Python program code created\\nwith a text editor. You don’t need to write special syntax to tell Python you’re making\\na module; almost any text file will do. Because Python handles all the details of finding\\nand loading modules, modules are also easy to use; clients simply import a module, or\\nspecific names a module defines, and use the objects they reference.\\n\\nModule Creation\\nTo define a module, simply use your text editor to type some Python code into a text\\nfile,  and  save  it  with  a  “.py”  extension;  any  such  file  is  automatically  considered  a\\nPython  module.  All  the  names  assigned  at  the  top  level  of  the  module  become  its\\nattributes (names associated with the module object) and are exported for clients to use\\n—they morph from variable to module object attribute automatically.\\nFor instance, if you type the following def into a file called module1.py and import it,\\nyou create a module object with one attribute—the name printer, which happens to\\nbe a reference to a function object:\\n\\ndef printer(x):                   # Module attribute\\n    print(x)\\n\\nModule Filenames\\nBefore we go on, I should say a few more words about module filenames. You can call\\nmodules just about anything you like, but module filenames should end in a .py suffix\\nif you plan to import them. The .py is technically optional for top-level files that will\\n\\n687\\n\\n\\x0cbe run but not imported, but adding it in all cases makes your files’ types more obvious\\nand allows you to import any of your files in the future.\\nBecause  module  names  become  variable  names  inside  a  Python  program  (without\\nthe .py), they should also follow the normal variable name rules outlined in Chap-\\nter 11. For instance, you can create a module file named if.py, but you cannot import\\nit because if is a reserved word—when you try to run import if, you’ll get a syntax\\nerror.  In  fact,  both  the  names  of  module  files  and  the  names  of  directories  used  in\\npackage imports (discussed in the next chapter) must conform to the rules for variable\\nnames presented in Chapter 11; they may, for instance, contain only letters, digits, and\\nunderscores. Package directories also cannot contain platform-specific syntax such as\\nspaces in their names.\\nWhen a module is imported, Python maps the internal module name to an external\\nfilename by adding a directory path from the module search path to the front, and\\na .py or other extension at the end. For instance, a module named M ultimately maps\\nto some external file <directory>\\\\M.<extension> that contains the module’s code.\\n\\nOther Kinds of Modules\\nAs mentioned in the preceding chapter, it is also possible to create a Python module by\\nwriting code in an external language such as C, C++, and others (e.g., Java, in the\\nJython implementation of the language). Such modules are called extension modules,\\nand they are generally used to wrap up external libraries for use in Python scripts. When\\nimported by Python code, extension modules look and feel the same as modules coded\\nas Python source code files—they are accessed with import statements, and they provide\\nfunctions and objects as module attributes. Extension modules are beyond the scope\\nof this book; see Python’s standard manuals or advanced texts such as Programming\\nPython for more details.\\n\\nModule Usage\\nClients can use the simple module file we just wrote by running an  import or  from\\nstatement. Both statements find, compile, and run a module file’s code, if it hasn’t yet\\nbeen loaded. The chief difference is that import fetches the module as a whole, so you\\nmust qualify to fetch its names; in contrast, from fetches (or copies) specific names out\\nof the module.\\nLet’s see what this means in terms of code. All of the following examples wind up calling\\nthe printer function defined in the prior section’s module1.py module file, but in dif-\\nferent ways.\\n\\n688 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cThe import Statement\\nIn the first example, the name module1 serves two different purposes—it identifies an\\nexternal file to be loaded, and it becomes a variable in the script, which references the\\nmodule object after the file is loaded:\\n\\n>>> import module1                         # Get module as a whole (one or more)\\n>>> module1.printer(\\'Hello world!\\')        # Qualify to get names\\nHello world!\\n\\nThe import statement simply lists one or more names of modules to load, separated by\\ncommas. Because it gives a name that refers to the whole module object, we must go\\nthrough the module name to fetch its attributes (e.g., module1.printer).\\n\\nThe from Statement\\nBy contrast, because from copies specific names from one file over to another scope, it\\nallows us to use the copied names directly in the script without going through the\\nmodule (e.g., printer):\\n\\n>>> from module1 import printer            # Copy out a variable (one or more)\\n>>> printer(\\'Hello world!\\')                # No need to qualify name\\nHello world!\\n\\nThis form of from allows us to list one or more names to be copied out, separated by\\ncommas. Here, it has the same effect as the prior example, but because the imported\\nname is copied into the scope where the from statement appears, using that name in\\nthe script requires less typing—we can use it directly instead of naming the enclosing\\nmodule. In fact, we must; from doesn’t assign the name of the module itself.\\nAs you’ll see in more detail later, the from statement is really just a minor extension to\\nthe import statement—it imports the module file as usual (running the full three-step\\nprocedure of the preceding chapter), but adds an extra step that copies one or more\\nnames (not objects) out of the file. The entire file is loaded, but you’re given names for\\nmore direct access to its parts.\\n\\nThe from * Statement\\nFinally, the next example uses a special form of from: when we use a * instead of specific\\nnames, we get copies of all names assigned at the top level of the referenced module.\\nHere  again,  we  can  then  use  the  copied  name  printer  in  our  script  without  going\\nthrough the module name:\\n\\n>>> from module1 import *                   # Copy out _all_ variables\\n>>> printer(\\'Hello world!\\')\\nHello world!\\n\\nTechnically, both import and from statements invoke the same import operation; the\\nfrom * form simply adds an extra step that copies all the names in the module into the\\nimporting scope. It essentially collapses one module’s namespace into another; again,\\n\\nModule Usage | 689\\n\\n\\x0cthe net effect is less typing for us. Note that only * works in this context; you can’t use\\npattern matching to select a subset of names (though you could with more work and\\na loop through a module’s __dict__, discussed ahead).\\nAnd that’s it—modules really are simple to use. To give you a better understanding of\\nwhat really happens when you define and use modules, though, let’s move on to look\\nat some of their properties in more detail.\\n\\nIn Python 3.X, the from ...* statement form described here can be used\\nonly at the top level of a module file, not within a function. Python 2.X\\nallows it to be used within a function, but issues a warning anyhow. It’s\\nrare  to  see  this  statement  used  inside  a  function  in  practice;  when\\npresent, it makes it impossible for Python to detect variables statically,\\nbefore the function runs. Best practice in all Pythons recommends listing\\nall your imports at the top of a module file; it’s not required, but makes\\nthem easier to spot.\\n\\nImports Happen Only Once\\nOne of the most common questions people seem to ask when they start using modules\\nis, “Why won’t my imports keep working?” They often report that the first import\\nworks fine, but later imports during an interactive session (or program run) seem to\\nhave no effect. In fact, they’re not supposed to. This section explains why.\\nModules are loaded and run on the first import or from, and only the first. This is on\\npurpose—because importing is an expensive operation, by default Python does it just\\nonce  per  file,  per  process.  Later  import  operations  simply  fetch  the  already  loaded\\nmodule object.\\n\\nInitialization code\\nAs one consequence, because top-level code in a module file is usually executed only\\nonce, you can use it to initialize variables. Consider the file simple.py, for example:\\n\\nprint(\\'hello\\')\\nspam = 1                   # Initialize variable\\n\\nIn this example, the print and = statements run the first time the module is imported,\\nand the variable spam is initialized at import time:\\n\\n% python\\n>>> import simple          # First import: loads and runs file\\'s code\\nhello\\n>>> simple.spam            # Assignment makes an attribute\\n1\\n\\nSecond and later imports don’t rerun the module’s code; they just fetch the already\\ncreated module object from Python’s internal modules table. Thus, the variable spam\\nis not reinitialized:\\n\\n690 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0c>>> simple.spam = 2        # Change attribute in module\\n>>> import simple          # Just fetches already loaded module\\n>>> simple.spam            # Code wasn\\'t rerun: attribute unchanged\\n2\\n\\nOf course, sometimes you really want a module’s code to be rerun on a subsequent\\nimport. We’ll see how to do this with Python’s reload function later in this chapter.\\n\\nimport and from Are Assignments\\nJust like def, import and from are executable statements, not compile-time declarations.\\nThey may be nested in if tests, to select among options; appear in function defs, to be\\nloaded only on calls (subject to the preceding note); be used in try statements, to pro-\\nvide defaults; and so on. They are not resolved or run until Python reaches them while\\nexecuting your program. In other words, imported modules and names are not available\\nuntil their associated import or from statements run.\\n\\nChanging mutables in modules\\nAlso, like def, the import and from are implicit assignments:\\n\\n• import assigns an entire module object to a single name.\\n• from assigns one or more names to objects of the same names in another module.\\n\\nAll the things we’ve already discussed about assignment apply to module access, too.\\nFor instance, names copied with a from become references to shared objects; as with\\nfunction arguments, reassigning a copied name has no effect on the module from which\\nit was copied, but changing a shared mutable object through a copied name can also\\nchange it in the module from which it was imported. To illustrate, consider the fol-\\nlowing file, small.py:\\n\\nx = 1\\ny = [1, 2]\\n\\nWhen importing with from, we copy names to the importer’s scope that initially share\\nobjects referenced by the module’s names:\\n\\n% python\\n>>> from small import x, y         # Copy two names out\\n>>> x = 42                         # Changes local x only\\n>>> y[0] = 42                      # Changes shared mutable in place\\n\\nHere, x is not a shared mutable object, but y is. The names y in the importer and the\\nimportee both reference the same list object, so changing it from one place changes it\\nin the other:\\n\\n>>> import small                   # Get module name (from doesn\\'t)\\n>>> small.x                        # Small\\'s x is not my x\\n1\\n>>> small.y                        # But we share a changed mutable\\n[42, 2]\\n\\nModule Usage | 691\\n\\n\\x0cFor  more  background  on  this,  see  Chapter  6.  And  for  a  graphical  picture  of  what\\nfrom assignments do with references, flip back to Figure 18-1 (function argument pass-\\ning), and mentally replace “caller” and “function” with “imported” and “importer.”\\nThe  effect  is  the  same,  except  that  here  we’re  dealing  with  names  in  modules,  not\\nfunctions. Assignment works the same everywhere in Python.\\n\\nCross-file name changes\\nRecall from the preceding example that the assignment to x in the interactive session\\nchanged the name x in that scope only, not the x in the file—there is no link from a\\nname copied with from back to the file it came from. To really change a global name in\\nanother file, you must use import:\\n\\n% python\\n>>> from small import x, y         # Copy two names out\\n>>> x = 42                         # Changes my x only\\n\\n>>> import small                   # Get module name\\n>>> small.x = 42                   # Changes x in other module\\n\\nThis phenomenon was introduced in Chapter 17. Because changing variables in other\\nmodules like this is a common source of confusion (and often a bad design choice),\\nwe’ll revisit this technique again later in this part of the book. Note that the change to\\ny[0] in the prior session is different; it changes an object, not a name, and the name in\\nboth modules references the same, changed object.\\n\\nimport and from Equivalence\\nNotice  in  the  prior  example  that  we  have  to  execute  an  import  statement  after  the\\nfrom to access the small module name at all. from only copies names from one module\\nto another; it does not assign the module name itself. At least conceptually, a  from\\nstatement like this one:\\n\\nfrom module import name1, name2     # Copy these two names out (only)\\n\\nis equivalent to this statement sequence:\\n\\nimport module                       # Fetch the module object\\nname1 = module.name1                # Copy names out by assignment\\nname2 = module.name2\\ndel module                          # Get rid of the module name\\n\\nLike all assignments, the from statement creates new variables in the importer, which\\ninitially refer to objects of the same names in the imported file. Only the names are\\ncopied out, though, not the objects they reference, and not the name of the module\\nitself. When we use the  from * form of this statement (from module import *), the\\nequivalence is the same, but all the top-level names in the module are copied over to\\nthe importing scope this way.\\n\\n692 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cNotice that the first step of the from runs a normal import operation, with all the se-\\nmantics outlined in the preceding chapter. Because of this, the from always imports the\\nentire module into memory if it has not yet been imported, regardless of how many\\nnames it copies out of the file. There is no way to load just part of a module file (e.g.,\\njust one function), but because modules are byte code in Python instead of machine\\ncode, the performance implications are generally negligible.\\n\\nPotential Pitfalls of the from Statement\\nBecause the from statement makes the location of a variable more implicit and obscure\\n(name is less meaningful to the reader than module.name), some Python users recommend\\nusing import instead of from most of the time. I’m not sure this advice is warranted,\\nthough; from is commonly and widely used, without too many dire consequences. In\\npractice, in realistic programs, it’s often convenient not to have to type a module’s name\\nevery time you wish to use one of its tools. This is especially true for large modules that\\nprovide many attributes—the standard library’s tkinter GUI module, for example.\\nIt is true that the from statement has the potential to corrupt namespaces, at least in\\nprinciple—if you use it to import variables that happen to have the same names as\\nexisting variables in your scope, your variables will be silently overwritten. This prob-\\nlem  doesn’t  occur  with  the  simple  import  statement  because  you  must  always  go\\nthrough a module’s name to get to its contents (module.attr will not clash with a vari-\\nable named attr in your scope). As long as you understand and expect that this can\\nhappen when using from, though, this isn’t a major concern in practice, especially if\\nyou list the imported names explicitly (e.g., from module import x, y, z).\\nOn the other hand, the from statement has more serious issues when used in conjunc-\\ntion with the reload call, as imported names might reference prior versions of objects.\\nMoreover, the from module import * form really can corrupt namespaces and make\\nnames difficult to understand, especially when applied to more than one file—in this\\ncase, there is no way to tell which module a name came from, short of searching the\\nexternal source files. In effect, the from * form collapses one namespace into another,\\nand so defeats the namespace partitioning feature of modules. We will explore these\\nissues in more detail in the section “Module Gotchas” on page 770 (see Chapter 25).\\nProbably the best real-world advice here is to generally prefer import to from for simple\\nmodules, to explicitly list the variables you want in most from statements, and to limit\\nthe from * form to just one import per file. That way, any undefined names can be\\nassumed to live in the module referenced with the from *. Some care is required when\\nusing the from statement, but armed with a little knowledge, most programmers find\\nit to be a convenient way to access modules.\\n\\nModule Usage | 693\\n\\n\\x0cWhen import is required\\nThe only time you really must use import instead of from is when you must use the same\\nname defined in two different modules. For example, if two files define the same name\\ndifferently:\\n# M.py\\ndef func():\\n    ...do something...\\n\\n# N.py\\ndef func():\\n    ...do something else...\\n\\nand you must use both versions of the name in your program, the from statement will\\nfail—you can have only one assignment to the name in your scope:\\n\\n# O.py\\nfrom M import func\\nfrom N import func             # This overwrites the one we fetched from M\\nfunc()                         # Calls N.func only!\\n\\nAn import will work here, though, because including the name of the enclosing module\\nmakes the two names unique:\\n\\n# O.py\\nimport M, N                    # Get the whole modules, not their names\\nM.func()                       # We can call both names now\\nN.func()                       # The module names make them unique\\n\\nThis case is unusual enough that you’re unlikely to encounter it very often in practice.\\nIf you do, though, import allows you to avoid the name collision. Another way out of\\nthis dilemma is using the as extension, which we’ll cover in Chapter 25 but is simple\\nenough to introduce here:\\n\\n# O.py\\nfrom M import func as mfunc    # Rename uniquely with \"as\"\\nfrom N import func as nfunc\\nmfunc(); nfunc()               # Calls one or the other\\n\\nThe as extension works in both import and from as a simple renaming tool (it can also\\nbe used to give a shorter synonym for a long module name in import); more on this \\nform in Chapter 25.\\n\\nModule Namespaces\\nModules are probably best understood as simply packages of names—i.e., places to\\ndefine names you want to make visible to the rest of a system. Technically, modules\\nusually correspond to files, and Python creates a module object to contain all the names\\nassigned in a module file. But in simple terms, modules are just namespaces (places\\nwhere  names  are  created),  and  the  names  that  live  in  a  module  are  called  its  at-\\ntributes. This section expands on the details behind this model.\\n\\n694 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cFiles Generate Namespaces\\nI’ve mentioned that files morph into namespaces, but how does this actually happen?\\nThe short answer is that every name that is assigned a value at the top level of a module\\nfile (i.e., not nested in a function or class body) becomes an attribute of that module.\\nFor instance, given an assignment statement such as X = 1 at the top level of a module\\nfile M.py, the name X becomes an attribute of M, which we can refer to from outside the\\nmodule as M.X. The name X also becomes a global variable to other code inside M.py,\\nbut we need to consider the notion of module loading and scopes a bit more formally\\nto understand why:\\n\\n• Module statements run on the first import. The first time a module is imported\\nanywhere in a system, Python creates an empty module object and executes the\\nstatements in the module file one after another, from the top of the file to the\\nbottom.\\n\\n• Top-level assignments create module attributes. During an import, statements\\nat the top level of the file not nested in a def or class that assign names (e.g., =,\\ndef) create attributes of the module object; assigned names are stored in the mod-\\nule’s namespace.\\n\\n• Module  namespaces  can  be  accessed  via  the  attribute__dict__  or  dir(M).\\nModule  namespaces  created  by  imports  are  dictionaries;  they  may  be  accessed\\nthrough the built-in __dict__ attribute associated with module objects and may be\\ninspected with the dir function. The dir function is roughly equivalent to the sorted\\nkeys list of an object’s __dict__ attribute, but it includes inherited names for classes,\\nmay not be complete, and is prone to changing from release to release.\\n\\n• Modules are a single scope (local is global). As we saw in Chapter 17, names\\nat the top level of a module follow the same reference/assignment rules as names\\nin a function, but the local and global scopes are the same—or, more formally,\\nthey follow the LEGB scope rule we met in Chapter 17, but without the L and E\\nlookup layers.\\nCrucially, though, the module’s global scope becomes an attribute dictionary of a\\nmodule object after the module has been loaded. Unlike function scopes, where\\nthe local namespace exists only while the function runs, a module file’s scope be-\\ncomes a module object’s attribute namespace and lives on after the import, pro-\\nviding a source of tools to importers.\\n\\nHere’s a demonstration of these ideas. Suppose we create the following module file in\\na text editor and call it module2.py:\\n\\nprint(\\'starting to load...\\')\\nimport sys\\nname = 42\\n\\ndef func(): pass\\n\\nModule Namespaces\\n\\n| 695\\n\\n\\x0cclass klass: pass\\n\\nprint(\\'done loading.\\')\\n\\nThe first time this module is imported (or run as a program), Python executes its state-\\nments from top to bottom. Some statements create names in the module’s namespace\\nas a side effect, but others do actual work while the import is going on. For instance,\\nthe two print statements in this file execute at import time:\\n\\n>>> import module2\\nstarting to load...\\ndone loading.\\n\\nOnce the module is loaded, its scope becomes an attribute namespace in the module\\nobject we get back from import. We can then access attributes in this namespace by\\nqualifying them with the name of the enclosing module:\\n\\n>>> module2.sys\\n<module \\'sys\\' (built-in)>\\n\\n>>> module2.name\\n42\\n\\n>>> module2.func\\n<function func at 0x000000000222E7B8>\\n\\n>>> module2.klass\\n<class \\'module2.klass\\'>\\n\\nHere, sys, name, func, and klass were all assigned while the module’s statements were\\nbeing run, so they are attributes after the import. We’ll talk about classes in Part VI,\\nbut notice the sys attribute—import statements really assign module objects to names,\\nand any type of assignment to a name at the top level of a file generates a module\\nattribute.\\n\\nNamespace Dictionaries: __dict__\\nIn fact, internally, module namespaces are stored as dictionary objects. These are just\\nnormal dictionaries with all the usual methods. When needed—for instance, to write\\ntools that list module content generically as we will in Chapter 25—we can access a\\nmodule’s namespace dictionary through the module’s __dict__ attribute. Continuing\\nthe prior section’s example (remember to wrap this in a list call in Python 3.X—it’s a\\nview object there, and contents may vary outside 3.3 used here):\\n\\n>>> list(module2.__dict__.keys())\\n[\\'__loader__\\', \\'func\\', \\'klass\\', \\'__builtins__\\', \\'__doc__\\', \\'__file__\\', \\'__name__\\',\\n\\'name\\', \\'__package__\\', \\'sys\\', \\'__initializing__\\', \\'__cached__\\']\\n\\nThe names we assigned in the module file become dictionary keys internally, so some\\nof the names here reflect top-level assignments in our file. However, Python also adds\\nsome names in the module’s namespace for us; for instance, __file__ gives the name\\n\\n696 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cof the file the module was loaded from, and __name__ gives its name as known to im-\\nporters (without the .py extension and directory path). To see just the names your code\\nassigns, filter out the double-underscore names as we’ve done before, in Chapter 15’s\\ndir coverage and Chapter 17’s built-in scope coverage:\\n\\n>>> list(name for name in module2.__dict__.keys() if not name.startswith(\\'__\\'))\\n[\\'func\\', \\'klass\\', \\'name\\', \\'sys\\']\\n>>> list(name for name in module2.__dict__ if not name.startswith(\\'__\\'))\\n[\\'func\\', \\'sys\\', \\'name\\', \\'klass\\']\\n\\nThis time we’re filtering with a generator instead of a list comprehension, and can omit\\nthe .keys() because dictionaries generate their keys automatically though implicitly;\\nthe effect is the same. We’ll see similar __dict__ dictionaries on class-related objects in\\nPart VI too. In both cases, attribute fetch is similar to dictionary indexing, though only\\nthe former kicks off inheritance in classes:\\n\\n>>> module2.name, module2.__dict__[\\'name\\']\\n(42, 42)\\n\\nAttribute Name Qualification\\nSpeaking of attribute fetch, now that you’re becoming more familiar with modules, we\\nshould firm up the notion of name qualification more formally too. In Python, you can\\naccess  the  attributes  of  any  object  that  has  attributes  using  the  qualification  (a.k.a.\\nattribute fetch) syntax object.attribute.\\nQualification is really an expression that returns the value assigned to an attribute name\\nassociated with an object. For example, the expression module2.sys in the previous\\nexample fetches the value assigned to sys in module2. Similarly, if we have a built-in list\\nobject L, L.append returns the append method object associated with that list.\\nIt’s important to keep in mind that attribute qualification has nothing to do with the\\nscope  rules  we  studied  in  Chapter  17;  it’s  an  independent  concept.  When  you  use\\nqualification to access names, you give Python an explicit object from which to fetch\\nthe specified names. The LEGB scope rule applies only to bare, unqualified names—it\\nmay be used for the leftmost name in a name path, but later names after dots search\\nspecific objects instead. Here are the rules:\\n\\nSimple variables\\n\\nX means search for the name X in the current scopes (following the LEGB rule of\\nChapter 17).\\n\\nQualification\\n\\nX.Y means find X in the current scopes, then search for the attribute Y in the object\\nX (not in scopes).\\n\\nQualification paths\\n\\nX.Y.Z means look up the name Y in the object X, then look up Z in the object X.Y.\\n\\nModule Namespaces\\n\\n| 697\\n\\n\\x0cGenerality\\n\\nQualification works on all objects with attributes: modules, classes, C extension\\ntypes, etc.\\n\\nIn Part VI, we’ll see that attribute qualification means a bit more for classes—it’s also\\nthe place where something called inheritance happens—but in general, the rules out-\\nlined here apply to all names in Python.\\n\\nImports Versus Scopes\\nAs we’ve learned, it is never possible to access names defined in another module file\\nwithout first importing that file. That is, you never automatically get to see names in\\nanother file, regardless of the structure of imports or function calls in your program. A\\nvariable’s meaning is always determined by the locations of assignments in your source\\ncode, and attributes are always requested of an object explicitly.\\nFor example, consider the following two simple modules. The first, moda.py, defines\\na variable X global to code in its file only, along with a function that changes the global\\nX in this file:\\n\\nX = 88                        # My X: global to this file only\\ndef f():\\n    global X                  # Change this file\\'s X\\n    X = 99                    # Cannot see names in other modules\\n\\nThe second module, modb.py, defines its own global variable X and imports and calls\\nthe function in the first module:\\n\\nX = 11                        # My X: global to this file only\\n\\nimport moda                   # Gain access to names in moda\\nmoda.f()                      # Sets moda.X, not this file\\'s X\\nprint(X, moda.X)\\n\\nWhen  run,  moda.f  changes  the  X  in  moda,  not  the  X  in  modb.  The  global  scope  for\\nmoda.f is always the file enclosing it, regardless of which module it is ultimately called\\nfrom:\\n\\n% python modb.py\\n11 99\\n\\nIn other words, import operations never give upward visibility to code in imported files\\n—an imported file cannot see names in the importing file. More formally:\\n\\n• Functions can never see names in other functions, unless they are physically en-\\n\\nclosing.\\n\\n• Module code can never see names in other modules, unless they are explicitly im-\\n\\nported.\\n\\n698 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cSuch behavior is part of the lexical scoping notion—in Python, the scopes surrounding\\na piece of code are completely determined by the code’s physical position in your file.\\nScopes are never influenced by function calls or module imports.1\\n\\nNamespace Nesting\\nIn some sense, although imports do not nest namespaces upward, they do nest down-\\nward. That is, although an imported module never has direct access to names in a file\\nthat imports it, using attribute qualification paths it is possible to descend into arbi-\\ntrarily nested modules and access their attributes. For example, consider the next three\\nfiles. mod3.py defines a single global name and attribute by assignment:\\n\\nX = 3\\n\\nmod2.py in turn defines its own X, then imports mod3 and uses qualification to access\\nthe imported module’s attribute:\\n\\nX = 2\\nimport mod3\\n\\nprint(X, end=\\' \\')             # My global X\\nprint(mod3.X)                 # mod3\\'s X\\n\\nmod1.py also defines its own X, then imports mod2, and fetches attributes in both the\\nfirst and second files:\\n\\nX = 1\\nimport mod2\\n\\nprint(X, end=\\' \\')             # My global X\\nprint(mod2.X, end=\\' \\')        # mod2\\'s X\\nprint(mod2.mod3.X)            # Nested mod3\\'s X\\n\\nReally, when mod1 imports mod2 here, it sets up a two-level namespace nesting. By using\\nthe path of names mod2.mod3.X, it can descend into mod3, which is nested in the imported\\nmod2. The net effect is that mod1 can see the Xs in all three files, and hence has access to\\nall three global scopes:\\n\\n% python mod1.py\\n2 3\\n1 2 3\\n\\nThe reverse, however, is not true: mod3 cannot see names in mod2, and mod2 cannot see\\nnames in  mod1. This example may be easier to grasp if you don’t think in terms of\\nnamespaces and scopes, but instead focus on the objects involved. Within mod1, mod2\\nis just a name that refers to an object with attributes, some of which may refer to other\\n\\n1. Some languages act differently and provide for dynamic scoping, where scopes really may depend on\\nruntime calls. This tends to make code trickier, though, because the meaning of a variable can differ over\\ntime. In Python, scopes more simply correspond to the text of your program.\\n\\nModule Namespaces\\n\\n| 699\\n\\n\\x0cobjects with attributes (import is an assignment). For paths like mod2.mod3.X, Python\\nsimply evaluates from left to right, fetching attributes from objects along the way.\\nNote that mod1 can say import mod2, and then mod2.mod3.X, but it cannot say import\\nmod2.mod3—this  syntax  invokes  something  called  package  (directory)  imports,  de-\\nscribed in the next chapter. Package imports also create module namespace nesting,\\nbut their import statements are taken to reflect directory trees, not simple file import \\nchains.\\n\\nReloading Modules\\nAs we’ve seen, a module’s code is run only once per process by default. To force a\\nmodule’s code to be reloaded and rerun, you need to ask Python to do so explicitly by\\ncalling the reload built-in function. In this section, we’ll explore how to use reloads to\\nmake your systems more dynamic. In a nutshell:\\n\\n• Imports (via both import and from statements) load and run a module’s code only\\n\\nthe first time the module is imported in a process.\\n\\n• Later imports use the already loaded module object without reloading or rerunning\\n\\nthe file’s code.\\n\\n• The reload function forces an already loaded module’s code to be reloaded and\\nrerun. Assignments in the file’s new code change the existing module object in\\nplace.\\n\\nWhy care about reloading modules? In short, dynamic customization: the reload func-\\ntion allows parts of a program to be changed without stopping the whole program.\\nWith reload, the effects of changes in components can be observed immediately. Re-\\nloading doesn’t help in every situation, but where it does, it makes for a much shorter\\ndevelopment cycle. For instance, imagine a database program that must connect to a\\nserver on startup; because program changes or customizations can be tested immedi-\\nately  after  reloads,  you  need  to  connect  only  once  while  debugging.  Long-running\\nservers can update themselves this way, too.\\nBecause Python is interpreted (more or less), it already gets rid of the compile/link steps\\nyou need to go through to get a C program to run: modules are loaded dynamically\\nwhen imported by a running program. Reloading offers a further performance advan-\\ntage by allowing you to also change parts of running programs without stopping.\\nThough beyond this book’s scope, note that reload currently only works on modules\\nwritten in Python; compiled extension modules coded in a language such as C can be\\ndynamically loaded at runtime, too, but they can’t be reloaded (though most users\\nprobably prefer to code customizations in Python anyhow!).\\n\\n700 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cVersion skew note: In Python 2.X, reload is available as a built-in func-\\ntion. In Python 3.X, it has been moved to the imp standard library mod-\\nule—it’s known as imp.reload in 3.X. This simply means that an extra\\nimport or from statement is required to load this tool in 3.X only. Readers\\nusing 2.X can ignore these imports in this book’s examples, or use them\\nanyhow—2.X also has a reload in its imp module to ease migration to\\n3.X. Reloading works the same regardless of its packaging.\\n\\nreload Basics\\nUnlike import and from:\\n\\n• reload is a function in Python, not a statement.\\n• reload is passed an existing module object, not a new name.\\n• reload lives in a module in Python 3.X and must be imported itself.\\n\\nBecause reload expects an object, a module must have been previously imported suc-\\ncessfully before you can reload it (if the import was unsuccessful due to a syntax or\\nother error, you may need to repeat it before you can reload the module). Furthermore,\\nthe syntax of import statements and reload calls differs: as a function reloads require\\nparentheses, but import statements do not. Abstractly, reloading looks like this:\\n\\nimport module                     # Initial import\\n...use module.attributes...\\n...                               # Now, go change the module file\\n...\\nfrom imp import reload            # Get reload itself (in 3.X)\\nreload(module)                    # Get updated exports\\n...use module.attributes...\\n\\nThe typical usage pattern is that you import a module, then change its source code in\\na text editor, and then reload it. This can occur when working interactively, but also\\nin larger programs that reload periodically.\\nWhen you call reload, Python rereads the module file’s source code and reruns its top-\\nlevel statements. Perhaps the most important thing to know about reload is that it\\nchanges a module object in place; it does not delete and re-create the module object.\\nBecause of that, every reference to an entire module object anywhere in your program\\nis automatically affected by a reload. Here are the details:\\n\\n• reload  runs  a  module  file’s  new  code  in  the  module’s  current  namespace.\\nRerunning a module file’s code overwrites its existing namespace, rather than de-\\nleting and re-creating it.\\n\\n• Top-level assignments in the file replace names with new values. For instance,\\nrerunning a def statement replaces the prior version of the function in the module’s\\nnamespace by reassigning the function name.\\n\\nReloading Modules\\n\\n| 701\\n\\n\\x0c• Reloads impact all clients that use import to fetch modules. Because clients\\nthat use import qualify to fetch attributes, they’ll find new values in the module\\nobject after a reload.\\n\\n• Reloads impact future from clients only. Clients that used from to fetch attributes\\nin the past won’t be affected by a reload; they’ll still have references to the old\\nobjects fetched before the reload.\\n\\n• Reloads apply to a single module only. You must run them on each module you\\n\\nwish to update, unless you use code or tools that apply reloads transitively.\\n\\nreload Example\\nTo demonstrate, here’s a more concrete example of reload in action. In the following,\\nwe’ll change and reload a module file without stopping the interactive Python session.\\nReloads are used in many other scenarios, too (see the sidebar “Why You Will Care:\\nModule  Reloads”  on  page  703),  but  we’ll  keep  things  simple  for  illustration  here.\\nFirst, in the text editor of your choice, write a module file named changer.py with the\\nfollowing contents:\\n\\nmessage = \"First version\"\\ndef printer():\\n    print(message)\\n\\nThis module creates and exports two names—one bound to a string, and another to a\\nfunction. Now, start the Python interpreter, import the module, and call the function\\nit exports. The function will print the value of the global message variable:\\n\\n% python\\n>>> import changer\\n>>> changer.printer()\\nFirst version\\n\\nKeeping the interpreter active, now edit the module file in another window:\\n\\n...modify changer.py without stopping Python...\\n% notepad changer.py\\n\\nChange the global message variable, as well as the printer function body:\\n\\nmessage = \"After editing\"\\ndef printer():\\n    print(\\'reloaded:\\', message)\\n\\nThen, return to the Python window and reload the module to fetch the new code. Notice\\nin the following interaction that importing the module again has no effect; we get the\\noriginal message, even though the file’s been changed. We have to call reload in order\\nto get the new version:\\n\\n...back to the Python interpreter...\\n>>> import changer\\n>>> changer.printer()                 # No effect: uses loaded module\\nFirst version\\n>>> from imp import reload\\n\\n702 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0c>>> reload(changer)                   # Forces new code to load/run\\n<module \\'changer\\' from \\'.\\\\\\\\changer.py\\'>\\n>>> changer.printer()                 # Runs the new version now\\nreloaded: After editing\\n\\nNotice that reload actually returns the module object for us—its result is usually ig-\\nnored, but because expression results are printed at the interactive prompt, Python\\nshows a default <module \\'name\\'...> representation.\\nTwo  final  notes  here:  first,  if  you  use  reload,  you’ll  probably  want  to  pair  it  with\\nimport instead of from, as the latter isn’t updated by reload operations—leaving your\\nnames in a state that’s strange enough to warrant postponing further elaboration until\\nthis part’s “gotchas” at the end of Chapter 25. Second, reload by itself updates only a\\nsingle module, but it’s straightforward to code a function that applies it transitively to\\nrelated modules—an extension we’ll save for a case study near the end of Chapter 25.\\n\\nWhy You Will Care: Module Reloads\\n\\nBesides allowing you to reload (and hence rerun) modules at the interactive prompt,\\nmodule reloads are also useful in larger systems, especially when the cost of restarting\\nthe entire application is prohibitive. For instance, game servers and systems that must\\nconnect to servers over a network on startup are prime candidates for dynamic reloads.\\n\\nThey’re also useful in GUI work (a widget’s callback action can be changed while the\\nGUI remains active), and when Python is used as an embedded language in a C or C+\\n+ program (the enclosing program can request a reload of the Python code it runs,\\nwithout having to stop). See Programming Python for more on reloading GUI callbacks\\nand embedded Python code.\\n\\nMore generally, reloads allow programs to provide highly dynamic interfaces. For in-\\nstance, Python is often used as a customization language for larger systems—users can\\ncustomize products by coding bits of Python code onsite, without having to recompile\\nthe entire product (or even having its source code at all). In such worlds, the Python\\ncode already adds a dynamic flavor by itself.\\n\\nTo be even more dynamic, though, such systems can automatically reload the Python\\ncustomization code periodically at runtime. That way, users’ changes are picked up\\nwhile the system is running; there is no need to stop and restart each time the Python\\ncode is modified. Not all systems require such a dynamic approach, but for those that\\ndo, module reloads provide an easy-to-use dynamic customization tool.\\n\\nChapter Summary\\nThis chapter delved into the essentials of module coding tools—the import and from\\nstatements, and the reload call. We learned how the from statement simply adds an\\nextra step that copies names out of a file after it has been imported, and how reload\\nforces a file to be imported again without stopping and restarting Python. We also\\nsurveyed namespace concepts, saw what happens when imports are nested, explored\\n\\nChapter Summary | 703\\n\\n\\x0cthe way files become module namespaces, and learned about some potential pitfalls of\\nthe from statement.\\nAlthough we’ve already seen enough to handle module files in our programs, the next\\nchapter extends our coverage of the import model by presenting package imports—a\\nway for our import statements to specify part of the directory path leading to the desired\\nmodule. As we’ll see, package imports give us a hierarchy that is useful in larger systems\\nand allow us to break conflicts between same-named modules. Before we move on,\\nthough, here’s a quick quiz on the concepts presented here.\\n\\nTest Your Knowledge: Quiz\\n1. How do you make a module?\\n2. How is the from statement related to the import statement?\\n3. How is the reload function related to imports?\\n4. When must you use import instead of from?\\n5. Name three potential pitfalls of the from statement.\\n6. What...is the airspeed velocity of an unladen swallow?\\n\\nTest Your Knowledge: Answers\\n1. To create a module, you simply write a text file containing Python statements; every\\nsource code file is automatically a module, and there is no syntax for declaring one.\\nImport operations load module files into module objects in memory. You can also\\nmake a module by writing code in an external language like C or Java, but such\\nextension modules are beyond the scope of this book.\\n\\n2. The from statement imports an entire module, like the import statement, but as an\\nextra step it also copies one or more variables from the imported module into the\\nscope where the from appears. This enables you to use the imported names directly\\n(name) instead of having to go through the module (module.name).\\n\\n3. By default, a module is imported only once per process. The reload function forces\\na module to be imported again. It is mostly used to pick up new versions of a\\nmodule’s source code during development, and in dynamic customization scenar-\\nios.\\n\\n4. You must use import instead of from only when you need to access the same name\\nin two different modules; because you’ll have to specify the names of the enclosing\\nmodules, the two names will be unique. The as extension can render from usable\\nin this context as well.\\n\\n5. The  from statement can obscure the meaning of a variable (which module it is\\ndefined in), can have problems with the reload call (names may reference prior\\nversions of objects), and can corrupt namespaces (it might silently overwrite names\\n\\n704 | Chapter 23:\\u2002Module Coding Basics\\n\\n\\x0cyou are using in your scope). The from * form is worse in most regards—it can\\nseriously corrupt namespaces and obscure the meaning of variables, so it is prob-\\nably best used sparingly.\\n\\n6. What do you mean? An African or European swallow?\\n\\nTest Your Knowledge: Answers\\n\\n| 705\\n\\n\\x0c\\x0cCHAPTER 24\\nModule Packages\\n\\nSo far, when we’ve imported modules, we’ve been loading files. This represents typical\\nmodule usage, and it’s probably the technique you’ll use for most imports you’ll code\\nearly on in your Python career. However, the module import story is a bit richer than\\nI have thus far implied.\\nIn addition to a module name, an import can name a directory path. A directory of\\nPython code is said to be a package, so such imports are known as package imports. In\\neffect, a package import turns a directory on your computer into another Python name-\\nspace, with attributes corresponding to the subdirectories and module files that the\\ndirectory contains.\\nThis is a somewhat advanced feature, but the hierarchy it provides turns out to be handy\\nfor organizing the files in a large system and tends to simplify module search path\\nsettings. As we’ll see, package imports are also sometimes required to resolve import\\nambiguities when multiple program files of the same name are installed on a single\\nmachine.\\nBecause it is relevant to code in packages only, we’ll also introduce Python’s recent\\nrelative imports model and syntax here. As we’ll see, this model modifies search paths\\nin 3.X, and extends the from statement for imports within packages in both 2.X and\\n3.X. This model can make such intrapackage imports more explicit and succinct, but\\ncomes with some tradeoffs that can impact your programs.\\nFinally, for readers using Python 3.3 and later, its new namespace package model—\\nwhich allows packages to span multiple directories and requires no initialization file—\\nis also introduced here. This new-style package model is optional and can be used in\\nconcert with the original (now known as “regular”) package model, but it upends some\\nof the original model’s basic ideas and rules. Because of that, we’ll explore regular\\npackages here first for all readers, and present namespace packages last as an optional\\ntopic.\\n\\n707\\n\\n\\x0cPackage Import Basics\\nAt a base level, package imports are straightforward—in the place where you have been\\nnaming a simple file in your import statements, you can instead list a path of names\\nseparated by periods:\\n\\nimport dir1.dir2.mod\\n\\nThe same goes for from statements:\\n\\nfrom dir1.dir2.mod import x\\n\\nThe “dotted” path in these statements is assumed to correspond to a path through the\\ndirectory hierarchy on your computer, leading to the file mod.py (or similar; the ex-\\ntension may vary). That is, the preceding statements indicate that on your machine\\nthere is a directory dir1, which has a subdirectory dir2, which contains a module file\\nmod.py (or similar).\\nFurthermore, these imports imply that dir1 resides within some container directory\\ndir0, which is a component of the normal Python module search path. In other words,\\nthese two import statements imply a directory structure that looks something like this\\n(shown with Windows backslash separators):\\n\\ndir0\\\\dir1\\\\dir2\\\\mod.py               # Or mod.pyc, mod.so, etc.\\n\\nThe container directory dir0 needs to be added to your module search path unless it’s\\nthe home directory of the top-level file, exactly as if dir1 were a simple module file.\\nMore formally, the leftmost component in a package import path is still relative to a\\ndirectory  included  in  the  sys.path  module  search  path  list  we  explored  in  Chap-\\nter 22. From there down, though, the import statements in your script explicitly give\\nthe directory paths leading to modules in packages.\\n\\nPackages and Search Path Settings\\nIf you use this feature, keep in mind that the directory paths in your import statements\\ncan be only variables separated by periods. You cannot use any platform-specific path\\nsyntax in your import statements, such as C:\\\\dir1, My Documents.dir2, or ../dir1—\\nthese do not work syntactically. Instead, use any such platform-specific syntax in your\\nmodule search path settings to name the container directories.\\nFor instance, in the prior example, dir0—the directory name you add to your module\\nsearch path—can be an arbitrarily long and platform-specific directory path leading up\\nto dir1. You cannot use an invalid statement like this:\\n\\nimport C:\\\\mycode\\\\dir1\\\\dir2\\\\mod      # Error: illegal syntax\\n\\nBut you can add C:\\\\mycode to your PYTHONPATH variable or a .pth file, and say this in\\nyour script:\\n\\nimport dir1.dir2.mod\\n\\n708 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cIn effect, entries on the module search path provide platform-specific directory path\\nprefixes, which lead to the leftmost names in import and from statements. These import\\nstatements themselves provide the remainder of the directory path in a platform-neutral\\nfashion.1\\nAs for simple file imports, you don’t need to add the container directory dir0 to your\\nmodule search path if it’s already there—per Chapter 22, it will be if it’s the home\\ndirectory of the top-level file, the directory you’re working in interactively, a standard\\nlibrary  directory,  or  the  site-packages  third-party  install  root.  One  way  or  another,\\nthough, your module search path must include all the directories containing leftmost\\ncomponents in your code’s package import statements.\\n\\nPackage __init__.py Files\\nIf you choose to use package imports, there is one more constraint you must follow: at\\nleast until Python 3.3, each directory named within the path of a package import state-\\nment must contain a file named __init__.py, or your package imports will fail. That is,\\nin  the  example  we’ve  been  using,  both  dir1  and  dir2  must  contain  a  file  called\\n__init__.py; the container directory dir0 does not require such a file because it’s not\\nlisted in the import statement itself.\\nMore formally, for a directory structure such as this:\\n\\ndir0\\\\dir1\\\\dir2\\\\mod.py\\n\\nand an import statement of the form:\\n\\nimport dir1.dir2.mod\\n\\nthe following rules apply:\\n\\n• dir1 and dir2 both must contain an __init__.py file.\\n• dir0, the container, does not require an  __init__.py file; this file will simply be\\n\\nignored if present.\\n\\n• dir0, not dir0\\\\dir1, must be listed on the module search path sys.path.\\n\\nTo satisfy the first two of these rules, package creators must create files of the sort we’ll\\nexplore here. To satisfy the latter of these, dir0 must be an automatic path component\\n(the home, libraries, or site-packages directories), or be given in PYTHONPATH or .pth file\\nsettings or manual sys.path changes.\\n\\n1. The dot path syntax was chosen partly for platform neutrality, but also because paths in import statements\\nbecome real nested object paths. This syntax also means that you may get odd error messages if you forget\\nto omit the .py in your import statements. For example, import mod.py is assumed to be a directory path\\nimport—it loads mod.py, then tries to load a mod\\\\py.py, and ultimately issues a potentially confusing\\n“No module named py” error message. As of Python 3.3 this error message has been improved to say\\n“No module named \\'m.py\\'; m is not a package.”\\n\\nPackage Import Basics\\n\\n| 709\\n\\n\\x0cThe net effect is that this example’s directory structure should be as follows, with in-\\ndentation designating directory nesting:\\n\\ndir0\\\\                               # Container on module search path\\n    dir1\\\\\\n        __init__.py\\n        dir2\\\\\\n            __init__.py\\n            mod.py\\n\\nThe  __init__.py  files  can  contain  Python  code,  just  like  normal  module  files.  Their\\nnames are special because their code is run automatically the first time a Python pro-\\ngram imports a directory, and thus serves primarily as a hook for performing initiali-\\nzation steps required by the package. These files can also be completely empty, though,\\nand sometimes have additional roles—as the next section explains.\\n\\nAs we’ll see near the end of this chapter, the requirement of packages\\nto have a file named __init__.py has been lifted as of Python 3.3. In that\\nrelease and later, directories of modules with no such file may be im-\\nported as single-directory namespace packages, which work the same\\nbut run no initialization-time code file. Prior to Python 3.3, though, and\\nin all of Python 2.X, packages still require __init__.py files. As described\\nahead, in 3.3 and later these files also provide a performance advantage\\nwhen used.\\n\\nPackage initialization file roles\\nIn more detail, the __init__.py file serves as a hook for package initialization-time ac-\\ntions, declares a directory as a Python package, generates a module namespace for a\\ndirectory, and implements the behavior of from * (i.e., from .. import *) statements\\nwhen used with directory imports:\\n\\nPackage initialization\\n\\nThe first time a Python program imports through a directory, it automatically runs\\nall  the  code  in  the  directory’s  __init__.py  file.  Because  of  that,  these  files  are  a\\nnatural place to put code to initialize the state required by files in a package. For\\ninstance, a package might use its initialization file to create required data files, open\\nconnections to databases, and so on. Typically, __init__.py files are not meant to\\nbe useful if executed directly; they are run automatically when a package is first\\naccessed.\\n\\nModule usability declarations\\n\\nPackage  __init__.py  files  are  also  partly  present  to  declare  that  a  directory  is  a\\nPython package. In this role, these files serve to prevent directories with common\\nnames from unintentionally hiding true modules that appear later on the module\\nsearch path. Without this safeguard, Python might pick a directory that has nothing\\nto do with your code, just because it appears nested in an earlier directory on the\\nsearch path. As we’ll see later, Python 3.3’s namespace packages obviate much of\\n\\n710 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cthis role, but achieve a similar effect algorithmically by scanning ahead on the path\\nto find later files.\\n\\nModule namespace initialization\\n\\nIn the package import model, the directory paths in your script become real nested\\nobject paths after an import. For instance, in the preceding example, after the im-\\nport the expression dir1.dir2 works and returns a module object whose namespace\\ncontains all the names assigned by dir2’s __init__.py initialization file. Such files\\nprovide  a  namespace  for  module  objects  created  for  directories,  which  would\\notherwise have no real associated module file.\\n\\nfrom * statement behavior\\n\\nAs an advanced feature, you can use __all__ lists in __init__.py files to define what\\nis exported when a directory is imported with the from * statement form. In an\\n__init__.py file, the __all__ list is taken to be the list of submodule names that\\nshould be automatically imported when from * is used on the package (directory)\\nname. If __all__ is not set, the from * statement does not automatically load sub-\\nmodules nested in the directory; instead, it loads just names defined by assignments\\nin the directory’s __init__.py file, including any submodules explicitly imported by\\ncode in this file. For instance, the statement from submodule import X in a direc-\\ntory’s __init__.py makes the name X available in that directory’s namespace. (We’ll\\nsee additional roles for __all__ in Chapter 25: it serves to declare from * exports\\nof simple files as well.)\\n\\nYou can also simply leave these files empty, if their roles are beyond your needs (and\\nfrankly, they are often empty in practice). They must exist, though, for your directory\\nimports to work at all.\\n\\nDon’t  confuse  package  __init__.py  files  with  the  class  __init__  con-\\nstructor methods we’ll meet in the next part of the book. The former\\nare files of code run when imports first step through a package directory\\nin a program run, while the latter are called when an instance is created.\\nBoth have initialization roles, but they are otherwise very different.\\n\\nPackage Import Example\\nLet’s actually code the example we’ve been talking about to show how initialization\\nfiles and paths come into play. The following three files are coded in a directory dir1\\nand its subdirectory dir2—comments give the pathnames of these files:\\n\\n# dir1\\\\__init__.py\\nprint(\\'dir1 init\\')\\nx = 1\\n\\n# dir1\\\\dir2\\\\__init__.py\\nprint(\\'dir2 init\\')\\ny = 2\\n\\nPackage Import Example | 711\\n\\n\\x0c# dir1\\\\dir2\\\\mod.py\\nprint(\\'in mod.py\\')\\nz = 3\\n\\nHere, dir1 will be either an immediate subdirectory of the one we’re working in (i.e.,\\nthe home directory), or an immediate subdirectory of a directory that is listed on the\\nmodule search path (technically, on sys.path). Either way, dir1’s container does not\\nneed an __init__.py file.\\nimport statements run each directory’s initialization file the first time that directory is\\ntraversed, as Python descends the path; print statements are included here to trace\\ntheir execution:\\n\\nC:\\\\code> python               # Run in dir1\\'s container directory\\n>>> import dir1.dir2.mod      # First imports run init files\\ndir1 init\\ndir2 init\\nin mod.py\\n>>>\\n>>> import dir1.dir2.mod      # Later imports do not\\n\\nJust like module files, an already imported directory may be passed to reload to force\\nreexecution of that single item. As shown here, reload accepts a dotted pathname to\\nreload nested directories and files:\\n\\n>>> from imp import reload    # from needed in 3.X only\\n>>> reload(dir1)\\ndir1 init\\n<module \\'dir1\\' from \\'.\\\\\\\\dir1\\\\\\\\__init__.py\\'>\\n>>>\\n>>> reload(dir1.dir2)\\ndir2 init\\n<module \\'dir1.dir2\\' from \\'.\\\\\\\\dir1\\\\\\\\dir2\\\\\\\\__init__.py\\'>\\n\\nOnce imported, the path in your import statement becomes a nested object path in your\\nscript. Here, mod is an object nested in the object dir2, which in turn is nested in the\\nobject dir1:\\n>>> dir1\\n<module \\'dir1\\' from \\'.\\\\\\\\dir1\\\\\\\\__init__.py\\'>\\n>>> dir1.dir2\\n<module \\'dir1.dir2\\' from \\'.\\\\\\\\dir1\\\\\\\\dir2\\\\\\\\__init__.py\\'>\\n>>> dir1.dir2.mod\\n<module \\'dir1.dir2.mod\\' from \\'.\\\\\\\\dir1\\\\\\\\dir2\\\\\\\\mod.py\\'>\\n\\nIn fact, each directory name in the path becomes a variable assigned to a module object\\nwhose namespace is initialized by all the assignments in that directory’s __init__.py\\nfile. dir1.x refers to the variable x assigned in dir1\\\\__init__.py, much as mod.z refers to\\nthe variable z assigned in mod.py:\\n\\n>>> dir1.x\\n1\\n>>> dir1.dir2.y\\n2\\n\\n712 | Chapter 24:\\u2002Module Packages\\n\\n\\x0c>>> dir1.dir2.mod.z\\n3\\n\\nfrom Versus import with Packages\\nimport statements can be somewhat inconvenient to use with packages, because you\\nmay have to retype the paths frequently in your program. In the prior section’s example,\\nfor instance, you must retype and rerun the full path from dir1 each time you want to\\nreach z. If you try to access dir2 or mod directly, you’ll get an error:\\n\\n>>> dir2.mod\\nNameError: name \\'dir2\\' is not defined\\n>>> mod.z\\nNameError: name \\'mod\\' is not defined\\n\\nIt’s often more convenient, therefore, to use the from statement with packages to avoid\\nretyping the paths at each access. Perhaps more importantly, if you ever restructure\\nyour directory tree, the from statement requires just one path update in your code,\\nwhereas imports may require many. The import as extension, discussed formally in the\\nnext chapter, can also help here by providing a shorter synonym for the full path, and\\na renaming tool when the same name appears in multiple modules:\\n\\nC:\\\\code> python\\n>>> from dir1.dir2 import mod             # Code path here only\\ndir1 init\\ndir2 init\\nin mod.py\\n>>> mod.z                                 # Don\\'t repeat path\\n3\\n>>> from dir1.dir2.mod import z\\n>>> z\\n3\\n>>> import dir1.dir2.mod as mod           # Use shorter name (see Chapter 25)\\n>>> mod.z\\n3\\n>>> from dir1.dir2.mod import z as modz   # Ditto if names clash (see Chapter 25)\\n>>> modz\\n3\\n\\nWhy Use Package Imports?\\nIf you’re new to Python, make sure that you’ve mastered simple modules before step-\\nping up to packages, as they are a somewhat more advanced feature. They do serve\\nuseful roles, though, especially in larger programs: they make imports more informa-\\ntive, serve as an organizational tool, simplify your module search path, and can resolve\\nambiguities.\\nFirst of all, because package imports give some directory information in program files,\\nthey both make it easier to locate your files and serve as an organizational tool. Without\\npackage paths, you must often resort to consulting the module search path to find files.\\n\\nWhy Use Package Imports?\\n\\n| 713\\n\\n\\x0cMoreover, if you organize your files into subdirectories for functional areas, package\\nimports make it more obvious what role a module plays, and so make your code more\\nreadable. For example, a normal import of a file in a directory somewhere on the module\\nsearch path, like this:\\n\\nimport utilities\\n\\noffers much less information than an import that includes the path:\\n\\nimport database.client.utilities\\n\\nPackage imports can also greatly simplify your  PYTHONPATH and .pth file search path\\nsettings. In fact, if you use explicit package imports for all your cross-directory imports,\\nand you make those package imports relative to a common root directory where all\\nyour Python code is stored, you really only need a single entry on your search path: the\\ncommon root. Finally, package imports serve to resolve ambiguities by making explicit\\nexactly which files you want to import—and resolve conflicts when the same module\\nname appears in more than one place. The next section explores this role in more detail.\\n\\nA Tale of Three Systems\\nThe only time package imports are actually required is to resolve ambiguities that may\\narise when multiple programs with same-named files are installed on a single machine.\\nThis is something of an install issue, but it can also become a concern in general practice\\n—especially  given  the  tendency  of  developers  to  use  simple  and  similar  names  for\\nmodule files. Let’s turn to a hypothetical scenario to illustrate.\\nSuppose  that  a  programmer  develops  a  Python  program  that  contains  a  file  called\\nutilities.py for common utility code, and a top-level file named main.py that users launch\\nto start the program. All over this program, its files say import utilities to load and\\nuse the common code. When the program is shipped, it arrives as a single .tar or .zip\\nfile containing all the program’s files, and when it is installed, it unpacks all its files into\\na single directory named system1 on the target machine:\\n\\nsystem1\\\\\\n    utilities.py        # Common utility functions, classes\\n    main.py             # Launch this to start the program\\n    other.py            # Import utilities to load my tools\\n\\nNow, suppose that a second programmer develops a different program with files also\\ncalled utilities.py and main.py, and again uses import utilities throughout the pro-\\ngram to load the common code file. When this second system is fetched and installed\\non the same computer as the first system, its files will unpack into a new directory called\\nsystem2 somewhere on the receiving machine—ensuring that they do not overwrite\\nsame-named files from the first system:\\n\\nsystem2\\\\\\n    utilities.py        # Common utilities\\n    main.py             # Launch this to run\\n    other.py            # Imports utilities\\n\\n714 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cSo far, there’s no problem: both systems can coexist and run on the same computer.\\nIn fact, you won’t even need to configure the module search path to use these programs\\non your computer—because Python always searches the home directory first (that is,\\nthe directory containing the top-level file), imports in either system’s files will auto-\\nmatically see all the files in that system’s directory. For instance, if you click on sys-\\ntem1\\\\main.py,  all  imports  will  search  system1  first.  Similarly,  if  you  launch  sys-\\ntem2\\\\main.py, system2 will be searched first instead. Remember, module search path\\nsettings are only needed to import across directory boundaries.\\nHowever, suppose that after you’ve installed these two programs on your machine, you\\ndecide that you’d like to use some of the code in each of the utilities.py files in a system\\nof your own. It’s common utility code, after all, and Python code by nature “wants” to\\nbe reused. In this case, you’d like to be able to say the following from code that you’re\\nwriting in a third directory to load one of the two files:\\n\\nimport utilities\\nutilities.func(\\'spam\\')\\n\\nNow the problem starts to materialize. To make this work at all, you’ll have to set the\\nmodule search path to include the directories containing the utilities.py files. But which\\ndirectory do you put first in the path—system1 or system2?\\nThe problem is the linear nature of the search path. It is always scanned from left to\\nright, so no matter how long you ponder this dilemma, you will always get just one\\nutilities.py—from the directory listed first (leftmost) on the search path. As is, you’ll\\nnever be able to import it from the other directory at all.\\nYou could try changing sys.path within your script before each import operation, but\\nthat’s both extra work and highly error prone. And changing PYTHONPATH before each\\nPython program run is too tedious, and won’t allow you to use both versions in a single\\nfile in an event. By default, you’re stuck.\\nThis is the issue that packages actually fix. Rather than installing programs in inde-\\npendent directories listed on the module search path individually, you can package and\\ninstall them as subdirectories under a common root. For instance, you might organize\\nall the code in this example as an install hierarchy that looks like this:\\n\\nroot\\\\\\n    system1\\\\\\n        __init__.py\\n        utilities.py\\n        main.py\\n        other.py\\n    system2\\\\\\n        __init__.py\\n        utilities.py\\n        main.py\\n        other.py\\n    system3\\\\                    # Here or elsewhere\\n        __init__.py             # Need __init__.py here only if imported elsewhere\\n        myfile.py               # Your new code here\\n\\nWhy Use Package Imports?\\n\\n| 715\\n\\n\\x0cNow, add just the common root directory to your search path. If your code’s imports\\nare all relative to this common root, you can import either system’s utility file with a\\npackage import—the enclosing directory name makes the path (and hence, the module\\nreference) unique. In fact, you can import both utility files in the same module, as long\\nas you use an import statement and repeat the full path each time you reference the\\nutility modules:\\n\\nimport system1.utilities\\nimport system2.utilities\\nsystem1.utilities.function(\\'spam\\')\\nsystem2.utilities.function(\\'eggs\\')\\n\\nThe names of the enclosing directories here make the module references unique.\\nNote that you have to use import instead of from with packages only if you need to\\naccess the same attribute name in two or more paths. If the name of the called function\\nhere were different in each path, you could use from statements to avoid repeating the\\nfull package path whenever you call one of the functions, as described earlier; the as\\nextension in from can also be used to provide unique synonyms.\\nAlso, notice in the install hierarchy shown earlier that __init__.py files were added to\\nthe system1 and system2 directories to make this work, but not to the root directory.\\nOnly directories listed within  import statements in your code require these files; as\\nwe’ve seen, they are run automatically the first time the Python process imports through\\na package directory.\\nTechnically, in this case the system3 directory doesn’t have to be under root—just the\\npackages of code from which you will import. However, because you never know when\\nyour own modules might be useful in other programs, you might as well place them\\nunder the common root directory as well to avoid similar name-collision problems in\\nthe future.\\nFinally, notice that both of the two original systems’ imports will keep working un-\\nchanged. Because their home directories are searched first, the addition of the common\\nroot on the search path is irrelevant to code in system1 and system2; they can keep\\nsaying just import utilities and expect to find their own files when run as programs\\n—though not when used as packages in 3.X, as the next section explains. If you’re\\ncareful to unpack all your Python systems under a common root like this, path con-\\nfiguration also becomes simple: you’ll only need to add the common root directory \\nonce.\\n\\nWhy You Will Care: Module Packages\\n\\nBecause packages are a standard part of Python, it’s common to see larger third-party\\nextensions shipped as sets of package directories, rather than flat lists of modules. The\\nwin32all Windows extensions package for Python, for instance, was one of the first to\\njump on the package bandwagon. Many of its utility modules reside in packages im-\\nported with paths. For instance, to load client-side COM tools, you use a statement\\nlike this:\\n\\n716 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cfrom win32com.client import constants, Dispatch\\n\\nThis line fetches names from the client module of the win32com package—an install\\nsubdirectory.\\n\\nPackage imports are also pervasive in code run under the Jython Java-based imple-\\nmentation of Python, because Java libraries are organized into hierarchies as well. In\\nrecent Python releases, the email and XML tools are likewise organized into package\\nsubdirectories in the standard library, and Python 3.X groups even more related mod-\\nules into packages—including tkinter GUI tools, HTTP networking tools, and more.\\nThe following imports access various standard library tools in 3.X (2.X usage may vary):\\n\\nfrom email.message import Message\\nfrom tkinter.filedialog import askopenfilename\\nfrom http.server import CGIHTTPRequestHandler\\n\\nWhether you create package directories or not, you will probably import from them\\neventually.\\n\\nPackage Relative Imports\\nThe coverage of package imports so far has focused mostly on importing package files\\nfrom outside the package. Within the package itself, imports of same-package files can\\nuse the same full path syntax as imports from outside the package—and as we’ll see,\\nsometimes should. However, package files can also make use of special intrapackage\\nsearch rules to simplify import statements. That is, rather than listing package import\\npaths, imports within the package can be relative to the package.\\nThe way this works is version-dependent: Python 2.X implicitly searches package di-\\nrectories first on imports, while 3.X requires explicit relative import syntax in order to\\nimport from the package directory. This 3.X change can enhance code readability by\\nmaking same-package imports more obvious, but it’s also incompatible with 2.X and\\nmay break some programs.\\nIf you’re starting out in Python with version 3.X, your focus in this section will likely\\nbe on its new import syntax and model. If you’ve used other Python packages in the\\npast, though, you’ll probably also be interested in how the 3.X model differs. Let’s\\nbegin our tour with the latter perspective on this topic.\\n\\nAs we’ll learn in this section, use of package relative imports can actually\\nlimit your files’ roles. In short, they can no longer be used as executable\\nprogram files in both 2.X and 3.X. Because of this, normal package im-\\nport paths may be a better option in many cases. Still, this feature has\\nfound  its  way  into  many  a  Python  file,  and  merits  a  review  by  most\\nPython programmers to better understand both its tradeoffs and moti-\\nvation.\\n\\nPackage Relative Imports\\n\\n| 717\\n\\n\\x0cChanges in Python 3.X\\nThe way import operations in packages work has changed slightly in Python 3.X. This\\nchange applies only to imports within files when files are used as part of a package\\ndirectory;  imports  in  other  usage  modes  work  as  before.  For  imports  in  packages,\\nthough, Python 3.X introduces two changes:\\n\\n• It modifies the module import search path semantics to skip the package’s own\\ndirectory by default. Imports check only paths on the sys.path search path. These\\nare known as absolute imports.\\n\\n• It extends the syntax of from statements to allow them to explicitly request that\\nimports search the package’s directory only, with leading dots. This is known as\\nrelative import syntax.\\n\\nThese changes are fully present in Python 3.X. The new from statement relative syntax\\nis also available in Python 2.X, but the default absolute search path change must be\\nenabled as an option there. Enabling this can break 2.X programs, but is available for\\n3.X forward compatibility.\\nThe impact of this change is that in 3.X (and optionally in 2.X), you must generally use\\nspecial from dotted syntax to import modules located in the same package as the im-\\nporter,  unless  your  imports  list  a  complete  path  relative  to  a  package  root  on\\nsys.path, or your imports are relative to the always-searched home directory of the\\nprogram’s top-level file (which is usually the current working directory).\\nBy default, though, your package directory is not automatically searched, and intra-\\npackage imports made by files in a directory used as a package will fail without the\\nspecial from syntax. As we’ll see, in 3.X this can affect the way you will structure imports\\nor directories for modules meant for use in both top-level programs and importable\\npackages. First, though, let’s take a more detailed look at how this all works.\\n\\nRelative Import Basics\\nIn both Python 3.X and 2.X, from statements can now use leading dots (“.”) to specify\\nthat they require modules located within the same package (known as package relative\\nimports),  instead  of  modules  located  elsewhere  on  the  module  import  search  path\\n(called absolute imports). That is:\\n\\n• Imports with dots: In both Python 3.X and 2.X, you can use leading dots in from\\nstatements’ module names to indicate that imports should be relative-only to the\\ncontaining package—such imports will search for modules inside the package di-\\nrectory only and will not look for same-named modules located elsewhere on the\\nimport search path (sys.path). The net effect is that package modules override\\noutside modules.\\n\\n• Imports without dots: In Python 2.X, normal imports in a package’s code without\\nleading dots currently default to a relative-then-absolute search path order—that\\n\\n718 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cis, they search the package’s own directory first. However, in Python 3.X, normal\\nimports within a package are absolute-only by default—in the absence of any spe-\\ncial dot syntax, imports skip the containing package itself and look elsewhere on\\nthe sys.path search path.\\n\\nFor example, in both Python 3.X and 2.X a statement of the form:\\n\\nfrom . import spam                        # Relative to this package\\n\\ninstructs Python to import a module named spam located in the same package directory\\nas the file in which this statement appears. Similarly, this statement:\\n\\nfrom .spam import name\\n\\nmeans “from a module named spam located in the same package as the file that contains\\nthis statement, import the variable name.”\\nThe  behavior  of  a  statement  without  the  leading  dot  depends  on  which  version  of\\nPython you use. In 2.X, such an import will still default to the original relative-then-\\nabsolute search path order (i.e., searching the package’s directory first), unless a state-\\nment of the following form is included at the top of the importing file (as its first exe-\\ncutable statement):\\n\\nfrom __future__ import  absolute_import   # Use 3.X relative import model in 2.X\\n\\nIf present, this statement enables the Python 3.X absolute-only search path change. In\\n3.X, and in 2.X when enabled, an import without a leading dot in the module name\\nalways causes Python to skip the relative components of the module import search path\\nand look instead in the absolute directories that sys.path contains. For instance, in\\n3.X’s model, a statement of the following form will always find a string module some-\\nwhere on sys.path, instead of a module of the same name in the package:\\n\\nimport string                             # Skip this package\\'s version\\n\\nBy contrast, without the from __future__ statement in 2.X, if there’s a local string\\nmodule in the package, it will be imported instead. To get the same behavior in 3.X,\\nand in 2.X when the absolute import change is enabled, run a statement of the following\\nform to force a relative import:\\n\\nfrom . import string                      # Searches this package only\\n\\nThis statement works in both Python 2.X and 3.X today. The only difference in the 3.X\\nmodel is that it is required in order to load a module that is located in the same package\\ndirectory as the file in which this appears, when the file is being used as part of a package\\n(and unless full package paths are spelled out).\\nNotice that leading dots can be used to force relative imports only with the from state-\\nment, not with the import statement. In Python 3.X, the import modname statement is\\nalways absolute-only, skipping the containing package’s directory. In 2.X, this state-\\nment form still performs relative imports, searching the package’s directory first. from\\nstatements without leading dots behave the same as import statements—absolute-only\\n\\nPackage Relative Imports\\n\\n| 719\\n\\n\\x0cin 3.X (skipping the package directory), and relative-then-absolute in 2.X (searching\\nthe package directory first).\\nOther dot-based relative reference patterns are possible, too. Within a module file lo-\\ncated in a package directory named mypkg, the following alternative import forms work\\nas described:\\n\\nfrom .string import name1, name2          # Imports names from mypkg.string\\nfrom . import string                      # Imports mypkg.string\\nfrom .. import string                     # Imports string sibling of mypkg\\n\\nTo understand these latter forms better, and to justify all this added complexity, we\\nneed to take a short detour to explore the rationale behind this change.\\n\\nWhy Relative Imports?\\nBesides making intrapackage imports more explicit, this feature is designed in part to\\nallow scripts to resolve ambiguities that can arise when a same-named file appears in\\nmultiple places on the module search path. Consider the following package directory:\\n\\nmypkg\\\\\\n    __init__.py\\n    main.py\\n    string.py\\n\\nThis  defines  a  package  named  mypkg  containing  modules  named  mypkg.main  and\\nmypkg.string. Now, suppose that the main module tries to import a module named\\nstring. In Python 2.X and earlier, Python will first look in the mypkg directory to per-\\nform a relative import. It will find and import the string.py file located there, assigning\\nit to the name string in the mypkg.main module’s namespace.\\nIt could be, though, that the intent of this import was to load the Python standard\\nlibrary’s string module instead. Unfortunately, in these versions of Python, there’s no\\nstraightforward way to ignore mypkg.string and look for the standard library’s string\\nmodule located on the module search path. Moreover, we cannot resolve this with full\\npackage  import  paths,  because  we  cannot  depend  on  any  extra  package  directory\\nstructure above the standard library being present on every machine.\\nIn other words, simple imports in packages can be both ambiguous and error-prone.\\nWithin a package, it’s not clear whether an import spam statement refers to a module\\nwithin or outside the package. As one consequence, a local module or package can hide\\nanother hanging directly off of sys.path, whether intentionally or not.\\nIn practice, Python users can avoid reusing the names of standard library modules they\\nneed for modules of their own (if you need the standard string, don’t name a new\\nmodule string!). But this doesn’t help if a package accidentally hides a standard mod-\\nule; moreover, Python might add a new standard library module in the future that has\\nthe same name as a module of your own. Code that relies on relative imports is also\\n\\n720 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cless easy to understand, because the reader may be confused about which module is\\nintended to be used. It’s better if the resolution can be made explicit in code.\\n\\nThe relative imports solution in 3.X\\nTo address this dilemma, imports run within packages have changed in Python 3.X to\\nbe  absolute-only  (and  can  be  made  so  as  an  option  in  2.X).  Under  this  model,  an\\nimport statement of the following form in our example file mypkg/main.py will always\\nfind a string module outside the package, via an absolute import search of sys.path:\\n\\nimport string                          # Imports string outside package (absolute)\\n\\nA from import without leading-dot syntax is considered absolute as well:\\n\\nfrom string import name                # Imports name from string outside package\\n\\nIf you really want to import a module from your package without giving its full path\\nfrom the package root, though, relative imports are still possible if you use the dot\\nsyntax in the from statement:\\n\\nfrom . import string                   # Imports mypkg.string here (relative)\\n\\nThis form imports the string module relative to the current package only and is the\\nrelative equivalent to the prior import example’s absolute form (both load a module as\\na whole). When this special relative syntax is used, the package’s directory is the only\\ndirectory searched.\\nWe can also copy specific names from a module with relative syntax:\\nfrom .string import name1, name2       # Imports names from mypkg.string\\n\\nThis statement again refers to the string module relative to the current package. If this\\ncode appears in our mypkg.main module, for example, it will import name1 and name2\\nfrom mypkg.string.\\nIn effect, the “.” in a relative import is taken to stand for the package directory con-\\ntaining the file in which the import appears. An additional leading dot performs the\\nrelative import starting from the parent of the current package. For example, this state-\\nment:\\n\\nfrom .. import spam                    # Imports a sibling of mypkg\\n\\nwill load a sibling of mypkg—i.e., the spam module located in the package’s own con-\\ntainer directory, next to mypkg. More generally, code located in some module A.B.C can\\nuse any of these forms:\\n\\nfrom . import D                        # Imports A.B.D     (. means A.B)\\nfrom .. import E                       # Imports A.E       (.. means A)\\n\\nfrom .D import X                       # Imports A.B.D.X   (. means A.B)\\nfrom ..E import X                      # Imports A.E.X     (.. means A)\\n\\nPackage Relative Imports\\n\\n| 721\\n\\n\\x0cRelative imports versus absolute package paths\\nAlternatively, a file can sometimes name its own package explicitly in an absolute im-\\nport  statement,  relative  to  a  directory  on  sys.path.  For  example,  in  the  following,\\nmypkg will be found in an absolute directory on sys.path:\\n\\nfrom mypkg import string                    # Imports mypkg.string (absolute)\\n\\nHowever, this relies on both the configuration and the order of the module search path\\nsettings, while relative import dot syntax does not. In fact, this form requires that the\\ndirectory immediately containing mypkg be included in the module search path. It prob-\\nably is if mypkg is the package root (or else the package couldn’t be used from the outside\\nin the first place!), but this directory may be nested in a much larger package tree. If\\nmypkg isn’t the package’s root, absolute import statements must list all the directories\\nbelow the package’s root entry in sys.path when naming packages explicitly like this:\\n\\nfrom system.section.mypkg import string     # system container on sys.path only\\n\\nIn large or deep packages, that could be substantially more work to code than a dot:\\n\\nfrom . import string                        # Relative import syntax\\n\\nWith this latter form, the containing package is searched automatically, regardless of\\nthe search path settings, search path order, and directory nesting. On the other hand,\\nthe full-path absolute form will work regardless of how the file is being used—as part\\nof a program or package—as we’ll explore ahead.\\n\\nThe Scope of Relative Imports\\nRelative imports can seem a bit perplexing on first encounter, but it helps if you re-\\nmember a few key points about them:\\n\\n• Relative imports apply to imports within packages only. Keep in mind that\\nthis feature’s module search path change applies only to import statements within\\nmodule  files  used  as  part  of  a  package—that  is,  intrapackage  imports.  Normal\\nimports in files not used as part of a package still work exactly as described earlier,\\nautomatically searching the directory containing the top-level script first.\\n\\n• Relative imports apply to the from statement only. Also remember that this\\nfeature’s new syntax applies only to from statements, not import statements. It’s\\ndetected by the fact that the module name in a from begins with one or more dots\\n(periods). Module names that contain embedded dots but don’t have a leading dot\\nare package imports, not relative imports.\\n\\nIn other words, package relative imports in 3.X really boil down to just the removal of\\n2.X’s inclusive search path behavior for packages, along with the addition of special\\nfrom syntax to explicitly request that relative package-only behavior be used. If you\\ncoded your package imports in the past so that they did not depend upon 2.X’s implicit\\nrelative lookup (e.g., by always spelling out full paths from a package root), this change\\n\\n722 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cis largely a moot point. If you didn’t, you’ll need to update your package files to use\\nthe new from syntax for local package files, or full absolute paths.\\n\\nModule Lookup Rules Summary\\nWith packages and relative imports, the module search story in Python 3.X that we\\nhave seen so far can be summarized as follows:\\n\\n• Basic modules with simple names (e.g., A) are located by searching each directory\\non the sys.path list, from left to right. This list is constructed from both system\\ndefaults and user-configurable settings described in Chapter 22.\\n\\n• Packages are simply directories of Python modules with a special __init__.py file,\\nwhich enables A.B.C directory path syntax in imports. In an import of A.B.C, for\\nexample, the directory named A is located relative to the normal module import\\nsearch of sys.path, B is another package subdirectory within A, and C is a module\\nor other importable item within B.\\n\\n• Within  a  package’s  files,  normal  import  and  from  statements  use  the  same\\nsys.path search rule as imports elsewhere. Imports in packages using from state-\\nments  and  leading  dots,  however,  are  relative  to  the  package;  that  is,  only  the\\npackage directory is checked, and the normal sys.path lookup is not used. In from .\\nimport A, for example, the module search is restricted to the directory containing\\nthe file in which this statement appears.\\n\\nPython 2.X works the same, except that normal imports without dots also automatically\\nsearch the package directory first before proceeding on to sys.path.\\nIn sum, Python imports select between relative (in the containing directory) and abso-\\nlute (in a directory on sys.path) resolutions as follows:\\n\\nDotted imports: from . import m\\n\\nAre relative-only in both 2.X and 3.X\\n\\nNondotted imports: import m, from m import x\\n\\nAre relative-then-absolute in 2.X, and absolute-only in 3.X\\n\\nAs we’ll see later, Python 3.3 adds another flavor to modules—namespace packages—\\nwhich is largely disjointed from the package-relative story we’re covering here. This\\nnewer model supports package-relative imports too, and is simply a different way to\\nconstruct a package. It augments the import search procedure to allow package content\\nto be spread across multiple simple directories as a last-resort resolution. Thereafter,\\nthough, the composite package behaves the same in terms of relative import rules.\\n\\nRelative Imports in Action\\nBut enough theory: let’s run some simple code to demonstrate the concepts behind\\nrelative imports.\\n\\nPackage Relative Imports\\n\\n| 723\\n\\n\\x0cImports outside packages\\nFirst of all, as mentioned previously, this feature does not impact imports outside a\\npackage. Thus, the following finds the standard library string module as expected:\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import string\\n>>> string\\n<module \\'string\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\string.py\\'>\\n\\nBut if we add a module of the same name in the directory we’re working in, it is selected\\ninstead, because the first entry on the module search path is the current working di-\\nrectory (CWD):\\n# code\\\\string.py\\nprint(\\'string\\' * 8)\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import string\\nstringstringstringstringstringstringstringstring\\n>>> string\\n<module \\'string\\' from \\'.\\\\\\\\string.py\\'>\\n\\nIn other words, normal imports are still relative to the “home” directory (the top-level\\nscript’s container, or the directory you’re working in). In fact, package relative import\\nsyntax is not even allowed in code that is not in a file being used as part of a package:\\n\\n>>> from . import string\\nSystemError: Parent module \\'\\' not loaded, cannot perform relative import\\n\\nIn this section, code entered at the interactive prompt behaves the same as it would if\\nrun in a top-level script, because the first entry on sys.path is either the interactive\\nworking directory or the directory containing the top-level file. The only difference is\\nthat the start of sys.path is an absolute directory, not an empty string:\\n\\n# code\\\\main.py\\nimport string                                         # Same code but in a file\\nprint(string)\\n\\nC:\\\\code> C:\\\\python33\\\\python main.py                   # Equivalent results in 2.X\\nstringstringstringstringstringstringstringstring\\n<module \\'string\\' from \\'c:\\\\\\\\code\\\\\\\\string.py\\'>\\n\\nSimilarly, a from . import string in this nonpackage file fails the same as it does at the\\ninteractive prompt—programs and packages are different file usage modes.\\n\\nImports within packages\\nNow, let’s get rid of the local string module we coded in the CWD and build a package\\ndirectory  there  with  two  modules,  including  the  required  but  empty  test\\\\pkg\\n\\\\__init__.py file. Package roots in this section are located in the CWD added automat-\\nically  to  sys.path,  so  we  don’t  need  to  set  PYTHONPATH.  I’ll  also  largely  omit  empty\\n\\n724 | Chapter 24:\\u2002Module Packages\\n\\n\\x0c__init__.py files and most error message text for space (and non-Windows readers will\\nhave to pardon the shell commands here, and translate for your platform):\\n\\nC:\\\\code> del string*           # del __pycache__\\\\string* for bytecode in 3.2+\\nC:\\\\code> mkdir pkg\\nc:\\\\code> notepad pkg\\\\__init__.py\\n\\n# code\\\\pkg\\\\spam.py\\nimport eggs                    # <== Works in 2.X but not 3.X!\\nprint(eggs.X)\\n\\n# code\\\\pkg\\\\eggs.py\\nX = 99999\\nimport string\\nprint(string)\\n\\nThe first file in this package tries to import the second with a normal import statement.\\nBecause this is taken to be relative in 2.X but absolute in 3.X, it fails in the latter. That\\nis, 2.X searches the containing package first, but 3.X does not. This is the incompatible\\nbehavior you have to be aware of in 3.X:\\n\\nC:\\\\code> c:\\\\Python27\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'C:\\\\Python27\\\\lib\\\\string.pyc\\'>\\n99999\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import pkg.spam\\nImportError: No module named \\'eggs\\'\\n\\nTo make this work in both 2.X and 3.X, change the first file to use the special relative\\nimport syntax, so that its import searches the package directory in 3.X too:\\n\\n# code\\\\pkg\\\\spam.py\\nfrom . import eggs             # <== Use package relative import in 2.X or 3.X\\nprint(eggs.X)\\n\\n# code\\\\pkg\\\\eggs.py\\nX = 99999\\nimport string\\nprint(string)\\n\\nC:\\\\code> c:\\\\Python27\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'C:\\\\Python27\\\\lib\\\\string.pyc\\'>\\n99999\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\string.py\\'>\\n99999\\n\\nPackage Relative Imports\\n\\n| 725\\n\\n\\x0cImports are still relative to the CWD\\nNotice in the preceding example that the package modules still have access to standard\\nlibrary modules like string—their normal imports are still relative to the entries on the\\nmodule search path. In fact, if you add a string module to the CWD again, imports in\\na package will find it there instead of in the standard library. Although you can skip\\nthe package directory with an absolute import in 3.X, you still can’t skip the home\\ndirectory of the program that imports the package:\\n\\n# code\\\\string.py\\nprint(\\'string\\' * 8)\\n\\n# code\\\\pkg\\\\spam.py\\nfrom . import eggs\\nprint(eggs.X)\\n\\n# code\\\\pkg\\\\eggs.py\\nX = 99999\\nimport string                  # <== Gets string in CWD, not Python lib!\\nprint(string)\\n\\nC:\\\\code> c:\\\\Python33\\\\python    # Same result in 2.X\\n>>> import pkg.spam\\nstringstringstringstringstringstringstringstring\\n<module \\'string\\' from \\'.\\\\\\\\string.py\\'>\\n99999\\n\\nSelecting modules with relative and absolute imports\\nTo show how this applies to imports of standard library modules, reset the package\\nagain. Get rid of the local string module, and define a new one inside the package itself:\\n\\nC:\\\\code> del string*           # del __pycache__\\\\string* for bytecode in 3.2+\\n\\n# code\\\\pkg\\\\spam.py\\nimport string                  # <== Relative in 2.X, absolute in 3.X\\nprint(string)\\n\\n# code\\\\pkg\\\\string.py\\nprint(\\'Ni\\' * 8)\\n\\nNow, which version of the string module you get depends on which Python you use.\\nAs before, 3.X interprets the import in the first file as absolute and skips the package,\\nbut 2.X does not—another example of the incompatible behavior in 3.X:\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import pkg.spam\\n<module \\'string\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\string.py\\'>\\n\\nC:\\\\code> c:\\\\Python27\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module \\'pkg.string\\' from \\'pkg\\\\string.py\\'>\\n\\n726 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cUsing relative import syntax in 3.X forces the package to be searched again, as it is in\\n2.X—by using absolute or relative import syntax in 3.X, you can either skip or select\\nthe package directory explicitly. In fact, this is the use case that the 3.X model addresses:\\n\\n# code\\\\pkg\\\\spam.py\\nfrom . import string           # <== Relative in both 2.X and 3.X\\nprint(string)\\n\\n# code\\\\pkg\\\\string.py\\nprint(\\'Ni\\' * 8)\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module \\'pkg.string\\' from \\'.\\\\\\\\pkg\\\\\\\\string.py\\'>\\n\\nC:\\\\code> c:\\\\Python27\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module \\'pkg.string\\' from \\'pkg\\\\string.py\\'>\\n\\nRelative imports search packages only\\nIt’s also important to note that relative import syntax is really a binding declaration, not\\njust a preference. If we delete the string.py file and any associated byte code in this\\nexample now, the relative import in spam.py fails in both 3.X and 2.X, instead of falling\\nback on the standard library (or any other) version of this module:\\n\\n# code\\\\pkg\\\\spam.py\\nfrom . import string           # <== Fails in both 2.X and 3.X if no string.py here!\\n\\nC:\\\\code> del pkg\\\\string*\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> import pkg.spam\\nImportError: cannot import name string\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> import pkg.spam\\nImportError: cannot import name string\\n\\nModules referenced by relative imports must exist in the package directory.\\n\\nImports are still relative to the CWD, again\\nAlthough absolute imports let you skip package modules this way, they still rely on\\nother components of sys.path. For one last test, let’s define two string modules of our\\nown. In the following, there is one module by that name in the CWD, one in the pack-\\nage, and another in the standard library:\\n\\n# code\\\\string.py\\nprint(\\'string\\' * 8)\\n\\n# code\\\\pkg\\\\spam.py\\n\\nPackage Relative Imports\\n\\n| 727\\n\\n\\x0cfrom . import string           # <== Relative in both 2.X and 3.X\\nprint(string)\\n\\n# code\\\\pkg\\\\string.py\\nprint(\\'Ni\\' * 8)\\n\\nWhen we import the string module with relative import syntax like this, we get the\\nversion in the package in both 2.X and 3.X, as desired:\\n\\nC:\\\\code> c:\\\\Python33\\\\python    # Same result in 2.X\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module \\'pkg.string\\' from \\'.\\\\\\\\pkg\\\\\\\\string.py\\'>\\n\\nWhen absolute syntax is used, though, the module we get varies per version again. 2.X\\ninterprets this as relative to the package first, but 3.X makes it “absolute,” which in this\\ncase really just means it skips the package and loads the version relative to the CWD\\n—not the version in the standard library:\\n\\n# code\\\\string.py\\nprint(\\'string\\' * 8)\\n\\n# code\\\\pkg\\\\spam.py\\nimport string                  # <== Relative in 2.X, \"absolute\" in 3.X: CWD!\\nprint(string)\\n\\n# code\\\\pkg\\\\string.py\\nprint(\\'Ni\\' * 8)\\n\\nC:\\\\code> c:\\\\Python33\\\\python\\n>>> import pkg.spam\\nstringstringstringstringstringstringstringstring\\n<module \\'string\\' from \\'.\\\\\\\\string.py\\'>\\n\\nC:\\\\code> c:\\\\Python27\\\\python\\n>>> import pkg.spam\\nNiNiNiNiNiNiNiNi\\n<module \\'pkg.string\\' from \\'pkg\\\\string.pyc\\'>\\n\\nAs you can see, although packages can explicitly request modules within their own\\ndirectories with dots, their “absolute” imports are otherwise still relative to the rest of\\nthe normal module search path. In this case, a file in the program using the package\\nhides the standard library module the package may want. The change in 3.X simply\\nallows package code to select files either inside or outside the package (i.e., relatively\\nor absolutely). Because import resolution can depend on an enclosing context that may\\nnot be foreseen, though, absolute imports in 3.X are not a guarantee of finding a module\\nin the standard library.\\nExperiment with these examples on your own for more insight. In practice, this is not\\nusually as ad hoc as it might seem: you can generally structure your imports, search\\npaths, and module names to work the way you wish during development. You should\\nkeep in mind, though, that imports in larger systems may depend upon context of use,\\nand the module import protocol is part of a successful library’s design.\\n\\n728 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cPitfalls of Package-Relative Imports: Mixed Use\\nNow that you’ve learned about package-relative imports, you should also keep in mind\\nthat they may not always be your best option. Absolute package imports, with a com-\\nplete directory path relative to a directory on sys.path, are still sometimes preferred\\nover both implicit package-relative imports in Python 2.X, and explicit package-relative\\nimport dot syntax in both Python 2.X and 3.X. This issue may seem obscure, but will\\nlikely become important fairly soon after you start coding packages of your own.\\nAs we’ve seen, Python 3.X’s relative import syntax and absolute search rule default\\nmake intrapackage imports explicit and thus easier to notice and maintain, and allow\\nexplicit choice in some name conflict scenarios. However, there are also two major\\nramifications of this model that you should be aware of:\\n\\n• In both Python 3.X and 2.X, use of package-relative import statements implicitly\\nbinds a file to a package directory and role, and precludes it from being used in\\nother ways.\\n\\n• In Python 3.X, the new relative search rule change means that a file can no longer\\n\\nserve as both script and package module as easily as it could in 2.X.\\n\\nThese constraint’s causes are a bit subtle, but because the following are simultaneously\\ntrue:\\n\\n• Python 3.X and 2.X do not allow from . relative syntax to be used unless the im-\\nporter is being used as part of a package (i.e., is being imported from somewhere\\nelse).\\n\\n• Python 3.X does not search a package module’s own directory for imports, unless\\nfrom . relative syntax is used (or the module is in the current working directory or\\nmain script’s home directory).\\n\\nUse of relative imports prevents you from creating directories that serve as both exe-\\ncutable programs and externally importable packages in 3.X and 2.X. Moreover, some\\nfiles can no longer serve as both script and package module in 3.X as they could in 2.X.\\nIn terms of import statements, the rules pan out as follows—the first is for package\\nmode only in both Pythons, and the second is for program mode only in 3.X:\\n\\nfrom . import mod      # Not allowed in nonpackage mode in both 2.X and 3.X\\nimport mod             # Does not search file\\'s own directory in package mode in 3.X\\n\\nThe net effect is that for files to be used in either 2.X or 3.X, you may need to choose a\\nsingle usage mode—package (with relative imports) or program (with simple imports),\\nand isolate true package module files in a subdirectory apart from top-level script files.\\nAlternatively, you can attempt manual sys.path changes (a generally brittle and error-\\nprone  task),  or  always  use  full  package  paths  in  absolute  imports  instead  of  either\\npackage-relative syntax or simple imports, and assume the package root is on the mod-\\nule search path:\\n\\nfrom system.section.mypkg import mod   # Works in both program and package mode\\n\\nPackage Relative Imports\\n\\n| 729\\n\\n\\x0cOf all these schemes, the last—full package path imports—may be the most portable\\nand functional, but we need to turn to more concrete code to see why.\\n\\nThe issue\\nFor example, in Python 2.X it’s common to use the same single directory as both pro-\\ngram and package, using normal undotted imports. This relies on the script’s home\\ndirectory to resolve imports when used as a program, and the 2.X relative-then-absolute\\nrule to resolve intrapackage imports when used as a package. This won’t quite work in\\n3.X, though—in package mode, plain imports do not load modules in the same direc-\\ntory anymore, unless that directory also happens to be the same as the main file’s con-\\ntainer or the current working directory (and hence, be on sys.path).\\nHere’s what this looks like in action, stripped to a bare minimum of code (for brevity\\nin this section I again omit __init__.py package directory files required prior to Python\\n3.3, and for variety use the 3.3 Windows launcher covered in Appendix B):\\n\\n# code\\\\pkg\\\\main.py\\nimport spam\\n\\n# code\\\\pkg\\\\spam.py\\nimport eggs                     # <== Works if in \".\" = home of main script file\\n\\n# code\\\\pkg\\\\eggs.py\\nprint(\\'Eggs\\' * 4)               # But won\\'t load this file when used as pkg in 3.X!\\n\\nc:\\\\code> python pkg\\\\main.py     # OK as program, in both 2.X and 3.X\\nEggsEggsEggsEggs\\nc:\\\\code> python pkg\\\\spam.py\\nEggsEggsEggsEggs\\n\\nc:\\\\code> py −2                  # OK as package in 2.X: relative-then-absolute\\n>>> import pkg.spam             # 2.X: plain imports search package directory first\\nEggsEggsEggsEggs\\n\\nC:\\\\code> py −3                  # But 3.X fails to find file here: absolute only\\n>>> import pkg.spam             # 3.X: plain imports search only CWD plus sys.path\\nImportError: No module named \\'eggs\\'\\n\\nYour next step might be to add the required relative import syntax for 3.X use, but it\\nwon’t help here. The following retains the single directory for both a main top-level\\nscript and package modules, and adds the required dots—in both 2.X and 3.X this now\\nworks when the directory is imported as a package, but fails when it is used as a program\\ndirectory (including attempts to run a module as a script directly):\\n\\n# code\\\\pkg\\\\main.py\\nimport spam\\n\\n# code\\\\pkg\\\\spam.py\\nfrom . import eggs              # <== Not a package if main file here (even if me)!\\n\\n# code\\\\pkg\\\\eggs.py\\n\\n730 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cprint(\\'Eggs\\' * 4)\\n\\nc:\\\\code> python                 # OK as package but not program in both 3.X and 2.X\\n>>> import pkg.spam\\nEggsEggsEggsEggs\\n\\nc:\\\\code> python pkg\\\\main.py\\nSystemError: ... cannot perform relative import\\nc:\\\\code> python pkg\\\\spam.py\\nSystemError: ... cannot perform relative import\\n\\nFix 1: Package subdirectories\\nIn a mixed-use case like this, one solution is to isolate all but the main files used only\\nby the program in a subdirectory—this way, your intrapackage imports still work in all\\nPythons, you can use the top directory as a standalone program, and the nested direc-\\ntory still serves as a package for use from other programs:\\n\\n# code\\\\pkg\\\\main.py\\nimport sub.spam                 # <== Works if move modules to pkg below main file\\n\\n# code\\\\pkg\\\\sub\\\\spam.py\\nfrom . import eggs              # Package relative works now: in subdirectory\\n\\n# code\\\\pkg\\\\sub\\\\eggs.py\\nprint(\\'Eggs\\' * 4)\\n\\nc:\\\\code> python pkg\\\\main.py     # From main script: same result in 2.X and 3.X\\nEggsEggsEggsEggs\\n\\nc:\\\\code> python                 # From elsewhere: same result in 2.X and 3.X\\n>>> import pkg.sub.spam\\nEggsEggsEggsEggs\\n\\nThe potential downside of this scheme is that you won’t be able to run package modules\\ndirectly to test them with embedded self-test code, though tests can be coded separately\\nin their parent directory instead:\\n\\nc:\\\\code> py −3 pkg\\\\sub\\\\spam.py  # But individual modules can\\'t be run to test\\nSystemError: ... cannot perform relative import\\n\\nFix 2: Full path absolute import\\nAlternatively, full path package import syntax would address this case too—it requires\\nthe directory above the package root to be in your path, though this is probably not an\\nextra requirement for a realistic software package. Most Python packages will either\\nrequire this setting, or arrange for it to be handled automatically with install tools (such \\nas distutils, which may store a package’s code in a directory on the default module\\nsearch path such as the site-packages root; see Chapter 22 for more details):\\n\\n# code\\\\pkg\\\\main.py\\nimport spam\\n\\nPackage Relative Imports\\n\\n| 731\\n\\n\\x0c# code\\\\pkg\\\\spam.py\\nimport pkg.eggs                 # <== Full package paths work in all cases, 2.X+3.X\\n\\n# code\\\\pkg\\\\eggs.py\\nprint(\\'Eggs\\' * 4)\\n\\nc:\\\\code> set PYTHONPATH=C:\\\\code\\nc:\\\\code> python pkg\\\\main.py     # From main script: Same result in 2.X and 3.X\\nEggsEggsEggsEggs\\n\\nc:\\\\code> python                 # From elsewhere: Same result in 2.X and 3.X\\n>>> import pkg.spam\\nEggsEggsEggsEggs\\n\\nUnlike the subdirectory fix, full path absolute imports like these also allow you to run\\nyour modules standalone to test:\\n\\nc:\\\\code> python pkg\\\\spam.py     # Individual modules are runnable too in 2.X and 3.X\\nEggsEggsEggsEggs\\n\\nExample: Application to module self-test code (preview)\\nTo summarize, here’s another typical example of the issue and its full path resolution.\\nThis uses a common technique we’ll expand on in the next chapter, but the idea is\\nsimple enough to include as a preview here (though you may want to review this again\\nlater—the coverage makes more sense here).\\nConsider the following two modules in a package directory, the second of which in-\\ncludes self-test code. In short, a module’s __name__ attribute is the string “__main__”\\nwhen it is being run as a top-level script, but not when it is being imported, which\\nallows it to be used as both module and script:\\n\\n# code\\\\dualpkg\\\\m1.py\\ndef somefunc():\\n    print(\\'m1.somefunc\\')\\n\\n# code\\\\dualpkg\\\\m2.py\\n...import m1 here...            # Replace me with a real import statement\\n\\ndef somefunc():\\n    m1.somefunc()\\n    print(\\'m2.somefunc\\')\\n\\nif __name__ == \\'__main__\\':\\n   somefunc()                   # Self-test or top-level script usage mode code\\n\\nThe second of these needs to import the first where the “...import m1 here...” place-\\nholder appears. Replacing this line with a relative import statement works when the\\nfile is used as a package, but is not allowed in nonpackage mode by either 2.X or 3.X\\n(results and error messages are omitted here for space; see the file dualpkg\\\\results.txt\\nin the book’s examples for the full listing):\\n\\n# code\\\\dualpkg\\\\m2.py\\nfrom . import m1\\n\\n732 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cc:\\\\code> py −3\\n>>> import dualpkg.m2           # OK\\nC:\\\\code> py −2\\n>>> import dualpkg.m2           # OK\\n\\nc:\\\\code> py −3 dualpkg\\\\m2.py    # Fails!\\nc:\\\\code> py −2 dualpkg\\\\m2.py    # Fails!\\n\\nConversely, a simple import statement works in nonpackage mode in both 2.X and\\n3.X, but fails in package mode in 3.X only, because such statements do not search the\\npackage directory in 3.X:\\n\\n# code\\\\dualpkg\\\\m2.py\\nimport m1\\n\\nc:\\\\code> py −3\\n>>> import dualpkg.m2           # Fails!\\nc:\\\\code> py −2\\n>>> import dualpkg.m2           # OK\\n\\nc:\\\\code> py −3 dualpkg\\\\m2.py    # OK\\nc:\\\\code> py −2 dualpkg\\\\m2.py    # OK\\n\\nAnd finally, using full package paths works again in both usage modes and Pythons, as\\nlong  as  the  package’s  root  is  on  the  module  search  path  (as  it  must  be  to  be  used\\nelsewhere):\\n\\n# code\\\\dualpkg\\\\m2.py\\nimport dualpkg.m1 as m1         # And: set PYTHONPATH=c:\\\\code\\n\\nc:\\\\code> py −3\\n>>> import dualpkg.m2           # OK\\nC:\\\\code> py −2\\n>>> import dualpkg.m2           # OK\\n\\nc:\\\\code> py −3 dualpkg\\\\m2.py    # OK\\nc:\\\\code> py −2 dualpkg\\\\m2.py    # OK\\n\\nIn sum, unless you’re willing and able to isolate your modules in subdirectories below\\nscripts, full package path imports are probably preferable to package-relative imports\\n—though they’re more typing, they handle all cases, and they work the same in 2.X\\nand 3.X. There may be additional workarounds that involve extra tasks (e.g., manually\\nsetting sys.path in your code), but we’ll skip them here because they are more obscure\\nand rely on import semantics, which is error-prone; full package imports rely only on\\nthe basic package mechanism.\\nNaturally, the extent to which this may impact your modules can vary per package;\\nabsolute imports may also require changes when directories are reorganized, and rel-\\native imports may become invalid if a local module is relocated.\\n\\nPackage Relative Imports\\n\\n| 733\\n\\n\\x0cBe sure to also watch for future Python changes on this front. Although\\nthis book covers Python up to 3.3 only, at this writing, there is talk in a\\nPEP of possibly addressing some package issues in Python 3.4, perhaps\\neven allowing relative imports to be used in program mode. On the other\\nhand, this initiative’s scope and outcome is uncertain and would work\\nonly on 3.4 and later; the full path solution given here is version-neutral;\\nand 3.4 is more than a year away in any event. That is, you can wait for\\na change to a 3.X change that limited functionality, or simply use tried-\\nand-true full package paths.\\n\\nPython 3.3 Namespace Packages\\nNow that you’ve learned all about package and package-relative imports, I need to\\nexplain that there’s a new option that modifies some of the ideas we just covered. At\\nleast abstractly, as of release 3.3 Python has four import models. From original to new-\\nest:\\n\\nBasic module imports: import mod, from mod import attr\\n\\nThe original model: imports of files and their contents, relative to the sys.path\\nmodule search path\\n\\nPackage imports: import dir1.dir2.mod, from dir1.mod import attr\\n\\nImports that give directory path extensions relative to the sys.path module search\\npath, where each package is contained in a single directory and has an initialization\\nfile, in Python 2.X and 3.X\\n\\nPackage-relative imports: from . import mod (relative), import mod (absolute)\\n\\nThe model used for intrapackage imports of the prior section, with its relative or\\nabsolute lookup schemes for dotted and nondotted imports, available but differing\\nin Python 2.X and 3.X\\n\\nNamespace packages: import splitdir.mod\\n\\nThe new namespace package model that we’ll survey here, which allows packages\\nto span multiple directories, and requires no initialization file, introduced in Python\\n3.3\\n\\nThe first two of these are self-contained, but the third tightens up the search order and\\nextends syntax for intrapackage imports, and the fourth upends some of the core no-\\ntions and requirements of the prior package model. In fact, Python 3.3 (and later) now\\nhas two flavors of packages:\\n\\n• The original model, now known as regular packages\\n• The alternative model, known as namespace packages\\n\\nThis is similar in spirit to the “classic” and “new style” class model dichotomy we’ll\\nmeet in the next part of this book, though the new is more an addition to the old here.\\nThe original and new package models are not mutually exclusive, and can be used\\n\\n734 | Chapter 24:\\u2002Module Packages\\n\\n\\x0csimultaneously in the same program. In fact, the new namespace package model works\\nas something of a fallback option, recognized only if normal modules and regular pack-\\nages of the same name are not present on the module search path.\\nThe rationale for namespace packages is rooted in package installation goals that may\\nseem obscure unless you are responsible for such tasks, and is better addressed by this\\nfeature’s PEP document. In short, though, they resolve a potential for collision of mul-\\ntiple __init__.py files when package parts are merged, by removing this file completely.\\nMoreover, by providing standard support for packages that can be split across multiple\\ndirectories and located in multiple sys.path entries, namespace packages both enhance\\ninstall flexibility and provide a common mechanism to replace the multiple incompat-\\nible solutions that have arisen to address this goal.\\nThough too early to judge their uptake, average Python users may find namespace\\npackages to be a useful and alternative extension to the regular package model—one\\nthat does not require initialization files, and allows any directory of code to be used as\\nan importable package. To see why, let’s move on to the details.\\n\\nNamespace Package Semantics\\nA namespace package is not fundamentally different from a regular package; it is just\\na different way of creating packages. Moreover, they are still relative to sys.path at the\\ntop level: the leftmost component of a dotted namespace package path must still be\\nlocated in an entry on the normal module search path.\\nIn terms of physical structure, though, the two can differ substantially. Regular pack-\\nages still must have an __init__.py file that is run automatically, and reside in a single\\ndirectory  as  before.  By  contrast,  new-style  namespace  packages  cannot  contain  an\\n__init__.py, and may span multiple directories that are collected at import time. In fact,\\nnone of the directories that make up a namespace package can have an __init__.py, but\\nthe content nested within each of them is treated as a single package.\\n\\nThe import algorithm\\nTo truly understand namespace packages, we have to look under the hood to see how\\nthe import operation works in 3.3. During imports, Python still iterates over each di-\\nrectory in the module search path, sys.path, just as in 3.2 and earlier. In 3.3, though,\\nwhile looking for an imported module or package named spam, for each directory in\\nthe module search path, Python tests for a wider variety of matching criteria, in the\\nfollowing order:\\n\\n1. If  directory\\\\spam\\\\__init__.py  is  found,  a  regular  package  is  imported  and  re-\\n\\nturned.\\n\\n2. If directory\\\\spam.{py, pyc, or other module extension} is found, a simple module\\n\\nis imported and returned.\\n\\nPython 3.3 Namespace Packages\\n\\n| 735\\n\\n\\x0c3. If directory\\\\spam is found and is a directory, it is recorded and the scan continues\\n\\nwith the next directory in the search path.\\n\\n4. If none of the above was found, the scan continues with the next directory in the\\n\\nsearch path.\\n\\nIf the search path scan completes without returning a module or package by steps 1 or\\n2, and at least one directory was recorded by step 3, then a namespace package is created.\\nThe creation of the namespace package happens immediately, and is not deferred until\\na sublevel import occurs. The new namespace package has a __path__ attribute set to\\nan iterable of the directory path strings that were found and recorded during the scan\\nby step 3, but does not have a __file__.\\nThe __path__ attribute is then used in later, deeper accesses to search all package com-\\nponents—each recorded entry on a namespace package’s __path__ is searched when-\\never further nested items are requested, much like the sole directory of a regular pack-\\nage.\\nViewed another way, the __path__ attribute of a namespace package serves the same\\nrole for lower-level components that sys.path does at the top for the leftmost compo-\\nnent of package import paths; it becomes the “parent path” for accessing lower items\\nusing the same four-step procedure just sketched.\\nThe net result is that a namespace package is a sort of virtual concatenation of directories\\nlocated via multiple sys.path entries. Once a namespace package is created, though,\\nthere is no functional difference between it and a regular package; it supports everything\\nwe’ve learned for regular packages, including package-relative import syntax.\\n\\nImpacts on Regular Packages: Optional __init__.py\\nAs one consequence of this new import procedure, as of Python 3.3 packages no longer\\nrequire __init__.py files—when a single-directory package does not have this file, it will\\nbe treated as a single-directory namespace package, and no warning will be issued. This\\nis a major relaxation of prior rules, but a commonly requested change; many packages\\nrequire no initialization code, and it seemed extraneous to have to create an empty\\ninitialization file in such cases. This is finally no longer required as of 3.3.\\nAt the same time, the original regular package model is still fully supported, and au-\\ntomatically runs code in __init__.py as before as an initialization hook. Moreover, when\\nit’s known that a package will never be a portion of a split namespace package, there\\nis a performance advantage to coding it as a regular package with an __init__.py. Cre-\\nation and loading of a regular package occurs immediately when it is located along the\\npath. With namespace packages, all entries in the path must be scanned before the\\npackage is created. More formally, regular packages stop the prior section’s algorithm\\nat step 1; namespace packages do not.\\n\\n736 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cPer this change’s PEP, there is no plan to remove support of regular packages—at least,\\nthat’s the story today; change is always a possibility in open source projects (indeed,\\nthe prior edition quoted plans on string formatting and relative imports in 2.X that were\\nlater abandoned), so as usual, be sure to watch for future developments on this front.\\nGiven  the  performance  advantage  and  auto-initialization  code  of  regular  packages,\\nthough, it seems unlikely that they would be removed altogether.\\n\\nNamespace Packages in Action\\nTo see how namespace packages work, consider the following two modules and nested\\ndirectory  structure—with  two  subdirectories  named  sub  located  in  different  parent\\ndirectories, dir1 and dir2:\\n\\nC:\\\\code\\\\ns\\\\dir1\\\\sub\\\\mod1.py\\nC:\\\\code\\\\ns\\\\dir2\\\\sub\\\\mod2.py\\n\\nIf we add both dir1 and dir2 to the module search path, sub becomes a namespace\\npackage  spanning  both,  with  the  two  module  files  available  under  that  name  even\\nthough they live in separate physical directories. Here’s the files’ contents and the re-\\nquired path settings on Windows: there are no __init__.py files here—in fact there\\ncannot be in namespace packages, as this is their chief physical differentiation:\\n\\nc:\\\\code> mkdir ns\\\\dir1\\\\sub                # Two dirs of same name in different dirs\\nc:\\\\code> mkdir ns\\\\dir2\\\\sub                # And similar outside Windows\\n\\nc:\\\\code> type ns\\\\dir1\\\\sub\\\\mod1.py         # Module files in different directories\\nprint(r\\'dir1\\\\sub\\\\mod1\\')\\n\\nc:\\\\code> type ns\\\\dir2\\\\sub\\\\mod2.py\\nprint(r\\'dir2\\\\sub\\\\mod2\\')\\n\\nc:\\\\code> set PYTHONPATH=C:\\\\code\\\\ns\\\\dir1;C:\\\\code\\\\ns\\\\dir2\\n\\nNow, when imported directly in 3.3 and later, the namespace package is the virtual\\nconcatenation of its individual directory components, and allows further nested parts\\nto be accessed through its single, composite name with normal imports:\\n\\nc:\\\\code> C:\\\\Python33\\\\python\\n>>> import sub\\n>>> sub                                   # Namespace packages: nested search paths\\n<module \\'sub\\' (namespace)>\\n>>> sub.__path__\\n_NamespacePath([\\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir1\\\\\\\\sub\\', \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\'])\\n\\n>>> from sub import mod1\\ndir1\\\\sub\\\\mod1\\n>>> import sub.mod2                       # Content from two different directories\\ndir2\\\\sub\\\\mod2\\n\\n>>> mod1\\n<module \\'sub.mod1\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir1\\\\\\\\sub\\\\\\\\mod1.py\\'>\\n\\nPython 3.3 Namespace Packages\\n\\n| 737\\n\\n\\x0c>>> sub.mod2\\n<module \\'sub.mod2\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\\\\\\\mod2.py\\'>\\n\\nThis is also true if we import through the namespace package name immediately—\\nbecause the namespace package is made when first reached, the timing of path exten-\\nsions is irrelevant:\\n\\nc:\\\\code> C:\\\\Python33\\\\python\\n>>> import sub.mod1\\ndir1\\\\sub\\\\mod1\\n>>> import sub.mod2                       # One package spanning two directories\\ndir2\\\\sub\\\\mod2\\n\\n>>> sub.mod1\\n<module \\'sub.mod1\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir1\\\\\\\\sub\\\\\\\\mod1.py\\'>\\n>>> sub.mod2\\n<module \\'sub.mod2\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\\\\\\\mod2.py\\'>\\n\\n>>> sub\\n<module \\'sub\\' (namespace)>\\n>>> sub.__path__\\n_NamespacePath([\\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir1\\\\\\\\sub\\', \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\'])\\n\\nInterestingly, relative imports work in namespace packages too—in the following, the\\nrelative import statement references a file in the package, even though the referenced\\nfile resides in a different directory:\\n\\nc:\\\\code> type ns\\\\dir1\\\\sub\\\\mod1.py\\nfrom . import mod2                        # And \"from . import string\" still fails\\nprint(r\\'dir1\\\\sub\\\\mod1\\')\\n\\nc:\\\\code> C:\\\\Python33\\\\python\\n>>> import sub.mod1                       # Relative import of mod2 in another dir\\ndir2\\\\sub\\\\mod2\\ndir1\\\\sub\\\\mod1\\n>>> import sub.mod2                       # Already imported module not rerun\\n>>> sub.mod2\\n<module \\'sub.mod2\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\\\\\\\mod2.py\\'>\\n\\nAs you can see, namespace packages are like ordinary single-directory packages in every\\nway, except for having a split physical storage—which is why single directory name-\\nspaces packages without __init__.py files are exactly like regular packages, but with no\\ninitialization logic to be run.\\n\\nNamespace Package Nesting\\nNamespace packages even support arbitrary nesting—once a package namespace pack-\\nage is created, it serves essentially the same role at its level that sys.path does at the\\ntop, becoming the “parent path” for lower levels. Continuing the prior section’s ex-\\nample:\\n\\nc:\\\\code> mkdir ns\\\\dir2\\\\sub\\\\lower          # Further nested components\\nc:\\\\code> type  ns\\\\dir2\\\\sub\\\\lower\\\\mod3.py\\n\\n738 | Chapter 24:\\u2002Module Packages\\n\\n\\x0cprint(r\\'dir2\\\\sub\\\\lower\\\\mod3\\')\\n\\nc:\\\\code> C:\\\\Python33\\\\python\\n>>> import sub.lower.mod3                 # Namespace pkg nested in namespace pkg\\ndir2\\\\sub\\\\lower\\\\mod3\\n\\nc:\\\\code> C:\\\\Python33\\\\python\\n>>> import sub                            # Same effect if accessed incrementally\\n>>> import sub.mod2\\ndir2\\\\sub\\\\mod2\\n>>> import sub.lower.mod3\\ndir2\\\\sub\\\\lower\\\\mod3\\n\\n>>> sub.lower                             # A single-directory namespace pkg\\n<module \\'sub.lower\\' (namespace)>\\n>>> sub.lower.__path__\\n_NamespacePath([\\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\\\\\\\lower\\'])\\n\\nIn  the  preceding,  sub  is  a  namespace  package  split  across  two  directories,  and\\nsub.lower is a single-directory namespace package nested within the portion of sub\\nphysically located in dir2. sub.lower is also the namespace package equivalent of a\\nregular package with no __init__.py.\\nThis nesting behavior holds true whether the lower component is a module, regular\\npackage,  or  another  namespace  package—by  serving  as  new  import  search  paths,\\nnamespace packages allow all three to be nested within them freely:\\n\\nc:\\\\code> mkdir ns\\\\dir1\\\\sub\\\\pkg\\nC:\\\\code> type  ns\\\\dir1\\\\sub\\\\pkg\\\\__init__.py\\nprint(r\\'dir1\\\\sub\\\\pkg\\\\__init__.py\\')\\n\\nc:\\\\code> C:\\\\Python33\\\\python\\n>>> import sub.mod2                       # Nested module\\ndir2\\\\sub\\\\mod2\\n>>> import sub.pkg                        # Nested regular package\\ndir1\\\\sub\\\\pkg\\\\__init__.py\\n>>> import sub.lower.mod3                 # Nested namespace package\\ndir2\\\\sub\\\\lower\\\\mod3\\n\\n>>> sub                                   # Modules, packages,and namespaces\\n<module \\'sub\\' (namespace)>\\n>>> sub.mod2\\n<module \\'sub.mod2\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\\\\\\\mod2.py\\'>\\n>>> sub.pkg\\n<module \\'sub.pkg\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir1\\\\\\\\sub\\\\\\\\pkg\\\\\\\\__init__.py\\'>\\n>>> sub.lower\\n<module \\'sub.lower\\' (namespace)>\\n>>> sub.lower.mod3\\n<module \\'sub.lower.mod3\\' from \\'C:\\\\\\\\code\\\\\\\\ns\\\\\\\\dir2\\\\\\\\sub\\\\\\\\lower\\\\\\\\mod3.py\\'>\\n\\nTrace through this example’s files and directories for more insight. As you can see,\\nnamespace packages integrate seamlessly into the former import models, and extend\\nit with new functionality.\\n\\nPython 3.3 Namespace Packages\\n\\n| 739\\n\\n\\x0cFiles Still Have Precedence over Directories\\nAs explained earlier, part of the purpose of __init___.py files in regular packages is to\\ndeclare the directory as a package—it tells Python to use the directory, rather than\\nskipping ahead to a possible file of the same name later on the path. This avoids inad-\\nvertently choosing a noncode subdirectory that accidentally appears early on the path,\\nover a desired module of the same name.\\nBecause namespace packages do not require these special files, they would seem to\\ninvalidate this safeguard. This isn’t the case, though—because the namespace algo-\\nrithm outlined earlier continues scanning the path after a namespace directory has been\\nfound,  files  later  on  the  path  still  have  priority  over  earlier  directories  with  no\\n__init__.py. For example, consider the following directories and modules:\\n\\nc:\\\\code> mkdir ns2\\nc:\\\\code> mkdir ns3\\nc:\\\\code> mkdir   ns3\\\\dir\\nc:\\\\code> notepad ns3\\\\dir\\\\ns2.py\\nc:\\\\code> type    ns3\\\\dir\\\\ns2.py\\nprint(r\\'ns3\\\\dir\\\\ns2.py!\\')\\n\\nThe ns2 directory here cannot be imported in Python 3.2 and earlier—it’s not a regular\\npackage, as it lacks an __init__.py initialization file. This directory can be imported\\nunder 3.3, though—it’s a namespace package directory in the current working direc-\\ntory, which is always the first item on the sys.path module search path irrespective of\\nPYTHONPATH settings:\\n\\nc:\\\\code> set PYTHONPATH=\\nc:\\\\code> py −3.2\\n>>> import ns2\\nImportError: No module named ns2\\n\\nc:\\\\code> py −3.3\\n>>> import ns2\\n>>> ns2                         # A single-directory namespace package in CWD\\n<module \\'ns2\\' (namespace)>\\n>>> ns2.__path__\\n_NamespacePath([\\'.\\\\\\\\ns2\\'])\\n\\nBut watch what happens when the directory containing a file of the same name as a\\nnamespace directory is added later on the search path, via PYTHONPATH settings—the file\\nis used instead, because Python keeps searching later path entries after a namespace\\npackage directory is found. It stops searching only when a module or regular package\\nis located, or the path has been completely scanned. Namespace packages are returned\\nonly if nothing else was found along the way:\\n\\nc:\\\\code> set PYTHONPATH=C:\\\\code\\\\ns3\\\\dir\\nc:\\\\code> py −3.3\\n>>> import ns2                  # Use later module file, not same-named directory!\\nns3\\\\dir\\\\ns2.py!\\n>>> ns2\\n<module \\'ns2\\' from \\'C:\\\\\\\\code\\\\\\\\ns3\\\\\\\\dir\\\\\\\\ns2.py\\'>\\n\\n740 | Chapter 24:\\u2002Module Packages\\n\\n\\x0c>>> import sys\\n>>> sys.path[:2]                # First \\'\\' means current working directory, CWD\\n[\\'\\', \\'C:\\\\\\\\code\\\\\\\\ns3\\\\\\\\dir\\']\\n\\nIn fact, setting the path to include a module works the same as it does in earlier Pythons,\\neven if a same-named namespace directory appears earlier on the path; namespace\\npackages are used in 3.3 only in cases that would be errors in earlier Pythons:\\n\\nc:\\\\code> py −3.2\\n>>> import ns2\\nns3\\\\dir\\\\ns2.py!\\n>>> ns2\\n<module \\'ns2\\' from \\'C:\\\\code\\\\ns3\\\\dir\\\\ns2.py\\'>\\n\\nThis is also why none of the directories in a namespace package is allowed to have a\\n__init__.py file: as soon as the import algorithm finds one that does, it returns a regular\\npackage immediately, and abandons the path search and the namespace package. Put\\nmore formally, the import algorithm chooses a namespace package only at the end of\\nthe path scan, and stops at steps 1 or 2 if either a regular package or module file is found\\nsooner.\\nThe net effect is that both module files and regular packages anywhere on the module\\nsearch path have precedence over namespace package directories. In the following, for\\nexample, a namespace package called sub exists as the concatenation of same-named\\ndirectories under dir1 and dir2 on the path:\\n\\nc:\\\\code> mkdir ns4\\\\dir1\\\\sub\\nc:\\\\code> mkdir ns4\\\\dir2\\\\sub\\nc:\\\\code> set PYTHONPATH=c:\\\\code\\\\ns4\\\\dir1;c:\\\\code\\\\ns4\\\\dir2\\nc:\\\\code> py −3\\n>>> import sub\\n>>> sub\\n<module \\'sub\\' (namespace)>\\n>>> sub.__path__\\n_NamespacePath([\\'c:\\\\\\\\code\\\\\\\\ns4\\\\\\\\dir1\\\\\\\\sub\\', \\'c:\\\\\\\\code\\\\\\\\ns4\\\\\\\\dir2\\\\\\\\sub\\'])\\n\\nMuch like a module file, though, a regular package added in the rightmost path entry\\ntakes priority over same-named namespace package directories too—the import path\\nscan starts recording a namespace package tentatively in dir1 as before, but abandons\\nit when the regular package is detected in dir2:\\n\\nc:\\\\code> notepad ns4\\\\dir2\\\\sub\\\\__init__.py\\nc:\\\\code> py −3\\n>>> import sub                  # Use later reg. package, not same-named directory!\\n>>> sub\\n<module \\'sub\\' from \\'c:\\\\\\\\code\\\\\\\\ns4\\\\\\\\dir2\\\\\\\\sub\\\\\\\\__init__.py\\'>\\n\\nThough a useful extension, because namespace packages are available only to readers\\nusing Python 3.3 (and later) I’m going to defer to Python’s manuals for more details on\\nthe subject. See especially this change’s PEP document for this change’s rationale, ad-\\nditional details, and more comprehensive examples.\\n\\nPython 3.3 Namespace Packages\\n\\n| 741\\n\\n\\x0cChapter Summary\\nThis chapter introduced Python’s package import model—an optional but useful way\\nto explicitly list part of the directory path leading up to your modules. Package imports\\nare still relative to a directory on your module import search path, but your script gives\\nthe rest of the path to the module explicitly.\\nAs we’ve seen, packages not only make imports more meaningful in larger systems, but\\nalso simplify import search path settings if all cross-directory imports are relative to a\\ncommon root directory, and resolve ambiguities when there is more than one module\\nof the same name—including the name of the enclosing directory in a package import\\nhelps distinguish between them.\\nBecause  it’s  relevant  only  to  code  in  packages,  we  also  explored  the  newer  relative\\nimport model here—a way for imports in package files to select modules in the same\\npackage explicitly using leading dots in a from, instead of relying on an older and error-\\nprone implicit package search rule. Finally, we surveyed Python 3.3 namespace pack-\\nages, which allow a logical package to span multiple physical directories as a fallback\\noption of import searches, and remove the initialization file requirements of the prior\\nmodel.\\nIn the next chapter, we will survey a handful of more advanced module-related topics,\\nsuch as the __name__ usage mode variable and name-string imports. As usual, though,\\nlet’s close out this chapter first with a short quiz to review what you’ve learned here.\\n\\nTest Your Knowledge: Quiz\\n1. What is the purpose of an __init__.py file in a module package directory?\\n2. How can you avoid repeating the full package path every time you reference a\\n\\npackage’s content?\\n\\n3. Which directories require __init__.py files?\\n4. When must you use import instead of from with packages?\\n5. What is the difference between from mypkg import spam and from . import spam?\\n6. What is a namespace package?\\n\\nTest Your Knowledge: Answers\\n1. The  __init__.py  file  serves  to  declare  and  initialize  a  regular  module  package;\\nPython automatically runs its code the first time you import through a directory\\nin  a  process.  Its  assigned  variables  become  the  attributes  of  the  module  object\\ncreated in memory to correspond to that directory. It is also not optional until 3.3\\nand  later—you  can’t  import  through  a  directory  with  package  syntax  unless  it\\ncontains this file.\\n\\n742 | Chapter 24:\\u2002Module Packages\\n\\n\\x0c2. Use the from statement with a package to copy names out of the package directly,\\nor use the as extension with the import statement to rename the path to a shorter\\nsynonym. In both cases, the path is listed in only one place, in the from or import\\nstatement.\\n\\n3. In Python 3.2 and earlier, each directory listed in an executed import or from state-\\nment must contain an __init__.py file. Other directories, including the directory\\nthat contains the leftmost component of a package path, do not need to include\\nthis file.\\n\\n4. You must use import instead of from with packages only if you need to access the\\nsame name defined in more than one path. With import, the path makes the ref-\\nerences unique, but from allows only one version of any given name (unless you\\nalso use the as extension to rename).\\n\\n5. In  Python  3.X,  from  mypkg  import  spam  is  an  absolute  import—the  search  for\\nmypkg skips the package directory and the module is located in an absolute directory\\nin sys.path. A statement from . import spam, on the other hand, is a relative import\\n—spam is looked up relative to the package in which this statement is contained\\nonly. In Python 2.X, the absolute import searches the package directory first before\\nproceeding to sys.path; relative imports work as described.\\n\\n6. A namespace package is an extension to the import model, available in Python 3.3\\nand  later,  that  corresponds  to  one  or  more  directories  that  do  not  have\\n__init__.py files. When Python finds these during an import search, and does not\\nfind a simple module or regular package first, it creates a namespace package that\\nis the virtual concatenation of all found directories having the requested module\\nname. Further nested components are looked up in all the namespace package’s\\ndirectories. The effect is similar to a regular package, but content may be split across\\nmultiple directories.\\n\\nTest Your Knowledge: Answers\\n\\n| 743\\n\\n\\x0c\\x0cCHAPTER 25\\nAdvanced Module Topics\\n\\nThis chapter concludes this part of the book with a collection of more advanced mod-\\nule-related  topics—data  hiding,  the  __future__  module,  the  __name__  variable,\\nsys.path changes, listing tools, importing modules by name string, transitive reloads,\\nand so on—along with the standard set of gotchas and exercises related to what we’ve\\ncovered in this part of the book.\\nAlong the way, we’ll build some larger and more useful tools than we have so far that\\ncombine functions and modules. Like functions, modules are more effective when their\\ninterfaces are well defined, so this chapter also briefly reviews module design concepts,\\nsome of which we have explored in prior chapters.\\nDespite the word “advanced” used in this chapter’s title for symmetry, this is mostly a\\ngrab-bag assortment of additional module topics. Because some of the topics discussed\\nhere are widely used—especially the __name__ trick—be sure to browse here before\\nmoving on to classes in the next part of the book.\\n\\nModule Design Concepts\\nLike functions, modules present design tradeoffs: you have to think about which func-\\ntions go in which modules, module communication mechanisms, and so on. All of this\\nwill become clearer when you start writing bigger Python systems, but here are a few\\ngeneral ideas to keep in mind:\\n\\n• You’re always in a module in Python. There’s no way to write code that doesn’t\\nlive in some module. As mentioned briefly in Chapter 17 and Chapter 21, even\\ncode  typed  at  the  interactive  prompt  really  goes  in  a  built-in  module  called\\n__main__; the only unique things about the interactive prompt are that code runs\\nand is discarded immediately, and expression results are printed automatically.\\n\\n• Minimize module coupling: global variables. Like functions, modules work\\nbest if they’re written to be closed boxes. As a rule of thumb, they should be as\\nindependent of global variables used within other modules as possible, except for\\n\\n745\\n\\n\\x0cfunctions and classes imported from them. The only things a module should share\\nwith the outside world are the tools it uses, and the tools it defines.\\n\\n• Maximize module cohesion: unified purpose. You can minimize a module’s\\ncouplings by maximizing its cohesion; if all the components of a module share a\\ngeneral purpose, you’re less likely to depend on external names.\\n\\n• Modules should rarely change other modules’ variables. We illustrated this\\nwith code in Chapter 17, but it’s worth repeating here: it’s perfectly OK to use\\nglobals defined in another module (that’s how clients import services, after all),\\nbut changing globals in another module is often a symptom of a design problem.\\nThere are exceptions, of course, but you should try to communicate results through\\ndevices such as function arguments and return values, not cross-module changes.\\nOtherwise, your globals’ values become dependent on the order of arbitrarily re-\\nmote assignments in other files, and your modules become harder to understand\\nand reuse.\\n\\nAs a summary, Figure 25-1 sketches the environment in which modules operate. Mod-\\nules contain variables, functions, classes, and other modules (if imported). Functions\\nhave local variables of their own, as do classes—objects that live within modules and\\nwhich we’ll begin studying in the next chapter. As we saw in Part IV, functions can\\nnest, too, but all are ultimately contained by modules at the top.\\n\\nFigure 25-1. Module execution environment. Modules are imported, but modules also import and use\\nother modules, which may be coded in Python or another language such as C. Modules in turn contain\\nvariables, functions, and classes to do their work, and their functions and classes may contain variables\\nand other items of their own. At the top, though, programs are just sets of modules.\\n\\n746 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cData Hiding in Modules\\nAs we’ve seen, a Python module exports all the names assigned at the top level of its\\nfile. There is no notion of declaring which names should and shouldn’t be visible out-\\nside the module. In fact, there’s no way to prevent a client from changing names inside\\na module if it wants to.\\nIn Python, data hiding in modules is a convention, not a syntactical constraint. If you\\nwant to break a module by trashing its names, you can, but fortunately, I’ve yet to meet\\na programmer for whom this was a life goal. Some purists object to this liberal attitude\\ntoward  data  hiding,  claiming  that  it  means  Python  can’t  implement  encapsulation.\\nHowever, encapsulation in Python is more about packaging than about restricting.\\nWe’ll expand this idea in the next part in relation to classes, which also have no privacy\\nsyntax but can often emulate its effect in code.\\n\\nMinimizing from * Damage: _X and __all__\\nAs a special case, you can prefix names with a single underscore (e.g., _X) to prevent\\nthem from being copied out when a client imports a module’s names with a from *\\nstatement. This really is intended only to minimize namespace pollution; because from\\n* copies out all names, the importer may get more than it’s bargained for (including\\nnames that overwrite names in the importer). Underscores aren’t “private” declara-\\ntions: you can still see and change such names with other import forms, such as the\\nimport statement:\\n\\n# unders.py\\na, _b, c, _d = 1, 2, 3, 4\\n\\n>>> from unders import *                 # Load non _X names only\\n>>> a, c\\n(1, 3)\\n>>> _b\\nNameError: name \\'_b\\' is not defined\\n\\n>>> import unders                        # But other importers get every name\\n>>> unders._b\\n2\\n\\nAlternatively, you can achieve a hiding effect similar to the _X naming convention by\\nassigning a list of variable name strings to the variable __all__ at the top level of the\\nmodule. When this feature is used, the from * statement will copy out only those names\\nlisted in the __all__ list. In effect, this is the converse of the _X convention: __all__\\nidentifies names to be copied, while _X identifies names not to be copied. Python looks\\nfor an __all__ list in the module first and copies its names irrespective of any under-\\nscores; if __all__ is not defined, from * copies all names without a single leading un-\\nderscore:\\n\\n# alls.py\\n__all__ = [\\'a\\', \\'_c\\']                    # __all__ has precedence over _X\\n\\nData Hiding in Modules\\n\\n| 747\\n\\n\\x0ca, b, _c, _d = 1, 2, 3, 4\\n\\n>>> from alls import *                   # Load __all__ names only\\n>>> a, _c\\n(1, 3)\\n>>> b\\nNameError: name \\'b\\' is not defined\\n\\n>>> from alls import a, b, _c, _d        # But other importers get every name\\n>>> a, b, _c, _d\\n(1, 2, 3, 4)\\n\\n>>> import alls\\n>>> alls.a, alls.b, alls._c, alls._d\\n(1, 2, 3, 4)\\n\\nLike the _X convention, the __all__ list has meaning only to the from * statement form\\nand does not amount to a privacy declaration: other import statements can still access\\nall names, as the last two tests show. Still, module writers can use either technique to\\nimplement modules that are well behaved when used with from *. See also the discus-\\nsion of __all__ lists in package __init__.py files in Chapter 24; there, these lists declare\\nsubmodules to be automatically loaded for a from * on their container.\\n\\nEnabling Future Language Features: __future__\\nChanges to the language that may potentially break existing code are usually introduced\\ngradually in Python. They often initially appear as optional extensions, which are dis-\\nabled by default. To turn on such extensions, use a special import statement of this form:\\n\\nfrom __future__ import featurename\\n\\nWhen used in a script, this statement must appear as the first executable statement in\\nthe file (possibly following a docstring or comment), because it enables special com-\\npilation of code on a per-module basis. It’s also possible to submit this statement at the\\ninteractive prompt to experiment with upcoming language changes; the feature will\\nthen be available for the remainder of the interactive session.\\nFor example, in this book we’ve seen how to use this statement in Python 2.X to activate\\n3.X true division in Chapter 5, 3.X print calls in Chapter 11, and 3.X absolute imports\\nfor packages in Chapter 24. Prior editions of this book used this statement form to\\ndemonstrate generator functions, which required a keyword that was not yet enabled\\nby default (they use a featurename of generators).\\nAll of these changes have the potential to break existing code in Python 2.X, so they\\nwere phased in gradually or offered as optional extensions, enabled with this special\\nimport. At the same time, some are available to allow you to write code that is forward\\ncompatible with later releases you may port to someday.\\nFor a list of futurisms you may import and turn on this way, run a  dir call on the\\n__future__ module after importing it, or see its library manual entry. Per its documen-\\n\\n748 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0ctation,  none  of  its  feature  names  will  ever  be  removed,  so  it’s  safe  to  leave  in  a\\n__future__ import even in code run by a version of Python where the feature is present\\nnormally.\\n\\nMixed Usage Modes: __name__ and __main__\\nOur next module-related trick lets you both import a file as a module and run it as a\\nstandalone program, and is widely used in Python files. It’s actually so simple that some\\nmiss  the  point  at  first:  each  module  has  a  built-in  attribute  called  __name__,  which\\nPython creates and assigns automatically as follows:\\n\\n• If  the  file  is  being  run  as  a  top-level  program  file,  __name__  is  set  to  the  string\\n\\n\"__main__\" when it starts.\\n\\n• If the file is being imported instead, __name__ is set to the module’s name as known\\n\\nby its clients.\\n\\nThe upshot is that a module can test its own __name__ to determine whether it’s being\\nrun or imported. For example, suppose we create the following module file, named\\nrunme.py, to export a single function called tester:\\n\\ndef tester():\\n    print(\"It\\'s Christmas in Heaven...\")\\n\\nif __name__ == \\'__main__\\':           # Only when run\\n    tester()                         # Not when imported\\n\\nThis module defines a function for clients to import and use as usual:\\n\\nc:\\\\code> python\\n>>> import runme\\n>>> runme.tester()\\nIt\\'s Christmas in Heaven...\\n\\nBut the module also includes code at the bottom that is set up to call the function\\nautomatically when this file is run as a program:\\n\\nc:\\\\code> python runme.py\\nIt\\'s Christmas in Heaven...\\n\\nIn effect, a module’s __name__ variable serves as a usage mode flag, allowing its code to\\nbe leveraged as both an importable library and a top-level script. Though simple, you’ll\\nsee this hook used in the majority of the Python program files you are likely to encounter\\nin the wild—both for testing and dual usage.\\nFor instance, perhaps the most common way you’ll see the __name__ test applied is for\\nself-test code. In short, you can package code that tests a module’s exports in the module\\nitself by wrapping it in a __name__ test at the bottom of the file. This way, you can use\\nthe file in clients by importing it, but also test its logic by running it from the system\\nshell or via another launching scheme.\\n\\nMixed Usage Modes: __name__ and __main__ | 749\\n\\n\\x0cCoding self-test code at the bottom of a file under the __name__ test is probably the most\\ncommon and simplest unit-testing protocol in Python. It’s much more convenient than\\nretyping all your tests at the interactive prompt. (Chapter 36 will discuss other com-\\nmonly used options for testing Python code—as you’ll see, the unittest and doctest\\nstandard library modules provide more advanced testing tools.)\\nIn addition, the __name__ trick is also commonly used when you’re writing files that\\ncan be used both as command-line utilities and as tool libraries. For instance, suppose\\nyou write a file-finder script in Python. You can get more mileage out of your code if\\nyou package it in functions and add a __name__ test in the file to automatically call those\\nfunctions when the file is run standalone. That way, the script’s code becomes reusable\\nin other programs.\\n\\nUnit Tests with __name__\\nIn  fact,  we’ve  already  seen  a  prime  example  in  this  book  of  an  instance  where  the\\n__name__ check could be useful. In the section on arguments in Chapter 18, we coded\\na script that computed the minimum value from the set of arguments sent in (this was\\nthe file minmax.py in “The min Wakeup Call!”):\\n\\ndef minmax(test, *args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if test(arg, res):\\n            res = arg\\n    return res\\n\\ndef lessthan(x, y): return x < y\\ndef grtrthan(x, y): return x > y\\n\\nprint(minmax(lessthan, 4, 2, 1, 5, 6, 3))        # Self-test code\\nprint(minmax(grtrthan, 4, 2, 1, 5, 6, 3))\\n\\nThis script includes self-test code at the bottom, so we can test it without having to\\nretype everything at the interactive command line each time we run it. The problem\\nwith the way it is currently coded, however, is that the output of the self-test call will\\nappear every time this file is imported from another file to be used as a tool—not exactly\\na user-friendly feature! To improve it, we can wrap up the self-test call in a __name__\\ncheck, so that it will be launched only when the file is run as a top-level script, not when\\nit is imported (this new version of the module file is renamed minmax2.py here):\\n\\nprint(\\'I am:\\', __name__)\\n\\ndef minmax(test, *args):\\n    res = args[0]\\n    for arg in args[1:]:\\n        if test(arg, res):\\n            res = arg\\n    return res\\n\\n750 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cdef lessthan(x, y): return x < y\\ndef grtrthan(x, y): return x > y\\n\\nif __name__ == \\'__main__\\':\\n    print(minmax(lessthan, 4, 2, 1, 5, 6, 3))    # Self-test code\\n    print(minmax(grtrthan, 4, 2, 1, 5, 6, 3))\\n\\nWe’re also printing the value of __name__ at the top here to trace its value. Python creates\\nand assigns this usage-mode variable as soon as it starts loading a file. When we run\\nthis file as a top-level script, its name is set to __main__, so its self-test code kicks in\\nautomatically:\\n\\nc:\\\\code> python minmax2.py\\nI am: __main__\\n1\\n6\\n\\nIf we import the file, though, its name is not __main__, so we must explicitly call the\\nfunction to make it run:\\n\\nc:\\\\code> python\\n>>> import minmax2\\nI am: minmax2\\n>>> minmax2.minmax(minmax2.lessthan, \\'s\\', \\'p\\', \\'a\\', \\'a\\')\\n\\'a\\'\\n\\nAgain, regardless of whether this is used for testing, the net effect is that we get to use\\nour code in two different roles—as a library module of tools, or as an executable pro-\\ngram.\\n\\nPer Chapter 24’s discussion of package relative imports, this section’s\\ntechnique can also have some implications for imports run by files that\\nare also used as package components in 3.X, but can still be leveraged\\nwith absolute package path imports and other techniques. See the prior\\nchapter’s discussion and example for more details.\\n\\nExample: Dual Mode Code\\nHere’s a more substantial module example that demonstrates another way that the\\nprior  section’s  __name__  trick  is  commonly  employed.  The  following  module,  for-\\nmats.py, defines string formatting utilities for importers, but also checks its name to\\nsee if it is being run as a top-level script; if so, it tests and uses arguments listed on the\\nsystem command line to run a canned or passed-in test. In Python, the sys.argv list \\ncontains command-line arguments—it is a list of strings reflecting words typed on the\\ncommand line, where the first item is always the name of the script being run. We used\\nthis in  Chapter 21’s benchmark tool as switches, but leverage it as a general input\\nmechanism here:\\n\\n#!python\\n\"\"\"\\n\\nExample: Dual Mode Code | 751\\n\\n\\x0cFile: formats.py (2.X and 3.X)\\nVarious specialized string display formatting utilities.\\nTest me with canned self-test or command-line arguments.\\nTo do: add parens for negative money, add more features.\\n\"\"\"\\n\\ndef commas(N):\\n    \"\"\"\\n    Format positive integer-like N for display with\\n    commas between digit groupings: \"xxx,yyy,zzz\".\\n    \"\"\"\\n    digits = str(N)\\n    assert(digits.isdigit())\\n    result = \\'\\'\\n    while digits:\\n        digits, last3 = digits[:-3], digits[-3:]\\n        result = (last3 + \\',\\' + result) if result else last3\\n    return result\\n\\ndef money(N, numwidth=0, currency=\\'$\\'):\\n    \"\"\"\\n    Format number N for display with commas, 2 decimal digits,\\n    leading $ and sign, and optional padding: \"$  -xxx,yyy.zz\".\\n    numwidth=0 for no space padding, currency=\\'\\' to omit symbol,\\n    and non-ASCII for others (e.g., pound=u\\'\\\\xA3\\' or u\\'\\\\u00A3\\').\\n    \"\"\"\\n    sign   = \\'-\\' if N < 0 else \\'\\'\\n    N      = abs(N)\\n    whole  = commas(int(N))\\n    fract  = (\\'%.2f\\' % N)[-2:]\\n    number = \\'%s%s.%s\\' % (sign, whole, fract)\\n    return \\'%s%*s\\' % (currency, numwidth, number)\\n\\nif __name__ == \\'__main__\\':\\n    def selftest():\\n        tests  = 0, 1        # fails: −1, 1.23\\n        tests += 12, 123, 1234, 12345, 123456, 1234567\\n        tests += 2 ** 32, 2 ** 100\\n        for test in tests:\\n            print(commas(test))\\n\\n        print(\\'\\')\\n        tests  = 0, 1, −1, 1.23, 1., 1.2, 3.14159\\n        tests += 12.34, 12.344, 12.345, 12.346\\n        tests += 2 ** 32, (2 ** 32 + .2345)\\n        tests += 1.2345, 1.2, 0.2345\\n        tests += −1.2345, −1.2, −0.2345\\n        tests += −(2 ** 32), −(2**32 + .2345)\\n        tests += (2 ** 100), −(2 ** 100)\\n        for test in tests:\\n            print(\\'%s [%s]\\' % (money(test, 17), test))\\n\\n    import sys\\n    if len(sys.argv) == 1:\\n        selftest()\\n\\n752 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0c    else:\\n        print(money(float(sys.argv[1]), int(sys.argv[2])))\\n\\nThis file works identically in Python 2.X and 3.X. When run directly, it tests itself as\\nbefore, but it uses options on the command line to control the test behavior. Run this\\nfile directly with no command-line arguments on your own to see what its self-test code\\nprints—it’s too extensive to list in full here:\\n\\nc:\\\\code> python formats.py\\n0\\n1\\n12\\n123\\n1,234\\n12,345\\n123,456\\n1,234,567\\n...etc...\\n\\nTo test specific strings, pass them in on the command line along with a minimum field\\nwidth; the script’s __main__ code passes them on to its money function, which in turn\\nruns commas:\\n\\nC:\\\\code> python formats.py 999999999 0\\n$999,999,999.00\\nC:\\\\code> python formats.py −999999999 0\\n$-999,999,999.00\\n\\nC:\\\\code> python formats.py 123456789012345 0\\n$123,456,789,012,345.00\\nC:\\\\code> python formats.py −123456789012345 25\\n$  −123,456,789,012,345.00\\n\\nC:\\\\code> python formats.py 123.456 0\\n$123.46\\nC:\\\\code> python formats.py −123.454 0\\n$-123.45\\n\\nAs before, because this code is instrumented for dual-mode usage, we can also import\\nits tools normally to reuse them as library components in scripts, modules, and the\\ninteractive prompt:\\n\\n>>> from formats import money, commas\\n>>> money(123.456)\\n\\'$123.46\\'\\n>>> money(-9999999.99, 15)\\n\\'$  −9,999,999.99\\'\\n>>> X = 99999999999999999999\\n>>> \\'%s (%s)\\' % (commas(X), X)\\n\\'99,999,999,999,999,999,999 (99999999999999999999)\\'\\n\\nYou can use command-line arguments in ways similar to this example to provide gen-\\neral inputs to scripts that may also package their code as functions and classes for reuse\\nby importers. For more advanced command-line processing, see “Python Command-\\n\\nExample: Dual Mode Code | 753\\n\\n\\x0cLine  Arguments”  on  page  1432  in  Appendix  A,  and  the  getopt,  optparse,  and  arg\\nparse modules’ documentation in Python’s standard library manual. In some scenarios,\\nyou might also use the built-in input function, used in Chapter 3 and Chapter 10, to\\nprompt the shell user for test inputs instead of pulling them from the command line.\\n\\nAlso see Chapter 7’s discussion of the new {,d} string format method\\nsyntax added in Python 2.7 and 3.1; this formatting extension separates\\nthousands groups with commas much like the code here. The module\\nlisted here, though, adds money formatting, can be changed, and serves\\nas a manual alternative for comma insertions in earlier Pythons.\\n\\nCurrency Symbols: Unicode in Action\\nThis module’s money function defaults to dollars, but supports other currency symbols\\nby allowing you to pass in non-ASCII Unicode characters. The Unicode ordinal with\\nhexadecimal value 00A3, for example, is the pound symbol, and 00A5 is the yen. You\\ncan code these in a variety of forms, as:\\n\\n• The character’s decoded Unicode code point ordinal (integer) in a text string, with\\neither Unicode or hex escapes (for 2.X compatibility, use a leading u in such string\\nliterals in Python 3.3)\\n\\n• The character’s raw encoded form in a byte string that is decoded before passed,\\nwith hex escapes (for 3.X compatibility, use a leading b in such string literals in\\nPython 2.X)\\n\\n• The actual character itself in your program’s text, along with a source code en-\\n\\ncoding declaration\\n\\nWe previewed Unicode in Chapter 4 and will get into more details in Chapter 37, but\\nits basic requirements here are fairly simple, and serve as a decent use case. To test\\nalternative currencies, I typed the following in a file, formats_currency.py, because it\\nwas too much to reenter interactively on changes:\\n\\nfrom __future__ import print_function # 2.X\\nfrom formats import money\\nX = 54321.987\\n\\nprint(money(X), money(X, 0, \\'\\'))\\nprint(money(X, currency=u\\'\\\\xA3\\'), money(X, currency=u\\'\\\\u00A5\\'))\\nprint(money(X, currency=b\\'\\\\xA3\\'.decode(\\'latin-1\\')))\\n\\nprint(money(X, currency=u\\'\\\\u20AC\\'), money(X, 0, b\\'\\\\xA4\\'.decode(\\'iso-8859-15\\')))\\nprint(money(X, currency=b\\'\\\\xA4\\'.decode(\\'latin-1\\')))\\n\\nThe following gives this test file’s output in Python 3.3 in IDLE, and in other contexts\\nconfigured properly. It works the same in 2.X because it prints and codes strings port-\\nably. Per Chapter 11, a __future__ import enables 3.X print calls in 2.X. And as intro-\\n\\n754 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cduced in Chapter 4, 3.X b\\'...\\' bytes literals are taken as simple strings in 2.X, and 2.X\\nu\\'...\\' Unicode literals as treated as normal strings in 3.X as of 3.3.\\n\\n$54,321.99 54,321.99\\n£54,321.99 ¥54,321.99\\n£54,321.99\\n€54,321.99 €54,321.99\\n¤54,321.99\\n\\nIf this works on your computer, you can probably skip the next few paragraphs. De-\\npending on your interface and system settings, though, getting this to run and display\\nproperly  may  require  additional  steps.  On  my  machine,  it  behaves  correctly  when\\nPython and the display medium are in sync, but the euro and generic currency symbols\\nin the last two lines fail with errors in a basic Command Prompt on Windows.\\nSpecifically, this test script always runs and produces the output shown in the IDLE\\nGUI in both 3.X and 2.X, because Unicode-to-glyph mappings are handled well. It also\\nworks as advertised in 3.X on Windows if you redirect the output to a file and open it\\nwith Notepad, because 3.X encodes content on this platform in a default Windows\\nformat that Notepad understands:\\n\\nc:\\\\code> formats_currency.py > temp\\nc:\\\\code> notepad temp\\n\\nHowever, this doesn’t work in 2.X, because Python tries to encode printed text as ASCII\\nby default. To show all the non-ASCII characters in a Windows Command Prompt\\nwindow  directly,  on  some  computers  you  may  need  to  change  the  Windows  code\\npage (used to render characters) as well as Python’s  PYTHONIOENCODING environment\\nvariable (used as the encoding of text in standard streams, including the translation of\\ncharacters to bytes when they are printed) to a common Unicode format such as UTF-8:\\n\\nc:\\\\code> chcp 65001                           # Console matches Python\\nc:\\\\code> set PYTHONIOENCODING=utf-8           # Python matches console\\nc:\\\\code> formats_currency.py > temp           # Both 3.X and 2.X write UTF-8 text\\nc:\\\\code> type temp                            # Console displays it properly\\nc:\\\\code> notepad temp                         # Notepad recognizes UTF-8 too\\n\\nYou may not need to take these steps on some platforms and even on some Windows\\ndistributions. I did because my laptop’s code page is set to 437 (U.S. characters), but\\nyour code pages may vary.\\nSubtly, the only reason this test works on Python 2.X at all is because 2.X allows normal\\nand Unicode strings to be mixed, as long as the normal string is all 7-bit ASCII char-\\nacters. On 3.3, the 2.X u\\'...\\' Unicode literal is supported for compatibility, but taken\\nthe same as normal \\'...\\' strings, which are always Unicode (removing the leading u\\nmakes the test work in 3.0 through 3.2 too, but breaks 2.X compatibility):\\n\\nc:\\\\code> py −2\\n>>> print u\\'\\\\xA5\\' + \\'1\\', \\'%s2\\' % u\\'\\\\u00A3\\'    # 2.X: unicode/str mix for ASCII str\\n¥1 £2\\n\\nc:\\\\code> py −3\\n\\nExample: Dual Mode Code | 755\\n\\n\\x0c>>> print(u\\'\\\\xA5\\' + \\'1\\', \\'%s2\\' % u\\'\\\\u00A3\\')   # 3.X: str is Unicode, u\\'\\' optional\\n¥1 £2\\n>>> print(\\'\\\\xA5\\' + \\'1\\', \\'%s2\\' % \\'\\\\u00A3\\')\\n¥1 £2\\n\\nAgain, there’s much more on Unicode in Chapter 37—a topic many see as peripheral,\\nbut which can crop up even in relatively simple contexts like this! The takeaway point\\nhere is that, operational issues aside, a carefully coded script can often manage to sup-\\nport Unicode in both 3.X and 2.X.\\n\\nDocstrings: Module Documentation at Work\\nFinally, because this example’s main file uses the docstring feature introduced in Chap-\\nter 15, we can use the help function or PyDoc’s GUI/browser modes to explore its tools\\nas well—modules are almost automatically general-purpose tools. Here’s help at work;\\nFigure 25-2 gives the PyDoc view on our file.\\n\\n>>> import formats\\n>>> help(formats)\\nHelp on module formats:\\n\\nNAME\\n    formats\\n\\nDESCRIPTION\\n    File: formats.py (2.X and 3.X)\\n    Various specialized string display formatting utilities.\\n    Test me with canned self-test or command-line arguments.\\n    To do: add parens for negative money, add more features.\\n\\nFUNCTIONS\\n    commas(N)\\n        Format positive integer-like N for display with\\n        commas between digit groupings: \"xxx,yyy,zzz\".\\n\\n    money(N, numwidth=0, currency=\\'$\\')\\n        Format number N for display with commas, 2 decimal digits,\\n        leading $ and sign, and optional padding: \"$  -xxx,yyy.zz\".\\n        numwidth=0 for no space padding, currency=\\'\\' to omit symbol,\\n        and non-ASCII for others (e.g., pound=u\\'£\\' or u\\'£\\').\\n\\nFILE\\n    c:\\\\code\\\\formats.py\\n\\nChanging the Module Search Path\\nLet’s return to more general module topics. In Chapter 22, we learned that the module\\nsearch path is a list of directories that can be customized via the environment variable\\nPYTHONPATH, and possibly via .pth files. What I haven’t shown you until now is how a\\nPython program itself can actually change the search path by changing the built-in\\n\\n756 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cFigure 25-2. PyDoc’s view of formats.py, obtained by running a “py −3 -m pydoc –b” command line\\nin 3.2 and later and clicking on the file’s index entry (see Chapter 15)\\n\\nsys.path list. Per Chapter 22, sys.path is initialized on startup, but thereafter you can\\ndelete, append, and reset its components however you like:\\n\\n>>> import sys\\n>>> sys.path\\n[\\'\\', \\'c:\\\\\\\\temp\\', \\'C:\\\\\\\\Windows\\\\\\\\system32\\\\\\\\python33.zip\\', ...more deleted...]\\n\\n>>> sys.path.append(\\'C:\\\\\\\\sourcedir\\')         # Extend module search path\\n>>> import string                            # All imports search the new dir last\\n\\nOnce you’ve made such a change, it will impact all future imports anywhere while a\\nPython program runs, as all importers share the same single sys.path list (there’s only\\none copy of a given module in memory during a program’s run—that’s why reload\\nexists). In fact, this list may be changed arbitrarily:\\n\\n>>> sys.path = [r\\'d:\\\\temp\\']                  # Change module search path\\n>>> sys.path.append(\\'c:\\\\\\\\lp5e\\\\\\\\examples\\')    # For this run (process) only\\n>>> sys.path.insert(0, \\'..\\')\\n>>> sys.path\\n[\\'..\\', \\'d:\\\\\\\\temp\\', \\'c:\\\\\\\\lp5e\\\\\\\\examples\\']\\n>>> import string\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nImportError: No module named \\'string\\'\\n\\nThus, you can use this technique to dynamically configure a search path inside a Python\\nprogram. Be careful, though: if you delete a critical directory from the path, you may\\nlose access to critical utilities. In the prior example, for instance, we no longer have\\n\\nChanging the Module Search Path | 757\\n\\n\\x0caccess to the string module because we deleted the Python source library’s directory\\nfrom the path!\\nAlso, remember that such sys.path settings endure for only as long as the Python ses-\\nsion or program (technically, process) that made them runs; they are not retained after\\nPython exits. By contrast, PYTHONPATH and .pth file path configurations live in the op-\\nerating system instead of a running Python program, and so are more global: they are\\npicked up by every program on your machine and live on after a program completes.\\nOn some systems, the former can be per-user and the latter can be installation-wide.\\n\\nThe as Extension for import and from\\nBoth the import and from statements were eventually extended to allow an imported\\nname to be given a different name in your script. We’ve used this extension earlier, but\\nhere are some additional details: the following import statement:\\n\\nimport modulename as name                     # And use name, not modulename\\n\\nis equivalent to the following, which renames the module in the importer’s scope only\\n(it’s still known by its original name to other files):\\n\\nimport modulename\\nname = modulename\\ndel modulename                                # Don\\'t keep original name\\n\\nAfter such an import, you can—and in fact must—use the name listed after the as to\\nrefer to the module. This works in a from statement, too, to assign a name imported\\nfrom a file to a different name in the importer’s scope; as before you get only the new\\nname you provide, not its original:\\n\\nfrom modulename import attrname as name       # And use name, not attrname\\n\\nAs discussed in Chapter 23, this extension is commonly used to provide short syno-\\nnyms for longer names, and to avoid name clashes when you are already using a name\\nin your script that would otherwise be overwritten by a normal import statement:\\n\\nimport reallylongmodulename as name           # Use shorter nickname\\nname.func()\\n\\nfrom module1 import utility as util1          # Can have only 1 \"utility\"\\nfrom module2 import utility as util2\\nutil1(); util2()\\n\\nIt also comes in handy for providing a short, simple name for an entire directory path\\nand  avoiding  name  collisions  when  using  the  package  import  feature  described  in\\nChapter 24:\\n\\nimport dir1.dir2.mod as mod                   # Only list full path once\\nmod.func()\\n\\nfrom dir1.dir2.mod import func as modfunc     # Rename to make unique if needed\\nmodfunc()\\n\\n758 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cThis is also something of a hedge against name changes: if a new release of a library\\nrenames a module or tool your code uses extensively, or provides a new alternative\\nyou’d rather use instead, you can simply rename it to its prior name on import to avoid\\nbreaking your code:\\n\\nimport newname as oldname\\nfrom library import newname as oldname\\n...and keep happily using oldname until you have time to update all your code...\\n\\nFor example, this approach can address some 3.X library changes (e.g., 3.X’s tkinter\\nversus 2.X’s Tkinter), though they’re often substantially more than just a new name!\\n\\nExample: Modules Are Objects\\nBecause modules expose most of their interesting properties as built-in attributes, it’s\\neasy to write programs that manage other programs. We usually call such manager \\nprograms metaprograms because they work on top of other systems. This is also referred\\nto as introspection, because programs can see and process object internals. Introspec-\\ntion is a somewhat advanced feature, but it can be useful for building programming\\ntools.\\nFor instance, to get to an attribute called name in a module called M, we can use attribute\\nqualification  or  index  the  module’s  attribute  dictionary,  exposed  in  the  built-in\\n__dict__ attribute we met in  Chapter 23. Python also exports the list of all loaded\\nmodules as the sys.modules dictionary and provides a built-in called getattr that lets\\nus fetch attributes from their string names—it’s like saying object.attr, but attr is an\\nexpression that yields a string at runtime. Because of that, all the following expressions\\nreach the same attribute and object:1\\n\\nM.name                                        # Qualify object by attribute\\nM.__dict__[\\'name\\']                            # Index namespace dictionary manually\\nsys.modules[\\'M\\'].name                         # Index loaded-modules table manually\\ngetattr(M, \\'name\\')                            # Call built-in fetch function\\n\\nBy exposing module internals like this, Python helps you build programs about pro-\\ngrams. For example, here is a module named mydir.py that puts these ideas to work to\\nimplement a customized version of the built-in dir function. It defines and exports a\\nfunction called listing, which takes a module object as an argument and prints a for-\\nmatted listing of the module’s namespace sorted by name:\\n\\n1. As we saw briefly in “Other Ways to Access Globals” in Chapter 17, because a function can access its\\nenclosing module by going through the sys.modules table like this, it can also be used to emulate the effect\\nof the global statement. For instance, the effect of global X; X=0 can be simulated (albeit with much\\nmore  typing!)  by  saying  this  inside  a  function:  import  sys;  glob=sys.modules[__name__];  glob.X=0.\\nRemember, each module gets a __name__ attribute for free; it’s visible as a global name inside the functions\\nwithin the module. This trick provides another way to change both local and global variables of the same\\nname inside a function.\\n\\nExample: Modules Are Objects\\n\\n| 759\\n\\n\\x0c#!python\\n\"\"\"\\nmydir.py: a module that lists the namespaces of other modules\\n\"\"\"\\nfrom __future__ import print_function  # 2.X compatibility\\n\\nseplen = 60\\nsepchr = \\'-\\'\\n\\ndef listing(module, verbose=True):\\n    sepline = sepchr * seplen\\n    if verbose:\\n        print(sepline)\\n        print(\\'name:\\', module.__name__, \\'file:\\', module.__file__)\\n        print(sepline)\\n\\n    count = 0\\n    for attr in sorted(module.__dict__):      # Scan namespace keys (or enumerate)\\n        print(\\'%02d) %s\\' % (count, attr), end = \\' \\')\\n        if attr.startswith(\\'__\\'):\\n            print(\\'<built-in name>\\')          # Skip __file__, etc.\\n        else:\\n            print(getattr(module, attr))      # Same as .__dict__[attr]\\n        count += 1\\n\\n    if verbose:\\n        print(sepline)\\n        print(module.__name__, \\'has %d names\\' % count)\\n        print(sepline)\\n\\nif __name__ == \\'__main__\\':\\n    import mydir\\n    listing(mydir)                            # Self-test code: list myself\\n\\nNotice the docstring at the top; as in the prior formats.py example, because we may\\nwant to use this as a general tool, the docstring provides functional information acces-\\nsible via help and GUI/browser mode of PyDoc—a tool that uses similar introspection\\ntools to do its job. A self-test is also provided at the bottom of this module, which\\nnarcissistically imports and lists itself. Here’s the sort of output produced in Python\\n3.3; this script works on 2.X too (where it may list fewer names) because it prints from\\nthe __future__:\\n\\nc:\\\\code> py −3 mydir.py\\n------------------------------------------------------------\\nname: mydir file: c:\\\\code\\\\mydir.py\\n------------------------------------------------------------\\n00) __builtins__ <built-in name>\\n01) __cached__ <built-in name>\\n02) __doc__ <built-in name>\\n03) __file__ <built-in name>\\n04) __initializing__ <built-in name>\\n05) __loader__ <built-in name>\\n06) __name__ <built-in name>\\n07) __package__ <built-in name>\\n\\n760 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0c08) listing <function listing at 0x000000000295B488>\\n09) print_function _Feature((2, 6, 0, \\'alpha\\', 2), (3, 0, 0, \\'alpha\\', 0), 65536)\\n10) sepchr -\\n11) seplen 60\\n------------------------------------------------------------\\nmydir has 12 names\\n------------------------------------------------------------\\n\\nTo use this as a tool for listing other modules, simply pass the modules in as objects to\\nthis file’s function. Here it is listing attributes in the tkinter GUI module in the standard\\nlibrary  (a.k.a.  Tkinter  in  Python  2.X);  it  will  technically  work  on  any  object  with\\n__name__, __file__, and __dict__ attributes:\\n\\n>>> import mydir\\n>>> import tkinter\\n>>> mydir.listing(tkinter)\\n------------------------------------------------------------\\nname: tkinter file: C:\\\\Python33\\\\lib\\\\tkinter\\\\__init__.py\\n------------------------------------------------------------\\n00) ACTIVE active\\n01) ALL all\\n02) ANCHOR anchor\\n03) ARC arc\\n04) At <function At at 0x0000000002BD41E0>\\n...many more names omitted...\\n156) image_types <function image_types at 0x0000000002BE2378>\\n157) mainloop <function mainloop at 0x0000000002BCBBF8>\\n158) sys <module \\'sys\\' (built-in)>\\n159) wantobjects 1\\n160) warnings <module \\'warnings\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\warnings.py\\'>\\n------------------------------------------------------------\\ntkinter has 161 names\\n------------------------------------------------------------\\n\\nWe’ll meet getattr and its relatives again later. The point to notice here is that mydir\\nis a program that lets you browse other programs. Because Python exposes its internals,\\nyou can process objects generically.2\\n\\nImporting Modules by Name String\\nThe module name in an import or from statement is a hardcoded variable name. Some-\\ntimes, though, your program will get the name of a module to be imported as a string\\nat runtime—from a user selection in a GUI, or a parse of an XML document, for in-\\nstance. Unfortunately, you can’t use import statements directly to load a module given\\nits name as a string—Python expects a variable name that’s taken literally and not\\nevaluated, not a string or expression. For instance:\\n\\n2. You can preload tools such as mydir.listing and the reloader we’ll meet in a moment into the interactive\\nnamespace by importing them in the file referenced by the PYTHONSTARTUP environment variable. Because\\ncode in the startup file runs in the interactive namespace (module __main__), importing common tools in\\nthe startup file can save you some typing. See Appendix A for more details.\\n\\nImporting Modules by Name String | 761\\n\\n\\x0c>>> import \\'string\\'\\n  File \"<stdin>\", line 1\\n    import \"string\"\\n                  ^\\nSyntaxError: invalid syntax\\n\\nIt also won’t work to simply assign the string to a variable name:\\n\\nx = \\'string\\'\\nimport x\\n\\nHere, Python will try to import a file x.py, not the string module—the name in an\\nimport statement both becomes a variable assigned to the loaded module and identifies\\nthe external file literally.\\n\\nRunning Code Strings\\nTo get around this, you need to use special tools to load a module dynamically from a\\nstring  that  is  generated  at  runtime.  The  most  general  approach  is  to  construct  an\\nimport statement as a string of Python code and pass it to the exec built-in function to\\nrun (exec is a statement in Python 2.X, but it can be used exactly as shown here—the\\nparentheses are simply ignored):\\n\\n>>> modname = \\'string\\'\\n>>> exec(\\'import \\' + modname)      # Run a string of code\\n>>> string                         # Imported in this namespace\\n<module \\'string\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\string.py\\'>\\n\\nWe met the exec function (and its cousin for expressions, eval) earlier, in Chapter 3\\nand Chapter 10. It compiles a string of code and passes it to the Python interpreter to\\nbe executed. In Python, the byte code compiler is available at runtime, so you can write\\nprograms that construct and run other programs like this. By default, exec runs the\\ncode in the current scope, but you can get more specific by passing in optional name-\\nspace dictionaries if needed. It also has security issues noted earlier in the book, which\\nmay be minor in a code string you are building yourself.\\n\\nDirect Calls: Two Options\\nThe only real drawback to exec here is that it must compile the import statement each\\ntime it runs, and compiling can be slow. Precompiling to byte code with the compile\\nbuilt-in  may  help  for  code  strings  run  many  times,  but  in  most  cases  it’s  probably\\nsimpler and may run quicker to use the built-in __import__ function to load from a\\nname string instead, as noted in Chapter 22. The effect is similar, but __import__ returns\\nthe module object, so assign it to a name here to keep it:\\n\\n>>> modname = \\'string\\'\\n>>> string = __import__(modname)\\n>>> string\\n<module \\'string\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\string.py\\'>\\n\\n762 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cAs also noted in Chapter 22, the newer call importlib.import_module does the same\\nwork, and is generally preferred in more recent Pythons for direct calls to import by\\nname string—at least per the current “official” policy stated in Python’s manuals:\\n\\n>>> import importlib\\n>>> modname = \\'string\\'\\n>>> string = importlib.import_module(modname)\\n>>> string\\n<module \\'string\\' from \\'C:\\\\\\\\Python33\\\\\\\\lib\\\\\\\\string.py\\'>\\n\\nThe import_module call takes a module name string, and an optional second argument\\nthat gives the package used as the anchor point for resolving relative imports, which\\ndefaults  to  None.  This  call  works  the  same  as  __import__  in  its  basic  roles,  but  see\\nPython’s manuals for more details.\\nThough  both  calls  still  work,  in  Pythons  where  both  are  available,  the  original\\n__import__ is generally intended for customizing import operations by reassignment in\\nthe built-in scope (and any future changes in “official” policy are beyond the scope of \\nthis book!).\\n\\nExample: Transitive Module Reloads\\nThis section develops a module tool that ties together and applies some earlier topics,\\nand serves as a larger case study to close out this chapter and part. We studied module\\nreloads in Chapter 23, as a way to pick up changes in code without stopping and re-\\nstarting a program. When you reload a module, though, Python reloads only that par-\\nticular module’s file; it doesn’t automatically reload modules that the file being reloaded\\nhappens to import.\\nFor example, if you reload some module A, and A imports modules B and C, the reload\\napplies only to A, not to B and C. The statements inside A that import B and C are rerun\\nduring the reload, but they just fetch the already loaded B and C module objects (as-\\nsuming they’ve been imported before). In actual yet abstract code, here’s the file A.py:\\n\\n# A.py\\nimport B                   # Not reloaded when A is!\\nimport C                   # Just an import of an already loaded module: no-ops\\n\\n% python\\n>>> . . .\\n>>> from imp import reload\\n>>> reload(A)\\n\\nBy default, this means that you cannot depend on reloads to pick up changes in all the\\nmodules in your program transitively—instead, you must use multiple reload calls to\\nupdate the subcomponents independently. This can require substantial work for large\\nsystems you’re testing interactively. You can design your systems to reload their sub-\\ncomponents automatically by adding reload calls in parent modules like A, but this\\ncomplicates the modules’ code.\\n\\nExample: Transitive Module Reloads\\n\\n| 763\\n\\n\\x0cA Recursive Reloader\\nA better approach is to write a general tool to do transitive reloads automatically by\\nscanning modules’ __dict__ namespace attributes and checking each item’s type to\\nfind nested modules to reload. Such a utility function could call itself recursively to\\nnavigate arbitrarily shaped and deep import dependency chains. Module __dict__ at-\\ntributes were introduced in Chapter 23 and employed earlier in this chapter, and the\\ntype call was presented in Chapter 9; we just need to combine the two tools.\\nThe module reloadall.py listed next defines a reload_all function that automatically\\nreloads a module, every module that the module imports, and so on, all the way to the\\nbottom of each import chain. It uses a dictionary to keep track of already reloaded\\nmodules, recursion to walk the import chains, and the standard library’s types module,\\nwhich simply predefines type results for built-in types. The visited dictionary techni-\\nque works to avoid cycles here when imports are recursive or redundant, because mod-\\nule objects are immutable and so can be dictionary keys; as we learned in Chapter 5\\nand Chapter 8, a set would offer similar functionality if we use visited.add(module) to\\ninsert:\\n\\n#!python\\n\"\"\"\\nreloadall.py: transitively reload nested modules (2.X + 3.X).\\nCall reload_all with one or more imported module module objects.\\n\"\"\"\\n\\nimport types\\nfrom imp import reload                                   # from required in 3.X\\n\\ndef status(module):\\n    print(\\'reloading \\' + module.__name__)\\n\\ndef tryreload(module):\\n    try:\\n        reload(module)                                   # 3.3 (only?) fails on some\\n    except:\\n        print(\\'FAILED: %s\\' % module)\\n\\ndef transitive_reload(module, visited):\\n    if not module in visited:                            # Trap cycles, duplicates\\n        status(module)                                   # Reload this module\\n        tryreload(module)                                # And visit children\\n        visited[module] = True\\n        for attrobj in module.__dict__.values():         # For all attrs\\n            if type(attrobj) == types.ModuleType:        # Recur if module\\n                transitive_reload(attrobj, visited)\\n\\ndef reload_all(*args):\\n    visited = {}                                         # Main entry point\\n    for arg in args:                                     # For all passed in\\n        if type(arg) == types.ModuleType:\\n            transitive_reload(arg, visited)\\n\\n764 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cdef tester(reloader, modname):                           # Self-test code\\n    import importlib, sys                                # Import on tests only\\n    if len(sys.argv) > 1: modname = sys.argv[1]          # command line (or passed)\\n    module  = importlib.import_module(modname)           # Import by name string\\n    reloader(module)                                     # Test passed-in reloader\\n\\nif __name__ == \\'__main__\\':\\n    tester(reload_all, \\'reloadall\\')                      # Test: reload myself?\\n\\nBesides namespace dictionaries, this script makes use of other tools we’ve studied here:\\nit includes a __name__ test to launch self-test code when run as a top-level script only,\\nand its tester function uses sys.argv to inspect command-line arguments and impor\\ntlib to import a module by name string passed in as a function or command-line ar-\\ngument. One curious bit: notice how this code must wrap the basic reload call in a\\ntry statement to catch exceptions—in Python 3.3, reloads sometimes fail due to a re-\\nwrite of the import machinery. The try was previewed in Chapter 10, and is covered\\nin full in Part VII.\\n\\nTesting recursive reloads\\nNow, to leverage this utility for normal use, import its reload_all function and pass it\\nan already loaded module object—just as you would for the built-in reload function.\\nWhen the file runs standalone, its self-test code calls reload_all automatically, reload-\\ning its own module by default if no command-line arguments are used. In this mode,\\nthe module must import itself because its own name is not defined in the file without\\nan import. This code works in both 3.X and 2.X because we’ve used + and % instead of\\na comma in the prints, though the set of modules used and thus reloaded may vary\\nacross lines:\\n\\nC:\\\\code> c:\\\\Python33\\\\python reloadall.py\\nreloading reloadall\\nreloading types\\n\\nc:\\\\code> C:\\\\Python27\\\\python reloadall.py\\nreloading reloadall\\nreloading types\\n\\nWith a command-line argument, the tester instead reloads the given module by its name\\nstring—here, the benchmark module we coded in Chapter 21. Note that we give a\\nmodule name in this mode, not a filename (as for import statements, don’t include\\nthe .py extension); the script ultimately imports the module using the module search\\npath as usual:\\n\\nc:\\\\code> reloadall.py pybench\\nreloading pybench\\nreloading timeit\\nreloading itertools\\nreloading sys\\nreloading time\\nreloading gc\\nreloading os\\n\\nExample: Transitive Module Reloads\\n\\n| 765\\n\\n\\x0creloading errno\\nreloading ntpath\\nreloading stat\\nreloading genericpath\\nreloading copyreg\\n\\nPerhaps most commonly, we can also deploy this module at the interactive prompt—\\nhere,  in  3.3  for  some  standard  library  modules.  Notice  how  os  is  imported  by\\ntkinter, but tkinter reaches sys before os can (if you want to test this on Python 2.X,\\nsubstitute Tkinter for tkinter):\\n\\n>>> from reloadall import reload_all\\n>>> import os, tkinter\\n>>> reload_all(os)                        # Normal usage mode\\nreloading os\\nreloading ntpath\\nreloading stat\\nreloading sys\\nreloading genericpath\\nreloading errno\\nreloading copyreg\\n\\n>>> reload_all(tkinter)\\nreloading tkinter\\nreloading _tkinter\\nreloading warnings\\nreloading sys\\nreloading linecache\\nreloading tokenize\\nreloading builtins\\nFAILED: <module \\'builtins\\'>\\nreloading re\\n...etc...\\nreloading os\\nreloading ntpath\\nreloading stat\\nreloading genericpath\\nreloading errno\\n...etc...\\n\\nAnd finally here is a session that shows the effect of normal versus transitive reloads—\\nchanges made to the two nested files are not picked up by reloads, unless the transitive\\nutility is used:\\n\\nimport b     # File a.py\\nX = 1\\n\\nimport c     # File b.py\\nY = 2\\n\\nZ = 3        # File c.py\\n\\nC:\\\\code> py −3\\n>>> import a\\n>>> a.X, a.b.Y, a.b.c.Z\\n\\n766 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0c(1, 2, 3)\\n\\n# Without stopping Python, change all three files\\' assignment values and save\\n\\n>>> from imp import reload\\n>>> reload(a)                             # Built-in reload is top level only\\n<module \\'a\\' from \\'.\\\\\\\\a.py\\'>\\n>>> a.X, a.b.Y, a.b.c.Z\\n(111, 2, 3)\\n\\n>>> from reloadall import reload_all\\n>>> reload_all(a)                         # Normal usage mode\\nreloading a\\nreloading b\\nreloading c\\n>>> a.X, a.b.Y, a.b.c.Z                   # Reloads all nested modules too\\n(111, 222, 333)\\n\\nStudy the reloader’s code and results for more on its operation. The next section exer-\\ncises its tools further.\\n\\nAlternative Codings\\nFor all the recursion fans in the audience, the following lists an alternative recursive\\ncoding for the function in the prior section—it uses a set instead of a dictionary to detect\\ncycles, is marginally more direct because it eliminates a top-level loop, and serves to\\nillustrate recursive function techniques in general (compare with the original to see how\\nthis differs). This version also gets some of its work for free from the original, though\\nthe order in which it reloads modules might vary if namespace dictionary order does\\ntoo:\\n\\n\"\"\"\\nreloadall2.py: transitively reload nested modules (alternative coding)\\n\"\"\"\\n\\nimport types\\nfrom imp import reload                              # from required in 3.X\\nfrom reloadall import status, tryreload, tester\\n\\ndef transitive_reload(objects, visited):\\n    for obj in objects:\\n        if type(obj) == types.ModuleType and obj not in visited:\\n            status(obj)\\n            tryreload(obj)                          # Reload this, recur to attrs\\n            visited.add(obj)\\n            transitive_reload(obj.__dict__.values(), visited)\\n\\ndef reload_all(*args):\\n    transitive_reload(args, set())\\n\\nif __name__ == \\'__main__\\':\\n    tester(reload_all, \\'reloadall2\\')                # Test code: reload myself?\\n\\nExample: Transitive Module Reloads\\n\\n| 767\\n\\n\\x0cAs we saw in Chapter 19, there is usually an explicit stack or queue equivalent to most\\nrecursive functions, which may be preferable in some contexts. The following is one\\nsuch transitive reloader; it uses a generator expression to filter out nonmodules and\\nmodules already visited in the current module’s namespace. Because it both pops and\\nadds items at the end of its list, it is stack based, though the order of both pushes and\\ndictionary values influences the order in which it reaches and reloads modules—it visits\\nsubmodules in namespace dictionaries from right to left, unlike the left-to-right order\\nof the recursive versions (trace through the code to see how). We could change this,\\nbut dictionary order is arbitrary anyhow.\\n\\n\"\"\"\\nreloadall3.py: transitively reload nested modules (explicit stack)\\n\"\"\"\\n\\nimport types\\nfrom imp import reload                              # from required in 3.X\\nfrom reloadall import status, tryreload, tester\\n\\ndef transitive_reload(modules, visited):\\n    while modules:\\n        next = modules.pop()                        # Delete next item at end\\n        status(next)                                # Reload this, push attrs\\n        tryreload(next)\\n        visited.add(next)\\n        modules.extend(x for x in next.__dict__.values()\\n            if type(x) == types.ModuleType and x not in visited)\\n\\ndef reload_all(*modules):\\n    transitive_reload(list(modules), set())\\n\\nif __name__ == \\'__main__\\':\\n    tester(reload_all, \\'reloadall3\\')                # Test code: reload myself?\\n\\nIf the recursion and nonrecursion used in this example is confusing, see the discussion\\nof recursive functions in Chapter 19 for background on the subject.\\n\\nTesting reload variants\\nTo prove that these work the same, let’s test all three of our reloader variants. Thanks\\nto their common testing function, we can run all three from a command line both with\\nno arguments to test the module reloading itself, and with the name of a module to be\\nreloaded listed on the command line (in sys.argv):\\n\\nc:\\\\code> reloadall.py\\nreloading reloadall\\nreloading types\\n\\nc:\\\\code> reloadall2.py\\nreloading reloadall2\\nreloading types\\n\\nc:\\\\code> reloadall3.py\\n\\n768 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0creloading reloadall3\\nreloading types\\n\\nThough it’s hard to see here, we really are testing the individual reloader alternatives\\n—each of these tests shares a common tester function, but passes it the reload_all\\nfrom its own file. Here are the variants reloading the 3.X tkinter GUI module and all\\nthe modules its imports reach:\\nc:\\\\code> reloadall.py tkinter\\nreloading tkinter\\nreloading _tkinter\\nreloading tkinter._fix\\n...etc...\\nc:\\\\code> reloadall2.py tkinter\\nreloading tkinter\\nreloading tkinter.constants\\nreloading tkinter._fix\\n...etc...\\nc:\\\\code> reloadall3.py tkinter\\nreloading tkinter\\nreloading sys\\nreloading tkinter.constants\\n...etc...\\n\\nAll three work on both Python 3.X and 2.X too—they’re careful to unify prints with\\nformatting, and avoid using version-specific tools (though you must use 2.X module\\nnames like Tkinter, and I’m using the 3.3 Windows launcher here to run per Appen-\\ndix B):\\n\\nc:\\\\code> py −2 reloadall.py\\nreloading reloadall\\nreloading types\\n\\nc:\\\\code> py −2 reloadall2.py Tkinter\\nreloading Tkinter\\nreloading _tkinter\\nreloading FixTk\\n...etc...\\n\\nAs usual we can test interactively, too, by importing and calling either a module’s main\\nreload entry point with a module object, or the testing function with a reloader function\\nand module name string:\\n\\nC:\\\\code> py −3\\n>>> import reloadall, reloadall2, reloadall3\\n>>> import tkinter\\n>>> reloadall.reload_all(tkinter)                           # Normal use case\\nreloading tkinter\\nreloading tkinter._fix\\nreloading os\\n...etc...\\n>>> reloadall.tester(reloadall2.reload_all, \\'tkinter\\')      # Testing utility\\nreloading tkinter\\nreloading tkinter._fix\\nreloading os\\n\\nExample: Transitive Module Reloads\\n\\n| 769\\n\\n\\x0c...etc...\\n>>> reloadall.tester(reloadall3.reload_all, \\'reloadall3\\')   # Mimic self-test code\\nreloading reloadall3\\nreloading types\\n\\nFinally, if you look at the output of tkinter reloads earlier, you may notice that each\\nof the three variants may produce results in a different order; they all depend on name-\\nspace dictionary ordering, and the last also relies on the order in which items are added\\nto its stack. In fact, under Python 3.3, the reload order for a given reloader can vary\\nfrom run to run. To ensure that all three are reloading the same modules irrespective\\nof the order in which they do so, we can use sets (or sorts) to test for order-neutral\\nequality of their printed messages—obtained here by running shell commands with the\\nos.popen utility we met in Chapter 13 and used in Chapter 21:\\n\\n>>> import os\\n>>> res1 = os.popen(\\'reloadall.py tkinter\\').read()\\n>>> res2 = os.popen(\\'reloadall2.py tkinter\\').read()\\n>>> res3 = os.popen(\\'reloadall3.py tkinter\\').read()\\n>>> res1[:75]\\n\\'reloading tkinter\\\\nreloading tkinter.constants\\\\nreloading tkinter._fix\\\\nreload\\'\\n\\n>>> res1 == res2, res2 == res3\\n(False, False)\\n>>> set(res1) == set(res2), set(res2) == set(res3)\\n(True, True)\\n\\nRun these scripts, study their code, and experiment on your own for more insight; these\\nare the sort of importable tools you might want to add to your own source code library.\\nWatch  for  a  similar  testing  technique  in  the  coverage  of  class  tree  listers  in  Chap-\\nter 31, where we’ll apply it to passed class objects and extend it further.\\nAlso keep in mind that all three variants reload only modules that were loaded with\\nimport statements—since names copied with from statements do not cause a module\\nto be nested and referenced in the importer’s namespace, their containing module is\\nnot reloaded. More fundamentally, the transitive reloaders rely on the fact that module\\nreloads update module objects in place, such that all references to those modules in any\\nscope will see the updated version automatically. Because they copy names out, from\\nimporters  are  not  updated  by  reloads—transitive  or  not—and  supporting  this  may\\nrequire  either  source  code  analysis,  or  customization  of  the  import  operation  (see\\nChapter 22 for pointers).\\nTool  impacts  like  this  are  perhaps  another  reason  to  prefer  import  to  from—which\\nbrings us to the end of this chapter and part, and the standard set of warnings for this \\npart’s topic.\\n\\nModule Gotchas\\nIn this section, we’ll take a look at the usual collection of boundary cases that can make\\nlife interesting for Python beginners. Some are review here, and a few are so obscure\\n\\n770 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cthat coming up with representative examples can be a challenge, but most illustrate\\nsomething important about the language.\\n\\nModule Name Clashes: Package and Package-Relative Imports\\nIf you have two modules of the same name, you may only be able to import one of them\\n—by default, the one whose directory is leftmost in the sys.path module search path\\nwill always be chosen. This isn’t an issue if the module you prefer is in your top-level\\nscript’s  directory;  since  that  is  always  first  in  the  module  path,  its  contents  will  be\\nlocated first automatically. For cross-directory imports, however, the linear nature of\\nthe module search path means that same-named files can clash.\\nTo  fix,  either  avoid  same-named  files  or  use  the  package  imports  feature  of  Chap-\\nter 24. If you need to get to both same-named files, structure your source files in sub-\\ndirectories,  such  that  package  import  directory  names  make  the  module  references\\nunique. As long as the enclosing package directory names are unique, you’ll be able to\\naccess either or both of the same-named modules.\\nNote that this issue can also crop up if you accidentally use a name for a module of\\nyour own that happens to be the same as a standard library module you need—your\\nlocal module in the program’s home directory (or another directory early in the module\\npath) can hide and replace the library module.\\nTo fix, either avoid using the same name as another module you need or store your\\nmodules in a package directory and use Python 3.X’s package-relative import model,\\navailable in 2.X as an option. In this model, normal imports skip the package directory\\n(so you’ll get the library’s version), but special dotted import statements can still select\\nthe local version of the module if needed.\\n\\nStatement Order Matters in Top-Level Code\\nAs  we’ve  seen,  when  a  module  is  first  imported  (or  reloaded),  Python  executes  its\\nstatements one by one, from the top of the file to the bottom. This has a few subtle\\nimplications regarding forward references that are worth underscoring here:\\n\\n• Code at the top level of a module file (not nested in a function) runs as soon as\\nPython reaches it during an import; because of that, it cannot reference names\\nassigned lower in the file.\\n\\n• Code inside a function body doesn’t run until the function is called; because names\\nin a function aren’t resolved until the function actually runs, they can usually ref-\\nerence names anywhere in the file.\\n\\nGenerally, forward references are only a concern in top-level module code that executes\\nimmediately;  functions  can  reference  names  arbitrarily.  Here’s  a  file  that  illustrates\\nforward reference dos and don’ts:\\n\\nModule Gotchas\\n\\n| 771\\n\\n\\x0cfunc1()                           # Error: \"func1\" not yet assigned\\n\\ndef func1():\\n    print(func2())                # OK: \"func2\" looked up later\\n\\nfunc1()                           # Error: \"func2\" not yet assigned\\n\\ndef func2():\\n    return \"Hello\"\\n\\nfunc1()                           # OK: \"func1\" and \"func2\" assigned\\n\\nWhen this file is imported (or run as a standalone program), Python executes its state-\\nments from top to bottom. The first call to func1 fails because the func1 def hasn’t run\\nyet. The call to func2 inside func1 works as long as func2’s def has been reached by the\\ntime func1 is called—and it hasn’t when the second top-level func1 call is run. The last\\ncall to func1 at the bottom of the file works because func1 and func2 have both been\\nassigned.\\nMixing defs with top-level code is not only difficult to read, it’s also dependent on\\nstatement ordering. As a rule of thumb, if you need to mix immediate code with defs,\\nput your defs at the top of the file and your top-level code at the bottom. That way,\\nyour functions are guaranteed to be defined and assigned by the time Python runs the\\ncode that uses them.\\n\\nfrom Copies Names but Doesn’t Link\\nAlthough it’s commonly used, the from statement is the source of a variety of potential\\ngotchas in Python. As we’ve learned, the from statement is really an assignment to names\\nin the importer’s scope—a name-copy operation, not a name aliasing. The implications\\nof this are the same as for all assignments in Python, but they’re subtle, especially given\\nthat the code that shares the objects lives in different files. For instance, suppose we\\ndefine the following module, nested1.py:\\n\\n# nested1.py\\nX = 99\\ndef printer(): print(X)\\n\\nIf we import its two names using from in another module, nested2.py, we get copies of\\nthose names, not links to them. Changing a name in the importer resets only the binding\\nof the local version of that name, not the name in nested1.py:\\n\\n# nested2.py\\nfrom nested1 import X, printer    # Copy names out\\nX = 88                            # Changes my \"X\" only!\\nprinter()                         # nested1\\'s X is still 99\\n\\n% python nested2.py\\n99\\n\\n772 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cIf we use import to get the whole module and then assign to a qualified name, however,\\nwe change the name in nested1.py. Attribute qualification directs Python to a name in\\nthe module object, rather than a name in the importer, nested3.py:\\n\\n# nested3.py\\nimport nested1                    # Get module as a whole\\nnested1.X = 88                    # OK: change nested1\\'s X\\nnested1.printer()\\n\\n% python nested3.py\\n88\\n\\nfrom * Can Obscure the Meaning of Variables\\nI mentioned this earlier but saved the details for here. Because you don’t list the vari-\\nables you want when using the from module import * statement form, it can accidentally\\noverwrite names you’re already using in your scope. Worse, it can make it difficult to\\ndetermine where a variable comes from. This is especially true if the from * form is used\\non more than one imported file.\\nFor example, if you use from * on three modules in the following, you’ll have no way\\nof knowing what a raw function call really means, short of searching all three external\\nmodule files—all of which may be in other directories:\\n\\n>>> from module1 import *          # Bad: may overwrite my names silently\\n>>> from module2 import *          # Worse: no way to tell what we get!\\n>>> from module3 import *\\n>>> . . .\\n\\n>>> func()                         # Huh???\\n\\nThe solution again is not to do this: try to explicitly list the attributes you want in your\\nfrom statements, and restrict the from * form to at most one imported module per file.\\nThat way, any undefined names must by deduction be in the module named in the\\nsingle from *. You can avoid the issue altogether if you always use import instead of\\nfrom, but that advice is too harsh; like much else in programming, from is a convenient\\ntool if used wisely. Even this example isn’t an absolute evil—it’s OK for a program to\\nuse this technique to collect names in a single space for convenience, as long as it’s well\\nknown.\\n\\nreload May Not Impact from Imports\\nHere’s another from-related gotcha: as discussed previously, because from copies (as-\\nsigns) names when run, there’s no link back to the modules where the names came\\nfrom. Names imported with from simply become references to objects, which happen\\nto have been referenced by the same names in the importee when the from ran.\\n\\nModule Gotchas\\n\\n| 773\\n\\n\\x0cBecause of this behavior, reloading the importee has no effect on clients that import its\\nnames using from. That is, the client’s names will still reference the original objects\\nfetched with from, even if the names in the original module are later reset:\\n\\nfrom module import X          # X may not reflect any module reloads!\\n . . .\\nfrom imp import reload\\nreload(module)                # Changes module, but not my names\\nX                             # Still references old object\\n\\nTo make reloads more effective, use import and name qualification instead of from.\\nBecause qualifications always go back to the module, they will find the new bindings\\nof module names after reloading has updated the module’s content in place:\\n\\nimport module                 # Get module, not names\\n . . .\\nfrom imp import reload\\nreload(module)                # Changes module in place\\nmodule.X                      # Get current X: reflects module reloads\\n\\nAs a related consequence, our transitive reloader earlier in this chapter doesn’t apply\\nto names fetched with from, only import; again, if you’re going to use reloads, you’re\\nprobably better off with import.\\n\\nreload, from, and Interactive Testing\\nIn fact, the prior gotcha is even more subtle than it appears. Chapter 3 warned that it’s\\nusually better not to launch programs with imports and reloads because of the com-\\nplexities involved. Things get even worse when from is brought into the mix. Python\\nbeginners most often stumble onto its issues in scenarios like this—imagine that after\\nopening a module file in a text edit window, you launch an interactive session to load\\nand test your module with from:\\n\\nfrom module import function\\nfunction(1, 2, 3)\\n\\nFinding a bug, you jump back to the edit window, make a change, and try to reload\\nthe module this way:\\n\\nfrom imp import reload\\nreload(module)\\n\\nThis doesn’t work, because the from statement assigned only the name function, not\\nmodule. To refer to the module in a reload, you have to first bind its name with an\\nimport statement at least once:\\n\\nfrom imp import reload\\nimport module\\nreload(module)\\nfunction(1, 2, 3)\\n\\nHowever, this doesn’t quite work either—reload updates the module object in place,\\nbut as discussed in the preceding section, names like function that were copied out of\\n\\n774 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cthe module in the past still refer to the old objects; in this instance, function is still the\\noriginal version of the function. To really get the new function, you must refer to it as\\nmodule.function after the reload, or rerun the from:\\n\\nfrom imp import reload\\nimport module\\nreload(module)\\nfrom module import function        # Or give up and use module.function()\\nfunction(1, 2, 3)\\n\\nNow, the new version of the function will finally run, but it seems an awful lot of work\\nto get there.\\nAs you can see, there are problems inherent in using reload with from: not only do you\\nhave to remember to reload after imports, but you also have to remember to rerun your\\nfrom statements after reloads. This is complex enough to trip up even an expert once\\nin a while. In fact, the situation has gotten even worse in Python 3.X, because you must\\nalso remember to import reload itself!\\nThe short story is that you should not expect reload and from to play together nicely.\\nAgain, the best policy is not to combine them at all—use reload with import, or launch\\nyour programs other ways, as suggested in Chapter 3: using the Run→Run Module\\nmenu option in IDLE, file icon clicks, system command lines, or the  exec built-in \\nfunction.\\n\\nRecursive from Imports May Not Work\\nI saved the most bizarre (and, thankfully, obscure) gotcha for last. Because imports\\nexecute a file’s statements from top to bottom, you need to be careful when using\\nmodules that import each other. This is often called recursive imports, but the recursion\\ndoesn’t really occur (in fact, circular may be a better term here)—such imports won’t\\nget stuck in infinite importing loops. Still, because the statements in a module may not\\nall have been run when it imports another module, some of its names may not yet exist.\\nIf you use import to fetch the module as a whole, this probably doesn’t matter; the\\nmodule’s names won’t be accessed until you later use qualification to fetch their values,\\nand by that time the module is likely complete. But if you use from to fetch specific\\nnames, you must bear in mind that you will only have access to names in that module\\nthat have already been assigned when a recursive import is kicked off.\\nFor instance, consider the following modules, recur1 and recur2. recur1 assigns a name\\nX, and then imports recur2 before assigning the name Y. At this point, recur2 can fetch\\nrecur1 as a whole with an import—it already exists in Python’s internal modules table,\\nwhich makes it importable, and also prevents the imports from looping. But if recur2\\nuses from, it will be able to see only the name X; the name Y, which is assigned below\\nthe import in recur1, doesn’t yet exist, so you get an error:\\n\\n# recur1.py\\nX = 1\\n\\nModule Gotchas\\n\\n| 775\\n\\n\\x0cimport recur2                             # Run recur2 now if it doesn\\'t exist\\nY = 2\\n\\n# recur2.py\\nfrom recur1 import X                      # OK: \"X\" already assigned\\nfrom recur1 import Y                      # Error: \"Y\" not yet assigned\\n\\nC:\\\\code> py −3\\n>>> import recur1\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \".\\\\recur1.py\", line 2, in <module>\\n    import recur2\\n  File \".\\\\recur2.py\", line 2, in <module>\\n    from recur1 import Y\\nImportError: cannot import name Y\\n\\nPython avoids rerunning recur1’s statements when they are imported recursively from\\nrecur2 (otherwise the imports would send the script into an infinite loop that might\\nrequire a Ctrl-C solution or worse), but recur1’s namespace is incomplete when it’s\\nimported by recur2.\\nThe solution? Don’t use from in recursive imports (no, really!). Python won’t get stuck\\nin a cycle if you do, but your programs will once again be dependent on the order of\\nthe statements in the modules. In fact, there are two ways out of this gotcha:\\n\\n• You can usually eliminate import cycles like this by careful design—maximizing\\n\\ncohesion and minimizing coupling are good first steps.\\n\\n• If you can’t break the cycles completely, postpone module name accesses by using\\nimport and attribute qualification (instead of from and direct names), or by running\\nyour froms either inside functions (instead of at the top level of the module) or near\\nthe bottom of your file to defer their execution.\\n\\nThere is additional perspective on this issue in the exercises at the end of this chapter\\n—which we’ve officially reached.\\n\\nChapter Summary\\nThis chapter surveyed some more advanced module-related concepts. We studied data\\nhiding techniques, enabling new language features with the __future__ module, the\\n__name__ usage mode variable, transitive reloads, importing by name strings, and more.\\nWe also explored and summarized module design issues, wrote some more substantial\\nprograms, and looked at common mistakes related to modules to help you avoid them\\nin your code.\\nThe next chapter begins our look at Python’s class—its object-oriented programming\\ntool. Much of what we’ve covered in the last few chapters will apply there, too: classes\\nlive in modules and are namespaces as well, but they add an extra component to at-\\ntribute lookup called inheritance search. As this is the last chapter in this part of the\\n\\n776 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cbook, however, before we dive into that topic, be sure to work through this part’s set\\nof lab exercises. And before that, here is this chapter’s quiz to review the topics covered\\nhere.\\n\\nTest Your Knowledge: Quiz\\n1. What is significant about variables at the top level of a module whose names begin\\n\\nwith a single underscore?\\n\\n2. What does it mean when a module’s __name__ variable is the string \"__main__\"?\\n3. If the user interactively types the name of a module to test, how can your code\\n\\nimport it?\\n\\n4. How is changing sys.path different from setting PYTHONPATH to modify the module\\n\\nsearch path?\\n\\n5. If the module __future__ allows us to import from the future, can we also import\\n\\nfrom the past?\\n\\nTest Your Knowledge: Answers\\n1. Variables at the top level of a module whose names begin with a single underscore\\nare not copied out to the importing scope when the from * statement form is used.\\nThey can still be accessed by an import or the normal from statement form, though.\\nThe __all__ list is similar, but the logical converse; its contents are the only names\\nthat are copied out on a from *.\\n\\n2. If a module’s __name__ variable is the string \"__main__\", it means that the file is\\nbeing executed as a top-level script instead of being imported from another file in\\nthe program. That is, the file is being used as a program, not a library. This usage\\nmode variable supports dual-mode code and tests.\\n\\n3. User input usually comes into a script as a string; to import the referenced module\\ngiven its string name, you can build and run an import statement with exec, or pass\\nthe string name in a call to the __import__ or importlib.import_module.\\n\\n4. Changing sys.path only affects one running program (process), and is temporary\\n—the change goes away when the program ends. PYTHONPATH settings live in the\\noperating system—they are picked up globally by all your programs on a machine,\\nand changes to these settings endure after programs exit.\\n\\n5. No, we can’t import from the past in Python. We can install (or stubbornly use)\\nan older version of the language, but the latest Python is generally the best Python\\n(at least within lines—see 2.X longevity!).\\n\\nTest Your Knowledge: Answers\\n\\n| 777\\n\\n\\x0cTest Your Knowledge: Part V Exercises\\nSee Part V in Appendix D for the solutions.\\n\\n1. Import basics. Write a program that counts the lines and characters in a file (similar\\nin spirit to part of what wc does on Unix). With your text editor, code a Python\\nmodule called mymod.py that exports three top-level names:\\n\\n• A countLines(name) function that reads an input file and counts the number\\nof lines in it (hint: file.readlines does most of the work for you, and len does\\nthe rest, though you could count with for and file iterators to support massive\\nfiles too).\\n\\n• A countChars(name) function that reads an input file and counts the number\\nof characters in it (hint: file.read returns a single string, which may be used\\nin similar ways).\\n\\n• A test(name) function that calls both counting functions with a given input\\nfilename. Such a filename generally might be passed in, hardcoded, input with\\nthe input built-in function, or pulled from a command line via the sys.argv\\nlist shown in this chapter’s formats.py and reloadall.py examples; for now, you\\ncan assume it’s a passed-in function argument.\\n\\nAll three mymod functions should expect a filename string to be passed in. If you\\ntype more than two or three lines per function, you’re working much too hard—\\nuse the hints I just gave!\\nNext, test your module interactively, using import and attribute references to fetch\\nyour exports. Does your PYTHONPATH need to include the directory where you created\\nmymod.py?  Try  running  your  module  on  itself:  for  example,  test(\"mymod.py\").\\nNote that test opens the file twice; if you’re feeling ambitious, you may be able to\\nimprove this by passing an open file object into the two count functions (hint:\\nfile.seek(0) is a file rewind).\\n\\n2. from/from *. Test your mymod module from exercise 1 interactively by using from to\\nload  the  exports  directly,  first  by  name,  then  using  the  from  *  variant  to  fetch\\neverything.\\n\\n3. __main__. Add a line in your mymod module that calls the test function automati-\\ncally only when the module is run as a script, not when it is imported. The line you\\nadd will probably test the value of __name__ for the string \"__main__\", as shown in\\nthis chapter. Try running your module from the system command line; then, im-\\nport  the  module  and  test  its  functions  interactively.  Does  it  still  work  in  both\\nmodes?\\n\\n4. Nested imports. Write a second module, myclient.py, that imports mymod and tests\\nits functions; then run myclient from the system command line. If myclient uses\\nfrom to fetch from mymod, will mymod’s functions be accessible from the top level of\\nmyclient? What if it imports with import instead? Try coding both variations in\\n\\n778 | Chapter 25:\\u2002Advanced Module Topics\\n\\n\\x0cmyclient and test interactively by importing myclient and inspecting its __dict__\\nattribute.\\n\\n5. Package imports. Import your file from a package. Create a subdirectory called\\nmypkg nested in a directory on your module import search path, copy or move the\\nmymod.py module file you created in exercise 1 or 3 into the new directory, and\\ntry to import it with a package import of the form import mypkg.mymod and call its\\nfunctions. Try to fetch your counter functions with a from too.\\nYou’ll need to add an __init__.py file in the directory your module was moved to\\nmake this go, but it should work on all major Python platforms (that’s part of the\\nreason Python uses “.” as a path separator). The package directory you create can\\nbe simply a subdirectory of the one you’re working in; if it is, it will be found via\\nthe home directory component of the search path, and you won’t have to configure\\nyour path. Add some code to your __init__.py, and see if it runs on each import.\\n6. Reloads.  Experiment  with  module  reloads:  perform  the  tests  in  Chapter  23’s\\nchanger.py example, changing the called function’s message and/or behavior re-\\npeatedly, without stopping the Python interpreter. Depending on your system, you\\nmight be able to edit changer in another window, or suspend the Python interpreter\\nand edit in the same window (on Unix, a Ctrl-Z key combination usually suspends\\nthe current process, and an fg command later resumes it, though a text edit window\\nprobably works just as well).\\n\\n7. Circular imports. In the section on recursive (a.k.a. circular) import gotchas, im-\\nporting recur1 raised an error. But if you restart Python and import recur2 inter-\\nactively, the error doesn’t occur—test this and see for yourself. Why do you think\\nit works to import recur2, but not recur1? (Hint: Python stores new modules in\\nthe built-in sys.modules table—a dictionary—before running their code; later im-\\nports fetch the module from this table first, whether the module is “complete” yet\\nor not.) Now, try running recur1 as a top-level script file: python recur1.py. Do\\nyou get the same error that occurs when recur1 is imported interactively? Why?\\n(Hint: when modules are run as programs, they aren’t imported, so this case has\\nthe same effect as importing recur2 interactively; recur2 is the first module impor-\\nted.) What happens when you run recur2 as a script? Circular imports are uncom-\\nmon and rarely this bizarre in practice. On the other hand, if you can understand\\nwhy they are a potential problem, you know a lot about Python’s import semantics.\\n\\nTest Your Knowledge: Part V Exercises\\n\\n| 779\\n\\n\\x0c\\x0cPART VI\\nClasses and OOP\\n\\n\\x0c\\x0cCHAPTER 26\\nOOP: The Big Picture\\n\\nSo far in this book, we’ve been using the term “object” generically. Really, the code\\nwritten up to this point has been object-based—we’ve passed objects around our scripts,\\nused them in expressions, called their methods, and so on. For our code to qualify as\\nbeing truly object-oriented (OO), though, our objects will generally need to also par-\\nticipate in something called an inheritance hierarchy.\\nThis chapter begins our exploration of the Python class—a coding structure and device\\nused to implement new kinds of objects in Python that support inheritance. Classes are\\nPython’s main object-oriented programming (OOP) tool, so we’ll also look at OOP\\nbasics along the way in this part of the book. OOP offers a different and often more\\neffective way of programming, in which we factor code to minimize redundancy, and\\nwrite new programs by customizing existing code instead of changing it in place.\\nIn Python, classes are created with a new statement: the class. As you’ll see, the objects\\ndefined with classes can look a lot like the built-in types we studied earlier in the book.\\nIn fact, classes really just apply and extend the ideas we’ve already covered; roughly,\\nthey  are  packages  of  functions  that  use  and  process  built-in  object  types.  Classes,\\nthough, are designed to create and manage new objects, and support inheritance—a\\nmechanism of code customization and reuse above and beyond anything we’ve seen\\nso far.\\nOne note up front: in Python, OOP is entirely optional, and you don’t need to use\\nclasses just to get started. You can get plenty of work done with simpler constructs such\\nas functions, or even simple top-level script code. Because using classes well requires\\nsome up-front planning, they tend to be of more interest to people who work in stra-\\ntegic mode (doing long-term product development) than to people who work in tacti-\\ncal mode (where time is in very short supply).\\nStill, as you’ll see in this part of the book, classes turn out to be one of the most useful\\ntools  Python  provides.  When  used  well,  classes  can  actually  cut  development  time\\nradically. They’re also employed in popular Python tools like the tkinter GUI API, so\\nmost Python programmers will usually find at least a working knowledge of class basics\\nhelpful.\\n\\n783\\n\\n\\x0cWhy Use Classes?\\nRemember when I told you that programs “do things with stuff” in Chapter 4 and\\nChapter 10? In simple terms, classes are just a way to define new sorts of stuff, reflecting\\nreal objects in a program’s domain. For instance, suppose we decide to implement that\\nhypothetical pizza-making robot we used as an example in Chapter 16. If we implement\\nit using classes, we can model more of its real-world structure and relationships. Two\\naspects of OOP prove useful here:\\n\\nInheritance\\n\\nPizza-making robots are kinds of robots, so they possess the usual robot-y prop-\\nerties. In OOP terms, we say they “inherit” properties from the general category\\nof all robots. These common properties need to be implemented only once for the\\ngeneral case and can be reused in part or in full by all types of robots we may build\\nin the future.\\n\\nComposition\\n\\nPizza-making robots are really collections of components that work together as a\\nteam. For instance, for our robot to be successful, it might need arms to roll dough,\\nmotors to maneuver to the oven, and so on. In OOP parlance, our robot is an\\nexample of composition; it contains other objects that it activates to do its bidding.\\nEach component might be coded as a class, which defines its own behavior and\\nrelationships.\\n\\nGeneral OOP ideas like inheritance and composition apply to any application that can\\nbe decomposed into a set of objects. For example, in typical GUI systems, interfaces\\nare written as collections of widgets—buttons, labels, and so on—which are all drawn\\nwhen their container is drawn (composition). Moreover, we may be able to write our\\nown custom widgets—buttons with unique fonts, labels with new color schemes, and\\nthe like—which are specialized versions of more general interface devices (inheritance).\\nFrom a more concrete programming perspective, classes are Python program units, just\\nlike functions and modules: they are another compartment for packaging logic and\\ndata. In fact, classes also define new namespaces, much like modules. But, compared\\nto other program units we’ve already seen, classes have three critical distinctions that\\nmake them more useful when it comes to building new objects:\\n\\nMultiple instances\\n\\nClasses are essentially factories for generating one or more objects. Every time we\\ncall a class, we generate a new object with a distinct namespace. Each object gen-\\nerated from a class has access to the class’s attributes and gets a namespace of its\\nown for data that varies per object. This is similar to the per-call state retention of\\nChapter 17’s closure functions, but is explicit and natural in classes, and is just one\\nof the things that classes do. Classes offer a complete programming solution.\\n\\n784 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0cCustomization via inheritance\\n\\nClasses also support the OOP notion of inheritance; we can extend a class by re-\\ndefining its attributes outside the class itself in new software components coded\\nas subclasses. More generally, classes can build up namespace hierarchies, which\\ndefine  names  to  be  used  by  objects  created  from  classes  in  the  hierarchy.  This\\nsupports multiple customizable behaviors more directly than other tools.\\n\\nOperator overloading\\n\\nBy providing special protocol methods, classes can define objects that respond to\\nthe sorts of operations we saw at work on built-in types. For instance, objects made\\nwith  classes  can  be  sliced,  concatenated,  indexed,  and  so  on.  Python  provides\\nhooks that classes can use to intercept and implement any built-in type operation.\\n\\nAt its base, the mechanism of OOP in Python is largely just two bits of magic: a special\\nfirst argument in functions (to receive the subject of a call) and inheritance attribute\\nsearch  (to  support  programming  by  customization).  Other  than  this,  the  model  is\\nlargely just functions that ultimately process built-in types. While not radically new,\\nthough, OOP adds an extra layer of structure that supports better programming than\\nflat procedural models. Along with the functional tools we met earlier, it represents a\\nmajor abstraction step above computer hardware that helps us build more sophisticated\\nprograms.\\n\\nOOP from 30,000 Feet\\nBefore we see what this all means in terms of code, I’d like to say a few words about\\nthe general ideas behind OOP. If you’ve never done anything object-oriented in your\\nlife before now, some of the terminology in this chapter may seem a bit perplexing on\\nthe first pass. Moreover, the motivation for these terms may be elusive until you’ve had\\na chance to study the ways that programmers apply them in larger systems. OOP is as\\nmuch an experience as a technology.\\n\\nAttribute Inheritance Search\\nThe good news is that OOP is much simpler to understand and use in Python than in\\nother  languages,  such  as  C++  or  Java.  As  a  dynamically  typed  scripting  language,\\nPython removes much of the syntactic clutter and complexity that clouds OOP in other\\ntools. In fact, much of the OOP story in Python boils down to this expression:\\n\\nobject.attribute\\n\\nWe’ve been using this expression throughout the book to access module attributes, call\\nmethods of objects, and so on. When we say this to an object that is derived from a\\nclass statement, however, the expression kicks off a search in Python—it searches a\\ntree of linked objects, looking for the first appearance of attribute that it can find.\\nWhen classes are involved, the preceding Python expression effectively translates to\\nthe following in natural language:\\n\\nOOP from 30,000 Feet\\n\\n| 785\\n\\n\\x0cFind the first occurrence of attribute by looking in object, then in all classes above it,\\nfrom bottom to top and left to right.\\n\\nIn other words, attribute fetches are simply tree searches. The term inheritance is ap-\\nplied because objects lower in a tree inherit attributes attached to objects higher in that\\ntree. As the search proceeds from the bottom up, in a sense, the objects linked into a\\ntree are the union of all the attributes defined in all their tree parents, all the way up\\nthe tree.\\nIn Python, this is all very literal: we really do build up trees of linked objects with code,\\nand Python really does climb this tree at runtime searching for attributes every time we\\nuse the object.attribute expression. To make this more concrete, Figure 26-1 sketches\\nan example of one of these trees.\\n\\nFigure 26-1. A class tree, with two instances at the bottom (I1 and I2), a class above them (C1), and\\ntwo superclasses at the top (C2 and C3). All of these objects are namespaces (packages of variables),\\nand the inheritance search is simply a search of the tree from bottom to top looking for the lowest\\noccurrence of an attribute name. Code implies the shape of such trees.\\n\\nIn this figure, there is a tree of five objects labeled with variables, all of which have\\nattached attributes, ready to be searched. More specifically, this tree links together three\\nclass objects (the ovals C1, C2, and C3) and two instance objects (the rectangles I1 and\\nI2) into an inheritance search tree. Notice that in the Python object model, classes and\\nthe instances you generate from them are two distinct object types:\\n\\nClasses\\n\\nServe as instance factories. Their attributes provide behavior—data and functions\\n—that is inherited by all the instances generated from them (e.g., a function to\\ncompute an employee’s salary from pay and hours).\\n\\nInstances\\n\\nRepresent the concrete items in a program’s domain. Their attributes record data\\nthat varies per specific object (e.g., an employee’s Social Security number).\\n\\nIn terms of search trees, an instance inherits attributes from its class, and a class inherits\\nattributes from all classes above it in the tree.\\n\\n786 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0cIn Figure 26-1, we can further categorize the ovals by their relative positions in the tree.\\nWe usually call classes higher in the tree (like C2 and C3) superclasses; classes lower in\\nthe tree (like C1) are known as subclasses. These terms refer to both relative tree positions\\nand roles. Superclasses provide behavior shared by all their subclasses, but because the\\nsearch proceeds from the bottom up, subclasses may override behavior defined in their\\nsuperclasses by redefining superclass names lower in the tree.1\\nAs these last few words are really the crux of the matter of software customization in\\nOOP, let’s expand on this concept. Suppose we build up the tree in Figure 26-1, and\\nthen say this:\\n\\nI2.w\\n\\nRight away, this code invokes inheritance. Because this is an object.attribute expres-\\nsion, it triggers a search of the tree in Figure 26-1—Python will search for the attribute\\nw by looking in I2 and above. Specifically, it will search the linked objects in this order:\\n\\nI2, C1, C2, C3\\n\\nand stop at the first attached w it finds (or raise an error if w isn’t found at all). In this\\ncase, w won’t be found until C3 is searched because it appears only in that object. In\\nother words, I2.w resolves to C3.w by virtue of the automatic search. In OOP termi-\\nnology, I2 “inherits” the attribute w from C3.\\nUltimately, the two instances inherit four attributes from their classes: w, x, y, and z.\\nOther attribute references will wind up following different paths in the tree. For ex-\\nample:\\n\\n• I1.x and I2.x both find x in C1 and stop because C1 is lower than C2.\\n• I1.y and I2.y both find y in C1 because that’s the only place y appears.\\n• I1.z and I2.z both find z in C2 because C2 is further to the left than C3.\\n• I2.name finds name in I2 without climbing the tree at all.\\n\\nTrace these searches through the tree in Figure 26-1 to get a feel for how inheritance\\nsearches work in Python.\\nThe first item in the preceding list is perhaps the most important to notice—because\\nC1 redefines the attribute x lower in the tree, it effectively replaces the version above it\\nin C2. As you’ll see in a moment, such redefinitions are at the heart of software cus-\\ntomization in OOP—by redefining and replacing the attribute, C1 effectively customizes\\nwhat it inherits from its superclasses.\\n\\n1. In other literature and circles, you may also occasionally see the terms base classes and derived classes\\nused to describe superclasses and subclasses, respectively. Python people and this book tend to use the\\nlatter terms.\\n\\nOOP from 30,000 Feet\\n\\n| 787\\n\\n\\x0cClasses and Instances\\nAlthough they are technically two separate object types in the Python model, the classes\\nand instances we put in these trees are almost identical—each type’s main purpose is\\nto serve as another kind of namespace—a package of variables, and a place where we\\ncan attach attributes. If classes and instances therefore sound like modules, they should;\\nhowever,  the  objects  in  class  trees  also  have  automatically  searched  links  to  other\\nnamespace objects, and classes correspond to statements, not entire files.\\nThe primary difference between classes and instances is that classes are a kind of fac-\\ntory for generating instances. For example, in a realistic application, we might have an\\nEmployee class that defines what it means to be an employee; from that class, we generate\\nactual Employee instances. This is another difference between classes and modules—\\nwe only ever have one instance of a given module in memory (that’s why we have to\\nreload a module to get its new code), but with classes, we can make as many instances\\nas we need.\\nOperationally, classes will usually have functions attached to them (e.g.,  computeSa\\nlary), and the instances will have more basic data items used by the class’s functions\\n(e.g., hoursWorked). In fact, the object-oriented model is not that different from the\\nclassic data-processing model of programs plus records—in OOP, instances are like\\nrecords with “data,” and classes are the “programs” for processing those records. In\\nOOP, though, we also have the notion of an inheritance hierarchy, which supports\\nsoftware customization better than earlier models.\\n\\nMethod Calls\\nIn the prior section, we saw how the attribute reference I2.w in our example class tree\\nwas translated to C3.w by the inheritance search procedure in Python. Perhaps just as\\nimportant to understand as the inheritance of attributes, though, is what happens when\\nwe try to call methods—functions attached to classes as attributes.\\nIf this I2.w reference is a function call, what it really means is “call the C3.w function to\\nprocess  I2.”  That  is,  Python  will  automatically  map  the  call  I2.w()  into  the  call\\nC3.w(I2), passing in the instance as the first argument to the inherited function.\\nIn fact, whenever we call a function attached to a class in this fashion, an instance of\\nthe class is always implied. This implied subject or context is part of the reason we refer\\nto this as an object-oriented model—there is always a subject object when an operation\\nis run. In a more realistic example, we might invoke a method called giveRaise attached\\nas an attribute to an Employee class; such a call has no meaning unless qualified with\\nthe employee to whom the raise should be given.\\nAs we’ll see later, Python passes in the implied instance to a special first argument in\\nthe method, called self by convention. Methods go through this argument to process\\nthe subject of the call. As we’ll also learn, methods can be called through either an\\ninstance—bob.giveRaise()—or a class—Employee.giveRaise(bob)—and both forms\\n\\n788 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0cserve purposes in our scripts. These calls also illustrate both of the key ideas in OOP:\\nto run a bob.giveRaise() method call, Python:\\n\\n1. Looks up giveRaise from bob, by inheritance search\\n2. Passes bob to the located giveRaise function, in the special self argument\\n\\nWhen you call Employee.giveRaise(bob), you’re just performing both steps yourself.\\nThis description is technically the default case (Python has additional method types\\nwe’ll meet later), but it applies to the vast majority of the OOP code written in the\\nlanguage. To see how methods receive their subjects, though, we need to move on to\\nsome code.\\n\\nCoding Class Trees\\nAlthough we are speaking in the abstract here, there is tangible code behind all these\\nideas, of course. We construct trees and their objects with class statements and class\\ncalls, which we’ll meet in more detail later. In short:\\n\\n• Each class statement generates a new class object.\\n• Each time a class is called, it generates a new instance object.\\n• Instances are automatically linked to the classes from which they are created.\\n• Classes are automatically linked to their superclasses according to the way we list\\nthem in parentheses in a class header line; the left-to-right order there gives the\\norder in the tree.\\n\\nTo build the tree in Figure 26-1, for example, we would run Python code of the following\\nform. Like function definition, classes are normally coded in module files and are run\\nduring an import (I’ve omitted the guts of the class statements here for brevity):\\n\\nclass C2: ...                      # Make class objects (ovals)\\nclass C3: ...\\nclass C1(C2, C3): ...              # Linked to superclasses (in this order)\\n\\nI1 = C1()                          # Make instance objects (rectangles)\\nI2 = C1()                          # Linked to their classes\\n\\nHere, we build the three class objects by running three class statements, and make the\\ntwo instance objects by calling the class C1 twice, as though it were a function. The\\ninstances remember the class they were made from, and the class C1 remembers its listed\\nsuperclasses.\\nTechnically, this example is using something called multiple inheritance, which simply\\nmeans that a class has more than one superclass above it in the class tree—a useful\\ntechnique when you wish to combine multiple tools. In Python, if there is more than\\none superclass listed in parentheses in a class statement (like C1’s here), their left-to-\\nright order gives the order in which those superclasses will be searched for attributes\\n\\nOOP from 30,000 Feet\\n\\n| 789\\n\\n\\x0cby inheritance. The leftmost version of a name is used by default, though you can always\\nchoose a name by asking for it from the class it lives in (e.g., C3.z).\\nBecause of the way inheritance searches proceed, the object to which you attach an\\nattribute turns out to be crucial—it determines the name’s scope. Attributes attached\\nto instances pertain only to those single instances, but attributes attached to classes are\\nshared  by  all  their  subclasses  and  instances.  Later,  we’ll  study  the  code  that  hangs\\nattributes on these objects in depth. As we’ll find:\\n\\n• Attributes are usually attached to classes by assignments made at the top level in\\n\\nclass statement blocks, and not nested inside function def statements there.\\n\\n• Attributes are usually attached to instances by assignments to the special argument\\n\\npassed to functions coded inside classes, called self.\\n\\nFor example, classes provide behavior for their instances with method functions we\\ncreate by coding def statements inside class statements. Because such nested defs as-\\nsign names within the class, they wind up attaching attributes to the class object that\\nwill be inherited by all instances and subclasses:\\n\\nclass C2: ...                    # Make superclass objects\\nclass C3: ...\\n\\nclass C1(C2, C3):                # Make and link class C1\\n    def setname(self, who):      # Assign name: C1.setname\\n        self.name = who          # Self is either I1 or I2\\n\\nI1 = C1()                        # Make two instances\\nI2 = C1()\\nI1.setname(\\'bob\\')                # Sets I1.name to \\'bob\\'\\nI2.setname(\\'sue\\')                # Sets I2.name to \\'sue\\'\\nprint(I1.name)                   # Prints \\'bob\\'\\n\\nThere’s nothing syntactically unique about def in this context. Operationally, though, \\nwhen a def appears inside a class like this, it is usually known as a method, and it\\nautomatically receives a special first argument—called self by convention—that pro-\\nvides a handle back to the instance to be processed. Any values you pass to the method\\nyourself go to arguments after self (here, to who).2\\nBecause classes are factories for multiple instances, their methods usually go through\\nthis automatically passed-in self argument whenever they need to fetch or set attributes\\nof the particular instance being processed by a method call. In the preceding code,\\nself is used to store a name in one of two instances.\\nLike simple variables, attributes of classes and instances are not declared ahead of time,\\nbut spring into existence the first time they are assigned values. When a method assigns\\nto a self attribute, it creates or changes an attribute in an instance at the bottom of the\\n\\n2. If you’ve ever used C++ or Java, you’ll recognize that Python’s self is the same as the this pointer, but\\nself is always explicit in both headers and bodies of Python methods to make attribute accesses more\\nobvious: a name has fewer possible meanings.\\n\\n790 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0cclass tree (i.e., one of the rectangles in Figure 26-1) because self automatically refers\\nto the instance being processed—the subject of the call.\\nIn fact, because all the objects in class trees are just namespace objects, we can fetch or\\nset any of their attributes by going through the appropriate names. Saying C1.setname\\nis as valid as saying I1.setname, as long as the names C1 and I1 are in your code’s scopes.\\n\\nOperator Overloading\\nAs currently coded, our C1 class doesn’t attach a name attribute to an instance until the\\nsetname method is called. Indeed, referencing I1.name before calling I1.setname would\\nproduce an undefined name error. If a class wants to guarantee that an attribute like\\nname is always set in its instances, it more typically will fill out the attribute at con-\\nstruction time, like this:\\n\\nclass C2: ...                    # Make superclass objects\\nclass C3: ...\\n\\nclass C1(C2, C3):\\n    def __init__(self, who):     # Set name when constructed\\n        self.name = who          # Self is either I1 or I2\\n\\nI1 = C1(\\'bob\\')                   # Sets I1.name to \\'bob\\'\\nI2 = C1(\\'sue\\')                   # Sets I2.name to \\'sue\\'\\nprint(I1.name)                   # Prints \\'bob\\'\\n\\nIf it’s coded or inherited, Python automatically calls a method named __init__ each\\ntime an instance is generated from a class. The new instance is passed in to the self\\nargument of __init__ as usual, and any values listed in parentheses in the class call go\\nto arguments two and beyond. The effect here is to initialize instances when they are\\nmade, without requiring extra method calls.\\nThe __init__ method is known as the constructor because of when it is run. It’s the\\nmost commonly used representative of a larger class of methods called operator over-\\nloading methods, which we’ll discuss in more detail in the chapters that follow. Such\\nmethods are inherited in class trees as usual and have double underscores at the start\\nand end of their names to make them distinct. Python runs them automatically when\\ninstances  that  support  them  appear  in  the  corresponding  operations,  and  they  are\\nmostly an alternative to using simple method calls. They’re also optional: if omitted,\\nthe operations are not supported. If no __init__ is present, class calls return an empty\\ninstance, without initializing it.\\nFor  example,  to  implement  set  intersection,  a  class  might  either  provide  a  method\\nnamed intersect, or overload the & expression operator to dispatch to the required\\nlogic by coding a method named __and__. Because the operator scheme makes instances\\nlook and feel more like built-in types, it allows some classes to provide a consistent and\\nnatural interface, and be compatible with code that expects a built-in type. Still, apart\\nfrom the __init__ constructor—which appears in most realistic classes—many pro-\\n\\nOOP from 30,000 Feet\\n\\n| 791\\n\\n\\x0cgrams may be better off with simpler named methods unless their objects are similar\\nto built-ins. A giveRaise may make sense for an Employee, but a & might not.\\n\\nOOP Is About Code Reuse\\nAnd that, along with a few syntax details, is most of the OOP story in Python. Of course,\\nthere’s a bit more to it than just inheritance. For example, operator overloading is much\\nmore general than I’ve described so far—classes may also provide their own imple-\\nmentations of operations such as indexing, fetching attributes, printing, and more. By\\nand large, though, OOP is about looking up attributes in trees with a special first ar-\\ngument in functions.\\nSo why would we be interested in building and searching trees of objects? Although it\\ntakes some experience to see how, when used well, classes support code reuse in ways\\nthat other Python program components cannot. In fact, this is their highest purpose.\\nWith classes, we code by customizing existing software, instead of either changing\\nexisting code in place or starting from scratch for each new project. This turns out to\\nbe a powerful paradigm in realistic programming.\\nAt a fundamental level, classes are really just packages of functions and other names,\\nmuch like modules. However, the automatic attribute inheritance search that we get\\nwith classes supports customization of software above and beyond what we can do\\nwith modules and functions. Moreover, classes provide a natural structure for code\\nthat packages and localizes logic and names, and so aids in debugging.\\nFor instance, because methods are simply functions with a special first argument, we\\ncan mimic some of their behavior by manually passing objects to be processed to simple\\nfunctions. The participation of methods in class inheritance, though, allows us to nat-\\nurally customize existing software by coding subclasses with new method definitions,\\nrather than changing existing code in place. There is really no such concept with mod-\\nules and functions.\\n\\nPolymorphism and classes\\nAs an example, suppose you’re assigned the task of implementing an employee database\\napplication. As a Python OOP programmer, you might begin by coding a general su-\\nperclass that defines default behaviors common to all the kinds of employees in your\\norganization:\\n\\nclass Employee:                      # General superclass\\n    def computeSalary(self): ...     # Common or default behaviors\\n    def giveRaise(self): ...\\n    def promote(self): ...\\n    def retire(self): ...\\n\\nOnce you’ve coded this general behavior, you can specialize it for each specific kind of\\nemployee to reflect how the various types differ from the norm. That is, you can code\\nsubclasses that customize just the bits of behavior that differ per employee type; the\\n\\n792 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0crest of the employee types’ behavior will be inherited from the more general class. For\\nexample, if engineers have a unique salary computation rule (perhaps it’s not hours\\ntimes rate), you can replace just that one method in a subclass:\\n\\nclass Engineer(Employee):            # Specialized subclass\\n     def computeSalary(self): ...    # Something custom here\\n\\nBecause the computeSalary version here appears lower in the class tree, it will replace\\n(override) the general version in Employee. You then create instances of the kinds of\\nemployee classes that the real employees belong to, to get the correct behavior:\\n\\nbob = Employee()                     # Default behavior\\nsue = Employee()                     # Default behavior\\ntom = Engineer()                     # Custom salary calculator\\n\\nNotice that you can make instances of any class in a tree, not just the ones at the bottom\\n—the class you make an instance from determines the level at which the attribute search\\nwill begin, and thus which versions of the methods it will employ.\\nUltimately, these three instance objects might wind up embedded in a larger container\\nobject—for instance, a list, or an instance of another class—that represents a depart-\\nment or company using the composition idea mentioned at the start of this chapter.\\nWhen you later ask for these employees’ salaries, they will be computed according to\\nthe classes from which the objects were made, due to the principles of the inheritance\\nsearch:\\n\\ncompany = [bob, sue, tom]            # A composite object\\nfor emp in company:\\n    print(emp.computeSalary())       # Run this object\\'s version: default or custom\\n\\nThis is yet another instance of the idea of polymorphism introduced in Chapter 4 and\\nexpanded in Chapter 16. Recall that polymorphism means that the meaning of an op-\\neration depends on the object being operated on. That is, code shouldn’t care about\\nwhat an object is, only about what it does. Here, the method computeSalary is located\\nby inheritance search in each object before it is called. The net effect is that we auto-\\nmatically run the correct version for the object being processed. Trace the code to see\\nwhy.3\\nIn other applications, polymorphism might also be used to hide (i.e., encapsulate) in-\\nterface differences. For example, a program that processes data streams might be coded\\nto expect objects with input and output methods, without caring what those methods\\nactually do:\\n\\ndef processor(reader, converter, writer):\\n    while True:\\n        data = reader.read()\\n\\n3. The  company  list  in  this  example  could  be  a  database  if  stored  in  a  file  with  Python  object  pickling,\\nintroduced in Chapter 9, to make the employees persistent. Python also comes with a module named\\nshelve,  which  allows  the  pickled  representation  of  class  instances  to  be  stored  in  an  access-by-key\\nfilesystem; we’ll deploy it in Chapter 28.\\n\\nOOP from 30,000 Feet\\n\\n| 793\\n\\n\\x0c        if not data: break\\n        data = converter(data)\\n        writer.write(data)\\n\\nBy passing in instances of subclasses that specialize the required read and write method\\ninterfaces for various data sources, we can reuse the processor function for any data\\nsource we need to use, both now and in the future:\\n\\nclass Reader:\\n    def read(self): ...              # Default behavior and tools\\n    def other(self): ...\\nclass FileReader(Reader):\\n    def read(self): ...              # Read from a local file\\nclass SocketReader(Reader):\\n    def read(self): ...              # Read from a network socket\\n...\\nprocessor(FileReader(...),   Converter,  FileWriter(...))\\nprocessor(SocketReader(...), Converter,  TapeWriter(...))\\nprocessor(FtpReader(...),    Converter,  XmlWriter(...))\\n\\nMoreover, because the internal implementations of those read and write methods have\\nbeen factored into single locations, they can be changed without impacting code such\\nas this that uses them. The processor function might even be a class itself to allow the\\nconversion logic of converter to be filled in by inheritance, and to allow readers and\\nwriters to be embedded by composition (we’ll see how this works later in this part of\\nthe book).\\n\\nProgramming by customization\\nOnce you get used to programming this way (by software customization), you’ll find\\nthat when it’s time to write a new program, much of your work may already be done\\n—your task largely becomes one of mixing together existing superclasses that already\\nimplement the behavior required by your program. For example, someone else might\\nhave written the Employee, Reader, and Writer classes in this section’s examples for use\\nin completely different programs. If so, you get all of that person’s code “for free.”\\nIn fact, in many application domains, you can fetch or purchase collections of super-\\nclasses, known as frameworks, that implement common programming tasks as classes,\\nready to be mixed into your applications. These frameworks might provide database\\ninterfaces,  testing  protocols,  GUI  toolkits,  and  so  on.  With  frameworks,  you  often\\nsimply code a subclass that fills in an expected method or two; the framework classes\\nhigher in the tree do most of the work for you. Programming in such an OOP world is\\njust a matter of combining and specializing already debugged code by writing subclasses\\nof your own.\\nOf course, it takes a while to learn how to leverage classes to achieve such OOP utopia.\\nIn practice, object-oriented work also entails substantial design work to fully realize\\nthe code reuse benefits of classes—to this end, programmers have begun cataloging\\ncommon OOP structures, known as design patterns, to help with design issues. The\\nactual code you write to do OOP in Python, though, is so simple that it will not in itself\\n\\n794 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0cpose an additional obstacle to your OOP quest. To see why, you’ll have to move on to\\nChapter 27.\\n\\nChapter Summary\\nWe took an abstract look at classes and OOP in this chapter, taking in the big picture\\nbefore we dive into syntax details. As we’ve seen, OOP is mostly about an argument\\nnamed self, and a search for attributes in trees of linked objects called inheritance.\\nObjects at the bottom of the tree inherit attributes from objects higher up in the tree\\n—a feature that enables us to program by customizing code, rather than changing it or\\nstarting from scratch. When used well, this model of programming can cut develop-\\nment time radically.\\nThe next chapter will begin to fill in the coding details behind the picture painted here.\\nAs we get deeper into Python classes, though, keep in mind that the OOP model in\\nPython is very simple; as we’ve seen here, it’s really just about looking up attributes in\\nobject trees and a special function argument. Before we move on, here’s a quick quiz\\nto review what we’ve covered here.\\n\\nTest Your Knowledge: Quiz\\n1. What is the main point of OOP in Python?\\n2. Where does an inheritance search look for an attribute?\\n3. What is the difference between a class object and an instance object?\\n4. Why is the first argument in a class’s method function special?\\n5. What is the __init__ method used for?\\n6. How do you create a class instance?\\n7. How do you create a class?\\n8. How do you specify a class’s superclasses?\\n\\nTest Your Knowledge: Answers\\n1. OOP is about code reuse—you factor code to minimize redundancy and program\\nby customizing what already exists instead of changing code in place or starting\\nfrom scratch.\\n\\n2. An inheritance search looks for an attribute first in the instance object, then in the\\nclass the instance was created from, then in all higher superclasses, progressing\\nfrom the bottom to the top of the object tree, and from left to right (by default).\\nThe search stops at the first place the attribute is found. Because the lowest version\\nof a name found along the way wins, class hierarchies naturally support customi-\\nzation by extension in new subclasses.\\n\\nTest Your Knowledge: Answers\\n\\n| 795\\n\\n\\x0c3. Both class and instance objects are namespaces (packages of variables that appear\\nas attributes). The main difference between them is that classes are a kind of factory\\nfor creating multiple instances. Classes also support operator overloading meth-\\nods, which instances inherit, and treat any functions nested in the class as methods\\nfor processing instances.\\n\\n4. The first argument in a class’s method function is special because it always receives\\nthe instance object that is the implied subject of the method call. It’s usually called\\nself by convention. Because method functions always have this implied subject\\nand object context by default, we say they are “object-oriented” (i.e., designed to\\nprocess or change objects).\\n\\n5. If the __init__ method is coded or inherited in a class, Python calls it automatically\\neach time an instance of that class is created. It’s known as the constructor method;\\nit is passed the new instance implicitly, as well as any arguments passed explicitly\\nto the class name. It’s also the most commonly used operator overloading method.\\nIf no __init__ method is present, instances simply begin life as empty namespaces.\\n6. You create a class instance by calling the class name as though it were a function;\\nany arguments passed into the class name show up as arguments two and beyond\\nin the __init__ constructor method. The new instance remembers the class it was\\ncreated from for inheritance purposes.\\n\\n7. You create a class by running a class statement; like function definitions, these\\nstatements normally run when the enclosing module file is imported (more on this\\nin the next chapter).\\n\\n8. You specify a class’s superclasses by listing them in parentheses in the class state-\\nment, after the new class’s name. The left-to-right order in which the classes are\\nlisted in the parentheses gives the left-to-right inheritance search order in the class\\ntree.\\n\\n796 | Chapter 26:\\u2002OOP: The Big Picture\\n\\n\\x0cCHAPTER 27\\nClass Coding Basics\\n\\nNow that we’ve talked about OOP in the abstract, it’s time to see how this translates\\nto actual code. This chapter begins to fill in the syntax details behind the class model\\nin Python.\\nIf you’ve never been exposed to OOP in the past, classes can seem somewhat compli-\\ncated if taken in a single dose. To make class coding easier to absorb, we’ll begin our\\ndetailed exploration of OOP by taking a first look at some basic classes in action in this\\nchapter. We’ll expand on the details introduced here in later chapters of this part of\\nthe book, but in their basic form, Python classes are easy to understand.\\nIn fact, classes have just three primary distinctions. At a base level, they are mostly just\\nnamespaces, much like the modules we studied in Part V. Unlike modules, though,\\nclasses also have support for generating multiple objects, for namespace inheritance,\\nand for operator overloading. Let’s begin our class statement tour by exploring each\\nof these three distinctions in turn.\\n\\nClasses Generate Multiple Instance Objects\\nTo understand how the multiple objects idea works, you have to first understand that\\nthere are two kinds of objects in Python’s OOP model: class objects and instance ob-\\njects. Class objects provide default behavior and serve as factories for instance objects.\\nInstance objects are the real objects your programs process—each is a namespace in\\nits own right, but inherits (i.e., has automatic access to) names in the class from which\\nit was created. Class objects come from statements, and instances come from calls; each\\ntime you call a class, you get a new instance of that class.\\nThis object-generation concept is very different from most of the other program con-\\nstructs we’ve seen so far in this book. In effect, classes are essentially factories for gen-\\nerating multiple instances. By contrast, only one copy of each module is ever imported\\ninto a single program. In fact, this is why reload works as it does, updating a single-\\ninstance shared object in place. With classes, each instance can have its own, inde-\\npendent data, supporting multiple versions of the object that the class models.\\n\\n797\\n\\n\\x0cIn this role, class instances are similar to the per-call state of the closure (a.k.a. factory)\\nfunctions of Chapter 17, but this is a natural part of the class model, and state in classes\\nis explicit attributes instead of implicit scope references. Moreover, this is just part of\\nwhat classes do—they also support customization by inheritance, operator overload-\\ning, and multiple behaviors via methods. Generally speaking, classes are a more com-\\nplete programming tool, though OOP and function programming are not mutually ex-\\nclusive paradigms. We may combine them by using functional tools in methods, by\\ncoding methods that are themselves generators, by writing user-defined iterators (as\\nwe’ll see in Chapter 30), and so on.\\nThe following is a quick summary of the bare essentials of Python OOP in terms of its\\ntwo object types. As you’ll see, Python classes are in some ways similar to both defs\\nand modules, but they may be quite different from what you’re used to in other lan-\\nguages.\\n\\nClass Objects Provide Default Behavior\\nWhen we run a class statement, we get a class object. Here’s a rundown of the main\\nproperties of Python classes:\\n\\n• The class statement creates a class object and assigns it a name. Just like the\\nfunction def statement, the Python class statement is an executable statement.\\nWhen reached and run, it generates a new class object and assigns it to the name\\nin the class header. Also, like defs, class statements typically run when the files\\nthey are coded in are first imported.\\n\\n• Assignments inside class statements make class attributes. Just like in module\\nfiles, top-level assignments within a class statement (not nested in a def) generate\\nattributes in a class object. Technically, the class statement defines a local scope\\nthat morphs into the attribute namespace of the class object, just like a module’s\\nglobal scope. After running a class statement, class attributes are accessed by name\\nqualification: object.name.\\n\\n• Class attributes provide object state and behavior. Attributes of a class object\\nrecord state information and behavior to be shared by all instances created from\\nthe class; function def statements nested inside a class generate methods, which\\nprocess instances.\\n\\nInstance Objects Are Concrete Items\\nWhen we call a class object, we get an instance object. Here’s an overview of the key\\npoints behind class instances:\\n\\n• Calling a class object like a function makes a new instance object. Each time\\na class is called, it creates and returns a new instance object. Instances represent\\nconcrete items in your program’s domain.\\n\\n798 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0c• Each instance object inherits class attributes and gets its own namespace. \\nInstance objects created from classes are new namespaces; they start out empty\\nbut inherit attributes that live in the class objects from which they were generated.\\n• Assignments to attributes of self in methods make per-instance attributes.\\nInside a class’s method functions, the first argument (called self by convention)\\nreferences the instance object being processed; assignments to attributes of self\\ncreate or change data in the instance, not the class.\\n\\nThe end result is that classes define common, shared data and behavior, and generate\\ninstances. Instances reflect concrete application entities, and record per-instance data\\nthat may vary per object.\\n\\nA First Example\\nLet’s turn to a real example to show how these ideas work in practice. To begin, let’s\\ndefine a class named FirstClass by running a Python class statement interactively:\\n\\n>>> class FirstClass:               # Define a class object\\n        def setdata(self, value):   # Define class\\'s methods\\n            self.data = value       # self is the instance\\n        def display(self):\\n            print(self.data)        # self.data: per instance\\n\\nWe’re working interactively here, but typically, such a statement would be run when\\nthe module file it is coded in is imported. Like functions created with defs, this class\\nwon’t even exist until Python reaches and runs this statement.\\nLike all compound statements, the class starts with a header line that lists the class\\nname, followed by a body of one or more nested and (usually) indented statements.\\nHere, the nested statements are defs; they define functions that implement the behavior\\nthe class means to export.\\nAs we learned in Part IV, def is really an assignment. Here, it assigns function objects\\nto the names setdata and display in the class statement’s scope, and so generates\\nattributes attached to the class—FirstClass.setdata and FirstClass.display. In fact,\\nany name assigned at the top level of the class’s nested block becomes an attribute of\\nthe class.\\nFunctions inside a class are usually called methods. They’re coded with normal defs,\\nand they support everything we’ve learned about functions already (they can have de-\\nfaults, return values, yield items on request, and so on). But in a method function, the\\nfirst argument automatically receives an implied instance object when called—the sub-\\nject of the call. We need to create a couple of instances to see how this works:\\n\\n>>> x = FirstClass()                # Make two instances\\n>>> y = FirstClass()                # Each is a new namespace\\n\\nBy calling the class this way (notice the parentheses), we generate instance objects,\\nwhich are just namespaces that have access to their classes’ attributes. Properly speak-\\n\\nClasses Generate Multiple Instance Objects\\n\\n| 799\\n\\n\\x0cFigure 27-1. Classes and instances are linked namespace objects in a class tree that is searched by\\ninheritance. Here, the “data” attribute is found in instances, but “setdata” and “display” are in the\\nclass above them.\\n\\ning, at this point, we have three objects: two instances and a class. Really, we have three\\nlinked namespaces, as sketched in Figure 27-1. In OOP terms, we say that x “is a”\\nFirstClass, as is y—they both inherit names attached to the class.\\nThe two instances start out empty but have links back to the class from which they\\nwere generated. If we qualify an instance with the name of an attribute that lives in the\\nclass object, Python fetches the name from the class by inheritance search (unless it\\nalso lives in the instance):\\n\\n>>> x.setdata(\"King Arthur\")        # Call methods: self is x\\n>>> y.setdata(3.14159)              # Runs: FirstClass.setdata(y, 3.14159)\\n\\nNeither x nor y has a setdata attribute of its own, so to find it, Python follows the link\\nfrom instance to class. And that’s about all there is to inheritance in Python: it happens\\nat attribute qualification time, and it just involves looking up names in linked objects\\n—here, by following the is-a links in Figure 27-1.\\nIn  the  setdata  function  inside  FirstClass,  the  value  passed  in  is  assigned  to\\nself.data. Within a method, self—the name given to the leftmost argument by con-\\nvention—automatically refers to the instance being processed (x or y), so the assign-\\nments store values in the instances’ namespaces, not the class’s; that’s how the data\\nnames in Figure 27-1 are created.\\nBecause classes can generate multiple instances, methods must go through the self\\nargument  to  get  to  the  instance  to  be  processed.  When  we  call  the  class’s  display\\nmethod to print self.data, we see that it’s different in each instance; on the other hand,\\nthe name display itself is the same in x and y, as it comes (is inherited) from the class:\\n\\n>>> x.display()                     # self.data differs in each instance\\nKing Arthur\\n>>> y.display()                     # Runs: FirstClass.display(y)\\n3.14159\\n\\nNotice that we stored different object types in the data member in each instance—a\\nstring and a floating-point number. As with everything else in Python, there are no\\ndeclarations for instance attributes (sometimes called members); they spring into exis-\\ntence the first time they are assigned values, just like simple variables. In fact, if we were\\n\\n800 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0cto  call  display  on  one  of  our  instances  before  calling  setdata,  we  would  trigger  an\\nundefined name error—the attribute named data doesn’t even exist in memory until it\\nis assigned within the setdata method.\\nAs another way to appreciate how dynamic this model is, consider that we can change\\ninstance attributes in the class itself, by assigning to self in methods, or outside the\\nclass, by assigning to an explicit instance object:\\n\\n>>> x.data = \"New value\"            # Can get/set attributes\\n>>> x.display()                     # Outside the class too\\nNew value\\n\\nAlthough less common, we could even generate an entirely new attribute in the in-\\nstance’s namespace by assigning to its name outside the class’s method functions:\\n\\n>>> x.anothername = \"spam\"          # Can set new attributes here too!\\n\\nThis would attach a new attribute called anothername, which may or may not be used\\nby any of the class’s methods, to the instance object x. Classes usually create all of the\\ninstance’s attributes by assignment to the self argument, but they don’t have to—\\nprograms can fetch, change, or create attributes on any objects to which they have\\nreferences.\\nIt usually doesn’t make sense to add data that the class cannot use, and it’s possible to\\nprevent this with extra “privacy” code based on attribute access operator overloading,\\nas we’ll discuss later in this book (see Chapter 30 and Chapter 39). Still, free attribute\\naccess translates to less syntax, and there are cases where it’s even useful—for example,\\nin coding data records of the sort we’ll see later in this chapter.\\n\\nClasses Are Customized by Inheritance\\nLet’s move on to the second major distinction of classes. Besides serving as factories\\nfor generating multiple instance objects, classes also allow us to make changes by in-\\ntroducing new components (called subclasses), instead of changing existing compo-\\nnents in place.\\nAs we’ve seen, instance objects generated from a class inherit the class’s attributes.\\nPython also allows classes to inherit from other classes, opening the door to coding\\nhierarchies of classes that specialize behavior—by redefining attributes in subclasses\\nthat appear lower in the hierarchy, we override the more general definitions of those\\nattributes higher in the tree. In effect, the further down the hierarchy we go, the more\\nspecific the software becomes. Here, too, there is no parallel with modules, whose\\nattributes live in a single, flat namespace that is not as amenable to customization.\\nIn Python, instances inherit from classes, and classes inherit from superclasses. Here\\nare the key ideas behind the machinery of attribute inheritance:\\n\\n• Superclasses are listed in parentheses in a class header. To make a class inherit\\nattributes from another class, just list the other class in parentheses in the new\\n\\nClasses Are Customized by Inheritance | 801\\n\\n\\x0cclass statement’s header line. The class that inherits is usually called a subclass,\\nand the class that is inherited from is its superclass.\\n\\n• Classes inherit attributes from their superclasses. Just as instances inherit the\\nattribute names defined in their classes, classes inherit all of the attribute names\\ndefined in their superclasses; Python finds them automatically when they’re ac-\\ncessed, if they don’t exist in the subclasses.\\n\\n• Instances  inherit  attributes  from  all  accessible  classes.  Each  instance  gets\\nnames from the class it’s generated from, as well as all of that class’s superclasses.\\nWhen looking for a name, Python checks the instance, then its class, then all su-\\nperclasses.\\n\\n• Each object.attribute reference invokes a new, independent search. Python\\nperforms an independent search of the class tree for each attribute fetch expression.\\nThis includes references to instances and classes made outside class statements\\n(e.g., X.attr), as well as references to attributes of the self instance argument in a\\nclass’s method functions. Each self.attr expression in a method invokes a new\\nsearch for attr in self and above.\\n\\n• Logic changes are made by subclassing, not by changing superclasses. By \\nredefining superclass names in subclasses lower in the hierarchy (class tree), sub-\\nclasses replace and thus customize inherited behavior.\\n\\nThe net effect—and the main purpose of all this searching—is that classes support\\nfactoring and customization of code better than any other language tool we’ve seen so\\nfar.  On  the  one  hand,  they  allow  us  to  minimize  code  redundancy  (and  so  reduce\\nmaintenance costs) by factoring operations into a single, shared implementation; on\\nthe other, they allow us to program by customizing what already exists, rather than\\nchanging it in place or starting from scratch.\\n\\nStrictly speaking, Python’s inheritance is a bit richer than described here,\\nwhen  we  factor  in  new-style  descriptors  and  metaclasses—advanced\\ntopics we’ll study later—but we can safely restrict our scope to instances\\nand their classes, both at this point in the book and in most Python\\napplication code. We’ll define inheritance formally in Chapter 40.\\n\\nA Second Example\\nTo illustrate the role of inheritance, this next example builds on the previous one. First,\\nwe’ll define a new class, SecondClass, that inherits all of FirstClass’s names and pro-\\nvides one of its own:\\n\\n>>> class SecondClass(FirstClass):                   # Inherits setdata\\n        def display(self):                           # Changes display\\n            print(\\'Current value = \"%s\"\\' % self.data)\\n\\n802 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0cFigure 27-2. Specialization: overriding inherited names by redefining them in extensions lower in the\\nclass tree. Here, SecondClass redefines and so customizes the “display” method for its instances.\\n\\nSecondClass defines the display method to print with a different format. By defining\\nan attribute with the same name as an attribute in FirstClass, SecondClass effectively\\nreplaces the display attribute in its superclass.\\nRecall that inheritance searches proceed upward from instances to subclasses to su-\\nperclasses, stopping at the first appearance of the attribute name that it finds. In this\\ncase,  since  the  display  name  in  SecondClass  will  be  found  before  the  one  in  First\\nClass, we say that SecondClass overrides FirstClass’s display. Sometimes we call this\\nact of replacing attributes by redefining them lower in the tree overloading.\\nThe net effect here is that SecondClass specializes FirstClass by changing the behavior\\nof the display method. On the other hand, SecondClass (and any instances created from\\nit) still inherits the setdata method in FirstClass verbatim. Let’s make an instance to\\ndemonstrate:\\n\\n>>> z = SecondClass()\\n>>> z.setdata(42)           # Finds setdata in FirstClass\\n>>> z.display()             # Finds overridden method in SecondClass\\nCurrent value = \"42\"\\n\\nAs before, we make a SecondClass instance object by calling it. The setdata call still\\nruns the version in FirstClass, but this time the display attribute comes from Second\\nClass and prints a custom message. Figure 27-2 sketches the namespaces involved.\\nNow,  here’s  a  crucial  thing  to  notice  about  OOP:  the  specialization  introduced  in\\nSecondClass is completely external to FirstClass. That is, it doesn’t affect existing or\\nfuture FirstClass objects, like the x from the prior example:\\n\\n>>> x.display()             # x is still a FirstClass instance (old message)\\nNew value\\n\\nRather than changing FirstClass, we customized it. Naturally, this is an artificial ex-\\nample, but as a rule, because inheritance allows us to make changes like this in external\\ncomponents (i.e., in subclasses), classes often support extension and reuse better than\\nfunctions or modules can.\\n\\nClasses Are Customized by Inheritance | 803\\n\\n\\x0cClasses Are Attributes in Modules\\nBefore we move on, remember that there’s nothing magic about a class name. It’s just\\na variable assigned to an object when the class statement runs, and the object can be\\nreferenced with any normal expression. For instance, if our FirstClass were coded in\\na module file instead of being typed interactively, we could import it and use its name\\nnormally in a class header line:\\n\\nfrom modulename import FirstClass           # Copy name into my scope\\nclass SecondClass(FirstClass):              # Use class name directly\\n    def display(self): ...\\n\\nOr, equivalently:\\n\\nimport modulename                           # Access the whole module\\nclass SecondClass(modulename.FirstClass):   # Qualify to reference\\n    def display(self): ...\\n\\nLike everything else, class names always live within a module, so they must follow all\\nthe rules we studied in Part V. For example, more than one class can be coded in a\\nsingle module file—like other statements in a module, class statements are run during\\nimports to define names, and these names become distinct module attributes. More\\ngenerally, each module may arbitrarily mix any number of variables, functions, and\\nclasses, and all names in a module behave the same way. The file food.py demonstrates:\\n\\n# food.py\\nvar = 1                                       # food.var\\ndef func(): ...                               # food.func\\nclass spam: ...                               # food.spam\\nclass ham:  ...                               # food.ham\\nclass eggs: ...                               # food.eggs\\n\\nThis holds true even if the module and class happen to have the same name. For ex-\\nample, given the following file, person.py:\\n\\nclass person: ...\\n\\nwe need to go through the module to fetch the class as usual:\\nimport person                                 # Import module\\nx = person.person()                           # Class within module\\n\\nAlthough this path may look redundant, it’s required: person.person refers to the per\\nson class inside the person module. Saying just person gets the module, not the class,\\nunless the from statement is used:\\n\\nfrom person import person                     # Get class from module\\nx = person()                                  # Use class name\\n\\nAs with any other variable, we can never see a class in a file without first importing and\\nsomehow fetching it from its enclosing file. If this seems confusing, don’t use the same\\nname for a module and a class within it. In fact, common convention in Python dictates\\nthat class names should begin with an uppercase letter, to help make them more distinct:\\n\\n804 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0cimport person                                 # Lowercase for modules\\nx = person.Person()                           # Uppercase for classes\\n\\nAlso, keep in mind that although classes and modules are both namespaces for attach-\\ning attributes, they correspond to very different source code structures: a module re-\\nflects an entire file, but a class is a statement within a file. We’ll say more about such\\ndistinctions later in this part of the book.\\n\\nClasses Can Intercept Python Operators\\nLet’s move on to the third and final major difference between classes and modules:\\noperator overloading. In simple terms, operator overloading lets objects coded with\\nclasses intercept and respond to operations that work on built-in types: addition, slic-\\ning, printing, qualification, and so on. It’s mostly just an automatic dispatch mechanism\\n—expressions  and  other  built-in  operations  route  control  to  implementations  in\\nclasses. Here, too, there is nothing similar in modules: modules can implement function\\ncalls, but not the behavior of expressions.\\nAlthough we could implement all class behavior as method functions, operator over-\\nloading lets objects be more tightly integrated with Python’s object model. Moreover,\\nbecause operator overloading makes our own objects act like built-ins, it tends to foster\\nobject interfaces that are more consistent and easier to learn, and it allows class-based\\nobjects to be processed by code written to expect a built-in type’s interface. Here is a\\nquick rundown of the main ideas behind overloading operators:\\n\\n• Methods named with double underscores (__X__) are special hooks. In Python\\nclasses we implement operator overloading by providing specially named methods\\nto intercept operations. The Python language defines a fixed and unchangeable\\nmapping from each of these operations to a specially named method.\\n\\n• Such methods are called automatically when instances appear in built-in\\noperations. For instance, if an instance object inherits an __add__ method, that\\nmethod is called whenever the object appears in a  + expression. The method’s\\nreturn value becomes the result of the corresponding expression.\\n\\n• Classes may override most built-in type operations. There are dozens of special\\noperator  overloading  method  names  for  intercepting  and  implementing  nearly\\nevery  operation  available  for  built-in  types.  This  includes  expressions,  but  also\\nbasic operations like printing and object creation.\\n\\n• There are no defaults for operator overloading methods, and none are re-\\nquired. If a class does not define or inherit an operator overloading method, it just\\nmeans that the corresponding operation is not supported for the class’s instances.\\nIf there is no __add__, for example, + expressions raise exceptions.\\n\\n• New-style classes have some defaults, but not for common operations. In\\nPython 3.X, and so-called “new style” classes in 2.X that we’ll define later, a root\\n\\nClasses Can Intercept Python Operators\\n\\n| 805\\n\\n\\x0cclass named  object does provide defaults for some  __X__ methods, but not for\\nmany, and not for most commonly used operations.\\n\\n• Operators allow classes to integrate with Python’s object model. By over-\\nloading type operations, the user-defined objects we implement with classes can\\nact  just  like  built-ins,  and  so  provide  consistency  as  well  as  compatibility  with\\nexpected interfaces.\\n\\nOperator overloading is an optional feature; it’s used primarily by people developing\\ntools for other Python programmers, not by application developers. And, candidly, you\\nprobably shouldn’t use it just because it seems clever or “cool.” Unless a class needs to\\nmimic built-in type interfaces, it should usually stick to simpler named methods. Why\\nwould an employee database application support expressions like * and +, for example?\\nNamed methods like giveRaise and promote would usually make more sense.\\nBecause of this, we won’t go into details on every operator overloading method available\\nin Python in this book. Still, there is one operator overloading method you are likely\\nto see in almost every realistic Python class: the __init__ method, which is known as\\nthe constructor method and is used to initialize objects’ state. You should pay special\\nattention to this method, because __init__, along with the self argument, turns out\\nto be a key requirement to reading and understanding most OOP code in Python.\\n\\nA Third Example\\nOn to another example. This time, we’ll define a subclass of the prior section’s Second\\nClass that implements three specially named attributes that Python will call automat-\\nically:\\n\\n• __init__ is run when a new instance object is created: self is the new ThirdClass\\n\\nobject.1\\n\\n• __add__ is run when a ThirdClass instance appears in a + expression.\\n• __str__ is run when an object is printed (technically, when it’s converted to its\\n\\nprint string by the str built-in function or its Python internals equivalent).\\n\\nOur new subclass also defines a normally named method called mul, which changes the\\ninstance object in place. Here’s the new subclass:\\n\\n>>> class ThirdClass(SecondClass):                     # Inherit from SecondClass\\n        def __init__(self, value):                     # On \"ThirdClass(value)\"\\n            self.data = value\\n        def __add__(self, other):                      # On \"self + other\"\\n            return ThirdClass(self.data + other)\\n        def __str__(self):                             # On \"print(self)\", \"str()\"\\n            return \\'[ThirdClass: %s]\\' % self.data\\n\\n1. Not to be confused with the __init__.py files in module packages! The method here is a class constructor\\nfunction used to initialize the newly created instance, not a module package. See Chapter 24 for more\\ndetails.\\n\\n806 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0c        def mul(self, other):                          # In-place change: named\\n            self.data *= other\\n\\n>>> a = ThirdClass(\\'abc\\')           # __init__ called\\n>>> a.display()                     # Inherited method called\\nCurrent value = \"abc\"\\n>>> print(a)                        # __str__: returns display string\\n[ThirdClass: abc]\\n\\n>>> b = a + \\'xyz\\'                   # __add__: makes a new instance\\n>>> b.display()                     # b has all ThirdClass methods\\nCurrent value = \"abcxyz\"\\n>>> print(b)                        # __str__: returns display string\\n[ThirdClass: abcxyz]\\n\\n>>> a.mul(3)                        # mul: changes instance in place\\n>>> print(a)\\n[ThirdClass: abcabcabc]\\n\\nThirdClass “is a” SecondClass, so its instances inherit the customized display method\\nfrom SecondClass of the preceding section. This time, though, ThirdClass creation calls\\npass an argument (e.g., “abc”). This argument is passed to the value argument in the\\n__init__  constructor  and  assigned  to  self.data  there.  The  net  effect  is  that  Third\\nClass arranges to set the data attribute automatically at construction time, instead of\\nrequiring setdata calls after the fact.\\nFurther, ThirdClass objects can now show up in + expressions and print calls. For +,\\nPython passes the instance object on the left to the self argument in __add__ and the\\nvalue on the right to other, as illustrated in Figure 27-3; whatever __add__ returns be-\\ncomes the result of the + expression (more on its result in a moment).\\nFor print, Python passes the object being printed to self in __str__; whatever string\\nthis method returns is taken to be the print string for the object. With __str__ (or its\\nmore broadly relevant twin __repr__, which we’ll meet and use in the next chapter),\\nwe can use a normal print to display objects of this class, instead of calling the special\\ndisplay method.\\n\\nFigure 27-3. In operator overloading, expression operators and other built-in operations performed\\non class instances are mapped back to specially named methods in the class. These special methods\\nare optional and may be inherited as usual. Here, a + expression triggers the __add__ method.\\n\\nClasses Can Intercept Python Operators\\n\\n| 807\\n\\n\\x0cSpecially named methods such as __init__, __add__, and __str__ are inherited by sub-\\nclasses and instances, just like any other names assigned in a class. If they’re not coded\\nin a class, Python looks for such names in all its superclasses, as usual. Operator over-\\nloading method names are also not built-in or reserved words; they are just attributes\\nthat Python looks for when objects appear in various contexts. Python usually calls\\nthem  automatically,  but  they  may  occasionally  be  called  by  your  code  as  well.  For\\nexample, the __init__ method is often called manually to trigger initialization steps in\\na superclass, as we’ll see in the next chapter.\\n\\nReturning results, or not\\nSome operator overloading methods like __str__ require results, but others are more\\nflexible. For example, notice how the __add__ method makes and returns a new instance\\nobject of its class, by calling ThirdClass with the result value—which in turn triggers\\n__init__ to initialize the result. This is a common convention, and explains why b in\\nthe listing has a display method; it’s a ThirdClass object too, because that’s what +\\nreturns for this class’s objects. This essentially propagates the type.\\nBy contrast, mul changes the current instance object in place, by reassigning the self\\nattribute. We could overload the * expression to do the latter, but this would be too\\ndifferent from the behavior of * for built-in types such as numbers and strings, for which\\nit  always  makes  new  objects.  Common  practice  dictates  that  overloaded  operators\\nshould work the same way that built-in operator implementations do. Because operator\\noverloading is really just an expression-to-method dispatch mechanism, though, you\\ncan interpret operators any way you like in your own class objects.\\n\\nWhy Use Operator Overloading?\\nAs a class designer, you can choose to use operator overloading or not. Your choice\\nsimply depends on how much you want your object to look and feel like built-in types.\\nAs mentioned earlier, if you omit an operator overloading method and do not inherit\\nit from a superclass, the corresponding operation will not be supported for your in-\\nstances; if it’s attempted, an exception will be raised (or, in some cases like printing, a\\nstandard default will be used).\\nFrankly, many operator overloading methods tend to be used only when you are im-\\nplementing objects that are mathematical in nature; a vector or matrix class may over-\\nload the addition operator, for example, but an employee class likely would not. For\\nsimpler classes, you might not use overloading at all, and would rely instead on explicit\\nmethod calls to implement your objects’ behavior.\\nOn the other hand, you might decide to use operator overloading if you need to pass\\na user-defined object to a function that was coded to expect the operators available on\\na built-in type like a list or a dictionary. Implementing the same operator set in your\\nclass will ensure that your objects support the same expected object interface and so\\nare compatible with the function. Although we won’t cover every operator overloading\\n\\n808 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0cmethod in this book, we’ll survey additional common operator overloading techniques\\nin action in Chapter 30.\\nOne overloading method we will use often here is the __init__ constructor method,\\nused to initialize newly created instance objects, and present in almost every realistic\\nclass. Because it allows classes to fill out the attributes in their new instances immedi-\\nately, the constructor is useful for almost every kind of class you might code. In fact,\\neven though instance attributes are not declared in Python, you can usually find out\\nwhich attributes an instance will have by inspecting its class’s __init__ method.\\nOf course, there’s nothing wrong with experimenting with interesting language tools,\\nbut they don’t always translate to production code. With time and experience, you’ll\\nfind these programming patterns and guidelines to be natural and nearly automatic.\\n\\nThe World’s Simplest Python Class\\nWe’ve begun studying class statement syntax in detail in this chapter, but I’d again\\nlike to remind you that the basic inheritance model that classes produce is very simple\\n—all it really involves is searching for attributes in trees of linked objects. In fact, we\\ncan create a class with nothing in it at all. The following statement makes a class with\\nno attributes attached, an empty namespace object:\\n\\n>>> class rec: pass              # Empty namespace object\\n\\nWe need the no-operation pass placeholder statement (discussed in Chapter 13) here\\nbecause we don’t have any methods to code. After we make the class by running this\\nstatement interactively, we can start attaching attributes to the class by assigning names\\nto it completely outside of the original class statement:\\n\\n>>> rec.name = \\'Bob\\'             # Just objects with attributes\\n>>> rec.age  = 40\\n\\nAnd, after we’ve created these attributes by assignment, we can fetch them with the\\nusual syntax. When used this way, a class is roughly similar to a “struct” in C, or a\\n“record” in Pascal. It’s basically an object with field names attached to it (as we’ll see\\nahead, doing similar with dictionary keys requires extra characters):\\n\\n>>> print(rec.name)              # Like a C struct or a record\\nBob\\n\\nNotice that this works even though there are no instances of the class yet; classes are\\nobjects in their own right, even without instances. In fact, they are just self-contained\\nnamespaces; as long as we have a reference to a class, we can set or change its attributes\\nanytime we wish. Watch what happens when we do create two instances, though:\\n\\n>>> x = rec()                    # Instances inherit class names\\n>>> y = rec()\\n\\nThe World’s Simplest Python Class\\n\\n| 809\\n\\n\\x0cThese instances begin their lives as completely empty namespace objects. Because they\\nremember the class from which they were made, though, they will obtain the attributes\\nwe attached to the class by inheritance:\\n\\n>>> x.name, y.name               # name is stored on the class only\\n(\\'Bob\\', \\'Bob\\')\\n\\nReally, these instances have no attributes of their own; they simply fetch the name at-\\ntribute from the class object where it is stored. If we do assign an attribute to an instance,\\nthough, it creates (or changes) the attribute in that object, and no other—crucially,\\nattribute references kick off inheritance searches, but attribute assignments affect only\\nthe objects in which the assignments are made. Here, this means that x gets its own\\nname, but y still inherits the name attached to the class above it:\\n>>> x.name = \\'Sue\\'               # But assignment changes x only\\n>>> rec.name, x.name, y.name\\n(\\'Bob\\', \\'Sue\\', \\'Bob\\')\\n\\nIn fact, as we’ll explore in more detail in Chapter 29, the attributes of a namespace\\nobject are usually implemented as dictionaries, and class inheritance trees are (generally\\nspeaking) just dictionaries with links to other dictionaries. If you know where to look,\\nyou can see this explicitly.\\nFor example, the __dict__ attribute is the namespace dictionary for most class-based\\nobjects. Some classes may also (or instead) define attributes in __slots__, an advanced\\nand  seldom-used  feature  that  we’ll  note  in  Chapter  28,  but  largely  postpone  until\\nChapter  31  and  Chapter  32.  Normally,  __dict__  literally  is  an  instance’s  attribute\\nnamespace.\\nTo  illustrate,  the  following  was  run  in  Python  3.3;  the  order  of  names  and  set  of\\n__X__ internal names present can vary from release to release, and we filter out built-\\nins with a generator expression as we’ve done before, but the names we assigned are\\npresent in all:\\n\\n>>> list(rec.__dict__.keys())\\n[\\'age\\', \\'__module__\\', \\'__qualname__\\', \\'__weakref__\\', \\'name\\', \\'__dict__\\', \\'__doc__\\']\\n\\n>>> list(name for name in rec.__dict__ if not name.startswith(\\'__\\'))\\n[\\'age\\', \\'name\\']\\n>>> list(x.__dict__.keys())\\n[\\'name\\']\\n>>> list(y.__dict__.keys())           # list() not required in Python 2.X\\n[]\\n\\nHere, the class’s namespace dictionary shows the name and age attributes we assigned\\nto it, x has its own name, and y is still empty. Because of this model, an attribute can\\noften  be  fetched  by  either  dictionary  indexing  or  attribute  notation,  but  only  if  it’s\\npresent on the object in question—attribute notation kicks off inheritance search, but\\nindexing looks in the single object only (as we’ll see later, both have valid roles):\\n\\n>>> x.name, x.__dict__[\\'name\\']        # Attributes present here are dict keys\\n(\\'Sue\\', \\'Sue\\')\\n\\n810 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0c>>> x.age                             # But attribute fetch checks classes too\\n40\\n>>> x.__dict__[\\'age\\']                 # Indexing dict does not do inheritance\\nKeyError: \\'age\\'\\n\\nTo facilitate inheritance search on attribute fetches, each instance has a link to its class\\nthat Python creates for us—it’s called __class__, if you want to inspect it:\\n\\n>>> x.__class__                       # Instance to class link\\n<class \\'__main__.rec\\'>\\n\\nClasses also have a __bases__ attribute, which is a tuple of references to their superclass\\nobjects—in this example just the implied object root class in Python 3.X we’ll explore\\nlater (you’ll get an empty tuple in 2.X instead):\\n\\n>>> rec.__bases__                     # Class to superclasses link, () in 2.X\\n(<class \\'object\\'>,)\\n\\nThese two attributes are how class trees are literally represented in memory by Python.\\nInternal details like these are not required knowledge—class trees are implied by the\\ncode you run, and their search is normally automatic—but they can often help demys-\\ntify the model.\\nThe main point to take away from this look under the hood is that Python’s class model\\nis extremely dynamic. Classes and instances are just namespace objects, with attributes\\ncreated on the fly by assignment. Those assignments usually happen within the class\\nstatements you code, but they can occur anywhere you have a reference to one of the\\nobjects in the tree.\\nEven methods, normally created by a def nested in a class, can be created completely\\nindependently of any class object. The following, for example, defines a simple function\\noutside of any class that takes one argument:\\n\\n>>> def uppername(obj):\\n        return obj.name.upper()       # Still needs a self argument (obj)\\n\\nThere is nothing about a class here yet—it’s a simple function, and it can be called as\\nsuch at this point, provided we pass in an object obj with a name attribute, whose value\\nin turn has an upper method—our class instances happen to fit the expected interface,\\nand kick off string uppercase conversion:\\n\\n>>> uppername(x)                      # Call as a simple function\\n\\'SUE\\'\\n\\nIf  we  assign  this  simple  function  to  an  attribute  of  our  class,  though,  it  becomes  a\\nmethod, callable through any instance, as well as through the class name itself as long\\nas we pass in an instance manually—a technique we’ll leverage further in the next\\nchapter:2\\n\\n>>> rec.method = uppername            # Now it\\'s a class\\'s method!\\n\\n>>> x.method()                        # Run  method to process x\\n\\'SUE\\'\\n\\nThe World’s Simplest Python Class\\n\\n| 811\\n\\n\\x0c>>> y.method()                        # Same, but pass y to self\\n\\'BOB\\'\\n\\n>>> rec.method(x)                     # Can call through instance or class\\n\\'SUE\\'\\n\\nNormally, classes are filled out by class statements, and instance attributes are created\\nby assignments to self attributes in method functions. The point again, though, is that\\nthey don’t have to be; OOP in Python really is mostly about looking up attributes in\\nlinked namespace objects.\\n\\nRecords Revisited: Classes Versus Dictionaries\\nAlthough the simple classes of the prior section are meant to illustrate class model\\nbasics, the techniques they employ can also be used for real work. For example, Chap-\\nter 8 and Chapter 9 showed how to use dictionaries, tuples, and lists to record properties\\nof entities in our programs, generically called records. It turns out that classes can often\\nserve better in this role—they package information like dictionaries, but can also bun-\\ndle processing logic in the form of methods. For reference, here is an example for tuple-\\nand dictionary-based records we used earlier in the book (using one of many dictionary\\ncoding techniques):\\n\\n>>> rec = (\\'Bob\\', 40.5, [\\'dev\\', \\'mgr\\'])     # Tuple-based record\\n>>> print(rec[0])\\nBob\\n\\n>>> rec = {}\\n>>> rec[\\'name\\'] = \\'Bob\\'                     # Dictionary-based record\\n>>> rec[\\'age\\']  = 40.5                      # Or {...}, dict(n=v), etc.\\n>>> rec[\\'jobs\\'] = [\\'dev\\', \\'mgr\\']\\n>>>\\n>>> print(rec[\\'name\\'])\\nBob\\n\\nThis code emulates tools like records in other languages. As we just saw, though, there\\nare also multiple ways to do the same with classes. Perhaps the simplest is this—trading\\nkeys for attributes:\\n\\n>>> class rec: pass\\n\\n>>> rec.name = \\'Bob\\'                        # Class-based record\\n>>> rec.age  = 40.5\\n>>> rec.jobs = [\\'dev\\', \\'mgr\\']\\n\\n2. In fact, this is one of the reasons the self argument must always be explicit in Python methods—because\\nmethods can be created as simple functions independent of a class, they need to make the implied instance\\nargument explicit. They can be called as either functions or methods, and Python can neither guess nor\\nassume that a simple function might eventually become a class’s method. The main reason for the explicit\\nself argument, though, is to make the meanings of names more obvious: names not referenced through\\nself are simple variables mapped to scopes, while names referenced through self with attribute notation\\nare obviously instance attributes.\\n\\n812 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0c>>>\\n>>> print(rec.name)\\nBob\\n\\nThis code has substantially less syntax than the dictionary equivalent. It uses an empty\\nclass statement to generate an empty namespace object. Once we make the empty\\nclass, we fill it out by assigning class attributes over time, as before.\\nThis works, but a new class statement will be required for each distinct record we will\\nneed. Perhaps more typically, we can instead generate instances of an empty class to\\nrepresent each distinct entity:\\n\\n>>> class rec: pass\\n\\n>>> pers1 = rec()                           # Instance-based records\\n>>> pers1.name = \\'Bob\\'\\n>>> pers1.jobs = [\\'dev\\', \\'mgr\\']\\n>>> pers1.age  = 40.5\\n>>>\\n>>> pers2 = rec()\\n>>> pers2.name = \\'Sue\\'\\n>>> pers2.jobs = [\\'dev\\', \\'cto\\']\\n>>>\\n>>> pers1.name, pers2.name\\n(\\'Bob\\', \\'Sue\\')\\n\\nHere, we make two records from the same class. Instances start out life empty, just like\\nclasses. We then fill in the records by assigning to attributes. This time, though, there\\nare two separate objects, and hence two separate name attributes. In fact, instances of\\nthe same class don’t even have to have the same set of attribute names; in this example,\\none has a unique age name. Instances really are distinct namespaces, so each has a\\ndistinct attribute dictionary. Although they are normally filled out consistently by a\\nclass’s methods, they are more flexible than you might expect.\\nFinally, we might instead code a more full-blown class to implement the record and its\\nprocessing—something that data-oriented dictionaries do not directly support:\\n\\n>>> class Person:\\n        def __init__(self, name, jobs, age=None):      # class = data + logic\\n            self.name = name\\n            self.jobs = jobs\\n            self.age  = age\\n        def info(self):\\n            return (self.name, self.jobs)\\n\\n>>> rec1 = Person(\\'Bob\\', [\\'dev\\', \\'mgr\\'], 40.5)         # Construction calls\\n>>> rec2 = Person(\\'Sue\\', [\\'dev\\', \\'cto\\'])\\n>>>\\n>>> rec1.jobs, rec2.info()                             # Attributes + methods\\n([\\'dev\\', \\'mgr\\'], (\\'Sue\\', [\\'dev\\', \\'cto\\']))\\n\\nThis scheme also makes multiple instances, but the class is not empty this time: we’ve\\nadded logic (methods) to initialize instances at construction time and collect attributes\\n\\nThe World’s Simplest Python Class\\n\\n| 813\\n\\n\\x0cinto a tuple on request. The constructor imposes some consistency on instances here\\nby always setting the name, job, and age attributes, even though the latter can be omitted\\nwhen an object is made. Together, the class’s methods and instance attributes create a\\npackage, which combines both data and logic.\\nWe could further extend this code by adding logic to compute salaries, parse names,\\nand so on. Ultimately, we might link the class into a larger hierarchy to inherit and\\ncustomize an existing set of methods via the automatic attribute search of classes, or\\nperhaps even store instances of the class in a file with Python object pickling to make\\nthem persistent. In fact, we will—in the next chapter, we’ll expand on this analogy\\nbetween classes and records with a more realistic running example that demonstrates\\nclass basics in action.\\nTo be fair to other tools, in this form, the two class construction calls above more closely\\nresemble dictionaries made all at once, but still seem less cluttered and provide extra\\nprocessing methods. In fact, the class’s construction calls more closely resemble Chap-\\nter 9’s named tuples—which makes sense, given that named tuples really are classes\\nwith extra logic to map attributes to tuple offsets:\\n\\n>>> rec = dict(name=\\'Bob\\', age=40.5, jobs=[\\'dev\\', \\'mgr\\'])        # Dictionaries\\n\\n>>> rec = {\\'name\\': \\'Bob\\', \\'age\\': 40.5, \\'jobs\\': [\\'dev\\', \\'mgr\\']}\\n\\n>>> rec = Rec(\\'Bob\\', 40.5, [\\'dev\\', \\'mgr\\'])                       # Named tuples\\n\\nIn the end, although types like dictionaries and tuples are flexible, classes allow us to\\nadd behavior to objects in ways that built-in types and simple functions do not directly\\nsupport. Although we can store functions in dictionaries, too, using them to process\\nimplied instances is nowhere near as natural and structured as it is in classes. To see\\nthis more clearly, let’s move ahead to the next chapter.\\n\\nChapter Summary\\nThis chapter introduced the basics of coding classes in Python. We studied the syntax\\nof the class statement, and we saw how to use it to build up a class inheritance tree.\\nWe also studied how Python automatically fills in the first argument in method func-\\ntions, how attributes are attached to objects in a class tree by simple assignment, and\\nhow specially named operator overloading methods intercept and implement built-in\\noperations for our instances (e.g., expressions and printing).\\nNow that we’ve learned all about the mechanics of coding classes in Python, the next\\nchapter turns to a larger and more realistic example that ties together much of what\\nwe’ve learned about OOP so far, and introduces some new topics. After that, we’ll\\ncontinue our look at class coding, taking a second pass over the model to fill in some\\nof the details that were omitted here to keep things simple. First, though, let’s work\\nthrough a quiz to review the basics we’ve covered so far.\\n\\n814 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0cTest Your Knowledge: Quiz\\n1. How are classes related to modules?\\n2. How are instances and classes created?\\n3. Where and how are class attributes created?\\n4. Where and how are instance attributes created?\\n5. What does self mean in a Python class?\\n6. How is operator overloading coded in a Python class?\\n7. When might you want to support operator overloading in your classes?\\n8. Which operator overloading method is most commonly used?\\n9. What are two key concepts required to understand Python OOP code?\\n\\nTest Your Knowledge: Answers\\n1. Classes are always nested inside a module; they are attributes of a module object.\\nClasses and modules are both namespaces, but classes correspond to statements\\n(not entire files) and support the OOP notions of multiple instances, inheritance,\\nand operator overloading (modules do not). In a sense, a module is like a single-\\ninstance class, without inheritance, which corresponds to an entire file of code.\\n\\n2. Classes are made by running class statements; instances are created by calling a\\n\\nclass as though it were a function.\\n\\n3. Class attributes are created by assigning attributes to a class object. They are nor-\\nmally generated by top-level assignments nested in a class statement—each name\\nassigned  in  the  class  statement  block  becomes  an  attribute  of  the  class  object\\n(technically, the class statement’s local scope morphs into the class object’s at-\\ntribute  namespace,  much  like  a  module).  Class  attributes  can  also  be  created,\\nthough, by assigning attributes to the class anywhere a reference to the class object\\nexists—even outside the class statement.\\n\\n4. Instance attributes are created by assigning attributes to an instance object. They\\nare  normally  created  within  a  class’s  method  functions  coded  inside  the  class\\nstatement, by assigning attributes to the self argument (which is always the im-\\nplied instance). Again, though, they may be created by assignment anywhere a\\nreference to the instance appears, even outside the class statement. Normally, all\\ninstance attributes are initialized in the __init__ constructor method; that way,\\nlater method calls can assume the attributes already exist.\\n\\n5. self  is  the  name  commonly  given  to  the  first  (leftmost)  argument  in  a  class’s\\nmethod function; Python automatically fills it in with the instance object that is\\nthe implied subject of the method call. This argument need not be called  self\\n(though this is a very strong convention); its position is what is significant. (Ex-\\nC++ or Java programmers might prefer to call it this because in those languages\\n\\nTest Your Knowledge: Answers\\n\\n| 815\\n\\n\\x0cthat name reflects the same idea; in Python, though, this argument must always be\\nexplicit.)\\n\\n6. Operator overloading is coded in a Python class with specially named methods;\\nthey all begin and end with double underscores to make them unique. These are\\nnot built-in or reserved names; Python just runs them automatically when an in-\\nstance appears in the corresponding operation. Python itself defines the mappings\\nfrom operations to special method names.\\n\\n7. Operator overloading is useful to implement objects that resemble built-in types\\n(e.g., sequences or numeric objects such as matrixes), and to mimic the built-in\\ntype interface expected by a piece of code. Mimicking built-in type interfaces en-\\nables you to pass in class instances that also have state information (i.e., attributes\\nthat remember data between operation calls). You shouldn’t use operator over-\\nloading when a simple named method will suffice, though.\\n\\n8. The __init__ constructor method is the most commonly used; almost every class\\nuses  this  method  to  set  initial  values  for  instance  attributes  and  perform  other\\nstartup tasks.\\n\\n9. The  special  self  argument  in  method  functions  and  the  __init__  constructor\\nmethod are the two cornerstones of OOP code in Python; if you get these, you\\nshould be able to read the text of most OOP Python code—apart from these, it’s\\nlargely just packages of functions. The inheritance search matters too, of course,\\nbut self represents the automatic object argument, and __init__ is widespread.\\n\\n816 | Chapter 27:\\u2002Class Coding Basics\\n\\n\\x0cCHAPTER 28\\nA More Realistic Example\\n\\nWe’ll dig into more class syntax details in the next chapter. Before we do, though, I’d\\nlike to show you a more realistic example of classes in action that’s more practical than\\nwhat we’ve seen so far. In this chapter, we’re going to build a set of classes that do\\nsomething more concrete—recording and processing information about people. As\\nyou’ll see, what we call instances and classes in Python programming can often serve\\nthe same roles as records and programs in more traditional terms.\\nSpecifically, in this chapter we’re going to code two classes:\\n\\n• Person—a class that creates and processes information about people\\n• Manager—a customization of Person that modifies inherited behavior\\n\\nAlong the way, we’ll make instances of both classes and test out their functionality.\\nWhen we’re done, I’ll show you a nice example use case for classes—we’ll store our\\ninstances in a shelve object-oriented database, to make them permanent. That way, you\\ncan use this code as a template for fleshing out a full-blown personal database written\\nentirely in Python.\\nBesides actual utility, though, our aim here is also educational: this chapter provides a\\ntutorial on object-oriented programming in Python. Often, people grasp the last chap-\\nter’s class syntax on paper, but have trouble seeing how to get started when confronted\\nwith having to code a new class from scratch. Toward this end, we’ll take it one step\\nat a time here, to help you learn the basics; we’ll build up the classes gradually, so you\\ncan see how their features come together in complete programs.\\nIn  the  end,  our  classes  will  still  be  relatively  small  in  terms  of  code,  but  they  will\\ndemonstrate all of the main ideas in Python’s OOP model. Despite its syntax details,\\nPython’s class system really is largely just a matter of searching for an attribute in a tree\\nof objects, along with a special first argument for functions.\\n\\n817\\n\\n\\x0cStep 1: Making Instances\\nOK, so much for the design phase—let’s move on to implementation. Our first task is\\nto start coding the main class, Person. In your favorite text editor, open a new file for\\nthe code we’ll be writing. It’s a fairly strong convention in Python to begin module\\nnames with a lowercase letter and class names with an uppercase letter; like the name\\nof self arguments in methods, this is not required by the language, but it’s so common\\nthat deviating might be confusing to people who later read your code. To conform,\\nwe’ll call our new module file person.py and our class within it Person, like this:\\n\\n# File person.py (start)\\n\\nclass Person:                             # Start a class\\n\\nAll our work will be done in this file until later in this chapter. We can code any number\\nof functions and classes in a single module file in Python, and this one’s person.py name\\nmight not make much sense if we add unrelated components to it later. For now, we’ll\\nassume everything in it will be Person-related. It probably should be anyhow—as we’ve\\nlearned, modules tend to work best when they have a single, cohesive purpose.\\n\\nCoding Constructors\\nNow, the first thing we want to do with our Person class is record basic information\\nabout people—to fill out record fields, if you will. Of course, these are known as in-\\nstance object attributes in Python-speak, and they generally are created by assignment\\nto self attributes in a class’s method functions. The normal way to give instance at-\\ntributes their first values is to assign them to self in the __init__ constructor method,\\nwhich contains code run automatically by Python each time an instance is created. Let’s\\nadd one to our class:\\n\\n# Add record field initialization\\n\\nclass Person:\\n    def __init__(self, name, job, pay):      # Constructor takes three arguments\\n        self.name = name                     # Fill out fields when created\\n        self.job  = job                      # self is the new instance object\\n        self.pay  = pay\\n\\nThis is a very common coding pattern: we pass in the data to be attached to an instance\\nas arguments to the constructor method and assign them to self to retain them per-\\nmanently. In OO terms, self is the newly created instance object, and name, job, and\\npay become state information—descriptive data saved on an object for later use. Al-\\nthough other techniques (such as enclosing scope reference closures) can save details,\\ntoo, instance attributes make this very explicit and easy to understand.\\nNotice that the argument names appear twice here. This code might even seem a bit\\nredundant at first, but it’s not. The job argument, for example, is a local variable in the\\nscope of the __init__ function, but self.job is an attribute of the instance that’s the\\n\\n818 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cimplied subject of the method call. They are two different variables, which happen to\\nhave  the  same  name.  By  assigning  the  job  local  to  the  self.job  attribute  with\\nself.job=job, we save the passed-in job on the instance for later use. As usual in Python,\\nwhere a name is assigned, or what object it is assigned to, determines what it means.\\nSpeaking of arguments, there’s really nothing magical about __init__, apart from the\\nfact that it’s called automatically when an instance is made and has a special first ar-\\ngument. Despite its weird name, it’s a normal function and supports all the features of\\nfunctions we’ve already covered. We can, for example, provide defaults for some of its\\narguments, so they need not be provided in cases where their values aren’t available or\\nuseful.\\nTo demonstrate, let’s make the job argument optional—it will default to None, meaning\\nthe  person  being  created  is  not  (currently)  employed.  If  job  defaults  to  None,  we’ll\\nprobably want to default pay to 0, too, for consistency (unless some of the people you\\nknow manage to get paid without having jobs!). In fact, we have to specify a default\\nfor pay because according to Python’s syntax rules and Chapter 18, any arguments in\\na function’s header after the first default must all have defaults, too:\\n\\n# Add defaults for constructor arguments\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):         # Normal function args\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n\\nWhat this code means is that we’ll need to pass in a name when making Persons, but\\njob and pay are now optional; they’ll default to None and 0 if omitted. The self argu-\\nment, as usual, is filled in by Python automatically to refer to the instance object—\\nassigning values to attributes of self attaches them to the new instance.\\n\\nTesting As You Go\\nThis class doesn’t do much yet—it essentially just fills out the fields of a new record—\\nbut it’s a real working class. At this point we could add more code to it for more features,\\nbut we won’t do that yet. As you’ve probably begun to appreciate already, programming\\nin Python is really a matter of incremental prototyping—you write some code, test it,\\nwrite more code, test again, and so on. Because Python provides both an interactive\\nsession and nearly immediate turnaround after code changes, it’s more natural to test\\nas you go than to write a huge amount of code to test all at once.\\nBefore adding more features, then, let’s test what we’ve got so far by making a few\\ninstances of our class and displaying their attributes as created by the constructor. We\\ncould do this interactively, but as you’ve also probably surmised by now, interactive\\ntesting has its limits—it gets tedious to have to reimport modules and retype test cases\\neach time you start a new testing session. More commonly, Python programmers use\\n\\nStep 1: Making Instances\\n\\n| 819\\n\\n\\x0cthe interactive prompt for simple one-off tests but do more substantial testing by writing\\ncode at the bottom of the file that contains the objects to be tested, like this:\\n\\n# Add incremental self-test code\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n\\nbob = Person(\\'Bob Smith\\')                         # Test the class\\nsue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)  # Runs __init__ automatically\\nprint(bob.name, bob.pay)                          # Fetch attached attributes\\nprint(sue.name, sue.pay)                          # sue\\'s and bob\\'s attrs differ\\n\\nNotice here that the bob object accepts the defaults for job and pay, but sue provides\\nvalues explicitly. Also note how we use keyword arguments when making sue; we could\\npass by position instead, but the keywords may help remind us later what the data is,\\nand they allow us to pass the arguments in any left-to-right order we like. Again, despite\\nits unusual name, __init__ is a normal function, supporting everything you already\\nknow  about  functions—including  both  defaults  and  pass-by-name  keyword  argu-\\nments.\\nWhen this file runs as a script, the test code at the bottom makes two instances of our\\nclass and prints two attributes of each (name and pay):\\n\\nC:\\\\code> person.py\\nBob Smith 0\\nSue Jones 100000\\n\\nYou can also type this file’s test code at Python’s interactive prompt (assuming you\\nimport the Person class there first), but coding canned tests inside the module file like\\nthis makes it much easier to rerun them in the future.\\nAlthough this is fairly simple code, it’s already demonstrating something important.\\nNotice that bob’s name is not sue’s, and sue’s pay is not bob’s. Each is an independent\\nrecord of information. Technically, bob and sue are both namespace objects—like all\\nclass instances, they each have their own independent copy of the state information\\ncreated by the class. Because each instance of a class has its own set of self attributes,\\nclasses are a natural for recording information for multiple objects this way; just like\\nbuilt-in types such as lists and dictionaries, classes serve as a sort of object factory.\\nOther Python program structures, such as functions and modules, have no such con-\\ncept. Chapter 17’s closure functions come close in terms of per-call state, but don’t\\nhave the multiple methods, inheritance, and larger structure we get from classes.\\n\\nUsing Code Two Ways\\nAs is, the test code at the bottom of the file works, but there’s a big catch—its top-level\\nprint statements run both when the file is run as a script and when it is imported as a\\n\\n820 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cmodule. This means if we ever decide to import the class in this file in order to use it\\nsomewhere else (and we will soon in this chapter), we’ll see the output of its test code\\nevery time the file is imported. That’s not very good software citizenship, though: client\\nprograms probably don’t care about our internal tests and won’t want to see our output\\nmixed in with their own.\\nAlthough we could split the test code off into a separate file, it’s often more convenient\\nto code tests in the same file as the items to be tested. It would be better to arrange to\\nrun the test statements at the bottom only when the file is run for testing, not when the\\nfile is imported. That’s exactly what the module __name__ check is designed for, as you\\nlearned in the preceding part of this book. Here’s what this addition looks like—add\\nthe require test and indent your self-test code:\\n\\n# Allow this file to be imported as well as run/tested\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n\\nif __name__ == \\'__main__\\':                  # When run for testing only\\n    # self-test code\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob.name, bob.pay)\\n    print(sue.name, sue.pay)\\n\\nNow, we get exactly the behavior we’re after—running the file as a top-level script tests\\nit because its __name__ is __main__, but importing it as a library of classes later does not:\\n\\nC:\\\\code> person.py\\nBob Smith 0\\nSue Jones 100000\\n\\nC:\\\\code> python\\nPython 3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) ...\\n>>> import person\\n>>>\\n\\nWhen imported, the file now defines the class, but does not use it. When run directly,\\nthis file creates two instances of our class as before, and prints two attributes of each;\\nagain, because each instance is an independent namespace object, the values of their\\nattributes differ.\\n\\nVersion Portability: Prints\\n\\nAll of this chapter’s code works on both Python 2.X and 3.X, but I’m running it under\\nPython 3.X, and a few of its outputs use 3.X print function calls with multiple argu-\\nments. As explained in Chapter 11, this means that some of its outputs may vary slightly\\nunder Python 2.X. If you run under 2.X the code will work as is, but you’ll notice\\n\\nStep 1: Making Instances\\n\\n| 821\\n\\n\\x0cparentheses around some output lines because the extra parentheses in a print turn\\nmultiple items into a tuple in 2.X only:\\n\\nC:\\\\code> c:\\\\python27\\\\python person.py\\n(\\'Bob Smith\\', 0)\\n(\\'Sue Jones\\', 100000)\\n\\nIf this difference is the sort of detail that might keep you awake at nights, simply remove\\nthe parentheses to use 2.X print statements, or add an import of Python 3.X’s print\\nfunction at the top of your script, as shown in Chapter 11 (I’d add this everywhere here,\\nbut it’s a bit distracting):\\n\\nfrom __future__ import print_function\\n\\nYou can also avoid the extra parentheses portably by using formatting to yield a single\\nobject to print. Either of the following works in both 2.X and 3.X, though the method\\nform is newer:\\n\\nprint(\\'{0} {1}\\'.format(bob.name, bob.pay))    # Format method\\nprint(\\'%s %s\\' % (bob.name, bob.pay))          # Format expression\\n\\nAs also described in Chapter 11, such formatting may be required in some cases, be-\\ncause objects nested in a tuple may print differently than those printed as top-level\\nobjects—the former prints with __repr__ and the latter with __str__ (operator over-\\nloading methods discussed further in this chapter as well as Chapter 30).\\nTo sidestep this issue, this edition codes displays with __repr__ (the fallback in all cases,\\nincluding nesting and the interactive prompt) instead of __str__ (the default for prints)\\nso that all object appearances print the same in 3.X and 2.X, even those in superfluous\\ntuple parentheses!\\n\\nStep 2: Adding Behavior Methods\\nEverything looks good so far—at this point, our class is essentially a record factory; it\\ncreates and fills out fields of records (attributes of instances, in more Pythonic terms).\\nEven as limited as it is, though, we can still run some operations on its objects. Although\\nclasses add an extra layer of structure, they ultimately do most of their work by em-\\nbedding and processing basic core data types like lists and strings. In other words, if\\nyou already know how to use Python’s simple core types, you already know much of\\nthe Python class story; classes are really just a minor structural extension.\\nFor example, the name field of our objects is a simple string, so we can extract last names\\nfrom our objects by splitting on spaces and indexing. These are all core data type op-\\nerations, which work whether their subjects are embedded in class instances or not:\\n\\n>>> name = \\'Bob Smith\\'      # Simple string, outside class\\n>>> name.split()            # Extract last name\\n[\\'Bob\\', \\'Smith\\']\\n>>> name.split()[-1]        # Or [1], if always just two parts\\n\\'Smith\\'\\n\\n822 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cSimilarly, we can give an object a pay raise by updating its pay field—that is, by changing\\nits state information in place with an assignment. This task also involves basic opera-\\ntions that work on Python’s core objects, regardless of whether they are standalone or\\nembedded in a class structure (I’m formatting the result in the following to mask the\\nfact that different Pythons print a different number of decimal digits):\\n\\n>>> pay = 100000            # Simple variable, outside class\\n>>> pay *= 1.10             # Give a 10% raise\\n>>> print(\\'%.2f\\' % pay)     # Or: pay = pay * 1.10, if you like to type\\n110000.00                   # Or: pay = pay + (pay * .10), if you _really_ do!\\n\\nTo apply these operations to the Person objects created by our script, simply do to\\nbob.name and sue.pay what we just did to name and pay. The operations are the same,\\nbut the subjects are attached as attributes to objects created from our class:\\n\\n# Process embedded built-in types: strings, mutability\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob.name, bob.pay)\\n    print(sue.name, sue.pay)\\n    print(bob.name.split()[-1])            # Extract object\\'s last name\\n    sue.pay *= 1.10                        # Give this object a raise\\n    print(\\'%.2f\\' % sue.pay)\\n\\nWe’ve added the last three lines here; when they’re run, we extract bob’s last name by\\nusing basic string and list operations on his name field, and give sue a pay raise by\\nmodifying her pay attribute in place with basic number operations. In a sense, sue is\\nalso a mutable object—her state changes in place just like a list after an append call.\\nHere’s the new version’s output:\\n\\nBob Smith 0\\nSue Jones 100000\\nSmith\\n110000.00\\n\\nThe preceding code works as planned, but if you show it to a veteran software developer\\nhe or she will probably tell you that its general approach is not a great idea in practice.\\nHardcoding operations like these outside of the class can lead to maintenance problems\\nin the future.\\nFor example, what if you’ve hardcoded the last-name-extraction formula at many dif-\\nferent places in your program? If you ever need to change the way it works (to support\\na new name structure, for instance), you’ll need to hunt down and update every oc-\\ncurrence. Similarly, if the pay-raise code ever changes (e.g., to require approval or da-\\n\\nStep 2: Adding Behavior Methods\\n\\n| 823\\n\\n\\x0ctabase updates), you may have multiple copies to modify. Just finding all the appear-\\nances of such code may be problematic in larger programs—they may be scattered\\nacross many files, split into individual steps, and so on. In a prototype like this, frequent\\nchange is almost guaranteed.\\n\\nCoding Methods\\nWhat we really want to do here is employ a software design concept known as encap-\\nsulation—wrapping up operation logic behind interfaces, such that each operation is\\ncoded only once in our program. That way, if our needs change in the future, there is\\njust one copy to update. Moreover, we’re free to change the single copy’s internals\\nalmost arbitrarily, without breaking the code that uses it.\\nIn Python terms, we want to code operations on objects in a class’s methods, instead\\nof littering them throughout our program. In fact, this is one of the things that classes\\nare very good at—factoring code to remove redundancy and thus optimize maintaina-\\nbility. As an added bonus, turning operations into methods enables them to be applied\\nto any instance of the class, not just those that they’ve been hardcoded to process.\\nThis is all simpler in code than it may sound in theory. The following achieves encap-\\nsulation by moving the two operations from code outside the class to methods inside\\nthe class. While we’re at it, let’s change our self-test code at the bottom to use the new\\nmethods we’re creating, instead of hardcoding operations:\\n\\n# Add methods to encapsulate operations for maintainability\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):                               # Behavior methods\\n        return self.name.split()[-1]                  # self is implied subject\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))      # Must change here only\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob.name, bob.pay)\\n    print(sue.name, sue.pay)\\n    print(bob.lastName(), sue.lastName())             # Use the new methods\\n    sue.giveRaise(.10)                                # instead of hardcoding\\n    print(sue.pay)\\n\\nAs we’ve learned, methods are simply normal functions that are attached to classes and\\ndesigned to process instances of those classes. The instance is the subject of the method\\ncall and is passed to the method’s self argument automatically.\\nThe transformation to the methods in this version is straightforward. The new last\\nName method, for example, simply does to self what the previous version hardcoded\\n\\n824 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cfor bob, because self is the implied subject when the method is called. lastName also\\nreturns the result, because this operation is a called function now; it computes a value\\nfor  its  caller  to  use  arbitrarily,  even  if  it  is  just  to  be  printed.  Similarly,  the  new\\ngiveRaise method just does to self what we did to sue before.\\nWhen run now, our file’s output is similar to before—we’ve mostly just refactored the\\ncode to allow for easier changes in the future, not altered its behavior:\\n\\nBob Smith 0\\nSue Jones 100000\\nSmith Jones\\n110000\\n\\nA few coding details are worth pointing out here. First, notice that sue’s pay is now still\\nan integer after a pay raise—we convert the math result back to an integer by calling\\nthe int built-in within the method. Changing the value to either int or float is probably\\nnot a significant concern for this demo: integer and floating-point objects have the same\\ninterfaces and can be mixed within expressions. Still, we may need to address truncation\\nand rounding issues in a real system—money probably is significant to Persons!\\nAs we learned in Chapter 5, we might handle this by using the round(N, 2) built-in to\\nround and retain cents, using the decimal type to fix precision, or storing monetary\\nvalues as full floating-point numbers and displaying them with a %.2f or {0:.2f} for-\\nmatting string to show cents as we did earlier. For now, we’ll simply truncate any cents\\nwith int. For another idea, also see the money function in the formats.py module of\\nChapter 25; you could import this tool to show pay with commas, cents, and currency\\nsigns.\\nSecond, notice that we’re also printing sue’s last name this time—because the last-name\\nlogic has been encapsulated in a method, we get to use it on any instance of the class.\\nAs we’ve seen, Python tells a method which instance to process by automatically pass-\\ning it in to the first argument, usually called self. Specifically:\\n\\n• In the first call, bob.lastName(), bob is the implied subject passed to self.\\n• In the second call, sue.lastName(), sue goes to self instead.\\n\\nTrace through these calls to see how the instance winds up in self—it’s a key concept.\\nThe net effect is that the method fetches the name of the implied subject each time.\\nThe same happens for giveRaise. We could, for example, give bob a raise by calling\\ngiveRaise  for  both  instances  this  way,  too.  Unfortunately  for  bob,  though,  his  zero\\nstarting pay will prevent him from getting a raise as the program is currently coded—\\nnothing times anything is nothing, something we may want to address in a future 2.0\\nrelease of our software.\\nFinally, notice that the giveRaise method assumes that percent is passed in as a floating-\\npoint number between zero and one. That may be too radical an assumption in the real\\nworld (a 1000% raise would probably be a bug for most of us!); we’ll let it pass for this\\nprototype, but we might want to test or at least document this in a future iteration of\\n\\nStep 2: Adding Behavior Methods\\n\\n| 825\\n\\n\\x0cthis code. Stay tuned for a rehash of this idea in a later chapter in this book, where we’ll\\ncode something called function decorators and explore Python’s assert statement—\\nalternatives that can do the validity test for us automatically during development. In\\nChapter 39, for example, we’ll write a tool that lets us validate with strange incantations\\nlike the following:\\n\\n    @rangetest(percent=(0.0, 1.0))               # Use decorator to validate\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n\\nStep 3: Operator Overloading\\nAt this point, we have a fairly full-featured class that generates and initializes instances,\\nalong with two new bits of behavior for processing instances in the form of methods.\\nSo far, so good.\\nAs it stands, though, testing is still a bit less convenient than it needs to be—to trace\\nour objects, we have to manually fetch and print individual attributes (e.g., bob.name,\\nsue.pay). It would be nice if displaying an instance all at once actually gave us some\\nuseful information. Unfortunately, the default display format for an instance object\\nisn’t very good—it displays the object’s class name, and its address in memory (which\\nis essentially useless in Python, except as a unique identifier).\\nTo see this, change the last line in the script to print(sue) so it displays the object as a\\nwhole. Here’s what you’ll get—the output says that sue is an “object” in 3.X, and an\\n“instance” in 2.X as coded:\\n\\nBob Smith 0\\nSue Jones 100000\\nSmith Jones\\n<__main__.Person object at 0x00000000029A0668>\\n\\nProviding Print Displays\\nFortunately, it’s easy to do better by employing operator overloading—coding methods\\nin a class that intercept and process built-in operations when run on the class’s instan-\\nces. Specifically, we can make use of what are probably the second most commonly\\nused operator overloading methods in Python, after __init__: the __repr__ method\\nwe’ll deploy here, and its __str__ twin introduced in the preceding chapter.\\nThese methods are run automatically every time an instance is converted to its print\\nstring.  Because  that’s  what  printing  an  object  does,  the  net  transitive  effect  is  that\\nprinting an object displays whatever is returned by the object’s __str__ or __repr__\\nmethod, if the object either defines one itself or inherits one from a superclass. Double-\\nunderscored names are inherited just like any other.\\nTechnically, __str__ is preferred by print and str, and __repr__ is used as a fallback\\nfor these roles and in all other contexts. Although the two can be used to implement\\n\\n826 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cdifferent displays in different contexts, coding just __repr__ alone suffices to give a\\nsingle display in all cases—prints, nested appearances, and interactive echoes. This still\\nallows clients to provide an alternative display with __str__, but for limited contexts\\nonly; since this is a self-contained example, this is a moot point here.\\nThe __init__ constructor method we’ve already coded is, strictly speaking, operator\\noverloading too—it is run automatically at construction time to initialize a newly cre-\\nated instance. Constructors are so common, though, that they almost seem like a special\\ncase. More focused methods like __repr__ allow us to tap into specific operations and\\nprovide specialized behavior when our objects are used in those contexts.\\nLet’s put this into code. The following extends our class to give a custom display that\\nlists attributes when our class’s instances are displayed as a whole, instead of relying\\non the less useful default display:\\n\\n# Add __repr__ overload method for printing objects\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __repr__(self):                                        # Added method\\n        return \\'[Person: %s, %s]\\' % (self.name, self.pay)      # String to print\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n\\nNotice that we’re doing string % formatting to build the display string in __repr__ here;\\nat the bottom, classes use built-in type objects and operations like these to get their\\nwork done. Again, everything you’ve already learned about both built-in types and\\nfunctions applies to class-based code. Classes largely just add an additional layer of\\nstructure that packages functions and data together and supports extensions.\\nWe’ve also changed our self-test code to print objects directly, instead of printing in-\\ndividual attributes. When run, the output is more coherent and meaningful now; the\\n“[...]” lines are returned by our new __repr__, run automatically by print operations:\\n\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\n\\nStep 3: Operator Overloading | 827\\n\\n\\x0cDesign note: as we’ll learn in Chapter 30, the __repr__ method is often used to provide\\nan as-code low-level display of an object when present, and __str__ is reserved for more\\nuser-friendly informational displays like ours here. Sometimes classes provide both a\\n__str__ for user-friendly displays and a __repr__ with extra details for developers to\\nview. Because printing runs __str__ and the interactive prompt echoes results with\\n__repr__, this can provide both target audiences with an appropriate display.\\nSince __repr__ applies to more display cases, including nested appearances, and be-\\ncause  we’re  not  interested  in  displaying  two  different  formats,  the  all-inclusive\\n__repr__ is sufficient for our class. Here, this also means that our custom display will\\nbe used in 2.X if we list both bob and sue in a 3.X print call—a technically nested\\nappearance, per the sidebar in “Version Portability: Prints” on page 821.\\n\\nStep 4: Customizing Behavior by Subclassing\\nAt  this  point,  our  class  captures  much  of  the  OOP  machinery  in  Python:  it  makes\\ninstances, provides behavior in methods, and even does a bit of operator overloading\\nnow to intercept print operations in __repr__. It effectively packages our data and logic\\ntogether into a single, self-contained software component, making it easy to locate code\\nand straightforward to change it in the future. By allowing us to encapsulate behavior,\\nit also allows us to factor that code to avoid redundancy and its associated maintenance\\nheadaches.\\nThe only major OOP concept it does not yet capture is customization by inheritance.\\nIn some sense, we’re already doing inheritance, because instances inherit methods from\\ntheir classes. To demonstrate the real power of OOP, though, we need to define a\\nsuperclass/subclass relationship that allows us to extend our software and replace bits\\nof inherited behavior. That’s the main idea behind OOP, after all; by fostering a coding\\nmodel based upon customization of work already done, it can dramatically cut devel-\\nopment time.\\n\\nCoding Subclasses\\nAs a next step, then, let’s put OOP’s methodology to use and customize our Person\\nclass by extending our software hierarchy. For the purpose of this tutorial, we’ll define\\na subclass of Person called Manager that replaces the inherited giveRaise method with\\na more specialized version. Our new class begins as follows:\\n\\nclass Manager(Person):                          # Define a subclass of Person\\n\\nThis code means that we’re defining a new class named Manager, which inherits from\\nand may add customizations to the superclass Person. In plain terms, a Manager is almost\\nlike a Person (admittedly, a very long journey for a very small joke...), but Manager has\\na custom way to give raises.\\n\\n828 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cFor the sake of argument, let’s assume that when a Manager gets a raise, it receives the\\npassed-in percentage as usual, but also gets an extra bonus that defaults to 10%. For\\ninstance, if a Manager’s raise is specified as 10%, it will really get 20%. (Any relation to\\nPersons living or dead is, of course, strictly coincidental.) Our new method begins as\\nfollows; because this redefinition of giveRaise will be closer in the class tree to Man\\nager instances than the original version in Person, it effectively replaces, and thereby\\ncustomizes, the operation. Recall that according to the inheritance search rules, the\\nlowest version of the name wins:1\\n\\nclass Manager(Person):                          # Inherit Person attrs\\n    def giveRaise(self, percent, bonus=.10):    # Redefine to customize\\n\\nAugmenting Methods: The Bad Way\\nNow, there are two ways we might code this Manager customization: a good way and a\\nbad way. Let’s start with the bad way, since it might be a bit easier to understand. The\\nbad way is to cut and paste the code of giveRaise in Person and modify it for Manager,\\nlike this:\\n\\nclass Manager(Person):\\n    def giveRaise(self, percent, bonus=.10):\\n        self.pay = int(self.pay * (1 + percent + bonus))   # Bad: cut and paste\\n\\nThis works as advertised—when we later call the giveRaise method of a Manager in-\\nstance, it will run this custom version, which tacks on the extra bonus. So what’s wrong\\nwith something that runs correctly?\\nThe problem here is a very general one: anytime you copy code with cut and paste, you\\nessentially double your maintenance effort in the future. Think about it: because we\\ncopied the original version, if we ever have to change the way raises are given (and we\\nprobably will), we’ll have to change the code in two places, not one. Although this is a\\nsmall and artificial example, it’s also representative of a universal issue—anytime you’re\\ntempted to program by copying code this way, you probably want to look for a better\\napproach.\\n\\nAugmenting Methods: The Good Way\\nWhat we really want to do here is somehow augment the original giveRaise, instead of\\nreplacing it altogether. The good way to do that in Python is by calling to the original\\nversion directly, with augmented arguments, like this:\\n\\nclass Manager(Person):\\n    def giveRaise(self, percent, bonus=.10):\\n        Person.giveRaise(self, percent + bonus)            # Good: augment original\\n\\n1. And no offense to any managers in the audience, of course. I once taught a Python class in New Jersey,\\nand nobody laughed at this joke, among others. The organizers later told me it was a group of managers\\nevaluating Python.\\n\\nStep 4: Customizing Behavior by Subclassing | 829\\n\\n\\x0cThis code leverages the fact that a class’s method can always be called either through\\nan  instance  (the  usual  way,  where  Python  sends  the  instance  to  the  self  argument\\nautomatically) or through the class (the less common scheme, where you must pass the\\ninstance manually). In more symbolic terms, recall that a normal method call of this\\nform:\\n\\ninstance.method(args...)\\n\\nis automatically translated by Python into this equivalent form:\\n\\nclass.method(instance, args...)\\n\\nwhere the class containing the method to be run is determined by the inheritance search\\nrule applied to the method’s name. You can code either form in your script, but there\\nis a slight asymmetry between the two—you must remember to pass along the instance\\nmanually if you call through the class directly. The method always needs a subject\\ninstance one way or another, and Python provides it automatically only for calls made\\nthrough an instance. For calls through the class name, you need to send an instance to\\nself yourself; for code inside a method like giveRaise, self already is the subject of the\\ncall, and hence the instance to pass along.\\nCalling through the class directly effectively subverts inheritance and kicks the call\\nhigher up the class tree to run a specific version. In our case, we can use this technique\\nto invoke the default giveRaise in Person, even though it’s been redefined at the Man\\nager level. In some sense, we must call through Person this way, because a self.giveR\\naise() inside Manager’s giveRaise code would loop—since self already is a Manager,\\nself.giveRaise() would resolve again to Manager.giveRaise, and so on and so forth\\nrecursively until available memory is exhausted.\\nThis “good” version may seem like a small difference in code, but it can make a huge\\ndifference for future code maintenance—because the giveRaise logic lives in just one\\nplace now (Person’s method), we have only one version to change in the future as needs\\nevolve. And really, this form captures our intent more directly anyhow—we want to\\nperform the standard giveRaise operation, but simply tack on an extra bonus. Here’s\\nour entire module file with this step applied:\\n\\n# Add customization of one behavior in a subclass\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __repr__(self):\\n        return \\'[Person: %s, %s]\\' % (self.name, self.pay)\\n\\nclass Manager(Person):\\n\\n830 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0c    def giveRaise(self, percent, bonus=.10):           # Redefine at this level\\n        Person.giveRaise(self, percent + bonus)        # Call Person\\'s version\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager(\\'Tom Jones\\', \\'mgr\\', 50000)           # Make a Manager: __init__\\n    tom.giveRaise(.10)                                 # Runs custom version\\n    print(tom.lastName())                              # Runs inherited method\\n    print(tom)                                         # Runs inherited __repr__\\n\\nTo test our Manager subclass customization, we’ve also added self-test code that makes\\na Manager, calls its methods, and prints it. When we make a Manager, we pass in a name,\\nand an optional job and pay as before—because Manager had no __init__ constructor,\\nit inherits that in Person. Here’s the new version’s output:\\n\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\n\\nEverything looks good here: bob and sue are as before, and when tom the Manager is\\ngiven a 10% raise, he really gets 20% (his pay goes from $50K to $60K), because the\\ncustomized giveRaise in Manager is run for him only. Also notice how printing tom as a\\nwhole at the end of the test code displays the nice format defined in Person’s __repr__:\\nManager objects get this, lastName, and the __init__ constructor method’s code “for\\nfree” from Person, by inheritance.\\n\\nWhat About super?\\n\\nTo  extend  inherited  methods,  the  examples  in  this  chapter  simply  call  the  original\\nthrough the superclass name: Person.giveRaise(...). This is the traditional and sim-\\nplest scheme in Python, and the one used in most of this book.\\nJava programmers may especially be interested to know that Python also has a super\\nbuilt-in function that allows calling back to a superclass’s methods more generically—\\nbut it’s cumbersome to use in 2.X; differs in form between 2.X and 3.X; relies on unusual\\nsemantics in 3.X; works unevenly with Python’s operator overloading; and does not\\nalways mesh well with traditionally coded multiple inheritance, where a single super-\\nclass call won’t suffice.\\nIn its defense, the super call has a valid use case too—cooperative same-named method\\ndispatch in multiple inheritance trees—but it relies on the “MRO” ordering of classes,\\nwhich many find esoteric and artificial; unrealistically assumes universal deployment\\nto be used reliably; does not fully support method replacement and varying argument\\n\\nStep 4: Customizing Behavior by Subclassing | 831\\n\\n\\x0clists; and to many observers seems an obscure solution to a use case that is rare in real\\nPython code.\\n\\nBecause of these downsides, this book prefers to call superclasses by explicit name\\ninstead of super, recommends the same policy for newcomers, and defers presenting\\nsuper until Chapter 32. It’s usually best judged after you learn the simpler, and generally\\nmore traditional and “Pythonic” ways of achieving the same goals, especially if you’re\\nnew to OOP. Topics like MROs and cooperative multiple inheritance dispatch seem a\\nlot to ask of beginners—and others.\\n\\nAnd to any Java programmers in the audience: I suggest resisting the temptation to use\\nPython’s super until you’ve had a chance to study its subtle implications. Once you\\nstep up to multiple inheritance, it’s not what you think it is, and more than you probably\\nexpect. The class it invokes may not be the superclass at all, and can even vary per\\ncontext. Or to paraphrase a movie line: Python’s super is like a box of chocolates—you\\nnever know what you’re going to get!\\n\\nPolymorphism in Action\\nTo make this acquisition of inherited behavior even more striking, we can add the\\nfollowing code at the end of our file temporarily:\\n\\nif __name__ == \\'__main__\\':\\n    ...\\n    print(\\'--All three--\\')\\n    for obj in (bob, sue, tom):               # Process objects generically\\n        obj.giveRaise(.10)                    # Run this object\\'s giveRaise\\n        print(obj)                            # Run the common __repr__\\n\\nHere’s the resulting output, with its new parts highlighted in bold:\\n\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\n--All three--\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 121000]\\n[Person: Tom Jones, 72000]\\n\\nIn the added code, object is either a Person or a Manager, and Python runs the appro-\\npriate giveRaise automatically—our original version in Person for bob and sue, and our\\ncustomized  version  in  Manager  for  tom.  Trace  the  method  calls  yourself  to  see  how\\nPython selects the right giveRaise method for each object.\\nThis is just Python’s notion of polymorphism, which we met earlier in the book, at work\\nagain—what giveRaise does depends on what you do it to. Here, it’s made all the more\\nobvious when it selects from code we’ve written ourselves in classes. The practical effect\\nin  this  code  is  that  sue  gets  another  10%  but  tom  gets  another  20%,  because\\n\\n832 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cgiveRaise is dispatched based upon the object’s type. As we’ve learned, polymorphism\\nis at the heart of Python’s flexibility. Passing any of our three objects to a function that\\ncalls a giveRaise method, for example, would have the same effect: the appropriate\\nversion would be run automatically, depending on which type of object was passed.\\nOn the other hand, printing runs the same __repr__ for all three objects, because it’s\\ncoded just once in Person. Manager both specializes and applies the code we originally\\nwrote in Person. Although this example is small, it’s already leveraging OOP’s talent\\nfor code customization and reuse; with classes, this almost seems automatic at times.\\n\\nInherit, Customize, and Extend\\nIn fact, classes can be even more flexible than our example implies. In general, classes\\ncan inherit, customize, or extend existing code in superclasses. For example, although\\nwe’re focused on customization here, we can also add unique methods to Manager that\\nare not present in Person, if Managers require something completely different (Python\\nnamesake reference intended). The following snippet illustrates. Here, giveRaise re-\\ndefines a superclass’s method to customize it, but someThingElse defines something\\nnew to extend:\\n\\nclass Person:\\n    def lastName(self): ...\\n    def giveRaise(self): ...\\n    def __repr__(self): ...\\n\\nclass Manager(Person):                       # Inherit\\n    def giveRaise(self, ...): ...            # Customize\\n    def someThingElse(self, ...): ...        # Extend\\n\\ntom = Manager()\\ntom.lastName()             # Inherited verbatim\\ntom.giveRaise()            # Customized version\\ntom.someThingElse()        # Extension here\\nprint(tom)                 # Inherited overload method\\n\\nExtra methods like this code’s someThingElse extend the existing software and are avail-\\nable on Manager objects only, not on Persons. For the purposes of this tutorial, however,\\nwe’ll limit our scope to customizing some of Person’s behavior by redefining it, not\\nadding to it.\\n\\nOOP: The Big Idea\\nAs is, our code may be small, but it’s fairly functional. And really, it already illustrates\\nthe main point behind OOP in general: in OOP, we program by customizing what has\\nalready been done, rather than copying or changing existing code. This isn’t always an\\nobvious win to newcomers at first glance, especially given the extra coding requirements\\nof classes. But overall, the programming style implied by classes can cut development\\ntime radically compared to other approaches.\\n\\nStep 4: Customizing Behavior by Subclassing | 833\\n\\n\\x0cFor instance, in our example we could theoretically have implemented a custom giv\\neRaise operation without subclassing, but none of the other options yield code as op-\\ntimal as ours:\\n\\n• Although we could have simply coded Manager from scratch as new, independent\\ncode, we would have had to reimplement all the behaviors in Person that are the\\nsame for Managers.\\n\\n• Although we could have simply changed the existing Person class in place for the\\nrequirements of Manager’s giveRaise, doing so would probably break the places\\nwhere we still need the original Person behavior.\\n\\n• Although we could have simply copied the Person class in its entirety, renamed the\\ncopy to Manager, and changed its giveRaise, doing so would introduce code re-\\ndundancy that would double our work in the future—changes made to Person in\\nthe future would not be picked up automatically, but would have to be manually\\npropagated  to  Manager’s  code.  As  usual,  the  cut-and-paste  approach  may  seem\\nquick now, but it doubles your work in the future.\\n\\nThe customizable hierarchies we can build with classes provide a much better solution\\nfor software that will evolve over time. No other tools in Python support this develop-\\nment mode. Because we can tailor and extend our prior work by coding new subclasses,\\nwe can leverage what we’ve already done, rather than starting from scratch each time,\\nbreaking what already works, or introducing multiple copies of code that may all have\\nto be updated in the future. When done right, OOP is a powerful programmer’s ally.\\n\\nStep 5: Customizing Constructors, Too\\nOur code works as it is, but if you study the current version closely, you may be struck\\nby  something  a  bit  odd—it  seems  pointless  to  have  to  provide  a  mgr  job  name  for\\nManager objects when we create them: this is already implied by the class itself. It would\\nbe better if we could somehow fill in this value automatically when a Manager is made.\\nThe trick we need to improve on this turns out to be the same as the one we employed\\nin the prior section: we want to customize the constructor logic for Managers in such a\\nway as to provide a job name automatically. In terms of code, we want to redefine an\\n__init__ method in Manager that provides the mgr string for us. And as in giveRaise\\ncustomization, we also want to run the original __init__ in Person by calling through\\nthe class name, so it still initializes our objects’ state information attributes.\\nThe following extension to person.py will do the job—we’ve coded the new Manager\\nconstructor and changed the call that creates tom to not pass in the mgr job name:\\n\\n# File person.py\\n# Add customization of constructor in a subclass\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n\\n834 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0c        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __repr__(self):\\n        return \\'[Person: %s, %s]\\' % (self.name, self.pay)\\n\\nclass Manager(Person):\\n    def __init__(self, name, pay):                     # Redefine constructor\\n        Person.__init__(self, name, \\'mgr\\', pay)        # Run original with \\'mgr\\'\\n    def giveRaise(self, percent, bonus=.10):\\n        Person.giveRaise(self, percent + bonus)\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager(\\'Tom Jones\\', 50000)                   # Job name not needed:\\n    tom.giveRaise(.10)                                  # Implied/set by class\\n    print(tom.lastName())\\n    print(tom)\\n\\nAgain, we’re using the same technique to augment the __init__ constructor here that\\nwe used for giveRaise earlier—running the superclass version by calling through the\\nclass name directly and passing the self instance along explicitly. Although the con-\\nstructor has a strange name, the effect is identical. Because we need Person’s construc-\\ntion logic to run too (to initialize instance attributes), we really have to call it this way;\\notherwise, instances would not have any attributes attached.\\nCalling superclass constructors from redefinitions this way turns out to be a very com-\\nmon coding pattern in Python. By itself, Python uses inheritance to look for and call\\nonly one __init__ method at construction time—the lowest one in the class tree. If you\\nneed higher __init__ methods to be run at construction time (and you usually do), you\\nmust call them manually, and usually through the superclass’s name. The upside to\\nthis is that you can be explicit about which argument to pass up to the superclass’s\\nconstructor and can choose to not call it at all: not calling the superclass constructor\\nallows you to replace its logic altogether, rather than augmenting it.\\nThe output of this file’s self-test code is the same as before—we haven’t changed what\\nit does, we’ve simply restructured to get rid of some logical redundancy:\\n\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 100000]\\nSmith Jones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\n\\nStep 5: Customizing Constructors, Too | 835\\n\\n\\x0cOOP Is Simpler Than You May Think\\nIn this complete form, and despite their relatively small sizes, our classes capture nearly\\nall the important concepts in Python’s OOP machinery:\\n\\n• Instance creation—filling out instance attributes\\n• Behavior methods—encapsulating logic in a class’s methods\\n• Operator overloading—providing behavior for built-in operations like printing\\n• Customizing behavior—redefining methods in subclasses to specialize them\\n• Customizing constructors—adding initialization logic to superclass steps\\n\\nMost of these concepts are based upon just three simple ideas: the inheritance search\\nfor attributes in object trees, the special self argument in methods, and operator over-\\nloading’s automatic dispatch to methods.\\nAlong the way, we’ve also made our code easy to change in the future, by harnessing\\nthe class’s propensity for factoring code to reduce redundancy. For example, we wrap-\\nped up logic in methods and called back to superclass methods from extensions to\\navoid  having  multiple  copies  of  the  same  code.  Most  of  these  steps  were  a  natural\\noutgrowth of the structuring power of classes.\\nBy and large, that’s all there is to OOP in Python. Classes certainly can become larger\\nthan this, and there are some more advanced class concepts, such as decorators and\\nmetaclasses, which we will meet in later chapters. In terms of the basics, though, our\\nclasses already do it all. In fact, if you’ve grasped the workings of the classes we’ve\\nwritten, most OOP Python code should now be within your reach.\\n\\nOther Ways to Combine Classes\\nHaving said that, I should also tell you that although the basic mechanics of OOP are\\nsimple in Python, some of the art in larger programs lies in the way that classes are put\\ntogether. We’re focusing on inheritance in this tutorial because that’s the mechanism\\nthe Python language provides, but programmers sometimes combine classes in other\\nways, too.\\nFor example, a common coding pattern involves nesting objects inside each other to\\nbuild up composites. We’ll explore this pattern in more detail in Chapter 31, which is\\nreally more about design than about Python. As a quick example, though, we could\\nuse this composition idea to code our Manager extension by embedding a Person, instead\\nof inheriting from it.\\nThe following alternative, coded in file person-composite.py, does so by using the __get\\nattr__ operator overloading method to intercept undefined attribute fetches and del-\\negate them to the embedded object with the getattr built-in. The getattr call was\\nintroduced in Chapter 25—it’s the same as X.Y attribute fetch notation and thus per-\\n\\n836 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cforms inheritance, but the attribute name Y is a runtime string—and __getattr__ is\\ncovered in full in Chapter 30, but its basic usage is simple enough to leverage here.\\nBy combining these tools, the giveRaise method here still achieves customization, by\\nchanging the argument passed along to the embedded object. In effect, Manager becomes\\na controller layer that passes calls down to the embedded object, rather than up to\\nsuperclass methods:\\n\\n# File person-composite.py\\n# Embedding-based Manager alternative\\n\\nclass Person:\\n    ...same...\\n\\nclass Manager:\\n    def __init__(self, name, pay):\\n        self.person = Person(name, \\'mgr\\', pay)      # Embed a Person object\\n    def giveRaise(self, percent, bonus=.10):\\n        self.person.giveRaise(percent + bonus)      # Intercept and delegate\\n    def __getattr__(self, attr):\\n        return getattr(self.person, attr)           # Delegate all other attrs\\n    def __repr__(self):\\n        return str(self.person)                     # Must overload again (in 3.X)\\n\\nif __name__ == \\'__main__\\':\\n    ...same...\\n\\nThe output of this version is the same as the prior, so I won’t list it again. The more\\nimportant point here is that this Manager alternative is representative of a general coding\\npattern  usually  known  as  delegation—a  composite-based  structure  that  manages  a\\nwrapped object and propagates method calls to it.\\nThis pattern works in our example, but it requires about twice as much code and is less\\nwell suited than inheritance to the kinds of direct customizations we meant to express\\n(in fact, no reasonable Python programmer would code this example this way in prac-\\ntice, except perhaps those writing general tutorials!). Manager isn’t really a Person here,\\nso we need extra code to manually dispatch method calls to the embedded object;\\noperator overloading methods like __repr__ must be redefined (in 3.X, at least, as noted\\nin  the  upcoming  sidebar  “Catching  Built-in  Attributes  in  3.X”  on  page  839);  and\\nadding new Manager behavior is less straightforward since state information is one level\\nremoved.\\nStill, object embedding, and design patterns based upon it, can be a very good fit when\\nembedded objects require more limited interaction with the container than direct cus-\\ntomization implies. A controller layer, or proxy, like this alternative Manager, for ex-\\nample, might come in handy if we want to adapt a class to an expected interface it does\\nnot support, or trace or validate calls to another object’s methods (indeed, we will use\\na nearly identical coding pattern when we study class decorators later in the book).\\nMoreover, a hypothetical Department class like the following could aggregate other ob-\\njects in order to treat them as a set. Replace the self-test code at the bottom of the\\n\\nStep 5: Customizing Constructors, Too | 837\\n\\n\\x0cperson.py file temporarily to try this on your own; the file person-department.py in the\\nbook’s examples does:\\n\\n# File person-department.py\\n# Aggregate embedded objects into a composite\\n\\nclass Person:\\n    ...same...\\n\\nclass Manager(Person):\\n    ...same...\\n\\nclass Department:\\n    def __init__(self, *args):\\n        self.members = list(args)\\n    def addMember(self, person):\\n        self.members.append(person)\\n    def giveRaises(self, percent):\\n        for person in self.members:\\n            person.giveRaise(percent)\\n    def showAll(self):\\n        for person in self.members:\\n            print(person)\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    tom = Manager(\\'Tom Jones\\', 50000)\\n\\n    development = Department(bob, sue)          # Embed objects in a composite\\n    development.addMember(tom)\\n    development.giveRaises(.10)                 # Runs embedded objects\\' giveRaise\\n    development.showAll()                       # Runs embedded objects\\' __repr__\\n\\nWhen run, the department’s showAll method lists all of its contained objects after up-\\ndating their state in true polymorphic fashion with giveRaises:\\n\\n[Person: Bob Smith, 0]\\n[Person: Sue Jones, 110000]\\n[Person: Tom Jones, 60000]\\n\\nInterestingly, this code uses both inheritance and composition—Department is a com-\\nposite that embeds and controls other objects to aggregate, but the embedded Person\\nand Manager objects themselves use inheritance to customize. As another example, a\\nGUI might similarly use inheritance to customize the behavior or appearance of labels\\nand buttons, but also composition to build up larger packages of embedded widgets,\\nsuch as input forms, calculators, and text editors. The class structure to use depends\\non the objects you are trying to model—in fact, the ability to model real-world entities\\nthis way is one of OOP’s strengths.\\nDesign issues like composition are explored in Chapter 31, so we’ll postpone further\\ninvestigations for now. But again, in terms of the basic mechanics of OOP in Python,\\nour Person and Manager classes already tell the entire story. Now that you’ve mastered\\n\\n838 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cthe basics of OOP, though, developing general tools for applying it more easily in your\\nscripts is often a natural next step—and the topic of the next section.\\n\\nCatching Built-in Attributes in 3.X\\n\\nAn implementation note: in Python 3.X—and in 2.X when 3.X’s “new style” classes\\nare enabled—the alternative delegation-based Manager class of the file person-compo-\\nsite.py that we coded in this chapter will not be able to intercept and delegate operator\\noverloading method attributes like __repr__ without redefining them itself. Although\\nwe know that __repr__ is the only such name used in our specific example, this is a\\ngeneral issue for delegation-based classes.\\n\\nRecall that built-in operations like printing and addition implicitly invoke operator\\noverloading methods such as __repr__ and __add__. In 3.X’s new-style classes, built-in\\noperations like these do not route their implicit attribute fetches through generic at-\\ntribute  managers:  neither  __getattr__  (run  for  undefined  attributes)  nor  its  cousin\\n__getattribute__ (run for all attributes) is invoked. This is why we have to redefine\\n__repr__  redundantly  in  the  alternative  Manager,  in  order  to  ensure  that  printing  is\\nrouted to the embedded Person object in 3.X.\\nComment out this method to see this live—the Manager instance prints with a default\\nin 3.X, but still uses Person’s __repr__ in 2.X. In fact, the  __repr__ in Manager isn’t\\nrequired in 2.X at all, as it’s coded to use 2.X normal and default (a.k.a. “classic”)\\nclasses:\\n\\nc:\\\\code> py −3 person-composite.py\\n[Person: Bob Smith, 0]\\n...etc...\\n<__main__.Manager object at 0x00000000029AA8D0>\\n\\nc:\\\\code> py −2 person-composite.py\\n[Person: Bob Smith, 0]\\n...etc...\\n[Person: Tom Jones, 60000]\\n\\nTechnically, this happens because built-in operations begin their implicit search for\\nmethod names at the instance in 2.X’s default classic classes, but start at the class in\\n3.X’s mandated new-style classes, skipping the instance entirely. By contrast, explicit\\nby-name attribute fetches are always routed to the instance first in both models. In 2.X\\nclassic classes, built-ins route attributes this way too—printing, for example, routes\\n__repr__ through __getattr__. This is why commenting out Manager’s __repr__ has no\\neffect in 2.X: the call is delegated to Person. New-style classes also inherit a default for\\n__repr__ from their automatic object superclass that would foil __getattr__, but the\\nnew-style __getattribute__ doesn’t intercept the name either.\\nThis  is  a  change,  but  isn’t  a  show-stopper—delegation-based  new-style  classes  can\\ngenerally redefine operator overloading methods to delegate them to wrapped objects,\\neither manually or via tools or superclasses. This topic is too advanced to explore further\\nin this tutorial, though, so don’t sweat the details too much here. Watch for it to be\\nrevisited in Chapter 31 and Chapter 32 (the latter of which defines new-style classes\\nmore formally); to impact examples again in the attribute management coverage of\\n\\nStep 5: Customizing Constructors, Too | 839\\n\\n\\x0cChapter 38 and the Private class decorator in Chapter 39 (the last of these also codes\\nworkarounds); and to be a special-case factor in a nearly formal inheritance definition\\nin Chapter 40. In a language like Python that supports both attribute interception and\\noperator overloading, the impacts of this change can be as broad as this spread implies!\\n\\nStep 6: Using Introspection Tools\\nLet’s make one final tweak before we throw our objects onto a database. As they are,\\nour classes are complete and demonstrate most of the basics of OOP in Python. They\\nstill have two remaining issues we probably should iron out, though, before we go live\\nwith them:\\n\\n• First, if you look at the display of the objects as they are right now, you’ll notice\\nthat when you print tom the Manager, the display labels him as a Person. That’s not\\ntechnically incorrect, since  Manager is a kind of customized and specialized  Per\\nson. Still, it would be more accurate to display an object with the most specific (that\\nis, lowest) class possible: the one an object is made from.\\n\\n• Second, and perhaps more importantly, the current display format shows only the\\nattributes we include in our __repr__, and that might not account for future goals.\\nFor example, we can’t yet verify that tom’s job name has been set to mgr correctly\\nby Manager’s constructor, because the __repr__ we coded for Person does not print\\nthis field. Worse, if we ever expand or otherwise change the set of attributes as-\\nsigned  to  our  objects  in  __init__,  we’ll  have  to  remember  to  also  update\\n__repr__ for new names to be displayed, or it will become out of sync over time.\\n\\nThe last point means that, yet again, we’ve made potential extra work for ourselves in\\nthe future by introducing redundancy in our code. Because any disparity in __repr__\\nwill be reflected in the program’s output, this redundancy may be more obvious than\\nthe other forms we addressed earlier; still, avoiding extra work in the future is generally\\na good thing.\\n\\nSpecial Class Attributes\\nWe can address both issues with Python’s introspection tools—special attributes and\\nfunctions that give us access to some of the internals of objects’ implementations. These\\ntools are somewhat advanced and generally used more by people writing tools for other\\nprogrammers to use than by programmers developing applications. Even so, a basic\\nknowledge of some of these tools is useful because they allow us to write code that\\nprocesses classes in generic ways. In our code, for example, there are two hooks that\\ncan help us out, both of which were introduced near the end of the preceding chapter\\nand used in earlier examples:\\n\\n• The built-in instance.__class__ attribute provides a link from an instance to the\\nclass from which it was created. Classes in turn have a __name__, just like modules,\\n\\n840 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cand a __bases__ sequence that provides access to superclasses. We can use these\\nhere to print the name of the class from which an instance is made rather than one\\nwe’ve hardcoded.\\n\\n• The built-in object.__dict__ attribute provides a dictionary with one key/value\\npair for every attribute attached to a namespace object (including modules, classes,\\nand instances). Because it is a dictionary, we can fetch its keys list, index by key,\\niterate over its keys, and so on, to process all attributes generically. We can use this\\nhere to print every attribute in any instance, not just those we hardcode in custom\\ndisplays, much as we did in Chapter 25’s module tools.\\n\\nWe met the first of these categories in the prior chapter, but here’s a quick review at\\nPython’s interactive prompt with the latest versions of our person.py classes. Notice\\nhow we load Person at the interactive prompt with a from statement here—class names\\nlive in and are imported from modules, exactly like function names and other variables:\\n\\n>>> from person import Person\\n>>> bob = Person(\\'Bob Smith\\')\\n>>> bob                                        # Show bob\\'s __repr__ (not __str__)\\n[Person: Bob Smith, 0]\\n>>> print(bob)                                 # Ditto: print => __str__ or __repr__\\n[Person: Bob Smith, 0]\\n\\n>>> bob.__class__                              # Show bob\\'s class and its name\\n<class \\'person.Person\\'>\\n>>> bob.__class__.__name__\\n\\'Person\\'\\n\\n>>> list(bob.__dict__.keys())                  # Attributes are really dict keys\\n[\\'pay\\', \\'job\\', \\'name\\']                         # Use list to force list in 3.X\\n\\n>>> for key in bob.__dict__:\\n        print(key, \\'=>\\', bob.__dict__[key])    # Index manually\\n\\npay => 0\\njob => None\\nname => Bob Smith\\n\\n>>> for key in bob.__dict__:\\n        print(key, \\'=>\\', getattr(bob, key))    # obj.attr, but attr is a var\\n\\npay => 0\\njob => None\\nname => Bob Smith\\n\\nAs noted briefly in the prior chapter, some attributes accessible from an instance might\\nnot be stored in the __dict__ dictionary if the instance’s class defines __slots__: an\\noptional and relatively obscure feature of new-style classes (and hence all classes in\\nPython 3.X) that stores attributes sequentially in the instance; may preclude an instance\\n__dict__ altogether; and which we won’t study in full until Chapter 31 and Chap-\\nter 32. Since slots really belong to classes instead of instances, and since they are rarely\\n\\nStep 6: Using Introspection Tools\\n\\n| 841\\n\\n\\x0cused  in  any  event,  we  can  reasonably  ignore  them  here  and  focus  on  the  normal\\n__dict__.\\nAs we do, though, keep in mind that some programs may need to catch exceptions for\\na missing __dict__, or use hasattr to test or getattr with a default if its users might\\ndeploy slots. As we’ll see in Chapter 32, the next section’s code won’t fail if used by a\\nclass with slots (its lack of them is enough to guarantee a __dict__) but slots—and other\\n“virtual” attributes—won’t be reported as instance data.\\n\\nA Generic Display Tool\\nWe can put these interfaces to work in a superclass that displays accurate class names\\nand formats all attributes of an instance of any class. Open a new file in your text editor\\nto code the following—it’s a new, independent module named classtools.py that im-\\nplements just such a class. Because its __repr__ display overload uses generic intro-\\nspection tools, it will work on any instance, regardless of the instance’s attributes set.\\nAnd because this is a class, it automatically becomes a general formatting tool: thanks\\nto inheritance, it can be mixed into any class that wishes to use its display format. As\\nan added bonus, if we ever want to change how instances are displayed we need only\\nchange this class, as every class that inherits its __repr__ will automatically pick up the\\nnew format when it’s next run:\\n\\n# File classtools.py (new)\\n\"Assorted class utilities and tools\"\\n\\nclass AttrDisplay:\\n    \"\"\"\\n    Provides an inheritable display overload method that shows\\n    instances with their class names and a name=value pair for\\n    each attribute stored on the instance itself (but not attrs\\n    inherited from its classes). Can be mixed into any class,\\n    and will work on any instance.\\n    \"\"\"\\n    def gatherAttrs(self):\\n        attrs = []\\n        for key in sorted(self.__dict__):\\n            attrs.append(\\'%s=%s\\' % (key, getattr(self, key)))\\n        return \\', \\'.join(attrs)\\n\\n    def __repr__(self):\\n        return \\'[%s: %s]\\' % (self.__class__.__name__, self.gatherAttrs())\\n\\nif __name__ == \\'__main__\\':\\n\\n    class TopTest(AttrDisplay):\\n        count = 0\\n        def __init__(self):\\n            self.attr1 = TopTest.count\\n            self.attr2 = TopTest.count+1\\n            TopTest.count += 2\\n\\n842 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0c    class SubTest(TopTest):\\n        pass\\n\\n    X, Y = TopTest(), SubTest()      # Make two instances\\n    print(X)                         # Show all instance attrs\\n    print(Y)                         # Show lowest class name\\n\\nNotice the docstrings here—because this is a general-purpose tool, we want to add\\nsome functional documentation for potential users to read. As we saw in Chapter 15,\\ndocstrings can be placed at the top of simple functions and modules, and also at the\\nstart of classes and any of their methods; the help function and the PyDoc tool extract\\nand display these automatically. We’ll revisit docstrings for classes in Chapter 29.\\nWhen run directly, this module’s self-test makes two instances and prints them; the\\n__repr__ defined here shows the instance’s class, and all its attributes names and values,\\nin sorted attribute name order. This output is the same in Python 3.X and 2.X because\\neach object’s display is a single constructed string:\\n\\nC:\\\\code> classtools.py\\n[TopTest: attr1=0, attr2=1]\\n[SubTest: attr1=2, attr2=3]\\n\\nAnother design note here: because this class uses __repr__ instead of __str__ its displays\\nare used in all contexts, but its clients also won’t have the option of providing an al-\\nternative low-level display—they can still add a __str__, but this applies to print and\\nstr only. In a more general tool, using __str__ instead limits a display’s scope, but\\nleaves clients the option of adding a __repr__ for a secondary display at interactive\\nprompts and nested appearances. We’ll follow this alternative policy when we code\\nexpanded versions of this class in Chapter 31; for this demo, we’ll stick with the all-\\ninclusive __repr__.\\n\\nInstance Versus Class Attributes\\nIf you study the classtools module’s self-test code long enough, you’ll notice that its\\nclass displays only instance attributes, attached to the self object at the bottom of the\\ninheritance tree; that’s what self’s __dict__ contains. As an intended consequence, we\\ndon’t see attributes inherited by the instance from classes above it in the tree (e.g.,\\ncount in this file’s self-test code—a class attribute used as an instance counter). Inher-\\nited class attributes are attached to the class only, not copied down to instances.\\nIf you ever do wish to include inherited attributes too, you can climb the __class__ link\\nto the instance’s class, use the __dict__ there to fetch class attributes, and then iterate\\nthrough the class’s __bases__ attribute to climb to even higher superclasses, repeating\\nas necessary. If you’re a fan of simple code, running a built-in dir call on the instance\\ninstead of using __dict__ and climbing would have much the same effect, since dir\\nresults include inherited names in the sorted results list. In Python 2.7:\\n\\n>>> from person import Person           # 2.X: keys is list, dir shows less\\n>>> bob = Person(\\'Bob Smith\\')\\n\\nStep 6: Using Introspection Tools\\n\\n| 843\\n\\n\\x0c>>> bob.__dict__.keys()                 # Instance attrs only\\n[\\'pay\\', \\'job\\', \\'name\\']\\n\\n>>> dir(bob)                            # Plus inherited attrs in classes\\n[\\'__doc__\\', \\'__init__\\', \\'__module__\\', \\'__repr__\\', \\'giveRaise\\', \\'job\\', \\'lastName\\',\\n\\'name\\', \\'pay\\']\\n\\nIf you’re using Python 3.X, your output will vary, and may be more than you bargained\\nfor; here’s the 3.3 result for the last two statements (keys list order can vary per run):\\n\\n>>> list(bob.__dict__.keys())           # 3.X keys is a view, not a list\\n[\\'name\\', \\'job\\', \\'pay\\']\\n\\n>>> dir(bob)                            # 3.X includes class type methods\\n[\\'__class__\\', \\'__delattr__\\', \\'__dict__\\', \\'__dir__\\', \\'__doc__\\', \\'__eq__\\',\\n\\'__format__\\', \\'__ge__\\', \\'__getattribute__\\', \\'__gt__\\', \\'__hash__\\', \\'__init__\\',\\n...more omitted: 31 attrs...\\n\\'__setattr__\\', \\'__sizeof__\\', \\'__str__\\', \\'__subclasshook__\\', \\'__weakref__\\',\\n\\'giveRaise\\', \\'job\\', \\'lastName\\', \\'name\\', \\'pay\\']\\n\\nThe  code  and  output  here  varies  between  Python  2.X  and  3.X,  because  3.X’s\\ndict.keys is not a list, and 3.X’s dir returns extra class-type implementation attributes.\\nTechnically, dir returns more in 3.X because classes are all “new style” and inherit a\\nlarge set of operator overloading names from the class type. In fact, as usual you’ll\\nprobably want to filter out most of the __X__ names in the 3.X dir result, since they are\\ninternal implementation details and not something you’d normally want to display:\\n\\n>>> len(dir(bob))\\n31\\n>>> list(name for name in dir(bob) if not name.startswith(\\'__\\'))\\n[\\'giveRaise\\', \\'job\\', \\'lastName\\', \\'name\\', \\'pay\\']\\n\\nIn the interest of space, we’ll leave optional display of inherited class attributes with\\neither tree climbs or dir as suggested experiments for now. For more hints on this front,\\nthough,  watch  for  the  classtree.py  inheritance  tree  climber  we  will  write  in  Chap-\\nter 29, and the lister.py attribute listers and climbers we’ll code in Chapter 31.\\n\\nName Considerations in Tool Classes\\nOne last subtlety here: because our AttrDisplay class in the classtools module is a\\ngeneral tool designed to be mixed into other arbitrary classes, we have to be aware of\\nthe potential for unintended name collisions with client classes. As is, I’ve assumed that\\nclient subclasses may want to use both its __repr__ and gatherAttrs, but the latter of\\nthese may be more than a subclass expects—if a subclass innocently defines a gather\\nAttrs name of its own, it will likely break our class, because the lower version in the\\nsubclass will be used instead of ours.\\nTo see this for yourself, add a gatherAttrs to TopTest in the file’s self-test code; unless\\nthe new method is identical, or intentionally customizes the original, our tool class will\\n\\n844 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cno longer work as planned—self.gatherAttrs within AttrDisplay searches anew from\\nthe TopTest instance:\\n\\n    class TopTest(AttrDisplay):\\n        ....\\n        def gatherAttrs(self):         # Replaces method in AttrDisplay!\\n            return \\'Spam\\'\\n\\nThis isn’t necessarily bad—sometimes we want other methods to be available to sub-\\nclasses, either for direct calls or for customization this way. If we really meant to provide\\na __repr__ only, though, this is less than ideal.\\nTo minimize the chances of name collisions like this, Python programmers often prefix\\nmethods not meant for external use with a single underscore: _gatherAttrs in our case.\\nThis isn’t foolproof (what if another class defines _gatherAttrs, too?), but it’s usually\\nsufficient, and it’s a common Python naming convention for methods internal to a class.\\nA better and less commonly used solution would be to use two underscores at the front\\nof the method name only: __gatherAttrs for us. Python automatically expands such\\nnames to include the enclosing class’s name, which makes them truly unique when\\nlooked up by the inheritance search. This is a feature usually called pseudoprivate class\\nattributes, which we’ll expand on in Chapter 31 and deploy in an expanded version of\\nthis class there. For now, we’ll make both our methods available.\\n\\nOur Classes’ Final Form\\nNow, to use this generic tool in our classes, all we need to do is import it from its\\nmodule, mix it in by inheritance in our top-level class, and get rid of the more specific\\n__repr__ we coded before. The new display overload method will be inherited by in-\\nstances of Person, as well as Manager; Manager gets __repr__ from Person, which now\\nobtains it from the AttrDisplay coded in another module. Here is the final version of\\nour person.py file with these changes applied:\\n\\n# File classtools.py (new)\\n...as listed earlier...\\n\\n# File person.py (final)\\n\"\"\"\\nRecord and process information about people.\\nRun this file directly to test its classes.\\n\"\"\"\\nfrom classtools import AttrDisplay                    # Use generic display tool\\n\\nclass Person(AttrDisplay):                            # Mix in a repr at this level\\n    \"\"\"\\n    Create and process person records\\n    \"\"\"\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n\\nStep 6: Using Introspection Tools\\n\\n| 845\\n\\n\\x0c    def lastName(self):                               # Assumes last is last\\n        return self.name.split()[-1]\\n\\n    def giveRaise(self, percent):                     # Percent must be 0..1\\n        self.pay = int(self.pay * (1 + percent))\\n\\nclass Manager(Person):\\n    \"\"\"\\n    A customized Person with special requirements\\n    \"\"\"\\n    def __init__(self, name, pay):\\n        Person.__init__(self, name, \\'mgr\\', pay)       # Job name is implied\\n\\n    def giveRaise(self, percent, bonus=.10):\\n        Person.giveRaise(self, percent + bonus)\\n\\nif __name__ == \\'__main__\\':\\n    bob = Person(\\'Bob Smith\\')\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(bob)\\n    print(sue)\\n    print(bob.lastName(), sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager(\\'Tom Jones\\', 50000)\\n    tom.giveRaise(.10)\\n    print(tom.lastName())\\n    print(tom)\\n\\nAs this is the final revision, we’ve added a few comments here to document our work\\n—docstrings for functional descriptions and # for smaller notes, per best-practice con-\\nventions, as well as blank lines between methods for readability—a generally good style\\nchoice when classes or methods grow large, which I resisted earlier for these small\\nclasses, in part to save space and keep the code more compact.\\nWhen we run this code now, we see all the attributes of our objects, not just the ones\\nwe hardcoded in the original __repr__. And our final issue is resolved: because AttrDis\\nplay takes class names off the self instance directly, each object is shown with the name\\nof its closest (lowest) class—tom displays as a Manager now, not a Person, and we can\\nfinally verify that his job name has been correctly filled in by the Manager constructor:\\n\\nC:\\\\code> person.py\\n[Person: job=None, name=Bob Smith, pay=0]\\n[Person: job=dev, name=Sue Jones, pay=100000]\\nSmith Jones\\n[Person: job=dev, name=Sue Jones, pay=110000]\\nJones\\n[Manager: job=mgr, name=Tom Jones, pay=60000]\\n\\nThis is the more useful display we were after. From a larger perspective, though, our\\nattribute display class has become a general tool, which we can mix into any class by\\ninheritance to leverage the display format it defines. Further, all its clients will auto-\\n\\n846 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cmatically pick up future changes in our tool. Later in the book, we’ll meet even more\\npowerful class tool concepts, such as decorators and metaclasses; along with Python’s\\nmany  introspection  tools,  they  allow  us  to  write  code  that  augments  and  manages\\nclasses in structured and maintainable ways.\\n\\nStep 7 (Final): Storing Objects in a Database\\nAt this point, our work is almost complete. We now have a two-module system that not\\nonly implements our original design goals for representing people, but also provides a\\ngeneral attribute display tool we can use in other programs in the future. By coding\\nfunctions and classes in module files, we’ve ensured that they naturally support reuse.\\nAnd by coding our software as classes, we’ve ensured that it naturally supports exten-\\nsion.\\nAlthough our classes work as planned, though, the objects they create are not real\\ndatabase records. That is, if we kill Python, our instances will disappear—they’re tran-\\nsient objects in memory and are not stored in a more permanent medium like a file, so\\nthey  won’t  be  available  in  future  program  runs.  It  turns  out  that  it’s  easy  to  make\\ninstance  objects  more  permanent,  with  a  Python  feature  called  object  persistence—\\nmaking objects live on after the program that creates them exits. As a final step in this\\ntutorial, let’s make our objects permanent.\\n\\nPickles and Shelves\\nObject persistence is implemented by three standard library modules, available in every\\nPython:\\n\\npickle\\n\\nSerializes arbitrary Python objects to and from a string of bytes\\n\\ndbm (named anydbm in Python 2.X)\\n\\nImplements an access-by-key filesystem for storing strings\\n\\nshelve\\n\\nUses the other two modules to store Python objects on a file by key\\n\\nWe met these modules very briefly in Chapter 9 when we studied file basics. They\\nprovide powerful data storage options. Although we can’t do them complete justice in\\nthis tutorial or book, they are simple enough that a brief introduction is enough to get\\nyou started.\\n\\nThe pickle module\\nThe pickle module is a sort of super-general object formatting and deformatting tool:\\ngiven a nearly arbitrary Python object in memory, it’s clever enough to convert the\\nobject to a string of bytes, which it can use later to reconstruct the original object in\\nmemory. The pickle module can handle almost any object you can create—lists, dic-\\n\\nStep 7 (Final): Storing Objects in a Database | 847\\n\\n\\x0ctionaries, nested combinations thereof, and class instances. The latter are especially\\nuseful things to pickle, because they provide both data (attributes) and behavior (meth-\\nods); in fact, the combination is roughly equivalent to “records” and “programs.” Be-\\ncause pickle is so general, it can replace extra code you might otherwise write to create\\nand parse custom text file representations for your objects. By storing an object’s pickle\\nstring on a file, you effectively make it permanent and persistent: simply load and un-\\npickle it later to re-create the original object.\\n\\nThe shelve module\\nAlthough it’s easy to use pickle by itself to store objects in simple flat files and load\\nthem from there later, the shelve module provides an extra layer of structure that allows\\nyou to store pickled objects by key. shelve translates an object to its pickled string with\\npickle and stores that string under a key in a dbm file; when later loading, shelve fetches\\nthe pickled string by key and re-creates the original object in memory with pickle. This\\nis  all  quite  a  trick,  but  to  your  script  a  shelve2  of  pickled  objects  looks  just  like  a\\ndictionary—you index by key to fetch, assign to keys to store, and use dictionary tools\\nsuch as len, in, and dict.keys to get information. Shelves automatically map dictionary\\noperations to objects stored in a file.\\nIn fact, to your script the only coding difference between a shelve and a normal dictio-\\nnary is that you must open shelves initially and must close them after making changes.\\nThe net effect is that a shelve provides a simple database for storing and fetching native\\nPython objects by keys, and thus makes them persistent across program runs. It does\\nnot support query tools such as SQL, and it lacks some advanced features found in\\nenterprise-level databases (such as true transaction processing), but native Python ob-\\njects stored on a shelve may be processed with the full power of the Python language\\nonce they are fetched back by key.\\n\\nStoring Objects on a Shelve Database\\nPickling and shelves are somewhat advanced topics, and we won’t go into all their\\ndetails here; you can read more about them in the standard library manuals, as well as\\napplication-focused books such as the Programming Python follow-up text. This is all\\nsimpler in Python than in English, though, so let’s jump into some code.\\nLet’s write a new script that throws objects of our classes onto a shelve. In your text\\neditor, open a new file we’ll call makedb.py. Since this is a new file, we’ll need to import\\nour classes in order to create a few instances to store. We used from to load a class at\\nthe interactive prompt earlier, but really, as with functions and other variables, there\\nare two ways to load a class from a file (class names are variables like any other, and\\nnot at all magic in this context):\\n\\n2. Yes, we use “shelve” as a noun in Python, much to the chagrin of a variety of editors I’ve worked with\\n\\nover the years, both electronic and human.\\n\\n848 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cimport person                                    # Load class with import\\nbob = person.Person(...)                         # Go through module name\\n\\nfrom person import Person                        # Load class with from\\nbob = Person(...)                                # Use name directly\\n\\nWe’ll use from to load in our script, just because it’s a bit less to type. To keep this\\nsimple, copy or retype in our new script the self-test lines from person.py that make\\ninstances of our classes, so we have something to store (this is a simple demo, so we\\nwon’t worry about the test-code redundancy here). Once we have some instances, it’s\\nalmost trivial to store them on a shelve. We simply import the shelve module, open a\\nnew shelve with an external filename, assign the objects to keys in the shelve, and close\\nthe shelve when we’re done because we’ve made changes:\\n\\n# File makedb.py: store Person objects on a shelve database\\n\\nfrom person import Person, Manager               # Load our classes\\nbob = Person(\\'Bob Smith\\')                        # Re-create objects to be stored\\nsue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\ntom = Manager(\\'Tom Jones\\', 50000)\\n\\nimport shelve\\ndb = shelve.open(\\'persondb\\')                     # Filename where objects are stored\\nfor obj in (bob, sue, tom):                      # Use object\\'s name attr as key\\n    db[obj.name] = obj                           # Store object on shelve by key\\ndb.close()                                       # Close after making changes\\n\\nNotice how we assign objects to the shelve using their own names as keys. This is just\\nfor convenience; in a shelve, the key can be any string, including one we might create\\nto be unique using tools such as process IDs and timestamps (available in the os and\\ntime standard library modules). The only rule is that the keys must be strings and should\\nbe unique, since we can store just one object per key, though that object can be a list,\\ndictionary, or other object containing many objects itself.\\nIn fact, the values we store under keys can be Python objects of almost any sort—built-\\nin types like strings, lists, and dictionaries, as well as user-defined class instances, and\\nnested combinations of all of these and more. For example, the name and job attributes\\nof our objects could be nested dictionaries and lists as in earlier incarnations in this\\nbook (though this would require a bit of redesign to the current code).\\nThat’s all there is to it—if this script has no output when run, it means it probably\\nworked; we’re not printing anything, just creating and storing objects in a file-based\\ndatabase.\\n\\nC:\\\\code> makedb.py\\n\\nExploring Shelves Interactively\\nAt this point, there are one or more real files in the current directory whose names all\\nstart with “persondb”. The actual files created can vary per platform, and just as in the\\nbuilt-in open function, the filename in shelve.open() is relative to the current working\\n\\nStep 7 (Final): Storing Objects in a Database | 849\\n\\n\\x0cdirectory unless it includes a directory path. Wherever they are stored, these files im-\\nplement a keyed-access file that contains the pickled representation of our three Python\\nobjects. Don’t delete these files—they are your database, and are what you’ll need to\\ncopy or transfer when you back up or move your storage.\\nYou can look at the shelve’s files if you want to, either from Windows Explorer or the\\nPython shell, but they are binary hash files, and most of their content makes little sense\\noutside  the  context  of  the  shelve  module.  With  Python  3.X  and  no  extra  software\\ninstalled, our database is stored in three files (in 2.X, it’s just one file, persondb, because\\nthe bsddb extension module is preinstalled with Python for shelves; in 3.X, bsddb is an\\noptional third-party open source add-on).\\nFor example, Python’s standard library glob module allows us to get directory listings\\nin Python code to verify the files here, and we can open the files in text or binary mode\\nto explore strings and bytes:\\n\\n>>> import glob\\n>>> glob.glob(\\'person*\\')\\n[\\'person-composite.py\\', \\'person-department.py\\', \\'person.py\\', \\'person.pyc\\',\\n\\'persondb.bak\\', \\'persondb.dat\\', \\'persondb.dir\\']\\n\\n>>> print(open(\\'persondb.dir\\').read())\\n\\'Sue Jones\\', (512, 92)\\n\\'Tom Jones\\', (1024, 91)\\n\\'Bob Smith\\', (0, 80)\\n\\n>>> print(open(\\'persondb.dat\\',\\'rb\\').read())\\nb\\'\\\\x80\\\\x03cperson\\\\nPerson\\\\nq\\\\x00)\\\\x81q\\\\x01}q\\\\x02(X\\\\x03\\\\x00\\\\x00\\\\x00jobq\\\\x03NX\\\\x03\\\\x00\\n...more omitted...\\n\\nThis content isn’t impossible to decipher, but it can vary on different platforms and\\ndoesn’t exactly qualify as a user-friendly database interface! To verify our work better,\\nwe can write another script, or poke around our shelve at the interactive prompt. Be-\\ncause shelves are Python objects containing Python objects, we can process them with\\nnormal Python syntax and development modes. Here, the interactive prompt effectively\\nbecomes a database client:\\n\\n>>> import shelve\\n>>> db = shelve.open(\\'persondb\\')                 # Reopen the shelve\\n\\n>>> len(db)                                      # Three \\'records\\' stored\\n3\\n>>> list(db.keys())                              # keys is the index\\n[\\'Sue Jones\\', \\'Tom Jones\\', \\'Bob Smith\\']          # list() to make a list in 3.X\\n\\n>>> bob = db[\\'Bob Smith\\']                        # Fetch bob by key\\n>>> bob                                          # Runs __repr__ from AttrDisplay\\n[Person: job=None, name=Bob Smith, pay=0]\\n\\n>>> bob.lastName()                               # Runs lastName from Person\\n\\'Smith\\'\\n\\n850 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0c>>> for key in db:                               # Iterate, fetch, print\\n        print(key, \\'=>\\', db[key])\\n\\nSue Jones => [Person: job=dev, name=Sue Jones, pay=100000]\\nTom Jones => [Manager: job=mgr, name=Tom Jones, pay=50000]\\nBob Smith => [Person: job=None, name=Bob Smith, pay=0]\\n\\n>>> for key in sorted(db):\\n        print(key, \\'=>\\', db[key])                # Iterate by sorted keys\\n\\nBob Smith => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones => [Person: job=dev, name=Sue Jones, pay=100000]\\nTom Jones => [Manager: job=mgr, name=Tom Jones, pay=50000]\\n\\nNotice that we don’t have to import our Person or Manager classes here in order to load\\nor use our stored objects. For example, we can call bob’s lastName method freely, and\\nget  his  custom  print  display  format  automatically,  even  though  we  don’t  have  his\\nPerson class in our scope here. This works because when Python pickles a class instance,\\nit records its self instance attributes, along with the name of the class it was created\\nfrom and the module where the class lives. When bob is later fetched from the shelve\\nand unpickled, Python will automatically reimport the class and link bob to it.\\nThe upshot of this scheme is that class instances automatically acquire all their class\\nbehavior when they are loaded in the future. We have to import our classes only to\\nmake new instances, not to process existing ones. Although a deliberate feature, this\\nscheme has somewhat mixed consequences:\\n\\n• The downside is that classes and their module’s files must be importable when an\\ninstance is later loaded. More formally, pickleable classes must be coded at the top\\nlevel of a module file accessible from a directory listed on the sys.path module\\nsearch path (and shouldn’t live in the topmost script files’ module __main__ unless \\nthey’re always in that module when used). Because of this external module file\\nrequirement, some applications choose to pickle simpler objects such as diction-\\naries or lists, especially if they are to be transferred across the Internet.\\n\\n• The upside is that changes in a class’s source code file are automatically picked up\\nwhen instances of the class are loaded again; there is often no need to update stored\\nobjects themselves, since updating their class’s code changes their behavior.\\n\\nShelves also have well-known limitations (the database suggestions at the end of this\\nchapter mention a few of these). For simple object storage, though, shelves and pickles\\nare remarkably easy-to-use tools.\\n\\nUpdating Objects on a Shelve\\nNow for one last script: let’s write a program that updates an instance (record) each\\ntime it runs, to prove the point that our objects really are persistent—that their current\\nvalues  are  available  every  time  a  Python  program  runs.  The  following  file,  upda-\\ntedb.py, prints the database and gives a raise to one of our stored objects each time. If\\n\\nStep 7 (Final): Storing Objects in a Database | 851\\n\\n\\x0cyou trace through what’s going on here, you’ll notice that we’re getting a lot of utility\\n“for free”—printing our objects automatically employs the general __repr__ overload-\\ning method, and we give raises by calling the giveRaise method we wrote earlier. This\\nall “just works” for objects based on OOP’s inheritance model, even when they live in\\na file:\\n\\n# File updatedb.py: update Person object on database\\n\\nimport shelve\\ndb = shelve.open(\\'persondb\\')               # Reopen shelve with same filename\\n\\nfor key in sorted(db):                     # Iterate to display database objects\\n    print(key, \\'\\\\t=>\\', db[key])            # Prints with custom format\\n\\nsue = db[\\'Sue Jones\\']                      # Index by key to fetch\\nsue.giveRaise(.10)                         # Update in memory using class\\'s method\\ndb[\\'Sue Jones\\'] = sue                      # Assign to key to update in shelve\\ndb.close()                                 # Close after making changes\\n\\nBecause this script prints the database when it starts up, we have to run it at least twice\\nto see our objects change. Here it is in action, displaying all records and increasing\\nsue’s pay each time it is run (it’s a pretty good script for sue...something to schedule to\\nrun regularly as a cron job perhaps?):\\n\\nC:\\\\code> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=100000]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\n\\nC:\\\\code> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=110000]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\n\\nC:\\\\code> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=121000]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\n\\nC:\\\\code> updatedb.py\\nBob Smith       => [Person: job=None, name=Bob Smith, pay=0]\\nSue Jones       => [Person: job=dev, name=Sue Jones, pay=133100]\\nTom Jones       => [Manager: job=mgr, name=Tom Jones, pay=50000]\\n\\nAgain, what we see here is a product of the shelve and pickle tools we get from Python,\\nand of the behavior we coded in our classes ourselves. And once again, we can verify\\nour script’s work at the interactive prompt—the shelve’s equivalent of a database client:\\n\\nC:\\\\code> python\\n>>> import shelve\\n>>> db = shelve.open(\\'persondb\\')             # Reopen database\\n>>> rec = db[\\'Sue Jones\\']                    # Fetch object by key\\n>>> rec\\n[Person: job=dev, name=Sue Jones, pay=146410]\\n\\n852 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0c>>> rec.lastName()\\n\\'Jones\\'\\n>>> rec.pay\\n146410\\n\\nFor another example of object persistence in this book, see the sidebar in Chapter 31\\ntitled “Why You Will Care: Classes and Persistence” on page 941. It stores a some-\\nwhat larger composite object in a flat file with pickle instead of shelve, but the effect\\nis similar. For more details and examples for both pickles and shelves, see also Chap-\\nter 9 (file basics) and Chapter 37 (3.X string tool changes), other books, and Python’s \\nmanuals.\\n\\nFuture Directions\\nAnd that’s a wrap for this tutorial. At this point, you’ve seen all the basics of Python’s\\nOOP machinery in action, and you’ve learned ways to avoid redundancy and its asso-\\nciated maintenance issues in your code. You’ve built full-featured classes that do real\\nwork. As an added bonus, you’ve made them real database records by storing them in\\na Python shelve, so their information lives on persistently.\\nThere is much more we could explore here, of course. For example, we could extend\\nour classes to make them more realistic, add new kinds of behavior to them, and so on.\\nGiving a raise, for instance, should in practice verify that pay increase rates are between\\nzero and one—an extension we’ll add when we meet decorators later in this book. You\\nmight also mutate this example into a personal contacts database, by changing the state\\ninformation stored on objects, as well as the classes’ methods used to process it. We’ll\\nleave this a suggested exercise open to your imagination.\\nWe could also expand our scope to use tools that either come with Python or are freely\\navailable in the open source world:\\n\\nGUIs\\n\\nAs is, we can only process our database with the interactive prompt’s command-\\nbased interface, and scripts. We could also work on expanding our object data-\\nbase’s usability by adding a desktop graphical user interface for browsing and up-\\ndating  its  records.  GUIs  can  be  built  portably  with  either  Python’s  tkinter\\n(Tkinter in 2.X) standard library support, or third-party toolkits such as WxPython\\nand PyQt. tkinter ships with Python, lets you build simple GUIs quickly, and is\\nideal for learning GUI programming techniques; WxPython and PyQt tend to be\\nmore complex to use but often produce higher-grade GUIs in the end.\\n\\nWebsites\\n\\nAlthough GUIs are convenient and fast, the Web is hard to beat in terms of acces-\\nsibility. We might also implement a website for browsing and updating records,\\ninstead of or in addition to GUIs and the interactive prompt. Websites can be\\nconstructed with either basic CGI scripting tools that come with Python, or full-\\nfeatured  third-party  web  frameworks  such  as  Django,  TurboGears,  Pylons,\\n\\nFuture Directions\\n\\n| 853\\n\\n\\x0cweb2Py, Zope, or Google’s App Engine. On the Web, your data can still be stored\\nin a shelve, pickle file, or other Python-based medium; the scripts that process it\\nare simply run automatically on a server in response to requests from web browsers\\nand other clients, and they produce HTML to interact with a user, either directly\\nor by interfacing with framework APIs. Rich Internet application (RIA) systems\\nsuch as Silverlight and pyjamas also attempt to combine GUI-like interactivity with\\nweb-based deployment.\\n\\nWeb services\\n\\nAlthough web clients can often parse information in the replies from websites (a\\ntechnique colorfully known as “screen scraping”), we might go further and provide\\na more direct way to fetch records on the Web via a web services interface such as\\nSOAP or XML-RPC calls—APIs supported by either Python itself or the third-party\\nopen source domain, which generally map data to and from XML format for trans-\\nmission. To Python scripts, such APIs return data more directly than text embed-\\nded in the HTML of a reply page.\\n\\nDatabases\\n\\nIf our database becomes higher-volume or critical, we might eventually move it\\nfrom shelves to a more full-featured storage mechanism such as the open source \\nZODB object-oriented database system (OODB), or a more traditional SQL-based\\nrelational database system such as MySQL, Oracle, or PostgreSQL. Python itself\\ncomes with the in-process SQLite database system built-in, but other open source\\noptions are freely available on the Web. ZODB, for example, is similar to Python’s\\nshelve but addresses many of its limitations, better supporting larger databases,\\nconcurrent updates, transaction processing, and automatic write-through on in-\\nmemory changes (shelves can cache objects and flush to disk at close time with\\ntheir writeback option, but this has limitations: see other resources). SQL-based\\nsystems like MySQL offer enterprise-level tools for database storage and may be\\ndirectly used from a Python script. As we saw in Chapter 9, MongoDB offers an\\nalternative approach that stores JSON documents, which closely parallel Python\\ndictionaries and lists, and are language neutral, unlike pickle data.\\n\\nORMs\\n\\nIf we do migrate to a relational database system for storage, we don’t have to sac-\\nrifice Python’s OOP tools. Object-relational mappers (ORMs) like SQLObject and\\nSQLAlchemy can automatically map relational tables and rows to and from Python\\nclasses and instances, such that we can process the stored data using normal Python\\nclass  syntax.  This  approach  provides  an  alternative  to  OODBs  like  shelve  and\\nZODB and leverages the power of both relational databases and Python’s class\\nmodel.\\n\\nWhile I hope this introduction whets your appetite for future exploration, all of these\\ntopics are of course far beyond the scope of this tutorial and this book at large. If you\\nwant to explore any of them on your own, see the Web, Python’s standard library\\nmanuals, and application-focused books such as Programming Python. In the latter I\\n\\n854 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0cpick up this example where we’ve stopped here, showing how to add both a GUI and\\na website on top of the database to allow for browsing and updating instance records.\\nI hope to see you there eventually, but first, let’s return to class fundamentals and finish\\nup the rest of the core Python language story.\\n\\nChapter Summary\\nIn this chapter, we explored all the fundamentals of Python classes and OOP in action,\\nby building upon a simple but real example, step by step. We added constructors,\\nmethods,  operator  overloading,  customization  with  subclasses,  and  introspection-\\nbased tools, and we met other concepts such as composition, delegation, and poly-\\nmorphism along the way.\\nIn the end, we took objects created by our classes and made them persistent by storing\\nthem on a shelve object database—an easy-to-use system for saving and retrieving na-\\ntive Python objects by key. While exploring class basics, we also encountered multiple\\nways to factor our code to reduce redundancy and minimize future maintenance costs.\\nFinally, we briefly previewed ways to extend our code with application-programming\\ntools such as GUIs and databases, covered in follow-up books.\\nIn the next chapters of this part of the book, we’ll return to our study of the details\\nbehind Python’s class model and investigate its application to some of the design con-\\ncepts used to combine classes in larger programs. Before we move ahead, though, let’s\\nwork through this chapter’s quiz to review what we covered here. Since we’ve already\\ndone a lot of hands-on work in this chapter, we’ll close with a set of mostly theory-\\noriented questions designed to make you trace through some of the code and ponder\\nsome of the bigger ideas behind it.\\n\\nTest Your Knowledge: Quiz\\n1. When we fetch a Manager object from the shelve and print it, where does the display\\n\\nformat logic come from?\\n\\n2. When we fetch a Person object from a shelve without importing its module, how\\n\\ndoes the object know that it has a giveRaise method that we can call?\\n\\n3. Why is it so important to move processing into methods, instead of hardcoding it\\n\\noutside the class?\\n\\n4. Why is it better to customize by subclassing rather than copying the original and\\n\\nmodifying?\\n\\n5. Why is it better to call back to a superclass method to run default actions, instead\\n\\nof copying and modifying its code in a subclass?\\n\\n6. Why is it better to use tools like __dict__ that allow objects to be processed ge-\\n\\nnerically than to write more custom code for each type of class?\\n\\nTest Your Knowledge: Quiz | 855\\n\\n\\x0c7. In general terms, when might you choose to use object embedding and composition\\n\\ninstead of inheritance?\\n\\n8. What would you have to change if the objects coded in this chapter used a dictio-\\n\\nnary for names and a list for jobs, as in similar examples earlier in this book?\\n\\n9. How might you modify the classes in this chapter to implement a personal contacts\\n\\ndatabase in Python?\\n\\nTest Your Knowledge: Answers\\n1. In the final version of our classes, Manager ultimately inherits its __repr__ printing\\nmethod from AttrDisplay in the separate classtools module and two levels up in\\nthe class tree. Manager doesn’t have one itself, so the inheritance search climbs to\\nits Person superclass; because there is no __repr__ there either, the search climbs\\nhigher  and  finds  it  in  AttrDisplay.  The  class  names  listed  in  parentheses  in  a\\nclass statement’s header line provide the links to higher superclasses.\\n\\n2. Shelves (really, the pickle module they use) automatically relink an instance to the\\nclass it was created from when that instance is later loaded back into memory.\\nPython reimports the class from its module internally, creates an instance with its\\nstored attributes, and sets the instance’s __class__ link to point to its original class.\\nThis way, loaded instances automatically obtain all their original methods (like\\nlastName, giveRaise, and __repr__), even if we have not imported the instance’s\\nclass into our scope.\\n\\n3. It’s important to move processing into methods so that there is only one copy to\\nchange in the future, and so that the methods can be run on any instance. This is\\nPython’s notion of encapsulation—wrapping up logic behind interfaces, to better\\nsupport future code maintenance. If you don’t do so, you create code redundancy\\nthat can multiply your work effort as the code evolves in the future.\\n\\n4. Customizing  with  subclasses  reduces  development  effort.  In  OOP,  we  code  by\\ncustomizing what has already been done, rather than copying or changing existing\\ncode. This is the real “big idea” in OOP—because we can easily extend our prior\\nwork by coding new subclasses, we can leverage what we’ve already done. This is\\nmuch better than either starting from scratch each time, or introducing multiple\\nredundant copies of code that may all have to be updated in the future.\\n\\n5. Copying and modifying code doubles your potential work effort in the future, re-\\ngardless of the context. If a subclass needs to perform default actions coded in a\\nsuperclass method, it’s much better to call back to the original through the super-\\nclass’s name than to copy its code. This also holds true for superclass constructors.\\nAgain, copying code creates redundancy, which is a major issue as code evolves.\\n6. Generic tools can avoid hardcoded solutions that must be kept in sync with the\\nrest of the class as it evolves over time. A generic __repr__ print method, for ex-\\nample, need not be updated each time a new attribute is added to instances in an\\n\\n856 | Chapter 28:\\u2002A More Realistic Example\\n\\n\\x0c__init__ constructor. In addition, a generic print method inherited by all classes\\nappears and need be modified in only one place—changes in the generic version\\nare picked up by all classes that inherit from the generic class. Again, eliminating\\ncode redundancy cuts future development effort; that’s one of the primary assets\\nclasses bring to the table.\\n\\n7. Inheritance is best at coding extensions based on direct customization (like our\\nManager specialization of Person). Composition is well suited to scenarios where\\nmultiple objects are aggregated into a whole and directed by a controller layer class.\\nInheritance  passes  calls  up  to  reuse,  and  composition  passes  down  to  delegate.\\nInheritance and composition are not mutually exclusive; often, the objects em-\\nbedded in a controller are themselves customizations based upon inheritance.\\n\\n8. Not  much  since  this  was  really  a  first-cut  prototype,  but  the  lastName  method\\nwould need to be updated for the new name format; the Person constructor would\\nhave change the job default to an empty list; and the Manager class would probably\\nneed to pass along a job list in its constructor instead of a single string (self-test\\ncode would change as well, of course). The good news is that these changes would\\nneed to be made in just one place—in our classes, where such details are encap-\\nsulated. The database scripts should work as is, as shelves support arbitrarily nes-\\nted data.\\n\\n9. The classes in this chapter could be used as boilerplate “template” code to imple-\\nment a variety of types of databases. Essentially, you can repurpose them by mod-\\nifying the constructors to record different attributes and providing whatever meth-\\nods  are  appropriate  for  the  target  application.  For  instance,  you  might  use  at-\\ntributes such as name, address, birthday, phone, email, and so on for a contacts\\ndatabase, and methods appropriate for this purpose. A method named sendmail,\\nfor example, might use Python’s standard library smptlib module to send an email\\nto one of the contacts automatically when called (see Python’s manuals or appli-\\ncation-level books for more details on such tools). The AttrDisplay tool we wrote\\nhere  could  be  used  verbatim  to  print  your  objects,  because  it  is  intentionally\\ngeneric. Most of the shelve database code here can be used to store your objects,\\ntoo, with minor changes.\\n\\nTest Your Knowledge: Answers\\n\\n| 857\\n\\n\\x0c\\x0cCHAPTER 29\\nClass Coding Details\\n\\nIf you haven’t quite gotten all of Python OOP yet, don’t worry; now that we’ve had a\\nfirst tour, we’re going to dig a bit deeper and study the concepts introduced earlier in\\nfurther detail. In this and the following chapter, we’ll take another look at class me-\\nchanics. Here, we’re going to study classes, methods, and inheritance, formalizing and\\nexpanding on some of the coding ideas introduced in Chapter 27. Because the class is\\nour last namespace tool, we’ll summarize Python’s namespace and scope concepts as\\nwell.\\nThe next chapter continues this in-depth second pass over class mechanics by covering\\none specific aspect: operator overloading. Besides presenting additional details, this\\nchapter and the next also give us an opportunity to explore some larger classes than\\nthose we have studied so far.\\nContent note: if you’ve been reading linearly, some of this chapter will be review and\\nsummary of topics introduced in the preceding chapter’s case study, revisited here by\\nlanguage  topics  with  smaller  and  more  self-contained  examples  for  readers  new  to\\nOOP.  Others  may  be  tempted  to  skip  some  of  this  chapter,  but  be  sure  to  see  the\\nnamespace coverage here, as it explains some subtleties in Python’s class model.\\n\\nThe class Statement\\nAlthough the Python class statement may seem similar to tools in other OOP languages\\non the surface, on closer inspection, it is quite different from what some programmers\\nare used to. For example, as in C++, the class statement is Python’s main OOP tool,\\nbut unlike in C++, Python’s class is not a declaration. Like a def, a class statement is\\nan object builder, and an implicit assignment—when run, it generates a class object\\nand stores a reference to it in the name used in the header. Also like a def, a class\\nstatement is true executable code—your class doesn’t exist until Python reaches and\\nruns  the  class  statement  that  defines  it.  This  typically  occurs  while  importing  the\\nmodule it is coded in, but not before.\\n\\n859\\n\\n\\x0cGeneral Form\\nclass is a compound statement, with a body of statements typically indented appearing\\nunder the header. In the header, superclasses are listed in parentheses after the class\\nname, separated by commas. Listing more than one superclass leads to multiple in-\\nheritance, which we’ll discuss more formally in Chapter 31. Here is the statement’s\\ngeneral form:\\n\\nclass name(superclass,...):           # Assign to name\\n    attr = value                      # Shared class data\\n    def method(self,...):             # Methods\\n        self.attr = value             # Per-instance data\\n\\nWithin the class statement, any assignments generate class attributes, and specially\\nnamed methods overload operators; for instance, a function called __init__ is called\\nat instance object construction time, if defined.\\n\\nExample\\nAs we’ve seen, classes are mostly just namespaces—that is, tools for defining names\\n(i.e., attributes) that export data and logic to clients. A class statement effectively de-\\nfines a namespace. Just as in a module file, the statements nested in a class statement\\nbody create its attributes. When Python executes a class statement (not a call to a\\nclass), it runs all the statements in its body, from top to bottom. Assignments that\\nhappen during this process create names in the class’s local scope, which become at-\\ntributes in the associated class object. Because of this, classes resemble both modules\\nand functions:\\n\\n• Like functions, class statements are local scopes where names created by nested\\n\\nassignments live.\\n\\n• Like names in a module, names assigned in a class statement become attributes\\n\\nin a class object.\\n\\nThe main distinction for classes is that their namespaces are also the basis of inheri-\\ntance in Python; reference attributes that are not found in a class or instance object are\\nfetched from other classes.\\nBecause class is a compound statement, any sort of statement can be nested inside its\\nbody—print, assignments, if, def, and so on. All the statements inside the class state-\\nment run when the class statement itself runs (not when the class is later called to make\\nan instance). Typically, assignment statements inside the class statement make data\\nattributes, and nested defs make method attributes. In general, though, any type of\\nname assignment at the top level of a class statement creates a same-named attribute\\nof the resulting class object.\\nFor example, assignments of simple nonfunction objects to class attributes produce\\ndata attributes, shared by all instances:\\n\\n860 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0c>>> class SharedData:\\n        spam = 42          # Generates a class data attribute\\n\\n>>> x = SharedData()       # Make two instances\\n>>> y = SharedData()\\n>>> x.spam, y.spam         # They inherit and share \\'spam\\' (a.k.a. SharedData.spam)\\n(42, 42)\\n\\nHere, because the name  spam is assigned at the top level of a  class statement, it is\\nattached to the class and so will be shared by all instances. We can change it by going\\nthrough the class name, and we can refer to it through either instances or the class:1\\n\\n>>> SharedData.spam = 99\\n>>> x.spam, y.spam, SharedData.spam\\n(99, 99, 99)\\n\\nSuch class attributes can be used to manage information that spans all the instances—\\na counter of the number of instances generated, for example (we’ll expand on this idea\\nby example in Chapter 32). Now, watch what happens if we assign the name  spam\\nthrough an instance instead of the class:\\n\\n>>> x.spam = 88\\n>>> x.spam, y.spam, SharedData.spam\\n(88, 99, 99)\\n\\nAssignments to instance attributes create or change the names in the instance, rather\\nthan in the shared class. More generally, inheritance searches occur only on attribute\\nreferences, not on assignment: assigning to an object’s attribute always changes that\\nobject, and no other.2 For example, y.spam is looked up in the class by inheritance, but\\nthe assignment to x.spam attaches a name to x itself.\\nHere’s a more comprehensive example of this behavior that stores the same name in\\ntwo places. Suppose we run the following class:\\n\\nclass MixedNames:                            # Define class\\n    data = \\'spam\\'                            # Assign class attr\\n    def __init__(self, value):               # Assign method name\\n        self.data = value                    # Assign instance attr\\n    def display(self):\\n        print(self.data, MixedNames.data)    # Instance attr, class attr\\n\\n1. If you’ve used C++ you may recognize this as similar to the notion of C++’s “static” data members—\\nmembers that are stored in the class, independent of instances. In Python, it’s nothing special: all class\\nattributes are just names assigned in the class statement, whether they happen to reference functions\\n(C++’s “methods”) or something else (C++’s “members”). In Chapter 32, we’ll also meet Python static\\nmethods (akin to those in C++), which are just self-less functions that usually process class attributes.\\n\\n2. Unless  the  class  has  redefined  the  attribute  assignment  operation  to  do  something  unique  with  the\\n__setattr__ operator overloading method (discussed in Chapter 30), or uses advanced attribute tools\\nsuch as properties and descriptors (discussed in Chapter 32 and Chapter 38). Much of this chapter presents\\nthe normal case, which suffices at this point in the book, but as we’ll see later, Python hooks allow\\nprograms to deviate from the norm often.\\n\\nThe class Statement\\n\\n| 861\\n\\n\\x0cThis class contains two defs, which bind class attributes to method functions. It also\\ncontains an = assignment statement; because this assignment assigns the name data\\ninside the class, it lives in the class’s local scope and becomes an attribute of the class\\nobject. Like all class attributes, this data is inherited and shared by all instances of the\\nclass that don’t have data attributes of their own.\\nWhen we make instances of this class, the name data is attached to those instances by\\nthe assignment to self.data in the constructor method:\\n>>> x = MixedNames(1)          # Make two instance objects\\n>>> y = MixedNames(2)          # Each has its own data\\n>>> x.display(); y.display()   # self.data differs, MixedNames.data is the same\\n1 spam\\n2 spam\\n\\nThe net result is that data lives in two places: in the instance objects (created by the\\nself.data assignment in __init__), and in the class from which they inherit names\\n(created by the data assignment in the class). The class’s display method prints both\\nversions, by first qualifying the self instance, and then the class.\\nBy using these techniques to store attributes in different objects, we determine their\\nscope of visibility. When attached to classes, names are shared; in instances, names\\nrecord per-instance data, not shared behavior or data. Although inheritance searches\\nlook up names for us, we can always get to an attribute anywhere in a tree by accessing\\nthe desired object directly.\\nIn the preceding example, for instance, specifying x.data or self.data will return an\\ninstance  name,  which  normally  hides  the  same  name  in  the  class;  however,  Mixed\\nNames.data grabs the class’s version of the name explicitly. The next section describes\\none of the most common roles for such coding patterns, and explains more about the\\nway we deployed it in the prior chapter.\\n\\nMethods\\nBecause you already know about functions, you also know about methods in classes.\\nMethods are just function objects created by def statements nested in a class state-\\nment’s  body.  From  an  abstract  perspective,  methods  provide  behavior  for  instance\\nobjects to inherit. From a programming perspective, methods work in exactly the same\\nway as simple functions, with one crucial exception: a method’s first argument always\\nreceives the instance object that is the implied subject of the method call.\\nIn other words, Python automatically maps instance method calls to a class’s method\\nfunctions as follows. Method calls made through an instance, like this:\\n\\ninstance.method(args...)\\n\\nare automatically translated to class method function calls of this form:\\n\\nclass.method(instance, args...)\\n\\n862 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cwhere Python determines the class by locating the method name using the inheritance\\nsearch procedure. In fact, both call forms are valid in Python.\\nBesides the normal inheritance of method attribute names, the special first argument\\nis the only real magic behind method calls. In a class’s method, the first argument is\\nusually called self by convention (technically, only its position is significant, not its\\nname). This argument provides methods with a hook back to the instance that is the\\nsubject of the call—because classes generate many instance objects, they need to use\\nthis argument to manage data that varies per instance.\\nC++ programmers may recognize Python’s self argument as being similar to C++’s\\nthis pointer. In Python, though, self is always explicit in your code: methods must\\nalways go through self to fetch or change attributes of the instance being processed\\nby the current method call. This explicit nature of self is by design—the presence of\\nthis name makes it obvious that you are using instance attribute names in your script,\\nnot names in the local or global scope.\\n\\nMethod Example\\nTo clarify these concepts, let’s turn to an example. Suppose we define the following\\nclass:\\n\\nclass NextClass:                            # Define class\\n    def printer(self, text):                # Define method\\n        self.message = text                 # Change instance\\n        print(self.message)                 # Access instance\\n\\nThe name printer references a function object; because it’s assigned in the class state-\\nment’s scope, it becomes a class object attribute and is inherited by every instance made\\nfrom the class. Normally, because methods like printer are designed to process in-\\nstances, we call them through instances:\\n\\n>>> x = NextClass()                         # Make instance\\n>>> x.printer(\\'instance call\\')              # Call its method\\ninstance call\\n>>> x.message                               # Instance changed\\n\\'instance call\\'\\n\\nWhen we call the method by qualifying an instance like this, printer is first located by\\ninheritance, and then its self argument is automatically assigned the instance object\\n(x); the text argument gets the string passed at the call (\\'instance call\\'). Notice that\\nbecause Python automatically passes the first argument to self for us, we only actually\\nhave to pass in one argument. Inside printer, the name self is used to access or set\\nper-instance data because it refers back to the instance currently being processed.\\nAs we’ve seen, though, methods may be called in one of two ways—through an in-\\nstance,  or  through  the  class  itself.  For  example,  we  can  also  call  printer  by  going\\nthrough the class name, provided we pass an instance to the self argument explicitly:\\n\\nMethods\\n\\n| 863\\n\\n\\x0c>>> NextClass.printer(x, \\'class call\\')      # Direct class call\\nclass call\\n>>> x.message                               # Instance changed again\\n\\'class call\\'\\n\\nCalls routed through the instance and the class have the exact same effect, as long as\\nwe pass the same instance object ourselves in the class form. By default, in fact, you get\\nan error message if you try to call a method without any instance:\\n\\n>>> NextClass.printer(\\'bad call\\')\\nTypeError: unbound method printer() must be called with NextClass instance...\\n\\nCalling Superclass Constructors\\nMethods  are  normally  called  through  instances.  Calls  to  methods  through  a  class,\\nthough, do show up in a variety of special roles. One common scenario involves the\\nconstructor method. The __init__ method, like all attributes, is looked up by inheri-\\ntance.  This  means  that  at  construction  time,  Python  locates  and  calls  just  one\\n__init__. If subclass constructors need to guarantee that superclass construction-time\\nlogic runs, too, they generally must call the superclass’s __init__ method explicitly\\nthrough the class:\\n\\nclass Super:\\n    def __init__(self, x):\\n        ...default code...\\n\\nclass Sub(Super):\\n    def __init__(self, x, y):\\n        Super.__init__(self, x)             # Run superclass __init__\\n        ...custom code...                   # Do my init actions\\n\\nI = Sub(1, 2)\\n\\nThis is one of the few contexts in which your code is likely to call an operator over-\\nloading method directly. Naturally, you should call the superclass constructor this way\\nonly if you really want it to run—without the call, the subclass replaces it completely.\\nFor a more realistic illustration of this technique in action, see the Manager class example\\nin the prior chapter’s tutorial.3\\n\\nOther Method Call Possibilities\\nThis pattern of calling methods through a class is the general basis of extending—\\ninstead of completely replacing—inherited method behavior. It requires an explicit\\ninstance to be passed because all methods do by default. Technically, this is because \\nmethods are instance methods in the absence of any special code.\\n\\n3. On a related note, you can also code multiple __init__ methods within the same class, but only the last\\n\\ndefinition will be used; see Chapter 31 for more details on multiple method definitions.\\n\\n864 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cIn Chapter 32, we’ll also meet a newer option added in Python 2.2, static methods, that\\nallow you to code methods that do not expect instance objects in their first arguments.\\nSuch methods can act like simple instanceless functions, with names that are local to\\nthe classes in which they are coded, and may be used to manage class data. A related\\nconcept we’ll meet in the same chapter, the class method, receives a class when called\\ninstead of an instance and can be used to manage per-class data, and is implied in\\nmetaclasses.\\nThese are both advanced and usually optional extensions, though. Normally, an in-\\nstance must always be passed to a method—whether automatically when it is called\\nthrough an instance, or manually when you call through a class.\\n\\nPer the sidebar “What About super?” on page 831 in Chapter 28, Python\\nalso has a super built-in function that allows calling back to a super-\\nclass’s methods more generically, but we’ll defer its presentation until\\nChapter 32 due to its downsides and complexities. See the aforemen-\\ntioned sidebar for more details; this call has well-known tradeoffs in\\nbasic usage, and an esoteric advanced use case that requires universal\\ndeployment to be most effective. Because of these issues, this book pre-\\nfers to call superclasses by explicit name instead of super as a policy; if\\nyou’re new to Python, I recommend the same approach for now, espe-\\ncially for your first pass over OOP. Learn the simple way now, so you\\ncan compare it to others later.\\n\\nInheritance\\nOf course, the whole point of the namespace created by the class statement is to sup-\\nport name inheritance. This section expands on some of the mechanisms and roles of\\nattribute inheritance in Python.\\nAs we’ve seen, in Python, inheritance happens when an object is qualified, and it in-\\nvolves searching an attribute definition tree—one or more namespaces. Every time you\\nuse an expression of the form object.attr where object is an instance or class object,\\nPython searches the namespace tree from bottom to top, beginning with object, looking\\nfor the first attr it can find. This includes references to self attributes in your methods.\\nBecause lower definitions in the tree override higher ones, inheritance forms the basis\\nof specialization.\\n\\nAttribute Tree Construction\\nFigure 29-1 summarizes the way namespace trees are constructed and populated with\\nnames. Generally:\\n\\n• Instance attributes are generated by assignments to self attributes in methods.\\n• Class attributes are created by statements (assignments) in class statements.\\n\\nInheritance | 865\\n\\n\\x0c• Superclass links are made by listing classes in parentheses in a class statement\\n\\nheader.\\n\\nThe net result is a tree of attribute namespaces that leads from an instance, to the class\\nit was generated from, to all the superclasses listed in the class header. Python searches\\nupward in this tree, from instances to superclasses, each time you use qualification to\\nfetch an attribute name from an instance object.4\\n\\nFigure 29-1. Program code creates a tree of objects in memory to be searched by attribute inheritance.\\nCalling a class creates a new instance that remembers its class, running a class statement creates a\\nnew class, and superclasses are listed in parentheses in the class statement header. Each attribute\\nreference triggers a new bottom-up tree search—even references to self attributes within a class’s\\nmethods.\\n\\nSpecializing Inherited Methods\\nThe tree-searching model of inheritance just described turns out to be a great way to\\nspecialize systems. Because inheritance finds names in subclasses before it checks su-\\nperclasses,  subclasses  can  replace  default  behavior  by  redefining  their  superclasses’\\n\\n4. Two fine points here: first, this description isn’t 100% complete, because we can also create instance and\\nclass attributes by assigning them to objects outside class statements—but that’s a much less common\\nand sometimes more error-prone approach (changes aren’t isolated to class statements). In Python, all\\nattributes are always accessible by default. We’ll talk more about attribute name privacy in Chapter 30\\nwhen we study __setattr__, in Chapter 31 when we meet __X names, and again in Chapter 39, where\\nwe’ll implement it with a class decorator.\\n\\nSecond, as also noted in Chapter 27, the full inheritance story grows more convoluted when advanced\\ntopics such as metaclasses and descriptors are added to the mix—and we’re deferring a formal definition\\nuntil Chapter 40 for this reason. In common usage, though, it’s simply a way to redefine, and hence\\ncustomize, behavior coded in classes.\\n\\n866 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cattributes. In fact, you can build entire systems as hierarchies of classes, which you\\nextend by adding new external subclasses rather than changing existing logic in place.\\nThe idea of redefining inherited names leads to a variety of specialization techniques.\\nFor instance, subclasses may replace inherited attributes completely, provide attributes\\nthat a superclass expects to find, and extend superclass methods by calling back to the\\nsuperclass from an overridden method. We’ve already seen some of these patterns in\\naction; here’s a self-contained example of extension at work:\\n\\n>>> class Super:\\n        def method(self):\\n            print(\\'in Super.method\\')\\n\\n>>> class Sub(Super):\\n        def method(self):                    # Override method\\n            print(\\'starting Sub.method\\')     # Add actions here\\n            Super.method(self)               # Run default action\\n            print(\\'ending Sub.method\\')\\n\\nDirect superclass method calls are the crux of the matter here. The Sub class replaces\\nSuper’s method function with its own specialized version, but within the replacement,\\nSub calls back to the version exported by Super to carry out the default behavior. In\\nother words, Sub.method just extends Super.method’s behavior, rather than replacing it\\ncompletely:\\n\\n>>> x = Super()                              # Make a Super instance\\n>>> x.method()                               # Runs Super.method\\nin Super.method\\n\\n>>> x = Sub()                                # Make a Sub instance\\n>>> x.method()                               # Runs Sub.method, calls Super.method\\nstarting Sub.method\\nin Super.method\\nending Sub.method\\n\\nThis extension coding pattern is also commonly used with constructors; see the section\\n“Methods” on page 862 for an example.\\n\\nClass Interface Techniques\\nExtension is only one way to interface with a superclass. The file shown in this section,\\nspecialize.py, defines multiple classes that illustrate a variety of common techniques:\\n\\nSuper\\n\\nDefines a method function and a delegate that expects an action in a subclass.\\n\\nInheritor\\n\\nDoesn’t provide any new names, so it gets everything defined in Super.\\n\\nReplacer\\n\\nOverrides Super’s method with a version of its own.\\n\\nInheritance | 867\\n\\n\\x0cExtender\\n\\nCustomizes Super’s method by overriding and calling back to run the default.\\n\\nProvider\\n\\nImplements the action method expected by Super’s delegate method.\\n\\nStudy each of these subclasses to get a feel for the various ways they customize their\\ncommon superclass. Here’s the file:\\n\\nclass Super:\\n    def method(self):\\n        print(\\'in Super.method\\')           # Default behavior\\n    def delegate(self):\\n        self.action()                      # Expected to be defined\\n\\nclass Inheritor(Super):                    # Inherit method verbatim\\n    pass\\n\\nclass Replacer(Super):                     # Replace method completely\\n    def method(self):\\n        print(\\'in Replacer.method\\')\\n\\nclass Extender(Super):                     # Extend method behavior\\n    def method(self):\\n        print(\\'starting Extender.method\\')\\n        Super.method(self)\\n        print(\\'ending Extender.method\\')\\n\\nclass Provider(Super):                     # Fill in a required method\\n    def action(self):\\n        print(\\'in Provider.action\\')\\n\\nif __name__ == \\'__main__\\':\\n    for klass in (Inheritor, Replacer, Extender):\\n        print(\\'\\\\n\\' + klass.__name__ + \\'...\\')\\n        klass().method()\\n    print(\\'\\\\nProvider...\\')\\n    x = Provider()\\n    x.delegate()\\n\\nA few things are worth pointing out here. First, notice how the self-test code at the end\\nof this example creates instances of three different classes in a for loop. Because classes\\nare objects, you can store them in a tuple and create instances generically with no extra\\nsyntax (more on this idea later). Classes also have the special __name__ attribute, like\\nmodules; it’s preset to a string containing the name in the class header. Here’s what\\nhappens when we run the file:\\n\\n% python specialize.py\\n\\nInheritor...\\nin Super.method\\n\\nReplacer...\\nin Replacer.method\\n\\n868 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cExtender...\\nstarting Extender.method\\nin Super.method\\nending Extender.method\\n\\nProvider...\\nin Provider.action\\n\\nAbstract Superclasses\\nOf the prior example’s classes, Provider may be the most crucial to understand. When\\nwe call the delegate method through a Provider instance, two independent inheritance\\nsearches occur:\\n\\n1. On  the  initial  x.delegate  call,  Python  finds  the  delegate  method  in  Super  by\\nsearching  the  Provider  instance  and  above.  The  instance  x  is  passed  into  the\\nmethod’s self argument as usual.\\n\\n2. Inside the Super.delegate method, self.action invokes a new, independent in-\\nheritance search of self and above. Because self references a Provider instance,\\nthe action method is located in the Provider subclass.\\n\\nThis “filling in the blanks” sort of coding structure is typical of OOP frameworks. In a\\nmore realistic context, the method filled in this way might handle an event in a GUI,\\nprovide data to be rendered as part of a web page, process a tag’s text in an XML file,\\nand so on—your subclass provides specific actions, but the framework handles the rest\\nof the overall job.\\nAt least in terms of the  delegate method, the superclass in this example is what is\\nsometimes called an abstract superclass—a class that expects parts of its behavior to be\\nprovided by its subclasses. If an expected method is not defined in a subclass, Python\\nraises an undefined name exception when the inheritance search fails.\\nClass coders sometimes make such subclass requirements more obvious with assert\\nstatements, or by raising the built-in NotImplementedError exception with raise state-\\nments. We’ll study statements that may trigger exceptions in depth in the next part of\\nthis book; as a quick preview, here’s the assert scheme in action:\\n\\nclass Super:\\n    def delegate(self):\\n        self.action()\\n    def action(self):\\n        assert False, \\'action must be defined!\\'      # If this version is called\\n\\n>>> X = Super()\\n>>> X.delegate()\\nAssertionError: action must be defined!\\n\\nWe’ll meet assert in Chapter 33 and Chapter 34; in short, if its first expression evaluates\\nto false, it raises an exception with the provided error message. Here, the expression is\\n\\nInheritance | 869\\n\\n\\x0calways false so as to trigger an error message if a method is not redefined, and inheri-\\ntance locates the version here. Alternatively, some classes simply raise a NotImplemen\\ntedError exception directly in such method stubs to signal the mistake:\\n\\nclass Super:\\n    def delegate(self):\\n        self.action()\\n    def action(self):\\n        raise NotImplementedError(\\'action must be defined!\\')\\n\\n>>> X = Super()\\n>>> X.delegate()\\nNotImplementedError: action must be defined!\\n\\nFor instances of subclasses, we still get the exception unless the subclass provides the\\nexpected method to replace the default in the superclass:\\n\\n>>> class Sub(Super): pass\\n\\n>>> X = Sub()\\n>>> X.delegate()\\nNotImplementedError: action must be defined!\\n\\n>>> class Sub(Super):\\n        def action(self): print(\\'spam\\')\\n\\n>>> X = Sub()\\n>>> X.delegate()\\nspam\\n\\nFor a somewhat more realistic example of this section’s concepts in action, see the “Zoo\\nanimal hierarchy” exercise (Exercise 8) at the end of Chapter 32, and its solution in\\n“Part VI, Classes and OOP” in Appendix D. Such taxonomies are a traditional way to\\nintroduce OOP, but they’re a bit removed from most developers’ job descriptions (with\\napologies to any readers who happen to work at the zoo!).\\n\\nAbstract superclasses in Python 3.X and 2.6+: Preview\\nAs of Python 2.6 and 3.0, the prior section’s abstract superclasses (a.k.a. “abstract base\\nclasses”), which require methods to be filled in by subclasses, may also be implemented\\nwith special class syntax. The way we code this varies slightly depending on the version.\\nIn Python 3.X, we use a keyword argument in a class header, along with special @\\ndecorator syntax, both of which we’ll study in detail later in this book:\\n\\nfrom abc import ABCMeta, abstractmethod\\n\\nclass Super(metaclass=ABCMeta):\\n    @abstractmethod\\n    def method(self, ...):\\n        pass\\n\\nBut in Python 2.6 and 2.7, we use a class attribute instead:\\n\\n870 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cclass Super:\\n    __metaclass__ = ABCMeta\\n    @abstractmethod\\n    def method(self, ...):\\n        pass\\n\\nEither way, the effect is the same—we can’t make an instance unless the method is\\ndefined lower in the class tree. In 3.X, for example, here is the special syntax equivalent\\nof the prior section’s example:\\n\\n>>> from abc import ABCMeta, abstractmethod\\n>>>\\n>>> class Super(metaclass=ABCMeta):\\n        def delegate(self):\\n            self.action()\\n        @abstractmethod\\n        def action(self):\\n            pass\\n\\n>>> X = Super()\\nTypeError: Can\\'t instantiate abstract class Super with abstract methods action\\n\\n>>> class Sub(Super): pass\\n\\n>>> X = Sub()\\nTypeError: Can\\'t instantiate abstract class Sub with abstract methods action\\n\\n>>> class Sub(Super):\\n        def action(self): print(\\'spam\\')\\n\\n>>> X = Sub()\\n>>> X.delegate()\\nspam\\n\\nCoded this way, a class with an abstract method cannot be instantiated (that is, we\\ncannot create an instance by calling it) unless all of its abstract methods have been\\ndefined in subclasses. Although this requires more code and extra knowledge, the po-\\ntential advantage of this approach is that errors for missing methods are issued when\\nwe attempt to make an instance of the class, not later when we try to call a missing\\nmethod. This feature may also be used to define an expected interface, automatically\\nverified in client classes.\\nUnfortunately, this scheme also relies on two advanced language tools we have not met\\nyet—function  decorators,  introduced  in  Chapter  32  and  covered  in  depth  in  Chap-\\nter  39,  as  well  as  metaclass  declarations,  mentioned  in  Chapter  32  and  covered  in\\nChapter 40—so we will finesse other facets of this option here. See Python’s standard\\nmanuals for more on this, as well as precoded abstract superclasses Python provides.\\n\\nInheritance | 871\\n\\n\\x0cNamespaces: The Conclusion\\nNow that we’ve examined class and instance objects, the Python namespace story is\\ncomplete. For reference, I’ll quickly summarize all the rules used to resolve names here.\\nThe first things you need to remember are that qualified and unqualified names are\\ntreated differently, and that some scopes serve to initialize object namespaces:\\n\\n• Unqualified names (e.g., X) deal with scopes.\\n• Qualified attribute names (e.g., object.X) use object namespaces.\\n• Some scopes initialize object namespaces (for modules and classes).\\n\\nThese concepts sometimes interact—in object.X, for example, object is looked up per\\nscopes, and then X is looked up in the result objects. Since scopes and namespaces are\\nessential to understanding Python code, let’s summarize the rules in more detail.\\n\\nSimple Names: Global Unless Assigned\\nAs we’ve learned, unqualified simple names follow the LEGB lexical scoping rule out-\\nlined when we explored functions in Chapter 17:\\n\\nAssignment (X = value)\\n\\nMakes names local by default: creates or changes the name X in the current local\\nscope, unless declared global (or nonlocal in 3.X).\\n\\nReference (X)\\n\\nLooks for the name X in the current local scope, then any and all enclosing func-\\ntions, then the current global scope, then the built-in scope, per the LEGB rule.\\nEnclosing classes are not searched: class names are fetched as object attributes\\ninstead.\\n\\nAlso per Chapter 17, some special-case constructs localize names further (e.g., variables\\nin some comprehensions and try statement clauses), but the vast majority of names\\nfollow the LEGB rule.\\n\\nAttribute Names: Object Namespaces\\nWe’ve also seen that qualified attribute names refer to attributes of specific objects and\\nobey the rules for modules and classes. For class and instance objects, the reference\\nrules are augmented to include the inheritance search procedure:\\n\\nAssignment (object.X = value)\\n\\nCreates or alters the attribute name X in the namespace of the object being quali-\\nfied, and none other. Inheritance-tree climbing happens only on attribute refer-\\nence, not on attribute assignment.\\n\\n872 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cReference (object.X)\\n\\nFor class-based objects, searches for the attribute name X in object, then in all\\naccessible classes above it, using the inheritance search procedure. For nonclass\\nobjects such as modules, fetches X from object directly.\\n\\nAs noted earlier, the preceding captures the normal and typical case. These attribute\\nrules can vary in classes that utilize more advanced tools, especially for new-style classes\\n—an option in 2.X and the standard in 3.X, which we’ll explore in Chapter 32. For\\nexample, reference inheritance can be richer than implied here when metaclasses are\\ndeployed, and classes which leverage attribute management tools such as properties,\\ndescriptors, and __setattr__ can intercept and route attribute assignments arbitrarily.\\nIn  fact,  some  inheritance  is  run  on  assignment  too,  to  locate  descriptors  with  a\\n__set__  method  in  new-style  classes;  such  tools  override  the  normal  rules  for  both\\nreference and assignment. We’ll explore attribute management tools in depth in Chap-\\nter 38, and formalize inheritance and its use of descriptors in Chapter 40. For now,\\nmost readers should focus on the normal rules given here, which cover most Python\\napplication code.\\n\\nThe “Zen” of Namespaces: Assignments Classify Names\\nWith  distinct  search  procedures  for  qualified  and  unqualified  names,  and  multiple\\nlookup layers for both, it can sometimes be difficult to tell where a name will wind up\\ngoing. In Python, the place where you assign a name is crucial—it fully determines the\\nscope or object in which a name will reside. The file manynames.py illustrates how this\\nprinciple translates to code and summarizes the namespace ideas we have seen through-\\nout this book (sans obscure special-case scopes like comprehensions):\\n\\n# File manynames.py\\n\\nX = 11                       # Global (module) name/attribute (X, or manynames.X)\\n\\ndef f():\\n    print(X)                 # Access global X (11)\\n\\ndef g():\\n    X = 22                   # Local (function) variable (X, hides module X)\\n    print(X)\\n\\nclass C:\\n    X = 33                   # Class attribute (C.X)\\n    def m(self):\\n        X = 44               # Local variable in method (X)\\n        self.X = 55          # Instance attribute (instance.X)\\n\\nThis file assigns the same name,  X, five times—illustrative, though not exactly best\\npractice! Because this name is assigned in five different locations, though, all five Xs in\\nthis program are completely different variables. From top to bottom, the assignments\\nto X here generate: a module attribute (11), a local variable in a function (22), a class\\n\\nNamespaces: The Conclusion | 873\\n\\n\\x0cattribute (33), a local variable in a method (44), and an instance attribute (55). Although\\nall five are named X, the fact that they are all assigned at different places in the source\\ncode or to different objects makes all of these unique variables.\\nYou should take the time to study this example carefully because it collects ideas we’ve\\nbeen exploring throughout the last few parts of this book. When it makes sense to you,\\nyou will have achieved Python namespace enlightenment. Or, you can run the code\\nand see what happens—here’s the remainder of this source file, which makes an in-\\nstance and prints all the Xs that it can fetch:\\n\\n# manynames.py, continued\\n\\nif __name__ == \\'__main__\\':\\n    print(X)                 # 11: module (a.k.a. manynames.X outside file)\\n    f()                      # 11: global\\n    g()                      # 22: local\\n    print(X)                 # 11: module name unchanged\\n\\n    obj = C()                # Make instance\\n    print(obj.X)             # 33: class name inherited by instance\\n\\n    obj.m()                  # Attach attribute name X to instance now\\n    print(obj.X)             # 55: instance\\n    print(C.X)               # 33: class (a.k.a. obj.X if no X in instance)\\n\\n    #print(C.m.X)            # FAILS: only visible in method\\n    #print(g.X)              # FAILS: only visible in function\\n\\nThe outputs that are printed when the file is run are noted in the comments in the code;\\ntrace through them to see which variable named X is being accessed each time. Notice\\nin particular that we can go through the class to fetch its attribute (C.X), but we can\\nnever fetch local variables in functions or methods from outside their def statements.\\nLocals are visible only to other code within the def, and in fact only live in memory\\nwhile a call to the function or method is executing.\\nSome of the names defined by this file are visible outside the file to other modules too,\\nbut recall that we must always import before we can access names in another file—\\nname segregation is the main point of modules, after all:\\n\\n# otherfile.py\\n\\nimport manynames\\n\\nX = 66\\nprint(X)                     # 66: the global here\\nprint(manynames.X)           # 11: globals become attributes after imports\\n\\nmanynames.f()                # 11: manynames\\'s X, not the one here!\\nmanynames.g()                # 22: local in other file\\'s function\\n\\nprint(manynames.C.X)         # 33: attribute of class in other module\\nI = manynames.C()\\nprint(I.X)                   # 33: still from class here\\n\\n874 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0cI.m()\\nprint(I.X)                   # 55: now from instance!\\n\\nNotice here how manynames.f() prints the X in manynames, not the X assigned in this file\\n—scopes are always determined by the position of assignments in your source code\\n(i.e., lexically) and are never influenced by what imports what or who imports whom.\\nAlso, notice that the instance’s own X is not created until we call I.m()—attributes, like\\nall variables, spring into existence when assigned, and not before. Normally we create\\ninstance attributes by assigning them in class __init__ constructor methods, but this\\nisn’t the only option.\\nFinally, as we learned in Chapter 17, it’s also possible for a function to change names\\noutside itself, with global and (in Python 3.X) nonlocal statements—these statements\\nprovide write access, but also modify assignment’s namespace binding rules:\\n\\nX = 11                       # Global in module\\n\\ndef g1():\\n    print(X)                 # Reference global in module (11)\\n\\ndef g2():\\n    global X\\n    X = 22                   # Change global in module\\n\\ndef h1():\\n    X = 33                   # Local in function\\n    def nested():\\n        print(X)             # Reference local in enclosing scope (33)\\n\\ndef h2():\\n    X = 33                   # Local in function\\n    def nested():\\n        nonlocal X           # Python 3.X statement\\n        X = 44               # Change local in enclosing scope\\n\\nOf course, you generally shouldn’t use the same name for every variable in your script\\n—but as this example demonstrates, even if you do, Python’s namespaces will work to\\nkeep names used in one context from accidentally clashing with those used in another.\\n\\nNested Classes: The LEGB Scopes Rule Revisited\\nThe preceding example summarized the effect of nested functions on scopes, which we\\nstudied in Chapter 17. It turns out that classes can be nested too—a useful coding\\npattern in some types of programs, with scope implications that follow naturally from\\nwhat you already know, but that may not be obvious on first encounter. This section\\nillustrates the concept by example.\\nThough they are normally coded at the top level of a module, classes also sometimes\\nappear nested in functions that generate them—a variation on the “factory function”\\n(a.k.a. closure) theme in Chapter 17, with similar state retention roles. There we noted\\n\\nNamespaces: The Conclusion | 875\\n\\n\\x0cthat class statements introduce new local scopes much like function def statements,\\nwhich follow the same LEGB scope lookup rule as function definitions.\\nThis rule applies both to the top level of the class itself, as well as to the top level of\\nmethod functions nested within it. Both form the L layer in this rule—they are normal\\nlocal scopes, with access to their names, names in any enclosing functions, globals in\\nthe enclosing module, and built-ins. Like modules, the class’s local scope morphs into\\nan attribute namespace after the class statement is run.\\nAlthough classes have access to enclosing functions’ scopes, though, they do not act\\nas enclosing scopes to code nested within the class: Python searches enclosing functions\\nfor referenced names, but never any enclosing classes. That is, a class is a local scope\\nand has access to enclosing local scopes, but it does not serve as an enclosing local scope\\nto further nested code. Because the search for names used in method functions skips\\nthe enclosing class, class attributes must be fetched as object attributes using inheri-\\ntance.\\nFor example, in the following nester function, all references to X are routed to the global\\nscope except the last, which picks up a local scope redefinition (the section’s code is in\\nfile classscope.py, and the output of each example is described in its last two comments):\\n\\nX = 1\\n\\ndef nester():\\n   print(X)                 # Global: 1\\n   class C:\\n       print(X)             # Global: 1\\n       def method1(self):\\n           print(X)         # Global: 1\\n       def method2(self):\\n           X = 3            # Hides global\\n           print(X)         # Local: 3\\n   I = C()\\n   I.method1()\\n   I.method2()\\n\\nprint(X)                    # Global: 1\\nnester()                    # Rest: 1, 1, 1, 3\\nprint(\\'-\\'*40)\\n\\nWatch what happens, though, when we reassign the same name in nested function\\nlayers: the redefinitions of X create locals that hide those in enclosing scopes, just as for\\nsimple nested functions; the enclosing class layer does not change this rule, and in fact\\nis irrelevant to it:\\n\\nX = 1\\n\\ndef nester():\\n   X = 2                    # Hides global\\n   print(X)                 # Local: 2\\n   class C:\\n       print(X)             # In enclosing def (nester): 2\\n\\n876 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0c       def method1(self):\\n           print(X)         # In enclosing def (nester): 2\\n       def method2(self):\\n           X = 3            # Hides enclosing (nester)\\n           print(X)         # Local: 3\\n   I = C()\\n   I.method1()\\n   I.method2()\\n\\nprint(X)                    # Global: 1\\nnester()                    # Rest: 2, 2, 2, 3\\nprint(\\'-\\'*40)\\n\\nAnd here’s what happens when we reassign the same name at multiple stops along the\\nway: assignments in the local scopes of both functions and classes hide globals or en-\\nclosing function locals of the same name, regardless of the nesting involved:\\n\\nX = 1\\n\\ndef nester():\\n   X = 2                    # Hides global\\n   print(X)                 # Local: 2\\n   class C:\\n       X = 3                # Class local hides nester\\'s: C.X or I.X (not scoped)\\n       print(X)             # Local: 3\\n       def method1(self):\\n           print(X)         # In enclosing def (not 3 in class!): 2\\n           print(self.X)    # Inherited class local: 3\\n       def method2(self):\\n           X = 4            # Hides enclosing (nester, not class)\\n           print(X)         # Local: 4\\n           self.X = 5       # Hides class\\n           print(self.X)    # Located in instance: 5\\n   I = C()\\n   I.method1()\\n   I.method2()\\n\\nprint(X)                    # Global: 1\\nnester()                    # Rest: 2, 3, 2, 3, 4, 5\\nprint(\\'-\\'*40)\\n\\nMost  importantly,  the  lookup  rules  for  simple  names  like  X  never  search  enclosing\\nclass statements—just defs, modules, and built-ins (it’s the LEGB rule, not CLEGB!).\\nIn method1, for example, X is found in a def outside the enclosing class that has the same\\nname in its local scope. To get to names assigned in the class (e.g., methods), we must\\nfetch them as class or instance object attributes, via self.X in this case.\\nBelieve it or not, we’ll see use cases for this nested classes coding pattern later in this\\nbook, especially in some of Chapter 39’s decorators. In this role, the enclosing function\\nusually both serves as a class factory and provides retained state for later use in the\\nenclosed class or its methods.\\n\\nNamespaces: The Conclusion | 877\\n\\n\\x0cNamespace Dictionaries: Review\\nIn Chapter 23, we learned that module namespaces have a concrete implementation as\\ndictionaries, exposed with the built-in __dict__ attribute. In Chapter 27 and Chap-\\nter 28, we learned that the same holds true for class and instance objects—attribute\\nqualification is mostly a dictionary indexing operation internally, and attribute inher-\\nitance is largely a matter of searching linked dictionaries. In fact, within Python, in-\\nstance and class objects are mostly just dictionaries with links between them. Python\\nexposes these dictionaries, as well as their links, for use in advanced roles (e.g., for\\ncoding tools).\\nWe put some of these tools to work in the prior chapter, but to summarize and help\\nyou better understand how attributes work internally, let’s work through an interactive\\nsession that traces the way namespace dictionaries grow when classes are involved.\\nNow that we know more about methods and superclasses, we can also embellish the\\ncoverage here for a better look. First, let’s define a superclass and a subclass with meth-\\nods that will store data in their instances:\\n\\n>>> class Super:\\n        def hello(self):\\n            self.data1 = \\'spam\\'\\n\\n>>> class Sub(Super):\\n        def hola(self):\\n            self.data2 = \\'eggs\\'\\n\\nWhen  we  make  an  instance  of  the  subclass,  the  instance  starts  out  with  an  empty\\nnamespace dictionary, but it has links back to the class for the inheritance search to\\nfollow. In fact, the inheritance tree is explicitly available in special attributes, which\\nyou can inspect. Instances have a __class__ attribute that links to their class, and classes \\nhave a __bases__ attribute that is a tuple containing links to higher superclasses (I’m\\nrunning this on Python 3.3; your name formats, internal attributes, and key orders may\\nvary):\\n\\n>>> X = Sub()\\n>>> X.__dict__                            # Instance namespace dict\\n{}\\n>>> X.__class__                           # Class of instance\\n<class \\'__main__.Sub\\'>\\n>>> Sub.__bases__                         # Superclasses of class\\n(<class \\'__main__.Super\\'>,)\\n>>> Super.__bases__                       # () empty tuple in Python 2.X\\n(<class \\'object\\'>,)\\n\\nAs classes assign to  self attributes, they populate the instance objects—that is, at-\\ntributes wind up in the instances’ attribute namespace dictionaries, not in the classes’.\\nAn instance object’s namespace records data that can vary from instance to instance,\\nand self is a hook into that namespace:\\n\\n>>> Y = Sub()\\n\\n878 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0c>>> X.hello()\\n>>> X.__dict__\\n{\\'data1\\': \\'spam\\'}\\n\\n>>> X.hola()\\n>>> X.__dict__\\n{\\'data2\\': \\'eggs\\', \\'data1\\': \\'spam\\'}\\n\\n>>> list(Sub.__dict__.keys())\\n[\\'__qualname__\\', \\'__module__\\', \\'__doc__\\', \\'hola\\']\\n>>> list(Super.__dict__.keys())\\n[\\'__module__\\', \\'hello\\', \\'__dict__\\', \\'__qualname__\\', \\'__doc__\\', \\'__weakref__\\']\\n\\n>>> Y.__dict__\\n{}\\n\\nNotice the extra underscore names in the class dictionaries; Python sets these auto-\\nmatically, and we can filter them out with the generator expressions we saw in Chap-\\nter 27 and Chapter 28 that we won’t repeat here. Most are not used in typical programs,\\nbut there are tools that use some of them (e.g., __doc__ holds the docstrings discussed\\nin Chapter 15).\\nAlso, observe that Y, a second instance made at the start of this series, still has an empty\\nnamespace dictionary at the end, even though X’s dictionary has been populated by\\nassignments in methods. Again, each instance has an independent namespace dictio-\\nnary, which starts out empty and can record completely different attributes than those\\nrecorded by the namespace dictionaries of other instances of the same class.\\nBecause attributes are actually dictionary keys inside Python, there are really two ways\\nto fetch and assign their values—by qualification, or by key indexing:\\n\\n>>> X.data1, X.__dict__[\\'data1\\']\\n(\\'spam\\', \\'spam\\')\\n\\n>>> X.data3 = \\'toast\\'\\n>>> X.__dict__\\n{\\'data2\\': \\'eggs\\', \\'data3\\': \\'toast\\', \\'data1\\': \\'spam\\'}\\n\\n>>> X.__dict__[\\'data3\\'] = \\'ham\\'\\n>>> X.data3\\n\\'ham\\'\\n\\nThis equivalence applies only to attributes actually attached to the instance, though.\\nBecause attribute fetch qualification also performs an inheritance search, it can access\\ninherited attributes that namespace dictionary indexing cannot. The inherited attribute\\nX.hello, for instance, cannot be accessed by X.__dict__[\\'hello\\'].\\nExperiment with these special attributes on your own to get a better feel for how name-\\nspaces actually do their attribute business. Also try running these objects through the\\ndir \\nto\\nX.__dict__.keys(), but dir sorts its list and includes some inherited and built-in at-\\n\\ntwo  chapters—dir(X) \\n\\nis  similar \\n\\nfunction  we  met \\n\\nin \\n\\nthe  prior \\n\\nNamespaces: The Conclusion | 879\\n\\n\\x0ctributes. Even if you will never use these in the kinds of programs you write, seeing that\\nthey are just normal dictionaries can help solidify namespaces in general.\\n\\nIn Chapter 32, we’ll learn also about slots, a somewhat advanced new-\\nstyle class feature that stores attributes in instances, but not in their\\nnamespace dictionaries. It’s tempting to treat these as class attributes,\\nand indeed, they appear in class namespaces where they manage the\\nper-instance values. As we’ll see, though, slots may prevent a __dict__\\nfrom  being  created  in  the  instance  entirely—a  potential  that  generic\\ntools must sometimes account for by using storage-neutral tools such\\nas dir and getattr.\\n\\nNamespace Links: A Tree Climber\\nThe prior section demonstrated the special __class__ and __bases__ instance and class\\nattributes, without really explaining why you might care about them. In short, these\\nattributes allow you to inspect inheritance hierarchies within your own code. For ex-\\nample, they can be used to display a class tree, as in the following Python 3.X and 2.X\\nexample:\\n\\n#!python\\n\"\"\"\\nclasstree.py: Climb inheritance trees using namespace links,\\ndisplaying higher superclasses with indentation for height\\n\"\"\"\\n\\ndef classtree(cls, indent):\\n    print(\\'.\\' * indent + cls.__name__)    # Print class name here\\n    for supercls in cls.__bases__:        # Recur to all superclasses\\n        classtree(supercls, indent+3)     # May visit super > once\\n\\ndef instancetree(inst):\\n    print(\\'Tree of %s\\' % inst)            # Show instance\\n    classtree(inst.__class__, 3)          # Climb to its class\\n\\ndef selftest():\\n    class A:      pass\\n    class B(A):   pass\\n    class C(A):   pass\\n    class D(B,C): pass\\n    class E:      pass\\n    class F(D,E): pass\\n    instancetree(B())\\n    instancetree(F())\\n\\nif __name__ == \\'__main__\\': selftest()\\n\\nThe  classtree  function  in  this  script  is  recursive—it  prints  a  class’s  name  using\\n__name__, then climbs up to the superclasses by calling itself. This allows the function\\nto traverse arbitrarily shaped class trees; the recursion climbs to the top, and stops at\\n\\n880 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0croot superclasses that have empty __bases__ attributes. When using recursion, each\\nactive level of a function gets its own copy of the local scope; here, this means that\\ncls and indent are different at each classtree level.\\nMost of this file is self-test code. When run standalone in Python 2.X, it builds an empty\\nclass tree, makes two instances from it, and prints their class tree structures:\\n\\nC:\\\\code> c:\\\\python27\\\\python classtree.py\\nTree of <__main__.B instance at 0x00000000022C3A88>\\n...B\\n......A\\nTree of <__main__.F instance at 0x00000000022C3A88>\\n...F\\n......D\\n.........B\\n............A\\n.........C\\n............A\\n......E\\n\\nWhen run by Python 3.X, the tree includes the implied object superclass that is auto-\\nmatically added above standalone root (i.e., topmost) classes, because all classes are\\n“new style” in 3.X—more on this change in Chapter 32:\\n\\nC:\\\\code> c:\\\\python33\\\\python classtree.py\\nTree of <__main__.selftest.<locals>.B object at 0x00000000029216A0>\\n...B\\n......A\\n.........object\\nTree of <__main__.selftest.<locals>.F object at 0x00000000029216A0>\\n...F\\n......D\\n.........B\\n............A\\n...............object\\n.........C\\n............A\\n...............object\\n......E\\n.........object\\n\\nHere, indentation marked by periods is used to denote class tree height. Of course, we\\ncould improve on this output format, and perhaps even sketch it in a GUI display. Even\\nas is, though, we can import these functions anywhere we want a quick display of a\\nphysical class tree:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> class Emp: pass\\n\\n>>> class Person(Emp): pass\\n\\n>>> bob = Person()\\n\\n>>> import classtree\\n>>> classtree.instancetree(bob)\\n\\nNamespaces: The Conclusion | 881\\n\\n\\x0cTree of <__main__.Person object at 0x000000000298B6D8>\\n...Person\\n......Emp\\n.........object\\n\\nRegardless of whether you will ever code or use such tools, this example demonstrates\\none of the many ways that you can make use of special attributes that expose interpreter\\ninternals. You’ll see another when we code the lister.py general-purpose class display\\ntools in Chapter 31’s section “Multiple Inheritance: “Mix-in” Classes” on page 956\\n—there, we will extend this technique to also display attributes in each object in a class\\ntree and function as a common superclass.\\nIn the last part of this book, we’ll revisit such tools in the context of Python tool building\\nat large, to code tools that implement attribute privacy, argument validation, and more.\\nWhile not in every Python programmer’s job description, access to internals enables\\npowerful development tools.\\n\\nDocumentation Strings Revisited\\nThe last section’s example includes a docstring for its module, but remember that doc-\\nstrings can be used for class components as well. Docstrings, which we covered in detail\\nin Chapter 15, are string literals that show up at the top of various structures and are\\nautomatically saved by Python in the corresponding objects’ __doc__ attributes. This\\nworks for module files, function defs, and classes and methods.\\nNow that we know more about classes and methods, the following file, docstr.py, pro-\\nvides a quick but comprehensive example that summarizes the places where docstrings\\ncan show up in your code. All of these can be triple-quoted blocks or simpler one-liner\\nliterals like those here:\\n\\n\"I am: docstr.__doc__\"\\n\\ndef func(args):\\n    \"I am: docstr.func.__doc__\"\\n    pass\\n\\nclass spam:\\n    \"I am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__\"\\n    def method(self):\\n        \"I am: spam.method.__doc__ or self.method.__doc__\"\\n        print(self.__doc__)\\n        print(self.method.__doc__)\\n\\nThe main advantage of documentation strings is that they stick around at runtime.\\nThus, if it’s been coded as a docstring, you can qualify an object with its __doc__ at-\\ntribute to fetch its documentation (printing the result interprets line breaks if it’s a\\nmultiline string):\\n\\n>>> import docstr\\n>>> docstr.__doc__\\n\\n882 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0c\\'I am: docstr.__doc__\\'\\n>>> docstr.func.__doc__\\n\\'I am: docstr.func.__doc__\\'\\n>>> docstr.spam.__doc__\\n\\'I am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__\\'\\n>>> docstr.spam.method.__doc__\\n\\'I am: spam.method.__doc__ or self.method.__doc__\\'\\n\\n>>> x = docstr.spam()\\n>>> x.method()\\nI am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__\\nI am: spam.method.__doc__ or self.method.__doc__\\n\\nA discussion of the PyDoc tool, which knows how to format all these strings in reports\\nand web pages, appears in Chapter 15. Here it is running its help function on our code\\nunder Python 2.X (Python 3.X shows additional attributes inherited from the implied\\nobject superclass in the new-style class model—run this on your own to see the 3.X\\nextras, and watch for more about this difference in Chapter 32):\\n\\n>>> help(docstr)\\nHelp on module docstr:\\n\\nNAME\\n    docstr - I am: docstr.__doc__\\n\\nFILE\\n    c:\\\\code\\\\docstr.py\\n\\nCLASSES\\n    spam\\n\\n    class spam\\n     |  I am: spam.__doc__ or docstr.spam.__doc__ or self.__doc__\\n     |\\n     |  Methods defined here:\\n     |\\n     |  method(self)\\n     |      I am: spam.method.__doc__ or self.method.__doc__\\n\\nFUNCTIONS\\n    func(args)\\n        I am: docstr.func.__doc__\\n\\nDocumentation strings are available at runtime, but they are less flexible syntactically\\nthan # comments, which can appear anywhere in a program. Both forms are useful\\ntools, and any program documentation is good (as long as it’s accurate, of course!). As\\nstated before, the Python “best practice” rule of thumb is to use docstrings for func-\\ntional documentation (what your objects do) and hash-mark comments for more mi-\\ncro-level documentation (how arcane bits of code work).\\n\\nDocumentation Strings Revisited | 883\\n\\n\\x0cClasses Versus Modules\\nFinally, let’s wrap up this chapter by briefly comparing the topics of this book’s last\\ntwo parts: modules and classes. Because they’re both about namespaces, the distinction\\ncan be confusing. In short:\\n\\n• Modules\\n\\n— Implement data/logic packages\\n— Are created with Python files or other-language extensions\\n— Are used by being imported\\n— Form the top-level in Python program structure\\n\\n• Classes\\n\\n— Implement new full-featured objects\\n— Are created with class statements\\n— Are used by being called\\n— Always live within a module\\n\\nClasses also support extra features that modules don’t, such as operator overloading,\\nmultiple instance generation, and inheritance. Although both classes and modules are\\nnamespaces, you should be able to tell by now that they are very different things. We\\nneed to move ahead to see just how different classes can be.\\n\\nChapter Summary\\nThis chapter took us on a second, more in-depth tour of the OOP mechanisms of the\\nPython language. We learned more about classes, methods, and inheritance, and we\\nwrapped up the namespaces and scopes story in Python by extending it to cover its\\napplication to classes. Along the way, we looked at some more advanced concepts,\\nsuch as abstract superclasses, class data attributes, namespace dictionaries and links,\\nand manual calls to superclass methods and constructors.\\nNow that we’ve learned all about the mechanics of coding classes in Python, Chap-\\nter 30 turns to a specific facet of those mechanics: operator overloading. After that we’ll\\nexplore common design patterns, looking at some of the ways that classes are com-\\nmonly used and combined to optimize code reuse. Before you read ahead, though, be\\nsure to work through the usual chapter quiz to review what we’ve covered here.\\n\\nTest Your Knowledge: Quiz\\n1. What is an abstract superclass?\\n2. What happens when a simple assignment statement appears at the top level of a\\n\\nclass statement?\\n\\n884 | Chapter 29:\\u2002Class Coding Details\\n\\n\\x0c3. Why might a class need to manually call the __init__ method in a superclass?\\n4. How can you augment, instead of completely replacing, an inherited method?\\n5. How does a class’s local scope differ from that of a function?\\n6. What...was the capital of Assyria?\\n\\nTest Your Knowledge: Answers\\n1. An abstract superclass is a class that calls a method, but does not inherit or define\\nit—it expects the method to be filled in by a subclass. This is often used as a way\\nto generalize classes when behavior cannot be predicted until a more specific sub-\\nclass is coded. OOP frameworks also use this as a way to dispatch to client-defined,\\ncustomizable operations.\\n\\n2. When a simple assignment statement (X = Y) appears at the top level of a class\\nstatement, it attaches a data attribute to the class (Class.X). Like all class attributes,\\nthis will be shared by all instances; data attributes are not callable method func-\\ntions, though.\\n\\n3. A class must manually call the __init__ method in a superclass if it defines an\\n__init__ constructor of its own and still wants the superclass’s construction code\\nto run. Python itself automatically runs just one constructor—the lowest one in\\nthe tree. Superclass constructors are usually called through the class name, passing\\nin the self instance manually: Superclass.__init__(self, ...).\\n\\n4. To augment instead of completely replacing an inherited method, redefine it in a\\nsubclass, but call back to the superclass’s version of the method manually from the\\nnew version of the method in the subclass. That is, pass the self instance to the\\nsuperclass’s version of the method manually: Superclass.method(self, ...).\\n\\n5. A class is a local scope and has access to enclosing local scopes, but it does not\\nserve as an enclosing local scope to further nested code. Like modules, the class\\nlocal scope morphs into an attribute namespace after the class statement is run.\\n6. Ashur (or Qalat Sherqat), Calah (or Nimrud), the short-lived Dur Sharrukin (or\\n\\nKhorsabad), and finally Nineveh.\\n\\nTest Your Knowledge: Answers\\n\\n| 885\\n\\n\\x0c\\x0cCHAPTER 30\\nOperator Overloading\\n\\nThis chapter continues our in-depth survey of class mechanics by focusing on operator\\noverloading. We looked briefly at operator overloading in prior chapters; here, we’ll\\nfill  in  more  details  and  look  at  a  handful  of  commonly  used  overloading  methods.\\nAlthough we won’t demonstrate each of the many operator overloading methods avail-\\nable, those we will code here are a representative sample large enough to uncover the\\npossibilities of this Python class feature.\\n\\nThe Basics\\nReally “operator overloading” simply means intercepting built-in operations in a class’s\\nmethods—Python automatically invokes your methods when instances of the class\\nappear in built-in operations, and your method’s return value becomes the result of the\\ncorresponding operation. Here’s a review of the key ideas behind overloading:\\n\\n• Operator overloading lets classes intercept normal Python operations.\\n• Classes can overload all Python expression operators.\\n• Classes can also overload built-in operations such as printing, function calls, at-\\n\\ntribute access, etc.\\n\\n• Overloading makes class instances act more like built-in types.\\n• Overloading is implemented by providing specially named methods in a class.\\n\\nIn other words, when certain specially named methods are provided in a class, Python\\nautomatically calls them when instances of the class appear in their associated expres-\\nsions. Your class provides the behavior of the corresponding operation for instance\\nobjects created from it.\\nAs we’ve learned, operator overloading methods are never required and generally don’t\\nhave defaults (apart from a handful that some classes get from object); if you don’t\\ncode or inherit one, it just means that your class does not support the corresponding\\noperation. When used, though, these methods allow classes to emulate the interfaces\\nof built-in objects, and so appear more consistent.\\n\\n887\\n\\n\\x0cConstructors and Expressions: __init__ and __sub__\\nAs a review, consider the following simple example: its Number class, coded in the file\\nnumber.py, provides a method to intercept instance construction (__init__), as well as\\none for catching subtraction expressions (__sub__). Special methods such as these are\\nthe hooks that let you tie into built-in operations:\\n\\n# File number.py\\n\\nclass Number:\\n    def __init__(self, start):                  # On Number(start)\\n        self.data = start\\n    def __sub__(self, other):                   # On instance - other\\n        return Number(self.data - other)        # Result is a new instance\\n\\n>>> from number import Number                   # Fetch class from module\\n>>> X = Number(5)                               # Number.__init__(X, 5)\\n>>> Y = X - 2                                   # Number.__sub__(X, 2)\\n>>> Y.data                                      # Y is new Number instance\\n3\\n\\nAs we’ve already learned, the __init__ constructor method seen in this code is the most\\ncommonly used operator overloading method in Python; it’s present in most classes,\\nand used to initialize the newly created instance object using any arguments passed to\\nthe class name. The __sub__ method plays the binary operator role that __add__ did in\\nChapter 27’s introduction, intercepting subtraction expressions and returning a new\\ninstance of the class as its result (and running __init__ along the way).\\nWe’ve already studied __init__ and basic binary operators like __sub__ in some depth,\\nso we won’t rehash their usage further here. In this chapter, we will tour some of the\\nother tools available in this domain and look at example code that applies them in\\ncommon use cases.\\n\\nTechnically, instance creation first triggers the __new__ method, which\\ncreates and returns the new instance object, which is then passed into\\n__init__ for initialization. Since __new__ has a built-in implementation\\nand is redefined in only very limited roles, though, nearly all Python\\nclasses initialize by defining an __init__ method. We’ll see one use case\\nfor __new__ when we study metaclasses in Chapter 40; though rare, it is\\nsometimes  also  used  to  customize  creation  of  instances  of  mutable\\ntypes.\\n\\nCommon Operator Overloading Methods\\nJust about everything you can do to built-in objects such as integers and lists has a\\ncorresponding specially named method for overloading in classes. Table 30-1 lists a\\nfew of the most common; there are many more. In fact, many overloading methods\\ncome in multiple versions (e.g., __add__, __radd__, and __iadd__ for addition), which\\n\\n888 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cis one reason there are so many. See other Python books, or the Python language ref-\\nerence manual, for an exhaustive list of the special method names available.\\n\\nTable 30-1. Common operator overloading methods\\n\\nMethod\\n__init__\\n\\n__del__\\n\\n__add__\\n\\n__or__\\n__repr__, __str__\\n__call__\\n\\n__getattr__\\n\\n__setattr__\\n\\n__delattr__\\n\\n__getattribute__\\n\\n__getitem__\\n\\n__setitem__\\n\\n__delitem__\\n\\n__len__\\n\\n__bool__\\n__lt__, __gt__,\\n__le__, __ge__,\\n__eq__, __ne__\\n__radd__\\n\\n__iadd__\\n__iter__, __next__\\n\\nImplements\\nConstructor\\nDestructor\\nOperator +\\nOperator | (bitwise OR)\\nPrinting, conversions\\nFunction calls\\nAttribute fetch\\nAttribute assignment\\nAttribute deletion\\nAttribute fetch\\nIndexing, slicing, iteration\\n\\nIndex and slice assignment\\nIndex and slice deletion\\nLength\\nBoolean tests\\nComparisons\\n\\nRight-side operators\\nIn-place augmented operators\\nIteration contexts\\n\\n__contains__\\n\\n__index__\\n\\nMembership test\\nInteger value\\n\\n__enter__, __exit__\\n__get__, __set__,\\n__delete__\\n\\nContext manager (Chapter 34)\\nDescriptor attributes (Chapter 38)\\n\\nCalled for\\nObject creation: X = Class(args)\\nObject reclamation of X\\nX + Y, X += Y if no __iadd__\\nX | Y, X |= Y if no __ior__\\nprint(X), repr(X), str(X)\\nX(*args, **kargs)\\n\\nX.undefined\\n\\nX.any = value\\n\\ndel X.any\\n\\nX.any\\nX[key], X[i:j], for loops and other iterations if no\\n__iter__\\nX[key] = value, X[i:j] = iterable\\ndel X[key], del X[i:j]\\nlen(X), truth tests if no __bool__\\nbool(X), truth tests (named __nonzero__ in 2.X)\\nX < Y, X > Y, X <= Y, X >= Y, X == Y, X != Y\\n(or else __cmp__ in 2.X only)\\n\\nOther + X\\nX += Y (or else __add__)\\nI=iter(X), next(I); for loops, in if no __con\\ntains__, all comprehensions, map(F,X), others\\n(__next__ is named next in 2.X)\\nitem in X (any iterable)\\nhex(X), bin(X), oct(X), O[X], O[X:] (replaces 2.X\\n__oct__, __hex__)\\nwith obj as var:\\n\\nX.attr, X.attr = value, del X.attr\\n\\n__new__\\n\\nCreation (Chapter 40)\\n\\nObject creation, before __init__\\n\\nAll overloading methods have names that start and end with two underscores to keep\\nthem distinct from other names you define in your classes. The mappings from special\\n\\nThe Basics\\n\\n| 889\\n\\n\\x0cmethod names to expressions or operations are predefined by the Python language,\\nand documented in full in the standard language manual and other reference resources.\\nFor example, the name __add__ always maps to + expressions by Python language def-\\ninition, regardless of what an __add__ method’s code actually does.\\nOperator overloading methods may be inherited from superclasses if not defined, just\\nlike any other methods. Operator overloading methods are also all optional—if you\\ndon’t code or inherit one, that operation is simply unsupported by your class, and\\nattempting it will raise an exception. Some built-in operations, like printing, have de-\\nfaults (inherited from the implied object class in Python 3.X), but most built-ins fail\\nfor class instances if no corresponding operator overloading method is present.\\nMost overloading methods are used only in advanced programs that require objects to\\nbehave like built-ins, though the __init__ constructor we’ve already met tends to ap-\\npear in most classes. Let’s explore some of the additional methods in Table 30-1 by\\nexample.\\n\\nAlthough expressions trigger operator methods, be careful not to as-\\nsume that there is a speed advantage to cutting out the middleman and\\ncalling the operator method directly. In fact, calling the operator method\\ndirectly might be twice as slow, presumably because of the overhead of\\na function call, which Python avoids or optimizes in built-in cases.\\n\\nHere’s  the  story  for  len  and  __len__  using  Appendix  B’s  Windows\\nlauncher and Chapter 21’s timing techniques on Python 3.3 and 2.7: in\\nboth, calling __len__ directly takes twice as long:\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 5\\n                  -s \"L = list(range(100))\" \"x = L.__len__()\"\\n1000 loops, best of 5: 0.134 usec per loop\\n\\nc:\\\\code> py −3 -m timeit -n 1000 -r 5\\n                  -s \"L = list(range(100))\" \"x = len(L)\"\\n1000 loops, best of 5: 0.063 usec per loop\\n\\nc:\\\\code> py −2 -m timeit -n 1000 -r 5\\n                  -s \"L = list(range(100))\" \"x = L.__len__()\"\\n1000 loops, best of 5: 0.117 usec per loop\\n\\nc:\\\\code> py −2 -m timeit -n 1000 -r 5\\n                  -s \"L = list(range(100))\" \"x = len(L)\"\\n1000 loops, best of 5: 0.0596 usec per loop\\n\\nThis is not as artificial as it may seem—I’ve actually come across rec-\\nommendations for using the slower alternative in the name of speed at\\na noted research institution!\\n\\nIndexing and Slicing: __getitem__ and __setitem__\\nOur first method set allows your classes to mimic some of the behaviors of sequences\\nand mappings. If defined in a class (or inherited by it), the __getitem__ method is called\\n\\n890 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cautomatically for instance-indexing operations. When an instance X appears in an in-\\ndexing expression like X[i], Python calls the __getitem__ method inherited by the in-\\nstance, passing X to the first argument and the index in brackets to the second argument.\\nFor example, the following class returns the square of an index value—atypical perhaps,\\nbut illustrative of the mechanism in general:\\n\\n>>> class Indexer:\\n        def __getitem__(self, index):\\n            return index ** 2\\n\\n>>> X = Indexer()\\n>>> X[2]                                # X[i] calls X.__getitem__(i)\\n4\\n\\n>>> for i in range(5):\\n        print(X[i], end=\\' \\')            # Runs __getitem__(X, i) each time\\n\\n0 1 4 9 16\\n\\nIntercepting Slices\\nInterestingly, in addition to indexing, __getitem__ is also called for slice expressions—\\nalways in 3.X, and conditionally in 2.X if you don’t provide more specific slicing meth-\\nods. Formally speaking, built-in types handle slicing the same way. Here, for example,\\nis slicing at work on a built-in list, using upper and lower bounds and a stride (see\\nChapter 7 if you need a refresher on slicing):\\n\\n>>> L = [5, 6, 7, 8, 9]\\n>>> L[2:4]                              # Slice with slice syntax: 2..(4-1)\\n[7, 8]\\n>>> L[1:]\\n[6, 7, 8, 9]\\n>>> L[:-1]\\n[5, 6, 7, 8]\\n>>> L[::2]\\n[5, 7, 9]\\n\\nReally, though, slicing bounds are bundled up into a slice object and passed to the list’s\\nimplementation of indexing. In fact, you can always pass a slice object manually—slice\\nsyntax is mostly syntactic sugar for indexing with a slice object:\\n\\n>>> L[slice(2, 4)]                      # Slice with slice objects\\n[7, 8]\\n>>> L[slice(1, None)]\\n[6, 7, 8, 9]\\n>>> L[slice(None, −1)]\\n[5, 6, 7, 8]\\n>>> L[slice(None, None, 2)]\\n[5, 7, 9]\\n\\nThis matters in classes with a __getitem__ method—in 3.X, the method will be called\\nboth for basic indexing (with an index) and for slicing (with a slice object). Our previous\\n\\nIndexing and Slicing: __getitem__ and __setitem__ | 891\\n\\n\\x0cclass won’t handle slicing because its math assumes integer indexes are passed, but the\\nfollowing class will. When called for indexing, the argument is an integer as before:\\n\\n>>> class Indexer:\\n        data = [5, 6, 7, 8, 9]\\n        def __getitem__(self, index):   # Called for index or slice\\n            print(\\'getitem:\\', index)\\n            return self.data[index]     # Perform index or slice\\n\\n>>> X = Indexer()\\n>>> X[0]                                # Indexing sends __getitem__ an integer\\ngetitem: 0\\n5\\n>>> X[1]\\ngetitem: 1\\n6\\n>>> X[-1]\\ngetitem: −1\\n9\\n\\nWhen called for slicing, though, the method receives a slice object, which is simply\\npassed along to the embedded list indexer in a new index expression:\\n\\n>>> X[2:4]                              # Slicing sends __getitem__ a slice object\\ngetitem: slice(2, 4, None)\\n[7, 8]\\n>>> X[1:]\\ngetitem: slice(1, None, None)\\n[6, 7, 8, 9]\\n>>> X[:-1]\\ngetitem: slice(None, −1, None)\\n[5, 6, 7, 8]\\n>>> X[::2]\\ngetitem: slice(None, None, 2)\\n[5, 7, 9]\\n\\nWhere needed, __getitem__ can test the type of its argument, and extract slice object\\nbounds—slice objects have attributes start, stop, and step, any of which can be None\\nif omitted:\\n\\n>>> class Indexer:\\n        def __getitem__(self, index):\\n            if isinstance(index, int):               # Test usage mode\\n                print(\\'indexing\\', index)\\n            else:\\n                print(\\'slicing\\', index.start, index.stop, index.step)\\n\\n>>> X = Indexer()\\n>>> X[99]\\nindexing 99\\n>>> X[1:99:2]\\nslicing 1 99 2\\n>>> X[1:]\\nslicing 1 None None\\n\\n892 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cIf used, the __setitem__ index assignment method similarly intercepts both index and\\nslice assignments—in 3.X (and usually in 2.X) it receives a slice object for the latter,\\nwhich may be passed along in another index assignment or used directly in the same\\nway:\\n\\nclass IndexSetter:\\n    def __setitem__(self, index, value):    # Intercept index or slice assignment\\n        ...\\n        self.data[index] = value            # Assign index or slice\\n\\nIn fact, __getitem__ may be called automatically in even more contexts than indexing\\nand  slicing—it’s  also  an  iteration  fallback  option,  as  we’ll  see  in  a  moment.  First,\\nthough, let’s take a quick look at 2.X’s flavor of these operations for 2.X readers, and\\nclarify a potential point of confusion in this category.\\n\\nSlicing and Indexing in Python 2.X\\nIn Python 2.X only, classes can also define __getslice__ and __setslice__ methods to\\nintercept slice fetches and assignments specifically. If defined, these methods are passed\\nthe  bounds  of  the  slice  expression,  and  are  preferred  over  __getitem__  and  __seti\\ntem__ for two-limit slices. In all other cases, though, this context works the same as in\\n3.X; for example, a slice object is still created and passed to __getitem__ if no __get\\nslice__ is found or a three-limit extended slice form is used:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> class Slicer:\\n        def __getitem__(self, index):     print index\\n        def __getslice__(self, i, j):     print i, j\\n        def __setslice__(self, i, j,seq): print i, j,seq\\n\\n>>> Slicer()[1]        # Runs __getitem__ with int, like 3.X\\n1\\n>>> Slicer()[1:9]      # Runs __getslice__ if present, else __getitem__\\n1 9\\n>>> Slicer()[1:9:2]    # Runs __getitem__ with slice(), like 3.X!\\nslice(1, 9, 2)\\n\\nThese slice-specific methods are removed in 3.X, so even in 2.X you should generally\\nuse __getitem__ and __setitem__ instead and allow for both indexes and slice objects\\nas arguments—both for forward compatibility, and to avoid having to handle two- and\\nthree-limit slices differently. In most classes, this works without any special code, be-\\ncause indexing methods can manually pass along the slice object in the square brackets\\nof another index expression, as in the prior section’s example. See the section “Mem-\\nbership: __contains__, __iter__, and __getitem__” on page 906 for another example\\nof slice interception at work.\\n\\nIndexing and Slicing: __getitem__ and __setitem__ | 893\\n\\n\\x0cBut 3.X’s __index__ Is Not Indexing!\\nOn a related note, don’t confuse the (perhaps unfortunately named) __index__ method\\nin Python 3.X for index interception—this method returns an integer value for an in-\\nstance when needed and is used by built-ins that convert to digit strings (and in retro-\\nspect, might have been better named __asindex__):\\n\\n>>> class C:\\n        def __index__(self):\\n            return 255\\n\\n>>> X = C()\\n>>> hex(X)               # Integer value\\n\\'0xff\\'\\n>>> bin(X)\\n\\'0b11111111\\'\\n>>> oct(X)\\n\\'0o377\\'\\n\\nAlthough this method does not intercept instance indexing like __getitem__, it is also\\nused in contexts that require an integer—including indexing:\\n\\n>>> (\\'C\\' * 256)[255]\\n\\'C\\'\\n>>> (\\'C\\' * 256)[X]       # As index (not X[i])\\n\\'C\\'\\n>>> (\\'C\\' * 256)[X:]      # As index (not X[i:])\\n\\'C\\'\\n\\nThis method works the same way in Python 2.X, except that it is not called for the\\nhex and oct built-in functions; use __hex__ and __oct__ in 2.X (only) instead to intercept\\nthese calls.\\n\\nIndex Iteration: __getitem__\\nHere’s a hook that isn’t always obvious to beginners, but turns out to be surprisingly\\nuseful. In the absence of more-specific iteration methods we’ll get to in the next section,\\nthe for statement works by repeatedly indexing a sequence from zero to higher indexes,\\nuntil  an  out-of-bounds  IndexError  exception  is  detected.  Because  of  that,  __geti\\ntem__ also turns out to be one way to overload iteration in Python—if this method is\\ndefined, for loops call the class’s  __getitem__ each time through, with successively\\nhigher offsets.\\nIt’s a case of “code one, get one free”—any built-in or user-defined object that responds\\nto indexing also responds to for loop iteration:\\n\\n>>> class StepperIndex:\\n        def __getitem__(self, i):\\n            return self.data[i]\\n\\n>>> X = StepperIndex()                # X is a StepperIndex object\\n>>> X.data = \"Spam\"\\n\\n894 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0c>>>\\n>>> X[1]                              # Indexing calls __getitem__\\n\\'p\\'\\n>>> for item in X:                    # for loops call __getitem__\\n        print(item, end=\\' \\')          # for indexes items 0..N\\n\\nS p a m\\n\\nIn fact, it’s really a case of “code one, get a bunch free.” Any class that supports for\\nloops automatically supports all iteration contexts in Python, many of which we’ve seen\\nin earlier chapters (iteration contexts were presented in Chapter 14). For example, the\\nin membership test, list comprehensions, the map built-in, list and tuple assignments,\\nand type constructors will also call __getitem__ automatically, if it’s defined:\\n\\n>>> \\'p\\' in X                          # All call __getitem__ too\\nTrue\\n\\n>>> [c for c in X]                    # List comprehension\\n[\\'S\\', \\'p\\', \\'a\\', \\'m\\']\\n\\n>>> list(map(str.upper, X))           # map calls (use list() in 3.X)\\n[\\'S\\', \\'P\\', \\'A\\', \\'M\\']\\n\\n>>> (a, b, c, d) = X                  # Sequence assignments\\n>>> a, c, d\\n(\\'S\\', \\'a\\', \\'m\\')\\n\\n>>> list(X), tuple(X), \\'\\'.join(X)     # And so on...\\n([\\'S\\', \\'p\\', \\'a\\', \\'m\\'], (\\'S\\', \\'p\\', \\'a\\', \\'m\\'), \\'Spam\\')\\n\\n>>> X\\n<__main__.StepperIndex object at 0x000000000297B630>\\n\\nIn practice, this technique can be used to create objects that provide a sequence interface\\nand to add logic to built-in sequence type operations; we’ll revisit this idea when ex-\\ntending built-in types in Chapter 32.\\n\\nIterable Objects: __iter__ and __next__\\nAlthough the __getitem__ technique of the prior section works, it’s really just a fallback\\nfor iteration. Today, all iteration contexts in Python will try the __iter__ method first,\\nbefore trying __getitem__. That is, they prefer the iteration protocol we learned about\\nin Chapter 14 to repeatedly indexing an object; only if the object does not support the\\niteration protocol is indexing attempted instead. Generally speaking, you should prefer\\n__iter__ too—it supports general iteration contexts better than __getitem__ can.\\nTechnically, iteration contexts work by passing an iterable object to the iter built-in\\nfunction to invoke an __iter__ method, which is expected to return an iterator object.\\nIf it’s provided, Python then repeatedly calls this iterator object’s __next__ method to\\nproduce items until a StopIteration exception is raised. A next built-in function is also\\n\\nIterable Objects: __iter__ and __next__ | 895\\n\\n\\x0cavailable  as  a  convenience  for  manual \\nI.__next__(). For a review of this model’s essentials, see Figure 14-1 in Chapter 14.\\nThis  iterable  object  interface  is  given  priority  and  attempted  first.  Only  if  no  such\\n__iter__ method is found, Python falls back on the __getitem__ scheme and repeatedly\\nindexes by offsets as before, until an IndexError exception is raised.\\n\\niterations—next(I) \\n\\nis  the  same  as\\n\\nVersion skew note: As described in Chapter 14, if you are using Python\\n2.X,  the  I.__next__()  iterator  method  just  described  is  named\\nI.next() in your Python, and the next(I) built-in is present for porta-\\nbility—it calls I.next() in 2.X and I.__next__() in 3.X. Iteration works\\nthe same in 2.X in all other respects.\\n\\nUser-Defined Iterables\\nIn  the  __iter__  scheme,  classes  implement  user-defined  iterables  by  simply  imple-\\nmenting  the  iteration  protocol  introduced  in  Chapter  14  and  elaborated  in  Chap-\\nter 20. For example, the following file uses a class to define a user-defined iterable that\\ngenerates squares on demand, instead of all at once (per the preceding note, in Python\\n2.X define next instead of __next__, and print with a trailing comma as usual):\\n\\n# File squares.py\\n\\nclass Squares:\\n    def __init__(self, start, stop):    # Save state when created\\n        self.value = start - 1\\n        self.stop  = stop\\n    def __iter__(self):                 # Get iterator object on iter\\n        return self\\n    def __next__(self):                 # Return a square on each iteration\\n        if self.value == self.stop:     # Also called by next built-in\\n            raise StopIteration\\n        self.value += 1\\n        return self.value ** 2\\n\\nWhen imported, its instances can appear in iteration contexts just like built-ins:\\n\\n% python\\n>>> from squares import Squares\\n>>> for i in Squares(1, 5):             # for calls iter, which calls __iter__\\n        print(i, end=\\' \\')               # Each iteration calls __next__\\n\\n1 4 9 16 25\\n\\nHere, the iterator object returned by __iter__ is simply the instance self, because the\\n__next__ method is part of this class itself. In more complex scenarios, the iterator\\nobject may be defined as a separate class and object with its own state information to\\nsupport multiple active iterations over the same data (we’ll see an example of this in a\\nmoment). The end of the iteration is signaled with a Python raise statement—intro-\\nduced in Chapter 29 and covered in full in the next part of this book, but which simply\\n\\n896 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0craises an exception as if Python itself had done so. Manual iterations work the same on\\nuser-defined iterables as they do on built-in types as well:\\n\\n>>> X = Squares(1, 5)                   # Iterate manually: what loops do\\n>>> I = iter(X)                         # iter calls __iter__\\n>>> next(I)                             # next calls __next__ (in 3.X)\\n1\\n>>> next(I)\\n4\\n...more omitted...\\n>>> next(I)\\n25\\n>>> next(I)                             # Can catch this in try statement\\nStopIteration\\n\\nAn equivalent coding of this iterable with __getitem__ might be less natural, because\\nthe for would then iterate through all offsets zero and higher; the offsets passed in\\nwould be only indirectly related to the range of values produced (0..N would need to\\nmap to start..stop). Because __iter__ objects retain explicitly managed state between\\nnext calls, they can be more general than __getitem__.\\nOn the other hand, iterables based on __iter__ can sometimes be more complex and\\nless functional than those based on __getitem__. They are really designed for iteration,\\nnot  random  indexing—in  fact,  they  don’t  overload  the  indexing  expression  at  all,\\nthough you can collect their items in a sequence such as a list to enable other operations:\\n\\n>>> X = Squares(1, 5)\\n>>> X[1]\\nTypeError: \\'Squares\\' object does not support indexing\\n>>> list(X)[1]\\n4\\n\\nSingle versus multiple scans\\nThe __iter__ scheme is also the implementation for all the other iteration contexts we\\nsaw in action for the __getitem__ method—membership tests, type constructors, se-\\nquence assignment, and so on. Unlike our prior __getitem__ example, though, we also\\nneed to be aware that a class’s __iter__ may be designed for a single traversal only, not\\nmany. Classes choose scan behavior explicitly in their code.\\nFor example, because the current Squares class’s __iter__ always returns self with just\\none copy of iteration state, it is a one-shot iteration; once you’ve iterated over an in-\\nstance of that class, it’s empty. Calling __iter__ again on the same instance returns\\nself again, in whatever state it may have been left. You generally need to make a new\\niterable instance object for each new iteration:\\n\\n>>> X = Squares(1, 5)                   # Make an iterable with state\\n>>> [n for n in X]                      # Exhausts items: __iter__ returns self\\n[1, 4, 9, 16, 25]\\n>>> [n for n in X]                      # Now it\\'s empty: __iter__ returns same self\\n[]\\n\\nIterable Objects: __iter__ and __next__ | 897\\n\\n\\x0c>>> [n for n in Squares(1, 5)]          # Make a new iterable object\\n[1, 4, 9, 16, 25]\\n>>> list(Squares(1, 3))                 # A new object for each new __iter__ call\\n[1, 4, 9]\\n\\nTo support multiple iterations more directly, we could also recode this example with\\nan extra class or other technique, as we will in a moment. As is, though, by creating a\\nnew instance for each iteration, you get a fresh copy of iteration state:\\n\\n>>> 36 in Squares(1, 10)                # Other iteration contexts\\nTrue\\n>>> a, b, c = Squares(1, 3)             # Each calls __iter__ and then __next__\\n>>> a, b, c\\n(1, 4, 9)\\n>>> \\':\\'.join(map(str, Squares(1, 5)))\\n\\'1:4:9:16:25\\'\\n\\nJust like single-scan built-ins such as map, converting to a list supports multiple scans\\nas well, but adds time and space performance costs, which may or may not be significant\\nto a given program:\\n\\n>>> X = Squares(1, 5)\\n>>> tuple(X), tuple(X)                  # Iterator exhausted in second tuple()\\n((1, 4, 9, 16, 25), ())\\n\\n>>> X = list(Squares(1, 5))\\n>>> tuple(X), tuple(X)\\n((1, 4, 9, 16, 25), (1, 4, 9, 16, 25))\\n\\nWe’ll improve this to support multiple scans more directly ahead, after a bit of compare-\\nand-contrast.\\n\\nClasses versus generators\\nNotice that the preceding example would probably be simpler if it was coded with\\ngenerator functions or expressions—tools introduced in Chapter 20 that automatically\\nproduce iterable objects and retain local variable state between iterations:\\n\\n>>> def gsquares(start, stop):\\n        for i in range(start, stop + 1):\\n            yield i ** 2\\n\\n>>> for i in gsquares(1, 5):\\n        print(i, end=\\' \\')\\n\\n1 4 9 16 25\\n\\n>>> for i in (x ** 2 for x in range(1, 6)):\\n        print(i, end=\\' \\')\\n\\n1 4 9 16 25\\n\\nUnlike classes, generator functions and expressions implicitly save their state and create\\nthe methods required to conform to the iteration protocol—with obvious advantages\\n\\n898 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cin code conciseness for simpler examples like these. On the other hand, the class’s more\\nexplicit attributes and methods, extra structure, inheritance hierarchies, and support\\nfor multiple behaviors may be better suited for richer use cases.\\nOf course, for this artificial example, you could in fact skip both techniques and simply\\nuse a for loop, map, or a list comprehension to build the list all at once. Barring perfor-\\nmance data to the contrary, the best and fastest way to accomplish a task in Python is\\noften also the simplest:\\n\\n>>> [x ** 2 for x in range(1, 6)]\\n[1, 4, 9, 16, 25]\\n\\nHowever, classes may be better at modeling more complex iterations, especially when\\nthey can benefit from the assets of classes in general. An iterable that produces items\\nin a complex database or web service result, for example, might be able to take fuller\\nadvantage of classes. The next section explores another use case for classes in user-\\ndefined iterables.\\n\\nMultiple Iterators on One Object\\nEarlier, I mentioned that the iterator object (with a __next__) produced by an iterable\\nmay  be  defined  as  a  separate  class  with  its  own  state  information  to  more  directly\\nsupport multiple active iterations over the same data. Consider what happens when\\nwe step across a built-in type like a string:\\n\\n>>> S = \\'ace\\'\\n>>> for x in S:\\n        for y in S:\\n            print(x + y, end=\\' \\')\\n\\naa ac ae ca cc ce ea ec ee\\n\\nHere, the outer loop grabs an iterator from the string by calling iter, and each nested\\nloop does the same to get an independent iterator. Because each active iterator has its\\nown state information, each loop can maintain its own position in the string, regardless\\nof any other active loops. Moreover, we’re not required to make a new string or convert\\nto a list each time; the single string object itself supports multiple scans.\\nWe saw related examples earlier, in Chapter 14 and Chapter 20. For instance, generator\\nfunctions and expressions, as well as built-ins like map and zip, proved to be single-\\niterator objects, thus supporting a single active scan. By contrast, the range built-in,\\nand other built-in types like lists, support multiple active iterators with independent\\npositions.\\nWhen we code user-defined iterables with classes, it’s up to us to decide whether we\\nwill support a single active iteration or many. To achieve the multiple-iterator effect,\\n__iter__ simply needs to define a new stateful object for the iterator, instead of re-\\nturning self for each iterator request.\\n\\nIterable Objects: __iter__ and __next__ | 899\\n\\n\\x0cThe following SkipObject class, for example, defines an iterable object that skips every\\nother item on iterations. Because its iterator object is created anew from a supplemental\\nclass  for  each  iteration,  it  supports  multiple  active  loops  directly  (this  is  file  skip-\\nper.py in the book’s examples):\\n\\n#!python3\\n# File skipper.py\\n\\nclass SkipObject:\\n    def __init__(self, wrapped):                  # Save item to be used\\n        self.wrapped = wrapped\\n    def __iter__(self):\\n        return SkipIterator(self.wrapped)         # New iterator each time\\n\\nclass SkipIterator:\\n    def __init__(self, wrapped):\\n        self.wrapped = wrapped                    # Iterator state information\\n        self.offset  = 0\\n    def __next__(self):\\n        if self.offset >= len(self.wrapped):      # Terminate iterations\\n            raise StopIteration\\n        else:\\n            item = self.wrapped[self.offset]      # else return and skip\\n            self.offset += 2\\n            return item\\n\\nif __name__ == \\'__main__\\':\\n    alpha = \\'abcdef\\'\\n    skipper = SkipObject(alpha)                   # Make container object\\n    I = iter(skipper)                             # Make an iterator on it\\n    print(next(I), next(I), next(I))              # Visit offsets 0, 2, 4\\n\\n    for x in skipper:               # for calls __iter__ automatically\\n        for y in skipper:           # Nested fors call __iter__ again each time\\n            print(x + y, end=\\' \\')   # Each iterator has its own state, offset\\n\\nA quick portability note: as is, this is 3.X-only code. To make it 2.X compatible, import\\nthe 3.X print function, and either use next instead of __next__ for 2.X-only use, or alias\\nthe two names in the class’s scope for dual 2.X/3.X usage (file skipper_2x.py in the\\nbook’s examples does):\\n\\n#!python\\nfrom __future__ import print_function             # 2.X/3.X compatibility\\n...\\nclass SkipIterator:\\n    ...\\n    def __next__(self):\\n        ...\\n    next = __next__                               # 2.X/3.X compatibility\\n\\nWhen the appropriate version is run in either Python, this example works like the nested\\nloops with built-in strings. Each active loop has its own position in the string because\\neach obtains an independent iterator object that records its own state information:\\n\\n900 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0c% python skipper.py\\na c e\\naa ac ae ca cc ce ea ec ee\\n\\nBy contrast, our earlier Squares example supports just one active iteration, unless we\\ncall Squares again in nested loops to obtain new objects. Here, there is just one SkipOb\\nject iterable, with multiple iterator objects created from it.\\n\\nClasses versus slices\\nAs before, we could achieve similar results with built-in tools—for example, slicing\\nwith a third bound to skip items:\\n\\n>>> S = \\'abcdef\\'\\n>>> for x in S[::2]:\\n        for y in S[::2]:            # New objects on each iteration\\n            print(x + y, end=\\' \\')\\n\\naa ac ae ca cc ce ea ec ee\\n\\nThis isn’t quite the same, though, for two reasons. First, each slice expression here will\\nphysically store the result list all at once in memory; iterables, on the other hand, pro-\\nduce just one value at a time, which can save substantial space for large result lists.\\nSecond, slices produce new objects, so we’re not really iterating over the same object in\\nmultiple places here. To be closer to the class, we would need to make a single object\\nto step across by slicing ahead of time:\\n\\n>>> S = \\'abcdef\\'\\n>>> S = S[::2]\\n>>> S\\n\\'ace\\'\\n>>> for x in S:\\n        for y in S:                 # Same object, new iterators\\n            print(x + y, end=\\' \\')\\n\\naa ac ae ca cc ce ea ec ee\\n\\nThis is more similar to our class-based solution, but it still stores the slice result in\\nmemory all at once (there is no generator form of built-in slicing today), and it’s only\\nequivalent for this particular case of skipping every other item.\\nBecause user-defined iterables coded with classes can do anything a class can do, they\\nare much more general than this example may imply. Though such generality is not\\nrequired in all applications, user-defined iterables are a powerful tool—they allow us\\nto make arbitrary objects look and feel like the other sequences and iterables we have\\nmet in this book. We could use this technique with a database object, for example, to\\nsupport iterations over large database fetches, with multiple cursors into the same query\\nresult.\\n\\nIterable Objects: __iter__ and __next__ | 901\\n\\n\\x0cCoding Alternative: __iter__ plus yield\\nAnd  now,  for  something  completely  implicit—but  potentially  useful  nonetheless.  In\\nsome applications, it’s possible to minimize coding requirements for user-defined itera-\\nbles by combining the __iter__ method we’re exploring here and the yield generator\\nfunction statement we studied in Chapter 20. Because generator functions automati-\\ncally save local variable state and create required iterator methods, they fit this role\\nwell, and complement the state retention and other utility we get from classes.\\nAs a review, recall that any function that contains a yield statement is turned into a\\ngenerator function. When called, it returns a new generator object with automatic re-\\ntention of local scope and code position, an automatically created __iter__ method\\nthat simply returns itself, and an automatically created __next__ method (next in 2.X)\\nthat starts the function or resumes it where it last left off:\\n\\n>>> def gen(x):\\n       for i in range(x): yield i ** 2\\n\\n>>> G = gen(5)               # Create a generator with __iter__ and __next__\\n>>> G.__iter__() == G        # Both methods exist on the same object\\nTrue\\n>>> I = iter(G)              # Runs __iter__: generator returns itself\\n>>> next(I), next(I)         # Runs __next__ (next in 2.X)\\n(0, 1)\\n>>> list(gen(5))             # Iteration contexts automatically run iter and next\\n[0, 1, 4, 9, 16]\\n\\nThis is still true even if the generator function with a yield happens to be a method\\nnamed __iter__: whenever invoked by an iteration context tool, such a method will\\nreturn a new generator object with the requisite __next__. As an added bonus, generator\\nfunctions coded as methods in classes have access to saved state in both instance at-\\ntributes and local scope variables.\\nFor example, the following class is equivalent to the initial Squares user-defined iterable\\nwe coded earlier in squares.py.\\n\\n# File squares_yield.py\\n\\nclass Squares:                                   # __iter__ + yield generator\\n    def __init__(self, start, stop):             # __next__ is automatic/implied\\n        self.start = start\\n        self.stop  = stop\\n    def __iter__(self):\\n        for value in range(self.start, self.stop + 1):\\n            yield value ** 2\\n\\nThere’s  no  need  to  alias  next  to  __next__  for  2.X  compatibility  here,  because  this\\nmethod is now automated and implied by the use of yield. As before, for loops and\\nother iteration tools iterate through instances of this class automatically:\\n\\n% python\\n>>> from squares_yield import Squares\\n>>> for i in Squares(1, 5): print(i, end=\\' \\')\\n\\n902 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0c1 4 9 16 25\\n\\nAnd as usual, we can look under the hood to see how this actually works in iteration\\ncontexts.  Running  our  class  instance  through  iter  obtains  the  result  of  calling\\n__iter__ as usual, but in this case the result is a generator object with an automatically\\ncreated __next__ of the same sort we always get when calling a generator function that\\ncontains a yield. The only difference here is that the generator function is automatically\\ncalled on iter. Invoking the result object’s next interface produces results on demand:\\n\\n>>> S = Squares(1, 5)          # Runs __init__: class saves instance state\\n>>> S\\n<squares_yield.Squares object at 0x000000000294B630>\\n\\n>>> I = iter(S)                # Runs __iter__: returns a generator\\n>>> I\\n<generator object __iter__ at 0x00000000029A8CF0>\\n>>> next(I)\\n1\\n>>> next(I)                    # Runs generator\\'s __next__\\n4\\n...etc...\\n>>> next(I)                    # Generator has both instance and local scope state\\nStopIteration\\n\\nIt may also help to notice that we could name the generator method something other\\nthan __iter__ and call manually to iterate—Squares(1,5).gen(), for example. Using\\nthe __iter__ name invoked automatically by iteration tools simply skips a manual at-\\ntribute fetch and call step:\\n\\nclass Squares:                 # Non __iter__ equivalent (squares_manual.py)\\n    def __init__(...):\\n        ...\\n    def gen(self):\\n        for value in range(self.start, self.stop + 1):\\n            yield value ** 2\\n\\n% python\\n>>> from squares_manual import Squares\\n>>> for i in Squares(1, 5).gen(): print(i, end=\\' \\')\\n...same results...\\n\\n>>> S = Squares(1, 5)\\n>>> I = iter(S.gen())          # Call generator manually for iterable/iterator\\n>>> next(I)\\n...same results...\\n\\nCoding the generator as __iter__ instead cuts out the middleman in your code, though\\nboth schemes ultimately wind up creating a new generator object for each iteration:\\n\\n• With  __iter__, iteration triggers  __iter__, which returns a new generator with\\n\\n__next__.\\n\\nIterable Objects: __iter__ and __next__ | 903\\n\\n\\x0c• Without __iter__, your code calls to make a generator, which returns itself for\\n\\n__iter__.\\n\\nSee Chapter 20 for more on yield and generators if this is puzzling, and compare it\\nwith the more explicit __next__ version in squares.py earlier. You’ll notice that this new\\nsquares_yield.py version is 4 lines shorter (7 versus 11). In a sense, this scheme reduces\\nclass coding requirements much like the closure functions of Chapter 17, but in this\\ncase does so with a combination of functional and OOP techniques, instead of an al-\\nternative to classes. For example, the generator method still leverages self attributes.\\nThis may also very well seem like one too many levels of magic to some observers—it\\nrelies on both the iteration protocol and the object creation of generators, both of which\\nare highly implicit (in contradiction of longstanding Python themes: see import this).\\nOpinions aside, it’s important to understand the non-yield flavor of class iterables too,\\nbecause it’s explicit, general, and sometimes broader in scope.\\nStill, the __iter__/yield technique may prove effective in cases where it applies. It also\\ncomes with a substantial advantage—as the next section explains.\\n\\nMultiple iterators with yield\\nBesides its code conciseness, the user-defined class iterable of the prior section based\\nupon the __iter__/yield combination has an important added bonus—it also supports\\nmultiple active iterators automatically. This naturally follows from the fact that each\\ncall to __iter__ is a call to a generator function, which returns a new generator with its\\nown copy of the local scope for state retention:\\n\\n% python\\n>>> from squares_yield import Squares   # Using the __iter__/yield Squares\\n>>> S = Squares(1, 5)\\n>>> I = iter(S)\\n>>> next(I); next(I)\\n1\\n4\\n>>> J = iter(S)                         # With yield, multiple iterators automatic\\n>>> next(J)\\n1\\n>>> next(I)                             # I is independent of J: own local state\\n9\\n\\nAlthough generator functions are single-scan iterables, the implicit calls to __iter__ in\\niteration contexts make new generators supporting new independent scans:\\n\\n>>> S = Squares(1, 3)\\n>>> for i in S:                         # Each for calls __iter__\\n        for j in S:\\n            print(\\'%s:%s\\' % (i, j), end=\\' \\')\\n\\n1:1 1:4 1:9 4:1 4:4 4:9 9:1 9:4 9:9\\n\\n904 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cTo do the same without yield requires a supplemental class that stores iterator state\\nexplicitly and manually, using techniques of the preceding section (and grows to 15\\nlines: 8 more than with yield):\\n\\n# File squares_nonyield.py\\n\\nclass Squares:\\n    def __init__(self, start, stop):                 # Non-yield generator\\n        self.start = start                           # Multiscans: extra object\\n        self.stop  = stop\\n    def __iter__(self):\\n        return SquaresIter(self.start, self.stop)\\n\\nclass SquaresIter:\\n    def __init__(self, start, stop):\\n        self.value = start - 1\\n        self.stop  = stop\\n    def __next__(self):\\n        if self.value == self.stop:\\n            raise StopIteration\\n        self.value += 1\\n        return self.value ** 2\\n\\nThis works the same as the yield multiscan version, but with more, and more explicit,\\ncode:\\n\\n% python\\n>>> from squares_nonyield import Squares\\n>>> for i in Squares(1, 5): print(i, end=\\' \\')\\n\\n1 4 9 16 25\\n>>>\\n>>> S = Squares(1, 5)\\n>>> I = iter(S)\\n>>> next(I); next(I)\\n1\\n4\\n>>> J = iter(S)                         # Multiple iterators without yield\\n>>> next(J)\\n1\\n>>> next(I)\\n9\\n\\n>>> S = Squares(1, 3)\\n>>> for i in S:                         # Each for calls __iter___\\n        for j in S:\\n            print(\\'%s:%s\\' % (i, j), end=\\' \\')\\n\\n1:1 1:4 1:9 4:1 4:4 4:9 9:1 9:4 9:9\\n\\nFinally, the generator-based approach could similarly remove the need for an extra\\niterator class in the prior item-skipper example of file skipper.py, thanks to its automatic\\nmethods and local variable state retention (and checks in at 9 lines versus the original’s\\n16):\\n\\nIterable Objects: __iter__ and __next__ | 905\\n\\n\\x0c# File skipper_yield.py\\n\\nclass SkipObject:                           # Another __iter__ + yield generator\\n    def __init__(self, wrapped):            # Instance scope retained normally\\n        self.wrapped = wrapped              # Local scope state saved auto\\n    def __iter__(self):\\n        offset = 0\\n        while offset < len(self.wrapped):\\n            item = self.wrapped[offset]\\n            offset += 2\\n            yield item\\n\\nThis works the same as the non-yield multiscan version, but with less, and less explicit,\\ncode:\\n\\n% python\\n>>> from skipper_yield import SkipObject\\n>>> skipper = SkipObject(\\'abcdef\\')\\n>>> I = iter(skipper)\\n>>> next(I); next(I); next(I)\\n\\'a\\'\\n\\'c\\'\\n\\'e\\'\\n>>> for x in skipper:                 # Each for calls __iter__: new auto generator\\n        for y in skipper:\\n            print(x + y, end=\\' \\')\\n\\naa ac ae ca cc ce ea ec ee\\n\\nOf course, these are all artificial examples that could be replaced with simpler tools like\\ncomprehensions, and their code may or may not scale up in kind to more realistic tasks.\\nStudy these alternatives to see how they compare. As so often in programming, the best\\ntool for the job will likely be the best tool for your job!\\n\\nMembership: __contains__, __iter__, and __getitem__\\nThe iteration story is even richer than we’ve seen thus far. Operator overloading is often\\nlayered: classes may provide specific methods, or more general alternatives used as\\nfallback options. For example:\\n\\n• Comparisons in Python 2.X use specific methods such as __lt__ for “less than” if\\npresent, or else the general __cmp__. Python 3.X uses only specific methods, not\\n__cmp__, as discussed later in this chapter.\\n\\n• Boolean tests similarly try a specific __bool__ first (to give an explicit True/False\\nresult), and if it’s absent fall back on the more general __len__ (a nonzero length\\nmeans True). As we’ll also see later in this chapter, Python 2.X works the same but\\nuses the name __nonzero__ instead of __bool__.\\n\\nIn the iterations domain, classes can implement the  in membership operator as an\\niteration, using either the __iter__ or __getitem__ methods. To support more specific\\nmembership, though, classes may code a __contains__ method—when present, this\\n\\n906 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cmethod  is  preferred  over  __iter__,  which  is  preferred  over  __getitem__.  The  __con\\ntains__ method should define membership as applying to keys for a mapping (and can\\nuse quick lookups), and as a search for sequences.\\nConsider the following class, whose file has been instrumented for dual 2.X/3.X usage\\nusing the techniques described earlier. It codes all three methods and tests membership\\nand various iteration contexts applied to an instance. Its methods print trace messages\\nwhen called:\\n\\n# File contains.py\\nfrom __future__ import print_function         # 2.X/3.X compatibility\\n\\nclass Iters:\\n    def __init__(self, value):\\n        self.data = value\\n    \\n    def __getitem__(self, i):                 # Fallback for iteration\\n        print(\\'get[%s]:\\' % i, end=\\'\\')         # Also for index, slice\\n        return self.data[i]\\n    \\n    def __iter__(self):                       # Preferred for iteration\\n        print(\\'iter=> \\', end=\\'\\')              # Allows only one active iterator\\n        self.ix = 0\\n        return self\\n    \\n    def __next__(self):\\n        print(\\'next:\\', end=\\'\\')\\n        if self.ix == len(self.data): raise StopIteration\\n        item = self.data[self.ix]\\n        self.ix += 1\\n        return item\\n    \\n    def __contains__(self, x):                # Preferred for \\'in\\'\\n        print(\\'contains: \\', end=\\'\\')\\n        return x in self.data\\n    next = __next__                           # 2.X/3.X compatibility\\n\\nif __name__ == \\'__main__\\':\\n    X = Iters([1, 2, 3, 4, 5])        # Make instance\\n    print(3 in X)                     # Membership\\n    for i in X:                       # for loops\\n        print(i, end=\\' | \\')\\n\\n    print()\\n    print([i ** 2 for i in X])        # Other iteration contexts\\n    print( list(map(bin, X)) )\\n\\n    I = iter(X)                       # Manual iteration (what other contexts do)\\n    while True:\\n        try:\\n            print(next(I), end=\\' @ \\')\\n        except StopIteration:\\n            break\\n\\nMembership: __contains__, __iter__, and __getitem__ | 907\\n\\n\\x0cAs is, the class in this file has an __iter__ that supports multiple scans, but only a single\\nscan can be active at any point in time (e.g., nested loops won’t work), because each\\niteration attempt resets the scan cursor to the front. Now that you know about yield\\nin iteration methods, you should be able to tell that the following is equivalent but\\nallows multiple active scans—and judge for yourself whether its more implicit nature\\nis worth the nested-scan support and six lines shaved (this is in file contains_yield.py):\\n\\nclass Iters:\\n    def __init__(self, value):\\n        self.data = value\\n    \\n    def __getitem__(self, i):                 # Fallback for iteration\\n        print(\\'get[%s]:\\' % i, end=\\'\\')         # Also for index, slice\\n        return self.data[i]\\n    \\n    def __iter__(self):                       # Preferred for iteration\\n        print(\\'iter=> next:\\', end=\\'\\')         # Allows multiple active iterators\\n        for x in self.data:                   # no __next__ to alias to next\\n            yield x\\n            print(\\'next:\\', end=\\'\\')\\n    \\n    def __contains__(self, x):                # Preferred for \\'in\\'\\n        print(\\'contains: \\', end=\\'\\')\\n        return x in self.data\\n\\nOn both Python 3.X and 2.X, when either version of this file runs its output is as follows\\n—the specific __contains__ intercepts membership, the general __iter__ catches other\\niteration contexts such that __next__ (whether explicitly coded or implied by yield) is\\ncalled repeatedly, and __getitem__ is never called:\\n\\ncontains: True\\niter=> next:1 | next:2 | next:3 | next:4 | next:5 | next:\\niter=> next:next:next:next:next:next:[1, 4, 9, 16, 25]\\niter=> next:next:next:next:next:next:[\\'0b1\\', \\'0b10\\', \\'0b11\\', \\'0b100\\', \\'0b101\\']\\niter=> next:1 @ next:2 @ next:3 @ next:4 @ next:5 @ next:\\n\\nWatch what happens to this code’s output if we comment out its __contains__ method,\\nthough—membership is now routed to the general __iter__ instead:\\n\\niter=> next:next:next:True\\niter=> next:1 | next:2 | next:3 | next:4 | next:5 | next:\\niter=> next:next:next:next:next:next:[1, 4, 9, 16, 25]\\niter=> next:next:next:next:next:next:[\\'0b1\\', \\'0b10\\', \\'0b11\\', \\'0b100\\', \\'0b101\\']\\niter=> next:1 @ next:2 @ next:3 @ next:4 @ next:5 @ next:\\n\\nAnd finally, here is the output if both __contains__ and __iter__ are commented out\\n—the indexing __getitem__ fallback is called with successively higher indexes until it\\nraises IndexError, for membership and other iteration contexts:\\n\\nget[0]:get[1]:get[2]:True\\nget[0]:1 | get[1]:2 | get[2]:3 | get[3]:4 | get[4]:5 | get[5]:\\nget[0]:get[1]:get[2]:get[3]:get[4]:get[5]:[1, 4, 9, 16, 25]\\nget[0]:get[1]:get[2]:get[3]:get[4]:get[5]:[\\'0b1\\', \\'0b10\\', \\'0b11\\', \\'0b100\\',\\'0b101\\']\\nget[0]:1 @ get[1]:2 @ get[2]:3 @ get[3]:4 @ get[4]:5 @ get[5]:\\n\\n908 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cAs we’ve seen, the __getitem__ method is even more general: besides iterations, it also\\nintercepts explicit indexing as well as slicing. Slice expressions trigger __getitem__ with\\na slice object containing bounds, both for built-in types and user-defined classes, so\\nslicing is automatic in our class:\\n>>> from contains import Iters\\n>>> X = Iters(\\'spam\\')               # Indexing\\n>>> X[0]                            # __getitem__(0)\\nget[0]:\\'s\\'\\n\\n>>> \\'spam\\'[1:]                      # Slice syntax\\n\\'pam\\'\\n>>> \\'spam\\'[slice(1, None)]          # Slice object\\n\\'pam\\'\\n\\n>>> X[1:]                           # __getitem__(slice(..))\\nget[slice(1, None, None)]:\\'pam\\'\\n>>> X[:-1]\\nget[slice(None, −1, None)]:\\'spa\\'\\n\\n>>> list(X)                         # And iteration too!\\niter=> next:next:next:next:next:[\\'s\\', \\'p\\', \\'a\\', \\'m\\']\\n\\nIn  more  realistic  iteration  use  cases  that  are  not  sequence-oriented,  though,  the\\n__iter__ method may be easier to write since it must not manage an integer index, and\\n__contains__ allows for membership optimization as a special case.\\n\\nAttribute Access: __getattr__ and __setattr__\\nIn Python, classes can also intercept basic attribute access (a.k.a. qualification) when\\nneeded or useful. Specifically, for an object created from a class, the dot operator ex-\\npression object.attribute can be implemented by your code too, for reference, as-\\nsignment, and deletion contexts. We saw a limited example in this category in Chap-\\nter 28, but will review and expand on the topic here.\\n\\nAttribute Reference\\nThe __getattr__ method intercepts attribute references. It’s called with the attribute\\nname as a string whenever you try to qualify an instance with an undefined (nonexistent)\\nattribute name. It is not called if Python can find the attribute using its inheritance tree\\nsearch procedure.\\nBecause of its behavior, __getattr__ is useful as a hook for responding to attribute\\nrequests in a generic fashion. It’s commonly used to delegate calls to embedded (or\\n“wrapped”) objects from a proxy controller object—of the sort introduced in Chap-\\nter 28’s introduction to delegation. This method can also be used to adapt classes to an\\ninterface, or add accessors for data attributes after the fact—logic in a method that\\nvalidates or computes an attribute after it’s already being used with simple dot notation.\\n\\nAttribute Access: __getattr__ and __setattr__ | 909\\n\\n\\x0cThe basic mechanism underlying these goals is straightforward—the following class\\ncatches attribute references, computing the value for one dynamically, and triggering\\nan error for others unsupported with the raise statement described earlier in this chap-\\nter for iterators (and fully covered in Part VII):\\n\\n>>> class Empty:\\n        def __getattr__(self, attrname):           # On self.undefined\\n            if attrname == \\'age\\':\\n                return 40\\n            else:\\n                raise AttributeError(attrname)\\n\\n>>> X = Empty()\\n>>> X.age\\n40\\n>>> X.name\\n...error text omitted...\\nAttributeError: name\\n\\nHere, the Empty class and its instance X have no real attributes of their own, so the access\\nto X.age gets routed to the __getattr__ method; self is assigned the instance (X), and\\nattrname is assigned the undefined attribute name string (\\'age\\'). The class makes age\\nlook like a real attribute by returning a real value as the result of the X.age qualification\\nexpression (40). In effect, age becomes a dynamically computed attribute—its value is\\nformed by running code, not fetching an object.\\nFor attributes that the class doesn’t know how to handle, __getattr__ raises the built-\\nin AttributeError exception to tell Python that these are bona fide undefined names;\\nasking for X.name triggers the error. You’ll see __getattr__ again when we see delegation\\nand properties at work in the next two chapters; let’s move on to related tools here.\\n\\nAttribute Assignment and Deletion\\nIn the same department, the __setattr__ intercepts all attribute assignments. If this\\nmethod is defined or inherited, self.attr = value becomes self.__setattr__(\\'attr\\',\\nvalue). Like __getattr__, this allows your class to catch attribute changes, and validate\\nor transform as desired.\\nThis method is a bit trickier to use, though, because assigning to any self attributes\\nwithin __setattr__ calls __setattr__ again, potentially causing an infinite recursion\\nloop (and a fairly quick stack overflow exception!). In fact, this applies to all self at-\\ntribute assignments anywhere in the class—all are routed to __setattr__, even those\\nin  other  methods,  and  those  to  names  other  than  that  which  may  have  triggered\\n__setattr__ in the first place. Remember, this catches all attribute assignments.\\nIf you wish to use this method, you can avoid loops by coding instance attribute as-\\nsignments  as  assignments \\nis,  use\\nself.__dict__[\\'name\\']  =  x,  not  self.name  =  x;  because  you’re  not  assigning  to\\n__dict__ itself, this avoids the loop:\\n\\nto  attribute  dictionary  keys.  That \\n\\n910 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0c>>> class Accesscontrol:\\n        def __setattr__(self, attr, value):\\n            if attr == \\'age\\':\\n                self.__dict__[attr] = value + 10      # Not self.name=val or setattr\\n            else:\\n                raise AttributeError(attr + \\' not allowed\\')\\n\\n>>> X = Accesscontrol()\\n>>> X.age = 40                                        # Calls __setattr__\\n>>> X.age\\n50\\n>>> X.name = \\'Bob\\'\\n...text omitted...\\nAttributeError: name not allowed\\n\\nIf you change the __dict__ assignment in this to either of the following, it triggers the\\ninfinite recursion loop and exception—both dot notation and its setattr built-in func-\\ntion equivalent (the assignment analog of getattr) fail when age is assigned outside the\\nclass:\\n\\nself.age = value + 10                            # Loops\\nsetattr(self, attr, value + 10)                  # Loops (attr is \\'age\\')\\n\\nAn assignment to another name within the class triggers a recursive __setattr__ call\\ntoo, though in this class ends less dramatically in the manual AttributeError exception:\\n\\nself.other = 99                                  # Recurs but doesn\\'t loop: fails\\n\\nIt’s also possible to avoid recursive loops in a class that uses __setattr__ by routing\\nany attribute assignments to a higher superclass with a call, instead of assigning keys\\nin __dict__:\\n\\nself.__dict__[attr] = value + 10                 # OK: doesn\\'t loop\\nobject.__setattr__(self, attr, value + 10)       # OK: doesn\\'t loop (new-style only)\\n\\nBecause the object form requires use of new-style classes in 2.X, though, we’ll postpone\\ndetails on this form until Chapter 38’s deeper look at attribute management at large.\\nA third attribute management method, __delattr__, is passed the attribute name string\\nand invoked on all attribute deletions (i.e., del object.attr). Like __setattr__, it must\\navoid  recursive  loops  by  routing  attribute  deletions  with  the  using  class  through\\n__dict__ or a superclass.\\n\\nAs  we’ll  learn  in  Chapter  32,  attributes  implemented  with  new-style\\nclass features such as slots and properties are not physically stored in the\\ninstance’s __dict__ namespace dictionary (and slots may even preclude\\nits existence entirely!). Because of this, code that wishes to support such\\nattributes \\nthe\\nobject.__setattr__ scheme shown here, not by self.__dict__ indexing\\nunless it’s known that subject classes store all their data in the instance\\nitself. In Chapter 38 we’ll also see that the new-style __getattribute__\\n\\nassign  with \\n\\n__setattr__ \\n\\nshould \\n\\ncode \\n\\nto \\n\\nAttribute Access: __getattr__ and __setattr__ | 911\\n\\n\\x0chas similar requirements. This change is mandated in Python 3.X, but\\nalso applies to 2.X if new-style classes are used.\\n\\nOther Attribute Management Tools\\nThese three attribute-access overloading methods allow you to control or specialize\\naccess to attributes in your objects. They tend to play highly specialized roles, some of\\nwhich we’ll explore later in this book. For another example of __getattr__ at work, see\\nChapter 28’s person-composite.py. And for future reference, keep in mind that there are\\nother ways to manage attribute access in Python:\\n\\n• The __getattribute__ method intercepts all attribute fetches, not just those that\\nare  undefined,  but  when  using  it  you  must  be  more  cautious  than  with  __get\\nattr__ to avoid loops.\\n\\n• The property built-in function allows us to associate methods with fetch and set\\n\\noperations on a specific class attribute.\\n\\n• Descriptors provide a protocol for associating __get__ and __set__ methods of a\\n\\nclass with accesses to a specific class attribute.\\n\\n• Slots attributes are declared in classes but create implicit storage in each instance.\\n\\nBecause these are somewhat advanced tools not of interest to every Python program-\\nmer, we’ll defer a look at properties until Chapter 32 and detailed coverage of all the\\nattribute management techniques until Chapter 38.\\n\\nEmulating Privacy for Instance Attributes: Part 1\\nAs another use case for such tools, the following code—file private0.py—generalizes\\nthe previous example, to allow each subclass to have its own list of private names that\\ncannot be assigned to its instances (and uses a user-defined exception class, which you’ll\\nhave to take on faith until Part VII):\\n\\nclass PrivateExc(Exception): pass                   # More on exceptions in Part VII\\n\\nclass Privacy:\\n    def __setattr__(self, attrname, value):         # On self.attrname = value\\n        if attrname in self.privates:\\n            raise PrivateExc(attrname, self)        # Make, raise user-define except\\n        else:\\n            self.__dict__[attrname] = value         # Avoid loops by using dict key\\n\\nclass Test1(Privacy):\\n    privates = [\\'age\\']\\n\\nclass Test2(Privacy):\\n    privates = [\\'name\\', \\'pay\\']\\n    def __init__(self):\\n        self.__dict__[\\'name\\'] = \\'Tom\\'               # To do better, see Chapter 39!\\n\\n912 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cif __name__ == \\'__main__\\':\\n    x = Test1()\\n    y = Test2()\\n\\n    x.name = \\'Bob\\'      # Works\\n   #y.name = \\'Sue\\'      # Fails\\n    print(x.name)\\n\\n    y.age  = 30         # Works\\n   #x.age  = 40         # Fails\\n    print(y.age)\\n\\nIn fact, this is a first-cut solution for an implementation of attribute privacy in Python\\n—disallowing changes to attribute names outside a class. Although Python doesn’t\\nsupport  private  declarations  per  se,  techniques  like  this  can  emulate  much  of  their\\npurpose.\\nThis is a partial—and even clumsy—solution, though; to make it more effective, we\\nmust augment it to allow classes to set their private attributes more naturally, without\\nhaving to go through __dict__ each time, as the constructor must do here to avoid\\ntriggering __setattr__ and an exception. A better and more complete approach might\\nrequire a wrapper (“proxy”) class to check for private attribute accesses made outside\\nthe class only, and a __getattr__ to validate attribute fetches too.\\nWe’ll postpone a more complete solution to attribute privacy until Chapter 39, where\\nwe’ll  use  class  decorators  to  intercept  and  validate  attributes  more  generally.  Even\\nthough privacy can be emulated this way, though, it almost never is in practice. Python\\nprogrammers are able to write large OOP frameworks and applications without private\\ndeclarations—an interesting finding about access controls in general that is beyond the\\nscope of our purposes here.\\nStill, catching attribute references and assignments is generally a useful technique; it\\nsupports delegation, a design technique that allows controller objects to wrap up em-\\nbedded objects, add new behaviors, and route other operations back to the wrapped\\nobjects. Because they involve design topics, we’ll revisit delegation and wrapper classes\\nin the next chapter.\\n\\nString Representation: __repr__ and __str__\\nOur next methods deal with display formats—a topic we’ve already explored in prior\\nchapters, but will summarize and formalize here. As a review, the following code ex-\\nercises the __init__ constructor and the __add__ overload method, both of which we’ve\\nalready seen (+ is an in-place operation here, just to show that it can be; per Chap-\\nter 27, a named method may be preferred). As we’ve learned, the default display of\\ninstance objects for a class like this is neither generally useful nor aesthetically pretty:\\n\\n>>> class adder:\\n        def __init__(self, value=0):\\n            self.data = value                    # Initialize data\\n\\nString Representation: __repr__ and __str__ | 913\\n\\n\\x0c        def __add__(self, other):\\n            self.data += other                   # Add other in place (bad form?)\\n\\n>>> x = adder()                                  # Default displays\\n>>> print(x)\\n<__main__.adder object at 0x00000000029736D8>\\n>>> x\\n<__main__.adder object at 0x00000000029736D8>\\n\\nBut coding or inheriting string representation methods allows us to customize the dis-\\nplay—as in the following, which defines a __repr__ method in a subclass that returns\\na string representation for its instances.\\n\\n>>> class addrepr(adder):                        # Inherit __init__, __add__\\n        def __repr__(self):                      # Add string representation\\n            return \\'addrepr(%s)\\' % self.data     # Convert to as-code string\\n\\n>>> x = addrepr(2)                               # Runs __init__\\n>>> x + 1                                        # Runs __add__ (x.add() better?)\\n>>> x                                            # Runs __repr__\\naddrepr(3)\\n>>> print(x)                                     # Runs __repr__\\naddrepr(3)\\n>>> str(x), repr(x)                              # Runs __repr__ for both\\n(\\'addrepr(3)\\', \\'addrepr(3)\\')\\n\\nIf defined, __repr__ (or its close relative, __str__) is called automatically when class\\ninstances are printed or converted to strings. These methods allow you to define a better\\ndisplay format for your objects than the default instance display. Here, __repr__ uses\\nbasic string formatting to convert the managed self.data object to a more human-\\nfriendly string for display.\\n\\nWhy Two Display Methods?\\nSo far, what we’ve seen is largely review. But while these methods are generally straight-\\nforward to use, their roles and behavior have some subtle implications both for design\\nand coding. In particular, Python provides two display methods to support alternative\\ndisplays for different audiences:\\n\\n• __str__ is tried first for the print operation and the str built-in function (the in-\\nternal equivalent of which print runs). It generally should return a user-friendly\\ndisplay.\\n\\n• __repr__ is used in all other contexts: for interactive echoes, the repr function, and\\nnested appearances, as well as by print and str if no __str__ is present. It should\\ngenerally return an as-code string that could be used to re-create the object, or a\\ndetailed display for developers.\\n\\nThat is, __repr__ is used everywhere, except by print and str when a __str__ is defined.\\nThis means you can code a __repr__ to define a single display format used everywhere,\\n\\n914 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cand may code a __str__ to either support print and str exclusively, or to provide an\\nalternative display for them.\\nAs noted in Chapter 28, general tools may also prefer __str__ to leave other classes the\\noption of adding an alternative __repr__ display for use in other contexts, as long as\\nprint  and  str  displays  suffice  for  the  tool.  Conversely,  a  general  tool  that  codes  a\\n__repr__ still leaves clients the option of adding alternative displays with a __str__ for\\nprint and str. In other words, if you code either, the other is available for an additional\\ndisplay. In cases where the choice isn’t clear, __str__ is generally preferred for larger\\nuser-friendly displays, and __repr__ for lower-level or as-code displays and all-inclusive\\nroles.\\nLet’s write some code to illustrate these two methods’ distinctions in more concrete\\nterms. The prior example in this section showed how __repr__ is used as the fallback\\noption  in  many  contexts.  However,  while  printing  falls  back  on  __repr__  if  no\\n__str__ is defined, the inverse is not true—other contexts, such as interactive echoes,\\nuse __repr__ only and don’t try __str__ at all:\\n\\n>>> class addstr(adder):\\n        def __str__(self):                       # __str__ but no __repr__\\n            return \\'[Value: %s]\\' % self.data     # Convert to nice string\\n\\n>>> x = addstr(3)\\n>>> x + 1\\n>>> x                                            # Default __repr__\\n<__main__.addstr object at 0x00000000029738D0>\\n>>> print(x)                                     # Runs __str__\\n[Value: 4]\\n>>> str(x), repr(x)\\n(\\'[Value: 4]\\', \\'<__main__.addstr object at 0x00000000029738D0>\\')\\n\\nBecause of this, __repr__ may be best if you want a single display for all contexts. By\\ndefining both methods, though, you can support different displays in different contexts\\n—for example, an end-user display with __str__, and a low-level display for program-\\nmers  to  use  during  development  with  __repr__.  In  effect,  __str__  simply  overrides\\n__repr__ for more user-friendly display contexts:\\n\\n>>> class addboth(adder):\\n        def __str__(self):\\n            return \\'[Value: %s]\\' % self.data     # User-friendly string\\n        def __repr__(self):\\n            return \\'addboth(%s)\\' % self.data     # As-code string\\n\\n>>> x = addboth(4)\\n>>> x + 1\\n>>> x                                            # Runs __repr__\\naddboth(5)\\n>>> print(x)                                     # Runs __str__\\n[Value: 5]\\n>>> str(x), repr(x)\\n(\\'[Value: 5]\\', \\'addboth(5)\\')\\n\\nString Representation: __repr__ and __str__ | 915\\n\\n\\x0cDisplay Usage Notes\\nThough generally simple to use, I should mention three usage notes regarding these\\nmethods here. First, keep in mind that __str__ and __repr__ must both return strings;\\nother result types are not converted and raise errors, so be sure to run them through a\\nto-string converter (e.g., str or %) if needed.\\nSecond, depending on a container’s string-conversion logic, the user-friendly display\\nof __str__ might only apply when objects appear at the top level of a print operation;\\nobjects nested in larger objects might still print with their __repr__ or its default. The\\nfollowing illustrates both of these points:\\n\\n>>> class Printer:\\n        def __init__(self, val):\\n            self.val = val\\n        def __str__(self):                  # Used for instance itself\\n            return str(self.val)            # Convert to a string result\\n\\n>>> objs = [Printer(2), Printer(3)]\\n>>> for x in objs: print(x)                 # __str__ run when instance printed\\n                                            # But not when instance is in a list!\\n2\\n3\\n>>> print(objs)\\n[<__main__.Printer object at 0x000000000297AB38>, <__main__.Printer obj...etc...>]\\n>>> objs\\n[<__main__.Printer object at 0x000000000297AB38>, <__main__.Printer obj...etc...>]\\n\\nTo ensure that a custom display is run in all contexts regardless of the container, code\\n__repr__, not __str__; the former is run in all cases if the latter doesn’t apply, including\\nnested appearances:\\n>>> class Printer:\\n        def __init__(self, val):\\n            self.val = val\\n        def __repr__(self):                 # __repr__ used by print if no __str__\\n            return str(self.val)            # __repr__ used if echoed or nested\\n\\n>>> objs = [Printer(2), Printer(3)]\\n>>> for x in objs: print(x)                 # No __str__: runs __repr__\\n\\n2\\n3\\n>>> print(objs)                             # Runs __repr__, not ___str__\\n[2, 3]\\n>>> objs\\n[2, 3]\\n\\nThird, and perhaps most subtle, the display methods also have the potential to trigger\\ninfinite recursion loops in rare contexts—because some objects’ displays include dis-\\nplays of other objects, it’s not impossible that a display may trigger a display of an object\\nbeing displayed, and thus loop. This is rare and obscure enough to skip here, but watch\\n\\n916 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cfor an example of this looping potential to appear for these methods in a note near the\\nend of the next chapter in its listinherited.py example’s class, where __repr__ can loop.\\nIn practice, __str__, and its more inclusive relative __repr__, seem to be the second\\nmost  commonly  used  operator  overloading  methods  in  Python  scripts,  behind\\n__init__. Anytime you can print an object and see a custom display, one of these two\\ntools is probably in use. For additional examples of these tools at work and the design\\ntradeoffs they imply, see Chapter 28’s case study and Chapter 31’s class lister mix-ins,\\nas well as their role in Chapter 35’s exception classes, where __str__ is required over\\n__repr__.\\n\\nRight-Side and In-Place Uses: __radd__ and __iadd__\\nOur next group of overloading methods extends the functionality of binary operator\\nmethods such as __add__ and __sub__ (called for + and -), which we’ve already seen.\\nAs mentioned earlier, part of the reason there are so many operator overloading meth-\\nods is because they come in multiple flavors—for every binary expression, we can im-\\nplement a left, right, and in-place variant. Though defaults are also applied if you don’t\\ncode all three, your objects’ roles dictate how many variants you’ll need to code.\\n\\nRight-Side Addition\\nFor instance, the __add__ methods coded so far technically do not support the use of\\ninstance objects on the right side of the + operator:\\n\\n>>> class Adder:\\n       def __init__(self, value=0):\\n           self.data = value\\n       def __add__(self, other):\\n           return self.data + other\\n\\n>>> x = Adder(5)\\n>>> x + 2\\n7\\n>>> 2 + x\\nTypeError: unsupported operand type(s) for +: \\'int\\' and \\'Adder\\'\\n\\nTo implement more general expressions, and hence support commutative-style opera-\\ntors, code the __radd__ method as well. Python calls __radd__ only when the object on\\nthe right side of the + is your class instance, but the object on the left is not an instance\\nof your class. The __add__ method for the object on the left is called instead in all other\\ncases (all of this section’s five Commuter classes are coded in file commuter.py in the\\nbook’s examples, along with a self-test):\\n\\nclass Commuter1:\\n    def __init__(self, val):\\n        self.val = val\\n    def __add__(self, other):\\n        print(\\'add\\', self.val, other)\\n\\nRight-Side and In-Place Uses: __radd__ and __iadd__ | 917\\n\\n\\x0c        return self.val + other\\n    def __radd__(self, other):\\n        print(\\'radd\\', self.val, other)\\n        return other + self.val\\n\\n>>> from commuter import Commuter1\\n>>> x = Commuter1(88)\\n>>> y = Commuter1(99)\\n\\n>>> x + 1                      # __add__: instance + noninstance\\nadd 88 1\\n89\\n>>> 1 + y                      # __radd__: noninstance + instance\\nradd 99 1\\n100\\n>>> x + y                      # __add__: instance + instance, triggers __radd__\\nadd 88 <commuter.Commuter1 object at 0x00000000029B39E8>\\nradd 99 88\\n187\\n\\nNotice how the order is reversed in __radd__: self is really on the right of the +, and\\nother is on the left. Also note that x and y are instances of the same class here; when\\ninstances of different classes appear mixed in an expression, Python prefers the class\\nof the one on the left. When we add the two instances together, Python runs __add__,\\nwhich in turn triggers __radd__ by simplifying the left operand.\\n\\nReusing __add__ in __radd__\\nFor truly commutative operations that do not require special-casing by position, it is\\nalso sometimes sufficient to reuse __add__ for __radd__: either by calling __add__ di-\\nrectly;  by  swapping  order  and  re-adding  to  trigger  __add__  indirectly;  or  by  simply\\nassigning __radd__ to be an alias for __add__ at the top level of the class statement (i.e.,\\nin the class’s scope). The following alternatives implement all three of these schemes,\\nand return the same results as the original—though the last saves an extra call or dis-\\npatch and hence may be quicker (in all, __radd__ is run when self is on the right side\\nof a +):\\n\\nclass Commuter2:\\n    def __init__(self, val):\\n        self.val = val\\n    def __add__(self, other):\\n        print(\\'add\\', self.val, other)\\n        return self.val + other\\n    def __radd__(self, other):\\n        return self.__add__(other)              # Call __add__ explicitly\\n\\nclass Commuter3:\\n    def __init__(self, val):\\n        self.val = val\\n    def __add__(self, other):\\n        print(\\'add\\', self.val, other)\\n        return self.val + other\\n    def __radd__(self, other):\\n\\n918 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0c        return self + other                     # Swap order and re-add\\n\\nclass Commuter4:\\n    def __init__(self, val):\\n        self.val = val\\n    def __add__(self, other):\\n        print(\\'add\\', self.val, other)\\n        return self.val + other\\n    __radd__ = __add__                          # Alias: cut out the middleman\\n\\nIn all these, right-side instance appearances trigger the single, shared __add__ method,\\npassing the right operand to self, to be treated the same as a left-side appearance. Run\\nthese on your own for more insight; their returned values are the same as the original.\\n\\nPropagating class type\\nIn more realistic classes where the class type may need to be propagated in results,\\nthings can become trickier: type testing may be required to tell whether it’s safe to\\nconvert and thus avoid nesting. For instance, without the isinstance test in the fol-\\nlowing, we could wind up with a Commuter5 whose val is another Commuter5 when two\\ninstances are added and __add__ triggers __radd__:\\n\\nclass Commuter5:                                # Propagate class type in results\\n    def __init__(self, val):\\n        self.val = val\\n    def __add__(self, other):\\n        if isinstance(other, Commuter5):        # Type test to avoid object nesting\\n            other = other.val\\n        return Commuter5(self.val + other)      # Else + result is another Commuter\\n    def __radd__(self, other):\\n        return Commuter5(other + self.val)\\n    def __str__(self):\\n        return \\'<Commuter5: %s>\\' % self.val\\n\\n>>> from commuter import Commuter5\\n>>> x = Commuter5(88)\\n>>> y = Commuter5(99)\\n>>> print(x + 10)                      # Result is another Commuter instance\\n<Commuter5: 98>\\n>>> print(10 + y)\\n<Commuter5: 109>\\n\\n>>> z = x + y                          # Not nested: doesn\\'t recur to __radd__\\n>>> print(z)\\n<Commuter5: 187>\\n>>> print(z + 10)\\n<Commuter5: 197>\\n>>> print(z + z)\\n<Commuter5: 374>\\n>>> print(z + z + 1)\\n<Commuter5: 375>\\n\\nThe need for the isinstance type test here is very subtle—uncomment, run, and trace\\nto see why it’s required. If you do, you’ll see that the last part of the preceding test\\n\\nRight-Side and In-Place Uses: __radd__ and __iadd__ | 919\\n\\n\\x0cwinds up differing and nesting objects—which still do the math correctly, but kick off\\npointless recursive calls to simplify their values, and extra constructor calls build re-\\nsults:\\n\\n>>> z = x + y                          # With isinstance test commented-out\\n>>> print(z)\\n<Commuter5: <Commuter5: 187>>\\n>>> print(z + 10)\\n<Commuter5: <Commuter5: 197>>\\n>>> print(z + z)\\n<Commuter5: <Commuter5: <Commuter5: <Commuter5: 374>>>>\\n>>> print(z + z + 1)\\n<Commuter5: <Commuter5: <Commuter5: <Commuter5: 375>>>>\\n\\nTo test, the rest of commuter.py looks and runs like this—classes can appear in tuples\\nnaturally:\\n\\n#!python\\nfrom __future__ import print_function           # 2.X/3.X compatibility\\n...classes defined here...\\n\\nif __name__ == \\'__main__\\':\\n    for klass in (Commuter1, Commuter2, Commuter3, Commuter4, Commuter5):\\n        print(\\'-\\' * 60)\\n        x = klass(88)\\n        y = klass(99)\\n        print(x + 1)\\n        print(1 + y)\\n        print(x + y)\\n\\nc:\\\\code> commuter.py\\n------------------------------------------------------------\\nadd 88 1\\n89\\nradd 99 1\\n100\\nadd 88 <__main__.Commuter1 object at 0x000000000297F2B0>\\nradd 99 88\\n187\\n------------------------------------------------------------\\n...etc...\\n\\nThere are too many coding variations to explore here, so experiment with these classes\\non your own for more insight; aliasing __radd__ to __add__ in Commuter5, for example,\\nsaves a line, but doesn’t prevent object nesting without isinstance. See also Python’s\\nmanuals for a discussion of other options in this domain; for example, classes may also\\nreturn the special NotImplemented object for unsupported operands to influence method\\nselection (this is treated as though the method were not defined).\\n\\nIn-Place Addition\\nTo  also  implement  +=  in-place  augmented  addition,  code  either  an  __iadd__  or  an\\n__add__. The latter is used if the former is absent. In fact, the prior section’s Commuter\\n\\n920 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cclasses already support += for this reason—Python runs __add__ and assigns the result\\nmanually. The __iadd__ method, though, allows for more efficient in-place changes to\\nbe coded where applicable:\\n\\n>>> class Number:\\n        def __init__(self, val):\\n            self.val = val\\n        def __iadd__(self, other):             # __iadd__ explicit: x += y\\n            self.val += other                  # Usually returns self\\n            return self\\n\\n>>> x = Number(5)\\n>>> x += 1\\n>>> x += 1\\n>>> x.val\\n7\\n\\nFor mutable objects, this method can often specialize for quicker in-place changes:\\n\\n>>> y = Number([1])                            # In-place change faster than +\\n>>> y += [2]\\n>>> y += [3]\\n>>> y.val\\n[1, 2, 3]\\n\\nThe normal __add__ method is run as a fallback, but may not be able optimize in-place\\ncases:\\n\\n>>> class Number:\\n        def __init__(self, val):\\n            self.val = val\\n        def __add__(self, other):              # __add__ fallback: x = (x + y)\\n            return Number(self.val + other)    # Propagates class type\\n\\n>>> x = Number(5)\\n>>> x += 1\\n>>> x += 1                                     # And += does concatenation here\\n>>> x.val\\n7\\n\\nThough we’ve focused on + here, keep in mind that every binary operator has similar\\nright-side  and  in-place  overloading  methods  that  work  the  same  (e.g.,  __mul__,\\n__rmul__, and __imul__). Still, right-side methods are an advanced topic and tend to be\\nfairly uncommon in practice; you only code them when you need operators to be com-\\nmutative, and then only if you need to support such operators at all. For instance, a\\nVector class may use these tools, but an Employee or Button class probably would not.\\n\\nCall Expressions: __call__\\nOn to our next overloading method: the __call__ method is called when your instance\\nis called. No, this isn’t a circular definition—if defined, Python runs a __call__ method\\nfor function call expressions applied to your instances, passing along whatever posi-\\n\\nCall Expressions: __call__ | 921\\n\\n\\x0ctional or keyword arguments were sent. This allows instances to conform to a function-\\nbased API:\\n\\n>>> class Callee:\\n        def __call__(self, *pargs, **kargs):       # Intercept instance calls\\n            print(\\'Called:\\', pargs, kargs)         # Accept arbitrary arguments\\n\\n>>> C = Callee()\\n>>> C(1, 2, 3)                                     # C is a callable object\\nCalled: (1, 2, 3) {}\\n>>> C(1, 2, 3, x=4, y=5)\\nCalled: (1, 2, 3) {\\'y\\': 5, \\'x\\': 4}\\n\\nMore formally, all the argument-passing modes we explored in Chapter 18 are sup-\\nported by the __call__ method—whatever is passed to the instance is passed to this\\nmethod, along with the usual implied instance argument. For example, the method\\ndefinitions:\\nclass C:\\n    def __call__(self, a, b, c=5, d=6): ...        # Normals and defaults\\n\\nclass C:\\n    def __call__(self, *pargs, **kargs): ...       # Collect arbitrary arguments\\n\\nclass C:\\n    def __call__(self, *pargs, d=6, **kargs): ...  # 3.X keyword-only argument\\n\\nall match all the following instance calls:\\n\\nX = C()\\nX(1, 2)                                            # Omit defaults\\nX(1, 2, 3, 4)                                      # Positionals\\nX(a=1, b=2, d=4)                                   # Keywords\\nX(*[1, 2], **dict(c=3, d=4))                       # Unpack arbitrary arguments\\nX(1, *(2,), c=3, **dict(d=4))                      # Mixed modes\\n\\nSee Chapter 18 for a refresher on function arguments. The net effect is that classes and\\ninstances with a __call__ support the exact same argument syntax and semantics as\\nnormal functions and methods.\\nIntercepting call expression like this allows class instances to emulate the look and feel\\nof things like functions, but also retain state information for use during calls. We saw\\nan example similar to the following while exploring scopes in Chapter 17, but you\\nshould now be familiar enough with operator overloading to understand this pattern\\nbetter:\\n\\n>>> class Prod:\\n        def __init__(self, value):                 # Accept just one argument\\n            self.value = value\\n        def __call__(self, other):\\n            return self.value * other\\n\\n>>> x = Prod(2)                                    # \"Remembers\" 2 in state\\n>>> x(3)                                           # 3 (passed) * 2 (state)\\n6\\n\\n922 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0c>>> x(4)\\n8\\n\\nIn this example, the __call__ may seem a bit gratuitous at first glance. A simple method\\ncan provide similar utility:\\n\\n>>> class Prod:\\n        def __init__(self, value):\\n            self.value = value\\n        def comp(self, other):\\n            return self.value * other\\n\\n>>> x = Prod(3)\\n>>> x.comp(3)\\n9\\n>>> x.comp(4)\\n12\\n\\nHowever, __call__ can become more useful when interfacing with APIs (i.e., libraries)\\nthat expect functions—it allows us to code objects that conform to an expected func-\\ntion call interface, but also retain state information, and other class assets such as in-\\nheritance.  In  fact,  it  may  be  the  third  most  commonly  used  operator  overloading\\nmethod, behind the __init__ constructor and the __str__ and __repr__ display-format\\nalternatives.\\n\\nFunction Interfaces and Callback-Based Code\\nAs an example, the tkinter GUI toolkit (named Tkinter in Python 2.X) allows you to\\nregister functions as event handlers (a.k.a. callbacks)—when events occur, tkinter calls\\nthe registered objects. If you want an event handler to retain state between events, you\\ncan register either a class’s bound method, or an instance that conforms to the expected\\ninterface with __call__.\\nIn the prior section’s code, for example, both x.comp from the second example and x\\nfrom the first can pass as function-like objects this way.  Chapter 17’s closure func-\\ntions with state in enclosing scopes can achieve similar effects, but don’t provide as\\nmuch support for multiple operations or customization.\\nI’ll have more to say about bound methods in the next chapter, but for now, here’s a\\nhypothetical example of __call__ applied to the GUI domain. The following class de-\\nfines an object that supports a function-call interface, but also has state information\\nthat remembers the color a button should change to when it is later pressed:\\n\\nclass Callback:\\n    def __init__(self, color):               # Function + state information\\n        self.color = color\\n    def __call__(self):                      # Support calls with no arguments\\n        print(\\'turn\\', self.color)\\n\\nCall Expressions: __call__ | 923\\n\\n\\x0cNow, in the context of a GUI, we can register instances of this class as event handlers\\nfor buttons, even though the GUI expects to be able to invoke event handlers as simple\\nfunctions with no arguments:\\n\\n# Handlers\\ncb1 = Callback(\\'blue\\')                       # Remember blue\\ncb2 = Callback(\\'green\\')                      # Remember green\\n\\nB1 = Button(command=cb1)                     # Register handlers\\nB2 = Button(command=cb2)\\n\\nWhen the button is later pressed, the instance object is called as a simple function with\\nno arguments, exactly like in the following calls. Because it retains state as instance\\nattributes, though, it remembers what to do—it becomes a stateful function object:\\n\\n# Events\\ncb1()                                        # Prints \\'turn blue\\'\\ncb2()                                        # Prints \\'turn green\\'\\n\\nIn fact, many consider such classes to be the best way to retain state information in the\\nPython language (per generally accepted Pythonic principles, at least). With OOP, the\\nstate remembered is made explicit with attribute assignments. This is different than\\nother state retention techniques (e.g., global variables, enclosing function scope refer-\\nences, and default mutable arguments), which rely on more limited or implicit behavior.\\nMoreover, the added structure and customization in classes goes beyond state reten-\\ntion.\\nOn the other hand, tools such as closure functions are useful in basic state retention\\nroles too, and 3.X’s nonlocal statement makes enclosing scopes a viable alternative in\\nmore programs. We’ll revisit such tradeoffs when we start coding substantial decorators\\nin Chapter 39, but here’s a quick closure equivalent:\\n\\ndef callback(color):                         # Enclosing scope versus attrs\\n    def oncall():\\n        print(\\'turn\\', color)\\n    return oncall\\n\\ncb3 = callback(\\'yellow\\')                     # Handler to be registered\\ncb3()                                        # On event: prints \\'turn yellow\\'\\n\\nBefore we move on, there are two other ways that Python programmers sometimes tie\\ninformation to a callback function like this. One option is to use default arguments in\\nlambda functions:\\n\\ncb4 = (lambda color=\\'red\\': \\'turn \\' + color)  # Defaults retain state too\\nprint(cb4())\\n\\nThe other is to use bound methods of a class— a bit of a preview, but simple enough to\\nintroduce here. A bound method object is a kind of object that remembers both the\\nself instance and the referenced function. This object may therefore be called later as\\na simple function without an instance:\\n\\n924 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cclass Callback:\\n    def __init__(self, color):               # Class with state information\\n        self.color = color\\n    def changeColor(self):                   # A normal named method\\n        print(\\'turn\\', self.color)\\n\\ncb1 = Callback(\\'blue\\')\\ncb2 = Callback(\\'yellow\\')\\n\\nB1 = Button(command=cb1.changeColor)         # Bound method: reference, don\\'t call\\nB2 = Button(command=cb2.changeColor)         # Remembers function + self pair\\n\\nIn this case, when this button is later pressed it’s as if the GUI does this, which invokes\\nthe instance’s changeColor method to process the object’s state information, instead of\\nthe instance itself:\\n\\ncb1 = Callback(\\'blue\\')\\nobj = cb1.changeColor                        # Registered event handler\\nobj()                                        # On event prints \\'turn blue\\'\\n\\nNote that a lambda is not required here, because a bound method reference by itself\\nalready defers a call until later. This technique is simpler, but perhaps less general than\\noverloading calls with __call__. Again, watch for more about bound methods in the\\nnext chapter.\\nYou’ll also see another __call__ example in Chapter 32, where we will use it to imple-\\nment something known as a function decorator—a callable object often used to add a\\nlayer of logic on top of an embedded function. Because __call__ allows us to attach\\nstate information to a callable object, it’s a natural implementation technique for a\\nfunction that must remember to call another function when called itself. For more\\n__call__ examples, see the state retention preview examples in Chapter 17, and the\\nmore advanced decorators and metaclasses of Chapter 39 and Chapter 40.\\n\\nComparisons: __lt__, __gt__, and Others\\nOur next batch of overloading methods supports comparisons. As suggested in Ta-\\nble 30-1, classes can define methods to catch all six comparison operators: <, >, <=, >=,\\n==, and !=. These methods are generally straightforward to use, but keep the following\\nqualifications in mind:\\n\\n• Unlike the __add__/__radd__ pairings discussed earlier, there are no right-side var-\\niants of comparison methods. Instead, reflective methods are used when only one\\noperand supports comparison (e.g., __lt__ and __gt__ are each other’s reflection).\\n• There are no implicit relationships among the comparison operators. The truth of\\n== does not imply that != is false, for example, so both __eq__ and __ne__ should\\nbe defined to ensure that both operators behave correctly.\\n\\n• In Python 2.X, a __cmp__ method is used by all comparisons if no more specific\\ncomparison methods are defined; it returns a number that is less than, equal to, or\\n\\nComparisons: __lt__, __gt__, and Others\\n\\n| 925\\n\\n\\x0cgreater than zero, to signal less than, equal, and greater than results for the com-\\nparison of its two arguments (self and another operand). This method often uses\\nthe  cmp(x,  y)  built-in  to  compute  its  result.  Both  the  __cmp__  method  and  the\\ncmp built-in function are removed in Python 3.X: use the more specific methods\\ninstead.\\n\\nWe don’t have space for an in-depth exploration of comparison methods, but as a quick\\nintroduction, consider the following class and test code:\\n\\nclass C:\\n    data = \\'spam\\'\\n    def __gt__(self, other):               # 3.X and 2.X version\\n        return self.data > other\\n    def __lt__(self, other):\\n        return self.data < other\\n\\nX = C()\\nprint(X > \\'ham\\')                           # True  (runs __gt__)\\nprint(X < \\'ham\\')                           # False (runs __lt__)\\n\\nWhen run under Python 3.X or 2.X, the prints at the end display the expected results\\nnoted in their comments, because the class’s methods intercept and implement com-\\nparison expressions. Consult Python’s manuals and other reference resources for more\\ndetails in this category; for example, __lt__ is used for sorts in Python3.X, and as for\\nbinary expression operators, these methods can also return NotImplemented for unsup-\\nported arguments.\\n\\nThe __cmp__ Method in Python 2.X\\nIn Python 2.X only, the __cmp__ method is used as a fallback if more specific methods\\nare not defined: its integer result is used to evaluate the operator being run. The fol-\\nlowing produces the same result as the prior section’s code under 2.X, for example, but\\nfails in 3.X because __cmp__ is no longer used:\\n\\nclass C:\\n    data = \\'spam\\'                          # 2.X only\\n    def __cmp__(self, other):              # __cmp__ not used in 3.X\\n        return cmp(self.data, other)       # cmp not defined in 3.X\\n\\nX = C()\\nprint(X > \\'ham\\')                           # True  (runs __cmp__)\\nprint(X < \\'ham\\')                           # False (runs __cmp__)\\n\\nNotice that this fails in 3.X because __cmp__ is no longer special, not because the cmp\\nbuilt-in function is no longer present. If we change the prior class to the following to\\ntry to simulate the cmp call, the code still works in 2.X but fails in 3.X:\\n\\nclass C:\\n    data = \\'spam\\'\\n    def __cmp__(self, other):\\n        return (self.data > other) - (self.data < other)\\n\\n926 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cSo why, you might be asking, did I just show you a comparison method that is no longer\\nsupported in 3.X? While it would be easier to erase history entirely, this book is designed\\nto support both 2.X and 3.X readers. Because __cmp__ may appear in code 2.X readers\\nmust reuse or maintain, it’s fair game in this book. Moreover, __cmp__ was removed\\nmore abruptly than the  __getslice__ method described earlier, and so may endure\\nlonger. If you use 3.X, though, or care about running your code under 3.X in the future,\\ndon’t use __cmp__ anymore: use the more specific comparison methods instead.\\n\\nBoolean Tests: __bool__ and __len__\\nThe next set of methods is truly useful (yes, pun intended!). As we’ve learned, every\\nobject is inherently true or false in Python. When you code classes, you can define what\\nthis means for your objects by coding methods that give the True or False values of\\ninstances on request. The names of these methods differ per Python line; this section\\nstarts with the 3.X story, then shows 2.X’s equivalent.\\nAs mentioned briefly earlier, in Boolean contexts, Python first tries __bool__ to obtain\\na direct Boolean value; if that method is missing, Python tries __len__ to infer a truth\\nvalue from the object’s length. The first of these generally uses object state or other\\ninformation to produce a Boolean result. In 3.X:\\n\\n>>> class Truth:\\n       def __bool__(self): return True\\n\\n>>> X = Truth()\\n>>> if X: print(\\'yes!\\')\\n\\nyes!\\n\\n>>> class Truth:\\n       def __bool__(self): return False\\n\\n>>> X = Truth()\\n>>> bool(X)\\nFalse\\n\\nIf this method is missing, Python falls back on length because a nonempty object is\\nconsidered true (i.e., a nonzero length is taken to mean the object is true, and a zero\\nlength means it is false):\\n\\n>>> class Truth:\\n       def __len__(self): return 0\\n\\n>>> X = Truth()\\n>>> if not X: print(\\'no!\\')\\n\\nno!\\n\\nIf both methods are present Python prefers __bool__ over __len__, because it is more\\nspecific:\\n\\nBoolean Tests: __bool__ and __len__ | 927\\n\\n\\x0c>>> class Truth:\\n       def __bool__(self): return True            # 3.X tries __bool__ first\\n       def __len__(self): return 0                # 2.X tries __len__ first\\n\\n>>> X = Truth()\\n>>> if X: print(\\'yes!\\')\\n\\nyes!\\n\\nIf neither truth method is defined, the object is vacuously considered true (though any\\npotential implications for more metaphysically inclined readers are strictly coinciden-\\ntal):\\n\\n>>> class Truth:\\n        pass\\n\\n>>> X = Truth()\\n>>> bool(X)\\nTrue\\n\\nAt least that’s the Truth in 3.X. These examples won’t generate exceptions in 2.X, but\\nsome of their results there may look a bit odd (and trigger an existential crisis or two)\\nunless you read the next section.\\n\\nBoolean Methods in Python 2.X\\nAlas, it’s not nearly as dramatic as billed—Python 2.X users simply use __nonzero__\\ninstead of __bool__ in all of the preceding section’s code. Python 3.X renamed the 2.X\\n__nonzero__ method to __bool__, but Boolean tests work the same otherwise; both 3.X\\nand 2.X use __len__ as a fallback.\\nSubtly, if you don’t use the 2.X name, the first test in the prior section will work the\\nsame for you anyhow, but only because __bool__ is not recognized as a special method\\nname in 2.X, and objects are considered true by default! To witness this version dif-\\nference live, you need to return False:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> class C:\\n        def __bool__(self):\\n            print(\\'in bool\\')\\n            return False\\n\\n>>> X = C()\\n>>> bool(X)\\nin bool\\nFalse\\n>>> if X: print(99)\\n\\nin bool\\n\\nThis works as advertised in 3.X. In 2.X, though, __bool__ is ignored and the object is\\nalways considered true by default:\\n\\n928 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cC:\\\\code> c:\\\\python27\\\\python\\n>>> class C:\\n        def __bool__(self):\\n            print(\\'in bool\\')\\n            return False\\n\\n>>> X = C()\\n>>> bool(X)\\nTrue\\n>>> if X: print(99)\\n\\n99\\n\\nThe short story here: in 2.X, use __nonzero__ for Boolean values, or return 0 from the\\n__len__ fallback method to designate false:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> class C:\\n        def __nonzero__(self):\\n            print(\\'in nonzero\\')\\n            return False                 # Returns int (or True/False, same as 1/0)\\n\\n>>> X = C()\\n>>> bool(X)\\nin nonzero\\nFalse\\n>>> if X: print(99)\\n\\nin nonzero\\n\\nBut keep in mind that __nonzero__ works in 2.X only; if used in 3.X it will be silently\\nignored  and  the  object  will  be  classified  as  true  by  default—just  like  using  3.X’s\\n__bool__ in 2.X!\\nAnd now that we’ve managed to cross over into the realm of philosophy, let’s move on\\nto look at one last overloading context: object demise.\\n\\nObject Destruction: __del__\\nIt’s time to close out this chapter—and learn how to do the same for our class objects.\\nWe’ve seen how the __init__ constructor is called whenever an instance is generated\\n(and noted how __new__ is run first to make the object). Its counterpart, the destruc-\\ntor method __del__, is run automatically when an instance’s space is being reclaimed\\n(i.e., at “garbage collection” time):\\n\\n>>> class Life:\\n        def __init__(self, name=\\'unknown\\'):\\n            print(\\'Hello \\' + name)\\n            self.name = name\\n        def live(self):\\n            print(self.name)\\n        def __del__(self):\\n            print(\\'Goodbye \\' + self.name)\\n\\nObject Destruction: __del__ | 929\\n\\n\\x0c>>> brian = Life(\\'Brian\\')\\nHello Brian\\n>>> brian.live()\\nBrian\\n>>> brian = \\'loretta\\'\\nGoodbye Brian\\n\\nHere, when brian is assigned a string, we lose the last reference to the Life instance\\nand so trigger its destructor method. This works, and it may be useful for implementing\\nsome cleanup activities, such as terminating a server connection. However, destructors\\nare not as commonly used in Python as in some OOP languages, for a number of reasons\\nthat the next section describes.\\n\\nDestructor Usage Notes\\nThe destructor method works as documented, but it has some well-known caveats and\\na few outright dark corners that make it somewhat rare to see in Python code:\\n\\n• Need: For one thing, destructors may not be as useful in Python as they are in some\\nother OOP languages. Because Python automatically reclaims all memory space\\nheld by an instance when the instance is reclaimed, destructors are not necessary\\nfor space management. In the current CPython implementation of Python, you\\nalso don’t need to close file objects held by the instance in destructors because they\\nare automatically closed when reclaimed. As mentioned in Chapter 9, though, it’s\\nstill sometimes best to run file close methods anyhow, because this autoclose be-\\nhavior may vary in alternative Python implementations (e.g., Jython).\\n\\n• Predictability: For another, you cannot always easily predict when an instance will\\nbe reclaimed. In some cases, there may be lingering references to your objects in\\nsystem tables that prevent destructors from running when your program expects\\nthem to be triggered. Python also does not guarantee that destructor methods will\\nbe called for objects that still exist when the interpreter exits.\\n\\n• Exceptions: In fact, __del__ can be tricky to use for even more subtle reasons. Ex-\\nceptions  raised  within  it,  for  example,  simply  print  a  warning  message  to\\nsys.stderr (the standard error stream) rather than triggering an exception event,\\nbecause of the unpredictable context under which it is run by the garbage collector\\n—it’s not always possible to know where such an exception should be delivered.\\n• Cycles: In addition, cyclic (a.k.a. circular) references among objects may prevent\\ngarbage collection from happening when you expect it to. An optional cycle de-\\ntector, enabled by default, can automatically collect such objects eventually, but\\nonly if they do not have __del__ methods. Since this is relatively obscure, we’ll\\nignore  further  details  here;  see  Python’s  standard  manuals’  coverage  of  both\\n__del__ and the gc garbage collector module for more information.\\n\\nBecause of these downsides, it’s often better to code termination activities in an ex-\\nplicitly called method (e.g., shutdown). As described in the next part of the book, the\\n\\n930 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0ctry/finally statement also supports termination actions, as does the with statement\\nfor objects that support its context manager model.\\n\\nChapter Summary\\nThat’s as many overloading examples as we have space for here. Most of the other\\noperator overloading methods work similarly to the ones we’ve explored, and all are\\njust hooks for intercepting built-in type operations. Some overloading methods, for\\nexample, have unique argument lists or return values, but the general usage pattern is\\nthe same. We’ll see a few others in action later in the book:\\n\\n• Chapter 34 uses __enter__ and __exit__ in with statement context managers.\\n• Chapter 38 uses the __get__ and __set__ class descriptor fetch/set methods.\\n• Chapter 40 uses the __new__ object creation method in the context of metaclasses.\\n\\nIn addition, some of the methods we’ve studied here, such as __call__ and __str__,\\nwill be employed by later examples in this book. For complete coverage, though, I’ll\\ndefer to other documentation sources—see Python’s standard language manual or ref-\\nerence books for details on additional overloading methods.\\nIn the next chapter, we leave the realm of class mechanics behind to explore common\\ndesign patterns—the ways that classes are commonly used and combined to optimize\\ncode reuse. After that, we’ll survey a handful of advanced topics and move on to ex-\\nceptions, the last core subject of this book. Before you read on, though, take a moment\\nto work through the chapter quiz below to review the concepts we’ve covered.\\n\\nTest Your Knowledge: Quiz\\n1. What two operator overloading methods can you use to support iteration in your\\n\\nclasses?\\n\\n2. What two operator overloading methods handle printing, and in what contexts?\\n3. How can you intercept slice operations in a class?\\n4. How can you catch in-place addition in a class?\\n5. When should you provide operator overloading?\\n\\nTest Your Knowledge: Answers\\n1. Classes can support iteration by defining (or inheriting) __getitem__ or __iter__.\\nIn all iteration contexts, Python tries to use __iter__ first, which returns an object\\nthat supports the iteration protocol with a __next__ method: if no __iter__ is found\\nby  inheritance  search,  Python  falls  back  on  the  __getitem__  indexing  method,\\n\\nTest Your Knowledge: Answers\\n\\n| 931\\n\\n\\x0cwhich  is  called  repeatedly,  with  successively  higher  indexes.  If  used,  the  yield\\nstatement can create the __next__ method automatically.\\n\\n2. The __str__ and __repr__ methods implement object print displays. The former is\\ncalled by the print and str built-in functions; the latter is called by print and str\\nif there is no __str__, and always by the repr built-in, interactive echoes, and nested\\nappearances. That is, __repr__ is used everywhere, except by print and str when\\na  __str__  is  defined.  A  __str__  is  usually  used  for  user-friendly  displays;\\n__repr__ gives extra details or the object’s as-code form.\\n\\n3. Slicing is caught by the __getitem__ indexing method: it is called with a slice object,\\ninstead of a simple integer index, and slice objects may be passed on or inspected\\nas needed. In Python 2.X, __getslice__ (defunct in 3.X) may be used for two-limit\\nslices as well.\\n\\n4. In-place addition tries __iadd__ first, and __add__ with an assignment second. The\\nsame pattern holds true for all binary operators. The __radd__ method is also avail-\\nable for right-side addition.\\n\\n5. When a class naturally matches, or needs to emulate, a built-in type’s interfaces.\\nFor example, collections might imitate sequence or mapping interfaces, and call-\\nables might be coded for use with an API that expects a function. You generally\\nshouldn’t implement expression operators if they don’t naturally map to your ob-\\njects naturally and logically, though—use normally named methods instead.\\n\\n932 | Chapter 30:\\u2002Operator Overloading\\n\\n\\x0cCHAPTER 31\\nDesigning with Classes\\n\\nSo far in this part of the book, we’ve concentrated on using Python’s OOP tool, the\\nclass. But OOP is also about design issues—that is, how to use classes to model useful\\nobjects. This chapter will touch on a few core OOP ideas and present some additional\\nexamples that are more realistic than many shown so far.\\nAlong  the  way,  we’ll  code  some  common  OOP  design  patterns  in  Python,  such  as\\ninheritance, composition, delegation, and factories. We’ll also investigate some design-\\nfocused  class  concepts,  such  as  pseudoprivate  attributes,  multiple  inheritance,  and\\nbound methods.\\nOne note up front: some of the design terms mentioned here require more explanation\\nthan I can provide in this book. If this material sparks your curiosity, I suggest exploring\\na text on OOP design or design patterns as a next step. As we’ll see, the good news is\\nthat Python makes many traditional design patterns trivial.\\n\\nPython and OOP\\nLet’s begin with a review—Python’s implementation of OOP can be summarized by\\nthree ideas:\\n\\nInheritance\\n\\nInheritance is based on attribute lookup in Python (in X.name expressions).\\n\\nPolymorphism\\n\\nIn X.method, the meaning of method depends on the type (class) of subject object X.\\n\\nEncapsulation\\n\\nMethods and operators implement behavior, though data hiding is a convention\\nby default.\\n\\nBy now, you should have a good feel for what inheritance is all about in Python. We’ve\\nalso talked about Python’s polymorphism a few times already; it flows from Python’s\\nlack of type declarations. Because attributes are always resolved at runtime, objects that\\n\\n933\\n\\n\\x0cimplement the same interfaces are automatically interchangeable; clients don’t need to\\nknow what sorts of objects are implementing the methods they call.\\nEncapsulation means packaging in Python—that is, hiding implementation details be-\\nhind an object’s interface. It does not mean enforced privacy, though that can be im-\\nplemented with code, as we’ll see in Chapter 39. Encapsulation is available and useful\\nin  Python  nonetheless:  it  allows  the  implementation  of  an  object’s  interface  to  be\\nchanged without impacting the users of that object.\\n\\nPolymorphism Means Interfaces, Not Call Signatures\\nSome OOP languages also define polymorphism to mean overloading functions based\\non the type signatures of their arguments—the number passed and/or their types. Be-\\ncause there are no type declarations in Python, this concept doesn’t really apply; as\\nwe’ve seen, polymorphism in Python is based on object interfaces, not types.\\nIf you’re pining for your C++ days, you can try to overload methods by their argument\\nlists, like this:\\n\\nclass C:\\n    def meth(self, x):\\n        ...\\n    def meth(self, x, y, z):\\n        ...\\n\\nThis code will run, but because the def simply assigns an object to a name in the class’s\\nscope, the last definition of the method function is the only one that will be retained.\\nPut another way, it’s just as if you say X = 1 and then X = 2; X will be 2. Hence, there\\ncan be only one definition of a method name.\\nIf they are truly required, you can always code type-based selections using the type-\\ntesting ideas we met in Chapter 4 and Chapter 9, or the argument list tools introduced\\nin Chapter 18:\\n\\nclass C:\\n    def meth(self, *args):\\n        if len(args) == 1:              # Branch on number arguments\\n            ...\\n        elif type(arg[0]) == int:       # Branch on argument types (or isinstance())\\n            ...\\n\\nYou normally shouldn’t do this, though—it’s not the Python way. As described in\\nChapter 16, you should write your code to expect only an object interface, not a specific\\ndata type. That way, it will be useful for a broader category of types and applications,\\nboth now and in the future:\\n\\nclass C:\\n    def meth(self, x):\\n        x.operation()                   # Assume x does the right thing\\n\\n934 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cIt’s also generally considered better to use distinct method names for distinct opera-\\ntions, rather than relying on call signatures (no matter what language you code in).\\nAlthough Python’s object model is straightforward, much of the art in OOP is in the\\nway we combine classes to achieve a program’s goals. The next section begins a tour\\nof some of the ways larger programs use classes to their advantage.\\n\\nOOP and Inheritance: “Is-a” Relationships\\nWe’ve explored the mechanics of inheritance in depth already, but I’d now like to show\\nyou an example of how it can be used to model real-world relationships. From a pro-\\ngrammer’s point of view, inheritance is kicked off by attribute qualifications, which\\ntrigger searches for names in instances, their classes, and then any superclasses. From\\na designer’s point of view, inheritance is a way to specify set membership: a class defines\\na set of properties that may be inherited and customized by more specific sets (i.e.,\\nsubclasses).\\nTo illustrate, let’s put that pizza-making robot we talked about at the start of this part\\nof the book to work. Suppose we’ve decided to explore alternative career paths and\\nopen a pizza restaurant (not bad, as career paths go). One of the first things we’ll need\\nto do is hire employees to serve customers, prepare the food, and so on. Being engineers\\nat heart, we’ve decided to build a robot to make the pizzas; but being politically and\\ncybernetically correct, we’ve also decided to make our robot a full-fledged employee\\nwith a salary.\\nOur pizza shop team can be defined by the four classes in the following Python 3.X and\\n2.X example file, employees.py. The most general class, Employee, provides common\\nbehavior such as bumping up salaries (giveRaise) and printing (__repr__). There are\\ntwo kinds of employees, and so two subclasses of Employee—Chef and Server. Both\\noverride the inherited work method to print more specific messages. Finally, our pizza\\nrobot is modeled by an even more specific class—PizzaRobot is a kind of Chef, which\\nis a kind of Employee. In OOP terms, we call these relationships “is-a” links: a robot is\\na chef, which is an employee. Here’s the employees.py file:\\n\\n# File employees.py (2.X + 3.X)\\nfrom __future__ import print_function\\n\\nclass Employee:\\n    def __init__(self, name, salary=0):\\n        self.name   = name\\n        self.salary = salary\\n    def giveRaise(self, percent):\\n        self.salary = self.salary + (self.salary * percent)\\n    def work(self):\\n        print(self.name, \"does stuff\")\\n    def __repr__(self):\\n        return \"<Employee: name=%s, salary=%s>\" % (self.name, self.salary)\\n\\nclass Chef(Employee):\\n\\nOOP and Inheritance: “Is-a” Relationships\\n\\n| 935\\n\\n\\x0c    def __init__(self, name):\\n        Employee.__init__(self, name, 50000)\\n    def work(self):\\n        print(self.name, \"makes food\")\\n\\nclass Server(Employee):\\n    def __init__(self, name):\\n        Employee.__init__(self, name, 40000)\\n    def work(self):\\n        print(self.name, \"interfaces with customer\")\\n\\nclass PizzaRobot(Chef):\\n    def __init__(self, name):\\n        Chef.__init__(self, name)\\n    def work(self):\\n        print(self.name, \"makes pizza\")\\n\\nif __name__ == \"__main__\":\\n    bob = PizzaRobot(\\'bob\\')       # Make a robot named bob\\n    print(bob)                    # Run inherited __repr__\\n    bob.work()                    # Run type-specific action\\n    bob.giveRaise(0.20)           # Give bob a 20% raise\\n    print(bob); print()\\n\\n    for klass in Employee, Chef, Server, PizzaRobot:\\n        obj = klass(klass.__name__)\\n        obj.work()\\n\\nWhen we run the self-test code included in this module, we create a pizza-making robot\\nnamed bob, which inherits names from three classes: PizzaRobot, Chef, and Employee.\\nFor instance, printing bob runs the Employee.__repr__ method, and giving bob a raise\\ninvokes  Employee.giveRaise  because  that’s  where  the  inheritance  search  finds  that\\nmethod:\\n\\nc:\\\\code> python employees.py\\n<Employee: name=bob, salary=50000>\\nbob makes pizza\\n<Employee: name=bob, salary=60000.0>\\n\\nEmployee does stuff\\nChef makes food\\nServer interfaces with customer\\nPizzaRobot makes pizza\\n\\nIn a class hierarchy like this, you can usually make instances of any of the classes, not\\njust the ones at the bottom. For instance, the for loop in this module’s self-test code\\ncreates instances of all four classes; each responds differently when asked to work be-\\ncause the work method is different in each. bob the robot, for example, gets work from\\nthe most specific (i.e., lowest) PizzaRobot class.\\nOf course, these classes just simulate real-world objects; work prints a message for the\\ntime being, but it could be expanded to do real work later (see Python’s interfaces to\\n\\n936 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cdevices such as serial ports, Arduino boards, and the Raspberry Pi if you’re taking this\\nsection much too literally!).\\n\\nOOP and Composition: “Has-a” Relationships\\nThe notion of composition was introduced in Chapter 26 and Chapter 28. From a\\nprogrammer’s point of view, composition involves embedding other objects in a con-\\ntainer  object,  and  activating  them  to  implement  container  methods.  To  a  designer,\\ncomposition is another way to represent relationships in a problem domain. But, rather\\nthan set membership, composition has to do with components—parts of a whole.\\nComposition also reflects the relationships between parts, called “has-a” relationships.\\nSome OOP design texts refer to composition as aggregation, or distinguish between the\\ntwo terms by using aggregation to describe a weaker dependency between container\\nand contained. In this text, a “composition” simply refers to a collection of embedded\\nobjects. The composite class generally provides an interface all its own and implements\\nit by directing the embedded objects.\\nNow that we’ve implemented our employees, let’s put them in the pizza shop and let\\nthem get busy. Our pizza shop is a composite object: it has an oven, and it has employees\\nlike servers and chefs. When a customer enters and places an order, the components\\nof the shop spring into action—the server takes the order, the chef makes the pizza,\\nand so on. The following example—file pizzashop.py—runs the same on Python 3.X\\nand 2.X and simulates all the objects and relationships in this scenario:\\n\\n# File pizzashop.py (2.X + 3.X)\\nfrom __future__ import print_function\\nfrom employees import PizzaRobot, Server\\n\\nclass Customer:\\n    def __init__(self, name):\\n        self.name = name\\n    def order(self, server):\\n        print(self.name, \"orders from\", server)\\n    def pay(self, server):\\n        print(self.name, \"pays for item to\", server)\\n\\nclass Oven:\\n    def bake(self):\\n        print(\"oven bakes\")\\n\\nclass PizzaShop:\\n    def __init__(self):\\n        self.server = Server(\\'Pat\\')         # Embed other objects\\n        self.chef   = PizzaRobot(\\'Bob\\')     # A robot named bob\\n        self.oven   = Oven()\\n\\n    def order(self, name):\\n        customer = Customer(name)           # Activate other objects\\n        customer.order(self.server)         # Customer orders from server\\n\\nOOP and Composition: “Has-a” Relationships\\n\\n| 937\\n\\n\\x0c        self.chef.work()\\n        self.oven.bake()\\n        customer.pay(self.server)\\n\\nif __name__ == \"__main__\":\\n    scene = PizzaShop()                     # Make the composite\\n    scene.order(\\'Homer\\')                    # Simulate Homer\\'s order\\n    print(\\'...\\')\\n    scene.order(\\'Shaggy\\')                   # Simulate Shaggy\\'s order\\n\\nThe PizzaShop class is a container and controller; its constructor makes and embeds\\ninstances of the employee classes we wrote in the prior section, as well as an Oven class\\ndefined here. When this module’s self-test code calls the PizzaShop order method, the\\nembedded objects are asked to carry out their actions in turn. Notice that we make a\\nnew Customer object for each order, and we pass on the embedded Server object to\\nCustomer methods; customers come and go, but the server is part of the pizza shop\\ncomposite. Also notice that employees are still involved in an inheritance relationship;\\ncomposition and inheritance are complementary tools.\\nWhen we run this module, our pizza shop handles two orders—one from Homer, and\\nthen one from Shaggy:\\n\\nc:\\\\code> python pizzashop.py\\nHomer orders from <Employee: name=Pat, salary=40000>\\nBob makes pizza\\noven bakes\\nHomer pays for item to <Employee: name=Pat, salary=40000>\\n...\\nShaggy orders from <Employee: name=Pat, salary=40000>\\nBob makes pizza\\noven bakes\\nShaggy pays for item to <Employee: name=Pat, salary=40000>\\n\\nAgain, this is mostly just a toy simulation, but the objects and interactions are repre-\\nsentative of composites at work. As a rule of thumb, classes can represent just about\\nany objects and relationships you can express in a sentence; just replace nouns with\\nclasses (e.g., Oven), and verbs with methods (e.g., bake), and you’ll have a first cut at a\\ndesign.\\n\\nStream Processors Revisited\\nFor a composition example that may be a bit more tangible than pizza-making robots,\\nrecall the generic data stream processor function we partially coded in the introduction\\nto OOP in Chapter 26:\\n\\ndef processor(reader, converter, writer):\\n    while True:\\n        data = reader.read()\\n        if not data: break\\n        data = converter(data)\\n        writer.write(data)\\n\\n938 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cRather than using a simple function here, we might code this as a class that uses com-\\nposition to do its work in order to provide more structure and support inheritance. The\\nfollowing 3.X/2.X file, streams.py, demonstrates one way to code the class:\\n\\nclass Processor:\\n    def __init__(self, reader, writer):\\n        self.reader = reader\\n        self.writer = writer\\n\\n    def process(self):\\n        while True:\\n            data = self.reader.readline()\\n            if not data: break\\n            data = self.converter(data)\\n            self.writer.write(data)\\n\\n    def converter(self, data):\\n        assert False, \\'converter must be defined\\'       # Or raise exception\\n\\nThis class defines a converter method that it expects subclasses to fill in; it’s an example\\nof the abstract superclass model we outlined in Chapter 29 (more on assert in Part VII—\\nit simply raises an exception if its test is false). Coded this way, reader and writer objects\\nare embedded within the class instance (composition), and we supply the conversion\\nlogic in a subclass rather than passing in a converter function (inheritance). The file\\nconverters.py shows how:\\n\\nfrom streams import Processor\\n\\nclass Uppercase(Processor):\\n    def converter(self, data):\\n        return data.upper()\\n\\nif __name__ == \\'__main__\\':\\n    import sys\\n    obj = Uppercase(open(\\'trispam.txt\\'), sys.stdout)\\n    obj.process()\\n\\nHere, the Uppercase class inherits the stream-processing loop logic (and anything else\\nthat may be coded in its superclasses). It needs to define only what is unique about it\\n—the data conversion logic. When this file is run, it makes and runs an instance that\\nreads from the file trispam.txt and writes the uppercase equivalent of that file to the\\nstdout stream:\\n\\nc:\\\\code> type trispam.txt\\nspam\\nSpam\\nSPAM!\\n\\nc:\\\\code> python converters.py\\nSPAM\\nSPAM\\nSPAM!\\n\\nOOP and Composition: “Has-a” Relationships\\n\\n| 939\\n\\n\\x0cTo process different sorts of streams, pass in different sorts of objects to the class con-\\nstruction call. Here, we use an output file instead of a stream:\\n\\nC:\\\\code> python\\n>>> import converters\\n>>> prog = converters.Uppercase(open(\\'trispam.txt\\'), open(\\'trispamup.txt\\', \\'w\\'))\\n>>> prog.process()\\n\\nC:\\\\code> type trispamup.txt\\nSPAM\\nSPAM\\nSPAM!\\n\\nBut, as suggested earlier, we could also pass in arbitrary objects coded as classes that\\ndefine the required input and output method interfaces. Here’s a simple example that\\npasses in a writer class that wraps up the text inside HTML tags:\\n\\nC:\\\\code> python\\n>>> from converters import Uppercase\\n>>>\\n>>> class HTMLize:\\n         def write(self, line):\\n            print(\\'<PRE>%s</PRE>\\' % line.rstrip())\\n\\n>>> Uppercase(open(\\'trispam.txt\\'), HTMLize()).process()\\n<PRE>SPAM</PRE>\\n<PRE>SPAM</PRE>\\n<PRE>SPAM!</PRE>\\n\\nIf you trace through this example’s control flow, you’ll see that we get both uppercase\\nconversion (by inheritance) and HTML formatting (by composition), even though the\\ncore processing logic in the original Processor superclass knows nothing about either\\nstep. The processing code only cares that writers have a write method and that a method\\nnamed convert is defined; it doesn’t care what those methods do when they are called.\\nSuch polymorphism and encapsulation of logic is behind much of the power of classes\\nin Python.\\nAs is, the  Processor superclass only provides a file-scanning loop. In more realistic\\nwork, we might extend it to support additional programming tools for its subclasses,\\nand, in the process, turn it into a full-blown application framework. Coding such a tool\\nonce in a superclass enables you to reuse it in all of your programs. Even in this simple\\nexample, because so much is packaged and inherited with classes, all we had to code\\nwas the HTML formatting step; the rest was free.\\nFor another example of composition at work, see exercise 9 at the end of Chapter 32\\nand its solution in Appendix D; it’s similar to the pizza shop example. We’ve focused\\non inheritance in this book because that is the main tool that the Python language itself\\nprovides for OOP. But, in practice, composition may be used as much as inheritance\\nas a way to structure classes, especially in larger systems. As we’ve seen, inheritance\\nand  composition  are  often  complementary  (and  sometimes  alternative)  techniques.\\n\\n940 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cBecause composition is a design issue outside the scope of the Python language and\\nthis book, though, I’ll defer to other resources for more on this topic.\\n\\nWhy You Will Care: Classes and Persistence\\n\\nI’ve mentioned Python’s pickle and shelve object persistence support a few times in\\nthis part of the book because it works especially well with class instances. In fact, these\\ntools are often compelling enough to motivate the use of classes in general—by pickling\\nor shelving a class instance, we get data storage that contains both data and logic com-\\nbined.\\n\\nFor example, besides allowing us to simulate real-world interactions, the pizza shop\\nclasses developed in this chapter could also be used as the basis of a persistent restaurant\\ndatabase. Instances of classes can be stored away on disk in a single step using Python’s\\npickle or shelve modules. We used shelves to store instances of classes in the OOP\\ntutorial in Chapter 28, but the object pickling interface is remarkably easy to use as well:\\n\\nimport pickle\\nobject = SomeClass()\\nfile   = open(filename, \\'wb\\')     # Create external file\\npickle.dump(object, file)         # Save object in file\\n\\nimport pickle\\nfile   = open(filename, \\'rb\\')\\nobject = pickle.load(file)        # Fetch it back later\\n\\nPickling  converts  in-memory  objects  to  serialized  byte  streams  (in  Python,  strings),\\nwhich may be stored in files, sent across a network, and so on; unpickling converts\\nback from byte streams to identical in-memory objects. Shelves are similar, but they\\nautomatically pickle objects to an access-by-key database, which exports a dictionary-\\nlike interface:\\n\\nimport shelve\\nobject = SomeClass()\\ndbase  = shelve.open(filename)\\ndbase[\\'key\\'] = object             # Save under key\\n\\nimport shelve\\ndbase  = shelve.open(filename)\\nobject = dbase[\\'key\\']             # Fetch it back later\\n\\nIn our pizza shop example, using classes to model employees means we can get a simple\\ndatabase of employees and shops with little extra work—pickling such instance objects\\nto a file makes them persistent across Python program executions:\\n\\n>>> from pizzashop import PizzaShop\\n>>> shop = PizzaShop()\\n>>> shop.server, shop.chef\\n(<Employee: name=Pat, salary=40000>, <Employee: name=Bob, salary=50000>)\\n>>> import pickle\\n>>> pickle.dump(shop, open(\\'shopfile.pkl\\', \\'wb\\'))\\n\\nThis stores an entire composite shop object in a file all at once. To bring it back later in\\nanother session or program, a single step suffices as well. In fact, objects restored this\\nway retain both state and behavior:\\n\\nOOP and Composition: “Has-a” Relationships\\n\\n| 941\\n\\n\\x0c>>> import pickle\\n>>> obj = pickle.load(open(\\'shopfile.pkl\\', \\'rb\\'))\\n>>> obj.server, obj.chef\\n(<Employee: name=Pat, salary=40000>, <Employee: name=Bob, salary=50000>)\\n\\n>>> obj.order(\\'LSP\\')\\nLSP orders from <Employee: name=Pat, salary=40000>\\nBob makes pizza\\noven bakes\\nLSP pays for item to <Employee: name=Pat, salary=40000>\\n\\nThis just runs a simulation as is, but we might extend the shop to keep track of inven-\\ntory, revenue, and so on—saving it to its file after changes would retain its updated\\nstate. See the standard library manual and related coverage in Chapter 9, Chapter 28,\\nand Chapter 37 for more on pickles and shelves.\\n\\nOOP and Delegation: “Wrapper” Proxy Objects\\nBeside inheritance and composition, object-oriented programmers often speak of del-\\negation, which usually implies controller objects that embed other objects to which\\nthey pass off operation requests. The controllers can take care of administrative activ-\\nities, such as logging or validating accesses, adding extra steps to interface components,\\nor monitoring active instances.\\nIn a sense, delegation is a special form of composition, with a single embedded object\\nmanaged by a wrapper (sometimes called a proxy) class that retains most or all of the\\nembedded object’s interface. The notion of proxies sometimes applies to other mech-\\nanisms too, such as function calls; in delegation, we’re concerned with proxies for all\\nof an object’s behavior, including method calls and other operations.\\nThis concept was introduced by example in Chapter 28, and in Python is often imple-\\nmented with the __getattr__ method hook we studied in Chapter 30. Because this\\noperator overloading method intercepts accesses to nonexistent attributes, a wrapper\\nclass can use __getattr__ to route arbitrary accesses to a wrapped object. Because this\\nmethod allows attribute requests to be routed generically, the wrapper class retains the\\ninterface of the wrapped object and may add additional operations of its own.\\nBy way of review, consider the file trace.py (which runs the same in 2.X and 3.X):\\n\\nclass Wrapper:\\n    def __init__(self, object):\\n        self.wrapped = object                    # Save object\\n    def __getattr__(self, attrname):\\n        print(\\'Trace: \\' + attrname)              # Trace fetch\\n        return getattr(self.wrapped, attrname)   # Delegate fetch\\n\\nRecall from Chapter 30 that __getattr__ gets the attribute name as a string. This code\\nmakes use of the getattr built-in function to fetch an attribute from the wrapped object\\nby name string—getattr(X,N) is like X.N, except that N is an expression that evaluates\\nto a string at runtime, not a variable. In fact, getattr(X,N) is similar to X.__dict__[N],\\n\\n942 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cbut the former also performs an inheritance search, like X.N, while the latter does not\\n(see Chapter 22 and Chapter 29 for more on the __dict__ attribute).\\nYou can use the approach of this module’s wrapper class to manage access to any object\\nwith attributes—lists, dictionaries, and even classes and instances. Here, the Wrapper\\nclass simply prints a trace message on each attribute access and delegates the attribute\\nrequest to the embedded wrapped object:\\n\\n>>> from trace import Wrapper\\n>>> x = Wrapper([1, 2, 3])                       # Wrap a list\\n>>> x.append(4)                                  # Delegate to list method\\nTrace: append\\n>>> x.wrapped                                    # Print my member\\n[1, 2, 3, 4]\\n\\n>>> x = Wrapper({\\'a\\': 1, \\'b\\': 2})                # Wrap a dictionary\\n>>> list(x.keys())                               # Delegate to dictionary method\\nTrace: keys\\n[\\'a\\', \\'b\\']\\n\\nThe net effect is to augment the entire interface of the wrapped object, with additional\\ncode in the Wrapper class. We can use this to log our method calls, route method calls\\nto extra or custom logic, adapt a class to a new interface, and so on.\\nWe’ll revive the notions of wrapped objects and delegated operations as one way to\\nextend built-in types in the next chapter. If you are interested in the delegation design\\npattern, also watch for the discussions in Chapter 32 and Chapter 39 of function dec-\\norators, a strongly related concept designed to augment a specific function or method\\ncall rather than the entire interface of an object, and class decorators, which serve as a\\nway to automatically add such delegation-based wrappers to all instances of a class.\\n\\nVersion skew note: As we saw by example in Chapter 28, delegation of\\nobject  interfaces  by  general  proxies  has  changed  substantially  in  3.X\\nwhen wrapped objects implement operator overloading methods. Tech-\\nnically, this is a new-style class difference, and can appear in 2.X code\\ntoo if it enables this option; per the next chapter, it’s mandatory in 3.X\\nand thus often considered a 3.X change.\\n\\nIn Python 2.X’s default classes, operator overloading methods run by\\nbuilt-in  operations  are  routed  through  generic  attribute  interception\\nmethods like __getattr__. Printing a wrapped object directly, for ex-\\nample, calls this method for __repr__ or __str__, which then passes the\\ncall  on  to  the  wrapped  object.  This  pattern  holds  for  __iter__,\\n__add__, and the other operator methods of the prior chapter.\\n\\nIn Python 3.X, this no longer happens: printing does not trigger __get\\nattr__ (or its __getattribute__ cousin we’ll study in the next chapter)\\nand a default display is used instead. In 3.X, new-style classes look up\\nmethods invoked implicitly by built-in operations in classes and skip\\nthe normal instance lookup entirely. Explicit name attribute fetches are\\nrouted to __getattr__ the same way in both 2.X and 3.X, but built-in\\n\\nOOP and Delegation: “Wrapper” Proxy Objects\\n\\n| 943\\n\\n\\x0coperation method lookup differs in ways that may impact some dele-\\ngation-based tools.\\n\\nWe’ll return to this issue in the next chapter as a new-style class change,\\nand see it live in Chapter 38 and Chapter 39, in the context of managed\\nattributes and decorators. For now, keep in mind that for delegation\\ncoding patterns, you may need to redefine operator overloading meth-\\nods in wrapper classes (either by hand, by tools, or by superclasses) if\\nthey are used by embedded objects and you want them to be intercepted\\nin new-style classes.\\n\\nPseudoprivate Class Attributes\\nBesides larger structuring goals, class designs often must address name usage too. In\\nChapter 28’s case study, for example, we noted that methods defined within a general\\ntool class might be modified by subclasses if exposed, and noted the tradeoffs of this\\npolicy—while it supports method customization and direct calls, it’s also open to ac-\\ncidental replacements.\\nIn  Part  V,  we  learned  that  every  name  assigned  at  the  top  level  of  a  module  file  is\\nexported.  By  default,  the  same  holds  for  classes—data  hiding  is  a  convention,  and\\nclients may fetch or change attributes in any class or instance to which they have a\\nreference. In fact, attributes are all “public” and “virtual,” in C++ terms; they’re all\\naccessible everywhere and are looked up dynamically at runtime.1\\nThat said, Python today does support the notion of name “mangling” (i.e., expansion)\\nto localize some names in classes. Mangled names are sometimes misleadingly called\\n“private attributes,” but really this is just a way to localize a name to the class that\\ncreated it—name mangling does not prevent access by code outside the class. This\\nfeature is mostly intended to avoid namespace collisions in instances, not to restrict\\naccess to names in general; mangled names are therefore better called “pseudoprivate”\\nthan “private.”\\nPseudoprivate names are an advanced and entirely optional feature, and you probably\\nwon’t find them very useful until you start writing general tools or larger class hierar-\\nchies for use in multiprogrammer projects. In fact, they are not always used even when\\nthey probably should be—more commonly, Python programmers code internal names\\nwith a single underscore (e.g., _X), which is just an informal convention to let you know\\nthat a name shouldn’t generally be changed (it means nothing to Python itself).\\n\\n1. This tends to scare people with a C++ background disproportionately. In Python, it’s even possible to\\nchange or completely delete a class’s method at runtime. On the other hand, almost nobody ever does\\nthis in practical programs. As a scripting language, Python is more about enabling than restricting. Also,\\nrecall from our discussion of operator overloading in Chapter 30 that __getattr__ and __setattr__ can\\nbe used to emulate privacy, but are generally not used for this purpose in practice. More on this when we\\ncode a more realistic privacy decorator in Chapter 39.\\n\\n944 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cBecause you may see this feature in other people’s code, though, you need to be some-\\nwhat aware of it, even if you don’t use it yourself. And once you learn its advantages\\nand contexts of use, you may find this feature to be more useful in your own code than\\nsome programmers realize.\\n\\nName Mangling Overview\\nHere’s  how  name  mangling  works:  within  a  class  statement  only,  any  names  that\\nstart with two underscores but don’t end with two underscores are automatically ex-\\npanded to include the name of the enclosing class at their front. For instance, a name\\nlike __X within a class named Spam is changed to _Spam__X automatically: the original\\nname is prefixed with a single underscore and the enclosing class’s name. Because the\\nmodified name contains the name of the enclosing class, it’s generally unique; it won’t\\nclash with similar names created by other classes in a hierarchy.\\nName mangling happens only for names that appear inside a class statement’s code,\\nand then only for names that begin with two leading underscores. It works for every\\nname  preceded  with  double  underscores,  though—both  class  attributes  (including\\nmethod names) and instance attribute names assigned to self. For example, in a class\\nnamed Spam, a method named __meth is mangled to _Spam__meth, and an instance at-\\ntribute reference self.__X is transformed to self._Spam__X.\\nDespite the mangling, as long as the class uses the double underscore version every-\\nwhere it refers to the name, all its references will still work. Because more than one class\\nmay add attributes to an instance, though, this mangling helps avoid clashes—but we\\nneed to move on to an example to see how.\\n\\nWhy Use Pseudoprivate Attributes?\\nOne of the main issues that the pseudoprivate attribute feature is meant to alleviate has\\nto do with the way instance attributes are stored. In Python, all instance attributes wind\\nup in the single instance object at the bottom of the class tree, and are shared by all\\nclass-level  method  functions  the  instance  is  passed  into.  This  is  different  from  the\\nC++ model, where each class gets its own space for data members it defines.\\nWithin a class’s method in Python, whenever a method assigns to a self attribute (e.g.,\\nself.attr = value), it changes or creates an attribute in the instance (recall that inher-\\nitance searches happen only on reference, not on assignment). Because this is true even\\nif multiple classes in a hierarchy assign to the same attribute, collisions are possible.\\nFor example, suppose that when a programmer codes a class, it is assumed that the\\nclass owns the attribute name X in the instance. In this class’s methods, the name is set,\\nand later fetched:\\n\\nclass C1:\\n    def meth1(self): self.X = 88         # I assume X is mine\\n    def meth2(self): print(self.X)\\n\\nPseudoprivate Class Attributes\\n\\n| 945\\n\\n\\x0cSuppose further that another programmer, working in isolation, makes the same as-\\nsumption in another class:\\n\\nclass C2:\\n    def metha(self): self.X = 99         # Me too\\n    def methb(self): print(self.X)\\n\\nBoth of these classes work by themselves. The problem arises if the two classes are ever\\nmixed together in the same class tree:\\n\\nclass C3(C1, C2): ...\\nI = C3()                                 # Only 1 X in I!\\n\\nNow, the value that each class gets back when it says self.X will depend on which class\\nassigned it last. Because all assignments to self.X refer to the same single instance,\\nthere is only one X attribute—I.X—no matter how many classes use that attribute name.\\nThis isn’t a problem if it’s expected, and indeed, this is how classes communicate—the\\ninstance is shared memory. To guarantee that an attribute belongs to the class that uses\\nit, though, prefix the name with double underscores everywhere it is used in the class,\\nas in this 2.X/3.X file, pseudoprivate.py:\\n\\nclass C1:\\n    def meth1(self): self.__X = 88       # Now X is mine\\n    def meth2(self): print(self.__X)     # Becomes _C1__X in I\\nclass C2:\\n    def metha(self): self.__X = 99       # Me too\\n    def methb(self): print(self.__X)     # Becomes _C2__X in I\\n\\nclass C3(C1, C2): pass\\nI = C3()                                 # Two X names in I\\n\\nI.meth1(); I.metha()\\nprint(I.__dict__)\\nI.meth2(); I.methb()\\n\\nWhen thus prefixed, the X attributes will be expanded to include the names of their\\nclasses before being added to the instance. If you run a  dir call on  I or inspect its\\nnamespace dictionary after the attributes have been assigned, you’ll see the expanded\\nnames, _C1__X and _C2__X, but not X. Because the expansion makes the names more\\nunique within the instance, the class coders can be fairly safe in assuming that they\\ntruly own any names that they prefix with two underscores:\\n\\n% python pseudoprivate.py\\n{\\'_C2__X\\': 99, \\'_C1__X\\': 88}\\n88\\n99\\n\\nThis trick can avoid potential name collisions in the instance, but note that it does not\\namount to true privacy. If you know the name of the enclosing class, you can still access\\neither of these attributes anywhere you have a reference to the instance by using the\\nfully expanded name (e.g., I._C1__X = 77). Moreover, names could still collide if un-\\nknowing programmers use the expanded naming pattern explicitly (unlikely, but not\\n\\n946 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cimpossible). On the other hand, this feature makes it less likely that you will acciden-\\ntally step on a class’s names.\\nPseudoprivate attributes are also useful in larger frameworks or tools, both to avoid\\nintroducing new method names that might accidentally hide definitions elsewhere in\\nthe class tree and to reduce the chance of internal methods being replaced by names\\ndefined lower in the tree. If a method is intended for use only within a class that may\\nbe mixed into other classes, the double underscore prefix virtually ensures that the\\nmethod won’t interfere with other names in the tree, especially in multiple-inheritance\\nscenarios:\\n\\nclass Super:\\n    def method(self): ...                  # A real application method\\n\\nclass Tool:\\n    def __method(self): ...                # Becomes _Tool__method\\n    def other(self): self.__method()       # Use my internal method\\n\\nclass Sub1(Tool, Super): ...\\n    def actions(self): self.method()       # Runs Super.method as expected\\n\\nclass Sub2(Tool):\\n    def __init__(self): self.method = 99   # Doesn\\'t break Tool.__method\\n\\nWe met multiple inheritance briefly in Chapter 26 and will explore it in more detail\\nlater in this chapter. Recall that superclasses are searched according to their left-to-right\\norder in class header lines. Here, this means Sub1 prefers Tool attributes to those in\\nSuper. Although in this example we could force Python to pick the application class’s\\nmethods first by switching the order of the superclasses listed in the Sub1 class header,\\npseudoprivate attributes resolve the issue altogether. Pseudoprivate names also prevent\\nsubclasses from accidentally redefining the internal method’s names, as in Sub2.\\nAgain, I should note that this feature tends to be of use primarily for larger, multiprog-\\nrammer projects, and then only for selected names. Don’t be tempted to clutter your\\ncode unnecessarily; only use this feature for names that truly need to be controlled by\\na single class. Although useful in some general class-based tools, for simpler programs,\\nit’s probably overkill.\\nFor more examples that make use of the __X naming feature, see the lister.py mix-in\\nclasses introduced later in this chapter in the multiple inheritance section, as well as\\nthe discussion of Private class decorators in Chapter 39.\\nIf you care about privacy in general, you might want to review the emulation of private\\ninstance attributes sketched in the section “Attribute Access: __getattr__ and __se-\\ntattr__” on page 909 in Chapter 30, and watch for the more complete Private class\\ndecorator we’ll build with delegation in Chapter 39. Although it’s possible to emulate\\ntrue access controls in Python classes, this is rarely done in practice, even for large \\nsystems.\\n\\nPseudoprivate Class Attributes\\n\\n| 947\\n\\n\\x0cMethods Are Objects: Bound or Unbound\\nMethods in general, and bound methods in particular, simplify the implementation of\\nmany design goals in Python. We met bound methods briefly while studying __call__ in\\nChapter 30. The full story, which we’ll flesh out here, turns out to be more general and\\nflexible than you might expect.\\nIn Chapter 19, we learned how functions can be processed as normal objects. Methods\\nare a kind of object too, and can be used generically in much the same way as other\\nobjects—they can be assigned to names, passed to functions, stored in data structures,\\nand so on—and like simple functions, qualify as “first class” objects. Because a class’s\\nmethods can be accessed from an instance or a class, though, they actually come in two\\nflavors in Python:\\n\\nUnbound (class) method objects: no self\\n\\nAccessing a function attribute of a class by qualifying the class returns an unbound\\nmethod object. To call the method, you must provide an instance object explicitly\\nas the first argument. In Python 3.X, an unbound method is the same as a simple\\nfunction and can be called through the class’s name; in 2.X it’s a distinct type and\\ncannot be called without providing an instance.\\n\\nBound (instance) method objects: self + function pairs\\n\\nAccessing a function attribute of a class by qualifying an instance returns a bound\\nmethod object. Python automatically packages the instance with the function in\\nthe bound method object, so you don’t need to pass an instance to call the method.\\n\\nBoth kinds of methods are full-fledged objects; they can be transferred around a pro-\\ngram at will, just like strings and numbers. Both also require an instance in their first\\nargument when run (i.e., a value for self). This is why we’ve had to pass in an instance\\nexplicitly when calling superclass methods from subclass methods in previous exam-\\nples (including this chapter’s employees.py); technically, such calls produce unbound\\nmethod objects along the way.\\nWhen calling a bound method object, Python provides an instance for you automati-\\ncally—the instance used to create the bound method object. This means that bound\\nmethod objects are usually interchangeable with simple function objects, and makes\\nthem especially useful for interfaces originally written for functions (see the sidebar\\n“Why You Will Care: Bound Method Callbacks” on page 953 for a realistic use case\\nin GUIs).\\nTo illustrate in simple terms, suppose we define the following class:\\n\\nclass Spam:\\n    def doit(self, message):\\n        print(message)\\n\\nNow, in normal operation, we make an instance and call its method in a single step to\\nprint the passed-in argument:\\n\\n948 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cobject1 = Spam()\\nobject1.doit(\\'hello world\\')\\n\\nReally,  though,  a  bound  method  object  is  generated  along  the  way,  just  before  the\\nmethod call’s parentheses. In fact, we can fetch a bound method without actually call-\\ning it. An object.name expression evaluates to an object as all expressions do. In the\\nfollowing, it returns a bound method object that packages the instance (object1) with\\nthe method function (Spam.doit). We can assign this bound method pair to another\\nname and then call it as though it were a simple function:\\n\\nobject1 = Spam()\\nx = object1.doit        # Bound method object: instance+function\\nx(\\'hello world\\')        # Same effect as object1.doit(\\'...\\')\\n\\nOn the other hand, if we qualify the class to get to doit, we get back an unbound method\\nobject, which is simply a reference to the function object. To call this type of method,\\nwe must pass in an instance as the leftmost argument—there isn’t one in the expression\\notherwise, and the method expects it:\\n\\nobject1 = Spam()\\nt = Spam.doit           # Unbound method object (a function in 3.X: see ahead)\\nt(object1, \\'howdy\\')     # Pass in instance (if the method expects one in 3.X)\\n\\nBy extension, the same rules apply within a class’s method if we reference self attributes\\nthat refer to functions in the class. A self.method expression is a bound method object\\nbecause self is an instance object:\\n\\nclass Eggs:\\n    def m1(self, n):\\n        print(n)\\n    def m2(self):\\n        x = self.m1     # Another bound method object\\n        x(42)           # Looks like a simple function\\n\\nEggs().m2()             # Prints 42\\n\\nMost  of  the  time,  you  call  methods  immediately  after  fetching  them  with  attribute\\nqualification, so you don’t always notice the method objects generated along the way.\\nBut if you start writing code that calls objects generically, you need to be careful to treat\\nunbound methods specially—they normally require an explicit instance object to be\\npassed in.\\n\\nFor an optional exception to this rule, see the discussion of static and\\nclass methods in the next chapter, and the brief mention of one in the\\nnext section. Like bound methods, static methods can masquerade as\\nbasic functions because they do not expect instances when called. For-\\nmally speaking, Python supports three kinds of class-level methods—\\ninstance, static, and class—and 3.X allows simple functions in classes,\\ntoo. Chapter 40’s metaclass methods are distinct too, but they are es-\\nsentially class methods with less scope.\\n\\nMethods Are Objects: Bound or Unbound | 949\\n\\n\\x0cUnbound Methods Are Functions in 3.X\\nIn Python 3.X, the language has dropped the notion of unbound methods. What we\\ndescribe as an unbound method here is treated as a simple function in 3.X. For most\\npurposes, this makes no difference to your code; either way, an instance will be passed\\nto a method’s first argument when it’s called through an instance.\\nPrograms that do explicit type testing might be impacted, though—if you print the type\\nof  an  instance-less  class-level  method,  it  displays  “unbound  method”  in  2.X,  and\\n“function” in 3.X.\\nMoreover, in 3.X it is OK to call a method without an instance, as long as the method\\ndoes not expect one and you call it only through the class and never through an instance.\\nThat is, Python 3.X will pass along an instance to methods only for through-instance\\ncalls. When calling through a class, you must pass an instance manually only if the\\nmethod expects one:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> class Selfless:\\n        def __init__(self, data):\\n            self.data = data\\n        def selfless(arg1, arg2):               # A simple function in 3.X\\n            return arg1 + arg2\\n        def normal(self, arg1, arg2):           # Instance expected when called\\n            return self.data + arg1 + arg2\\n\\n>>> X = Selfless(2)\\n>>> X.normal(3, 4)                  # Instance passed to self automatically: 2+(3+4)\\n9\\n>>> Selfless.normal(X, 3, 4)        # self expected by method: pass manually\\n9\\n>>> Selfless.selfless(3, 4)         # No instance: works in 3.X, fails in 2.X!\\n7\\n\\nThe last test in this fails in 2.X, because unbound methods require an instance to be\\npassed by default; it works in 3.X because such methods are treated as simple functions\\nnot requiring an instance. Although this removes some potential error trapping in 3.X\\n(what if a programmer accidentally forgets to pass an instance?), it allows a class’s\\nmethods to be used as simple functions as long as they are not passed and do not expect\\na “self” instance argument.\\nThe following two calls still fail in both 3.X and 2.X, though—the first (calling through\\nan instance) automatically passes an instance to a method that does not expect one,\\nwhile the second (calling through a class) does not pass an instance to a method that\\ndoes expect one (error message text here is per 3.3):\\n\\n>>> X.selfless(3, 4)\\nTypeError: selfless() takes 2 positional arguments but 3 were given\\n\\n>>> Selfless.normal(3, 4)\\nTypeError: normal() missing 1 required positional argument: \\'arg2\\'\\n\\n950 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cBecause of this change, the staticmethod built-in function and decorator described in\\nthe next chapter is not needed in 3.X for methods without a self argument that are\\ncalled only through the class name, and never through an instance—such methods are\\nrun as simple functions, without receiving an instance argument. In 2.X, such calls are\\nerrors unless an instance is passed manually or the method is marked as being static\\n(more on static methods in the next chapter).\\nIt’s important to be aware of the differences in behavior in 3.X, but bound methods are\\ngenerally more important from a practical perspective anyway. Because they pair to-\\ngether the instance and function in a single object, they can be treated as callables\\ngenerically. The next section demonstrates what this means in code.\\n\\nFor a more visual illustration of unbound method treatment in Python\\n3.X and 2.X, see also the lister.py example in the multiple inheritance\\nsection later in this chapter. Its classes print the value of methods fetched\\nfrom both instances and classes, in both versions of Python—as un-\\nbound methods in 2.X and simple functions in 3.X. Also note that this\\nchange is inherent in 3.X itself, not the new-style class model it man-\\ndates.\\n\\nBound Methods and Other Callable Objects\\nAs mentioned earlier, bound methods can be processed as generic objects, just like\\nsimple functions—they can be passed around a program arbitrarily. Moreover, because\\nbound methods combine both a function and an instance in a single package, they can\\nbe treated like any other callable object and require no special syntax when invoked.\\nThe following, for example, stores four bound method objects in a list and calls them\\nlater with normal call expressions:\\n\\n>>> class Number:\\n        def __init__(self, base):\\n            self.base = base\\n        def double(self):\\n            return self.base * 2\\n        def triple(self):\\n            return self.base * 3\\n\\n>>> x = Number(2)                                       # Class instance objects\\n>>> y = Number(3)                                       # State + methods\\n>>> z = Number(4)\\n>>> x.double()                                          # Normal immediate calls\\n4\\n\\n>>> acts = [x.double, y.double, y.triple, z.double]     # List of bound methods\\n>>> for act in acts:                                    # Calls are deferred\\n        print(act())                                    # Call as though functions\\n\\n4\\n6\\n\\nMethods Are Objects: Bound or Unbound | 951\\n\\n\\x0c9\\n8\\n\\nLike simple functions, bound method objects have introspection information of their\\nown, including attributes that give access to the instance object and method function\\nthey pair. Calling the bound method simply dispatches the pair:\\n\\n>>> bound = x.double\\n>>> bound.__self__, bound.__func__\\n(<__main__.Number object at 0x...etc...>, <function Number.double at 0x...etc...>)\\n>>> bound.__self__.base\\n2\\n>>> bound()                   # Calls bound.__func__(bound.__self__, ...)\\n4\\n\\nOther callables\\nIn fact, bound methods are just one of a handful of callable object types in Python. As\\nthe following demonstrates, simple functions coded with a def or lambda, instances that \\ninherit a __call__, and bound instance methods can all be treated and called the same\\nway:\\n\\n>>> def square(arg):\\n        return arg ** 2                          # Simple functions (def or lambda)\\n\\n>>> class Sum:\\n        def __init__(self, val):                 # Callable instances\\n            self.val = val\\n        def __call__(self, arg):\\n            return self.val + arg\\n\\n>>> class Product:\\n        def __init__(self, val):                 # Bound methods\\n            self.val = val\\n        def method(self, arg):\\n            return self.val * arg\\n\\n>>> sobject = Sum(2)\\n>>> pobject = Product(3)\\n>>> actions = [square, sobject, pobject.method]  # Function, instance, method\\n\\n>>> for act in actions:                          # All three called same way\\n        print(act(5))                            # Call any one-arg callable\\n\\n25\\n7\\n15\\n>>> actions[-1](5)                               # Index, comprehensions, maps\\n15\\n>>> [act(5) for act in actions]\\n[25, 7, 15]\\n>>> list(map(lambda act: act(5), actions))\\n[25, 7, 15]\\n\\n952 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cTechnically speaking, classes belong in the callable objects category too, but we nor-\\nmally call them to generate instances rather than to do actual work—a single action is\\nbetter coded as a simple function than a class with a constructor, but the class here\\nserves to illustrate its callable nature:\\n\\n>>> class Negate:\\n        def __init__(self, val):                 # Classes are callables too\\n            self.val = -val                      # But called for object, not work\\n        def __repr__(self):                      # Instance print format\\n            return str(self.val)\\n\\n>>> actions = [square, sobject, pobject.method, Negate]     # Call a class too\\n>>> for act in actions:\\n        print(act(5))\\n\\n25\\n7\\n15\\n-5\\n>>> [act(5) for act in actions]                     # Runs __repr__ not __str__!\\n[25, 7, 15, −5]\\n\\n>>> table = {act(5): act for act in actions}        # 3.X/2.7 dict comprehension\\n>>> for (key, value) in table.items():\\n        print(\\'{0:2} => {1}\\'.format(key, value))    # 2.6+/3.X str.format\\n\\n25 => <function square at 0x0000000002987400>\\n15 => <bound method Product.method of <__main__.Product object at ...etc...>>\\n-5 => <class \\'__main__.Negate\\'>\\n 7 => <__main__.Sum object at 0x000000000298BE48>\\n\\nAs you can see, bound methods, and Python’s callable objects model in general, are\\nsome of the many ways that Python’s design makes for an incredibly flexible language.\\nYou should now understand the method object model. For other examples of bound\\nmethods  at  work,  see  the  upcoming  sidebar  “Why  You  Will  Care:  Bound  Method\\nCallbacks” on page 953 as well as the prior chapter’s discussion of callback handlers\\nin the section on the method __call__.\\n\\nWhy You Will Care: Bound Method Callbacks\\n\\nBecause bound methods automatically pair an instance with a class’s method function,\\nyou can use them anywhere a simple function is expected. One of the most common\\nplaces you’ll see this idea put to work is in code that registers methods as event callback\\nhandlers in the tkinter GUI interface (named Tkinter in Python 2.X) we’ve met before.\\nAs review, here’s the simple case:\\n\\ndef handler():\\n    ...use globals or closure scopes for state...\\n...\\nwidget = Button(text=\\'spam\\', command=handler)\\n\\nTo register a handler for button click events, we usually pass a callable object that takes\\nno arguments to the command keyword argument. Function names (and lambdas) work\\n\\nMethods Are Objects: Bound or Unbound | 953\\n\\n\\x0chere, and so do class-level methods—though they must be bound methods if they ex-\\npect an instance when called:\\n\\nclass MyGui:\\n    def handler(self):\\n        ...use self.attr for state...\\n    def makewidgets(self):\\n        b = Button(text=\\'spam\\', command=self.handler)\\n\\nHere, the event handler is self.handler—a bound method object that remembers both\\nself and MyGui.handler. Because self will refer to the original instance when handler\\nis later invoked on events, the method will have access to instance attributes that can\\nretain state between events, as well as class-level methods. With simple functions, state\\nnormally must be retained in global variables or enclosing function scopes instead.\\nSee also the discussion of __call__ operator overloading in Chapter 30 for another way\\nto make classes compatible with function-based APIs, and lambda in Chapter 19 for\\nanother tool often used in callback roles. As noted in the former of these, you don’t\\ngenerally need to wrap a bound method in a lambda; the bound method in the preceding\\nexample already defers the call (note that there are no parentheses to trigger one), so\\nadding a lambda here would be pointless!\\n\\nClasses Are Objects: Generic Object Factories\\nSometimes, class-based designs require objects to be created in response to conditions\\nthat can’t be predicted when a program is written. The factory design pattern allows\\nsuch a deferred approach. Due in large part to Python’s flexibility, factories can take\\nmultiple forms, some of which don’t seem special at all.\\nBecause classes are also “first class” objects, it’s easy to pass them around a program,\\nstore them in data structures, and so on. You can also pass classes to functions that\\ngenerate arbitrary kinds of objects; such functions are sometimes called factories in\\nOOP design circles. Factories can be a major undertaking in a strongly typed language\\nsuch as C++ but are almost trivial to implement in Python.\\nFor example, the call syntax we met in Chapter 18 can call any class with any number\\nof positional or keyword constructor arguments in one step to generate any sort of \\ninstance:2\\n\\ndef factory(aClass, *pargs, **kargs):        # Varargs tuple, dict\\n    return aClass(*pargs, **kargs)           # Call aClass (or apply in 2.X only)\\n\\nclass Spam:\\n\\n2. Actually, this syntax can invoke any callable object, including functions, classes, and methods. Hence,\\nthe factory function here can also run any callable object, not just a class (despite the argument name).\\nAlso,  as  we  learned  in  Chapter  18,  Python  2.X  has  an  alternative  to  aClass(*pargs,  **kargs):  the\\napply(aClass,  pargs,  kargs)  built-in  call,  which  has  been  removed  in  Python  3.X  because  of  its\\nredundancy and limitations.\\n\\n954 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0c    def doit(self, message):\\n        print(message)\\n\\nclass Person:\\n    def __init__(self, name, job=None):\\n        self.name = name\\n        self.job  = job\\n\\nobject1 = factory(Spam)                      # Make a Spam object\\nobject2 = factory(Person, \"Arthur\", \"King\")  # Make a Person object\\nobject3 = factory(Person, name=\\'Brian\\')      # Ditto, with keywords and default\\n\\nIn this code, we define an object generator function called factory. It expects to be\\npassed a class object (any class will do) along with one or more arguments for the class’s\\nconstructor. The function uses special “varargs” call syntax to call the function and\\nreturn an instance.\\nThe rest of the example simply defines two classes and generates instances of both by\\npassing them to the factory function. And that’s the only factory function you’ll ever\\nneed to write in Python; it works for any class and any constructor arguments. If you\\nrun this live (factory.py), your objects will look like this:\\n\\n>>> object1.doit(99)\\n99\\n>>> object2.name, object2.job\\n(\\'Arthur\\', \\'King\\')\\n>>> object3.name, object3.job\\n(\\'Brian\\', None)\\n\\nBy now, you should know that everything is a “first class” object in Python—including\\nclasses, which are usually just compiler input in languages like C++. It’s natural to pass\\nthem around this way. As mentioned at the start of this part of the book, though, only\\nobjects derived from classes do full OOP in Python.\\n\\nWhy Factories?\\nSo what good is the factory function (besides providing an excuse to illustrate first-\\nclass class objects in this book)? Unfortunately, it’s difficult to show applications of\\nthis design pattern without listing much more code than we have space for here. In\\ngeneral, though, such a factory might allow code to be insulated from the details of\\ndynamically configured object construction.\\nFor instance, recall the processor example presented in the abstract in Chapter 26, and\\nthen again as a composition example earlier in this chapter. It accepts reader and writer\\nobjects  for  processing  arbitrary  data  streams.  The  original  version  of  this  example\\nmanually passed in instances of specialized classes like FileWriter and SocketReader to\\ncustomize the data streams being processed; later, we passed in hardcoded file, stream,\\nand formatter objects. In a more dynamic scenario, external devices such as configu-\\nration files or GUIs might be used to configure the streams.\\n\\nClasses Are Objects: Generic Object Factories\\n\\n| 955\\n\\n\\x0cIn such a dynamic world, we might not be able to hardcode the creation of stream\\ninterface objects in our scripts, but might instead create them at runtime according to\\nthe contents of a configuration file.\\nSuch a file might simply give the string name of a stream class to be imported from a\\nmodule, plus an optional constructor call argument. Factory-style functions or code\\nmight come in handy here because they would allow us to fetch and pass in classes that\\nare not hardcoded in our program ahead of time. Indeed, those classes might not even\\nhave existed at all when we wrote our code:\\n\\nclassname = ...parse from config file...\\nclassarg  = ...parse from config file...\\n\\nimport streamtypes                           # Customizable code\\naclass = getattr(streamtypes, classname)     # Fetch from module\\nreader = factory(aclass, classarg)           # Or aclass(classarg)\\nprocessor(reader, ...)\\n\\nHere, the getattr built-in is again used to fetch a module attribute given a string name\\n(it’s like saying obj.attr, but attr is a string). Because this code snippet assumes a\\nsingle constructor argument, it doesn’t strictly need factory—we could make an in-\\nstance with just aclass(classarg). The factory function may prove more useful in the\\npresence of unknown argument lists, however, and the general factory coding pattern\\ncan improve the code’s flexibility.\\n\\nMultiple Inheritance: “Mix-in” Classes\\nOur last design pattern is one of the most useful, and will serve as a subject for a more\\nrealistic example to wrap up this chapter and point toward the next. As a bonus, the\\ncode we’ll write here may be a useful tool.\\nMany class-based designs call for combining disparate sets of methods. As we’ve seen,\\nin a class statement, more than one superclass can be listed in parentheses in the header\\nline. When you do this, you leverage multiple inheritance—the class and its instances\\ninherit names from all the listed superclasses.\\nWhen searching for an attribute, Python’s inheritance search traverses all superclasses\\nin the class header from left to right until a match is found. Technically, because any\\nof the superclasses may have superclasses of its own, this search can be a bit more\\ncomplex for larger class trees:\\n\\n• In classic classes (the default until Python 3.0), the attribute search in all cases\\nproceeds depth-first all the way to the top of the inheritance tree, and then from\\nleft to right. This order is usually called DFLR, for its depth-first, left-to-right path.\\n• In new-style classes (optional in 2.X and standard in 3.X), the attribute search is\\nusually as before, but in diamond patterns proceeds across by tree levels before\\nmoving up, in a more breadth-first fashion. This order is usually called the new-\\n\\n956 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cstyle MRO, for method resolution order, though it’s used for all attributes, not just\\nmethods.\\n\\nThe second of these search rules is explained fully in the new-style class discussion in\\nthe next chapter. Though difficult to understand without the next chapter’s code (and\\nsomewhat rare to create yourself), diamond patterns appear when multiple classes in a\\ntree share a common superclass; the new-style search order is designed to visit such a\\nshared superclass just once, and after all its subclasses. In either model, though, when\\na class has multiple superclasses, they are searched from left to right according to the\\norder listed in the class statement header lines.\\nIn general, multiple inheritance is good for modeling objects that belong to more than\\none set. For instance, a person may be an engineer, a writer, a musician, and so on, and\\ninherit properties from all such sets. With multiple inheritance, objects obtain the un-\\nion of the behavior in all their superclasses. As we’ll see ahead, multiple inheritance\\nalso allows classes to function as general packages of mixable attributes.\\nThough a useful pattern, multiple inheritance’s chief downside is that it can pose a\\nconflict when the same method (or other attribute) name is defined in more than one\\nsuperclass. When this occurs, the conflict is resolved either automatically by the in-\\nheritance search order, or manually in your code:\\n\\n• Default: By default, inheritance chooses the first occurrence of an attribute it finds\\nwhen an attribute is referenced normally—by self.method(), for example. In this\\nmode, Python chooses the lowest and leftmost in classic classes, and in nondia-\\nmond patterns in all classes; new-style classes may choose an option to the right\\nbefore one above in diamonds.\\n\\n• Explicit: In some class models, you may sometimes need to select an attribute ex-\\nplicitly by referencing it through its class name—with superclass.method(self),\\nfor instance. Your code breaks the conflict and overrides the search’s default—to\\nselect an option to the right of or above the inheritance search’s default.\\n\\nThis is an issue only when the same name appears in multiple superclasses, and you do\\nnot wish to use the first one inherited. Because this isn’t as common an issue in typical\\nPython code as it may sound, we’ll defer details on this topic until we study new-style\\nclasses and their MRO and super tools in the next chapter, and revisit this as a “gotcha”\\nat the end of that chapter. First, though, the next section demonstrates a practical use\\ncase for multiple inheritance-based tools.\\n\\nCoding Mix-in Display Classes\\nPerhaps the most common way multiple inheritance is used is to “mix in” general-\\npurpose methods from superclasses. Such superclasses are usually called mix-in classes\\n—they provide methods you add to application classes by inheritance. In a sense, mix-\\nin classes are similar to modules: they provide packages of methods for use in their\\nclient  subclasses.  Unlike  simple  functions  in  modules,  though,  methods  in  mix-in\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 957\\n\\n\\x0cclasses also can participate in inheritance hierarchies, and have access to the self in-\\nstance for using state information and other methods in their trees.\\nFor example, as we’ve seen, Python’s default way to print a class instance object isn’t\\nincredibly useful:\\n>>> class Spam:\\n        def __init__(self):                     # No __repr__ or __str__\\n            self.data1 = \"food\"\\n\\n>>> X = Spam()\\n>>> print(X)                                    # Default: class name + address (id)\\n<__main__.Spam object at 0x00000000029CA908>    # Same in 2.X, but says \"instance\"\\n\\nAs you saw in both Chapter 28’s case study and Chapter 30’s operator overloading\\ncoverage, you can provide a __str__ or __repr__ method to implement a custom string\\nrepresentation of your own. But, rather than coding one of these in each and every class\\nyou wish to print, why not code it once in a general-purpose tool class and inherit it in\\nall your classes?\\nThat’s what mix-ins are for. Defining a display method in a mix-in superclass once\\nenables us to reuse it anywhere we want to see a custom display format—even in classes\\nthat may already have another superclass. We’ve already seen tools that do related\\nwork:\\n\\n• Chapter  28’s  AttrDisplay  class  formatted  instance  attributes  in  a  generic\\n__repr__ method, but it did not climb class trees and was utilized in single-inher-\\nitance mode only.\\n\\n• Chapter  29’s  classtree.py  module  defined  functions  for  climbing  and  sketching\\nclass trees, but it did not display object attributes along the way and was not ar-\\nchitected as an inheritable class.\\n\\nHere, we’re going to revisit these examples’ techniques and expand upon them to code\\na set of three mix-in classes that serve as generic display tools for listing instance at-\\ntributes, inherited attributes, and attributes on all objects in a class tree. We’ll also use\\nour tools in multiple-inheritance mode and deploy coding techniques that make classes\\nbetter suited to use as generic tools.\\nUnlike Chapter 28, we’ll also code this with a __str__ instead of a __repr__. This is\\npartially a style issue and limits their role to print and str, but the displays we’ll be\\ndeveloping will be rich enough to be categorized as more user-friendly than as-code.\\nThis policy also leaves client classes the option of coding an alternative lower-level\\ndisplay  for  interactive  echoes  and  nested  appearances  with  a  __repr__.  Using\\n__repr__ here would still allow an alternative __str__, but the nature of the displays\\nwe’ll be implementing more strongly suggests a __str__ role. See Chapter 30 for a review\\nof these distinctions.\\n\\n958 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cListing instance attributes with __dict__\\nLet’s get started with the simple case—listing attributes attached to an instance. The\\nfollowing class, coded in the file listinstance.py, defines a mix-in called ListInstance\\nthat overloads the __str__ method for all classes that include it in their header lines.\\nBecause this is coded as a class, ListInstance is a generic tool whose formatting logic\\ncan be used for instances of any subclass client:\\n\\n#!python\\n# File listinstance.py (2.X + 3.X)\\n\\nclass ListInstance:\\n    \"\"\"\\n    Mix-in class that provides a formatted print() or str() of instances via\\n    inheritance of __str__ coded here;  displays instance attrs only;  self is\\n    instance of lowest class; __X names avoid clashing with client\\'s attrs\\n    \"\"\"\\n    def __attrnames(self):\\n        result = \\'\\'\\n        for attr in sorted(self.__dict__):\\n            result += \\'\\\\t%s=%s\\\\n\\' % (attr, self.__dict__[attr])\\n        return result\\n\\n    def __str__(self):\\n        return \\'<Instance of %s, address %s:\\\\n%s>\\' % (\\n                           self.__class__.__name__,         # My class\\'s name\\n                           id(self),                        # My address\\n                           self.__attrnames())              # name=value list\\n\\nif __name__ == \\'__main__\\':\\n    import testmixin\\n    testmixin.tester(ListInstance)\\n\\nAll the code in this section runs in both Python 2.X and 3.X. A coding note: this code\\nexhibits a classic comprehension pattern, and you could save some program real estate\\nby implementing the __attrnames method here more concisely with a generator ex-\\npression that is triggered by the string join method, but it’s arguably less clear—ex-\\npressions that wrap lines like this should generally make you consider simpler coding\\nalternatives:\\n\\n    def __attrnames(self):\\n        return \\'\\'.join(\\'\\\\t%s=%s\\\\n\\' % (attr, self.__dict__ [attr])\\n                          for attr in sorted(self.__dict__))\\n\\nListInstance uses some previously explored tricks to extract the instance’s class name\\nand attributes:\\n\\n• Each instance has a built-in __class__ attribute that references the class from which\\nit was created, and each class has a __name__ attribute that references the name in\\nthe header, so the expression self.__class__.__name__ fetches the name of an in-\\nstance’s class.\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 959\\n\\n\\x0c• This class does most of its work by simply scanning the instance’s attribute dic-\\ntionary  (remember,  it’s  exported  in  __dict__)  to  build  up  a  string  showing  the\\nnames and values of all instance attributes. The dictionary’s keys are sorted to\\nfinesse any ordering differences across Python releases.\\n\\nIn these respects, ListInstance is similar to Chapter 28’s attribute display; in fact, it’s\\nlargely  just  a  variation  on  a  theme.  Our  class  here  uses  two  additional  techniques,\\nthough:\\n\\n• It displays the instance’s memory address by calling the id built-function, which\\nreturns any object’s address (by definition, a unique object identifier, which will\\nbe useful in later mutations of this code).\\n\\n• It uses the pseudoprivate naming pattern for its worker method: __attrnames. As\\nwe learned earlier in this chapter, Python automatically localizes any such name\\nto its enclosing class by expanding the attribute name to include the class name (in\\nthis case, it becomes  _ListInstance__attrnames). This holds true for both class\\nattributes  (like  methods)  and  instance  attributes  attached  to  self.  As  noted  in\\nChapter 28’s first-cut version, this behavior is useful in a general tool like this, as\\nit ensures that its names don’t clash with any names used in its client subclasses.\\n\\nBecause ListInstance defines a __str__ operator overloading method, instances de-\\nrived from this class display their attributes automatically when printed, giving a bit\\nmore information than a simple address. Here is the class in action, in single-inheritance\\nmode, mixed in to the previous section’s class (this code works the same in both Python\\n3.X and 2.X, though 2.X default repr displays use the label “instance” instead of “ob-\\nject”):\\n\\n>>> from listinstance import ListInstance\\n>>> class Spam(ListInstance):                    # Inherit a __str__ method\\n        def __init__(self):\\n            self.data1 = \\'food\\'\\n\\n>>> x = Spam()\\n>>> print(x)                                     # print() and str() run __str__\\n<Instance of Spam, address 43034496:\\n        data1=food\\n>\\n\\nYou can also fetch and save the listing output as a string without printing it with str,\\nand interactive echoes still use the default format because we’re left __repr__ as an\\noption for clients:\\n\\n>>> display = str(x)                             # Print this to interpret escapes\\n>>> display\\n\\'<Instance of Spam, address 43034496:\\\\n\\\\tdata1=food\\\\n>\\'\\n\\n>>> x                                            # The __repr__ still is a default\\n<__main__.Spam object at 0x000000000290A780>\\n\\n960 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cThe ListInstance class is useful for any classes you write—even classes that already\\nhave one or more superclasses. This is where multiple inheritance comes in handy: by\\nadding ListInstance to the list of superclasses in a class header (i.e., mixing it in), you\\nget its __str__ “for free” while still inheriting from the existing superclass(es). The file\\ntestmixin0.py demonstrates with a first-cut testing script:\\n\\n# File testmixin0.py\\nfrom listinstance import ListInstance # Get lister tool class\\n\\nclass Super:\\n    def __init__(self):               # Superclass __init__\\n        self.data1 = \\'spam\\'           # Create instance attrs\\n    def ham(self):\\n        pass\\n\\nclass Sub(Super, ListInstance):       # Mix in ham and a __str__\\n    def __init__(self):               # Listers have access to self\\n        Super.__init__(self)\\n        self.data2 = \\'eggs\\'           # More instance attrs\\n        self.data3 = 42\\n    def spam(self):                   # Define another method here\\n        pass\\n\\nif __name__ == \\'__main__\\':\\n    X = Sub()\\n    print(X)                          # Run mixed-in __str__\\n\\nHere, Sub inherits names from both Super and ListInstance; it’s a composite of its own\\nnames and names in both its superclasses. When you make a Sub instance and print it,\\nyou automatically get the custom representation mixed in from ListInstance (in this\\ncase, this script’s output is the same under both Python 3.X and 2.X, except for object\\naddresses, which can naturally vary per process):\\n\\nc:\\\\code> python testmixin0.py\\n<Instance of Sub, address 44304144:\\n        data1=spam\\n        data2=eggs\\n        data3=42\\n>\\n\\nThis testmixin0 testing script works, but it hardcodes the tested class’s name in the\\ncode, and makes it difficult to experiment with alternatives—as we will in a moment.\\nTo be more flexible, we can borrow a page from Chapter 25’s module reloaders, and\\npass in the object to be tested, as in the following improved test script, testmixin—the\\none actually used by all the lister class modules’ self-test code. In this context the object\\npassed in to the tester is a mix-in class instead of a function, but the principle is similar:\\neverything qualifies as a passable “first class” object in Python:\\n\\n#!python\\n# File testmixin.py (2.X + 3.X)\\n\"\"\"\\nGeneric lister mixin tester: similar to transitive reloader in\\nChapter 25, but passes a class object to tester (not function),\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 961\\n\\n\\x0cand testByNames adds loading of both module and class by name\\nstrings here, in keeping with Chapter 31\\'s factories pattern.\\n\"\"\"\\nimport importlib\\n\\ndef tester(listerclass, sept=False):\\n\\n    class Super:\\n        def __init__(self):            # Superclass __init__\\n            self.data1 = \\'spam\\'        # Create instance attrs\\n        def ham(self):\\n            pass\\n\\n    class Sub(Super, listerclass):     # Mix in ham and a __str__\\n        def __init__(self):            # Listers have access to self\\n            Super.__init__(self)\\n            self.data2 = \\'eggs\\'        # More instance attrs\\n            self.data3 = 42\\n        def spam(self):                # Define another method here\\n            pass\\n\\n    instance = Sub()                   # Return instance with lister\\'s __str__\\n    print(instance)                    # Run mixed-in __str__ (or via str(x))\\n    if sept: print(\\'-\\' * 80)\\n\\ndef testByNames(modname, classname, sept=False):\\n    modobject   = importlib.import_module(modname)  # Import by namestring\\n    listerclass = getattr(modobject, classname)     # Fetch attr by namestring\\n    tester(listerclass, sept)\\n\\nif __name__ == \\'__main__\\':\\n    testByNames(\\'listinstance\\',  \\'ListInstance\\',  True)      # Test all three here\\n    testByNames(\\'listinherited\\', \\'ListInherited\\', True)\\n    testByNames(\\'listtree\\',      \\'ListTree\\',      False)\\n\\nWhile it’s at it, this script also adds the ability to specify test module and class by name\\nstring, and leverages this in its self-test code—an application of the factory pattern’s\\nmechanics described earlier. Here is the new script in action, being run by the lister\\nmodule that imports it to test its own class (with the same results in 2.X and 3.X again);\\nwe can run the test script itself too, but that mode tests the two lister variants, which\\nwe have yet to see (or code!):\\n\\nc:\\\\code> python listinstance.py\\n<Instance of Sub, address 43256968:\\n        data1=spam\\n        data2=eggs\\n        data3=42\\n>\\n\\nc:\\\\code> python testmixin.py\\n<Instance of Sub, address 43977584:\\n        data1=spam\\n        data2=eggs\\n        data3=42\\n\\n962 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0c>\\n...and tests of two other lister classes coming up...\\n\\nThe ListInstance class we’ve coded so far works in any class it’s mixed into because\\nself refers to an instance of the subclass that pulls this class in, whatever that may be.\\nAgain,  in  a  sense,  mix-in  classes  are  the  class  equivalent  of  modules—packages  of\\nmethods useful in a variety of clients. For example, here is ListInstance working again\\nin single-inheritance mode on a different class’s instances, loaded with  import, and\\ndisplaying attributes assigned outside the class:\\n\\n>>> import listinstance\\n>>> class C(listinstance.ListInstance): pass\\n\\n>>> x = C()\\n>>> x.a, x.b, x.c = 1, 2, 3\\n>>> print(x)\\n<Instance of C, address 43230824:\\n        a=1\\n        b=2\\n        c=3\\n>\\n\\nBesides the utility they provide, mix-ins optimize code maintenance, like all classes do.\\nFor example, if you later decide to extend ListInstance’s __str__ to also print all the\\nclass attributes that an instance inherits, you’re safe; because it’s an inherited method,\\nchanging __str__ automatically updates the display of each subclass that imports the\\nclass and mixes it in. And since it’s now officially “later,” let’s move on to the next\\nsection to see what such an extension might look like.\\n\\nListing inherited attributes with dir\\nAs it is, our ListerInstance mix-in displays instance attributes only (i.e., names at-\\ntached to the instance object itself). It’s trivial to extend the class to display all the\\nattributes accessible from an instance, though—both its own and those it inherits from\\nits classes. The trick is to use the dir built-in function instead of scanning the instance’s\\n__dict__ dictionary; the latter holds instance attributes only, but the former also col-\\nlects all inherited attributes in Python 2.2 and later.\\nThe following mutation codes this scheme; I’ve coded this in its own module to facil-\\nitate simple testing, but if existing clients were to use this version instead they would\\npick up the new display automatically (and recall from Chapter 25 that an import’s\\nas clause can rename a new version to a prior name being used):\\n\\n#!python\\n# File listinherited.py (2.X + 3.X)\\n\\nclass ListInherited:\\n    \"\"\"\\n    Use dir() to collect both instance attrs and names inherited from\\n    its classes;  Python 3.X shows more names than 2.X because of the\\n    implied object superclass in the new-style class model;  getattr()\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 963\\n\\n\\x0c    fetches inherited names not in self.__dict__;  use __str__, not\\n    __repr__, or else this loops when printing bound methods!\\n    \"\"\"\\n    def __attrnames(self):\\n        result = \\'\\'\\n        for attr in dir(self):                              # Instance dir()\\n            if attr[:2] == \\'__\\' and attr[-2:] == \\'__\\':      # Skip internals\\n                result += \\'\\\\t%s\\\\n\\' % attr\\n            else:\\n                result += \\'\\\\t%s=%s\\\\n\\' % (attr, getattr(self, attr))\\n        return result\\n\\n    def __str__(self):\\n        return \\'<Instance of %s, address %s:\\\\n%s>\\' % (\\n                           self.__class__.__name__,         # My class\\'s name\\n                           id(self),                        # My address\\n                           self.__attrnames())              # name=value list\\n\\nif __name__ == \\'__main__\\':\\n    import testmixin\\n    testmixin.tester(ListInherited)\\n\\nNotice that this code skips __X__ names’ values; most of these are internal names that\\nwe don’t generally care about in a generic listing like this. This version also must use\\nthe getattr built-in function to fetch attributes by name string instead of using instance\\nattribute dictionary indexing—getattr employs the inheritance search protocol, and\\nsome of the names we’re listing here are not stored on the instance itself.\\nTo test the new version, run its file directly—it passes the class it defines to the test-\\nmixin.py file’s test function to be used as a mix-in in a subclass. This output of this test\\nand lister class varies per release, though, because dir results differ. In Python 2.X, we\\nget the following; notice the name mangling at work in the lister’s method name (I\\ntruncated some of the full value displays to fit on this page):\\n\\nc:\\\\code> c:\\\\python27\\\\python listinherited.py\\n<Instance of Sub, address 35161352:\\n        _ListInherited__attrnames=<bound method Sub.__attrnames of <test...more...>>\\n        __doc__\\n        __init__\\n        __module__\\n        __str__\\n        data1=spam\\n        data2=eggs\\n        data3=42\\n        ham=<bound method Sub.ham of <testmixin.Sub instance at 0x00000...more...>>\\n        spam=<bound method Sub.spam of <testmixin.Sub instance at 0x00000...more...>>\\n>\\n\\nIn Python 3.X, more attributes are displayed because all classes are “new style” and\\ninherit names from the implied object superclass; more on this in Chapter 32. Because\\nso many names are inherited from the default superclass, I’ve omitted many here—\\nthere are 32 in total in 3.3. Run this on your own for the full listing:\\n\\n964 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cc:\\\\code> c:\\\\python33\\\\python listinherited.py\\n<Instance of Sub, address 43253152:\\n        _ListInherited__attrnames=<bound method Sub.__attrnames of <test...more...>>\\n        __class__\\n        __delattr__\\n        __dict__\\n        __dir__\\n        __doc__\\n        __eq__\\n        ...more names omitted 32 total...\\n        __repr__\\n        __setattr__\\n        __sizeof__\\n        __str__\\n        __subclasshook__\\n        __weakref__\\n        data1=spam\\n        data2=eggs\\n        data3=42\\n        ham=<bound method Sub.ham of <testmixin.tester.<locals>.Sub ...more...>>\\n        spam=<bound method Sub.spam of <testmixin.tester.<locals>.Sub ...more...>>\\n>\\n\\nAs one possible improvement to address the proliferation of inherited built-in names\\nand  long  values  here,  the  following  alternative  for  ___attrnames  in  file  listinheri-\\nted2.py of the book example’s package groups the double-underscore names separately,\\nand minimizes line wrapping for large attribute values; notice how it escapes a % with\\n%% so that just one remains for the final formatting operation at the end:\\n\\n    def __attrnames(self, indent=\\' \\'*4):\\n        result  = \\'Unders%s\\\\n%s%%s\\\\nOthers%s\\\\n\\' % (\\'-\\'*77, indent, \\'-\\'*77)\\n        unders = []\\n        for attr in dir(self):                              # Instance dir()\\n            if attr[:2] == \\'__\\' and attr[-2:] == \\'__\\':      # Skip internals\\n                unders.append(attr)\\n            else:\\n                display = str(getattr(self, attr))[:82-(len(indent) + len(attr))]\\n                result += \\'%s%s=%s\\\\n\\' % (indent, attr, display)\\n        return result % \\', \\'.join(unders)\\n\\nWith this change, the class’s test output is a bit more sophisticated, but also more\\nconcise and usable:\\n\\nc:\\\\code> c:\\\\python27\\\\python listinherited2.py\\n<Instance of Sub, address 36299208:\\nUnders-----------------------------------------------------------------------------\\n    __doc__, __init__, __module__, __str__\\nOthers-----------------------------------------------------------------------------\\n    _ListInherited__attrnames=<bound method Sub.__attrnames of <testmixin.Sub insta\\n    data1=spam\\n    data2=eggs\\n    data3=42\\n    ham=<bound method Sub.ham of <testmixin.Sub instance at 0x000000000229E1C8>>\\n    spam=<bound method Sub.spam of <testmixin.Sub instance at 0x000000000229E1C8>>\\n>\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 965\\n\\n\\x0cc:\\\\code> c:\\\\python33\\\\python listinherited2.py\\n<Instance of Sub, address 43318912:\\nUnders-----------------------------------------------------------------------------\\n    __class__, __delattr__, __dict__, __dir__, __doc__, __eq__, __format__, __ge__,\\n__getattribute__, __gt__, __hash__, __init__, __le__, __lt__, __module__, __ne__,\\n__new__, __qualname__, __reduce__, __reduce_ex__, __repr__, __setattr__, __sizeof__,\\n__str__, __subclasshook__, __weakref__\\nOthers-----------------------------------------------------------------------------\\n    _ListInherited__attrnames=<bound method Sub.__attrnames of <testmixin.tester.<l\\n    data1=spam\\n    data2=eggs\\n    data3=42\\n    ham=<bound method Sub.ham of <testmixin.tester.<locals>.Sub object at 0x0000000\\n    spam=<bound method Sub.spam of <testmixin.tester.<locals>.Sub object at 0x00000\\n>\\n\\nDisplay  format  is  an  open-ended  problem  (e.g.,  Python’s  standard  pprint  “pretty\\nprinter” module may offer options here too), so we’ll leave further polishing as a sug-\\ngested exercise. The tree lister of the next section may be more useful in any event.\\n\\nLooping in __repr__: One caution here—now that we’re displaying in-\\nherited  methods  too,  we  have  to  use  __str__  instead  of  __repr__  to\\noverload printing. With __repr__, this code will fall into recursive loops\\n—displaying the value of a method triggers the __repr__ of the method’s\\nclass, in order to display the class. That is, if the lister’s __repr__ tries\\nto display a method, displaying the method’s class will trigger the lister’s\\n__repr__ again. Subtle, but true! Change __str__ to __repr__ here to see\\nthis for yourself. If you must use __repr__ in such a context, you can\\navoid the loops by using isinstance to compare the type of attribute\\nvalues against types.MethodType in the standard library, to know which\\nitems to skip.\\n\\nListing attributes per object in class trees\\nLet’s code one last extension. As it is, our latest lister includes inherited names, but\\ndoesn’t give any sort of designation of the classes from which the names are acquired.\\nAs we saw in the classtree.py example near the end of Chapter 29, though, it’s straight-\\nforward to climb class inheritance trees in code. The following mix-in class, coded in\\nthe file listtree.py, makes use of this same technique to display attributes grouped by\\nthe classes they live in—it sketches the full physical class tree, displaying attributes\\nattached to each object along the way. The reader must still infer attribute inheritance,\\nbut this gives substantially more detail than a simple flat list:\\n\\n#!python\\n# File listtree.py (2.X + 3.X)\\n\\nclass ListTree:\\n    \"\"\"\\n    Mix-in that returns an __str__ trace of the entire class tree and all\\n\\n966 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0c    its objects\\' attrs at and above self;  run by print(), str() returns\\n    constructed string;  uses __X attr names to avoid impacting clients;\\n    recurses to superclasses explicitly, uses str.format() for clarity;\\n    \"\"\"\\n    def __attrnames(self, obj, indent):\\n        spaces = \\' \\' * (indent + 1)\\n        result = \\'\\'\\n        for attr in sorted(obj.__dict__):\\n            if attr.startswith(\\'__\\') and attr.endswith(\\'__\\'):\\n                result += spaces + \\'{0}\\\\n\\'.format(attr)\\n            else:\\n                result += spaces + \\'{0}={1}\\\\n\\'.format(attr, getattr(obj, attr))\\n        return result\\n\\n    def __listclass(self, aClass, indent):\\n        dots = \\'.\\' * indent\\n        if aClass in self.__visited:\\n            return \\'\\\\n{0}<Class {1}:, address {2}: (see above)>\\\\n\\'.format(\\n                           dots,\\n                           aClass.__name__,\\n                           id(aClass))\\n        else:\\n            self.__visited[aClass] = True\\n            here  = self.__attrnames(aClass, indent)\\n            above = \\'\\'\\n            for super in aClass.__bases__:\\n                above += self.__listclass(super, indent+4)\\n            return \\'\\\\n{0}<Class {1}, address {2}:\\\\n{3}{4}{5}>\\\\n\\'.format(\\n                           dots,\\n                           aClass.__name__,\\n                           id(aClass),\\n                           here, above,\\n                           dots)\\n\\n    def __str__(self):\\n        self.__visited = {}\\n        here  = self.__attrnames(self, 0)\\n        above = self.__listclass(self.__class__, 4)\\n        return \\'<Instance of {0}, address {1}:\\\\n{2}{3}>\\'.format(\\n                           self.__class__.__name__,\\n                           id(self),\\n                           here, above)\\n\\nif __name__ == \\'__main__\\':\\n    import testmixin\\n    testmixin.tester(ListTree)\\n\\nThis  class  achieves  its  goal  by  traversing  the  inheritance  tree—from  an  instance’s\\n__class__ to its class, and then from the class’s __bases__ to all superclasses recursively,\\nscanning each object’s attribute __dict__ along the way. Ultimately, it concatenates\\neach tree portion’s string as the recursion unwinds.\\nIt can take a while to understand recursive programs like this, but given the arbitrary\\nshape and depth of class trees, we really have no choice here (apart from explicit stack\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 967\\n\\n\\x0cequivalents of the sorts we met in Chapter 19 and Chapter 25, which tend to be no\\nsimpler, and which we’ll omit here for space and time). This class is coded to keep its\\nbusiness as explicit as possible, though, to maximize clarity.\\nFor example, you could replace the __listclass method’s loop statement in the first\\nof the following with the implicitly run generator expression in the second, but the\\nsecond seems unnecessarily convoluted in this context—recursive calls embedded in a\\ngenerator expression—and has no obvious performance advantage, especially given this\\nprogram’s limited scope (neither alternative makes a temporary list, though the first\\nmay  create  more  temporary  results  depending  on  the  internal  implementation  of\\nstrings, concatenation, and join—something you’d need to time with Chapter 21’s\\ntools to determine):\\n\\n            above = \\'\\'\\n            for super in aClass.__bases__:\\n                above += self.__listclass(super, indent+4)\\n...or...\\n            above = \\'\\'.join(\\n                    self.__listclass(super, indent+4) for super in aClass.__bases__)\\n\\nYou could also code the else clause in __listclass like the following, as in the prior\\nedition of this book—an alternative that embeds everything in the format arguments\\nlist; relies on the fact that the join call kicks off the generator expression and its recursive\\ncalls before the format operation even begins building up the result text; and seems\\nmore difficult to understand, despite the fact that I wrote it (never a good sign!):\\n\\n            self.__visited[aClass] = True\\n            genabove = (self.__listclass(c, indent+4) for c in aClass.__bases__)\\n            return \\'\\\\n{0}<Class {1}, address {2}:\\\\n{3}{4}{5}>\\\\n\\'.format(\\n                           dots,\\n                           aClass.__name__,\\n                           id(aClass),\\n                           self.__attrnames(aClass, indent),   # Runs before format!\\n                           \\'\\'.join(genabove),\\n                           dots)\\n\\nAs always, explicit is better than implicit, and your code can be as big a factor in this\\nas the tools it uses.\\nAlso notice how this version uses the Python 3.X and 2.6/2.7 string format method\\ninstead of % formatting expressions, in an effort to make substitutions arguably clearer;\\nwhen many substitutions are applied like this, explicit argument numbers may make\\nthe code easier to decipher. In short, in this version we exchange the first of the fol-\\nlowing lines for the second:\\n\\n        return \\'<Instance of %s, address %s:\\\\n%s%s>\\' % (...)          # Expression\\n        return \\'<Instance of {0}, address {1}:\\\\n{2}{3}>\\'.format(...)  # Method\\n\\nThis policy has an unfortunate downside in 3.2 and 3.3 too, but we have to run the\\ncode to see why.\\n\\n968 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cRunning the tree lister\\nNow,  to  test,  run  this  class’s  module  file  as  before;  it  passes  the  ListTree  class  to\\ntestmixin.py to be mixed in with a subclass in the test function. The file’s tree-sketcher\\noutput in Python 2.X is as follows:\\n\\nc:\\\\code> c:\\\\python27\\\\python listtree.py\\n<Instance of Sub, address 36690632:\\n _ListTree__visited={}\\n data1=spam\\n data2=eggs\\n data3=42\\n\\n....<Class Sub, address 36652616:\\n     __doc__\\n     __init__\\n     __module__\\n     spam=<unbound method Sub.spam>\\n\\n........<Class Super, address 36652712:\\n         __doc__\\n         __init__\\n         __module__\\n         ham=<unbound method Super.ham>\\n........>\\n\\n........<Class ListTree, address 30795816:\\n         _ListTree__attrnames=<unbound method ListTree.__attrnames>\\n         _ListTree__listclass=<unbound method ListTree.__listclass>\\n         __doc__\\n         __module__\\n         __str__\\n........>\\n....>\\n>\\n\\nNotice in this output how methods are unbound now under 2.X, because we fetch them\\nfrom classes directly. In the previous section’s version they displayed as bound methods,\\nbecause ListInherited fetched these from instances with getattr instead (the first ver-\\nsion indexed the instance __dict__ and did not display inherited methods on classes at\\nall). Also observe how the lister’s __visited table has its name mangled in the instance’s\\nattribute dictionary; unless we’re very unlucky, this won’t clash with other data there.\\nSome of the lister class’s methods are mangled for pseudoprivacy as well.\\nUnder Python 3.X in the following, we again get extra attributes which may vary within\\nthe 3.X line, and extra superclasses—as we’ll learn in the next chapter, all top-level\\nclasses inherit from the built-in object class automatically in 3.X; Python 2.X classes\\ndo so manually if they desire new-style class behavior. Also notice that the attributes\\nthat were unbound methods in 2.X are simple functions in 3.X, as described earlier in\\nthis chapter (and that again, I’ve deleted most built-in attributes in object to save space\\nhere; run this on your own for the complete listing):\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 969\\n\\n\\x0cc:\\\\code> c:\\\\python33\\\\python listtree.py\\n<Instance of Sub, address 44277488:\\n _ListTree__visited={}\\n data1=spam\\n data2=eggs\\n data3=42\\n\\n....<Class Sub, address 36990264:\\n     __doc__\\n     __init__\\n     __module__\\n     __qualname__\\n     spam=<function tester.<locals>.Sub.spam at 0x0000000002A3C840>\\n\\n........<Class Super, address 36989352:\\n         __dict__\\n         __doc__\\n         __init__\\n         __module__\\n         __qualname__\\n         __weakref__\\n         ham=<function tester.<locals>.Super.ham at 0x0000000002A3C730>\\n\\n............<Class object, address 506770624:\\n             __class__\\n             __delattr__\\n             __dir__\\n             __doc__\\n             __eq__\\n             ...more omitted: 22 total...\\n             __repr__\\n             __setattr__\\n             __sizeof__\\n             __str__\\n             __subclasshook__\\n............>\\n........>\\n\\n........<Class ListTree, address 36988440:\\n         _ListTree__attrnames=<function ListTree.__attrnames at 0x0000000002A3C158>\\n         _ListTree__listclass=<function ListTree.__listclass at 0x0000000002A3C1E0>\\n         __dict__\\n         __doc__\\n         __module__\\n         __qualname__\\n         __str__\\n         __weakref__\\n\\n............<Class object:, address 506770624: (see above)>\\n........>\\n....>\\n>\\n\\nThis version avoids listing the same class object twice by keeping a table of classes\\nvisited so far (this is why an object’s id is included—to serve as a key for a previously\\n\\n970 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cdisplayed  item  in  the  report).  Like  the  transitive  module  reloader  of  Chapter  25,  a\\ndictionary works to avoid repeats in the output because class objects are hashable and\\nthus may be dictionary keys; a set would provide similar functionality.\\nTechnically, cycles are not generally possible in class inheritance trees—a class must\\nalready have been defined to be named as a superclass, and Python raises an exception\\nas it should if you attempt to create a cycle later by __bases__ changes—but the visited\\nmechanism here avoids relisting a class twice:\\n\\n>>> class C: pass\\n>>> class B(C): pass\\n>>> C.__bases__ = (B,)        # Deep, dark magic!\\nTypeError: a __bases__ item causes an inheritance cycle\\n\\nUsage variation: Showing underscore name values\\nThis  version  also  takes  care  to  avoid  displaying  large  internal  objects  by  skipping\\n__X__ names again. If you comment out the code that treats these names specially:\\n\\n        for attr in sorted(obj.__dict__):\\n#            if attr.startswith(\\'__\\') and attr.endswith(\\'__\\'):\\n#                result += spaces + \\'{0}\\\\n\\'.format(attr)\\n#            else:\\n                result += spaces + \\'{0}={1}\\\\n\\'.format(attr, getattr(obj, attr))\\n\\nthen their values will display normally. Here’s the output in 2.X with this temporary\\nchange made, giving the values of every attribute in the class tree:\\n\\nc:\\\\code> c:\\\\python27\\\\python listtree.py\\n<Instance of Sub, address 35750408:\\n _ListTree__visited={}\\n data1=spam\\n data2=eggs\\n data3=42\\n\\n....<Class Sub, address 36353608:\\n     __doc__=None\\n     __init__=<unbound method Sub.__init__>\\n     __module__=testmixin\\n     spam=<unbound method Sub.spam>\\n\\n........<Class Super, address 36353704:\\n         __doc__=None\\n         __init__=<unbound method Super.__init__>\\n         __module__=testmixin\\n         ham=<unbound method Super.ham>\\n........>\\n\\n........<Class ListTree, address 31254568:\\n         _ListTree__attrnames=<unbound method ListTree.__attrnames>\\n         _ListTree__listclass=<unbound method ListTree.__listclass>\\n         __doc__=\\n    Mix-in that returns an __str__ trace of the entire class tree and all\\n    its objects\\' attrs at and above self;  run by print(), str() returns\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 971\\n\\n\\x0c    constructed string;  uses __X attr names to avoid impacting clients;\\n    recurses to superclasses explicitly, uses str.format() for clarity;\\n\\n         __module__=__main__\\n         __str__=<unbound method ListTree.__str__>\\n........>\\n....>\\n>\\n\\nThis test’s output is much larger in 3.X and may justify isolating underscore names in\\ngeneral as we did earlier. In fact, this test may not even work in some currently recent\\n3.X releases as is:\\n\\nc:\\\\code> c:\\\\python33\\\\python listtree.py\\n   ...etc...\\n   File \"listtree.py\", line 18, in __attrnames\\n    result += spaces + \\'{0}={1}\\\\n\\'.format(attr, getattr(obj, attr))\\nTypeError: Type method_descriptor doesn\\'t define __format__\\n\\nI debated recoding to work around this issue, but it serves as a fair example of debugging\\nrequirements and techniques in a dynamic open source project like Python. Per the\\nfollowing note, the str.format call no longer supports certain object types that are the\\nvalues of built-in attribute names—yet another reason these names are probably better\\nskipped.\\n\\nDebugging a str.format issue: In 3.X, running the commented-out ver-\\nsion works in 3.0 and 3.1, but there seems to be a bug, or at least a\\nregression, here in 3.2 and 3.3—these Pythons fail with an exception\\nbecause five built-in methods in object do not define a __format__ ex-\\npected by str.format, and the default in object is apparently no longer\\napplied correctly in such cases with empty and generic formatting tar-\\ngets. To see this live, it’s enough to run simplified code that isolates the\\nproblem:\\n\\n c:\\\\code> py −3.1\\n>>> \\'{0}\\'.format(object.__reduce__)\\n\"<method \\'__reduce__\\' of \\'object\\' objects>\"\\nc:\\\\code> py −3.3\\n>>> \\'{0}\\'.format(object.__reduce__)\\nTypeError: Type method_descriptor doesn\\'t define __format__\\n\\nPer both prior behavior and current Python documentation, empty tar-\\ngets like this are supposed to convert the object to its str print string\\n(see both the original PEP 3101 and the 3.3 language reference manual).\\nOddly,  the  {0}  and  {0:s}  string  targets  both  now  fail,  but  the  {0!s}\\nforced str conversion target works, as does manual str preconversion\\n—apparently reflecting a change for a type-specific case that neglected\\nperhaps more common generic usage modes:\\n\\nc:\\\\code> py −3.3\\n>>> \\'{0:s}\\'.format(object.__reduce__)\\nTypeError: Type method_descriptor doesn\\'t define __format__\\n>>> \\'{0!s}\\'.format(object.__reduce__)\\n\"<method \\'__reduce__\\' of \\'object\\' objects>\"\\n\\n972 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0c>>> \\'{0}\\'.format(str(object.__reduce__))\\n\"<method \\'__reduce__\\' of \\'object\\' objects>\"\\n\\nTo fix, wrap the format call in a try statement to catch the exception;\\nuse % formatting expressions instead of the str.format method; use one\\nof the aforementioned still-working str.format usage modes and hope\\nit does not change too; or wait for a repair of this in a later 3.X release.\\nHere’s the recommended workaround using the tried-and-true % (it’s\\nalso  noticeably  shorter,  but  I  won’t  repeat  Chapter  7’s  comparisons\\nhere):\\n\\nc:\\\\code> py −3.3\\n>>> \\'%s\\' % object.__reduce__\\n\"<method \\'__reduce__\\' of \\'object\\' objects>\"\\n\\nTo apply this in the tree lister’s code, change the first of these to its\\nfollower:\\n\\nresult += spaces + \\'{0}={1}\\\\n\\'.format(attr, getattr(obj, attr))\\nresult += spaces + \\'%s=%s\\\\n\\' % (attr, getattr(obj, attr))\\n\\nPython 2.X has the same regression in 2.7 but not 2.6—inherited from\\nthe 3.2 change, apparently—but does not show object methods in this\\nchapter’s example. Since this example generates too much output in 3.X\\nanyhow, it’s a moot point here, but is a decent example of real-world\\ncoding. Unfortunately, using newer features like str.format sometimes\\nputs your code in the awkward position of beta tester in the current 3.X\\nline!\\n\\nUsage variation: Running on larger modules\\nFor more fun, uncomment the underscore handler lines to enable them again, and try\\nmixing this class into something more substantial, like the Button class of Python’s\\ntkinter GUI toolkit module. In general, you’ll want to name ListTree first (leftmost)\\nin a class header, so its __str__ is picked up; Button has one, too, and the leftmost\\nsuperclass is always searched first in multiple inheritance.\\nThe output of the following is fairly massive (20K characters and 330 lines in 3.X—and\\n38K if you forget to uncomment the underscore detection!), so run this code on your\\nown to see the full listing. Notice how our lister’s __visited dictionary attribute mixes\\nharmlessly with those created by tkinter itself. If you’re using Python 2.X, also recall\\nthat you should use Tkinter for the module name instead of tkinter:\\n\\n>>> from listtree import ListTree\\n>>> from tkinter import Button                  # Both classes have a __str__\\n>>> class MyButton(ListTree, Button): pass      # ListTree first: use its __str__\\n\\n>>> B = MyButton(text=\\'spam\\')\\n>>> open(\\'savetree.txt\\', \\'w\\').write(str(B))     # Save to a file for later viewing\\n20513\\n>>> len(open(\\'savetree.txt\\').readlines())       # Lines in the file\\n330\\n>>> print(B)                                    # Print the display here\\n<Instance of MyButton, address 43363688:\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 973\\n\\n\\x0c _ListTree__visited={}\\n _name=43363688\\n _tclCommands=[]\\n _w=.43363688\\n children={}\\n master=.\\n ...much more omitted...\\n>\\n>>> S = str(B)                                  # Or print just the first part\\n>>> print(S[:1000])\\n\\nExperiment arbitrarily on your own. The main point here is that OOP is all about code\\nreuse, and mix-in classes are a powerful example. Like almost everything else in pro-\\ngramming, multiple inheritance can be a useful device when applied well. In practice,\\nthough, it is an advanced feature and can become complicated if used carelessly or\\nexcessively. We’ll revisit this topic as a gotcha at the end of the next chapter.\\n\\nCollector module\\nFinally, to make importing our tools even easier, we can provide a collector module\\nthat combines them in a single namespace—importing just the following gives access\\nto all three lister mix-ins at once:\\n\\n# File lister.py\\n# Collect all three listers in one module for convenience\\n\\nfrom listinstance  import ListInstance\\nfrom listinherited import ListInherited\\nfrom listtree      import ListTree\\n\\nLister = ListTree  # Choose a default lister\\n\\nImporters can use the individual class names as is, or alias them to a common name\\nused in subclasses that can be modified in the import statement:\\n\\n>>> import lister\\n>>> lister.ListInstance                          # Use a specific lister\\n<class \\'listinstance.ListInstance\\'>\\n>>> lister.Lister                                # Use Lister default\\n<class \\'listtree.ListTree\\'>\\n\\n>>> from lister import Lister                    # Use Lister default\\n>>> Lister\\n<class \\'listtree.ListTree\\'>\\n\\n>>> from lister import ListInstance as Lister    # Use Lister alias\\n>>> Lister\\n<class \\'listinstance.ListInstance\\'>\\n\\nPython often makes flexible tool APIs nearly automatic.\\n\\n974 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cRoom for improvement: MRO, slots, GUIs\\nLike most software, there’s much more we could do here. The following gives some\\npointers on extensions you may wish to explore. Some are interesting projects, and two\\nserve as segue to the next chapter, but for space will have to remain in the suggested\\nexercise category here.\\n\\nGeneral ideas: GUIs, built-ins\\n\\nGrouping double-underscore names as we did earlier may help reduce the size of\\nthe tree display, though some like __init__ are user-defined and may merit special\\ntreatment.  Sketching  the  tree  in  a  GUI  might  be  a  natural  next  step  too—the\\ntkinter toolkit that we utilized in the prior section’s lister examples ships with\\nPython and provides basic but easy support, and others offer richer but more com-\\nplex alternatives. See the notes at the end of  Chapter 28’s case study for more\\npointers in this department.\\n\\nPhysical trees versus inheritance: using the MRO (preview)\\n\\nIn the next chapter, we’ll also meet the new-style class model, which modifies the\\nsearch order for one special multiple inheritance case (diamonds). There, we’ll also\\nstudy the class.__mro__ new-style class object attribute—a tuple giving the class\\ntree search order used by inheritance, known as the new-style MRO.\\nAs is, our ListTree tree lister sketches the physical shape of the inheritance tree,\\nand expects the viewer to infer from this where an attribute is inherited from. This\\nwas its goal, but a general object viewer might also use the MRO tuple to auto-\\nmatically associate an attribute with the class from which it is inherited—by scan-\\nning the new-style MRO (or the classic classes’ DFLR ordering) for each inherited\\nattribute in a dir result, we can simulate Python’s inheritance search, and map\\nattributes to their source objects in the physical class tree displayed.\\nIn fact, we will write code that comes very close to this idea in the next chapter’s\\nmapattrs module, and reuse this example’s test classes there to demonstrate the\\nidea, so stay tuned for an epilogue to this story. This might be used instead of or\\nin  addition  to  displaying  attribute  physical  locations  in  __attrnames  here;  both\\nforms might be useful data for programmers to see. This approach is also one way\\nto deal with slots, the topic of the next note.\\nVirtual data: slots, properties, and more (preview)\\n\\nBecause they scan instance __dict__ namespace dictionaries, the ListInstance and\\nListTree classes presented here raise some subtle design issues. In Python classes,\\nsome names associated with instance data may not be stored at the instance itself.\\nThis includes topics presented in the next chapter such as new-style properties,\\nslots, and descriptors, but also attributes dynamically computed in all classes with\\ntools like __getattr__. None of these “virtual” attributes’ names are stored in an\\ninstance’s namespace dictionary, so none will be displayed as part of an instance’s\\nown data.\\n\\nMultiple Inheritance: “Mix-in” Classes\\n\\n| 975\\n\\n\\x0cOf these, slots seem the most strongly associated with an instance; they store data\\non instances, even though their names don’t appear in instance namespace dic-\\ntionaries. Properties and descriptors are associated with instances too, but they\\ndon’t reserve space in the instance, their computed nature is much more explicit,\\nand they may seem closer to class-level methods than instance data.\\nAs we’ll see in the next chapter, slots function like instance attributes, but are\\ncreated and managed by automatically created items in classes. They are a relatively\\ninfrequently used new-style class option, where instance attributes are declared in\\na __slots__ class attribute, and not physically stored in an instance’s __dict__; in\\nfact, slots may suppress a __dict__ entirely. Because of this, tools that display in-\\nstances by scanning their namespaces alone won’t directly associate the instance\\nwith  attributes  stored  in  slots.  As  is,  ListTree  displays  slots  as  class  attributes\\nwherever they appear (though not at the instance), and ListInstance doesn’t dis-\\nplay them at all.\\nThough this will make more sense after we study this feature in the next chapter,\\nit impacts code here and similar tools. For example, if in textmixin.py we assign\\n__slots__=[\\'data1\\'] in Super and __slots__=[\\'data3\\'] in Sub, only the data2 at-\\ntribute is displayed in the instance by these two lister classes. ListTree also displays\\ndata1 and data3, but as attributes of the Super and Sub class objects and with a\\nspecial format for their values (technically, they are class-level descriptors, another\\nnew-style tool introduced in the next chapter).\\nAs the next chapter will explain, to show slot attributes as instance names, tools\\ngenerally need to use dir to get a list of all attributes—both physically present and\\ninherited—and then use either getattr to fetch their values from the instance, or\\nfetch values from their inheritance source via __dict__ in tree scans and accept the\\ndisplay of the implementations of some at classes. Because dir includes the names\\nof inherited “virtual” attributes—including both slots and properties—they would\\nbe included in the instance set. As we’ll also find, the MRO might assist here to\\nmap dir attribute to their sources, or restrict instance displays to names coded in\\nuser-defined classes by filtering out names inherited from the built-in object.\\nListInherited is immune to most of this, because it already displays the full dir\\nresults set, which include both __dict__ names and all classes’ __slots__ names,\\nthough its display is of marginal use as is. A ListTree variant using the dir technique\\nalong with the MRO sequence to map attributes to classes would apply to slots\\ntoo, because slots-based names appear in class’s __dict__ results individually as\\nslot management tools, though not in the instance __dict__.\\nAlternatively, as a policy we could simply let our code handle slot-based attributes\\nas it currently does, rather than complicating it for a rarely used, advanced feature\\nthat’s even questionable practice today. Slots and normal instance attributes are\\ndifferent kinds of names. In fact, displaying slots names as attributes of classes\\ninstead of instances is technically more accurate—as we’ll see in the next chapter\\ntheir implementation is at classes, though their space is at instances.\\n\\n976 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cUltimately, attempting to collect all the “virtual” attributes associated with a class\\nmay be a bit of a pipe dream anyhow. Techniques like those outlined here may\\naddress slots and properties, but some attributes are entirely dynamic, with no\\nphysical basis at all: those computed on fetch by generic method such as __get\\nattr__ are not data in the classic sense. Tools that attempt to display data in a\\nwildly  dynamic  language  Python  must  come  with  the  caveat  that  some  data  is\\nethereal at best!\\n\\nWe’ll also make a minor extension to this section’s code in the exercises at the end of\\nthis part of the book, to list superclass names in parentheses at the start of instance\\ndisplays, so keep it filed for future reference for now. To better understand the last of\\nthe preceding two points, we need to wrap up this chapter and move on to the next\\nand last in this part of the book.\\n\\nOther Design-Related Topics\\nIn this chapter, we’ve studied inheritance, composition, delegation, multiple inheri-\\ntance, bound methods, and factories—all common patterns used to combine classes\\nin Python programs. We’ve really only scratched the surface here in the design patterns\\ndomain, though. Elsewhere in this book you’ll find coverage of other design-related\\ntopics, such as:\\n\\n• Abstract superclasses (Chapter 29)\\n• Decorators (Chapter 32 and Chapter 39)\\n• Type subclasses (Chapter 32)\\n• Static and class methods (Chapter 32)\\n• Managed attributes (Chapter 32 and Chapter 38)\\n• Metaclasses (Chapter 32 and Chapter 40)\\n\\nFor more details on design patterns, though, we’ll delegate to other resources on OOP\\nat large. Although patterns are important in OOP work and are often more natural in\\nPython than other languages, they are not specific to Python itself, and a subject that’s\\noften best acquired by experience.\\n\\nChapter Summary\\nIn this chapter, we sampled common ways to use and combine classes to optimize their\\nreusability and factoring benefits—what are usually considered design issues that are\\noften independent of any particular programming language (though Python can make\\nthem easier to implement). We studied delegation (wrapping objects in proxy classes),\\ncomposition (controlling embedded objects), and inheritance (acquiring behavior from\\nother classes), as well as some more esoteric concepts such as pseudoprivate attributes,\\nmultiple inheritance, bound methods, and factories.\\n\\nChapter Summary | 977\\n\\n\\x0cThe next chapter ends our look at classes and OOP by surveying more advanced class-\\nrelated topics. Some of its material may be of more interest to tool writers than appli-\\ncation programmers, but it still merits a review by most people who will do OOP in\\nPython—if not for your code, then for the code of others you may need to understand.\\nFirst, though, here’s another quick chapter quiz to review.\\n\\nTest Your Knowledge: Quiz\\n1. What is multiple inheritance?\\n2. What is delegation?\\n3. What is composition?\\n4. What are bound methods?\\n5. What are pseudoprivate attributes used for?\\n\\nTest Your Knowledge: Answers\\n1. Multiple inheritance occurs when a class inherits from more than one superclass;\\nit’s useful for mixing together multiple packages of class-based code. The left-to-\\nright order in class statement headers determines the general order of attribute\\nsearches.\\n\\n2. Delegation involves wrapping an object in a proxy class, which adds extra behavior\\nand passes other operations to the wrapped object. The proxy retains the interface\\nof the wrapped object.\\n\\n3. Composition is a technique whereby a controller class embeds and directs a num-\\nber of objects, and provides an interface all its own; it’s a way to build up larger\\nstructures with classes.\\n\\n4. Bound methods combine an instance and a method function; you can call them\\nwithout passing in an instance object explicitly because the original instance is still\\navailable.\\n\\n5. Pseudoprivate attributes (whose names begin but do not end with two leading\\nunderscores: __X) are used to localize names to the enclosing class. This includes\\nboth class attributes like methods defined inside the class, and self instance at-\\ntributes assigned inside the class’s methods. Such names are expanded to include\\nthe class name, which makes them generally unique.\\n\\n978 | Chapter 31:\\u2002Designing with Classes\\n\\n\\x0cCHAPTER 32\\nAdvanced Class Topics\\n\\nThis chapter concludes our look at OOP in Python by presenting a few more advanced\\nclass-related topics: we will survey subclassing built-in types, “new style” class changes\\nand extensions, static and class methods, slots and properties, function and class dec-\\norators, the MRO and the super call, and more.\\nAs we’ve seen, Python’s OOP model is, at its core, relatively simple, and some of the\\ntopics presented in this chapter are so advanced and optional that you may not en-\\ncounter them very often in your Python applications-programming career. In the in-\\nterest of completeness, though—and because you never know when an “advanced”\\ntopic may crop up in code you use—we’ll round out our discussion of classes with a\\nbrief look at these advanced tools for OOP work.\\nAs usual, because this is the last chapter in this part of the book, it ends with a section\\non class-related “gotchas,” and the set of lab exercises for this part. I encourage you to\\nwork through the exercises to help cement the ideas we’ve studied here. I also suggest\\nworking on or studying larger OOP Python projects as a supplement to this book. As\\nwith much in computing, the benefits of OOP tend to become more apparent with\\npractice.\\n\\nContent notes: This chapter collects advanced class topics, but some are\\ntoo large for this chapter to cover well. Topics such as properties, de-\\nscriptors, decorators, and metaclasses are mentioned only briefly here,\\nand given a fuller treatment in the final part of this book, after excep-\\ntions. Be sure to look ahead for more complete examples and extended\\ncoverage of some of the subjects that fall into this chapter’s category.\\n\\nYou’ll also notice that this is the largest chapter in this book—I’m as-\\nsuming that readers courageous enough to take on this chapter’s topics\\nare ready to roll up their sleeves and explore its in-depth coverage. If\\nyou’re  not  looking  for  advanced  OOP  topics,  you  may  wish  to  skip\\nahead to chapter-end materials, and come back here when you confront\\nthese tools in the code of your programming future.\\n\\n979\\n\\n\\x0cExtending Built-in Types\\nBesides implementing new kinds of objects, classes are sometimes used to extend the\\nfunctionality of Python’s built-in types to support more exotic data structures. For\\ninstance, to add queue insert and delete methods to lists, you can code classes that wrap\\n(embed) a list object and export insert and delete methods that process the list specially,\\nlike the delegation technique we studied in Chapter 31. As of Python 2.2, you can also\\nuse inheritance to specialize built-in types. The next two sections show both techniques\\nin action.\\n\\nExtending Types by Embedding\\nDo you remember those set functions we wrote in Chapter 16 and Chapter 18? Here’s\\nwhat they look like brought back to life as a Python class. The following example (the\\nfile setwrapper.py) implements a new set object type by moving some of the set func-\\ntions to methods and adding some basic operator overloading. For the most part, this\\nclass just wraps a Python list with extra set operations. But because it’s a class, it also\\nsupports multiple instances and customization by inheritance in subclasses. Unlike our\\nearlier functions, using classes here allows us to make multiple self-contained set ob-\\njects with preset data and behavior, rather than passing lists into functions manually:\\n\\nclass Set:\\n   def __init__(self, value = []):    # Constructor\\n       self.data = []                 # Manages a list\\n       self.concat(value)\\n\\n   def intersect(self, other):        # other is any sequence\\n       res = []                       # self is the subject\\n       for x in self.data:\\n           if x in other:             # Pick common items\\n               res.append(x)\\n       return Set(res)                # Return a new Set\\n\\n   def union(self, other):            # other is any sequence\\n       res = self.data[:]             # Copy of my list\\n       for x in other:                # Add items in other\\n           if not x in res:\\n               res.append(x)\\n       return Set(res)\\n\\n   def concat(self, value):           # value: list, Set...\\n       for x in value:                # Removes duplicates\\n          if not x in self.data:\\n               self.data.append(x)\\n\\n   def __len__(self):          return len(self.data)            # len(self), if self\\n   def __getitem__(self, key): return self.data[key]            # self[i], self[i:j]\\n   def __and__(self, other):   return self.intersect(other)     # self & other\\n   def __or__(self, other):    return self.union(other)         # self | other\\n\\n980 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c   def __repr__(self):         return \\'Set:\\' + repr(self.data)  # print(self),...\\n   def __iter__(self):         return iter(self.data)           # for x in self,...\\n\\nTo use this class, we make instances, call methods, and run defined operators as usual:\\n\\nfrom setwrapper import Set\\nx = Set([1, 3, 5, 7])\\nprint(x.union(Set([1, 4, 7])))       # prints Set:[1, 3, 5, 7, 4]\\nprint(x | Set([1, 4, 6]))            # prints Set:[1, 3, 5, 7, 4, 6]\\n\\nOverloading operations such as indexing and iteration also enables instances of our\\nSet class to often masquerade as real lists. Because you will interact with and extend\\nthis class in an exercise at the end of this chapter, I won’t say much more about this\\ncode until Appendix D.\\n\\nExtending Types by Subclassing\\nBeginning with Python 2.2, all the built-in types in the language can now be subclassed\\ndirectly. Type-conversion functions such as list, str, dict, and tuple have become\\nbuilt-in type names—although transparent to your script, a type-conversion call (e.g.,\\nlist(\\'spam\\')) is now really an invocation of a type’s object constructor.\\nThis change allows you to customize or extend the behavior of built-in types with user-\\ndefined class statements: simply subclass the new type names to customize them. In-\\nstances of your type subclasses can generally be used anywhere that the original built-\\nin type can appear. For example, suppose you have trouble getting used to the fact that\\nPython list offsets begin at 0 instead of 1. Not to worry—you can always code your\\nown subclass that customizes this core behavior of lists. The file typesubclass.py shows\\nhow:\\n\\n# Subclass built-in list type/class\\n# Map 1..N to 0..N-1; call back to built-in version.\\n\\nclass MyList(list):\\n    def __getitem__(self, offset):\\n        print(\\'(indexing %s at %s)\\' % (self, offset))\\n        return list.__getitem__(self, offset - 1)\\n\\nif __name__ == \\'__main__\\':\\n    print(list(\\'abc\\'))\\n    x = MyList(\\'abc\\')               # __init__ inherited from list\\n    print(x)                        # __repr__ inherited from list\\n\\n    print(x[1])                     # MyList.__getitem__\\n    print(x[3])                     # Customizes list superclass method\\n\\n    x.append(\\'spam\\'); print(x)      # Attributes from list superclass\\n    x.reverse();      print(x)\\n\\nIn this file, the MyList subclass extends the built-in list’s __getitem__ indexing method\\nonly, to map indexes 1 to N back to the required 0 to N−1. All it really does is decrement\\n\\nExtending Built-in Types\\n\\n| 981\\n\\n\\x0cthe  submitted  index  and  call  back  to  the  superclass’s  version  of  indexing,  but  it’s\\nenough to do the trick:\\n\\n% python typesubclass.py\\n[\\'a\\', \\'b\\', \\'c\\']\\n[\\'a\\', \\'b\\', \\'c\\']\\n(indexing [\\'a\\', \\'b\\', \\'c\\'] at 1)\\na\\n(indexing [\\'a\\', \\'b\\', \\'c\\'] at 3)\\nc\\n[\\'a\\', \\'b\\', \\'c\\', \\'spam\\']\\n[\\'spam\\', \\'c\\', \\'b\\', \\'a\\']\\n\\nThis output also includes tracing text the class prints on indexing. Of course, whether\\nchanging indexing this way is a good idea in general is another issue—users of your\\nMyList class may very well be confused by such a core departure from Python sequence\\nbehavior!  The  ability  to  customize  built-in  types  this  way  can  be  a  powerful  asset,\\nthough.\\nFor instance, this coding pattern gives rise to an alternative way to code a set—as a\\nsubclass of the built-in list type, rather than a standalone class that manages an em-\\nbedded list object as shown in the prior section. As we learned in Chapter 5, Python\\ntoday comes with a powerful built-in set object, along with literal and comprehension\\nsyntax for making new sets. Coding one yourself, though, is still a great way to learn\\nabout type subclassing in general.\\nThe following class, coded in the file setsubclass.py, customizes lists to add just methods\\nand operators related to set processing. Because all other behavior is inherited from the\\nbuilt-in list superclass, this makes for a shorter and simpler alternative—everything\\nnot defined here is routed to list directly:\\n\\nfrom __future__ import print_function    # 2.X compatibility\\n\\nclass Set(list):\\n    def __init__(self, value = []):      # Constructor\\n        list.__init__([])                # Customizes list\\n        self.concat(value)               # Copies mutable defaults\\n\\n    def intersect(self, other):          # other is any sequence\\n        res = []                         # self is the subject\\n        for x in self:\\n            if x in other:               # Pick common items\\n                res.append(x)\\n        return Set(res)                  # Return a new Set\\n\\n    def union(self, other):              # other is any sequence\\n        res = Set(self)                  # Copy me and my list\\n        res.concat(other)\\n        return res\\n\\n    def concat(self, value):             # value: list, Set, etc.\\n        for x in value:                  # Removes duplicates\\n            if not x in self:\\n\\n982 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c                self.append(x)\\n\\n    def __and__(self, other): return self.intersect(other)\\n    def __or__(self, other):  return self.union(other)\\n    def __repr__(self):       return \\'Set:\\' + list.__repr__(self)\\n\\nif __name__ == \\'__main__\\':\\n    x = Set([1,3,5,7])\\n    y = Set([2,1,4,5,6])\\n    print(x, y, len(x))\\n    print(x.intersect(y), y.union(x))\\n    print(x & y, x | y)\\n    x.reverse(); print(x)\\n\\nHere is the output of the self-test code at the end of this file. Because subclassing core\\ntypes is a somewhat advanced feature with a limited target audience, I’ll omit further\\ndetails here, but I invite you to trace through these results in the code to study its\\nbehavior (which is the same on Python 3.X and 2.X):\\n\\n% python setsubclass.py\\nSet:[1, 3, 5, 7] Set:[2, 1, 4, 5, 6] 4\\nSet:[1, 5] Set:[2, 1, 4, 5, 6, 3, 7]\\nSet:[1, 5] Set:[1, 3, 5, 7, 2, 4, 6]\\nSet:[7, 5, 3, 1]\\n\\nThere are more efficient ways to implement sets with dictionaries in Python, which\\nreplace the nested linear search scans in the set implementations shown here with more\\ndirect dictionary index operations (hashing) and so run much quicker. For more details,\\nsee the continuation of this thread in the follow-up book Programming Python. Again,\\nif you’re interested in sets, also take another look at the set object type we explored in\\nChapter 5; this type provides extensive set operations as built-in tools. Set implemen-\\ntations are fun to experiment with, but they are no longer strictly required in Python\\ntoday.\\nFor another type subclassing example, explore the implementation of the bool type in\\nPython 2.3 and later. As mentioned earlier in the book, bool is a subclass of int with\\ntwo instances (True and False) that behave like the integers 1 and 0 but inherit custom\\nstring-representation methods that display their names.\\n\\nThe “New Style” Class Model\\nIn release 2.2, Python introduced a new flavor of classes, known as new-style classes;\\nclasses following the original and traditional model became known as classic classes\\nwhen compared to the new kind. In 3.X the class story has merged, but it remains split\\nfor Python 2.X users and code:\\n\\n• In Python 3.X, all classes are automatically what were formerly called “new style,”\\nwhether they explicitly inherit from object or not. Coding the object superclass is\\noptional and implied.\\n\\nThe “New Style” Class Model\\n\\n| 983\\n\\n\\x0c• In Python 2.X, classes must explicitly inherit from object (or another built-in type)\\nto be considered “new style” and enable and obtain all new-style behavior. Classes\\nwithout this are “classic.”\\n\\nBecause all classes are automatically new-style in 3.X, the features of new-style classes\\nare simply normal class features in that line. I’ve opted to keep their descriptions in this\\nsection separate, however, in deference to users of Python 2.X code—classes in such\\ncode acquire new-style features and behavior only when they are derived from object.\\nIn other words, when Python 3.X users see descriptions of “new style” topics in this\\nbook, they should take them to be descriptions of existing properties of their classes.\\nFor 2.X readers, these are a set of optional changes and extensions that you may choose\\nto enable or not, unless the code you must use already employs them.\\nIn Python 2.X, the identifying syntactic difference for new-style classes is that they are\\nderived from either a built-in type, such as list, or a special built-in class known as\\nobject.  The  built-in  name  object  is  provided  to  serve  as  a  superclass  for  new-style\\nclasses if no other built-in type is appropriate to use:\\n\\nclass newstyle(object):                    # 2.X explicit new-style derivation\\n    ...normal class code...                # Not required in 3.X: automatic\\n\\nAny class derived from object, or any other built-in type, is automatically treated as a\\nnew-style class. That is, as long as a built-in type is somewhere in its superclass tree, a\\n2.X class acquires new-style class behavior and extensions. Classes not derived from\\nbuilt-ins such as object are considered classic.\\n\\nJust How New Is New-Style?\\nAs we’ll see, new-style classes come with profound differences that impact programs\\nbroadly, especially when code leverages their added advanced features. In fact, at least\\nin terms of its OOP support, these changes on some levels transform Python into a\\ndifferent language altogether—one that’s mandated in the 3.X line, one that’s optional\\nin 2.X only if ignored by every programmer, and one that borrows much more from\\n(and is often as complex as) other languages in this domain.\\nNew-style classes stem in part from an attempt to merge the notion of class with that\\nof type around the time of Python 2.2, though they went unnoticed by many until they\\nwere escalated to required knowledge in 3.X. You’ll need to judge the success of that\\nmerging for yourself, but as we’ll see, there are still distinctions in the model—now\\nbetween class and metaclass—and one of its side effects is to make normal classes more\\npowerful but also substantially more complex. The new-style inheritance algorithm\\nformalized in Chapter 40, for example, grows in complexity by at least a factor of 2.\\nStill, some programmers using straightforward application code may notice only slight\\ndivergence from traditional “classic” classes. After all, we’ve managed to get to this\\npoint in this book writing substantial class examples, with mostly just passing mentions\\n\\n984 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cof this change. Moreover, the classic class model still available in 2.X works exactly as\\nit has for some two decades.1\\nHowever, because they modify core class behaviors, new-style classes had to be intro-\\nduced in Python 2.X as a distinct tool so as to avoid impacting any existing code that\\ndepends on the prior model. For example, some subtle differences, such as diamond\\npattern inheritance search and the interaction of built-in operations and managed at-\\ntribute methods such as __getattr__ can cause some existing code to fail if left un-\\nchanged. Using optional extensions in the new model such as slots can have the same\\neffect.\\nThe class model split is removed in Python 3.X, which mandates new-style classes, but\\nit still exists for readers using 2.X, or reusing the vast amount of existing 2.X code in\\nproduction use. Because this has been an optional extension in 2.X, code written for\\nthat line may use either class model.\\nThe  next  two  top-level  sections  provide  overviews  of  the  ways  in  which  new-style\\nclasses differ and the new tools they provide. These topics represent potential changes\\nto  some  Python  2.X  readers,  but  simply  additional  advanced  class  topics  to  many\\nPython 3.X readers. If you’re in the latter group, you’ll find full coverage here, though\\nsome of it is presented in the context of changes—which you can accept as features,\\nbut only if you never must deal with any of the millions of lines of existing 2.X code.\\n\\nNew-Style Class Changes\\nNew-style classes differ from classic classes in a number of ways, some of which are\\nsubtle but can impact both existing 2.X code and common coding styles. As preview\\nand summary, here are some of the most prominent ways they differ:\\n\\nAttribute fetch for built-ins: instance skipped\\n\\nThe __getattr__ and __getattribute__ generic attribute interception methods are\\nstill run for attributes accessed by explicit name, but no longer for attributes im-\\nplicitly fetched by built-in operations. They are not called for __X__ operator over-\\nloading method names in built-in contexts only—the search for such names begins\\nat classes, not instances. This breaks or complicates objects that serve as proxies\\nfor another object’s interface, if wrapped objects implement operator overloading.\\n\\n1. As a data point, the book Programming Python, a 1,600-page applications programming follow-up to this\\nbook that uses 3.X exclusively, neither uses nor needs to accommodate any of the new-style class tools\\nof this chapter, and still manages to build significant programs for GUIs, websites, systems programming,\\ndatabases, and text. It’s mostly straightforward code that leverages built-in types and libraries to do its\\nwork, not obscure and esoteric OOP extensions. When it does use classes, they are relatively simple,\\nproviding structure and code factoring. That book’s code is also probably more representative of real-\\nworld programming than some in this language tutorial text—which suggests that many of Python’s\\nadvanced OOP tools may be artificial, having more to do with language design than practical program\\ngoals. Then again, that book has the luxury of restricting its toolset to such code; as soon as your coworker\\nfinds a way to use an arcane language feature, all bets are off!\\n\\nNew-Style Class Changes\\n\\n| 985\\n\\n\\x0cSuch methods must be redefined for the sake of differing built-ins dispatch in new-\\nstyle classes.\\n\\nClasses and types merged: type testing\\n\\nClasses are now types, and types are now classes. In fact, the two are essentially\\nsynonyms, though the metaclasses that now subsume types are still somewhat dis-\\ntinct from normal classes. The type(I) built-in returns the class an instance is made\\nfrom, instead of a generic instance type, and is normally the same as I.__class__.\\nMoreover, classes are instances of the type class, and type may be subclassed to\\ncustomize class creation with metaclasses coded with class statements. This can\\nimpact code that tests types or otherwise relies on the prior type model.\\n\\nAutomatic object root class: defaults\\n\\nAll new-style classes (and hence types) inherit from object, which comes with a\\nsmall set of default operator overloading methods (e.g., __repr__). In 3.X, this class\\nis added automatically above the user-defined root (i.e., topmost) classes in a tree,\\nand need not be listed as a superclass explicitly. This can affect code that assumes\\nthe absence of method defaults and root classes.\\n\\nInheritance search order: MRO and diamonds\\n\\nDiamond patterns of multiple inheritance have a slightly different search order—\\nroughly, at diamonds they are searched across before up, and more breadth-first\\nthan depth-first. This attribute search order, known as the MRO, can be traced\\nwith a new __mro__ attribute available on new-style classes. The new search order\\nlargely  applies  only  to  diamond  class  trees,  though  the  new  model’s  implied\\nobject root itself forms a diamond in all multiple inheritance trees. Code that relies\\non the prior order will not work the same.\\n\\nInheritance algorithm: Chapter 40\\n\\nThe algorithm used for inheritance in new-style classes is substantially more com-\\nplex than the depth-first model of classic classes, incorporating special cases for\\ndescriptors, metaclasses, and built-ins. We won’t be able to formalize this until\\nChapter 40 after we’ve studied metaclasses and descriptors in more depth, but it\\ncan impact code that does not anticipate its extra convolutions.\\n\\nNew advanced tools: code impacts\\n\\nNew-style classes have a set of new class tools, including slots, properties, descrip-\\ntors, super, and the __getattribute__ method. Most of these have very specific\\ntool-building purposes. Their use can also impact or break existing code, though;\\nslots, for example, sometimes prevent creation of an instance namespace dictionary\\naltogether, and generic attribute handlers may require different coding.\\n\\nWe’ll explore the extensions noted in the last of these items in a later top-level section\\nof its own, and will defer formal inheritance algorithm coverage until Chapter 40 as\\nnoted. Because the other items on this list have the potential to break traditional Python\\ncode, though, let’s take a closer look at each in turn here.\\n\\n986 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cContent note: Keep in mind that new-style class changes apply to both\\n3.X and 2.X, even though they are an option in the latter. This chapter\\nand book sometimes label features as 3.X changes to contrast with tra-\\nditional  2.X  code,  but  some  are  technically  introduced  by  new-style\\nclasses—which are mandated in 3.X, but can show up in 2.X code too.\\nFor space, this distinction is called out often but not dogmatically here.\\nComplicating this distinction, some 3.X class-related changes owe to\\nnew-style classes (e.g., skipping __getattr__ for operator methods) but\\nsome do not (e.g., replacing unbound methods with functions). More-\\nover, many 2.X programmers stick to classic classes, ignoring what they\\nview as a 3.X feature. New-style classes are not new, though, and apply\\nto both Pythons—if they appear in 2.X code, they’re required reading\\nfor 2.X users too.\\n\\nAttribute Fetch for Built-ins Skips Instances\\nWe introduced this new-style class change in sidebars in both Chapter 28 and Chap-\\nter 31 because of their impact on prior examples and topics. In new-style classes (and\\nhence  all  classes  in  3.X),  the  generic  instance  attribute  interception  methods  __get\\nattr__ and __getattribute__ are no longer called by built-in operations for __X__ op-\\nerator overloading method names—the search for such names begins at classes, not\\ninstances.  Attributes  accessed  by  explicit  name,  however,  are  routed  through  these\\nmethods, even if they are __X__ names. Hence, this is primarily a change to the behavior\\nof built-in operations.\\nMore formally, if a class defines a __getitem__ index overload method and X is an in-\\nstance of this class, then an index expression like X[I] is roughly equivalent to X.__geti\\ntem__(I) for classic classes, but type(X).__getitem__(X, I) for new-style classes—the\\nlatter beginning its search in the class, and thus skipping a __getattr__ step from the\\ninstance for an undefined name.\\nTechnically, this method search for built-in operations like X[I] uses normal inheri-\\ntance beginning at the class level, and inspects only the namespace dictionaries of all\\nthe classes from which X derives—a distinction that can matter in the metaclass model\\nwe’ll meet later in this chapter and focus on in Chapter 40, where classes may acquire\\nbehavior differently. The instance, however, is omitted by built-ins’ search.\\n\\nWhy the lookup change?\\nYou can find formal rationales for this change elsewhere; this book is disinclined to\\nparrot justifications for a change that breaks many working programs. But this is im-\\nagined as both an optimization path and a solution to a seemingly obscure call pat-\\ntern issue. The former rationale is supported by the frequency of built-in operations. If\\nevery +, for example, requires extra steps at the instance, it can degrade program speed\\n—especially so given the new-style model’s many attribute-level extensions.\\n\\nNew-Style Class Changes\\n\\n| 987\\n\\n\\x0cThe latter rationale is more obscure, and is described in Python manuals; in short, it\\nreflects a conundrum introduced by the metaclass model. Because classes are now in-\\nstances of metaclasses, and because metaclasses can define built-in operator methods\\nto process the classes they generate, a method call run for a class must skip the class\\nitself and look one level higher to pick up a method that processes the class, rather than\\nselecting the class’s own version. Its own version would result in an unbound method\\ncall, because the class’s own method processes lower instances. This is just the usual\\nunbound method model we discussed in the prior chapter, but is potentially aggravated\\nby the fact that classes can acquire type behavior from metaclasses too.\\nAs a result, because classes are both types and instances in their own right, all instances\\nare skipped for built-in operation method lookup. This is supposedly applied to normal\\ninstances for uniformity and consistency, but both non-built-in names and direct and\\nexplicit calls to built-in names still check the instance anyhow. Though perhaps a con-\\nsequence of the new-style class model, to some this may seem a solution arrived at for\\nthe sake of a usage pattern that was more artificial and obscure than the widely used\\none it broke. Its role as optimization path seems more defensible, but also not without\\nrepercussions.\\nIn particular, this has potentially broad implications for the delegation-based classes,\\noften known as proxy classes, when embedded objects implement operator overload-\\ning. In new-style classes, such a proxy object’s class must generally redefine any such\\nnames to catch and delegate, either manually or with tools. The net effect is to either\\nsignificantly complicate or wholly obviate an entire category of programs. We explored\\ndelegation in Chapter 28 and Chapter 31; it’s a common pattern used to augment or\\nadapt another class’s interface—to add validation, tracing, timing, and many other\\nsorts of logic. Though proxies may be more the exception than the rule in typical Python\\ncode, many Python programs depend upon them.\\n\\nImplications for attribute interception\\nIn simple terms, and run in Python 2.X to show how new-style classes differ, indexing\\nand prints are routed to __getattr__ in traditional classes, but not for new-style classes,\\nwhere printing uses a default:2\\n\\n>>> class C:\\n        data = \\'spam\\'\\n        def __getattr__(self, name):             # Classic in 2.X: catches built-ins\\n            print(name)\\n            return getattr(self.data, name)\\n\\n>>> X = C()\\n>>> X[0]\\n__getitem__\\n\\n2. As of this chapter’s interaction listings, I’ve started omitting some blank lines and shortening some hex\\naddresses to 32 bits in object displays, to reduce size and clutter. I’m going to assume that by this point\\nin the book, you’ll find such small details irrelevant.\\n\\n988 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c\\'s\\'\\n>>> print(X)                                     # Classic doesn\\'t inherit default\\n__str__\\nspam\\n\\n>>> class C(object):                             # New-style in 2.X and 3.X\\n        ...rest of class unchanged...\\n\\n>>> X = C()                                      # Built-ins not routed to getattr\\n>>> X[0]\\nTypeError: \\'C\\' object does not support indexing\\n>>> print(X)\\n<__main__.C object at 0x02205780>\\n\\nThough apparently rationalized in the name of class metaclass methods and optimizing\\nbuilt-in operations, this divergence is not addressed by special-casing normal instances\\nhaving a __getattr__, and applies only to built-in operations—not to normally named\\nmethods, or explicit calls to built-in methods by name:\\n\\n>>> class C: pass                                # 2.X classic class\\n>>> X = C()\\n>>> X.normal = lambda: 99\\n>>> X.normal()\\n99\\n>>> X.__add__ = lambda(y): 88 + y\\n>>> X.__add__(1)\\n89\\n>>> X + 1\\n89\\n\\n>>> class C(object): pass                        # 2.X/3.X new-style class\\n>>> X = C()\\n>>> X.normal = lambda: 99\\n>>> X.normal()                                   # Normals still from instance\\n99\\n>>> X.__add__ = lambda(y): 88 + y\\n>>> X.__add__(1)                                 # Ditto for explicit built-in names\\n89\\n>>> X + 1\\nTypeError: unsupported operand type(s) for +: \\'C\\' and \\'int\\'\\n\\nThis  behavior  winds  up  being  inherited  by  the  __getattr__  attribute  interception\\nmethod:\\n\\n>>> class C(object):\\n        def __getattr__(self, name): print(name)\\n\\n>>> X = C()\\n>>> X.normal             # Normal names are still routed to getattr\\nnormal\\n>>> X.__add__            # Direct calls by name are too, but expressions are not!\\n__add__\\n>>> X + 1\\nTypeError: unsupported operand type(s) for +: \\'C\\' and \\'int\\'\\n\\nNew-Style Class Changes\\n\\n| 989\\n\\n\\x0cProxy coding requirements\\nIn a more realistic delegation scenario, this means that built-in operations like expres-\\nsions no longer work the same as their traditional direct-call equivalent. Asymmetri-\\ncally, direct calls to built-in method names still work, but equivalent expressions do\\nnot because through-type calls fail for names not at the class level and above. In other\\nwords, this distinction arises in built-in operations only; explicit fetches run correctly:\\n\\n>>> class C(object):\\n        data = \\'spam\\'\\n        def __getattr__(self, name):\\n            print(\\'getattr: \\' + name)\\n            return getattr(self.data, name)\\n\\n>>> X = C()\\n>>> X.__getitem__(1)           # Traditional mapping works but new-style\\'s does not\\ngetattr: __getitem__\\n\\'p\\'\\n\\n>>> X[1]\\nTypeError: \\'C\\' object does not support indexing\\n>>> type(X).__getitem__(X, 1)\\nAttributeError: type object \\'C\\' has no attribute \\'__getitem__\\'\\n\\n>>> X.__add__(\\'eggs\\')          # Ditto for +: instance skipped for expression only\\ngetattr: __add__\\n\\'spameggs\\'\\n\\n>>> X + \\'eggs\\'\\nTypeError: unsupported operand type(s) for +: \\'C\\' and \\'str\\'\\n>>> type(X).__add__(X, \\'eggs\\')\\nAttributeError: type object \\'C\\' has no attribute \\'__add__\\'\\n\\nThe net effect: to code a proxy of an object whose interface may in part be invoked by\\nbuilt-in operations, new-style classes require both __getattr__ for normal names, as\\nwell as method redefinitions for all names accessed by built-in operations—whether\\ncoded manually, obtained from superclasses, or generated by tools. When redefinitions\\nare so incorporated, calls through both instances and types are equivalent to built-in\\noperations, though redefined names are no longer routed to the generic __getattr__\\nundefined name handler, even for explicit name calls:\\n\\n>>> class C(object):                                    # New-style: 3.X and 2.X\\n        data = \\'spam\\'\\n        def __getattr__(self, name):                    # Catch normal names\\n            print(\\'getattr: \\' + name)\\n            return getattr(self.data, name)\\n        def __getitem__(self, i):                       # Redefine built-ins\\n            print(\\'getitem: \\' + str(i))\\n            return self.data[i]                         # Run expr or getattr\\n        def __add__(self, other):\\n            print(\\'add: \\' +  other)\\n            return getattr(self.data, \\'__add__\\')(other)\\n\\n>>> X = C()\\n\\n990 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> X.upper\\ngetattr: upper\\n<built-in method upper of str object at 0x0233D670>\\n>>> X.upper()\\ngetattr: upper\\n\\'SPAM\\'\\n\\n>>> X[1]                            # Built-in operation (implicit)\\ngetitem: 1\\n\\'p\\'\\n>>> X.__getitem__(1)                # Traditional equivalence (explicit)\\ngetitem: 1\\n\\'p\\'\\n>>> type(X).__getitem__(X, 1)       # New-style equivalence\\ngetitem: 1\\n\\'p\\'\\n\\n>>> X + \\'eggs\\'                      # Ditto for + and others\\nadd: eggs\\n\\'spameggs\\'\\n>>> X.__add__(\\'eggs\\')\\nadd: eggs\\n\\'spameggs\\'\\n>>> type(X).__add__(X, \\'eggs\\')\\nadd: eggs\\n\\'spameggs\\'\\n\\nFor more details\\nWe will revisit this change in Chapter 40 on metaclasses, and by example in the contexts\\nof attribute management in Chapter 38 and privacy decorators in Chapter 39. In the\\nlatter of these, we’ll also explore coding structures for providing proxies with the re-\\nquired operator methods generically—it’s not an impossible task, and may need to be\\ncoded just once if done well. For more of the sort of code influenced by this issue, see\\nthose later chapters, as well as the earlier examples in Chapter 28 and Chapter 31.\\nBecause we’ll expand on this issue later in the book, we’ll cut the coverage short here.\\nFor external links and pointers on this issue, though, see the following (along with your\\nlocal search engine):\\n\\n• Python Issue 643841: this issue has been discussed widely, but its most official\\nhistory seems to be documented at http://bugs.python.org/issue643841. There, it\\nwas raised as a concern for real programs and escalated to be addressed, but a\\nproposed library remedy or broader change in Python was struck down in favor of\\na simple documentation change to describe the new mandated behavior.\\n\\n• Tool  recipes:  also  see  http://code.activestate.com/recipes/252151,  an  Active  State\\nPython recipe that describes a tool that automatically fills in special method names\\nas generic call dispatchers in a proxy class created with metaclass techniques in-\\ntroduced later in this chapter. This tool still must ask you to pass in the operator\\n\\nNew-Style Class Changes\\n\\n| 991\\n\\n\\x0cmethod names that a wrapped object may implement, though (it must, as interface\\ncomponents of a wrapped object may be inherited from arbitrary sources).\\n\\n• Other approaches: a web search today will uncover numerous additional tools that\\nsimilarly populate proxy classes with overloading methods; it’s a widespread con-\\ncern! Again, in Chapter 39, we’ll also see how to code straightforward and general\\nsuperclasses  once  that  provide  the  required  methods  or  attributes  as  mix-ins,\\nwithout metaclasses, redundant code generation, or similarly complex techniques.\\n\\nThis story may evolve over time, of course, but has been an issue for many years. As\\nthis stands today, classic class proxies for objects that do any operator overloading are\\neffectively broken as new-style classes. Such classes in both 2.X and 3.X require coding\\nor generating wrappers for all the implicitly invoked operator methods a wrapped ob-\\nject may support. This is not ideal for such programs—some proxies may require doz-\\nens of wrapper methods (potentially over 50!)—but reflects, or is at least an artifact of,\\nthe design goals of new-style class developers.\\n\\nBe sure to see Chapter 40’s metaclass coverage for an additional illus-\\ntration of this issue and its rationale. We’ll also see there that this be-\\nhavior of built-ins qualifies as a special case in new-style inheritance.\\nUnderstanding this well requires more background on metaclasses than\\nthe current chapter can provide, a regrettable byproduct of metaclasses\\nin general—they’ve become prerequisite to more usage than their orig-\\ninators may have foreseen.\\n\\nType Model Changes\\nOn to our next new-style change: depending on your assessment, in new-style classes\\nthe distinction between type and class has either been greatly muted or has vanished\\nentirely. Specifically:\\n\\nClasses are types\\n\\nThe type object generates classes as its instances, and classes generate instances of\\nthemselves. Both are considered types, because they generate instances. In fact,\\nthere is no real difference between built-in types like lists and strings and user-\\ndefined types coded as classes. This is why we can subclass built-in types, as shown\\nearlier in this chapter—a subclass of a built-in type such as list qualifies as a new-\\nstyle class and becomes a new user-defined type.\\n\\nTypes are classes\\n\\nNew class-generating types may be coded in Python as the metaclasses we’ll meet\\nlater  in  this  chapter—user-defined  type  subclasses  that  are  coded  with  normal\\nclass statements, and control creation of the classes that are their instances. As\\nwe’ll see, metaclasses are both class and type, though they are distinct enough to\\nsupport a reasonable argument that the prior type/class dichotomy has become\\none of metaclass/class, perhaps at the cost of added complexity in normal classes.\\n\\n992 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cBesides allowing us to subclass built-in types and code metaclasses, one of the most\\npractical contexts where this type/class merging becomes most obvious is when we do\\nexplicit type testing. With Python 2.X’s classic classes, the type of a class instance is a\\ngeneric “instance,” but the types of built-in objects are more specific:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> class C: pass                       # Classic classes in 2.X\\n\\n>>> I = C()                             # Instances are made from classes\\n>>> type(I), I.__class__\\n(<type \\'instance\\'>, <class __main__.C at 0x02399768>)\\n\\n>>> type(C)                             # But classes are not the same as types\\n<type \\'classobj\\'>\\n>>> C.__class__\\nAttributeError: class C has no attribute \\'__class__\\'\\n\\n>>> type([1, 2, 3]), [1, 2, 3].__class__\\n(<type \\'list\\'>, <type \\'list\\'>)\\n\\n>>> type(list), list.__class__\\n(<type \\'type\\'>, <type \\'type\\'>)\\n\\nBut with new-style classes in 2.X, the type of a class instance is the class it’s created\\nfrom, since classes are simply user-defined types—the type of an instance is its class,\\nand the type of a user-defined class is the same as the type of a built-in object type.\\nClasses have a __class__ attribute now, too, because they are instances of type:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> class C(object): pass               # New-style classes in 2.X\\n\\n>>> I = C()                             # Type of instance is class it\\'s made from\\n>>> type(I), I.__class__\\n(<class \\'__main__.C\\'>, <class \\'__main__.C\\'>)\\n\\n>>> type(C), C.__class__                # Classes are user-defined types\\n(<type \\'type\\'>, <type \\'type\\'>)\\n\\nThe same is true for all classes in Python 3.X, since all classes are automatically new-\\nstyle, even if they have no explicit superclasses. In fact, the distinction between built-\\nin types and user-defined class types seems to melt away altogether in 3.X:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> class C: pass\\n\\n>>> I = C()                             # All classes are new-style in 3.X\\n>>> type(I), I.__class__                # Type of instance is class it\\'s made from\\n(<class \\'__main__.C\\'>, <class \\'__main__.C\\'>)\\n\\n>>> type(C), C.__class__                # Class is a type, and type is a class\\n(<class \\'type\\'>, <class \\'type\\'>)\\n\\n>>> type([1, 2, 3]), [1, 2, 3].__class__\\n(<class \\'list\\'>, <class \\'list\\'>)\\n\\nNew-Style Class Changes\\n\\n| 993\\n\\n\\x0c>>> type(list), list.__class__          # Classes and built-in types work the same\\n(<class \\'type\\'>, <class \\'type\\'>)\\n\\nAs you can see, in 3.X classes are types, but types are also classes. Technically, each\\nclass is generated by a metaclass—a class that is normally either type itself, or a subclass\\nof it customized to augment or manage generated classes. Besides impacting code that\\ndoes type testing, this turns out to be an important hook for tool developers. We’ll talk\\nmore about metaclasses later in this chapter, and again in more detail in Chapter 40.\\n\\nImplications for type testing\\nBesides providing for built-in type customization and metaclass hooks, the merging of\\nclasses and types in the new-style class model can impact code that does type testing.\\nIn Python 3.X, for example, the types of class instances compare directly and mean-\\ningfully, and in the same way as built-in type objects. This follows from the fact that\\nclasses are now types, and an instance’s type is the instance’s class:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> class C: pass\\n>>> class D: pass\\n\\n>>> c, d = C(), D()\\n>>> type(c) == type(d)                 # 3.X: compares the instances\\' classes\\nFalse\\n\\n>>> type(c), type(d)\\n(<class \\'__main__.C\\'>, <class \\'__main__.D\\'>)\\n>>> c.__class__, d.__class__\\n(<class \\'__main__.C\\'>, <class \\'__main__.D\\'>)\\n\\n>>> c1, c2 = C(), C()\\n>>> type(c1) == type(c2)\\nTrue\\n\\nWith classic classes in 2.X, though, comparing instance types is almost useless, because\\nall  instances  have  the  same  “instance”  type.  To  truly  compare  types,  the  instance\\n__class__ attributes must be compared (if you care about portability, this works in 3.X,\\ntoo, but it’s not required there):\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> class C: pass\\n>>> class D: pass\\n\\n>>> c, d = C(), D()\\n>>> type(c) == type(d)                 # 2.X: all instances are same type!\\nTrue\\n>>> c.__class__ == d.__class__         # Compare classes explicitly if needed\\nFalse\\n\\n>>> type(c), type(d)\\n(<type \\'instance\\'>, <type \\'instance\\'>)\\n>>> c.__class__, d.__class__\\n(<class __main__.C at 0x024585A0>, <class __main__.D at 0x024588D0>)\\n\\n994 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cAnd as you should expect by now, new-style classes in 2.X work the same as all classes\\nin 3.X in this regard—comparing instance types compares the instances’ classes auto-\\nmatically:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> class C(object): pass\\n>>> class D(object): pass\\n\\n>>> c, d = C(), D()\\n>>> type(c) == type(d)                 # 2.X new-style: same as all in 3.X\\nFalse\\n\\n>>> type(c), type(d)\\n(<class \\'__main__.C\\'>, <class \\'__main__.D\\'>)\\n>>> c.__class__, d.__class__\\n(<class \\'__main__.C\\'>, <class \\'__main__.D\\'>)\\n\\nOf course, as I’ve pointed out numerous times in this book, type checking is usually\\nthe wrong thing to do in Python programs (we code to object interfaces, not object\\ntypes), and the more general isinstance built-in is more likely what you’ll want to use\\nin the rare cases where instance class types must be queried. However, knowledge of\\nPython’s type model can help clarify the class model in general.\\n\\nAll Classes Derive from “object”\\nAnother ramification of the type change in the new-style class model is that because all\\nclasses derive (inherit) from the class object either implicitly or explicitly, and because\\nall types are now classes, every object derives from the object built-in class, whether\\ndirectly or through a superclass. Consider the following interaction in Python 3.X:\\n\\n>>> class C: pass                     # For new-style classes\\n>>> X = C()\\n>>> type(X), type(C)                  # Type is class instance was created from\\n(<class \\'__main__.C\\'>, <class \\'type\\'>)\\n\\nAs before, the type of a class instance is the class it was made from, and the type of a\\nclass is the type class because classes and types have merged. It is also true, though,\\nthat the instance and class are both derived from the built-in object class and type, an\\nimplicit or explicit superclass of every class:\\n\\n>>> isinstance(X, object)\\nTrue\\n>>> isinstance(C, object)             # Classes always inherit from object\\nTrue\\n\\nThe preceding returns the same results for both new-style and classic classes in 2.X\\ntoday, though 2.X type results differ. More importantly, as we’ll see ahead, object is\\nnot added to or present in a 2.X classic class’s __bases__ tuple, and so is not a true\\nsuperclass.\\n\\nNew-Style Class Changes\\n\\n| 995\\n\\n\\x0cThe same relationship holds true for built-in types like lists and strings, because types\\nare classes in the new-style model—built-in types are now classes, and their instances\\nderive from object, too:\\n\\n>>> type(\\'spam\\'), type(str)\\n(<class \\'str\\'>, <class \\'type\\'>)\\n\\n>>> isinstance(\\'spam\\', object)        # Same for  built-in types (classes)\\nTrue\\n>>> isinstance(str, object)\\nTrue\\n\\nIn fact, type itself derives from object, and object derives from type, even though the\\ntwo are different objects—a circular relationship that caps the object model and stems\\nfrom the fact that types are classes that generate classes:\\n\\n>>> type(type)                        # All classes are types, and vice versa\\n<class \\'type\\'>\\n>>> type(object)\\n<class \\'type\\'>\\n\\n>>> isinstance(type, object)          # All classes derive from object, even type\\nTrue\\n>>> isinstance(object, type)          # Types make classes, and type is a class\\nTrue\\n>>> type is object\\nFalse\\n\\nImplications for defaults\\nThe preceding may seem obscure, but this model has a number of practical implica-\\ntions. For one thing, it means that we sometimes must be aware of the method defaults\\nthat come with the explicit or implicit object root class in new-style classes only:\\n\\nc:\\\\code> py −2\\n>>> dir(object)\\n[\\'__class__\\', \\'__delattr__\\', \\'__doc__\\', \\'__format__\\', \\'__getattribute__\\', \\'__hash__\\'\\n, \\'__init__\\', \\'__new__\\', \\'__reduce__\\', \\'__reduce_ex__\\', \\'__repr__\\', \\'__setattr__\\', \\'\\n__sizeof__\\', \\'__str__\\', \\'__subclasshook__\\']\\n\\n>>> class C: pass\\n>>> C.__bases__                       # Classic classes do not inherit from object\\n()\\n>>> X = C()\\n>>> X.__repr__\\nAttributeError: C instance has no attribute \\'__repr__\\'\\n\\n>>> class C(object): pass             # New-style classes inherit object defaults\\n>>> C.__bases__\\n(<type \\'object\\'>,)\\n>>> X = C()\\n>>> X.__repr__\\n<method-wrapper \\'__repr__\\' of C object at 0x00000000020B5978>\\n\\nc:\\\\code> py −3\\n\\n996 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> class C: pass                     # This means all classes get defaults in 3.X\\n>>> C.__bases__\\n(<class \\'object\\'>,)\\n>>> C().__repr__\\n<method-wrapper \\'__repr__\\' of C object at 0x0000000002955630>\\n\\nThis model also makes for fewer special cases than the prior type/class distinction of\\nclassic  classes,  and  it  allows  us  to  write  code  that  can  safely  assume  and  use  an\\nobject superclass (e.g., by assuming it as an “anchor” in some super built-in roles de-\\nscribed ahead, and by passing it method calls to invoke default behavior). We’ll see\\nexamples of the latter later in the book; for now, let’s move on to explore the last major\\nnew-style change.\\n\\nDiamond Inheritance Change\\nOur final new-style class model change is also one of its most visible: its slightly different\\ninheritance search order for so-called diamond pattern multiple inheritance trees—a\\ntree pattern in which more than one superclass leads to the same higher superclass\\nfurther above (and whose name comes from the diamond shape of the tree if you sketch\\nout—a square resting on one of its corners).\\nThe diamond pattern is a fairly advanced design concept, only occurs in multiple in-\\nheritance trees, and tends to be coded rarely in Python practice, so we won’t cover this\\ntopic in full depth. In short, though, the differing search orders were introduced briefly\\nin the prior chapter’s multiple inheritance coverage:\\n\\nFor classic classes (the default in 2.X): DFLR\\n\\nThe inheritance search path is strictly depth first, and then left to right—Python\\nclimbs all the way to the top, hugging the left side of the tree, before it backs up\\nand begins to look further to the right. This search order is known as DFLR for the\\nfirst letters in its path’s directions.\\n\\nFor new-style classes (optional in 2.X and automatic in 3.X): MRO\\n\\nThe inheritance search path is more breadth-first in diamond cases—Python first\\nlooks in any superclasses to the right of the one just searched before ascending to\\nthe common superclass at the top. In other words, this search proceeds across by\\nlevels before moving up. This search order is called the new-style MRO for “method\\nresolution order” (and often just MRO for short when used in contrast with the\\nDFLR order). Despite the name, this is used for all attributes in Python, not just\\nmethods.\\n\\nThe new-style MRO algorithm is a bit more complex than just described—and we’ll\\nexpand on it a bit more formally later—but this is as much as many programmers need\\nto know. Still, it has both important benefits for new-style class code, as well as pro-\\ngram-breaking potential for existing classic class code.\\nFor example, the new-style MRO allows lower superclasses to overload attributes of\\nhigher superclasses, regardless of the sort of multiple inheritance trees they are mixed\\n\\nNew-Style Class Changes\\n\\n| 997\\n\\n\\x0cinto. Moreover, the new-style search rule avoids visiting the same superclass more than\\nonce when it is accessible from multiple subclasses. It’s arguably better than DFLR, but\\napplies to a small subset of Python user code; as we’ll see, though, the new-style class\\nmodel itself makes diamonds much more common, and the MRO more important.\\nAt the same time, the new MRO will locate attributes differently, creating a potential\\nincompatibility for 2.X classic classes. Let’s move on to some code to see how its dif-\\nferences pan out in practice.\\n\\nImplications for diamond inheritance trees\\nTo illustrate how the new-style MRO search differs, consider this simplistic incarnation\\nof the diamond multiple inheritance pattern for classic classes. Here, D’s superclasses\\nB and C both lead to the same common ancestor, A:\\n\\n>>> class A:       attr = 1           # Classic (Python 2.X)\\n>>> class B(A):    pass               # B and C both lead to A\\n>>> class C(A):    attr = 2\\n>>> class D(B, C): pass               # Tries A before C\\n\\n>>> x = D()\\n>>> x.attr                            # Searches x, D, B, A\\n1\\n\\nThe attribute x.attr here is found in superclass  A, because with classic classes, the\\ninheritance search climbs as high as it can before backing up and moving right. The\\nfull DFLR search order would visit x, D, B, A, C, and then A. For this attribute, the search\\nstops as soon as attr is found in A, above B.\\nHowever, with new-style classes derived from a built-in like object (and all classes in\\n3.X), the search order is different: Python looks in C to the right of B, before trying A\\nabove B. The full MRO search order would visit x, D, B, C, and then A. For this attribute,\\nthe search stops as soon as attr is found in C:\\n\\n>>> class A(object): attr = 1         # New-style (\"object\" not required in 3.X)\\n>>> class B(A):      pass\\n>>> class C(A):      attr = 2\\n>>> class D(B, C):   pass             # Tries C before A\\n\\n>>> x = D()\\n>>> x.attr                            # Searches x, D, B, C\\n2\\n\\nThis change in the inheritance search procedure is based upon the assumption that if\\nyou mix in C lower in the tree, you probably intend to grab its attributes in preference\\nto A’s. It also assumes that C is always intended to override A’s attributes in all contexts,\\nwhich is probably true when it’s used standalone but may not be when it’s mixed into\\na diamond with classic classes—you might not even know that C may be mixed in like\\nthis when you code it.\\n\\n998 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cSince it is most likely that the programmer meant that C should override A in this case,\\nthough, new-style classes visit C first. Otherwise, C could be essentially pointless in a\\ndiamond context for any names in A too—it could not customize A and would be used\\nonly for names unique to C.\\n\\nExplicit conflict resolution\\nOf course, the problem with assumptions is that they assume things! If this search order\\ndeviation seems too subtle to remember, or if you want more control over the search\\nprocess, you can always force the selection of an attribute from anywhere in the tree\\nby assigning or otherwise naming the one you want at the place where the classes are\\nmixed together. The following, for example, chooses new-style order in a classic class\\nby resolving the choice explicitly:\\n\\n>>> class A:       attr = 1           # Classic\\n>>> class B(A):    pass\\n>>> class C(A):    attr = 2\\n>>> class D(B, C): attr = C.attr      # <== Choose C, to the right\\n\\n>>> x = D()\\n>>> x.attr                            # Works like new-style (all 3.X)\\n2\\n\\nHere, a tree of classic classes is emulating the search order of new-style classes for a\\nspecific attribute: the assignment to the attribute in D picks the version in C, thereby\\nsubverting the normal inheritance search path (D.attr will be lowest in the tree). New-\\nstyle classes can similarly emulate classic classes by choosing the higher version of the\\ntarget attribute at the place where the classes are mixed together:\\n\\n>>> class A(object): attr = 1         # New-style\\n>>> class B(A):      pass\\n>>> class C(A):      attr = 2\\n>>> class D(B, C):   attr = B.attr    # <== Choose A.attr, above\\n\\n>>> x = D()\\n>>> x.attr                            # Works like classic (default 2.X)\\n1\\n\\nIf you are willing to always resolve conflicts like this, you may be able to largely ignore\\nthe search order difference and not rely on assumptions about what you meant when\\nyou coded your classes.\\nNaturally, attributes picked this way can also be method functions—methods are nor-\\nmal, assignable attributes that happen to reference callable function objects:\\n\\n>>> class A:\\n        def meth(s): print(\\'A.meth\\')\\n\\n>>> class C(A):\\n        def meth(s): print(\\'C.meth\\')\\n\\n>>> class B(A):\\n\\nNew-Style Class Changes\\n\\n| 999\\n\\n\\x0c        pass\\n\\n>>> class D(B, C): pass               # Use default search order\\n>>> x = D()                           # Will vary per class type\\n>>> x.meth()                          # Defaults to classic order in 2.X\\nA.meth\\n\\n>>> class D(B, C): meth = C.meth      # <== Pick C\\'s method: new-style (and 3.X)\\n>>> x = D()\\n>>> x.meth()\\nC.meth\\n\\n>>> class D(B, C): meth = B.meth      # <== Pick B\\'s method: classic\\n>>> x = D()\\n>>> x.meth()\\nA.meth\\n\\nHere, we select methods by explicitly assigning to names lower in the tree. We might\\nalso  simply  call  the  desired  class  explicitly;  in  practice,  this  pattern  might  be  more\\ncommon, especially for things like constructors:\\n\\nclass D(B, C):\\n    def meth(self):                   # Redefine lower\\n        ...\\n        C.meth(self)                  # <== Pick C\\'s method by calling\\n\\nSuch selections by assignment or call at mix-in points can effectively insulate your code\\nfrom this difference in class flavors. This applies only to the attributes you handle this\\nway, of course, but explicitly resolving the conflicts ensures that your code won’t vary\\nper Python version, at least in terms of attribute conflict selection. In other words, this\\ncan serve as a portability technique for classes that may need to be run under both the\\nnew-style and classic class models.\\n\\nExplicit is better than implicit—for method resolution too: Even without\\nthe classic/new-style class divergence, the explicit method resolution\\ntechnique shown here may come in handy in multiple inheritance sce-\\nnarios in general. For instance, if you want part of a superclass on the\\nleft and part of a superclass on the right, you might need to tell Python\\nwhich same-named attributes to choose by using explicit assignments\\nor calls in subclasses. We’ll revisit this notion in a “gotcha” at the end\\nof this chapter.\\n\\nAlso note that diamond inheritance patterns might be more problematic\\nin some cases than I’ve implied here (e.g., what if B and C both have\\nrequired constructors that call to the constructor in A?). Since such con-\\ntexts are rare in real-world Python, we’ll defer this topic until we explore\\nthe super built-in function near the end of this chapter; besides provid-\\ning generic access to superclasses in single inheritance trees, super sup-\\nports a cooperative mode for resolving conflicts in multiple inheritance\\ntrees  by  ordering  method  calls  per  the  MRO—assuming  this  order\\nmakes sense in this context too!\\n\\n1000 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cScope of search order change\\nIn sum, by default, the diamond pattern is searched differently for classic and new-style\\nclasses, and this is a non-backward-compatible change. Keep in mind, though, that this\\nchange primarily affects diamond pattern cases of multiple inheritance; new-style class\\ninheritance works the same for most other inheritance tree structures. Further, it’s not\\nimpossible that this entire issue may be of more theoretical than practical importance\\n—because the new-style search wasn’t significant enough to address until Python 2.2\\nand didn’t become standard until 3.0, it seems unlikely to impact most Python code.\\nHaving said that, I should also note that even though you might not code diamond\\npatterns in classes you write yourself, because the implied object superclass is above\\nevery root class in 3.X as we saw earlier, every case of multiple inheritance exhibits the\\ndiamond pattern today. That is, in new-style classes, object automatically plays the\\nrole that the class A does in the example we just considered. Hence the new-style MRO\\nsearch rule not only modifies logical semantics, but is also an important performance\\noptimization—it avoids visiting and searching the same class more than once, even the\\nautomatic object.\\nJust as important, we’ve also seen that the implied object superclass in the new-style\\nmodel  provides  default  methods  for  a  variety  of  built-in  operations,  including  the\\n__str__ and __repr__ display format methods. Run a dir(object) to see which methods\\nare provided. Without the new-style MRO search order, in multiple inheritance cases\\nthe defaults in object would always override redefinitions in user-coded classes, unless\\nthey were always made in the leftmost superclass. In other words, the new-style class\\nmodel itself makes using the new-style search order more critical!\\nFor a more visual example of the implied object superclass in 3.X, and other examples\\nof diamond patterns created by it, see the ListTree class’s output in the lister.py example\\nin the preceding chapter, as well as the classtree.py tree walker example in Chapter 29—\\nand the next section.\\n\\nMore on the MRO: Method Resolution Order\\nTo  trace  how  new-style  inheritance  works  by  default,  we  can  also  use  the  new\\nclass.__mro__ attribute mentioned in the preceding chapter’s class lister examples—\\ntechnically a new-style extension, but useful here to explore a change. This attribute\\nreturns a class’s MRO—the order in which inheritance searches classes in a new-style\\nclass tree. This MRO is based on the C3 superclass linearization algorithm initially\\ndeveloped in the Dylan programming language, but later adopted by other languages\\nincluding Python 2.3 and Perl 6.\\n\\nThe MRO algorithm\\nThis book avoids a full description of the MRO algorithm deliberately, because many\\nPython programmers don’t need to care (this only impacts diamonds, which are rela-\\n\\nNew-Style Class Changes\\n\\n| 1001\\n\\n\\x0ctively rare in real-world code); because it differs between 2.X and 3.X; and because the\\ndetails of the MRO are a bit too arcane and academic for this text. As a rule, this book\\navoids formal algorithms and prefers to teach informally by example.\\nOn the other hand, some readers may still have an interest in the formal theory behind\\nnew-style  MRO.  If  this  set  includes  you,  it’s  described  in  full  detail  online;  search\\nPython’s manuals and the Web for current MRO links. In short, though, the MRO\\nessentially works like this:\\n\\n1. List all the classes that an instance inherits from using the classic class’s DFLR\\n\\nlookup rule, and include a class multiple times if it’s visited more than once.\\n\\n2. Scan the resulting list for duplicate classes, removing all but the last occurrence of\\n\\nduplicates in the list.\\n\\nThe resulting MRO list for a given class includes the class, its superclasses, and all\\nhigher superclasses up to the object root class at the top of the tree. It’s ordered such\\nthat each class appears before its parents, and multiple parents retain the order in which\\nthey appear in the __bases__ superclass tuple.\\nCrucially, though, because common parents in diamonds appear only at the position\\nof their last visitation, lower classes are searched first when the MRO list is later used\\nby attribute inheritance. Moreover, each class is included and thus visited just once,\\nno matter how many classes lead to it.\\nWe’ll see applications of this algorithm later in this chapter, including that in super—\\na built-in that elevates the MRO to required reading if you wish to fully understand\\nhow methods are dispatched by this call, should you choose to use it. As we’ll see,\\ndespite its name, this call invokes the next class on the MRO, which might not be a\\nsuperclass at all.\\n\\nTracing the MRO\\nIf you just want to see how Python’s new-style inheritance orders superclasses in gen-\\neral, though, new-style classes (and hence all classes in 3.X) have a class.__mro__ at-\\ntribute, which is a tuple giving the linear search order Python uses to look up attributes\\nin superclasses. Really, this attribute is the inheritance order in new-style classes, and\\nis often as much MRO detail as many Python users need.\\nHere are some illustrative examples, run in 3.X; for diamond inheritance patterns only,\\nthe search is the new order we’ve been studying—across before up, per the MRO for\\nnew-style classes always used in 3.X, and available as an option in 2.X:\\n\\n>>> class A: pass\\n>>> class B(A): pass         # Diamonds: order differs for newstyle\\n>>> class C(A): pass         # Breadth-first across lower levels\\n>>> class D(B, C): pass\\n>>> D.__mro__\\n(<class \\'__main__.D\\'>, <class \\'__main__.B\\'>, <class \\'__main__.C\\'>,\\n<class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\n1002 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cFor nondiamonds, though, the search is still as it has always been (albeit with an extra\\nobject root)—to the top, and then to the right (a.k.a. DFLR, depth first and left to\\nright, the model used for all classic classes in 2.X):\\n\\n>>> class A: pass\\n>>> class B(A): pass         # Nondiamonds: order same as classic\\n>>> class C: pass            # Depth first, then left to right\\n>>> class D(B, C): pass\\n>>> D.__mro__\\n(<class \\'__main__.D\\'>, <class \\'__main__.B\\'>, <class \\'__main__.A\\'>,\\n<class \\'__main__.C\\'>, <class \\'object\\'>)\\n\\nThe MRO of the following tree, for example, is the same as the earlier diamond, per\\nDFLR:\\n\\n>>> class A: pass\\n>>> class B: pass            # Another nondiamond: DFLR\\n>>> class C(A): pass\\n>>> class D(B, C): pass\\n>>> D.__mro__\\n(<class \\'__main__.D\\'>, <class \\'__main__.B\\'>, <class \\'__main__.C\\'>,\\n<class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\nNotice how the implied object superclass always shows up at the end of the MRO; as\\nwe’ve seen, it’s added automatically above root (topmost) classes in new-style class trees\\nin 3.X (and optionally in 2.X):\\n\\n>>> A.__bases__              # Superclass links: object at two roots\\n(<class \\'object\\'>,)\\n>>> B.__bases__\\n(<class \\'object\\'>,)\\n>>> C.__bases__\\n(<class \\'__main__.A\\'>,)\\n>>> D.__bases__\\n(<class \\'__main__.B\\'>, <class \\'__main__.C\\'>)\\n\\nTechnically, the implied object superclass always creates a diamond in multiple in-\\nheritance even if your classes do not—your classes are searched as before, but the new-\\nstyle MRO ensures that object is visited last, so your classes can override its defaults:\\n\\n>>> class X: pass\\n>>> class Y: pass\\n>>> class A(X): pass         # Nondiamond: depth first then left to right\\n>>> class B(Y): pass         # Though implied \"object\" always forms a diamond\\n>>> class D(A, B): pass\\n>>> D.mro()\\n[<class \\'__main__.D\\'>, <class \\'__main__.A\\'>, <class \\'__main__.X\\'>,\\n<class \\'__main__.B\\'>, <class \\'__main__.Y\\'>, <class \\'object\\'>]\\n\\n>>> X.__bases__, Y.__bases__\\n((<class \\'object\\'>,), (<class \\'object\\'>,))\\n>>> A.__bases__, B.__bases__\\n((<class \\'__main__.X\\'>,), (<class \\'__main__.Y\\'>,))\\n\\nNew-Style Class Changes\\n\\n| 1003\\n\\n\\x0cThe class.__mro__ attribute is available only on new-style classes; it’s not present in\\n2.X unless classes derive from object. Strictly speaking, new-style classes also have a\\nclass.mro() method used in the prior example for variety; it’s called at class instantia-\\ntion time and its return value is a list used to initialize the __mro__ attribute when the\\nclass is created (the method is available for customization in metaclasses, described\\nlater). You can also select MRO names if classes’ object displays are too detailed, though\\nthis book usually shows the objects to remind you of their true form:\\n\\n>>> D.mro() == list(D.__mro__)\\nTrue\\n>>> [cls.__name__ for cls in D.__mro__]\\n[\\'D\\', \\'A\\', \\'X\\', \\'B\\', \\'Y\\', \\'object\\']\\n\\nHowever you access or display them, class MRO paths might be useful to resolve con-\\nfusion, and in tools that must imitate Python’s inheritance search order. The next sec-\\ntion shows the latter role in action.\\n\\nExample: Mapping Attributes to Inheritance Sources\\nAs a prime MRO use case, we noted at the end of the prior chapter that class tree\\nclimbers—such as the class tree lister mix-in we wrote there—might benefit from the\\nMRO. As coded, the tree lister gave the physical locations of attributes in a class tree.\\nHowever, by mapping the list of inherited attributes in a dir result to the linear MRO\\nsequence (or DFLR order for classic classes), such tools can more directly associate\\nattributes with the classes from which they are inherited—also a useful relationship for\\nprogrammers.\\nWe  won’t  recode  our  tree  lister  here,  but  as  a  first  major  step,  the  following  file,\\nmapattrs.py, implements tools that can be used to associate attributes with their in-\\nheritance source; as an added bonus, its mapattrs function demonstrates how inheri-\\ntance actually searches for attributes in class tree objects, though the new-style MRO\\nis largely automated for us:\\n\\n\"\"\"\\nFile mapattrs.py (3.X + 2.X)\\n\\nMain tool: mapattrs() maps all attributes on or inherited by an\\ninstance to the instance or class from which they are inherited.\\n\\nAssumes dir() gives all attributes of an instance.  To simulate\\ninheritance, uses either the class\\'s MRO tuple, which gives the\\nsearch order for new-style classes (and all in 3.X), or a recursive\\ntraversal to infer the DFLR order of classic classes in 2.X.\\n\\nAlso here: inheritance() gives version-neutral class ordering;\\nassorted dictionary tools using 3.X/2.7 comprehensions.\\n\"\"\"\\n\\nimport pprint\\ndef trace(X, label=\\'\\', end=\\'\\\\n\\'):\\n\\n1004 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c    print(label + pprint.pformat(X) + end)  # Print nicely\\n\\ndef filterdictvals(D, V):\\n    \"\"\"\\n    dict D with entries for value V removed.\\n    filterdictvals(dict(a=1, b=2, c=1), 1) => {\\'b\\': 2}\\n    \"\"\"\\n    return {K: V2 for (K, V2) in D.items() if V2 != V}\\n\\ndef invertdict(D):\\n    \"\"\"\\n    dict D with values changed to keys (grouped by values).\\n    Values must all be hashable to work as dict/set keys.\\n    invertdict(dict(a=1, b=2, c=1)) => {1: [\\'a\\', \\'c\\'], 2: [\\'b\\']}\\n    \"\"\"\\n    def keysof(V):\\n        return sorted(K for K in D.keys() if D[K] == V)\\n    return {V: keysof(V) for V in set(D.values())}\\n\\ndef dflr(cls):\\n    \"\"\"\\n    Classic depth-first left-to-right order of class tree at cls.\\n    Cycles not possible: Python disallows on __bases__ changes.\\n    \"\"\"\\n    here = [cls]\\n    for sup in cls.__bases__:\\n        here += dflr(sup)\\n    return here\\n\\ndef inheritance(instance):\\n    \"\"\"\\n    Inheritance order sequence: new-style (MRO) or classic (DFLR)\\n    \"\"\"\\n    if hasattr(instance.__class__, \\'__mro__\\'):\\n        return (instance,) + instance.__class__.__mro__\\n    else:\\n        return [instance] + dflr(instance.__class__)\\n\\ndef mapattrs(instance, withobject=False, bysource=False):\\n    \"\"\"\\n    dict with keys giving all inherited attributes of instance,\\n    with values giving the object that each is inherited from.\\n    withobject: False=remove object built-in class attributes.\\n    bysource:   True=group result by objects instead of attributes.\\n    Supports classes with slots that preclude __dict__ in instances.\\n    \"\"\"\\n    attr2obj = {}\\n    inherits = inheritance(instance)\\n    for attr in dir(instance):\\n        for obj in inherits:\\n             if hasattr(obj, \\'__dict__\\') and attr in obj.__dict__:      # See slots\\n               attr2obj[attr] = obj\\n               break\\n\\n    if not withobject:\\n\\nNew-Style Class Changes\\n\\n| 1005\\n\\n\\x0c        attr2obj = filterdictvals(attr2obj, object)\\n    return attr2obj if not bysource else invertdict(attr2obj)\\n\\nif __name__ == \\'__main__\\':\\n    print(\\'Classic classes in 2.X, new-style in 3.X\\')\\n    class A:         attr1 = 1\\n    class B(A):      attr2 = 2\\n    class C(A):      attr1 = 3\\n    class D(B, C):   pass\\n    I = D()\\n    print(\\'Py=>%s\\' % I.attr1)                        # Python\\'s search == ours?\\n    trace(inheritance(I),             \\'INH\\\\n\\')       # [Inheritance order]\\n    trace(mapattrs(I),                \\'ATTRS\\\\n\\')     # Attrs  => Source\\n    trace(mapattrs(I, bysource=True), \\'OBJS\\\\n\\')      # Source => [Attrs]\\n\\n    print(\\'New-style classes in 2.X and 3.X\\')\\n    class A(object): attr1 = 1                       # \"(object)\" optional in 3.X\\n    class B(A):      attr2 = 2\\n    class C(A):      attr1 = 3\\n    class D(B, C):   pass\\n    I = D()\\n    print(\\'Py=>%s\\' % I.attr1)\\n    trace(inheritance(I),             \\'INH\\\\n\\')\\n    trace(mapattrs(I),                \\'ATTRS\\\\n\\')\\n    trace(mapattrs(I, bysource=True), \\'OBJS\\\\n\\')\\n\\nThis file assumes dir gives all an instance’s attributes. It maps each attribute in a dir\\nresult to its source by scanning either the MRO order for new-style classes, or the DFLR\\norder for classic classes, searching each object’s namespace __dict__ along the way.\\nFor classic classes, the DFLR order is computed with a simple recursive scan. The net\\neffect is to simulate Python’s inheritance search in both class models.\\nThis file’s self-test code applies its tools to the diamond multiple-inheritance trees we\\nsaw earlier. It uses Python’s pprint library module to display lists and dictionaries nicely\\n—pprint.pprint is its basic call, and its  pformat returns a print string. Run this on\\nPython 2.7 to see both classic DFLR and new-style MRO search orders; on Python 3.3,\\nthe object derivation is unnecessary, and both tests give the same, new-style results.\\nImportantly, attr1, whose value is labeled with “Py=>” and whose name appears in\\nthe results lists, is inherited from class A in classic search, but from class C in new-style\\nsearch:\\n\\nc:\\\\code> py −2 mapattrs.py\\nClassic classes in 2.X, new-style in 3.X\\nPy=>1\\nINH\\n[<__main__.D instance at 0x000000000225A688>,\\n <class __main__.D at 0x0000000002248828>,\\n <class __main__.B at 0x0000000002248768>,\\n <class __main__.A at 0x0000000002248708>,\\n <class __main__.C at 0x00000000022487C8>,\\n <class __main__.A at 0x0000000002248708>]\\n\\nATTRS\\n\\n1006 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c{\\'__doc__\\': <class __main__.D at 0x0000000002248828>,\\n \\'__module__\\': <class __main__.D at 0x0000000002248828>,\\n \\'attr1\\': <class __main__.A at 0x0000000002248708>,\\n \\'attr2\\': <class __main__.B at 0x0000000002248768>}\\n\\nOBJS\\n{<class __main__.A at 0x0000000002248708>: [\\'attr1\\'],\\n <class __main__.B at 0x0000000002248768>: [\\'attr2\\'],\\n <class __main__.D at 0x0000000002248828>: [\\'__doc__\\', \\'__module__\\']}\\n\\nNew-style classes in 2.X and 3.X\\nPy=>3\\nINH\\n(<__main__.D object at 0x0000000002257B38>,\\n <class \\'__main__.D\\'>,\\n <class \\'__main__.B\\'>,\\n <class \\'__main__.C\\'>,\\n <class \\'__main__.A\\'>,\\n <type \\'object\\'>)\\n\\nATTRS\\n{\\'__dict__\\': <class \\'__main__.A\\'>,\\n \\'__doc__\\': <class \\'__main__.D\\'>,\\n \\'__module__\\': <class \\'__main__.D\\'>,\\n \\'__weakref__\\': <class \\'__main__.A\\'>,\\n \\'attr1\\': <class \\'__main__.C\\'>,\\n \\'attr2\\': <class \\'__main__.B\\'>}\\n\\nOBJS\\n{<class \\'__main__.A\\'>: [\\'__dict__\\', \\'__weakref__\\'],\\n <class \\'__main__.B\\'>: [\\'attr2\\'],\\n <class \\'__main__.C\\'>: [\\'attr1\\'],\\n <class \\'__main__.D\\'>: [\\'__doc__\\', \\'__module__\\']}\\n\\nAs a larger application of these tools, the following is our inheritance simulator at work\\nin 3.3 on the preceding chapter’s testmixin0.py file’s test classes (I’ve deleted some built-\\nin names here for space; as usual, run live for the whole list). Notice how __X pseudo-\\nprivate names are mapped to their defining classes, and how ListInstance appears in\\nthe MRO before object, which has a __str__ that would otherwise be chosen first—as\\nyou’ll recall, mixing this method in was the whole point of the lister classes!\\n\\nc:\\\\code> py −3\\n>>> from mapattrs import trace, dflr, inheritance, mapattrs\\n>>> from testmixin0 import Sub\\n>>> I = Sub()                      # Sub inherits from Super and ListInstance roots\\n>>> trace(dflr(I.__class__))       # 2.X search order: implied object before lister!\\n[<class \\'testmixin0.Sub\\'>,\\n <class \\'testmixin0.Super\\'>,\\n <class \\'object\\'>,\\n <class \\'listinstance.ListInstance\\'>,\\n <class \\'object\\'>]\\n\\n>>> trace(inheritance(I))          # 3.X (+ 2.X newstyle) search order: lister first\\n(<testmixin0.Sub object at 0x0000000002974630>,\\n <class \\'testmixin0.Sub\\'>,\\n\\nNew-Style Class Changes\\n\\n| 1007\\n\\n\\x0c <class \\'testmixin0.Super\\'>,\\n <class \\'listinstance.ListInstance\\'>,\\n <class \\'object\\'>)\\n\\n>>> trace(mapattrs(I))\\n{\\'_ListInstance__attrnames\\': <class \\'listinstance.ListInstance\\'>,\\n \\'__init__\\': <class \\'testmixin0.Sub\\'>,\\n \\'__str__\\': <class \\'listinstance.ListInstance\\'>,\\n ...etc...\\n \\'data1\\': <testmixin0.Sub object at 0x0000000002974630>,\\n \\'data2\\': <testmixin0.Sub object at 0x0000000002974630>,\\n \\'data3\\': <testmixin0.Sub object at 0x0000000002974630>,\\n \\'ham\\': <class \\'testmixin0.Super\\'>,\\n \\'spam\\': <class \\'testmixin0.Sub\\'>}\\n\\n>>> trace(mapattrs(I, bysource=True))\\n{<testmixin0.Sub object at 0x0000000002974630>: [\\'data1\\', \\'data2\\', \\'data3\\'],\\n <class \\'listinstance.ListInstance\\'>: [\\'_ListInstance__attrnames\\', \\'__str__\\'],\\n <class \\'testmixin0.Super\\'>: [\\'__dict__\\', \\'__weakref__\\', \\'ham\\'],\\n <class \\'testmixin0.Sub\\'>: [\\'__doc__\\',\\n                            \\'__init__\\',\\n                            \\'__module__\\',\\n                            \\'__qualname__\\',\\n                            \\'spam\\']}\\n\\n>>> trace(mapattrs(I, withobject=True))\\n{\\'_ListInstance__attrnames\\': <class \\'listinstance.ListInstance\\'>,\\n \\'__class__\\': <class \\'object\\'>,\\n \\'__delattr__\\': <class \\'object\\'>,\\n ...etc...\\n\\nHere’s the bit you might run if you want to label class objects with names inherited by\\nan instance, though you may want to filter out some built-in double-underscore names\\nfor the sake of users’ eyesight!\\n\\n>>> amap = mapattrs(I, withobject=True, bysource=True)\\n>>> trace(amap)\\n{<testmixin0.Sub object at 0x0000000002974630>: [\\'data1\\', \\'data2\\', \\'data3\\'],\\n <class \\'listinstance.ListInstance\\'>: [\\'_ListInstance__attrnames\\', \\'__str__\\'],\\n <class \\'testmixin0.Super\\'>: [\\'__dict__\\', \\'__weakref__\\', \\'ham\\'],\\n <class \\'testmixin0.Sub\\'>: [\\'__doc__\\',\\n                            \\'__init__\\',\\n                            \\'__module__\\',\\n                            \\'__qualname__\\',\\n                            \\'spam\\'],\\n <class \\'object\\'>: [\\'__class__\\',\\n                    \\'__delattr__\\',\\n                    ...etc...\\n                    \\'__sizeof__\\',\\n                    \\'__subclasshook__\\']}\\n\\nFinally, and as both a follow-up to the prior chapter’s ruminations and segue to the\\nnext section here, the following shows how this scheme works for class-based slots\\nattributes too. Because a class’s  __dict__ includes both normal class attributes and\\nindividual entries for the instance attributes defined by its __slots__ list, the slots at-\\n\\n1008 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0ctributes inherited by an instance will be correctly associated with the implementing\\nclass from which they are acquired, even though they are not physically stored in the\\ninstance’s __dict__ itself:\\n\\n# mapattrs-slots.py: test __slots__ attribute inheritance\\nfrom mapattrs import mapattrs, trace\\n\\nclass A(object): __slots__ = [\\'a\\', \\'b\\']; x = 1; y = 2\\nclass B(A):      __slots__ = [\\'b\\', \\'c\\']\\nclass C(A):      x = 2\\nclass D(B, C):\\n    z = 3\\n    def __init__(self): self.name = \\'Bob\\';\\n\\nI = D()\\ntrace(mapattrs(I, bysource=True))     # Also: trace(mapattrs(I))\\n\\nFor explicitly new-style classes like those in this file, the results are the same under both\\n2.7 and 3.3, though 3.3 adds an extra built-in name to the set. The attribute names here\\nreflect all those inherited by the instance from user-defined classes, even those imple-\\nmented by slots defined at classes and stored in space allocated in the instance:\\n\\nc:\\\\code> py −3 mapattrs-slots.py\\n{<__main__.D object at 0x00000000028988E0>: [\\'name\\'],\\n <class \\'__main__.C\\'>: [\\'x\\'],\\n <class \\'__main__.D\\'>: [\\'__dict__\\',\\n                        \\'__doc__\\',\\n                        \\'__init__\\',\\n                        \\'__module__\\',\\n                        \\'__qualname__\\',\\n                        \\'__weakref__\\',\\n                        \\'z\\'],\\n <class \\'__main__.A\\'>: [\\'a\\', \\'y\\'],\\n <class \\'__main__.B\\'>: [\\'__slots__\\', \\'b\\', \\'c\\']}\\n\\nBut we need to move ahead to understand the role of slots better—and understand why\\nmapattrs must be careful to check to see if a __dict__ is present before fetching it!\\nStudy this code for more insight. For the prior chapter’s tree lister, your next step might\\nbe to index the mapattrs function’s bysource=True dictionary result to obtain an object’s\\nattributes during the tree sketch traversal, instead of (or perhaps in addition to?) its\\ncurrent physical __dict__ scan. You’ll probably need to use getattr on the instance to\\nfetch attribute values, because some may be implemented as slots or other “virtual”\\nattributes at their source classes, and fetching these at the class directly won’t return\\nthe instance’s value. If I code anymore here, though, I’ll deprive readers of the remaining\\nfun, and the next section of its subject matter.\\n\\nNew-Style Class Changes\\n\\n| 1009\\n\\n\\x0cPython’s pprint module used in this example works as shown in Pythons\\n3.3 and 2.7, but appears to have an issue in Pythons 3.2 and 3.1 where\\nit raises a wrong-number-arguments exception internally for the objects\\ndisplayed here. Since I’ve already devoted too much space to covering\\ntransitory Python defects, and since this has been repaired in the ver-\\nsions of Python used in this edition, we’ll leave working around this in\\nthe suggested exercises column for readers running this on the infected\\nPythons; change trace to simple prints as needed, and mind the note\\non battery dependence in Chapter 1!\\n\\nNew-Style Class Extensions\\nBeyond the changes described in the prior section (some of which, frankly, may seem\\ntoo academic and obscure to matter to many readers of this book), new-style classes\\nprovide a handful of more advanced class tools that have more direct and practical\\napplication—slots, properties, descriptors, and more. The following sections provide an\\noverview of each of these additional features, available for new-style class in Python\\n2.X and all classes in Python 3.X. Also in this extensions category are the __mro__ at-\\ntribute and the super call, both covered elsewhere—the former in the previous section\\nto explore a change, and the latter postponed until chapter end to serve as a larger case\\nstudy.\\n\\nSlots: Attribute Declarations\\nBy assigning a sequence of string attribute names to a special __slots__ class attribute,\\nwe can enable a new-style class to both limit the set of legal attributes that instances of\\nthe class will have, and optimize memory usage and possibly program speed. As we’ll\\nfind, though, slots should be used only in applications that clearly warrant the added\\ncomplexity. They will complicate your code, may complicate or break code you may\\nuse, and require universal deployment to be effective.\\n\\nSlot basics\\nTo use slots, assign a sequence of string names to the special __slots__ variable and\\nattribute at the top level of a class statement: only those names in the __slots__ list\\ncan be assigned as instance attributes. However, like all names in Python, instance\\nattribute names must still be assigned before they can be referenced, even if they’re\\nlisted in __slots__:\\n\\n>>> class limiter(object):\\n        __slots__ = [\\'age\\', \\'name\\', \\'job\\']\\n\\n>>> x = limiter()\\n>>> x.age                                           # Must assign before use\\nAttributeError: age\\n\\n1010 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> x.age = 40                                      # Looks like instance data\\n>>> x.age\\n40\\n>>> x.ape = 1000                                    # Illegal: not in __slots__\\nAttributeError: \\'limiter\\' object has no attribute \\'ape\\'\\n\\nThis feature is envisioned as both a way to catch typo errors like this (assignments to\\nillegal attribute names not in __slots__ are detected) as well as an optimization mech-\\nanism.\\nAllocating a namespace dictionary for every instance object can be expensive in terms\\nof memory if many instances are created and only a few attributes are required. To save\\nspace, instead of allocating a dictionary for each instance, Python reserves just enough\\nspace in each instance to hold a value for each slot attribute, along with inherited at-\\ntributes  in  the  common  class  to  manage  slot  access.  This  might  additionally  speed\\nexecution, though this benefit is less clear and might vary per program, platform, and\\nPython.\\nSlots are also something of a major break with Python’s core dynamic nature, which\\ndictates that any name may be created by assignment. In fact, they imitate C++ for\\nefficiency at the expense of flexibility, and even have the potential to break some pro-\\ngrams. As we’ll see, slots also come with a plethora of special-case usage rules. Per\\nPython’s own manual, they should not be used except in clearly warranted cases—they\\nare difficult to use correctly, and are, to quote the manual:\\n\\nbest reserved for rare cases where there are large numbers of instances in a memory-\\ncritical application.\\n\\nIn other words, this is yet another feature that should be used only if clearly warranted.\\nUnfortunately, slots seem to be showing up in Python code much more often than they\\nshould; their obscurity seems to be a draw in itself. As usual, knowledge is your best\\nally in such things, so let’s take a quick look here.\\n\\nIn Python 3.3, non-slots attribute space requirements have been reduced\\nwith a key-sharing dictionary model, where the  __dict__ dictionaries\\nused for objects’ attributes may share part of their internal storage, in-\\ncluding  that  of  their  keys.  This  may  lessen  some  of  the  value  of\\n__slots__ as an optimization tool; per benchmark reports, this change\\nreduces memory use by 10% to 20% for object-oriented programs, gives\\na small improvement in speed for programs that create many similar\\nobjects, and may be optimized further in the future. On the other hand,\\nthis won’t negate the presence of __slots__ in existing code you may\\nneed to understand!\\n\\nSlots and namespace dictionaries\\nPotential benefits aside, slots can complicate the class model—and code that relies on\\nit—substantially. In fact, some instances with slots may not have a __dict__ attribute\\n\\nNew-Style Class Extensions\\n\\n| 1011\\n\\n\\x0cnamespace dictionary at all, and others will have data attributes that this dictionary\\ndoes not include. To be clear: this is a major incompatibility with the traditional class\\nmodel—one that can complicate any code that accesses attributes generically, and may\\neven cause some programs to fail altogether.\\nFor instance, programs that list or access instance attributes by name string may need\\nto use more storage-neutral interfaces than __dict__ if slots may be used. Because an\\ninstance’s data may include class-level names such as slots—either in addition to or\\ninstead of namespace dictionary storage—both attribute sources may need to be quer-\\nied for completeness.\\nLet’s see what this means in terms of code, and explore more about slots along the way.\\nFirst off, when slots are used, instances do not normally have an attribute dictionary\\n—instead, Python uses the class descriptors feature introduced ahead to allocate and\\nmanage space reserved for slot attributes in the instance. In Python 3.X, and in 2.X for\\nnew-style classes derived from object:\\n\\n>>> class C:                             # Requires \"(object)\" in 2.X only\\n        __slots__ = [\\'a\\', \\'b\\']           # __slots__ means no __dict__ by default\\n\\n>>> X = C()\\n>>> X.a = 1\\n>>> X.a\\n1\\n>>> X.__dict__\\nAttributeError: \\'C\\' object has no attribute \\'__dict__\\'\\n\\nHowever, we can still fetch and set slot-based attributes by name string using storage-\\nneutral tools such as getattr and setattr (which look beyond the instance __dict__\\nand thus include class-level names like slots) and dir (which collects all inherited names\\nthroughout a class tree):\\n\\n>>> getattr(X, \\'a\\')\\n1\\n>>> setattr(X, \\'b\\', 2)                   # But getattr() and setattr() still work\\n>>> X.b\\n2\\n>>> \\'a\\' in dir(X)                        # And dir() finds slot attributes too\\nTrue\\n>>> \\'b\\' in dir(X)\\nTrue\\n\\nAlso keep in mind that without an attribute namespace dictionary, it’s not possible to\\nassign new names to instances that are not names in the slots list:\\n\\n>>> class D:                             # Use D(object) for same result in 2.X\\n        __slots__ = [\\'a\\', \\'b\\']\\n        def __init__(self):\\n            self.d = 4                   # Cannot add new names if no __dict__\\n\\n>>> X = D()\\nAttributeError: \\'D\\' object has no attribute \\'d\\'\\n\\n1012 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cWe can still accommodate extra attributes, though, by including __dict__ explicitly in\\n__slots__, in order to create an attribute namespace dictionary too:\\n\\n>>> class D:\\n        __slots__ = [\\'a\\', \\'b\\', \\'__dict__\\']    # Name __dict__ to include one too\\n        c = 3                                 # Class attrs work normally\\n        def __init__(self):\\n            self.d = 4                        # d stored in __dict__, a is a slot\\n\\n>>> X = D()\\n>>> X.d\\n4\\n>>> X.c\\n3\\n>>> X.a                          # All instance attrs undefined until assigned\\nAttributeError: a\\n>>> X.a = 1\\n>>> X.b = 2\\n\\nIn this case, both storage mechanisms are used. This renders __dict__ too limited for\\ncode that wishes to treat slots as instance data, but generic tools such as getattr still\\nallow us to process both storage forms as a single set of attributes:\\n\\n>>> X.__dict__                   # Some objects have both __dict__ and slot names\\n{\\'d\\': 4}                         # getattr() can fetch either type of attr\\n>>> X.__slots__\\n[\\'a\\', \\'b\\', \\'__dict__\\']\\n>>> getattr(X, \\'a\\'), getattr(X, \\'c\\'), getattr(X, \\'d\\')    # Fetches all 3 forms\\n(1, 3, 4)\\n\\nBecause dir also returns all inherited attributes, though, it might be too broad in some\\ncontexts; it also includes class-level methods, and even all object defaults. Code that\\nwishes to list just instance attributes may in principle still need to allow for both storage\\nforms explicitly. We might at first naively code this as follows:\\n\\n>>> for attr in list(X.__dict__) + X.__slots__:          # Wrong...\\n        print(attr, \\'=>\\', getattr(X, attr))\\n\\nSince either can be omitted, we may more correctly code this as follows, using  get\\nattr to allow for defaults—a noble but nonetheless inaccurate approach, as the next\\nsection will explain:\\n\\n>>> for attr in list(getattr(X, \\'__dict__\\', [])) + getattr(X, \\'__slots__\\', []):\\n        print(attr, \\'=>\\', getattr(X, attr))\\n\\nd => 4\\na => 1                                                   # Less wrong...\\nb => 2\\n__dict__ => {\\'d\\': 4}\\n\\nMultiple __slot__ lists in superclasses\\nThe preceding code works in this specific case, but in general it’s not entirely accu-\\nrate. Specifically, this code addresses only slot names in the lowest __slots__ attribute\\n\\nNew-Style Class Extensions\\n\\n| 1013\\n\\n\\x0cinherited by an instance, but slot lists may appear more than once in a class tree. That\\nis, a name’s absence in the lowest __slots__ list does not preclude its existence in a\\nhigher __slots__. Because slot names become class-level attributes, instances acquire\\nthe union of all slot names anywhere in the tree, by the normal inheritance rule:\\n\\n>>> class E:\\n        __slots__ = [\\'c\\', \\'d\\']            # Superclass has slots\\n>>> class D(E):\\n        __slots__ = [\\'a\\', \\'__dict__\\']     # But so does its subclass\\n\\n>>> X = D()\\n>>> X.a = 1; X.b = 2; X.c = 3             # The instance is the union (slots: a, c)\\n>>> X.a, X.c\\n(1, 3)\\n\\nInspecting just the inherited slots list won’t pick up slots defined higher in a class tree:\\n\\n>>> E.__slots__                           # But slots are not concatenated\\n[\\'c\\', \\'d\\']\\n>>> D.__slots__\\n[\\'a\\', \\'__dict__\\']\\n>>> X.__slots__                           # Instance inherits *lowest* __slots__\\n[\\'a\\', \\'__dict__\\']\\n>>> X.__dict__                            # And has its own an attr dict\\n{\\'b\\': 2}\\n\\n>>> for attr in list(getattr(X, \\'__dict__\\', [])) + getattr(X, \\'__slots__\\', []):\\n        print(attr, \\'=>\\', getattr(X, attr))\\n\\nb => 2                                    # Other superclass slots missed!\\na => 1\\n__dict__ => {\\'b\\': 2}\\n\\n>>> dir(X)                                # But dir() includes all slot names\\n[...many names omitted... \\'a\\', \\'b\\', \\'c\\', \\'d\\']\\n\\nIn other words, in terms of listing instance attributes generically, one __slots__ isn’t\\nalways enough—they are potentially subject to the full inheritance search procedure.\\nSee  the  earlier  mapattrs-slots.py  for  another  example  of  slots  appearing  in  multiple\\nsuperclasses.  If  multiple  classes  in  a  class  tree  have  their  own  __slots__  attributes,\\ngeneric programs must develop other policies for listing attributes—as the next section\\nexplains.\\n\\nHandling slots and other “virtual” attributes generically\\nAt  this  point,  you  may  wish  to  review  the  discussion  of  slots  policy  options  at  the\\ncoverage of the lister.py display mix-in classes near the end of the preceding chapter—\\na prime example of why generic programs may need to care about slots. Such tools that\\nattempt to list instance data attributes generically must account for slots, and perhaps\\nother such “virtual” instance attributes like properties and descriptors discussed ahead\\n—names that similarly reside in classes but may provide attribute values for instances\\n\\n1014 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0con request. Slots are the most data-centric of these, but are representative of a larger\\ncategory.\\nSuch attributes require inclusive approaches, special handling, or general avoidance—\\nthe latter of which becomes unsatisfactory as soon as any programmer uses slots in\\nsubject code. Really, class-level instance attributes like slots probably necessitate a re-\\ndefinition of the term instance data—as locally stored attributes, the union of all in-\\nherited attributes, or some subset thereof.\\nFor example, some programs might classify slot names as attributes of classes instead\\nof instances; these attributes do not exist in instance namespace dictionaries, after all.\\nAlternatively, as shown earlier, programs can be more inclusive by relying on dir to\\nfetch all inherited attribute names and getattr to fetch their corresponding values for\\nthe instance—without regard to their physical location or implementation. If you must\\nsupport slots as instance data, this is likely the most robust way to proceed:\\n\\n>>> class Slotful:\\n        __slots__ = [\\'a\\', \\'b\\', \\'__dict__\\']\\n        def __init__(self, data):\\n            self.c = data\\n\\n>>> I = Slotful(3)\\n>>> I.a, I.b = 1, 2\\n>>> I.a, I.b, I.c                            # Normal attribute fetch\\n(1, 2, 3)\\n\\n>>> I.__dict__                               # Both __dict__ and slots storage\\n{\\'c\\': 3}\\n>>> [x for x in dir(I) if not x.startswith(\\'__\\')]\\n[\\'a\\', \\'b\\', \\'c\\']\\n\\n>>> I.__dict__[\\'c\\']                          # __dict__ is only one attr source\\n3\\n>>> getattr(I, \\'c\\'), getattr(I, \\'a\\')         # dir+getattr is broader than __dict__\\n(3, 1)                                       # applies to slots, properties, descrip\\n\\n>>> for a in (x for x in dir(I) if not x.startswith(\\'__\\')):\\n        print(a, getattr(I, a))\\n\\na 1\\nb 2\\nc 3\\n\\nUnder this dir/getattr model, you can still map attributes to their inheritance sources,\\nand filter them more selectively by source or type if needed, by scanning the MRO—\\nas we did earlier in both mapattrs.py and its application to slots in mapattrs-slots.py.\\nAs an added bonus, such tools and policies for handling slots will potentially apply\\nautomatically to properties and descriptors too, though these attributes are more ex-\\nplicitly computed values, and less obviously instance-related data than slots.\\nAlso keep in mind that this is not just a tools issue. Class-based instance attributes like\\nslots also impact the traditional coding of the __setattr__ operator overloading method\\n\\nNew-Style Class Extensions\\n\\n| 1015\\n\\n\\x0cwe met in Chapter 30. Because slots and some other attributes are not stored in the\\ninstance __dict__, and may even imply its absence, new-style classes must instead gen-\\nerally run attribute assignments by routing them to the object superclass. In practice,\\nthis  may  make  this  method  fundamentally  different  in  some  classic  and  new-style \\nclasses.\\n\\nSlot usage rules\\nSlot declarations can appear in multiple classes in a class tree, but when they do they\\nare subject to a number of constraints that are somewhat difficult to rationalize unless\\nyou understand the implementation of slots as class-level descriptors for each slot name\\nthat are inherited by the instances where the managed space is reserved (descriptors\\nare an advanced tool we’ll study in detail in the last part of this book):\\n\\n• Slots in subs are pointless when absent in supers: If a subclass inherits from a su-\\nperclass without a __slots__, the instance __dict__ attribute created for the su-\\nperclass will always be accessible, making a __slots__ in the subclass largely point-\\nless. The subclass still manages its slots, but doesn’t compute their values in any\\nway, and doesn’t avoid a dictionary—the main reason to use slots.\\n\\n• Slots in supers are pointless when absent in subs: Similarly, because the meaning of\\na __slots__ declaration is limited to the class in which it appears, subclasses will\\nproduce  an  instance  __dict__  if  they  do  not  define  a  __slots__,  rendering  a\\n__slots__ in a superclass largely pointless.\\n\\n• Redefinition renders super slots pointless: If a class defines the same slot name as a\\nsuperclass, its redefinition hides the slot in the superclass per normal inheritance.\\nYou  can  access  the  version  of  the  name  defined  by  the  superclass  slot  only  by\\nfetching its descriptor directly from the superclass.\\n\\n• Slots prevent class-level defaults: Because slots are implemented as class-level de-\\nscriptors (along with per-instance space), you cannot use class attributes of the\\nsame name to provide defaults as you can for normal instance attributes: assigning\\nthe same name in the class overwrites the slot descriptor.\\n\\n• Slots  and  __dict__:  As  shown  earlier,  __slots__  preclude  both  an  instance\\n\\n__dict__ and assigning names not listed, unless __dict__ is listed explicitly too.\\n\\nWe’ve already seen the last of these in action, and the earlier mapattrs-slots.py illustrates\\nthe third. It’s easy to demonstrate how the new rules here translate to actual code—\\nmost crucially, a namespace dictionary is created when any class in a tree omits slots,\\nthereby negating the memory optimization benefit:\\n\\n>>> class C: pass                        # Bullet 1: slots in sub but not super\\n>>> class D(C): __slots__ = [\\'a\\']        # Makes instance dict for nonslots\\n>>> X = D()                              # But slot name still managed in class\\n>>> X.a = 1; X.b = 2\\n>>> X.__dict__\\n{\\'b\\': 2}\\n>>> D.__dict__.keys()\\n\\n1016 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cdict_keys([... \\'a\\', \\'__slots__\\', ...])\\n\\n>>> class C: __slots__ = [\\'a\\']           # Bullet 2: slots in super but not sub\\n>>> class D(C): pass                     # Makes instance dict for nonslots\\n>>> X = D()                              # But slot name still managed in class\\n>>> X.a = 1; X.b = 2\\n>>> X.__dict__\\n{\\'b\\': 2}\\n>>> C.__dict__.keys()\\ndict_keys([... \\'a\\', \\'__slots__\\', ...])\\n\\n>>> class C: __slots__ = [\\'a\\']           # Bullet 3: only lowest slot accessible\\n>>> class D(C): __slots__ = [\\'a\\']\\n\\n>>> class C: __slots__ = [\\'a\\']; a = 99  # Bullet 4: no class-level defaults\\nValueError: \\'a\\' in __slots__ conflicts with class variable\\n\\nIn other words, besides their program-breaking potential, slots essentially require both\\nuniversal and careful deployment to be effective—because slots do not compute values\\ndynamically like properties (coming up in the next section), they are largely pointless\\nunless each class in a tree uses them and is cautious to define only new slot names not\\ndefined by other classes. It’s an all-or-nothing feature—an unfortunate property shared\\nby the super call discussed ahead:\\n\\n>>> class C: __slots__ = [\\'a\\']           # Assumes universal use, differing names\\n>>> class D(C): __slots__ = [\\'b\\']\\n>>> X = D()\\n>>> X.a = 1; X.b = 2\\n>>> X.__dict__\\nAttributeError: \\'D\\' object has no attribute \\'__dict__\\'\\n>>> C.__dict__.keys(), D.__dict__.keys()\\n(dict_keys([... \\'a\\', \\'__slots__\\', ...]), dict_keys([... \\'b\\', \\'__slots__\\', ...]))\\n\\nSuch rules—among others regarding weak references omitted here for space—are part\\nof the reason slots are not generally recommended, except in pathological cases where\\ntheir space reduction is significant. Even then, their potential to complicate or break\\ncode should be ample cause to carefully consider the tradeoffs. Not only must they be\\nspread almost neurotically throughout a framework, they may also break tools you rely\\non.\\n\\nExample impacts of slots: ListTree and mapattrs\\nAs a more realistic example of slots’ effects, due to the first bullet in the prior section,\\nChapter  31’s  ListTree  class  does  not  fail  when  mixed  in  to  a  class  that  defines\\n__slots__, even though it scans instance namespace dictionaries. The lister class’s own\\nlack of slots is enough to ensure that the instance will still have a __dict__, and hence\\nnot trigger an exception when fetched or indexed. For example, both of the following\\ndisplay without error—the second also allows names not in the slots list to be assigned\\nas instances attributes, including any required by the superclass:\\n\\nclass C(ListTree): pass\\nX = C()                                        # OK: no __slots__ used\\n\\nNew-Style Class Extensions\\n\\n| 1017\\n\\n\\x0cprint(X)\\n\\nclass C(ListTree): __slots__ = [\\'a\\', \\'b\\']      # OK: superclass produces __dict__\\nX = C()\\nX.c = 3\\nprint(X)                                       # Displays c at X, a and b at C\\n\\nThe following classes display correctly as well—any nonslot class like ListTree gener-\\nates an instance __dict__, and can thus safely assume its presence:\\n\\nclass A: __slots__ = [\\'a\\']                     # Both OK by bullet 1 above\\nclass B(A, ListTree): pass\\n\\nclass A: __slots__ = [\\'a\\']\\nclass B(A, ListTree): __slots__ = [\\'b\\']        # Displays b at B, a at A\\n\\nAlthough it renders subclass slots pointless, this is a positive side effect for tools classes\\nlike ListTree (and its Chapter 28 predecessor). In general, though, some tools might\\nneed to catch exceptions when __dict__ is absent or use a hasattr or getattr to test or\\nprovide defaults if slot usage may preclude a namespace dictionary in instance objects\\ninspected.\\nFor example, you should now be able to understand why the mapattrs.py program\\nearlier in this chapter must check for the presence of a __dict__ before fetching it—\\ninstance objects created from classes with __slots__ won’t have one. In fact, if we use\\nthe highlighted alternative line in the following, the mapattrs function fails with an\\nexception when attempting to look for an attribute name in the instance at the front of\\nthe inheritance path sequence:\\n\\ndef mapattrs(instance, withobject=False, bysource=False):\\n    for attr in dir(instance):\\n        for obj in inherits:\\n            if attr in obj.__dict__:           # May fail if __slots__ used\\n\\n>>> class C: __slots__ = [\\'a\\']\\n>>> X = C()\\n>>> mapattrs(X)\\nAttributeError: \\'C\\' object has no attribute \\'__dict__\\'\\n\\nEither of the following works around the issue, and allows the tool to support slots—\\nthe first provides a default, and the second is more verbose but seems marginally more\\nexplicit in its intent:\\n\\n            if attr in getattr(obj, \\'__dict__\\', {}):\\n\\n            if hasattr(obj, \\'__dict__\\') and attr in obj.__dict__:\\n\\nAs mentioned earlier, some tools may benefit from mapping dir results to objects in\\nthe MRO this way, instead of scanning an instance __dict__ in general—without this\\nmore inclusive approach, attributes implemented by class-level tools like slots won’t\\nbe reported as instance data. Even so, this doesn’t necessarily excuse such tools from\\nallowing for a missing __dict__ in the instance too!\\n\\n1018 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cWhat about slots speed?\\nFinally, while slots primarily optimize memory use, their speed impact is less clear-cut.\\nHere’s a simple test script using the timeit techniques we studied in Chapter 21. For\\nboth the slots and nonslots (instance dictionary) storage models, it makes 1,000 in-\\nstances, assigns and fetches 4 attributes on each, and repeats 1,000 times—for both\\nmodels taking the best of 3 runs that each exercise a total of 8M attribute operations:\\n\\n# File slots-test.py\\nfrom __future__ import print_function\\nimport timeit\\nbase = \"\"\"\\nIs = []\\nfor i in range(1000):\\n    X = C()\\n    X.a = 1; X.b = 2; X.c = 3; X.d = 4\\n    t = X.a + X.b + X.c + X.d\\n    Is.append(X)\\n\"\"\"\\n\\nstmt = \"\"\"\\nclass C:\\n    __slots__ = [\\'a\\', \\'b\\', \\'c\\', \\'d\\']\\n\"\"\" + base\\nprint(\\'Slots   =>\\', end=\\' \\')\\nprint(min(timeit.repeat(stmt, number=1000, repeat=3)))\\n\\nstmt = \"\"\"\\nclass C:\\n    pass\\n\"\"\" + base\\nprint(\\'Nonslots=>\\', end=\\' \\')\\nprint(min(timeit.repeat(stmt, number=1000, repeat=3)))\\n\\nAt least on this code, on my laptop, and in my installed versions (Python 3.3 and 2.7),\\nthe best times imply that slots are slightly quicker in 3.X and a wash in 2.X, though this\\nsays little about memory space, and is prone to change arbitrarily in the future:\\n\\nc:\\\\code> py −3 slots-test.py\\nSlots   => 0.7780903942045899\\nNonslots=> 0.9888108080898417\\n\\nc:\\\\code> py −2 slots-test.py\\nSlots   => 0.80868754371\\nNonslots=> 0.802224740747\\n\\nFor more on slots in general, see the Python standard manual set. Also watch for the\\nPrivate decorator case study of Chapter 39—an example that naturally allows for at-\\ntributes based on both __slots__ and __dict__ storage, by using delegation and storage-\\nneutral accessor tools like getattr.\\n\\nNew-Style Class Extensions\\n\\n| 1019\\n\\n\\x0cProperties: Attribute Accessors\\nOur next new-style extension is properties—a mechanism that provides another way\\nfor new-style classes to define methods called automatically for access or assignment\\nto instance attributes. This feature is similar to properties (a.k.a. “getters” and “setters”)\\nin languages like Java and C#, but in Python is generally best used sparingly, as a way\\nto add accessors to attributes after the fact as needs evolve and warrant. Where needed,\\nthough, properties allow attribute values to be computed dynamically without requir-\\ning method calls at the point of access.\\nThough properties cannot support generic attribute routing goals, at least for specific\\nattributes  they  are  an  alternative  to  some  traditional  uses  of  the  __getattr__  and\\n__setattr__ overloading methods we first studied in  Chapter 30. Properties have a\\nsimilar effect to these two methods, but by contrast incur an extra method call only for\\naccesses to names that require dynamic computation—other nonproperty names are\\naccessed normally with no extra calls. Although __getattr__ is invoked only for unde-\\nfined names, the __setattr__ method is instead called for assignment to every attribute.\\nProperties and slots are related too, but serve different goals. Both implement instance\\nattributes that are not physically stored in instance namespace dictionaries—a sort of\\n“virtual” attribute—and both are based on the notion of class-level attribute descrip-\\ntors. In contrast, slots manage instance storage, while properties intercept access and\\ncompute values arbitrarily. Because their underlying descriptor implementation tool is\\ntoo advanced for us to cover here, properties and descriptors both get full treatment in\\nChapter 38.\\n\\nProperty basics\\nAs a brief introduction, though, a property is a type of object assigned to a class attribute\\nname. You generate a property by calling the property built-in function, passing in up\\nto three accessor methods—handlers for get, set, and delete operations—as well as an\\noptional docstring for the property. If any argument is passed as None or omitted, that\\noperation is not supported.\\nThe  resulting  property  object  is  typically  assigned  to  a  name  at  the  top  level  of  a\\nclass statement (e.g., name=property()), and a special @ syntax we’ll meet later is avail-\\nable to automate this step. When thus assigned, later accesses to the class property\\nname itself as an object attribute (e.g., obj.name) are automatically routed to one of the\\naccessor methods passed into the property call.\\nFor example, we’ve seen how the  __getattr__ operator overloading method allows\\nclasses to intercept undefined attribute references in both classic and new-style classes:\\n\\n>>> class operators:\\n        def __getattr__(self, name):\\n            if name == \\'age\\':\\n                return 40\\n            else:\\n\\n1020 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c                raise AttributeError(name)\\n\\n>>> x = operators()\\n>>> x.age                                         # Runs __getattr__\\n40\\n>>> x.name                                        # Runs __getattr__\\nAttributeError: name\\n\\nHere  is  the  same  example,  coded  with  properties  instead;  note  that  properties  are\\navailable for all classes but require the new-style object derivation in 2.X to work prop-\\nerly for intercepting attribute assignments (and won’t complain if you forget this—but\\nwill silently overwrite your property with the new data!):\\n\\n>>> class properties(object):                     # Need object in 2.X for setters\\n        def getage(self):\\n            return 40\\n        age = property(getage, None, None, None)  # (get, set, del, docs), or use @\\n\\n>>> x = properties()\\n>>> x.age                                         # Runs getage\\n40\\n>>> x.name                                        # Normal fetch\\nAttributeError: \\'properties\\' object has no attribute \\'name\\'\\n\\nFor some coding tasks, properties can be less complex and quicker to run than the\\ntraditional techniques. For example, when we add attribute assignment support, prop-\\nerties become more attractive—there’s less code to type, and no extra method calls are\\nincurred for assignments to attributes we don’t wish to compute dynamically:\\n\\n>>> class properties(object):                     # Need object in 2.X for setters\\n        def getage(self):\\n            return 40\\n        def setage(self, value):\\n            print(\\'set age: %s\\' % value)\\n            self._age = value\\n        age = property(getage, setage, None, None)\\n\\n>>> x = properties()\\n>>> x.age                                         # Runs getage\\n40\\n>>> x.age = 42                                    # Runs setage\\nset age: 42\\n>>> x._age                                        # Normal fetch:  no getage call\\n42\\n>>> x.age                                         # Runs getage\\n40\\n>>> x.job = \\'trainer\\'                             # Normal assign: no setage call\\n>>> x.job                                         # Normal fetch:  no getage call\\n\\'trainer\\'\\n\\nThe equivalent class based on operator overloading incurs extra method calls for as-\\nsignments to attributes not being managed and needs to route attribute assignments\\nthrough  the  attribute  dictionary  to  avoid  loops  (or,  for  new-style  classes,  to  the\\n\\nNew-Style Class Extensions\\n\\n| 1021\\n\\n\\x0cobject superclass’s __setattr__ to better support “virtual” attributes such as slots and\\nproperties coded in other classes):\\n\\n>>> class operators:\\n        def __getattr__(self, name):              # On undefined reference\\n            if name == \\'age\\':\\n                return 40\\n            else:\\n                raise AttributeError(name)\\n        def __setattr__(self, name, value):       # On all assignments\\n            print(\\'set: %s %s\\' % (name, value))\\n            if name == \\'age\\':\\n                self.__dict__[\\'_age\\'] = value     # Or object.__setattr__()\\n            else:\\n                self.__dict__[name] = value\\n\\n>>> x = operators()\\n>>> x.age                                         # Runs __getattr__\\n40\\n>>> x.age = 41                                    # Runs __setattr__\\nset: age 41\\n>>> x._age                                        # Defined: no __getattr__ call\\n41\\n>>> x.age                                         # Runs __getattr__\\n40\\n>>> x.job = \\'trainer\\'                             # Runs __setattr__ again\\nset: job trainer\\n>>> x.job                                         # Defined: no __getattr__ call\\n\\'trainer\\'\\n\\nProperties seem like a win for this simple example. However, some applications of\\n__getattr__  and  __setattr__  still  require  more  dynamic  or  generic  interfaces  than\\nproperties directly provide.\\nFor example, in many cases the set of attributes to be supported cannot be determined\\nwhen  the  class  is  coded,  and  may  not  even  exist  in  any  tangible  form  (e.g.,  when\\ndelegating arbitrary attribute references to a wrapped/embedded object generically). In\\nsuch contexts, a generic __getattr__ or a __setattr__ attribute handler with a passed-\\nin attribute name is usually preferable. Because such generic handlers can also support\\nsimpler cases, properties are often an optional and redundant extension—albeit one\\nthat may avoid extra calls on assignments, and one that some programmers may prefer\\nwhen applicable.\\nFor more details on both options, stay tuned for Chapter 38 in the final part of this\\nbook. As we’ll see there, it’s also possible to code properties using the @ symbol function\\ndecorator syntax—a topic introduced later in this chapter, and an equivalent and au-\\ntomatic alternative to manual assignment in the class scope:\\n\\nclass properties(object):\\n    @property                          # Coding properties with decorators: ahead\\n    def age(self):\\n        ...\\n    @age.setter\\n\\n1022 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c    def age(self, value):\\n        ...\\n\\nTo make sense of this decorator syntax, though, we must move ahead.\\n\\n__getattribute__ and Descriptors: Attribute Tools\\nAlso in the class extensions department, the __getattribute__ operator overloading\\nmethod, available for new-style classes only, allows a class to intercept all attribute\\nreferences, not just undefined references. This makes it more potent than its  __get\\nattr__ cousin we used in the prior section, but also trickier to use—it’s prone to loops\\nmuch like __setattr__, but in different ways.\\nFor more specialized attribute interception goals, in addition to properties and operator\\noverloading methods, Python supports the notion of attribute descriptors—classes with\\n__get__ and __set__ methods, assigned to class attributes and inherited by instances,\\nthat intercept read and write accesses to specific attributes. As a preview, here’s one of\\nthe simplest descriptors you’re likely to encounter:\\n\\n>>> class AgeDesc(object):\\n        def __get__(self, instance, owner): return 40\\n        def __set__(self, instance, value): instance._age = value\\n\\n>>> class descriptors(object):\\n        age = AgeDesc()\\n\\n>>> x = descriptors()\\n>>> x.age                                         # Runs AgeDesc.__get__\\n40\\n>>> x.age = 42                                    # Runs AgeDesc.__set__\\n>>> x._age                                        # Normal fetch: no AgeDesc call\\n42\\n\\nDescriptors have access to state in instances of themselves as well as their client class,\\nand are in a sense a more general form of properties; in fact, properties are a simplified\\nway to define a specific type of descriptor—one that runs functions on access. De-\\nscriptors are also used to implement the slots feature we met earlier, and other Python\\ntools.\\nBecause __getattribute__ and descriptors are too substantial to cover well here, we’ll\\ndefer the rest of their coverage, as well as much more on properties, to Chapter 38 in\\nthe final part of this book. We’ll also employ them in examples in Chapter 39 and study\\nhow they factor into inheritance in Chapter 40.\\n\\nOther Class Changes and Extensions\\nAs mentioned, we’re also postponing coverage of the  super built-in—an additional\\nmajor new-style class extension that relies on its MRO—until the end of this chapter.\\nBefore we get there, though, we’re going to explore additional class-related changes\\n\\nNew-Style Class Extensions\\n\\n| 1023\\n\\n\\x0cand extensions that are not necessarily bound to new-style classes, but were introduced\\nat roughly the same time: static and class methods, decorators, and more.\\nMany of the changes and feature additions of new-style classes integrate with the notion\\nof subclassable types mentioned earlier in this chapter, because subclassable types and\\nnew-style classes were introduced in conjunction with a merging of the type/class di-\\nchotomy in Python 2.2 and beyond. As we’ve seen, in 3.X, this merging is complete:\\nclasses are now types, and types are classes, and Python classes today still reflect both\\nthat conceptual merging and its implementation.\\nAlong with these changes, Python also grew a more coherent and generalized protocol\\nfor coding metaclasses—classes that subclass the type object, intercept class creation\\ncalls, and may provide behavior acquired by classes. Accordingly, they provide a well-\\ndefined hook for management and augmentation of class objects. They are also an\\nadvanced topic that is optional for most Python programmers, so we’ll postpone further\\ndetails here. We’ll glimpse metaclasses again later in this chapter in conjunction with\\nclass decorators—a feature whose roles often overlap—but we’ll postpone their full\\ncoverage until Chapter 40, in the final part of this book. For our purpose here, let’s\\nmove on to a handful of additional class-related extensions.\\n\\nStatic and Class Methods\\nAs of Python 2.2, it is possible to define two kinds of methods within a class that can\\nbe called without an instance: static methods work roughly like simple instance-less\\nfunctions inside a class, and class methods are passed a class instead of an instance.\\nBoth are similar to tools in other languages (e.g., C++ static methods). Although this\\nfeature was added in conjunction with the new-style classes discussed in the prior sec-\\ntions, static and class methods work for classic classes too.\\nTo  enable  these  method  modes,  you  must  call  special  built-in  functions  named\\nstaticmethod and classmethod within the class, or invoke them with the special @name\\ndecoration syntax we’ll meet later in this chapter. These functions are required to enable\\nthese special method modes in Python 2.X, and are generally needed in 3.X. In Python\\n3.X, a staticmethod declaration is not required for instance-less methods called only\\nthrough a class name, but is still required if such methods are called through instances.\\n\\nWhy the Special Methods?\\nAs we’ve learned, a class’s method is normally passed an instance object in its first\\nargument, to serve as the implied subject of the method call—that’s the “object” in\\n“object-oriented  programming.”  Today,  though,  there  are  two  ways  to  modify  this\\nmodel. Before I explain what they are, I should explain why this might matter to you.\\nSometimes, programs need to process data associated with classes instead of instances.\\nConsider keeping track of the number of instances created from a class, or maintaining\\n\\n1024 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0ca list of all of a class’s instances that are currently in memory. This type of information\\nand its processing are associated with the class rather than its instances. That is, the\\ninformation is usually stored on the class itself and processed apart from any instance.\\nFor such tasks, simple functions coded outside a class can often suffice—because they\\ncan access class attributes through the class name, they have access to class data and\\nnever require access to an instance. However, to better associate such code with a class,\\nand to allow such processing to be customized with inheritance as usual, it would be\\nbetter to code these types of functions inside the class itself. To make this work, we\\nneed methods in a class that are not passed, and do not expect, a self instance argu-\\nment.\\nPython supports such goals with the notion of static methods—simple functions with \\nno self argument that are nested in a class and are designed to work on class attributes\\ninstead of instance attributes. Static methods never receive an automatic self argument,\\nwhether called through a class or an instance. They usually keep track of information\\nthat spans all instances, rather than providing behavior for instances.\\nAlthough less commonly used, Python also supports the notion of class methods—\\nmethods of a class that are passed a class object in their first argument instead of an\\ninstance, regardless of whether they are called through an instance or a class. Such\\nmethods can access class data through their class argument—what we’ve called self\\nthus far—even if called through an instance. Normal methods, now known in formal\\ncircles as instance methods, still receive a subject instance when called; static and class\\nmethods do not.\\n\\nStatic Methods in 2.X and 3.X\\nThe concept of static methods is the same in both Python 2.X and 3.X, but its imple-\\nmentation requirements have evolved somewhat in Python 3.X. Since this book covers\\nboth versions, I need to explain the differences in the two underlying models before we\\nget to the code.\\nReally, we already began this story in the preceding chapter, when we explored the\\nnotion of unbound methods. Recall that both Python 2.X and 3.X always pass an in-\\nstance  to  a  method  that  is  called  through  an  instance.  However,  Python  3.X  treats\\nmethods fetched directly from a class differently than 2.X—a difference in Python lines\\nthat has nothing to do with new-style classes:\\n\\n• Both  Python  2.X  and  3.X  produce  a  bound  method  when  a  method  is  fetched\\n\\nthrough an instance.\\n\\n• In Python 2.X, fetching a method from a class produces an unbound method, which \\n\\ncannot be called without manually passing an instance.\\n\\n• In Python 3.X, fetching a method from a class produces a simple function, which\\n\\ncan be called normally with no instance present.\\n\\nStatic and Class Methods\\n\\n| 1025\\n\\n\\x0cIn other words, Python 2.X class methods always require an instance to be passed in,\\nwhether they are called through an instance or a class. By contrast, in Python 3.X we\\nare required to pass an instance to a method only if the method expects one—methods\\nthat do not include an instance argument can be called through the class without pass-\\ning an instance. That is, 3.X allows simple functions in a class, as long as they do not\\nexpect and are not passed an instance argument. The net effect is that:\\n\\n• In Python 2.X, we must always declare a method as static in order to call it without\\n\\nan instance, whether it is called through a class or an instance.\\n\\n• In Python 3.X, we need not declare such methods as static if they will be called\\nthrough a class only, but we must do so in order to call them through an instance.\\n\\nTo illustrate, suppose we want to use class attributes to count how many instances are\\ngenerated from a class. The following file, spam.py, makes a first attempt—its class has\\na counter stored as a class attribute, a constructor that bumps up the counter by one\\neach time a new instance is created, and a method that displays the counter’s value.\\nRemember, class attributes are shared by all instances. Therefore, storing the counter\\nin the class object itself ensures that it effectively spans all instances:\\n\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n    def printNumInstances():\\n        print(\"Number of instances created: %s\" % Spam.numInstances)\\n\\nThe printNumInstances method is designed to process class data, not instance data—\\nit’s about all the instances, not any one in particular. Because of that, we want to be\\nable to call it without having to pass an instance. Indeed, we don’t want to make an\\ninstance to fetch the number of instances, because this would change the number of\\ninstances we’re trying to fetch! In other words, we want a self-less “static” method.\\nWhether  this  code’s  printNumInstances  works  or  not,  though,  depends  on  which\\nPython you use, and which way you call the method—through the class or through an\\ninstance. In 2.X, calls to a self-less method function through both the class and in-\\nstances fail (as usual, I’ve omitted some error text here for space):\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> from spam import Spam\\n>>> a = Spam()                       # Cannot call unbound class methods in 2.X\\n>>> b = Spam()                       # Methods expect a self object by default\\n>>> c = Spam()\\n\\n>>> Spam.printNumInstances()\\nTypeError: unbound method printNumInstances() must be called with Spam instance\\nas first argument (got nothing instead)\\n>>> a.printNumInstances()\\nTypeError: printNumInstances() takes no arguments (1 given)\\n\\nThe problem here is that unbound instance methods aren’t exactly the same as simple\\nfunctions in 2.X. Even though there are no arguments in the def header, the method\\n\\n1026 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cstill expects an instance to be passed in when it’s called, because the function is asso-\\nciated with a class. In Python 3.X, calls to self-less methods made through classes\\nwork, but calls from instances fail:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> from spam import Spam\\n>>> a = Spam()                       # Can call functions in class in 3.X\\n>>> b = Spam()                       # Calls through instances still pass a self\\n>>> c = Spam()\\n\\n>>> Spam.printNumInstances()         # Differs in 3.X\\nNumber of instances created: 3\\n>>> a.printNumInstances()\\nTypeError: printNumInstances() takes 0 positional arguments but 1 was given\\n\\nThat is, calls to instance-less methods like printNumInstances made through the class\\nfail in Python 2.X but work in Python 3.X. On the other hand, calls made through an\\ninstance fail in both Pythons, because an instance is automatically passed to a method\\nthat does not have an argument to receive it:\\n\\nSpam.printNumInstances()             # Fails in 2.X, works in 3.X\\ninstance.printNumInstances()         # Fails in both 2.X and 3.X (unless static)\\n\\nIf you’re able to use 3.X and stick with calling self-less methods through classes only,\\nyou already have a static method feature. However, to allow self-less methods to be\\ncalled through classes in 2.X and through instances in both 2.X and 3.X, you need to\\neither adopt other designs or be able to somehow mark such methods as special. Let’s\\nlook at both options in turn.\\n\\nStatic Method Alternatives\\nShort of marking a  self-less method as special, you can sometimes achieve similar\\nresults with different coding structures. For example, if you just want to call functions\\nthat  access  class  members  without  an  instance,  perhaps  the  simplest  idea  is  to  use\\nnormal functions outside the class, not class methods. This way, an instance isn’t ex-\\npected in the call. The following mutation of spam.py illustrates, and works the same\\nin Python 3.X and 2.X:\\n\\ndef printNumInstances():\\n    print(\"Number of instances created: %s\" % Spam.numInstances)\\n\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> import spam\\n>>> a = spam.Spam()\\n>>> b = spam.Spam()\\n>>> c = spam.Spam()\\n>>> spam.printNumInstances()           # But function may be too far removed\\n\\nStatic and Class Methods\\n\\n| 1027\\n\\n\\x0cNumber of instances created: 3         # And cannot be changed via inheritance\\n>>> spam.Spam.numInstances\\n3\\n\\nBecause the class name is accessible to the simple function as a global variable, this\\nworks fine. Also, note that the name of the function becomes global, but only to this\\nsingle module; it will not clash with names in other files of the program.\\nPrior to static methods in Python, this structure was the general prescription. Because\\nPython already provides modules as a namespace-partitioning tool, one could argue\\nthat there’s not typically any need to package functions in classes unless they implement\\nobject behavior. Simple functions within modules like the one here do much of what\\ninstance-less class methods could, and are already associated with the class because\\nthey live in the same module.\\nUnfortunately, this approach is still less than ideal. For one thing, it adds to this file’s\\nscope an extra name that is used only for processing a single class. For another, the\\nfunction is much less directly associated with the class by structure; in fact, its definition\\ncould be hundreds of lines away. Perhaps worse, simple functions like this cannot be\\ncustomized by inheritance, since they live outside a class’s namespace: subclasses can-\\nnot directly replace or extend such a function by redefining it.\\nWe might try to make this example work in a version-neutral way by using a normal\\nmethod and always calling it through (or with) an instance, as usual:\\n\\nclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n    def printNumInstances(self):\\n        print(\"Number of instances created: %s\" % Spam.numInstances)\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> from spam import Spam\\n>>> a, b, c = Spam(), Spam(), Spam()\\n>>> a.printNumInstances()\\nNumber of instances created: 3\\n>>> Spam.printNumInstances(a)\\nNumber of instances created: 3\\n>>> Spam().printNumInstances()         # But fetching counter changes counter!\\nNumber of instances created: 4\\n\\nUnfortunately, as mentioned earlier, such an approach is completely unworkable if we\\ndon’t have an instance available, and making an instance changes the class data, as\\nillustrated in the last line here. A better solution would be to somehow mark a method\\ninside a class as never requiring an instance. The next section shows how.\\n\\nUsing Static and Class Methods\\nToday, there is another option for coding simple functions associated with a class that\\nmay be called through either the class or its instances. As of Python 2.2, we can code\\n\\n1028 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cclasses with static and class methods, neither of which requires an instance argument\\nto be passed in when invoked. To designate such methods, classes call the built-in\\nfunctions staticmethod and classmethod, as hinted in the earlier discussion of new-style\\nclasses. Both mark a function object as special—that is, as requiring no instance if static\\nand  requiring  a  class  argument  if  a  class  method.  For  example,  in  the  file  bothme-\\nthods.py (which unifies 2.X and 3.X printing with lists, though displays still vary slightly\\nfor 2.X classic classes):\\n# File bothmethods.py\\n\\nclass Methods:\\n    def imeth(self, x):            # Normal instance method: passed a self\\n        print([self, x])\\n\\n    def smeth(x):                  # Static: no instance passed\\n        print([x])\\n\\n    def cmeth(cls, x):             # Class: gets class, not instance\\n        print([cls, x])\\n\\n    smeth = staticmethod(smeth)    # Make smeth a static method (or @: ahead)\\n    cmeth = classmethod(cmeth)     # Make cmeth a class method (or @: ahead)\\n\\nNotice how the last two assignments in this code simply reassign (a.k.a. rebind) the\\nmethod names smeth and cmeth. Attributes are created and changed by any assignment\\nin a class statement, so these final assignments simply overwrite the assignments made\\nearlier by the defs. As we’ll see in a few moments, the special @ syntax works here as\\nan alternative to this just as it does for properties—but makes little sense unless you\\nfirst understand the assignment form here that it automates.\\nTechnically, Python now supports three kinds of class-related methods, with differing\\nargument protocols:\\n\\n• Instance methods, passed a self instance object (the default)\\n• Static methods, passed no extra object (via staticmethod)\\n• Class methods, passed a class object (via classmethod, and inherent in metaclasses)\\n\\nMoreover, Python 3.X extends this model by also allowing simple functions in a class\\nto serve the role of static methods without extra protocol, when called through a class\\nobject only. Despite its name, the bothmethods.py module illustrates all three method\\ntypes, so let’s expand on these in turn.\\nInstance methods are the normal and default case that we’ve seen in this book. An\\ninstance  method  must  always  be  called  with  an  instance  object.  When  you  call  it\\nthrough an instance, Python passes the instance to the first (leftmost) argument auto-\\nmatically; when you call it through a class, you must pass along the instance manually:\\n\\n>>> from bothmethods import Methods    # Normal instance methods\\n>>> obj = Methods()                    # Callable through instance or class\\n>>> obj.imeth(1)\\n[<bothmethods.Methods object at 0x0000000002A15710>, 1]\\n\\nStatic and Class Methods\\n\\n| 1029\\n\\n\\x0c>>> Methods.imeth(obj, 2)\\n[<bothmethods.Methods object at 0x0000000002A15710>, 2]\\n\\nStatic methods, by contrast, are called without an instance argument. Unlike simple\\nfunctions outside a class, their names are local to the scopes of the classes in which they\\nare defined, and they may be looked up by inheritance. Instance-less functions can be\\ncalled through a class normally in Python 3.X, but never by default in 2.X. Using the\\nstaticmethod built-in allows such methods to also be called through an instance in 3.X\\nand through both a class and an instance in Python 2.X (that is, the first of the following\\nworks in 3.X without staticmethod, but the second does not):\\n\\n>>> Methods.smeth(3)                   # Static method: call through class\\n[3]                                    # No instance passed or expected\\n>>> obj.smeth(4)                       # Static method: call through instance\\n[4]                                    # Instance not passed\\n\\nClass methods are similar, but Python automatically passes the class (not an instance)\\nin to a class method’s first (leftmost) argument, whether it is called through a class or\\nan instance:\\n\\n>>> Methods.cmeth(5)                   # Class method: call through class\\n[<class \\'bothmethods.Methods\\'>, 5]     # Becomes cmeth(Methods, 5)\\n>>> obj.cmeth(6)                       # Class method: call through instance\\n[<class \\'bothmethods.Methods\\'>, 6]     # Becomes cmeth(Methods, 6)\\n\\nIn Chapter 40, we’ll also find that metaclass methods—a unique, advanced, and tech-\\nnically distinct method type—behave similarly to the explicitly-declared class methods\\nwe’re exploring here.\\n\\nCounting Instances with Static Methods\\nNow, given these built-ins, here is the static method equivalent of this section’s in-\\nstance-counting example—it marks the method as special, so it will never be passed\\nan instance automatically:\\n\\nclass Spam:\\n    numInstances = 0                         # Use static method for class data\\n    def __init__(self):\\n        Spam.numInstances += 1\\n    def printNumInstances():\\n        print(\"Number of instances: %s\" % Spam.numInstances)\\n    printNumInstances = staticmethod(printNumInstances)\\n\\nUsing the static method built-in, our code now allows the self-less method to be called\\nthrough the class or any instance of it, in both Python 2.X and 3.X:\\n\\n>>> from spam_static import Spam\\n>>> a = Spam()\\n>>> b = Spam()\\n>>> c = Spam()\\n>>> Spam.printNumInstances()                 # Call as simple function\\nNumber of instances: 3\\n\\n1030 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> a.printNumInstances()                    # Instance argument not passed\\nNumber of instances: 3\\n\\nCompared to simply moving printNumInstances outside the class, as prescribed earlier,\\nthis version requires an extra staticmethod call (or an @ line we’ll see ahead). However,\\nit also localizes the function name in the class scope (so it won’t clash with other names\\nin the module); moves the function code closer to where it is used (inside the class\\nstatement); and allows subclasses to customize the static method with inheritance—a\\nmore convenient and powerful approach than importing functions from the files in\\nwhich superclasses are coded. The following subclass and new testing session illustrate\\n(be sure to start a new session after changing files, so that your from imports load the\\nlatest version of the file):\\n\\nclass Sub(Spam):\\n    def printNumInstances():                 # Override a static method\\n        print(\"Extra stuff...\")              # But call back to original\\n        Spam.printNumInstances()\\n    printNumInstances = staticmethod(printNumInstances)\\n\\n>>> from spam_static import Spam, Sub\\n>>> a = Sub()\\n>>> b = Sub()\\n>>> a.printNumInstances()                    # Call from subclass instance\\nExtra stuff...\\nNumber of instances: 2\\n>>> Sub.printNumInstances()                  # Call from subclass itself\\nExtra stuff...\\nNumber of instances: 2\\n>>> Spam.printNumInstances()                 # Call original version\\nNumber of instances: 2\\n\\nMoreover, classes can inherit the static method without redefining it—it is run without\\nan instance, regardless of where it is defined in a class tree:\\n\\n>>> class Other(Spam): pass                  # Inherit static method verbatim\\n\\n>>> c = Other()\\n>>> c.printNumInstances()\\nNumber of instances: 3\\n\\nNotice how this also bumps up the superclass’s instance counter, because its construc-\\ntor is inherited and run—a behavior that begins to encroach on the next section’s sub-\\nject.\\n\\nCounting Instances with Class Methods\\nInterestingly, a class method can do similar work here—the following has the same\\nbehavior as the static method version listed earlier, but it uses a class method that\\nreceives  the  instance’s  class  in  its  first  argument.  Rather  than  hardcoding  the  class\\nname, the class method uses the automatically passed class object generically:\\n\\nStatic and Class Methods\\n\\n| 1031\\n\\n\\x0cclass Spam:\\n    numInstances = 0                         # Use class method instead of static\\n    def __init__(self):\\n        Spam.numInstances += 1\\n    def printNumInstances(cls):\\n        print(\"Number of instances: %s\" % cls.numInstances)\\n    printNumInstances = classmethod(printNumInstances)\\n\\nThis  class  is  used  in  the  same  way  as  the  prior  versions,  but  its  printNumInstances\\nmethod receives the Spam class, not the instance, when called from both the class and\\nan instance:\\n\\n>>> from spam_class import Spam\\n>>> a, b = Spam(), Spam()\\n>>> a.printNumInstances()                    # Passes class to first argument\\nNumber of instances: 2\\n>>> Spam.printNumInstances()                 # Also passes class to first argument\\nNumber of instances: 2\\n\\nWhen using class methods, though, keep in mind that they receive the most specific\\n(i.e., lowest) class of the call’s subject. This has some subtle implications when trying\\nto  update  class  data  through  the  passed-in  class.  For  example,  if  in  module\\nspam_class.py we subclass to customize as before, augment Spam.printNumInstances to\\nalso display its cls argument, and start a new testing session:\\n\\nclass Spam:\\n    numInstances = 0                         # Trace class passed in\\n    def __init__(self):\\n        Spam.numInstances += 1\\n    def printNumInstances(cls):\\n        print(\"Number of instances: %s %s\" % (cls.numInstances, cls))\\n    printNumInstances = classmethod(printNumInstances)\\n\\nclass Sub(Spam):\\n    def printNumInstances(cls):              # Override a class method\\n        print(\"Extra stuff...\", cls)         # But call back to original\\n        Spam.printNumInstances()\\n    printNumInstances = classmethod(printNumInstances)\\n\\nclass Other(Spam): pass                      # Inherit class method verbatim\\n\\nThe lowest class is passed in whenever a class method is run, even for subclasses that\\nhave no class methods of their own:\\n\\n>>> from spam_class import Spam, Sub, Other\\n>>> x = Sub()\\n>>> y = Spam()\\n>>> x.printNumInstances()                           # Call from subclass instance\\nExtra stuff... <class \\'spam_class.Sub\\'>\\nNumber of instances: 2 <class \\'spam_class.Spam\\'>\\n>>> Sub.printNumInstances()                         # Call from subclass itself\\nExtra stuff... <class \\'spam_class.Sub\\'>\\nNumber of instances: 2 <class \\'spam_class.Spam\\'>\\n>>> y.printNumInstances()                           # Call from superclass instance\\nNumber of instances: 2 <class \\'spam_class.Spam\\'>\\n\\n1032 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cIn the first call here, a class method call is made through an instance of the Sub subclass,\\nand Python passes the lowest class, Sub, to the class method. All is well in this case—\\nsince Sub’s redefinition of the method calls the Spam superclass’s version explicitly, the\\nsuperclass method in Spam receives its own class in its first argument. But watch what\\nhappens for an object that inherits the class method verbatim:\\n\\n>>> z = Other()                                     # Call from lower sub\\'s instance\\n>>> z.printNumInstances()\\nNumber of instances: 3 <class \\'spam_class.Other\\'>\\n\\nThis last call here passes  Other to  Spam’s class method. This works in this example\\nbecause  fetching  the  counter  finds  it  in  Spam  by  inheritance.  If  this  method  tried  to\\nassign to the passed class’s data, though, it would update Other, not Spam! In this specific\\ncase, Spam is probably better off hardcoding its own class name to update its data if it\\nmeans to count instances of all its subclasses too, rather than relying on the passed-in\\nclass argument.\\n\\nCounting instances per class with class methods\\nIn fact, because class methods always receive the lowest class in an instance’s tree:\\n\\n• Static methods and explicit class names may be a better solution for processing\\n\\ndata local to a class.\\n\\n• Class methods may be better suited to processing data that may differ for each class\\n\\nin a hierarchy.\\n\\nCode that needs to manage per-class instance counters, for example, might be best off\\nleveraging class methods. In the following, the top-level superclass uses a class method\\nto manage state information that varies for and is stored on each class in the tree—\\nsimilar in spirit to the way instance methods manage state information that varies per\\nclass instance:\\nclass Spam:\\n    numInstances = 0\\n    def count(cls):                    # Per-class instance counters\\n        cls.numInstances += 1          # cls is lowest class above instance\\n    def __init__(self):\\n        self.count()                   # Passes self.__class__ to count\\n    count = classmethod(count)\\n\\nclass Sub(Spam):\\n    numInstances = 0\\n    def __init__(self):                # Redefines __init__\\n        Spam.__init__(self)\\n\\nclass Other(Spam):                     # Inherits __init__\\n    numInstances = 0\\n\\n>>> from spam_class2 import Spam, Sub, Other\\n>>> x = Spam()\\n>>> y1, y2 = Sub(), Sub()\\n\\nStatic and Class Methods\\n\\n| 1033\\n\\n\\x0c>>> z1, z2, z3 = Other(), Other(), Other()\\n>>> x.numInstances, y1.numInstances, z1.numInstances             # Per-class data!\\n(1, 2, 3)\\n>>> Spam.numInstances, Sub.numInstances, Other.numInstances\\n(1, 2, 3)\\n\\nStatic and class methods have additional advanced roles, which we will finesse here;\\nsee other resources for more use cases. In recent Python versions, though, the static\\nand class method designations have become even simpler with the advent of function\\ndecoration syntax—a way to apply one function to another that has roles well beyond\\nthe static method use case that was its initial motivation. This syntax also allows us to\\naugment classes in Python 2.X and 3.X—to initialize data like the numInstances counter\\nin the last example, for instance. The next section explains how.\\n\\nFor a postscript on Python’s method types, be sure to watch for coverage\\nof metaclass methods in Chapter 40—because these are designed to pro-\\ncess a class that is an instance of a metaclass, they turn out to be very\\nsimilar to the class methods defined here, but require no classmethod\\ndeclaration, and apply only to the shadowy metaclass realm.\\n\\nDecorators and Metaclasses: Part 1\\nBecause the staticmethod and classmethod call technique described in the prior section\\ninitially seemed obscure to some observers, a device was eventually added to make the\\noperation simpler. Python decorators—similar to the notion and syntax of annotations\\nin Java—both addressed this specific need and provided a general tool for adding logic\\nthat manages both functions and classes, or later calls to them.\\nThis is called a “decoration,” but in more concrete terms is really just a way to run extra\\nprocessing steps at function and class definition time with explicit syntax. It comes in\\ntwo flavors:\\n\\n• Function decorators—the initial entry in this set, added in Python 2.4—augment\\nfunction definitions. They specify special operation modes for both simple func-\\ntions and classes’ methods by wrapping them in an extra layer of logic implemented\\nas another function, usually called a metafunction.\\n\\n• Class decorators—a later extension, added in Python 2.6 and 3.0—augment class\\ndefinitions. They do the same for classes, adding support for management of whole\\nobjects and their interfaces. Though perhaps simpler, they often overlap in roles \\nwith metaclasses.\\n\\nFunction decorators turn out to be very general tools: they are useful for adding many\\ntypes of logic to functions besides the static and class method use cases. For instance,\\nthey may be used to augment functions with code that logs calls made to them, checks\\nthe types of passed arguments during debugging, and so on. Function decorators can\\nbe used to manage either functions themselves or later calls to them. In the latter mode,\\n\\n1034 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cfunction decorators are similar to the delegation design pattern we explored in Chap-\\nter 31, but they are designed to augment a specific function or method call, not an entire\\nobject interface.\\nPython provides a few built-in function decorators for operations such as marking static\\nand class methods and defining properties (as sketched earlier, the property built-in\\nworks as a decorator automatically), but programmers can also code arbitrary decora-\\ntors of their own. Although they are not strictly tied to classes, user-defined function\\ndecorators often are coded as classes to save the original functions for later dispatch,\\nalong with other data as state information.\\nThis proved such a useful hook that it was extended in Python 2.6, 2.7, and 3.X—class\\ndecorators bring augmentation to classes too, and are more directly tied to the class\\nmodel. Like their function cohorts, class decorators may manage classes themselves or\\nlater instance creation calls, and often employ delegation in the latter mode. As we’ll\\nfind, their roles also often overlap with metaclasses; when they do, the newer class\\ndecorators may offer a more lightweight way to achieve the same goals.\\n\\nFunction Decorator Basics\\nSyntactically, a function decorator is a sort of runtime declaration about the function\\nthat follows. A function decorator is coded on a line by itself just before the def state-\\nment that defines a function or method. It consists of the @ symbol, followed by what\\nwe  call  a  metafunction—a  function  (or  other  callable  object)  that  manages  another\\nfunction. Static methods since Python 2.4, for example, may be coded with decorator\\nsyntax like this:\\n\\nclass C:\\n   @staticmethod                    # Function decoration syntax\\n   def meth():\\n       ...\\n\\nInternally,  this  syntax  has  the  same  effect  as  the  following—passing  the  function\\nthrough the decorator and assigning the result back to the original name:\\n\\nclass C:\\n   def meth():\\n       ...\\n   meth = staticmethod(meth)        # Name rebinding equivalent\\n\\nDecoration rebinds the method name to the decorator’s result. The net effect is that\\ncalling  the  method  function’s  name  later  actually  triggers  the  result  of  its  staticme\\nthod decorator first. Because a decorator can return any sort of object, this allows the\\ndecorator to insert a layer of logic to be run on every call. The decorator function is free\\nto return either the original function itself, or a new proxy object that saves the original\\nfunction passed to the decorator to be invoked indirectly after the extra logic layer runs.\\nWith this addition, here’s a better way to code our static method example from the\\nprior section in either Python 2.X or 3.X:\\n\\nDecorators and Metaclasses: Part 1 | 1035\\n\\n\\x0cclass Spam:\\n    numInstances = 0\\n    def __init__(self):\\n        Spam.numInstances = Spam.numInstances + 1\\n\\n    @staticmethod\\n    def printNumInstances():\\n        print(\"Number of instances created: %s\" % Spam.numInstances)\\n\\n>>> from spam_static_deco import Spam\\n>>> a = Spam()\\n>>> b = Spam()\\n>>> c = Spam()\\n>>> Spam.printNumInstances()            # Calls from classes and instances work\\nNumber of instances created: 3\\n>>> a.printNumInstances()\\nNumber of instances created: 3\\n\\nBecause they also accept and return functions, the classmethod and property built-in\\nfunctions may be used as decorators in the same way—as in the following mutation of\\nthe prior bothmethods.py:\\n\\n# File bothmethods_decorators.py\\n\\nclass Methods(object):             # object needed in 2.X for property setters\\n    def imeth(self, x):            # Normal instance method: passed a self\\n        print([self, x])\\n\\n    @staticmethod\\n    def smeth(x):                  # Static: no instance passed\\n        print([x])\\n\\n    @classmethod\\n    def cmeth(cls, x):             # Class: gets class, not instance\\n        print([cls, x])\\n\\n    @property                      # Property: computed on fetch\\n    def name(self):\\n        return \\'Bob \\' + self.__class__.__name__\\n\\n>>> from bothmethods_decorators import Methods\\n>>> obj = Methods()\\n>>> obj.imeth(1)\\n[<bothmethods_decorators.Methods object at 0x0000000002A256A0>, 1]\\n>>> obj.smeth(2)\\n[2]\\n>>> obj.cmeth(3)\\n[<class \\'bothmethods_decorators.Methods\\'>, 3]\\n>>> obj.name\\n\\'Bob Methods\\'\\n\\nKeep in mind that staticmethod and its kin here are still built-in functions; they may\\nbe used in decoration syntax, just because they take a function as an argument and\\nreturn a callable to which the original function name can be rebound. In fact, any such\\n\\n1036 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cfunction can be used in this way—even user-defined functions we code ourselves, as\\nthe next section explains.\\n\\nA First Look at User-Defined Function Decorators\\nAlthough Python provides a handful of built-in functions that can be used as decorators,\\nwe can also write custom decorators of our own. Because of their wide utility, we’re\\ngoing to devote an entire chapter to coding decorators in the final part of this book. As\\na quick example, though, let’s look at a simple user-defined decorator at work.\\nRecall from Chapter 30 that the __call__ operator overloading method implements a\\nfunction-call interface for class instances. The following code uses this to define a call\\nproxy class that saves the decorated function in the instance and catches calls to the\\noriginal name. Because this is a class, it also has state information—a counter of calls\\nmade:\\n\\nclass tracer:\\n    def __init__(self, func):          # Remember original, init counter\\n        self.calls = 0\\n        self.func  = func\\n    def __call__(self, *args):         # On later calls: add logic, run original\\n        self.calls += 1\\n        print(\\'call %s to %s\\' % (self.calls, self.func.__name__))\\n        return self.func(*args)\\n\\n@tracer                                # Same as spam = tracer(spam)\\ndef spam(a, b, c):                     # Wrap spam in a decorator object\\n    return a + b + c\\n\\nprint(spam(1, 2, 3))                   # Really calls the tracer wrapper object\\nprint(spam(\\'a\\', \\'b\\', \\'c\\'))             # Invokes __call__ in class\\n\\nBecause  the  spam  function  is  run  through  the  tracer  decorator,  when  the  original\\nspam name is called it actually triggers the __call__ method in the class. This method\\ncounts and logs the call, and then dispatches it to the original wrapped function. Note\\nhow the *name argument syntax is used to pack and unpack the passed-in arguments;\\nbecause of this, this decorator can be used to wrap any function with any number of\\npositional arguments.\\nThe net effect, again, is to add a layer of logic to the original spam function. Here is the\\nscript’s 3.X and 2.X output—the first line comes from the tracer class, and the second\\ngives the return value of the spam function itself:\\n\\nc:\\\\code> python tracer1.py\\ncall 1 to spam\\n6\\ncall 2 to spam\\nabc\\n\\nTrace through this example’s code for more insight. As it is, this decorator works for\\nany function that takes positional arguments, but it does not handle keyword argu-\\n\\nDecorators and Metaclasses: Part 1 | 1037\\n\\n\\x0cments,  and  cannot  decorate  class-level  method  functions  (in  short,  for  methods  its\\n__call__ would be passed a tracer instance only). As we’ll see in Part VIII, there are a\\nvariety of ways to code function decorators, including nested def statements; some of\\nthe alternatives are better suited to methods than the version shown here.\\nFor example, by using nested functions with enclosing scopes for state, instead of call-\\nable class instances with attributes, function decorators often become more broadly\\napplicable to class-level methods too. We’ll postpone the full details on this, but here’s\\na brief look at this closure based coding model; it uses function attributes for counter\\nstate for portability, but could leverage variables and nonlocal instead in 3.X only:\\n\\ndef tracer(func):                      # Remember original\\n    def oncall(*args):                 # On later calls\\n        oncall.calls += 1\\n        print(\\'call %s to %s\\' % (oncall.calls, func.__name__))\\n        return func(*args)\\n    oncall.calls = 0\\n    return oncall\\n\\nclass C:\\n    @tracer\\n    def spam(self,a, b, c): return a + b + c\\n\\nx = C()\\nprint(x.spam(1, 2, 3))\\nprint(x.spam(\\'a\\', \\'b\\', \\'c\\'))           # Same output as tracer1 (in tracer2.py)\\n\\nA First Look at Class Decorators and Metaclasses\\nFunction decorators turned out to be so useful that Python 2.6 and 3.0 expanded the\\nmodel, allowing decorators to be applied to classes as well as functions. In short, class\\ndecorators are similar to function decorators, but they are run at the end of a class\\nstatement to rebind a class name to a callable. As such, they can be used to either\\nmanage classes just after they are created, or insert a layer of wrapper logic to manage\\ninstances when they are later created. Symbolically, the code structure:\\n\\ndef decorator(aClass): ...\\n\\n@decorator                             # Class decoration syntax\\nclass C: ...\\n\\nis mapped to the following equivalent:\\n\\ndef decorator(aClass): ...\\n\\nclass C: ...                           # Name rebinding equivalent\\nC = decorator(C)\\n\\nThe class decorator is free to augment the class itself, or return a proxy object that\\nintercepts later instance construction calls. For example, in the code of the section\\n“Counting instances per class with class methods” on page 1033, we could use this\\n\\n1038 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0chook to automatically augment the classes with instance counters and any other data\\nrequired:\\n\\ndef count(aClass):\\n    aClass.numInstances = 0\\n    return aClass                 # Return class itself, instead of a wrapper\\n\\n@count\\nclass Spam: ...                   # Same as Spam = count(Spam)\\n\\n@count\\nclass Sub(Spam): ...              # numInstances = 0 not needed here\\n\\n@count\\nclass Other(Spam): ...\\n\\nIn fact, as coded, this decorator can be applied to class or functions—it happily returns\\nthe object being defined in either context after initializing the object’s attribute:\\n\\n@count\\ndef spam(): pass        # Like spam = count(spam)\\n\\n@count\\nclass Other: pass       # Like Other = count(Other)\\n\\nspam.numInstances       # Both are set to zero\\nOther.numInstances\\n\\nThough this decorator manages a function or class itself, as we’ll see later in this book,\\nclass decorators can also manage an object’s entire interface by intercepting construc-\\ntion calls, and wrapping the new instance object in a proxy that deploys attribute ac-\\ncessor tools to intercept later requests—a multilevel coding technique we’ll use to im-\\nplement class attribute privacy in Chapter 39. Here’s a preview of the model:\\n\\ndef decorator(cls):                             # On @ decoration\\n    class Proxy:\\n        def __init__(self, *args):              # On instance creation: make a cls\\n            self.wrapped = cls(*args)\\n        def __getattr__(self, name):            # On attribute fetch: extra ops here\\n            return getattr(self.wrapped, name)\\n    return Proxy\\n\\n@decorator\\nclass C: ...        # Like C = decorator(C)\\nX = C()             # Makes a Proxy that wraps a C, and catches later X.attr\\n\\nMetaclasses, mentioned briefly earlier, are a similarly advanced class-based tool whose\\nroles often intersect with those of class decorators. They provide an alternate model,\\nwhich routes the creation of a class object to a subclass of the top-level type class, at\\nthe conclusion of a class statement:\\n\\nclass Meta(type):\\n    def __new__(meta, classname, supers, classdict):\\n        ...extra logic + class creation via type call...\\n\\nDecorators and Metaclasses: Part 1 | 1039\\n\\n\\x0cclass C(metaclass=Meta):\\n    ...my creation routed to Meta...            # Like C = Meta(\\'C\\', (), {...})\\n\\nIn Python 2.X, the effect is the same, but the coding differs—use a class attribute instead\\nof a keyword argument in the class header:\\n\\nclass C:\\n    __metaclass__ = Meta\\n    ... my creation routed to Meta...\\n\\nIn either line, Python calls a class’s metaclass to create the new class object, passing in\\nthe data defined during the class statement’s run; in 2.X, the metaclass simply defaults\\nto the classic class creator:\\n\\n classname = Meta(classname, superclasses, attributedict)\\n\\nTo assume control of the creation or initialization of a new class object, a metaclass\\ngenerally  redefines  the  __new__  or  __init__  method  of  the  type  class  that  normally\\nintercepts this call. The net effect, as with class decorators, is to define code to be run\\nautomatically at class creation time. Here, this step binds the class name to the result\\nof a call to a user-defined metaclass. In fact, a metaclass need not be a class at all—a\\npossibility we’ll explore later that blurs some of the distinction between this tool and\\ndecorators, and may even qualify the two as functionally equivalent in many roles.\\nBoth schemes, class decorators and metaclasses, are free to augment a class or return\\nan arbitrary object to replace it—a protocol with almost limitless class-based custom-\\nization possibilities. As we’ll see later, metaclasses may also define methods that process\\ntheir instance classes, rather than normal instances of them—a technique that’s similar\\nto class methods, and might be emulated in spirit by methods and data in class deco-\\nrator proxies, or even a class decorator that returns a metaclass instance. Such mind-\\nbinding concepts will require Chapter 40’s conceptual groundwork (and quite possibly\\nsedation!).\\n\\nFor More Details\\nNaturally, there’s much more to the decorator and metaclass stories than I’ve shown\\nhere. Although they are a general mechanism whose usage may be required by some\\npackages, coding new user-defined decorators and metaclasses is an advanced topic of\\ninterest primarily to tool writers, not application programmers. Because of this, we’ll\\ndefer additional coverage until the final and optional part of this book:\\n\\n• Chapter 38 shows how to code properties using function decorator syntax in more\\n\\ndepth.\\n\\n• Chapter 39 has much more on decorators, including more comprehensive exam-\\n\\nples.\\n\\n• Chapter 40 covers metaclasses, and more on the class and instance management\\n\\nstory.\\n\\n1040 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cAlthough these chapters cover advanced topics, they’ll also provide us with a chance\\nto see Python at work in more substantial examples than much of the rest of the book\\nwas able to provide. For now, let’s move on to our final class-related topic.\\n\\nThe super Built-in Function: For Better or Worse?\\nSo far, I’ve mentioned Python’s super built-in function only briefly in passing because\\nit is relatively uncommon and may even be controversial to use. Given this call’s in-\\ncreased  visibility  in  recent  years,  though,  it  merits  some  further  elaboration  in  this\\nedition. Besides introducing super, this section also serves as a language design case\\nstudy to close out a chapter on so many tools whose presence may to some seem curious\\nin a scripting language like Python.\\nSome of this section calls this proliferation of tools into question, and I encourage you\\nto judge any subjective content here for yourself (and we’ll return to such things at the\\nend of this book after we’ve expanded on other advanced tools such as metaclasses and\\ndescriptors). Still, Python’s rapid growth rate in recent years represents a strategic de-\\ncision point for its community going forward, and super seems as good a representative\\nexample as any.\\n\\nThe Great super Debate\\nAs noted in Chapter 28 and Chapter 29, Python has a super built-in function that can\\nbe used to invoke superclass methods generically, but was deferred until this point of\\nthe  book.  This  was  deliberate—because  super  has  substantial  downsides  in  typical\\ncode, and a sole use case that seems obscure and complex to many observers, most\\nbeginners are better served by the traditional explicit-name call scheme used so far. See\\nthe sidebar “What About super?” on page 831 in Chapter 28 for a brief summary of\\nthe rationale for this policy.\\nThe Python community itself seems split on this subject, with online articles about it\\nrunning the gamut from “Python’s Super Considered Harmful” to “Python’s super()\\nconsidered super!”3 Frankly, in my live classes this call seems to be most often of interest\\nto Java programmers starting to use Python anew, because of its conceptual similarity\\nto a tool in that language (many a new Python feature ultimately owes its existence to\\nprogrammers of other languages bringing their old habits to a new model). Python’s\\nsuper is not Java’s—it translates differently to Python’s multiple inheritance, and has\\n\\n3. Both are opinion pieces in part, but are suggested reading. The first was eventually retitled “Python’s\\nSuper is nifty, but you can’t use it,” and is today at https://fuhm.net/super-harmful. Oddly—and despite\\nits subjective tone—the second article (“Python’s super() considered super!”) alone somehow found its\\nway  into  Python’s  official  library  manual;  see  its  link  in  the  manual’s  super  section...and  consider\\ndemanding that differing opinions be represented more evenly in your tools’ documentation, or omitted\\naltogether. Python’s manuals are not the place for personal opinion and one-sided propaganda!\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1041\\n\\n\\x0ca use case beyond Java’s—but it has managed to generate both controversy and mis-\\nunderstanding since its conception.\\nThis book postponed the super call until now (and omitted it almost entirely in prior\\neditions) because it has significant issues—it’s prohibitively cumbersome to use in 2.X,\\ndiffers in form between 2.X and 3.X, is based upon unusual semantics in 3.X, and mixes\\npoorly with Python’s multiple inheritance and operator overloading in typical Python\\ncode. In fact, as we’ll see, in some code super can actually mask problems, and dis-\\ncourage a more explicit coding style that offers better control.\\nIn its defense, this call does have a valid use case too—cooperative same-named method\\ndispatch in diamond multiple inheritance trees—but it seems to ask a lot of newcomers.\\nIt requires that super be used universally and consistently (if not neurotically), much\\nlike __slots__ discussed earlier; relies on the arguably obscure MRO algorithm to order\\ncalls; and addresses a use case that seems far more the exception than the norm in\\nPython programs. In this role, super seems an advanced tool based upon esoteric prin-\\nciples, which may be beyond much of Python’s audience, and seems artificial to real\\nprogram goals. That aside, its expectation of universal use seems unrealistic for the vast\\namount of existing Python code.\\nBecause of all these factors, this introductory-level book has preferred the traditional\\nexplicit-name call scheme thus far and recommends the same for newcomers. You’re\\nbetter off learning the traditional scheme first, and might be better off sticking with\\nthat in general, rather than using an extra special-case tool that may not work in some\\ncontexts, and relies on arcane magic in the valid but atypical use case it addresses. This\\nis not just your author’s opinion; despite its advocate’s best intentions, super is not\\nwidely recognized as “best practice” in Python today, for completely valid reasons.\\nOn the other hand, just as for other tools the increasing use of this call in Python code\\nin recent years makes it no longer optional for many Python programmers—the first\\ntime you see it, it’s officially mandatory! For readers who may wish to experiment with\\nsuper, and for other readers who may have it imposed upon them, this section provides\\na brief look at this tool and its rationale—beginning with alternatives to it.\\n\\nTraditional Superclass Call Form: Portable, General\\nIn general, this book’s examples prefer to call back to superclass methods when needed\\nby naming the superclass explicitly, because this technique is traditional in Python,\\nbecause it works the same in both Python 2.X and 3.X, and because it sidesteps limi-\\ntations and complexities related to this call in both 2.X and 3.X. As shown earlier, the\\ntraditional superclass method call scheme to augment a superclass method works as\\nfollows:\\n\\n>>> class C:                    # In Python 2.X and 3.X\\n        def act(self):\\n            print(\\'spam\\')\\n\\n1042 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> class D(C):\\n        def act(self):\\n            C.act(self)         # Name superclass explicitly, pass self\\n            print(\\'eggs\\')\\n\\n>>> X = D()\\n>>> X.act()\\nspam\\neggs\\n\\nThis form works the same in 2.X and 3.X, follows Python’s normal method call map-\\nping model, applies to all inheritance tree forms, and does not lead to confusing be-\\nhavior when operator overloading is used. To see why these distinctions matter, let’s\\nsee how super compares.\\n\\nBasic super Usage and Its Tradeoffs\\nIn this section, we’ll both introduce super in basic, single-inheritance mode, and look\\nat its perceived downsides in this role. As we’ll find, in this context super does work as\\nadvertised, but is not much different from traditional calls, relies on unusual semantics,\\nand is cumbersome to deploy in 2.X. More critically, as soon as your classes grow to\\nuse multiple inheritance, this super usage mode can both mask problems in your code\\nand route calls in ways you may not expect.\\n\\nOdd semantics: A magic proxy in Python 3.X\\nThe super built-in actually has two intended roles. The more esoteric of these—coop-\\nerative multiple inheritance dispatch protocols in diamond multiple-inheritance trees\\n(yes, a mouthful!)—relies on the 3.X MRO, was borrowed from the Dylan language,\\nand will be covered later in this section.\\nThe role we’re interested in here is more commonly used, and more frequently reques-\\nted by people with Java backgrounds—to allow superclasses to be named generically\\nin inheritance trees. This is intended to promote simpler code maintenance, and to\\navoid having to type long superclass reference paths in calls. In Python 3.X, this call\\nseems at least at first glance to achieve this purpose well:\\n\\n>>> class C:                    # In Python 3.X (only: see 2.X super form ahead)\\n        def act(self):\\n            print(\\'spam\\')\\n\\n>>> class D(C):\\n        def act(self):\\n            super().act()       # Reference superclass generically, omit self\\n            print(\\'eggs\\')\\n\\n>>> X = D()\\n>>> X.act()\\nspam\\neggs\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1043\\n\\n\\x0cThis works, and minimizes code changes—you don’t need to update the call if  D’s\\nsuperclass  changes  in  the  future.  One  of  the  biggest  downsides  of  this  call  in  3.X,\\nthough, is its reliance on deep magic: though prone to change, it operates today by\\ninspecting the call stack in order to automatically locate the self argument and find\\nthe superclass, and pairs the two in a special proxy object that routes the later call to\\nthe superclass version of the method. If that sounds complicated and strange, it’s be-\\ncause it is. In fact, this call form doesn’t work at all outside the context of a class’s\\nmethod:\\n\\n>>> super                       # A \"magic\" proxy object that routes later calls\\n<class \\'super\\'>\\n>>> super()\\nSystemError: super(): no arguments\\n\\n>>> class E(C):\\n        def method(self):       # self is implicit in super...only!\\n            proxy = super()     # This form has no meaning outside a method\\n            print(proxy)        # Show the normally hidden proxy object\\n            proxy.act()         # No arguments: implicitly calls superclass method!\\n\\n>>> E().method()\\n<super: <class \\'E\\'>, <E object>>\\nspam\\n\\ninheritance  trees,  a  superclass \\n\\nReally, this call’s semantics resembles nothing else in Python—it’s neither a bound nor\\nunbound method, and somehow finds a self even though you omit one in the call. In\\nsingle \\nis  available  from  self  via  the  path\\nself.__class__.__bases__[0], but the heavily implicit nature of this call makes this\\ndifficult to see, and even flies in the face of Python’s explicit self policy that holds true\\neverywhere else. That is, this call violates a fundamental Python idiom for a single use\\ncase. It also soundly contradicts Python’s longstanding EIBTI design rule (run an “im-\\nport this” for more on this rule).\\n\\nPitfall: Adding multiple inheritance naively\\nBesides its unusual semantics, even in 3.X this super role applies most directly to single\\ninheritance trees, and can become problematic as soon as classes employ multiple in-\\nheritance with traditionally coded classes. This seems a major limitation of scope; due\\nto the utility of mix-in classes in Python, multiple inheritance from disjoint and inde-\\npendent superclasses is probably more the norm than the exception in realistic code.\\nThe super call seems a recipe for disaster in classes coded to naively use its basic mode,\\nwithout allowing for its much more subtle implications in multiple inheritance trees.\\nThe following illustrates the trap. This code begins its life happily deploying super in\\nsingle-inheritance mode to invoke a method one level up from C:\\n\\n>>> class A:                      # In Python 3.X\\n        def act(self): print(\\'A\\')\\n>>> class B:\\n        def act(self): print(\\'B\\')\\n\\n1044 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> class C(A):\\n        def act(self):\\n            super().act()         # super applied to a single-inheritance tree\\n>>> X = C()\\n>>> X.act()\\nA\\n\\nIf such classes later grow to use more than one superclass, though, super can become\\nerror-prone, and even unusable—it does not raise an exception for multiple inheritance\\ntrees, but will naively pick just the leftmost superclass having the method being run\\n(technically, the first per the MRO), which may or may not be the one that you want:\\n\\n>>> class C(A, B):                # Add a B mix-in class with the same method\\n        def act(self):\\n            super().act()         # Doesn\\'t fail on multi-inher, but picks just one!\\n>>> X = C()\\n>>> X.act()\\nA\\n\\n>>> class C(B, A):\\n        def act(self):\\n            super().act()         # If B is listed first, A.act() is no longer run!\\n>>> X = C()\\n>>> X.act()\\nB\\n\\nPerhaps worse, this silently masks the fact that you should probably be selecting su-\\nperclasses explicitly in this case, as we learned earlier in both this chapter and its pred-\\necessor. In other words, super usage may obscure a common source of errors in Python\\n—one so common that it shows up again in this part’s “Gotchas.” If you may need to\\nuse direct calls later, why not use them earlier too?\\n>>> class C(A, B):                # Traditional form\\n        def act(self):            # You probably need to be more explicit here\\n            A.act(self)           # This form handles both single and multiple inher\\n            B.act(self)           # And works the same in both Python 3.X and 2.X\\n>>> X = C()                       # So why use the super() special case at all?\\n>>> X.act()\\nA\\nB\\n\\nAs we’ll see in a few moments, you might also be able to address such cases by deploying\\nsuper calls in every class of the tree. But that’s also one of the biggest downsides of\\nsuper—why code it in every class, when it’s usually not needed, and when using the\\npreceding simpler traditional form in a single class will usually suffice? Especially in\\nexisting code—and new code that uses existing code—this super requirement seems\\nharsh, if not unrealistic.\\nMuch more subtly, as we’ll also see ahead, once you step up to multiple inheritance\\ncalls this way, the super calls in your code might not invoke the class you expect them\\nto. They’ll be routed per the MRO order, which, depending on where else super might\\nbe used, may invoke a method in a class that is not the caller’s superclass at all—an\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1045\\n\\n\\x0cimplicit ordering that might make for interesting debugging sessions! Unless you com-\\npletely understand what super means once multiple inheritance is introduced, you may\\nbe better off not deploying it in single-inheritance mode either.\\nThis coding situation isn’t nearly as abstract as it may seem. Here’s a real-world example\\nof such a case, taken from the PyMailGUI case study in Programming Python—the\\nfollowing very typical Python classes use multiple inheritance to mix in both application\\nlogic and window tools from independent, standalone classes, and hence must invoke\\nboth  superclass  constructors  explicitly  with  direct  calls  by  name.  As  coded,  a\\nsuper().__init__() here would run only one constructor, and adding super throughout\\nthis  example’s  disjoint  class  trees  would  be  more  work,  would  be  no  simpler,  and\\nwouldn’t make sense in tools meant for arbitrary deployment in clients that may use\\nsuper or not:\\n\\nclass PyMailServerWindow(PyMailServer, windows.MainWindow):\\n    \"a Tk, with extra protocol and mixed-in methods\"\\n    def __init__(self):\\n        windows.MainWindow.__init__(self, appname, srvrname)\\n        PyMailServer.__init__(self)\\n\\nclass PyMailFileWindow(PyMailFile, windows.PopupWindow):\\n    \"a Toplevel, with extra protocol and mixed-in methods\"\\n    def __init__(self, filename):\\n        windows.PopupWindow.__init__(self, appname, filename)\\n        PyMailFile.__init__(self, filename)\\n\\nThe crucial point here is that using super for just the single inheritance cases where it\\napplies most clearly is a potential source of error and confusion, and means that pro-\\ngrammers must remember two ways to accomplish the same goal, when just one—\\nexplicit direct calls—could suffice for all cases.\\nIn other words, unless you can be sure that you will never add a second superclass to\\na class in a tree over your software’s entire lifespan, you cannot use super in single-\\ninheritance mode without understanding and allowing for its much more sophisticated\\nrole in multiple-inheritance trees. We’ll discuss the latter ahead, but it’s not optional\\nif you deploy super at all.\\nFrom a more practical view, it’s also not clear that the trivial amount of code mainte-\\nnance that this super role is envisioned to avoid fully justifies its presence. In Python\\npractice, superclass names in headers are rarely changed; when they are, there are usu-\\nally at most a very small number of superclass calls to update within the class. And\\nconsider this: if you add a new superclass in the future that doesn’t use super (as in the\\npreceding example), you’ll have to either wrap it in an adaptor proxy or augment all\\nthe super calls in your class to use the traditional explicit-name call scheme anyhow—\\na maintenance task that seems just as likely, but perhaps more error-prone if you’ve\\ngrown to rely on super magic.\\n\\n1046 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cLimitation: Operator overloading\\nAs briefly noted in Python’s library manual, super also doesn’t fully work in the pres-\\nence of __X__ operator overloading methods. If you study the following code, you’ll see\\nthat direct named calls to overload methods in the superclass operate normally, but\\nusing the super result in an expression fails to dispatch to the superclass’s overload\\nmethod:\\n\\n>>> class C:                            # In Python 3.X\\n        def __getitem__(self, ix):      # Indexing overload method\\n            print(\\'C index\\')\\n\\n>>> class D(C):\\n        def __getitem__(self, ix):      # Redefine to extend here\\n            print(\\'D index\\')\\n            C.__getitem__(self, ix)     # Traditional call form works\\n            super().__getitem__(ix)     # Direct name calls work too\\n            super()[ix]                 # But operators do not! (__getattribute__)\\n\\n>>> X = C()\\n>>> X[99]\\nC index\\n>>> X = D()\\n>>> X[99]\\nD index\\nC index\\nC index\\nTraceback (most recent call last):\\n  File \"\", line 1, in\\n  File \"\", line 6, in __getitem__\\nTypeError: \\'super\\' object is not subscriptable\\n\\nThis behavior is due to the very same new-style (and 3.X) class change described earlier\\nin this chapter (see “Attribute Fetch for Built-ins Skips Instances” on page 987)—be-\\ncause the proxy object returned by super uses __getattribute__ to catch and dispatch\\nlater method calls, it fails to intercept the automatic __X__ method invocations run by\\nbuilt-in operations including expressions, as these begin their search in the class instead\\nof the instance. This may seem less severe than the multiple-inheritance limitation, but\\noperators should generally work the same as the equivalent method call, especially for\\na built-in like this. Not supporting this adds another exception for super users to con-\\nfront and remember.\\nOther languages’ mileage may vary, but in Python, self is explicit, multiple-inheritance\\nmix-ins and operator overloading are common, and superclass name updates are rare.\\nBecause super adds an odd special case to the language—one with strange semantics,\\nlimited scope, rigid requirements, and questionable reward—most Python program-\\nmers may be better served by the more broadly applicable traditional call scheme. While\\nsuper has some advanced applications too that we’ll study ahead, they may be too\\nobscure to warrant making it a mandatory part of every Python programmer’s toolbox.\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1047\\n\\n\\x0cUse differs in Python 2.X: Verbose calls\\nIf you are a Python 2.X user reading this dual-version book, you should also know that\\nthe super technique is not portable between Python lines. Its form differs between 2.X\\nand 3.X—and not just between classic and new-style classes. It’s really a different tool\\nin 2.X, which cannot run 3.X’s simpler form.\\nTo make this call work in Python 2.X, you must first use new-style classes. Even then,\\nyou must also explicitly pass in the immediate class name and self to super, making\\nthis  call  so  complex  and  verbose  that  in  most  cases  it’s  probably  easier  to  avoid  it\\ncompletely, and simply name the superclass explicitly per the previous traditional code\\npattern (for brevity, I’ll leave it to readers to consider what changing a class’s own name\\nmeans for code maintenance when using the 2.X super form!):\\n\\n>>> class C(object):                # In Python 2.X: for new-style classes only\\n        def act(self):\\n            print(\\'spam\\')\\n\\n>>> class D(C):\\n        def act(self):\\n            super(D, self).act()    # 2.X: different call format - seems too complex\\n            print(\\'eggs\\')           # \"D\" may be just as much to type/change as \"C\"!\\n\\n>>> X = D()\\n>>> X.act()\\nspam\\neggs\\n\\nAlthough you can use the 2.X call form in 3.X for backward compatibility, it’s too\\ncumbersome to deploy in 3.X-only code, and the more reasonable 3.X form is not usable\\nin 2.X:\\n\\n>>> class D(C):\\n        def act(self):\\n            super().act()           # Simpler 3.X call format fails in 2.X\\n            print(\\'eggs\\')\\n\\n>>> X = D()\\n>>> X.act()\\nTypeError: super() takes at least 1 argument (0 given)\\n\\nOn the other hand, the traditional call form with explicit class names works in 2.X in\\nboth classic and new-style classes, and exactly as it does in 3.X:\\n\\n>>> class D(C):\\n        def act(self):\\n            C.act(self)             # But traditional pattern works portably\\n            print(\\'eggs\\')           # And may often be simpler in 2.X code\\n\\n>>> X = D()\\n>>> X.act()\\nspam\\neggs\\n\\n1048 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cSo why use a technique that works in only limited contexts instead of one that works\\nin many more? Though its basis is complex, the next sections attempt to rally support\\nfor the super cause.\\n\\nThe super Upsides: Tree Changes and Dispatch\\nHaving just shown you the downsides of super, I should also confess that I’ve been\\ntempted to use this call in code that would only ever run on 3.X, and which used a very\\nlong superclass reference path through a module package (that is, mostly for laziness,\\nbut coding brevity can matter too). To be fair, super may still be useful in some use\\ncases, the chief among which merit a brief introduction here:\\n\\n• Changing class trees at runtime: When a superclass may be changed at runtime, it’s\\nnot possible to hardcode its name in a call expression, but it is possible to dispatch\\ncalls via super.\\nOn the other hand, this case is extremely rare in Python programming, and other\\ntechniques can often be used in this context as well.\\n\\n• Cooperative multiple inheritance method dispatch: When multiple inheritance trees\\nmust dispatch to the same-named method in multiple classes, super can provide a\\nprotocol for orderly call routing.\\nOn the other hand, the class tree must rely upon the ordering of classes by the\\nMRO—a complex tool in its own right that is artificial to the problem a program\\nis meant to address—and must be coded or augmented to use super in each version\\nof the method in the tree to be effective. Such dispatch can also often be imple-\\nmented in other ways (e.g., via instance state).\\n\\nAs discussed earlier, super can also be used to select a superclass generically as long as\\nthe MRO’s default makes sense, though in traditional code naming a superclass ex-\\nplicitly is often preferable, and may even be required. Moreover, even valid super use\\ncases tend to be uncommon in many Python programs—to the point of seeming aca-\\ndemic curiosity to some. The two cases just listed, however, are most often cited as\\nsuper rationales, so let’s take a quick look at each.\\n\\nRuntime Class Changes and super\\nSuperclass that might be changed at runtime dynamically preclude hardcoding their\\nnames in a subclass’s methods, while super will happily look up the current superclass\\ndynamically. Still, this case may be too rare in practice to warrant the super model by\\nitself, and can often be implemented in other ways in the exceptional cases where it is\\nneeded. To illustrate, the following changes the superclass of C dynamically by changing\\nthe subclass’s __bases__ tuple in 3.X:\\n\\n>>> class X:\\n        def m(self): print(\\'X.m\\')\\n>>> class Y:\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1049\\n\\n\\x0c        def m(self): print(\\'Y.m\\')\\n>>> class C(X):                                 # Start out inheriting from X\\n        def m(self): super().m()                # Can\\'t hardcode class name here\\n\\n>>> i = C()\\n>>> i.m()\\nX.m\\n>>> C.__bases__ = (Y,)                          # Change superclass at runtime!\\n>>> i.m()\\nY.m\\n\\nThis  works  (and  shares  behavior-morphing  goals  with  other  deep  magic,  such  as\\nchanging an instance’s __class__), but seems rare in the extreme. Moreover, there may\\nbe other ways to achieve the same effect—perhaps most simply, calling through the\\ncurrent superclass tuple’s value indirectly: special code to be sure, but only for a very\\nspecial case (and perhaps not any more special than implicit routing by MROs):\\n\\n>>> class C(X):\\n        def m(self): C.__bases__[0].m(self)     # Special code for a special case\\n\\n>>> i = C()\\n>>> i.m()\\nX.m\\n>>> C.__bases__ = (Y,)                          # Same effect, without super()\\n>>> i.m()\\nY.m\\n\\nGiven the preexisting alternatives, this case alone doesn’t seem to justify super, though\\nin more complex trees, the next rationale—based on the tree’s MRO order instead of\\nphysical superclass links—may apply here as well.\\n\\nCooperative Multiple Inheritance Method Dispatch\\nThe second of the use cases listed earlier is the main rationale commonly given for\\nsuper, and also borrows from other programming languages (most notably, Dylan),\\nwhere its use case may be more common than it is in typical Python code. It generally\\napplies to diamond pattern multiple inheritance trees, discussed earlier in this chapter,\\nand  allows  for  cooperative  and  conformant  classes  to  route  calls  to  a  same-named\\nmethod coherently among multiple class implementations. Especially for constructors,\\nwhich have multiple implementations normally, this can simplify call routing protocol\\nwhen used consistently.\\nIn this mode, each super call selects the method from a next class following it in the\\nMRO ordering of the class of the self subject of a method call. The MRO was intro-\\nduced earlier; it’s the path Python follows for inheritance in new-style classes. Because\\nthe MRO’s linear ordering depends on which class self was made from, the order of\\nmethod dispatch orchestrated by super can vary per class tree, and visits each class just\\nonce as long as all classes use super to dispatch.\\n\\n1050 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cSince every class participates in a diamond under  object in 3.X (and 2.X new-style\\nclasses), the applications are broader than you might expect. In fact, some of the earlier\\nexamples that demonstrated super shortcomings in multiple inheritance trees could\\nuse this call to achieve their dispatch goals. To do so, however, super must be used\\nuniversally in the class tree to ensure that method call chains are passed on—a fairly\\nmajor requirement that may be difficult to enforce in much existing and new code.\\n\\nThe basics: Cooperative super call in action\\nLet’s take a look at what this role means in code. In this and the following sections,\\nwe’ll both learn how super works, and explore the tradeoffs it implies along the way.\\nTo get started, consider the following traditionally coded Python classes (condensed\\nsomewhat here as usual for space):\\n\\n>>> class B:\\n        def __init__(self): print(\\'B.__init__\\')      # Disjoint class tree branches\\n>>> class C:\\n        def __init__(self): print(\\'C.__init__\\')\\n>>> class D(B, C): pass\\n\\n>>> x = D()                                          # Runs leftmost only by default\\nB.__init__\\n\\nIn this case, superclass tree branches are disjoint (they don’t share a common explicit\\nancestor), so subclasses that combine them must call through each superclass by name\\n—a common situation in much existing Python code that super cannot address directly\\nwithout code changes:\\n>>> class D(B, C):\\n        def __init__(self):                          # Traditional form\\n            B.__init__(self)                         # Invoke supers by name\\n            C.__init__(self)\\n\\n>>> x = D()\\nB.__init__\\nC.__init__\\n\\nIn diamond class tree patterns, though, explicit-name calls may by default trigger the\\ntop-level class’s method more than once, though this might be subverted with addi-\\ntional protocols (e.g., status markers in the instance):\\n\\n>>> class A:\\n        def __init__(self): print(\\'A.__init__\\')\\n>>> class B(A):\\n        def __init__(self): print(\\'B.__init__\\'); A.__init__(self)\\n>>> class C(A):\\n        def __init__(self): print(\\'C.__init__\\'); A.__init__(self)\\n\\n>>> x = B()\\nB.__init__\\nA.__init__\\n>>> x = C()                                # Each super works by itself\\nC.__init__\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1051\\n\\n\\x0cA.__init__\\n\\n>>> class D(B, C): pass                    # Still runs leftmost only\\n>>> x = D()\\nB.__init__\\nA.__init__\\n\\n>>> class D(B, C):\\n        def __init__(self):                # Traditional form\\n            B.__init__(self)               # Invoke both supers by name\\n            C.__init__(self)\\n\\n>>> x = D()                                # But this now invokes A twice!\\nB.__init__\\nA.__init__\\nC.__init__\\nA.__init__\\n\\nBy contrast, if all classes use super, or are appropriately coerced by proxies to behave\\nas if they do, the method calls are dispatched according to class order in the MRO, such\\nthat the top-level class’s method is run just once:\\n\\n>>> class A:\\n        def __init__(self): print(\\'A.__init__\\')\\n>>> class B(A):\\n        def __init__(self): print(\\'B.__init__\\'); super().__init__()\\n>>> class C(A):\\n        def __init__(self): print(\\'C.__init__\\'); super().__init__()\\n\\n>>> x = B()                   # Runs B.__init__, A is next super in self\\'s B MRO\\nB.__init__\\nA.__init__\\n>>> x = C()\\nC.__init__\\nA.__init__\\n\\n>>> class D(B, C): pass\\n>>> x = D()                   # Runs B.__init__, C is next super in self\\'s D MRO!\\nB.__init__\\nC.__init__\\nA.__init__\\n\\nThe real magic behind this is the linear MRO list constructed for the class of self—\\nbecause each class appears just once on this list, and because super dispatches to the\\nnext class on this list, it ensures an orderly invocation chain that visits each class just\\nonce. Crucially, the next class following B in the MRO differs depending on the class\\nof self—it’s A for a B instance, but C for a D instance, accounting for the order of con-\\nstructors run:\\n\\n>>> B.__mro__\\n(<class \\'__main__.B\\'>, <class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\n>>> D.__mro__\\n(<class \\'__main__.D\\'>, <class \\'__main__.B\\'>, <class \\'__main__.C\\'>,\\n<class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\n1052 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cThe MRO and its algorithm were presented earlier in this chapter. By selecting a next\\nclass in the MRO sequence, a super call in a class’s method propagates the call through\\nthe tree, so long as all classes do the same. In this mode super does not necessarily\\nchoose a superclass at all; it picks the next in the linearized MRO, which might be a\\nsibling—or even a lower relative—in the class tree of a given instance. See “Tracing the\\nMRO” on page 1002 for other examples of the path super dispatch would follow, es-\\npecially for nondiamonds.\\nThe preceding works—and may even seem clever at first glance—but its scope may\\nalso appear limited to some. Most Python programs do not rely on the nuances of\\ndiamond pattern multiple inheritance trees (in fact, many Python programmers I’ve\\nmet do not know what the term means!). Moreover, super applies most directly to single\\ninheritance  and  cooperative  diamond  cases,  and  may  seem  superfluous  for  disjoint\\nnondiamond cases, where we might want to invoke superclass methods selectively or\\nindependently. Even cooperative diamonds can be managed in other ways that may\\nafford programmers more control than an automatic MRO ordering can. To evaluate\\nthis tool objectively, though, we need to look deeper.\\n\\nConstraint: Call chain anchor requirement\\nThe super call comes with complexities that may not be apparent on first encounter,\\nand may even seem initially like features. For example, because all classes inherit from\\nobject in 3.X automatically (and explicitly in 2.X new-style classes), the MRO ordering\\ncan be used even in cases where the diamond is only implicit—in the following, trig-\\ngering constructors in independent classes automatically:\\n\\n>>> class B:\\n        def __init__(self): print(\\'B.__init__\\'); super().__init__()\\n>>> class C:\\n        def __init__(self): print(\\'C.__init__\\'); super().__init__()\\n\\n>>> x = B()                   # object is an implied super at the end of MRO\\nB.__init__\\n>>> x = C()\\nC.__init__\\n\\n>>> class D(B, C): pass       # Inherits B.__init__ but B\\'s MRO differs for D\\n>>> x = D()                   # Runs B.__init__, C is next super in self\\'s D MRO!\\nB.__init__\\nC.__init__\\n\\nTechnically, this dispatch model generally requires that the method being called by\\nsuper must exist, and must have the same argument signature across the class tree, and\\nevery appearance of the method but the last must use super itself. This prior example\\nworks only because the implied object superclass at the end of the MRO of all three\\nclasses happens to have a compatible __init__ that satisfies these rules:\\n\\n>>> B.__mro__\\n(<class \\'__main__.B\\'>, <class \\'object\\'>)\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1053\\n\\n\\x0c>>> D.__mro__\\n(<class \\'__main__.D\\'>, <class \\'__main__.B\\'>, <class \\'__main__.C\\'>, <class \\'object\\'>)\\n\\nHere, for a D instance, the next class in the MRO after B is C, which is followed by\\nobject whose __init__ silently accepts the call from C and ends the chain. Thus, B’s\\nmethod calls C’s, which ends in object’s version, even though C is not a superclass to B.\\nReally, though, this example is atypical—and perhaps even lucky. In most cases, no\\nsuch suitable default will exist in object, and it may be less trivial to satisfy this model’s\\nexpectations. Most trees will require an explicit—and possibly extra—superclass to\\nserve the anchoring role that object does here, to accept but not forward the call. Other\\ntrees may require careful design to adhere to this requirement. Moreover, unless Python\\noptimizes it away, the call to object (or other anchor) defaults at the end of the chain\\nmay also add extra performance costs.\\nBy contrast, in such cases direct calls incur neither extra coding requirements nor added\\nperformance cost, and make dispatch more explicit and direct:\\n\\n>>> class B:\\n        def __init__(self): print(\\'B.__init__\\')\\n>>> class C:\\n        def __init__(self): print(\\'C.__init__\\')\\n>>> class D(B, C):\\n        def __init__(self): B.__init__(self); C.__init__(self)\\n\\n>>> x = D()\\nB.__init__\\nC.__init__\\n\\nScope: An all-or-nothing model\\nAlso keep in mind that traditional classes that were not written to use super in this role\\ncannot be directly used in such cooperative dispatch trees, as they will not forward calls\\nalong the MRO chain. It’s possible to incorporate such classes with proxies that wrap\\nthe original object and add the requisite super calls, but this imposes both additional\\ncoding requirements and performance costs on the model. Given that there are many\\nmillions  of  lines  of  existing  Python  code  that  do  not  use  super,  this  seems  a  major\\ndetriment.\\nWatch what happens, for example, if any one class fails to pass along the call chain by\\nomitting a super, ending the call chain prematurely—like __slots__, super is generally\\nan all-or-nothing feature:\\n\\n>>> class B:\\n        def __init__(self): print(\\'B.__init__\\'); super().__init__()\\n>>> class C:\\n        def __init__(self): print(\\'C.__init__\\'); super().__init__()\\n>>> class D(B, C):\\n        def __init__(self): print(\\'D.__init__\\'); super().__init__()\\n>>> X = D()\\nD.__init__\\nB.__init__\\n\\n1054 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cC.__init__\\n>>> D.__mro__\\n(<class \\'__main__.D\\'>, <class \\'__main__.B\\'>, <class \\'__main__.C\\'>, <class \\'object\\'>)\\n\\n# What if you must use a class that doesn\\'t call super?\\n\\n>>> class B:\\n        def __init__(self): print(\\'B.__init__\\')\\n>>> class D(B, C):\\n        def __init__(self): print(\\'D.__init__\\'); super().__init__()\\n>>> X = D()\\nD.__init__\\nB.__init__             # It\\'s an all-or-nothing tool...\\n\\nSatisfying this mandatory propagation requirement may be no simpler than direct by-\\nname calls—which you might still forget, but which you won’t need to require of all\\nthe code your classes employ. As mentioned, it’s possible to adapt a class like B by\\ninheriting from a proxy class that embeds B instances, but that seems artificial to pro-\\ngram goals, adds an extra call to each wrapped method, is subject to the new-style class\\nproblems we met earlier regarding interface proxies and built-ins, and seems an extra-\\nordinary and even stunning added coding requirement inherent in a model intended to\\nsimplify code.\\n\\nFlexibility: Call ordering assumptions\\nRouting with super also assumes that you really mean to pass method calls throughout\\nall your classes per the MRO, which may or may not match your call ordering require-\\nments. For example, imagine that—irrespective of other inheritance ordering needs—\\nthe following requires that the class C’s version of a given method be run before B’s in\\nsome contexts. If the MRO says otherwise, you’re back to traditional calls, which may\\nconflict with super usage—in the following, invoking C’s method twice:\\n\\n# What if method call ordering needs differ from the MRO?\\n\\n>>> class B:\\n        def __init__(self): print(\\'B.__init__\\'); super().__init__()\\n>>> class C:\\n        def __init__(self): print(\\'C.__init__\\'); super().__init__()\\n>>> class D(B, C):\\n        def __init__(self): print(\\'D.__init__\\'); C.__init__(self); B.__init__(self)\\n>>> X = D()\\nD.__init__\\nC.__init__\\nB.__init__\\nC.__init__             # It\\'s the MRO xor explicit calls...\\n\\nSimilarly, if you want some methods to not run at all, the super automatic path won’t\\napply as directly as explicit calls may, and will make it difficult to take more explicit\\ncontrol of the dispatch process. In realistic programs with many methods, resources,\\nand state variables, these seem entirely plausible scenarios. While you could reorder\\nsuperclasses in D for this method, that may break other expectations.\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1055\\n\\n\\x0cCustomization: Method replacement\\nOn a related note, the universal deployment expectations of super may make it difficult\\nfor a single class to replace (override) an inherited method altogether. Not passing the\\ncall higher with super—intentionally in this case—works fine for the class itself, but\\nmay break the call chain of trees it’s mixed into, thereby preventing methods elsewhere\\nin the tree from running. Consider the following tree:\\n\\n>>> class A:\\n        def method(self): print(\\'A.method\\'); super().method()\\n>>> class B(A):\\n        def method(self): print(\\'B.method\\'); super().method()\\n>>> class C:\\n        def method(self): print(\\'C.method\\')       # No super: must anchor the chain!\\n>>> class D(B, C):\\n        def method(self): print(\\'D.method\\'); super().method()\\n>>> X = D()\\n>>> X.method()\\nD.method\\nB.method\\nA.method               # Dispatch to all per the MRO automatically\\nC.method\\n\\nMethod replacement here breaks the super model, and probably leads us back to the\\ntraditional form:\\n\\n# What if a class needs to replace a super\\'s default entirely?\\n\\n>>> class B(A):\\n        def method(self): print(\\'B.method\\')       # Drop super to replace A\\'s method\\n>>> class D(B, C):\\n        def method(self): print(\\'D.method\\'); super().method()\\n>>> X = D()\\n>>> X.method()\\nD.method\\nB.method               #  But replacement also breaks the call chain...\\n\\n>>> class D(B, C):\\n        def method(self): print(\\'D.method\\'); B.method(self); C.method(self)\\n>>> D().method()\\nD.method\\nB.method\\nC.method               # It\\'s back to explicit calls...\\n\\nOnce again, the problem with assumptions is that they assume things! Although the\\nassumption of universal routing might be reasonable for constructors, it would also\\nseem to conflict with one of the core tenets of OOP—unrestricted subclass customiza-\\ntion. This might suggest restricting super usage to constructors, but even these might\\nsometimes warrant replacement, and this adds an odd special-case requirement for one\\nspecific context. A tool that can be used only for certain categories of methods might\\nbe seen by some as redundant—and even spurious, given the extra complexity it im-\\nplies.\\n\\n1056 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cCoupling: Application to mix-in classes\\nSubtly, when we say super selects the next class in the MRO, we really mean the next\\nclass in the MRO that implements the requested method—it technically skips ahead until\\nit finds a class with the requested name. This matters for independent mix-in classes,\\nwhich might be added to arbitrary client trees. Without this skipping-ahead behavior,\\nsuch mix-ins wouldn’t work at all—they would otherwise drop the call chain of their\\nclients’ arbitrary methods, and couldn’t rely on their own super calls to work as ex-\\npected.\\nIn the following independent branches, for example, C’s call to method is passed on,\\neven though Mixin, the next class in the C instance’s MRO, doesn’t define that method’s\\nname. As long as method name sets are disjoint, this just works—the call chains of each\\nbranch can exist independently:\\n\\n# Mix-ins work for disjoint method sets\\n\\n>>> class A:\\n        def other(self): print(\\'A.other\\')\\n>>> class Mixin(A):\\n        def other(self): print(\\'Mixin.other\\'); super().other()\\n\\n>>> class B:\\n        def method(self): print(\\'B.method\\')\\n>>> class C(Mixin, B):\\n        def method(self): print(\\'C.method\\'); super().other(); super().method()\\n\\n>>> C().method()\\nC.method\\nMixin.other\\nA.other\\nB.method\\n\\n>>> C.__mro__\\n(<class \\'__main__.C\\'>, <class \\'__main__.Mixin\\'>, <class \\'__main__.A\\'>,\\n<class \\'__main__.B\\'>, <class \\'object\\'>)\\n\\nSimilarly, mixing the other way doesn’t break call chains of the mix-in either. For in-\\nstance, in the following, even though B doesn’t define other when called in C, classes\\ndo later in the MRO. In fact, the call chains work even if one of the branches doesn’t\\nuse super at all—as long as a method is defined somewhere ahead on the MRO, its call\\nworks:\\n\\n>>> class C(B, Mixin):\\n        def method(self): print(\\'C.method\\'); super().other(); super().method()\\n\\n>>> C().method()\\nC.method\\nMixin.other\\nA.other\\nB.method\\n\\n>>> C.__mro__\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1057\\n\\n\\x0c(<class \\'__main__.C\\'>, <class \\'__main__.B\\'>, <class \\'__main__.Mixin\\'>,\\n<class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\nThis is also true in the presence of diamonds—disjoint method sets are dispatched as\\nexpected, even if not implemented by each disjoint branch, because we select the next\\non the MRO with the method. Really, because the MRO contains the same classes in\\nthese cases, and because a subclass always appears before its superclass in the MRO,\\nthey are equivalent contexts. For example, the call in Mixin to other in the following\\nstill finds it in A, even though the next class after Mixin on the MRO is B (the call to\\nmethod in C works again for similar reasons):\\n\\n# Explicit diamonds work too\\n\\n>>> class A:\\n        def other(self): print(\\'A.other\\')\\n>>> class Mixin(A):\\n        def other(self): print(\\'Mixin.other\\'); super().other()\\n\\n>>> class B(A):\\n        def method(self): print(\\'B.method\\')\\n>>> class C(Mixin, B):\\n        def method(self): print(\\'C.method\\'); super().other(); super().method()\\n\\n>>> C().method()\\nC.method\\nMixin.other\\nA.other\\nB.method\\n\\n>>> C.__mro__\\n(<class \\'__main__.C\\'>, <class \\'__main__.Mixin\\'>, <class \\'__main__.B\\'>,\\n<class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\n# Other mix-in orderings work too\\n\\n>>> class C(B, Mixin):\\n        def method(self): print(\\'C.method\\'); super().other(); super().method()\\n\\n>>> C().method()\\nC.method\\nMixin.other\\nA.other\\nB.method\\n\\n>>> C.__mro__\\n(<class \\'__main__.C\\'>, <class \\'__main__.B\\'>, <class \\'__main__.Mixin\\'>,\\n<class \\'__main__.A\\'>, <class \\'object\\'>)\\n\\nStill, this has an effect that is no different—but may seem wildly more implicit—than\\ndirect by-name calls, which also work the same in this case regardless of superclass\\nordering, and whether there is a diamond or not. In this case, the motivation for relying\\non MRO ordering seems on shaky ground, if the traditional form is both simpler and\\nmore explicit, and offers more control and flexibility:\\n\\n1058 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c# But direct calls work here too: explicit is better than implicit\\n\\n>>> class C(Mixin, B):\\n       def method(self): print(\\'C.method\\'); Mixin.other(self); B.method(self)\\n\\n>>> X = C()\\n>>> X.method()\\nC.method\\nMixin.other\\nA.other\\nB.method\\n\\nMore  crucially,  this  example  so  far  assumes  that  method  names  are  disjoint  in  its\\nbranches; the dispatch order for same-named methods in diamonds like this may be\\nmuch less fortuitous. In a diamond like the preceding, for example, it’s not impossible\\nthat a client class could invalidate a super call’s intent—the call to method in Mixin in\\nthe following works to run A’s version as expected, unless it’s mixed into a tree that\\ndrops the call chain:\\n\\n# But for nondisjoint methods: super creates overly strong coupling\\n\\n>>> class A:\\n        def method(self): print(\\'A.method\\')\\n>>> class Mixin(A):\\n        def method(self): print(\\'Mixin.method\\'); super().method()\\n>>> Mixin().method()\\nMixin.method\\nA.method\\n\\n>>> class B(A):\\n        def method(self): print(\\'B.method\\')      # super here would invoke A after B\\n>>> class C(Mixin, B):\\n        def method(self): print(\\'C.method\\'); super().method()\\n>>> C().method()\\nC.method\\nMixin.method\\nB.method                                         # We miss A in this context only!\\n\\nIt may be that B shouldn’t redefine this method anyhow (and frankly, we may be en-\\ncroaching on problems inherent in multiple inheritance in general), but this need not\\nalso break the mix-in—direct calls give you more control in such cases, and allow mix-\\nin classes to be much more independent of usage contexts:\\n\\n# And direct calls do not: they are immune to context of use\\n\\n>>> class A:\\n        def method(self): print(\\'A.method\\')\\n>>> class Mixin(A):\\n        def method(self): print(\\'Mixin.method\\'); A.method(self)       # C irrelevant\\n\\n>>> class C(Mixin, B):\\n        def method(self): print(\\'C.method\\'); Mixin.method(self)\\n>>> C().method()\\nC.method\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1059\\n\\n\\x0cMixin.method\\nA.method\\n\\nMore to the point, by making mix-ins more self-contained, direct calls minimize com-\\nponent coupling that always skews program complexity higher—a fundamental soft-\\nware principle that seems neglected by super’s variable and context-specific dispatch\\nmodel.\\n\\nCustomization: Same-argument constraints\\nAs a final note, you should also consider the consequences of using super when method\\narguments  differ  per  class—because  a  class  coder  can’t  be  sure  which  version  of  a\\nmethod  super  might  invoke  (indeed,  this  may  vary  per  tree!),  every  version  of  the\\nmethod must generally accept the same arguments list, or choose its inputs with anal-\\nysis of generic argument lists—either of which imposes additional requirements on\\nyour code. In realistic programs, this constraint may in fact be a true showstopper for\\nmany potential super applications, precluding its use entirely.\\nTo illustrate why this can matter, recall the pizza shop employee classes we wrote in\\nChapter 31. As coded there, both subclasses use direct by-name calls to invoke the\\nsuperclass constructor, filling in an expected salary argument automatically—the logic\\nbeing that the subclass implies the pay grade:\\n\\n>>> class Employee:\\n        def __init__(self, name, salary):                  # Common superclass\\n            self.name = name\\n            self.salary = salary\\n\\n>>> class Chef1(Employee):\\n        def __init__(self, name):                          # Differing arguments\\n            Employee.__init__(self, name, 50000)           # Dispatch by direct call\\n\\n>>> class Server1(Employee):\\n        def __init__(self, name):\\n            Employee.__init__(self, name, 40000)\\n\\n>>> bob = Chef1(\\'Bob\\')\\n>>> sue = Server1(\\'Sue\\')\\n>>> bob.salary, sue.salary\\n(50000, 40000)\\n\\nThis works, but since this is a single-inheritance tree, we might be tempted to deploy\\nsuper here to route the constructor calls generically. Doing so works for either subclass\\nin isolation, since its MRO includes just itself and its actual superclass:\\n\\n>>> class Chef2(Employee):\\n        def __init__(self, name):\\n            super().__init__(name, 50000)                  # Dispatch by super()\\n\\n>>> class Server2(Employee):\\n        def __init__(self, name):\\n            super().__init__(name, 40000)\\n\\n1060 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c>>> bob = Chef2(\\'Bob\\')\\n>>> sue = Server2(\\'Sue\\')\\n>>> bob.salary, sue.salary\\n(50000, 40000)\\n\\nWatch what happens, though, when an employee is a member of both categories. Be-\\ncause the constructors in the tree have differing argument lists, we’re in trouble:\\n\\n>>> class TwoJobs(Chef2, Server2): pass\\n\\n>>> tom = TwoJobs(\\'Tom\\')\\nTypeError: __init__() takes 2 positional arguments but 3 were given\\n\\nThe problem here is that the super call in Chef2 no longer invokes its Employee super-\\nclass, but instead invokes its sibling class and follower on the MRO, Server2. Since this\\nsibling has a differing argument list than the true superclass—expecting just self and\\nname—the code breaks. This is inherent in super use: because the MRO can differ per\\ntree, it might call different versions of a method in different trees—even some you may\\nnot be able to anticipate when coding a class by itself:\\n\\n>>> TwoJobs.__mro__\\n(<class \\'__main__.TwoJobs\\'>, <class \\'__main__.Chef2\\'>, <class \\'__main__.Server2\\'>\\n<class \\'__main__.Employee\\'>, <class \\'object\\'>)\\n\\n>>> Chef2.__mro__\\n(<class \\'__main__.Chef2\\'>, <class \\'__main__.Employee\\'>, <class \\'object\\'>)\\n\\nBy contrast, the direct by-name call scheme still works when the classes are mixed,\\nthough the results are a bit dubious—the combined category gets the pay of the leftmost\\nsuperclass:\\n\\n>>> class TwoJobs(Chef1, Server1): pass\\n\\n>>> tom = TwoJobs(\\'Tom\\')\\n>>> tom.salary\\n50000\\n\\nReally, we probably want to route the call to the top-level class in this event with a new\\nsalary—a model that is possible with direct calls but not with super alone. Moreover,\\ncalling Employee directly in this one class means our code uses two dispatch techniques\\nwhen just one—direct calls—would suffice:\\n\\n>>> class TwoJobs(Chef1, Server1):\\n        def __init__(self, name): Employee.__init__(self, name, 70000)\\n\\n>>> tom = TwoJobs(\\'Tom\\')\\n>>> tom.salary\\n70000\\n\\n>>> class TwoJobs(Chef2, Server2):\\n        def __init__(self, name): super().__init__(name, 70000)\\n\\n>>> tom = TwoJobs(\\'Tom\\')\\nTypeError: __init__() takes 2 positional arguments but 3 were given\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1061\\n\\n\\x0cThis example may warrant redesign in general—splitting off shareable parts of Chef\\nand  Server  to  mix-in  classes  without  a  constructor,  for  example.  It’s  also  true  that\\npolymorphism in general assumes that the methods in an object’s external interface\\nhave the same argument signature, though this doesn’t quite apply to customization\\nof superclass methods—an internal implementation technique that should by nature\\nsupport variation, especially in constructors.\\nBut the crucial point here is that because direct calls do not make code dependent on\\na magic ordering that can vary per tree, they more directly support argument list flex-\\nibility.  More  broadly,  the  questionable  (or  weak)  performances  super  turns  in  on\\nmethod replacement, mix-in coupling, call ordering, and argument constraints should\\nmake you evaluate its deployment carefully. Even in single-inheritance mode, its po-\\ntential for later impacts as trees grow is considerable.\\nIn sum, the three requirements of super in this role are also the source of most of its\\nusability issues:\\n\\n• The method called by super must exist—which requires extra code if no anchor is\\n\\npresent.\\n\\n• The method called by super must have the same argument signature across the\\nclass tree—which impairs flexibility, especially for implementation-level methods\\nlike constructors.\\n\\n• Every appearance of the method called by super but the last must use super itself\\n—which  makes  it  difficult  to  use  existing  code,  change  call  ordering,  override\\nmethods, and code self-contained classes.\\n\\nTaken together, these seem to make for a tool with both substantial complexity and\\nsignificant  tradeoffs—downsides  that  will  assert  themselves  the  moment  the  code\\ngrows to incorporate multiple inheritance.\\nNaturally, there may be creative workarounds for the super dilemmas just posed, but\\nadditional coding steps would further dilute the call’s benefits—and we’ve run out of\\nspace here in any event. There are also alternative non-super solutions to some diamond\\nmethod dispatch problems, but these will have to be left as a user exercise for space\\nreasons too. In general, when superclass methods are called by explicit name, root\\nclasses of diamonds might check state in instances to avoid firing twice—a similarly\\ncomplex coding pattern, but required rarely in most code, and which to some may seem\\nno more difficult than using super itself.\\n\\nThe super Summary\\nSo there it is—the bad and the good. As with all Python extensions, you should be the\\njudge on this one too. I’ve tried to give both sides of the debate a fair shake here to help\\nyou decide. But because the super call:\\n\\n• Differs in form between 2.X and 3.X\\n\\n1062 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c• In 3.X, relies on arguably non-Pythonic magic, and does not fully apply to operator\\n\\noverloading or traditionally coded multiple-inheritance trees\\n\\n• In 2.X, seems so verbose in this intended role that it may make code more complex\\n\\ninstead of less\\n\\n• Claims  code  maintenance  benefits  that  may  be  more  hypothetical  than  real  in\\n\\nPython practice\\n\\neven ex–Java programmers should also consider this book’s preferred traditional tech-\\nnique of explicit-name superclass calls to be at least as valid a solution as Python’s super\\n—a call that on some levels seems an unusual and limited answer to a question that\\nwas not being asked by most Python programmers, and was not deemed important for\\nmuch of Python’s history.\\nAt the same time, the super call offers one solution to the difficult problem of same-\\nnamed method dispatch in multiple inheritance trees, for programs that choose to use\\nit universally and consistently. But therein lies one of its largest obstacles: it requires\\nuniversal deployment to address a problem most programmers probably do not have.\\nMoreover, at this point in Python’s history, asking programmers to change their exist-\\ning code to use this call widely enough to make it reliable seems highly unrealistic.\\nPerhaps the chief problem of this role, though, is the role itself—same-named method\\ndispatch in multiple inheritance trees is relatively rare in real Python programs, and\\nobscure enough to have generated both much controversy and much misunderstanding\\nsurrounding this role. People don’t use Python the same way they use C++, Java, or\\nDylan, and lessons from other such languages do not necessarily apply.\\nAlso keep in mind that using super makes your program’s behavior dependent on the\\nMRO algorithm—a procedure that we’ve covered only informally here due to its com-\\nplexity, that is artificial to your program’s purpose, and that seems tersely documented\\nand understood in the Python world. As we’ve seen, even if you understand the MRO,\\nits implications on customization, coupling, and flexibility are remarkably subtle. If you\\ndon’t completely understand this algorithm—or have goals that its application does\\nnot address—you may be better served not relying on it to implicitly trigger actions in\\nyour code.\\nOr, to quote a Python motto from its import this creed:\\n\\nIf the implementation is hard to explain, it’s a bad idea.\\n\\nThe super call seems firmly in this category. Most programmers won’t use an arcane\\ntool aimed at a rare use case, no matter how clever it may be. This is especially true in\\na scripting language that bills itself as friendly to nonspecialists. Regrettably, use by any\\nprogrammer can impose such a tool on others anyhow—the real reason I’ve covered it\\nhere, and a theme we’ll revisit at the end of this book.\\nAs usual, time and user base will tell if this call’s tradeoffs or momentum lead to broader\\nadoption or not. At the least, it behooves you to also know about the traditional explicit-\\nname superclass call technique, as it is still commonly used and often either simpler or\\n\\nThe super Built-in Function: For Better or Worse?\\n\\n| 1063\\n\\n\\x0crequired in today’s real-world Python programming. If you do choose to use this tool,\\nmy own advice to readers is to remember that using super:\\n\\n• In single-inheritance mode can mask later problems and lead to unexpected be-\\n\\nhavior as trees grow\\n\\n• In multiple-inheritance mode brings with it substantial complexity for an atypical\\n\\nPython use case\\n\\nFor other opinions on Python’s super that go into further details both good and bad,\\nsearch the Web for related articles. You can find plenty of additional positions, though\\nin the end, Python’s future relies as much on yours as any other.\\n\\nClass Gotchas\\nWe’ve reached the end of the primary OOP coverage in this book. After exceptions,\\nwe’ll explore additional class-related examples and topics in the last part of the book,\\nbut  that  part  mostly  just  gives  expanded  coverage  to  concepts  introduced  here.  As\\nusual, let’s wrap up this part with the standard warnings about pitfalls to avoid.\\nMost class issues can be boiled down to namespace issues—which makes sense, given\\nthat classes are just namespaces with a handful of extra tricks. Some of the items in this\\nsection are more like class usage pointers than problems, but even experienced class\\ncoders have been known to stumble on a few.\\n\\nChanging Class Attributes Can Have Side Effects\\nTheoretically speaking, classes (and class instances) are mutable objects. As with built-\\nin lists and dictionaries, you can change them in place by assigning to their attributes\\n—and as with lists and dictionaries, this means that changing a class or instance object\\nmay impact multiple references to it.\\nThat’s usually what we want, and is how objects change their state in general, but\\nawareness of this issue becomes especially critical when changing class attributes. Be-\\ncause all instances generated from a class share the class’s namespace, any changes at\\nthe class level are reflected in all instances, unless they have their own versions of the\\nchanged class attributes.\\nBecause classes, modules, and instances are all just objects with attribute namespaces,\\nyou can normally change their attributes at runtime by assignments. Consider the fol-\\nlowing class. Inside the class body, the assignment to the name a generates an attribute\\nX.a, which lives in the class object at runtime and will be inherited by all of X’s instances:\\n\\n>>> class X:\\n        a = 1       # Class attribute\\n\\n>>> I = X()\\n>>> I.a             # Inherited by instance\\n\\n1064 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c1\\n>>> X.a\\n1\\n\\nSo far, so good—this is the normal case. But notice what happens when we change the\\nclass attribute dynamically outside the class statement: it also changes the attribute in\\nevery object that inherits from the class. Moreover, new instances created from the class\\nduring this session or program run also get the dynamically set value, regardless of what\\nthe class’s source code says:\\n\\n>>> X.a = 2         # May change more than X\\n>>> I.a             # I changes too\\n2\\n>>> J = X()         # J inherits from X\\'s runtime values\\n>>> J.a             # (but assigning to J.a changes a in J, not X or I)\\n2\\n\\nIs this a useful feature or a dangerous trap? You be the judge. As we learned in Chap-\\nter 27, you can actually get work done by changing class attributes without ever making\\na single instance—a technique that can simulate the use of “records” or “structs” in\\nother languages. As a refresher, consider the following unusual but legal Python pro-\\ngram:\\n\\nclass X: pass                       # Make a few attribute namespaces\\nclass Y: pass\\n\\nX.a = 1                             # Use class attributes as variables\\nX.b = 2                             # No instances anywhere to be found\\nX.c = 3\\nY.a = X.a + X.b + X.c\\n\\nfor X.i in range(Y.a): print(X.i)   # Prints 0..5\\n\\nHere, the classes X and Y work like “fileless” modules—namespaces for storing variables\\nwe don’t want to clash. This is a perfectly legal Python programming trick, but it’s less\\nappropriate when applied to classes written by others; you can’t always be sure that\\nclass attributes you change aren’t critical to the class’s internal behavior. If you’re out\\nto simulate a C struct, you may be better off changing instances than classes, as that\\nway only one object is affected:\\n\\nclass Record: pass\\nX = Record()\\nX.name = \\'bob\\'\\nX.job  = \\'Pizza maker\\'\\n\\nChanging Mutable Class Attributes Can Have Side Effects, Too\\nThis gotcha is really an extension of the prior. Because class attributes are shared by all\\ninstances, if a class attribute references a mutable object, changing that object in place\\nfrom any instance impacts all instances at once:\\n\\nClass Gotchas\\n\\n| 1065\\n\\n\\x0c>>> class C:\\n        shared = []                 # Class attribute\\n        def __init__(self):\\n            self.perobj = []        # Instance attribute\\n\\n>>> x = C()                         # Two instances\\n>>> y = C()                         # Implicitly share class attrs\\n>>> y.shared, y.perobj\\n([], [])\\n\\n>>> x.shared.append(\\'spam\\')         # Impacts y\\'s view too!\\n>>> x.perobj.append(\\'spam\\')         # Impacts x\\'s data only\\n>>> x.shared, x.perobj\\n([\\'spam\\'], [\\'spam\\'])\\n\\n>>> y.shared, y.perobj              # y sees change made through x\\n([\\'spam\\'], [])\\n>>> C.shared                        # Stored on class and shared\\n[\\'spam\\']\\n\\nThis effect is no different than many we’ve seen in this book already: mutable objects\\nare shared by simple variables, globals are shared by functions, module-level objects\\nare shared by multiple importers, and mutable function arguments are shared by the\\ncaller and the callee. All of these are cases of general behavior—multiple references to\\na mutable object—and all are impacted if the shared object is changed in place from\\nany reference. Here, this occurs in class attributes shared by all instances via inheri-\\ntance, but it’s the same phenomenon at work. It may be made more subtle by the\\ndifferent behavior of assignments to instance attributes themselves:\\nx.shared.append(\\'spam\\')    # Changes shared object attached to class in place\\nx.shared = \\'spam\\'          # Changed or creates instance attribute attached to x\\n\\nBut again, this is not a problem, it’s just something to be aware of; shared mutable class\\nattributes can have many valid uses in Python programs.\\n\\nMultiple Inheritance: Order Matters\\nThis may be obvious by now, but it’s worth underscoring: if you use multiple inheri-\\ntance, the order in which superclasses are listed in the class statement header can be\\ncritical. Python always searches superclasses from left to right, according to their order\\nin the header line.\\nFor instance, in the multiple inheritance example we studied in Chapter 31, suppose\\nthat the Super class implemented a __str__ method, too:\\n\\nclass ListTree:\\n    def __str__(self): ...\\n\\nclass Super:\\n    def __str__(self): ...\\n\\nclass Sub(ListTree, Super):    # Get ListTree\\'s __str__ by listing it first\\n\\n1066 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cx = Sub()                      # Inheritance searches ListTree before Super\\n\\nWhich class would we inherit it from—ListTree or Super? As inheritance searches pro-\\nceed from left to right, we would get the method from whichever class is listed first\\n(leftmost) in Sub’s class header. Presumably, we would list ListTree first because its\\nwhole purpose is its custom __str__ (indeed, we had to do this in Chapter 31 when\\nmixing this class with a tkinter.Button that had a __str__ of its own).\\nBut now suppose Super and ListTree have their own versions of other same-named\\nattributes, too. If we want one name from Super and another from ListTree, the order\\nin which we list them in the class header won’t help—we will have to override inher-\\nitance by manually assigning to the attribute name in the Sub class:\\n\\nclass ListTree:\\n    def __str__(self): ...\\n    def other(self): ...\\n\\nclass Super:\\n    def __str__(self): ...\\n    def other(self): ...\\n\\nclass Sub(ListTree, Super):    # Get ListTree\\'s __str__ by listing it first\\n    other = Super.other        # But explicitly pick Super\\'s version of other\\n    def __init__(self):\\n        ...\\n\\nx = Sub()                      # Inheritance searches Sub before ListTree/Super\\n\\nHere, the assignment to other within the Sub class creates Sub.other—a reference back\\nto the Super.other object. Because it is lower in the tree, Sub.other effectively hides\\nListTree.other, the attribute that the inheritance search would normally find. Simi-\\nlarly, if we listed Super first in the class header to pick up its other, we would need to\\nselect ListTree’s method explicitly:\\n\\nclass Sub(Super, ListTree):               # Get Super\\'s other by order\\n    __str__ = Lister.__str__              # Explicitly pick Lister.__str__\\n\\nMultiple inheritance is an advanced tool. Even if you understood the last paragraph,\\nit’s still a good idea to use it sparingly and carefully. Otherwise, the meaning of a name\\nmay  come  to  depend  on  the  order  in  which  classes  are  mixed  in  an  arbitrarily  far-\\nremoved subclass. (For another example of the technique shown here in action, see the\\ndiscussion of explicit conflict resolution in “The ‘New-Style’ Class Model”, as well as\\nthe earlier super coverage.)\\nAs a rule of thumb, multiple inheritance works best when your mix-in classes are as\\nself-contained as possible—because they may be used in a variety of contexts, they\\nshould not make assumptions about names related to other classes in a tree. The pseu-\\ndoprivate __X attributes feature we studied in Chapter 31 can help by localizing names\\nthat a class relies on owning and limiting the names that your mix-in classes add to the\\nmix.  In  this  example,  for  instance,  if  ListTree  only  means  to  export  its  custom\\n\\nClass Gotchas\\n\\n| 1067\\n\\n\\x0c__str__, it can name its other method __other to avoid clashing with like-named classes\\nin the tree.\\n\\nScopes in Methods and Classes\\nWhen working out the meaning of names in class-based code, it helps to remember\\nthat classes introduce local scopes, just as functions do, and methods are simply further\\nnested functions. In the following example, the generate function returns an instance\\nof the nested Spam class. Within its code, the class name Spam is assigned in the gener\\nate function’s local scope, and hence is visible to any further nested functions, including\\ncode inside method; it’s the E in the “LEGB” scope lookup rule:\\n\\ndef generate():\\n    class Spam:                  # Spam is a name in generate\\'s local scope\\n        count = 1\\n        def method(self):\\n            print(Spam.count)    # Visible in generate\\'s scope, per LEGB rule (E)\\n    return Spam()\\n\\ngenerate().method()\\n\\nThis example works in Python since version 2.2 because the local scopes of all enclosing\\nfunction defs are automatically visible to nested defs (including nested method defs,\\nas in this example).\\nEven so, keep in mind that method defs cannot see the local scope of the enclosing\\nclass; they can see only the local scopes of enclosing defs. That’s why methods must\\ngo through the self instance or the class name to reference methods and other attributes\\ndefined in the enclosing class statement. For example, code in the method must use\\nself.count or Spam.count, not just count.\\nTo avoid nesting, we could restructure this code such that the class Spam is defined at\\nthe top level of the module: the nested method function and the top-level generate will\\nthen both find Spam in their global scopes; it’s not localized to a function’s scope, but\\nis still local to a single module:\\n\\ndef generate():\\n    return Spam()\\n\\nclass Spam:                    # Define at top level of module\\n    count = 1\\n    def method(self):\\n        print(Spam.count)      # Works: in global (enclosing module)\\n\\ngenerate().method()\\n\\nIn fact, this approach is recommended for all Python releases—code tends to be simpler\\nin general if you avoid nesting classes and functions. On the other hand, class nesting\\nis useful in closure contexts, where the enclosing function’s scope retains state used by\\nthe class or its methods. In the following, the nested method has access to its own scope,\\n\\n1068 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cthe enclosing function’s scope (for label), the enclosing module’s global scope, any-\\nthing saved in the self instance by the class, and the class itself via its nonlocal name:\\n\\n>>> def generate(label):       # Returns a class instead of an instance\\n        class Spam:\\n            count = 1\\n            def method(self):\\n                print(\"%s=%s\" % (label, Spam.count))\\n        return Spam\\n\\n>>> aclass = generate(\\'Gotchas\\')\\n>>> I = aclass()\\n>>> I.method()\\nGotchas=1\\n\\nMiscellaneous Class Gotchas\\nHere’s a handful of additional class-related warnings, mostly as review.\\n\\nChoose per-instance or class storage wisely\\nOn a similar note, be careful when you decide whether an attribute should be stored\\non a class or its instances: the former is shared by all instances, and the latter will differ\\nper  instance.  This  can  be  a  crucial  design  issue  in  practice.  In  a  GUI  program,  for\\ninstance, if you want information to be shared by all of the window class objects your\\napplication will create (e.g., the last directory used for a Save operation, or an already\\nentered password), it must be stored as class-level data; if stored in the instance as\\nself attributes, it will vary per window or be missing entirely when looked up by in-\\nheritance.\\n\\nYou usually want to call superclass constructors\\nRemember that Python runs only one __init__ constructor method when an instance\\nis made—the lowest in the class inheritance tree. It does not automatically run the\\nconstructors of all superclasses higher up. Because constructors normally perform re-\\nquired startup work, you’ll usually need to run a superclass constructor from a subclass\\nconstructor—using a manual call through the superclass’s name (or super), passing\\nalong whatever arguments are required—unless you mean to replace the super’s con-\\nstructor altogether, or the superclass doesn’t have or inherit a constructor at all.\\n\\nDelegation-based classes in 3.X: __getattr__ and built-ins\\nAnother reminder: as described earlier in this chapter and elsewhere, classes that use\\nthe __getattr__ operator overloading method to delegate attribute fetches to wrapped\\nobjects may fail in Python 3.X (and 2.X when new-style classes are used) unless operator\\noverloading methods are redefined in the wrapper class. The names of operator over-\\nloading  methods  implicitly  fetched  by  built-in  operations  are  not  routed  through\\ngeneric attribute-interception methods. To work around this, you must redefine such\\n\\nClass Gotchas\\n\\n| 1069\\n\\n\\x0cmethods  in  wrapper  classes,  either  manually,  with  tools,  or  by  definition  in  super-\\nclasses; we’ll see how in Chapter 40.\\n\\nKISS Revisited: “Overwrapping-itis”\\nWhen used well, the code reuse features of OOP make it excel at cutting development\\ntime. Sometimes, though, OOP’s abstraction potential can be abused to the point of\\nmaking code difficult to understand. If classes are layered too deeply, code can become\\nobscure; you may have to search through many classes to discover what an operation\\ndoes.\\nFor example, I once worked in a C++ shop with thousands of classes (some machine-\\ngenerated),  and  up  to  15  levels  of  inheritance.  Deciphering  method  calls  in  such  a\\ncomplex system was often a monumental task: multiple classes had to be consulted for\\neven the most basic of operations. In fact, the logic of the system was so deeply wrapped\\nthat understanding a piece of code in some cases required days of wading through\\nrelated files. This obviously isn’t ideal for programmer productivity!\\nThe most general rule of thumb of Python programming applies here, too: don’t make\\nthings complicated unless they truly must be. Wrapping your code in multiple layers of\\nclasses to the point of incomprehensibility is always a bad idea. Abstraction is the basis\\nof polymorphism and encapsulation, and it can be a very effective tool when used well.\\nHowever, you’ll simplify debugging and aid maintainability if you make your class\\ninterfaces intuitive, avoid making your code overly abstract, and keep your class hier-\\narchies short and flat unless there is a good reason to do otherwise. Remember: code\\nyou write is generally code that others must read. See Chapter 20 for more on KISS.\\n\\nChapter Summary\\nThis chapter presented an assortment of advanced class-related topics, including sub-\\nclassing built-in types, new-style classes, static methods, and decorators. Most of these\\nare optional extensions to the OOP model in Python, but they may become more useful\\nas you start writing larger object-oriented programs, and are fair game if they appear\\nin code you must understand. As mentioned earlier, our discussion of some of the more\\nadvanced class tools continues in the final part of this book; be sure to look ahead if\\nyou need more details on properties, descriptors, decorators, and metaclasses.\\nThis is the end of the class part of this book, so you’ll find the usual lab exercises at the\\nend of the chapter: be sure to work through them to get some practice coding real\\nclasses. In the next chapter, we’ll begin our look at our last core language topic, ex-\\nceptions—Python’s mechanism for communicating errors and other conditions to your\\ncode. This is a relatively lightweight topic, but I’ve saved it for last because new ex-\\nceptions are supposed to be coded as classes today. Before we tackle that final core\\nsubject, though, take a look at this chapter’s quiz and the lab exercises.\\n\\n1070 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cTest Your Knowledge: Quiz\\n1. Name two ways to extend a built-in object type.\\n2. What are function and class decorators used for?\\n3. How do you code a new-style class?\\n4. How are new-style and classic classes different?\\n5. How are normal and static methods different?\\n6. Are tools like __slots__ and super valid to use in your code?\\n7. How long should you wait before lobbing a “Holy Hand Grenade”?\\n\\nTest Your Knowledge: Answers\\n1. You can embed a built-in object in a wrapper class, or subclass the built-in type\\ndirectly. The latter approach tends to be simpler, as most original behavior is au-\\ntomatically inherited.\\n\\n2. Function decorators are generally used to manage a function or method, or add to\\nit a layer of logic that is run each time the function or method is called. They can\\nbe used to log or count calls to a function, check its argument types, and so on.\\nThey are also used to “declare” static methods (simple functions in a class that are\\nnot passed an instance when called), as well as class methods and properties. Class\\ndecorators are similar, but manage whole objects and their interfaces instead of a\\nfunction call.\\n\\n3. New-style classes are coded by inheriting from the object built-in class (or any\\nother built-in type). In Python 3.X, all classes are new-style automatically, so this\\nderivation is not required (but doesn’t hurt); in 2.X, classes with this explicit der-\\nivation are new-style and those without it are “classic.”\\n\\n4. New-style classes search the diamond pattern of multiple inheritance trees differ-\\nently—they essentially search breadth-first (across), instead of depth-first (up) in\\ndiamond trees. New-style classes also change the result of the  type built-in for\\ninstances and classes, do not run generic attribute fetch methods such as __get\\nattr__ for built-in operation methods, and support a set of advanced extra tools\\nincluding properties, descriptors, super, and __slots__ instance attribute lists.\\n\\n5. Normal (instance) methods receive a self argument (the implied instance), but\\nstatic methods do not. Static methods are simple functions nested in class objects.\\nTo make a method static, it must either be run through a special built-in function\\nor be decorated with decorator syntax. Python 3.X allows simple functions in a\\nclass to be called through the class without this step, but calls through instances\\nstill require static method declaration.\\n\\n6. Of course, but you shouldn’t use advanced tools automatically without carefully\\nconsidering their implications. Slots, for example, can break code; super can mask\\n\\nTest Your Knowledge: Answers\\n\\n| 1071\\n\\n\\x0clater problems when used for single inheritance, and in multiple inheritance brings\\nwith it substantial complexity for an isolated use case; and both require universal\\ndeployment to be most useful. Evaluating new or advanced tools is a primary task\\nof any engineer, and is why we explored tradeoffs so carefully in this chapter. This\\nbook’s goal is not to tell you which tools to use, but to underscore the importance\\nof objectively analyzing them—a task often given too low a priority in the software\\nfield.\\n\\n7. Three seconds. (Or, more accurately: “And the Lord spake, saying, ‘First shalt thou\\ntake out the Holy Pin. Then, shalt thou count to three, no more, no less. Three\\nshalt be the number thou shalt count, and the number of the counting shall be\\nthree. Four shalt thou not count, nor either count thou two, excepting that thou\\nthen proceed to three. Five is right out. Once the number three, being the third\\nnumber, be reached, then lobbest thou thy Holy Hand Grenade of Antioch towards\\nthy foe, who, being naughty in my sight, shall snuff it.’”)4\\n\\nTest Your Knowledge: Part VI Exercises\\nThese exercises ask you to write a few classes and experiment with some existing code.\\nOf course, the problem with existing code is that it must be existing. To work with the\\nset class in exercise 5, either pull the class source code off this book’s website (see the\\npreface for a pointer) or type it up by hand (it’s fairly brief). These programs are starting\\nto get more sophisticated, so be sure to check the solutions at the end of the book for\\npointers. You’ll find them in Appendix D, under Part VI.\\n\\n1. Inheritance. Write a class called Adder that exports a method add(self, x, y) that\\nprints a “Not Implemented” message. Then, define two subclasses of Adder that\\nimplement the add method:\\nListAdder\\n\\nWith an add method that returns the concatenation of its two list arguments\\n\\nDictAdder\\n\\nWith an add method that returns a new dictionary containing the items in both\\nits two dictionary arguments (any definition of dictionary addition will do)\\n\\nExperiment by making instances of all three of your classes interactively and calling\\ntheir add methods.\\nNow, extend your Adder superclass to save an object in the instance with a con-\\nstructor (e.g., assign self.data a list or a dictionary), and overload the + operator\\nwith an __add__ method to automatically dispatch to your add methods (e.g., X +\\nY triggers X.add(X.data,Y)). Where is the best place to put the constructors and\\n\\n4. This quote is from Monty Python and the Holy Grail (and if you didn’t know that, it may be time to find\\n\\na copy!).\\n\\n1072 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0coperator overloading methods (i.e., in which classes)? What sorts of objects can\\nyou add to your class instances?\\nIn practice, you might find it easier to code your add methods to accept just one\\nreal argument (e.g.,  add(self,y)), and add that one argument to the instance’s\\ncurrent data (e.g., self.data + y). Does this make more sense than passing two\\narguments to add? Would you say this makes your classes more “object-oriented”?\\n2. Operator overloading. Write a class called MyList that shadows (“wraps”) a Python\\nlist: it should overload most list operators and operations, including +, indexing,\\niteration, slicing, and list methods such as append and sort. See the Python reference\\nmanual or other documentation for a list of all possible methods to support. Also,\\nprovide a constructor for your class that takes an existing list (or a MyList instance)\\nand copies its components into an instance attribute. Experiment with your class\\ninteractively. Things to explore:\\n\\na. Why is copying the initial value important here?\\nb. Can you use an empty slice (e.g., start[:]) to copy the initial value if it’s a\\n\\nMyList instance?\\n\\nc. Is there a general way to route list method calls to the wrapped list?\\nd. Can you add a MyList and a regular list? How about a list and a MyList instance?\\ne. What type of object should operations like + and slicing return? What about\\n\\nindexing operations?\\n\\nf. If you are working with a reasonably recent Python release (version 2.2 or\\nlater), you may implement this sort of wrapper class by embedding a real list\\nin a standalone class, or by extending the built-in list type with a subclass.\\nWhich is easier, and why?\\n\\n3. Subclassing. Make a subclass of MyList from exercise 2 called MyListSub, which\\nextends MyList to print a message to stdout before each call to the + overloaded\\noperation  and  counts  the  number  of  such  calls.  MyListSub  should  inherit  basic\\nmethod behavior from MyList. Adding a sequence to a MyListSub should print a\\nmessage, increment the counter for + calls, and perform the superclass’s method.\\nAlso, introduce a new method that prints the operation counters to stdout, and\\nexperiment with your class interactively. Do your counters count calls per instance,\\nor per class (for all instances of the class)? How would you program the other\\noption? (Hint: it depends on which object the count members are assigned to: class\\nmembers are shared by instances, but self members are per-instance data.)\\n\\n4. Attribute methods. Write a class called Attrs with methods that intercept every\\nattribute qualification (both fetches and assignments), and print messages listing\\ntheir arguments to stdout. Create an Attrs instance, and experiment with quali-\\nfying it interactively. What happens when you try to use the instance in expres-\\nsions? Try adding, indexing, and slicing the instance of your class. (Note: a fully\\ngeneric approach based upon __getattr__ will work in 2.X’s classic classes but not\\nin 3.X’s new-style classes—which are optional in 2.X—for reasons noted in Chap-\\n\\nTest Your Knowledge: Part VI Exercises\\n\\n| 1073\\n\\n\\x0cter 28, Chapter 31, and Chapter 32, and summarized in the solution to this exer-\\ncise.)\\n\\n5. Set objects. Experiment with the set class described in “Extending Types by Em-\\n\\nbedding”. Run commands to do the following sorts of operations:\\n\\na. Create two sets of integers, and compute their intersection and union by using\\n\\n& and | operator expressions.\\n\\nb. Create  a  set  from  a  string,  and  experiment  with  indexing  your  set.  Which\\n\\nmethods in the class are called?\\n\\nc. Try  iterating  through  the  items  in  your  string  set  using  a  for  loop.  Which\\n\\nmethods run this time?\\n\\nd. Try  computing  the  intersection  and  union  of  your  string  set  and  a  simple\\n\\nPython string. Does it work?\\n\\ne. Now, extend your set by subclassing to handle arbitrarily many operands using\\nthe *args argument form. (Hint: see the function versions of these algorithms\\nin Chapter 18.) Compute intersections and unions of multiple operands with\\nyour set subclass. How can you intersect three or more sets, given that & has\\nonly two sides?\\n\\nf. How would you go about emulating other list operations in the set class? (Hint:\\n__add__ can catch concatenation, and __getattr__ can pass most named list\\nmethod calls like append to the wrapped list.)\\n\\n6. Class tree links. In “Namespaces: The Whole Story” in Chapter 29 and in “Multiple\\nInheritance:  ‘Mix-in’  Classes”  in  Chapter  31,  we  learned  that  classes  have  a\\n__bases__ attribute that returns a tuple of their superclass objects (the ones listed\\nin parentheses in the class header). Use __bases__ to extend the lister.py mix-in\\nclasses  we  wrote  in  Chapter  31  so  that  they  print  the  names  of  the  immediate\\nsuperclasses of the instance’s class. When you’re done, the first line of the string\\nrepresentation should look like this (your address will almost certainly vary):\\n\\n<Instance of Sub(Super, Lister), address 7841200:\\n\\n7. Composition. Simulate a fast-food ordering scenario by defining four classes:\\n\\nLunch\\n\\nA container and controller class\\n\\nCustomer\\n\\nThe actor who buys food\\n\\nEmployee\\n\\nThe actor from whom a customer orders\\n\\nFood\\n\\nWhat the customer buys\\n\\nTo get you started, here are the classes and methods you’ll be defining:\\n\\nclass Lunch:\\n    def __init__(self)               # Make/embed Customer and Employee\\n\\n1074 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0c    def order(self, foodName)        # Start a Customer order simulation\\n    def result(self)                 # Ask the Customer what Food it has\\n\\nclass Customer:\\n    def __init__(self)                        # Initialize my food to None\\n    def placeOrder(self, foodName, employee)  # Place order with an Employee\\n    def printFood(self)                       # Print the name of my food\\n\\nclass Employee:\\n    def takeOrder(self, foodName)    # Return a Food, with requested name\\n\\nclass Food:\\n    def __init__(self, name)         # Store food name\\n\\nThe order simulation should work as follows:\\n\\na. The  Lunch  class’s  constructor  should  make  and  embed  an  instance  of  Cus\\ntomer  and  an  instance  of  Employee,  and  it  should  export  a  method  called\\norder. When called, this order method should ask the Customer to place an\\norder  by  calling  its  placeOrder  method.  The  Customer’s  placeOrder  method\\nshould  in  turn  ask  the  Employee  object  for  a  new  Food  object  by  calling\\nEmployee’s takeOrder method.\\n\\nb. Food objects should store a food name string (e.g., “burritos”), passed down\\nfrom Lunch.order, to Customer.placeOrder, to Employee.takeOrder, and finally\\nto Food’s constructor. The top-level Lunch class should also export a method\\ncalled result, which asks the customer to print the name of the food it received\\nfrom the Employee via the order (this can be used to test your simulation).\\n\\nNote that Lunch needs to pass either the Employee or itself to the Customer to allow\\nthe Customer to call Employee methods.\\nExperiment with your classes interactively by importing the Lunch class, calling its\\norder method to run an interaction, and then calling its result method to verify\\nthat the Customer got what he or she ordered. If you prefer, you can also simply\\ncode test cases as self-test code in the file where your classes are defined, using the\\nmodule __name__ trick of Chapter 25. In this simulation, the Customer is the active\\nagent; how would your classes change if Employee were the object that initiated\\ncustomer/employee interaction instead?\\n\\n8. Zoo animal hierarchy. Consider the class tree shown in Figure 32-1.\\n\\nCode a set of six class statements to model this taxonomy with Python inheri-\\ntance. Then, add a speak method to each of your classes that prints a unique mes-\\nsage,  and  a  reply  method  in  your  top-level  Animal  superclass  that  simply  calls\\nself.speak to invoke the category-specific message printer in a subclass below (this\\nwill kick off an independent inheritance search from self). Finally, remove the\\nspeak method from your Hacker class so that it picks up the default above it. When\\nyou’re finished, your classes should work this way:\\n\\n% python\\n>>> from zoo import Cat, Hacker\\n\\nTest Your Knowledge: Part VI Exercises\\n\\n| 1075\\n\\n\\x0c>>> spot = Cat()\\n>>> spot.reply()                   # Animal.reply: calls Cat.speak\\nmeow\\n>>> data = Hacker()                # Animal.reply: calls Primate.speak\\n>>> data.reply()\\nHello world!\\n\\nFigure 32-1. A zoo hierarchy composed of classes linked into a tree to be searched by attribute\\ninheritance. Animal has a common “reply” method, but each class may have its own custom\\n“speak” method called by “reply”.\\n\\n9. The  Dead  Parrot  Sketch.  Consider  the  object  embedding  structure  captured  in\\n\\nFigure 32-2.\\nCode a set of Python classes to implement this structure with composition. Code\\nyour  Scene object to define an  action method, and embed instances of the  Cus\\ntomer, Clerk, and Parrot classes (each of which should define a line method that\\nprints a unique message). The embedded objects may either inherit from a common\\nsuperclass that defines line and simply provide message text, or define line them-\\nselves. In the end, your classes should operate like this:\\n\\n% python\\n>>> import parrot\\n>>> parrot.Scene().action()        # Activate nested objects\\ncustomer: \"that\\'s one ex-bird!\"\\nclerk: \"no it isn\\'t...\"\\nparrot: None\\n\\n1076 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cFigure 32-2. A scene composite with a controller class (Scene) that embeds and directs instances of\\nthree other classes (Customer, Clerk, Parrot). The embedded instance’s classes may also participate\\nin an inheritance hierarchy; composition and inheritance are often equally useful ways to structure\\nclasses for code reuse.\\n\\nWhy You Will Care: OOP by the Masters\\n\\nWhen I teach Python classes, I invariably find that about halfway through the class,\\npeople who have used OOP in the past are following along intensely, while people who\\nhave not are beginning to glaze over (or nod off completely). The point behind the\\ntechnology just isn’t apparent.\\n\\nIn a book like this, I have the luxury of including material like the new Big Picture\\noverview in Chapter 26, and the gradual tutorial of Chapter 28—in fact, you should\\nprobably review that section if you’re starting to feel like OOP is just some computer\\nscience mumbo-jumbo. Though it adds much more structure than the generators we\\nmet earlier, OOP similarly relies on some magic (inheritance search and a special first\\nargument) that beginners can find difficult to rationalize.\\n\\nIn real classes, however, to help get the newcomers on board (and keep them awake),\\nI have been known to stop and ask the experts in the audience why they use OOP. The\\nanswers they’ve given might help shed some light on the purpose of OOP, if you’re new\\nto the subject.\\n\\nHere, then, with only a few embellishments, are the most common reasons to use OOP,\\nas cited by my students over the years:\\n\\nCode reuse\\n\\nThis one’s easy (and is the main reason for using OOP). By supporting inheritance,\\nclasses allow you to program by customization instead of starting each project from\\nscratch.\\n\\nEncapsulation\\n\\nWrapping up implementation details behind object interfaces insulates users of a\\nclass from code changes.\\n\\nStructure\\n\\nClasses provide new local scopes, which minimizes name clashes. They also pro-\\nvide a natural place to write and look for implementation code, and to manage\\nobject state.\\n\\nTest Your Knowledge: Part VI Exercises\\n\\n| 1077\\n\\n\\x0cMaintenance\\n\\nClasses  naturally  promote  code  factoring,  which  allows  us  to  minimize  redun-\\ndancy. Thanks both to the structure and code reuse support of classes, usually only\\none copy of the code needs to be changed.\\n\\nConsistency\\n\\nClasses and inheritance allow you to implement common interfaces, and hence\\ncreate a common look and feel in your code; this eases debugging, comprehension,\\nand maintenance.\\n\\nPolymorphism\\n\\nThis is more a property of OOP than a reason for using it, but by supporting code\\ngenerality, polymorphism makes code more flexible and widely applicable, and\\nhence more reusable.\\n\\nOther\\n\\nAnd, of course, the number one reason students gave for using OOP: it looks good\\non a résumé! (OK, I threw this one in as a joke, but it is important to be familiar\\nwith OOP if you plan to work in the software field today.)\\n\\nFinally, keep in mind what I said at the beginning of this part of the book: you won’t\\nfully appreciate OOP until you’ve used it for a while. Pick a project, study larger ex-\\namples, work through the exercises—do whatever it takes to get your feet wet with OO\\ncode; it’s worth the effort.\\n\\n1078 | Chapter 32:\\u2002Advanced Class Topics\\n\\n\\x0cPART VII\\nExceptions and Tools\\n\\n\\x0c\\x0cCHAPTER 33\\nException Basics\\n\\nThis part of the book deals with exceptions, which are events that can modify the flow\\nof control through a program. In Python, exceptions are triggered automatically on\\nerrors, and they can be triggered and intercepted by your code. They are processed by\\nfour statements we’ll study in this part, the first of which has two variations (listed\\nseparately here) and the last of which was an optional extension until Python 2.6 and\\n3.0:\\n\\ntry/except\\n\\nCatch and recover from exceptions raised by Python, or by you.\\n\\ntry/finally\\n\\nPerform cleanup actions, whether exceptions occur or not.\\n\\nraise\\n\\nTrigger an exception manually in your code.\\n\\nassert\\n\\nConditionally trigger an exception in your code.\\n\\nwith/as\\n\\nImplement context managers in Python 2.6, 3.0, and later (optional in 2.5).\\n\\nThis topic was saved until nearly the end of the book because you need to know about\\nclasses to code exceptions of your own. With a few exceptions (pun intended), though,\\nyou’ll find that exception handling is simple in Python because it’s integrated into the\\nlanguage itself as another high-level tool.\\n\\nWhy Use Exceptions?\\nIn a nutshell, exceptions let us jump out of arbitrarily large chunks of a program. Con-\\nsider the hypothetical pizza-making robot we discussed earlier in the book. Suppose\\nwe took the idea seriously and actually built such a machine. To make a pizza, our\\nculinary automaton would need to execute a plan, which we would implement as a\\n\\n1081\\n\\n\\x0cPython program: it would take an order, prepare the dough, add toppings, bake the\\npie, and so on.\\nNow, suppose that something goes very wrong during the “bake the pie” step. Perhaps\\nthe oven is broken, or perhaps our robot miscalculates its reach and spontaneously\\ncombusts. Clearly, we want to be able to jump to code that handles such states quickly.\\nAs we have no hope of finishing the pizza task in such unusual cases, we might as well\\nabandon the entire plan.\\nThat’s exactly what exceptions let you do: you can jump to an exception handler in a\\nsingle step, abandoning all function calls begun since the exception handler was en-\\ntered. Code in the exception handler can then respond to the raised exception as ap-\\npropriate (by calling the fire department, for instance!).\\nOne way to think of an exception is as a sort of structured “super go to.” An exception\\nhandler (try statement) leaves a marker and executes some code. Somewhere further\\nahead in the program, an exception is raised that makes Python jump back to that\\nmarker, abandoning any active functions that were called after the marker was left.\\nThis protocol provides a coherent way to respond to unusual events. Moreover, because\\nPython jumps to the handler statement immediately, your code is simpler—there is\\nusually no need to check status codes after every call to a function that could possibly\\nfail.\\n\\nException Roles\\nIn Python programs, exceptions are typically used for a variety of purposes. Here are\\nsome of their most common roles:\\n\\nError handling\\n\\nPython raises exceptions whenever it detects errors in programs at runtime. You\\ncan catch and respond to the errors in your code, or ignore the exceptions that are\\nraised. If an error is ignored, Python’s default exception-handling behavior kicks\\nin: it stops the program and prints an error message. If you don’t want this default\\nbehavior, code a try statement to catch and recover from the exception—Python\\nwill jump to your try handler when the error is detected, and your program will\\nresume execution after the try.\\n\\nEvent notification\\n\\nExceptions can also be used to signal valid conditions without you having to pass\\nresult flags around a program or test them explicitly. For instance, a search routine\\nmight raise an exception on failure, rather than returning an integer result code—\\nand hoping that the code will never be a valid result!\\n\\nSpecial-case handling\\n\\nSometimes a condition may occur so rarely that it’s hard to justify convoluting your\\ncode to handle it in multiple places. You can often eliminate special-case code by\\nhandling unusual cases in exception handlers in higher levels of your program. An\\n\\n1082 | Chapter 33:\\u2002Exception Basics\\n\\n\\x0cassert can similarly be used to check that conditions are as expected during de-\\nvelopment.\\n\\nTermination actions\\n\\nAs  you’ll  see,  the  try/finally  statement  allows  you  to  guarantee  that  required\\nclosing-time operations will be performed, regardless of the presence or absence\\nof exceptions in your programs. The newer with statement offers an alternative in\\nthis department for objects that support it.\\n\\nUnusual control flows\\n\\nFinally, because exceptions are a sort of high-level and structured “go to,” you can\\nuse them as the basis for implementing exotic control flows. For instance, although\\nthe language does not explicitly support backtracking, you can implement it in\\nPython by using exceptions and a bit of support logic to unwind assignments.1\\nThere is no “go to” statement in Python (thankfully!), but exceptions can some-\\ntimes serve similar roles; a raise, for instance, can be used to jump out of multiple\\nloops.\\n\\nWe saw some of these roles briefly earlier, and will study typical exception use cases\\nin action later in this part of the book. For now, let’s get started with a look at Python’s\\nexception-processing tools.\\n\\nExceptions: The Short Story\\nCompared to some other core language topics we’ve met in this book, exceptions are\\na fairly lightweight tool in Python. Because they are so simple, let’s jump right into\\nsome code.\\n\\nDefault Exception Handler\\nSuppose we write the following function:\\n\\n>>> def fetcher(obj, index):\\n        return obj[index]\\n\\nThere’s not much to this function—it simply indexes an object on a passed-in index.\\nIn normal operation, it returns the result of a legal index:\\n\\n>>> x = \\'spam\\'\\n>>> fetcher(x, 3)                           # Like x[3]\\n\\'m\\'\\n\\n1. But true backtracking is not part of the Python language. Backtracking undoes all computations before\\nit jumps, but Python exceptions do not: variables assigned between the time a try statement is entered\\nand the time an exception is raised are not reset to their prior values. Even the generator functions and\\nexpressions we met in Chapter 20 don’t do full backtracking—they simply respond to next(G) requests\\nby restoring state and resuming. For more on backtracking, see books on artificial intelligence or the\\nProlog or Icon programming languages.\\n\\nExceptions: The Short Story | 1083\\n\\n\\x0cHowever, if we ask this function to index off the end of the string, an exception will be\\ntriggered when the function tries to run obj[index]. Python detects out-of-bounds in-\\ndexing for sequences and reports it by raising (triggering) the built-in IndexError ex-\\nception:\\n\\n>>> fetcher(x, 4)                           # Default handler - shell interface\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<stdin>\", line 2, in fetcher\\nIndexError: string index out of range\\n\\nBecause our code does not explicitly catch this exception, it filters back up to the top\\nlevel of the program and invokes the default exception handler, which simply prints the\\nstandard error message. By this point in the book, you’ve probably seen your share of\\nstandard error messages. They include the exception that was raised, along with a stack\\ntrace—a list of all the lines and functions that were active when the exception occurred.\\nThe error message text here was printed by Python 3.3; it can vary slightly per release,\\nand even per interactive shell, so you shouldn’t rely upon its exact form—in either this\\nbook or your code. When you’re coding interactively in the basic shell interface, the\\nfilename is just “<stdin>,” meaning the standard input stream.\\nWhen working in the IDLE GUI’s interactive shell, the filename is “<pyshell>,” and\\nsource lines are displayed, too. Either way, file line numbers are not very meaningful\\nwhen there is no file (we’ll see more interesting error messages later in this part of the\\nbook):\\n\\n>>> fetcher(x, 4)                           # Default handler - IDLE GUI interface\\nTraceback (most recent call last):\\n  File \"<pyshell#6>\", line 1, in <module>\\n    fetcher(x, 4)\\n  File \"<pyshell#3>\", line 2, in fetcher\\n    return obj[index]\\nIndexError: string index out of range\\n\\nIn a more realistic program launched outside the interactive prompt, after printing an\\nerror message the default handler at the top also terminates the program immediately.\\nThat course of action makes sense for simple scripts; errors often should be fatal, and\\nthe best you can do when they occur is inspect the standard error message.\\n\\nCatching Exceptions\\nSometimes, this isn’t what you want, though. Server programs, for instance, typically\\nneed to remain active even after internal errors. If you don’t want the default exception\\nbehavior, wrap the call in a try statement to catch exceptions yourself:\\n\\n>>> try:\\n...     fetcher(x, 4)\\n... except IndexError:                      # Catch and recover\\n...     print(\\'got exception\\')\\n...\\n\\n1084 | Chapter 33:\\u2002Exception Basics\\n\\n\\x0cgot exception\\n>>>\\n\\nNow, Python jumps to your handler—the block under the except clause that names\\nthe exception raised—automatically when an exception is triggered while the try block\\nis running. The net effect is to wrap a nested block of code in an error handler that\\nintercepts the block’s exceptions.\\nWhen working interactively like this, after the except clause runs, we wind up back at\\nthe Python prompt. In a more realistic program, try statements not only catch excep-\\ntions, but also recover from them:\\n\\n>>> def catcher():\\n        try:\\n            fetcher(x, 4)\\n        except IndexError:\\n            print(\\'got exception\\')\\n        print(\\'continuing\\')\\n\\n>>> catcher()\\ngot exception\\ncontinuing\\n>>>\\n\\nThis time, after the exception is caught and handled, the program resumes execution\\nafter the entire try statement that caught it—which is why we get the “continuing”\\nmessage here. We don’t see the standard error message, and the program continues on\\nits way normally.\\nNotice that there’s no way in Python to go back to the code that triggered the exception\\n(short of rerunning the code that reached that point all over again, of course). Once\\nyou’ve  caught  the  exception,  control  continues  after  the  entire  try  that  caught  the\\nexception, not after the statement that kicked it off. In fact, Python clears the memory\\nof any functions that were exited as a result of the exception, like fetcher in our ex-\\nample; they’re not resumable. The try both catches exceptions, and is where the pro-\\ngram resumes.\\n\\nPresentation note: The interactive prompt’s “...” reappears in this part\\nfor some top-level try statements, because their code won’t work if cut\\nand pasted unless nested in a function or class (the except and other\\nlines must align with the try, and not have extra preceding spaces that\\nare needed to illustrate their indentation structure). To run, simply type\\nor paste statements with “...” prompts one line at a time.\\n\\nRaising Exceptions\\nSo far, we’ve been letting Python raise exceptions for us by making mistakes (on pur-\\npose this time!), but our scripts can raise exceptions too—that is, exceptions can be\\nraised by Python or by your program, and can be caught or not. To trigger an exception\\n\\nExceptions: The Short Story | 1085\\n\\n\\x0cmanually, simply run a raise statement. User-triggered exceptions are caught the same\\nway as those Python raises. The following may not be the most useful Python code ever\\npenned, but it makes the point—raising the built-in IndexError exception:\\n\\n>>> try:\\n...     raise IndexError                    # Trigger exception manually\\n... except IndexError:\\n...     print(\\'got exception\\')\\n...\\ngot exception\\n\\nAs usual, if they’re not caught, user-triggered exceptions are propagated up to the top-\\nlevel default exception handler and terminate the program with a standard error mes-\\nsage:\\n\\n>>> raise IndexError\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nIndexError\\n\\nAs we’ll see in the next chapter, the assert statement can be used to trigger exceptions,\\ntoo—it’s a conditional raise, used mostly for debugging purposes during development:\\n\\n>>> assert False, \\'Nobody expects the Spanish Inquisition!\\'\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nAssertionError: Nobody expects the Spanish Inquisition!\\n\\nUser-Defined Exceptions\\nThe raise statement introduced in the prior section raises a built-in exception defined\\nin Python’s built-in scope. As you’ll learn later in this part of the book, you can also\\ndefine new exceptions of your own that are specific to your programs. User-defined\\nexceptions are coded with classes, which inherit from a built-in exception class: usually\\nthe class named Exception:\\n\\n>>> class AlreadyGotOne(Exception): pass    # User-defined exception\\n\\n>>> def grail():\\n        raise AlreadyGotOne()               # Raise an instance\\n\\n>>> try:\\n...     grail()\\n... except AlreadyGotOne:                   # Catch class name\\n...     print(\\'got exception\\')\\n...\\ngot exception\\n>>>\\n\\nAs we’ll see in the next chapter, an as clause on an except can gain access to the ex-\\nception object itself. Class-based exceptions allow scripts to build exception categories,\\nwhich can inherit behavior, and have attached state information and methods. They\\ncan also customize their error message text displayed if they’re not caught:\\n\\n1086 | Chapter 33:\\u2002Exception Basics\\n\\n\\x0c>>> class Career(Exception):\\n        def __str__(self): return \\'So I became a waiter...\\'\\n\\n>>> raise Career()\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.Career: So I became a waiter...\\n>>>\\n\\nTermination Actions\\nFinally, try statements can say “finally”—that is, they may include finally blocks.\\nThese look like except handlers for exceptions, but the try/finally combination speci-\\nfies termination actions that always execute “on the way out,” regardless of whether\\nan exception occurs in the try block or not;\\n\\n>>> try:\\n...     fetcher(x, 3)\\n... finally:                                # Termination actions\\n...     print(\\'after fetch\\')\\n...\\n\\'m\\'\\nafter fetch\\n>>>\\n\\nHere, if the try block finishes without an exception, the finally block will run, and\\nthe program will resume after the entire try. In this case, this statement seems a bit silly\\n—we might as well have simply typed the print right after a call to the function, and\\nskipped the try altogether:\\n\\nfetcher(x, 3)\\nprint(\\'after fetch\\')\\n\\nThere is a problem with coding this way, though: if the function call raises an exception,\\nthe print will never be reached. The try/finally combination avoids this pitfall—when\\nan exception does occur in a try block, finally blocks are executed while the program\\nis being unwound:\\n>>> def after():\\n        try:\\n            fetcher(x, 4)\\n        finally:\\n            print(\\'after fetch\\')\\n        print(\\'after try?\\')\\n\\n>>> after()\\nafter fetch\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<stdin>\", line 3, in after\\n  File \"<stdin>\", line 2, in fetcher\\nIndexError: string index out of range\\n>>>\\n\\nExceptions: The Short Story | 1087\\n\\n\\x0cHere, we don’t get the “after try?” message because control does not resume after the\\ntry/finally block when an exception occurs. Instead, Python jumps back to run the\\nfinally action, and then propagates the exception up to a prior handler (in this case,\\nto the default handler at the top). If we change the call inside this function so as not to\\ntrigger an exception, the finally code still runs, but the program continues after the try:\\n\\n>>> def after():\\n        try:\\n            fetcher(x, 3)\\n        finally:\\n            print(\\'after fetch\\')\\n        print(\\'after try?\\')\\n\\n>>> after()\\nafter fetch\\nafter try?\\n>>>\\n\\nIn practice, try/except combinations are useful for catching and recovering from ex-\\nceptions, and try/finally combinations come in handy to guarantee that termination\\nactions will fire regardless of any exceptions that may occur in the try block’s code.\\nFor instance, you might use try/except to catch errors raised by code that you import\\nfrom a third-party library, and try/finally to ensure that calls to close files or terminate\\nserver connections are always run. We’ll see some such practical examples later in this\\npart of the book.\\nAlthough  they  serve  conceptually  distinct  purposes,  as  of  Python  2.5,  we  can  mix\\nexcept and finally clauses in the same try statement—the finally is run on the way\\nout regardless of whether an exception was raised, and regardless of whether the ex-\\nception was caught by an except clause.\\nAs we’ll learn in the next chapter, Python 2.X and 3.X both provide an alternative to\\ntry/finally when using some types of objects. The with/as statement runs an object’s\\ncontext management logic to guarantee that termination actions occur, irrespective of\\nany exceptions in its nested block:\\n\\n>>> with open(\\'lumberjack.txt\\', \\'w\\') as file:        # Always close file on exit\\n        file.write(\\'The larch!\\\\n\\')\\n\\nAlthough this option requires fewer lines of code, it’s applicable only when processing\\ncertain object types, so try/finally is a more general termination structure, and is often\\nsimpler than coding a class in cases where with is not already supported. On the other\\nhand,  with/as  may  also  run  startup  actions  too,  and  supports  user-defined  context\\nmanagement code with access to Python’s full OOP toolset.\\n\\nWhy You Will Care: Error Checks\\n\\nOne way to see how exceptions are useful is to compare coding styles in Python and\\nlanguages without exceptions. For instance, if you want to write robust programs in\\nthe C language, you generally have to test return values or status codes after every\\n\\n1088 | Chapter 33:\\u2002Exception Basics\\n\\n\\x0coperation that could possibly go astray, and propagate the results of the tests as your\\nprograms run:\\n\\ndoStuff()\\n{                                 # C program\\n    if (doFirstThing() == ERROR)  # Detect errors everywhere\\n        return ERROR;             # even if not handled here\\n    if (doNextThing() == ERROR)\\n        return ERROR;\\n    ...\\n    return doLastThing();\\n}\\n\\nmain()\\n{\\n    if (doStuff() == ERROR)\\n        badEnding();\\n    else\\n        goodEnding();\\n}\\n\\nIn fact, realistic C programs often have as much code devoted to error detection as to\\ndoing actual work. But in Python, you don’t have to be so methodical (and neurotic!).\\nYou can instead wrap arbitrarily vast pieces of a program in exception handlers and\\nsimply write the parts that do the actual work, assuming all is normally well:\\n\\ndef doStuff():        # Python code\\n    doFirstThing()    # We don\\'t care about exceptions here,\\n    doNextThing()     # so we don\\'t need to detect them\\n    ...\\n    doLastThing()\\n\\nif __name__ == \\'__main__\\':\\n    try:\\n        doStuff()     # This is where we care about results,\\n    except:           # so it\\'s the only place we must check\\n        badEnding()\\n    else:\\n        goodEnding()\\n\\nBecause control jumps immediately to a handler when an exception occurs, there’s no\\nneed to instrument all your code to guard for errors, and there’s no extra performance\\noverhead to run all the tests. Moreover, because Python detects errors automatically,\\nyour code often doesn’t need to check for errors in the first place. The upshot is that\\nexceptions let you largely ignore the unusual cases and avoid error-checking code that\\ncan distract from your program’s goals.\\n\\nChapter Summary\\nAnd that is the majority of the exception story; exceptions really are a simple tool.\\nTo summarize, Python exceptions are a high-level control flow device. They may be\\nraised by Python, or by your own programs. In both cases, they may be ignored (to\\ntrigger the default error message), or caught by try statements (to be processed by your\\n\\nChapter Summary | 1089\\n\\n\\x0ccode). The try statement comes in two logical formats that, as of Python 2.5, can be\\ncombined—one that handles exceptions, and one that executes finalization code re-\\ngardless of whether exceptions occur or not. Python’s  raise and assert statements\\ntrigger  exceptions  on  demand—both  built-ins  and  new  exceptions  we  define  with\\nclasses—and the with/as statement is an alternative way to ensure that termination\\nactions are carried out for objects that support it.\\nIn the rest of this part of the book, we’ll fill in some of the details about the statements\\ninvolved, examine the other sorts of clauses that can appear under a try, and discuss\\nclass-based exception objects. The next chapter begins our tour by taking a closer look\\nat the statements we introduced here. Before you turn the page, though, here are a few\\nquiz questions to review.\\n\\nTest Your Knowledge: Quiz\\n1. Name three things that exception processing is good for.\\n2. What happens to an exception if you don’t do anything special to handle it?\\n3. How can your script recover from an exception?\\n4. Name two ways to trigger exceptions in your script.\\n5. Name two ways to specify actions to be run at termination time, whether an ex-\\n\\nception occurs or not.\\n\\nTest Your Knowledge: Answers\\n1. Exception processing is useful for error handling, termination actions, and event\\nnotification. It can also simplify the handling of special cases and can be used to\\nimplement alternative control flows as a sort of structured “go to” operation. In\\ngeneral, exception processing also cuts down on the amount of error-checking code\\nyour program may require—because all errors filter up to handlers, you may not\\nneed to test the outcome of every operation.\\n\\n2. Any  uncaught  exception  eventually  filters  up  to  the  default  exception  handler\\nPython provides at the top of your program. This handler prints the familiar error\\nmessage and shuts down your program.\\n\\n3. If you don’t want the default message and shutdown, you can code try/except\\nstatements to catch and recover from exceptions that are raised within its nested\\ncode block. Once an exception is caught, the exception is terminated and your\\nprogram continues after the try.\\n\\n4. The raise and assert statements can be used to trigger an exception, exactly as if\\nit had been raised by Python itself. In principle, you can also raise an exception by\\nmaking a programming mistake, but that’s not usually an explicit goal!\\n\\n1090 | Chapter 33:\\u2002Exception Basics\\n\\n\\x0c5. The try/finally statement can be used to ensure actions are run after a block of\\ncode exits, regardless of whether the block raises an exception or not. The with/\\nas statement can also be used to ensure termination actions are run, but only when\\nprocessing object types that support it.\\n\\nTest Your Knowledge: Answers\\n\\n| 1091\\n\\n\\x0c\\x0cCHAPTER 34\\nException Coding Details\\n\\nIn the prior chapter we took a quick look at exception-related statements in action.\\nHere, we’re going to dig a bit deeper—this chapter provides a more formal introduction\\nto exception processing syntax in Python. Specifically, we’ll explore the details behind\\nthe try, raise, assert, and with statements. As we’ll see, although these statements are\\nmostly straightforward, they offer powerful tools for dealing with exceptional condi-\\ntions in Python code.\\n\\nOne procedural note up front: The exception story has changed in major\\nways in recent years. As of Python 2.5, the finally clause can appear in\\nthe  same  try  statement  as  except  and  else  clauses  (previously,  they\\ncould not be combined). Also, as of Python 3.0 and 2.6, the new with\\ncontext manager statement has become official, and user-defined ex-\\nceptions must now be coded as class instances, which should inherit\\nfrom  a  built-in  exception  superclass.  Moreover,  3.X  sports  slightly\\nmodified syntax for the raise statement and except clauses, some of\\nwhich is available in 2.6 and 2.7.\\n\\nI  will  focus  on  the  state  of  exceptions  in  recent  Python  2.X  and  3.X\\nreleases in this edition, but because you are still very likely to see the\\noriginal techniques in code for some time to come, along the way I’ll\\npoint out how things have evolved in this domain.\\n\\nThe try/except/else Statement\\nNow that we’ve seen the basics, it’s time for the details. In the following discussion,\\nI’ll first present try/except/else and try/finally as separate statements, because in\\nversions of Python prior to 2.5 they serve distinct roles and cannot be combined, and\\nstill are at least logically distinct today. Per the preceding note, in Python 2.5 and later\\nexcept and finally can be mixed in a single try statement; we’ll see the implications\\nof that merging after we’ve explored the two original forms in isolation.\\n\\n1093\\n\\n\\x0cSyntactically, the try is a compound, multipart statement. It starts with a try header\\nline, followed by a block of (usually) indented statements; then one or more except\\nclauses that identify exceptions to be caught and blocks to process them; and an op-\\ntional  else  clause  and  block  at  the  end.  You  associate  the  words  try,  except,  and\\nelse by indenting them to the same level (i.e., lining them up vertically). For reference,\\nhere’s the general and most complete format in Python 3.X:\\n\\ntry:\\n    statements              # Run this main action first\\nexcept name1:\\n    statements              # Run if name1 is raised during try block\\nexcept (name2, name3):\\n    statements              # Run if any of these exceptions occur\\nexcept name4 as var:\\n    statements              # Run if name4 is raised, assign instance raised to var\\nexcept:\\n    statements              # Run for all other exceptions raised\\nelse:\\n    statements              # Run if no exception was raised during try block\\n\\nSemantically,  the  block  under  the  try  header  in  this  statement  represents  the  main\\naction of the statement—the code you’re trying to run and wrap in error processing\\nlogic. The except clauses define handlers for exceptions raised during the try block,\\nand the else clause (if coded) provides a handler to be run if no exceptions occur. The\\nvar entry here has to do with a feature of raise statements and exception classes, which\\nwe will discuss in full later in this chapter.\\n\\nHow try Statements Work\\nOperationally, here’s how try statements are run. When a try statement is entered,\\nPython marks the current program context so it can return to it if an exception occurs.\\nThe statements nested under the try header are run first. What happens next depends\\non whether exceptions are raised while the try block’s statements are running, and\\nwhether they match those that the try is watching for:\\n\\n• If an exception occurs while the try block’s statements are running, and the ex-\\nception matches one that the statement names, Python jumps back to the try and\\nruns the statements under the first except clause that matches the raised exception,\\nafter assigning the raised exception object to the variable named after the as key-\\nword in the clause (if present). After the except block runs, control then resumes\\nbelow the entire try statement (unless the except block itself raises another ex-\\nception, in which case the process is started anew from this point in the code).\\n\\n• If an exception occurs while the try block’s statements are running, but the ex-\\nception does not match one that the statement names, the exception is propagated\\nup to the next most recently entered try statement that matches the exception; if\\nno such matching try statement can be found and the search reaches the top level\\nof the process, Python kills the program and prints a default error message.\\n\\n1094 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0c• If an exception does not occur while the try block’s statements are running, Python\\nruns the statements under the else line (if present), and control then resumes below\\nthe entire try statement.\\n\\nIn other words, except clauses catch any matching exceptions that happen while the\\ntry block is running, and the else clause runs only if no exceptions happen while the\\ntry block runs. Exceptions raised are matched to exceptions named in except clauses\\nby superclass relationships we’ll explore in the next chapter, and the empty except clause\\n(with no exception name) matches all (or all other) exceptions.\\nThe except clauses are focused exception handlers—they catch exceptions that occur\\nonly within the statements in the associated try block. However, as the try block’s\\nstatements can call functions coded elsewhere in a program, the source of an exception\\nmay be outside the try statement itself.\\nIn fact, a try block might invoke arbitrarily large amounts of program code—including\\ncode that may have try statements of its own, which will be searched first when ex-\\nceptions occur. That is, try statements can nest at runtime, a topic I’ll have more to say \\nabout in Chapter 36.\\n\\ntry Statement Clauses\\nWhen you write a try statement, a variety of clauses can appear after the try header.\\nTable 34-1 summarizes all the possible forms—you must use at least one. We’ve already\\nmet some of these: as you know, except clauses catch exceptions, finally clauses run\\non the way out, and else clauses run if no exceptions are encountered.\\nFormally, there may be any number of except clauses, but you can code else only if\\nthere is at least one except, and there can be only one else and one finally. Through\\nPython 2.4, the finally clause must appear alone (without else or except); the try/\\nfinally is really a different statement. As of Python 2.5, however, a finally can appear\\nin the same statement as except and else (more on the ordering rules later in this chapter\\nwhen we meet the unified try statement).\\n\\nTable 34-1. try statement clause forms\\n\\nClause form\\nexcept:\\nexcept name:\\nexcept name as value:\\nexcept (name1, name2):\\nexcept (name1, name2) as value:\\nelse:\\n\\nfinally:\\n\\nInterpretation\\nCatch all (or all other) exception types.\\nCatch a specific exception only.\\nCatch the listed exception and assign its instance.\\nCatch any of the listed exceptions.\\nCatch any listed exception and assign its instance.\\nRun if no exceptions are raised in the try block.\\nAlways perform this block on exit.\\n\\nThe try/except/else Statement\\n\\n| 1095\\n\\n\\x0cWe’ll explore the entries with the extra as value part in more detail when we meet the\\nraise statement later in this chapter. They provide access to the objects that are raised\\nas exceptions.\\n\\nCatching any and all exceptions\\nThe first and fourth entries in Table 34-1 are new here:\\n\\n• except clauses that list no exception name (except:) catch all exceptions not pre-\\n\\nviously listed in the try statement.\\n\\n• except clauses that list a set of exceptions in parentheses (except (e1, e2, e3):)\\n\\ncatch any of the listed exceptions.\\n\\nBecause Python looks for a match within a given try by inspecting the except clauses\\nfrom top to bottom, the parenthesized version has the same effect as listing each ex-\\nception in its own except clause, but you have to code the statement body associated\\nwith each only once. Here’s an example of multiple  except clauses at work, which\\ndemonstrates just how specific your handlers can be:\\n\\ntry:\\n    action()\\nexcept NameError:\\n    ...\\nexcept IndexError:\\n    ...\\nexcept KeyError:\\n    ...\\nexcept (AttributeError, TypeError, SyntaxError):\\n    ...\\nelse:\\n    ...\\n\\nIn this example, if an exception is raised while the call to the action function is running,\\nPython returns to the try and searches for the first except that names the exception\\nraised. It inspects the except clauses from top to bottom and left to right, and runs the\\nstatements under the first one that matches. If none match, the exception is propagated\\npast this try. Note that the else runs only when no exception occurs in action—it does\\nnot run when an exception without a matching except is raised.\\n\\nCatching all: The empty except and Exception\\nIf you really want a general “catchall” clause, an empty except does the trick:\\n\\ntry:\\n    action()\\nexcept NameError:\\n    ...                   # Handle NameError\\nexcept IndexError:\\n    ...                   # Handle IndexError\\nexcept:\\n    ...                   # Handle all other exceptions\\n\\n1096 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0celse:\\n    ...                   # Handle the no-exception case\\n\\nThe empty except clause is a sort of wildcard feature—because it catches everything, it\\nallows your handlers to be as general or specific as you like. In some scenarios, this\\nform may be more convenient than listing all possible exceptions in a try. For example,\\nthe following catches everything without listing anything:\\n\\ntry:\\n    action()\\nexcept:\\n    ...                   # Catch all possible exceptions\\n\\nEmpty excepts also raise some design issues, though. Although convenient, they may\\ncatch unexpected system exceptions unrelated to your code, and they may inadver-\\ntently intercept exceptions meant for another handler. For example, even system exit\\ncalls and Ctrl-C key combinations in Python trigger exceptions, and you usually want\\nthese  to  pass.  Even  worse,  the  empty  except  may  also  catch  genuine  programming\\nmistakes for which you probably want to see an error message. We’ll revisit this as a\\ngotcha at the end of this part of the book. For now, I’ll just say, “use with care.”\\nPython 3.X more strongly supports an alternative that solves one of these problems—\\ncatching  an  exception  named  Exception  has  almost  the  same  effect  as  an  empty\\nexcept, but ignores exceptions related to system exits:\\n\\ntry:\\n    action()\\nexcept Exception:\\n    ...                   # Catch all possible exceptions, except exits\\n\\nWe’ll explore how this form works its voodoo formally in the next chapter when we\\nstudy exception classes. In short, it works because exceptions match if they are a sub-\\nclass of one named in an except clause, and Exception is a superclass of all the exceptions\\nyou should generally catch this way. This form has most of the same convenience of\\nthe empty except, without the risk of catching exit events. Though better, it also has\\nsome of the same dangers—especially with regard to masking programming errors.\\n\\nVersion skew note: See also the raise statement ahead for more on the\\nas portion of except clauses in try. Syntactically, Python 3.X requires\\nthe except E as V: handler clause form listed in Table 34-1 and used in\\nthis book, rather than the older except E, V: form. The latter form is\\nstill available (but not recommended) in Python 2.6 and 2.7: if used, it’s\\nconverted to the former.\\n\\nThe change was made to eliminate confusion regarding the dual role of\\ncommas in the older form. In this form, two alternate exceptions are\\nproperly coded as except (E1, E2):. Because 3.X supports the as form\\nonly, commas in a handler clause are always taken to mean a tuple,\\nregardless of whether parentheses are used or not, and the values are\\ninterpreted as alternative exceptions to be caught.\\n\\nThe try/except/else Statement\\n\\n| 1097\\n\\n\\x0cAs we’ll see ahead, though, this option does not modify the scoping\\nrules in 2.X: even with the new as syntax, the variable V is still available\\nafter the except block in 2.X. In 3.X, V is not available later, and is in\\nfact forcibly deleted.\\n\\nThe try else Clause\\nThe purpose of the else clause is not always immediately obvious to Python newcom-\\ners. Without it, though, there is no direct way to tell (without setting and checking\\nBoolean flags) whether the flow of control has proceeded past a try statement because\\nno exception was raised, or because an exception occurred and was handled. Either\\nway, we wind up after the try:\\n\\ntry:\\n    ...run code...\\nexcept IndexError:\\n    ...handle exception...\\n# Did we get here because the try failed or not?\\n\\nMuch like the way else clauses in loops make the exit cause more apparent, the else\\nclause provides syntax in a try that makes what has happened obvious and unambig-\\nuous:\\n\\ntry:\\n    ...run code...\\nexcept IndexError:\\n    ...handle exception...\\nelse:\\n    ...no exception occurred...\\n\\nYou can almost emulate an else clause by moving its code into the try block:\\n\\ntry:\\n    ...run code...\\n    ...no exception occurred...\\nexcept IndexError:\\n    ...handle exception...\\n\\nThis can lead to incorrect exception classifications, though. If the “no exception oc-\\ncurred” action triggers an IndexError, it will register as a failure of the try block and\\nerroneously trigger the exception handler below the try (subtle, but true!). By using an\\nexplicit  else  clause  instead,  you  make  the  logic  more  obvious  and  guarantee  that\\nexcept handlers will run only for real failures in the code you’re wrapping in a try, not\\nfor failures in the else no-exception case’s action.\\n\\nExample: Default Behavior\\nBecause  the  control  flow  through  a  program  is  easier  to  capture  in  Python  than  in\\nEnglish, let’s run some examples that further illustrate exception basics in the context\\nof larger code samples in files.\\n\\n1098 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0cI’ve mentioned that exceptions not caught by try statements percolate up to the top\\nlevel of the Python process and run Python’s default exception-handling logic (i.e.,\\nPython terminates the running program and prints a standard error message). To il-\\nlustrate, running the following module file, bad.py, generates a divide-by-zero excep-\\ntion:\\n\\ndef gobad(x, y):\\n    return x / y\\n\\ndef gosouth(x):\\n    print(gobad(x, 0))\\n\\ngosouth(1)\\n\\nBecause the program ignores the exception it triggers, Python kills the program and\\nprints a message:\\n% python bad.py\\nTraceback (most recent call last):\\n  File \"bad.py\", line 7, in <module>\\n    gosouth(1)\\n  File \"bad.py\", line 5, in gosouth\\n    print(gobad(x, 0))\\n  File \"bad.py\", line 2, in gobad\\n    return x / y\\nZeroDivisionError: division by zero\\n\\nI ran this in a shell window with Python 3.X. The message consists of a stack trace\\n(“Traceback”) and the name of and details about the exception that was raised. The\\nstack trace lists all lines active when the exception occurred, from oldest to newest.\\nNote that because we’re not working at the interactive prompt, in this case the file and\\nline number information is more useful. For example, here we can see that the bad\\ndivide happens at the last entry in the trace—line 2 of the file bad.py, a return state-\\nment.1\\nBecause Python detects and reports all errors at runtime by raising exceptions, excep-\\ntions are intimately bound up with the ideas of error handling and debugging in general.\\nIf you’ve worked through this book’s examples, you’ve undoubtedly seen an exception\\nor two along the way—even typos usually generate a SyntaxError or other exception\\nwhen a file is imported or executed (that’s when the compiler is run). By default, you\\nget a useful error display like the one just shown, which helps you track down the\\nproblem.\\nOften, this standard error message is all you need to resolve problems in your code.\\nFor more heavy-duty debugging jobs, you can catch exceptions with try statements,\\n\\n1. As mentioned in the prior chapter, the text of error messages and stack traces tends to vary slightly over\\ntime and shells. Don’t be alarmed if your error messages don’t exactly match mine. When I ran this\\nexample in Python 3.3’s IDLE GUI, for instance, its error message text showed filenames with full absolute\\ndirectory paths.\\n\\nThe try/except/else Statement\\n\\n| 1099\\n\\n\\x0cor use one of the debugging tools that I introduced in Chapter 3 and will summarize\\nagain in Chapter 36, such as the pdb standard library module.\\n\\nExample: Catching Built-in Exceptions\\nPython’s default exception handling is often exactly what you want—especially for\\ncode in a top-level script file, an error often should terminate your program immedi-\\nately. For many programs, there is no need to be more specific about errors in your code.\\nSometimes, though, you’ll want to catch errors and recover from them instead. If you\\ndon’t want your program terminated when Python raises an exception, simply catch it\\nby wrapping the program logic in a try. This is an important capability for programs\\nsuch as network servers, which must keep running persistently. For example, the fol-\\nlowing code, in the file kaboom.py, catches and recovers from the TypeError Python\\nraises immediately when you try to concatenate a list and a string (remember, the +\\noperator expects the same sequence type on both sides):\\n\\ndef kaboom(x, y):\\n    print(x + y)               # Trigger TypeError\\n\\ntry:\\n    kaboom([0, 1, 2], \\'spam\\')\\nexcept TypeError:              # Catch and recover here\\n    print(\\'Hello world!\\')\\nprint(\\'resuming here\\')         # Continue here if exception or not\\n\\nWhen the exception occurs in the function kaboom, control jumps to the try statement’s\\nexcept  clause,  which  prints  a  message.  Since  an  exception  is  “dead”  after  it’s  been\\ncaught like this, the program continues executing below the try rather than being ter-\\nminated by Python. In effect, the code processes and clears the error, and your script\\nrecovers:\\n\\n% python kaboom.py\\nHello world!\\nresuming here\\n\\nKeep in mind that once you’ve caught an error, control resumes at the place where you\\ncaught it (i.e., after the try); there is no direct way to go back to the place where the\\nexception occurred (here, in the function kaboom). In a sense, this makes exceptions\\nmore like simple jumps than function calls—there is no way to return to the code that\\ntriggered the error.\\n\\nThe try/finally Statement\\nThe other flavor of the try statement is a specialization that has to do with finalization\\n(a.k.a. termination) actions. If a finally clause is included in a try, Python will always\\nrun its block of statements “on the way out” of the try statement, whether an exception\\noccurred while the try block was running or not. Its general form is:\\n\\n1100 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0ctry:\\n    statements                 # Run this action first\\nfinally:\\n    statements                 # Always run this code on the way out\\n\\nWith this variant, Python begins by running the statement block associated with the\\ntry header line as usual. What happens next depends on whether an exception occurs\\nduring the try block:\\n\\n• If an exception does not occur while the try block is running, Python continues on\\n\\nto run the finally block, and then continues execution past the try statement.\\n\\n• If an exception does occur during the try block’s run, Python still comes back and\\nruns the finally block, but it then propagates the exception up to a previously\\nentered try or the top-level default handler; the program does not resume execution\\nbelow the finally clause’s try statement. That is, the finally block is run even if\\nan exception is raised, but unlike an except, the finally does not terminate the\\nexception—it continues being raised after the finally block runs.\\n\\nThe try/finally form is useful when you want to be completely sure that an action will\\nhappen after some code runs, regardless of the exception behavior of the program. In\\npractice, it allows you to specify cleanup actions that always must occur, such as file\\ncloses and server disconnects where required.\\nNote that the finally clause cannot be used in the same try statement as except and\\nelse in Python 2.4 and earlier, so the try/finally is best thought of as a distinct state-\\nment  form  if  you  are  using  an  older  release.  In  Python  2.5,  and  later,  however,\\nfinally can appear in the same statement as except and else, so today there is really a\\nsingle try statement with many optional clauses (more about this shortly). Whichever\\nversion you use, though, the finally clause still serves the same purpose—to specify\\n“cleanup” actions that must always be run, regardless of any exceptions.\\n\\nAs we’ll also see later in this chapter, as of Python 2.6 and 3.0, the new\\nwith statement and its context managers provide an object-based way\\nto do similar work for exit actions. Unlike finally, this new statement\\nalso supports entry actions, but it is limited in scope to objects that\\nimplement the context manager protocol it leverages.\\n\\nExample: Coding Termination Actions with try/finally\\nWe saw some simple try/finally examples in the prior chapter. Here’s a more realistic\\nexample that illustrates a typical role for this statement:\\n\\nclass MyError(Exception): pass\\n\\ndef stuff(file):\\n    raise MyError()\\n\\nfile = open(\\'data\\', \\'w\\')     # Open an output file (this can fail too)\\n\\nThe try/finally Statement\\n\\n| 1101\\n\\n\\x0ctry:\\n    stuff(file)              # Raises exception\\nfinally:\\n    file.close()             # Always close file to flush output buffers\\nprint(\\'not reached\\')         # Continue here only if no exception\\n\\nWhen the function in this code raises its exception, the control flow jumps back and\\nruns the finally block to close the file. The exception is then propagated on to either\\nanother try or the default top-level handler, which prints the standard error message\\nand shuts down the program. Hence, the statement after this try is never reached. If\\nthe  function  here  did  not  raise  an  exception,  the  program  would  still  execute  the\\nfinally block to close the file, but it would then continue below the entire try state-\\nment.\\nIn this specific case, we’ve wrapped a call to a file-processing function in a try with a\\nfinally clause to make sure that the file is always closed, and thus finalized, whether\\nthe function triggers an exception or not. This way, later code can be sure that the file’s\\noutput buffer’s content has been flushed from memory to disk. A similar code structure\\ncan guarantee that server connections are closed, and so on.\\nAs we learned in Chapter 9, file objects are automatically closed on garbage collection\\nin standard Python (CPython); this is especially useful for temporary files that we don’t\\nassign to variables. However, it’s not always easy to predict when garbage collection\\nwill occur, especially in larger programs or alternative Python implementations with\\ndiffering garbage collection policies (e.g., Jython, PyPy). The try statement makes file\\ncloses more explicit and predictable and pertains to a specific block of code. It ensures\\nthat the file will be closed on block exit, regardless of whether an exception occurs or\\nnot.\\nThis particular example’s function isn’t all that useful (it just raises an exception), but\\nwrapping calls in try/finally statements is a good way to ensure that your closing-time\\ntermination  activities  always  run.  Again,  Python  always  runs  the  code  in  your\\nfinally blocks, regardless of whether an exception happens in the try block.2\\nNotice how the user-defined exception here is again defined with a class—as we’ll see\\nmore formally in the next chapter, exceptions today must all be class instances in 2.6,\\n3.0, and later releases in both lines.\\n\\nUnified try/except/finally\\nIn all versions of Python prior to release 2.5 (for its first 15 years of life, more or less),\\nthe try statement came in two flavors and was really two separate statements—we\\ncould  either  use  a  finally  to  ensure  that  cleanup  code  was  always  run,  or  write\\n\\n2. Unless Python crashes completely, of course. It does a good job of avoiding this, though, by checking all\\npossible errors as a program runs. When a program does crash hard, it is usually due to a bug in linked-\\nin C extension code, outside of Python’s scope.\\n\\n1102 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0cexcept blocks to catch and recover from specific exceptions and optionally specify an\\nelse clause to be run if no exceptions occurred.\\nThat is, the finally clause could not be mixed with except and else. This was partly\\nbecause of implementation issues, and partly because the meaning of mixing the two\\nseemed obscure—catching and recovering from exceptions seemed a disjoint concept\\nfrom performing cleanup actions.\\nIn Python 2.5 and later, though, the two statements have merged. Today, we can mix\\nfinally, except, and else clauses in the same statement—in part because of similar\\nutility in the Java language. That is, we can now write a statement of this form:\\n\\ntry:                               # Merged form\\n    main-action\\nexcept Exception1:\\n    handler1\\nexcept Exception2:                 # Catch exceptions\\n    handler2\\n...\\nelse:                              # No-exception handler\\n    else-block\\nfinally:                           # The finally encloses all else\\n    finally-block\\n\\nThe code in this statement’s main-action block is executed first, as usual. If that code\\nraises an exception, all the except blocks are tested, one after another, looking for a\\nmatch to the exception raised. If the exception raised is Exception1, the handler1 block\\nis executed; if it’s Exception2, handler2 is run, and so on. If no exception is raised, the\\nelse-block is executed.\\nNo matter what’s happened previously, the finally-block is executed once the main\\naction block is complete and any raised exceptions have been handled. In fact, the code\\nin the finally-block will be run even if there is an error in an exception handler or the\\nelse-block and a new exception is raised.\\nAs always, the finally clause does not end the exception—if an exception is active\\nwhen the finally-block is executed, it continues to be propagated after the finally-\\nblock runs, and control jumps somewhere else in the program (to another try, or to\\nthe default top-level handler). If no exception is active when the finally is run, control\\nresumes after the entire try statement.\\nThe net effect is that the finally is always run, regardless of whether:\\n\\n• An exception occurred in the main action and was handled.\\n• An exception occurred in the main action and was not handled.\\n• No exceptions occurred in the main action.\\n• A new exception was triggered in one of the handlers.\\n\\nAgain, the finally serves to specify cleanup actions that must always occur on the way\\nout of the try, regardless of what exceptions have been raised or handled.\\n\\nUnified try/except/finally | 1103\\n\\n\\x0cUnified try Statement Syntax\\nWhen combined like this, the try statement must have either an except or a finally,\\nand the order of its parts must be like this:\\n\\ntry -> except -> else -> finally\\n\\nwhere the else and finally are optional, and there may be zero or more excepts, but\\nthere must be at least one except if an else appears. Really, the try statement consists\\nof two parts: excepts with an optional else, and/or the finally.\\nIn fact, it’s more accurate to describe the merged statement’s syntactic form this way\\n(square brackets mean optional and star means zero-or-more here):\\n\\ntry:                               # Format 1\\n    statements\\nexcept [type [as value]]:          # [type [, value]] in Python 2.X\\n    statements\\n[except [type [as value]]:\\n    statements]*\\n[else:\\n    statements]\\n[finally:\\n    statements]\\n\\ntry:                               # Format 2\\n    statements\\nfinally:\\n    statements\\n\\nBecause of these rules, the else can appear only if there is at least one except, and it’s\\nalways possible to mix except and finally, regardless of whether an else appears or\\nnot. It’s also possible to mix finally and else, but only if an except appears too (though\\nthe except can omit an exception name to catch everything and run a raise statement,\\ndescribed later, to reraise the current exception). If you violate any of these ordering\\nrules, Python will raise a syntax error exception before your code runs.\\n\\nCombining finally and except by Nesting\\nPrior to Python 2.5, it is actually possible to combine finally and except clauses in a\\ntry by syntactically nesting a try/except in the try block of a try/finally statement.\\nWe’ll explore this technique more fully in Chapter 36, but the basics may help clarify\\nthe meaning of a combined try—the following has the same effect as the new merged\\nform shown at the start of this section:\\n\\ntry:                               # Nested equivalent to merged form\\n    try:\\n        main-action\\n    except Exception1:\\n        handler1\\n    except Exception2:\\n        handler2\\n\\n1104 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0c    ...\\n    else:\\n        no-error\\nfinally:\\n    cleanup\\n\\nAgain, the finally block is always run on the way out, regardless of what happened in\\nthe main action and regardless of any exception handlers run in the nested try (trace\\nthrough  the  four  cases  listed  previously  to  see  how  this  works  the  same).  Since  an\\nelse always requires an  except, this nested form even sports the same mixing con-\\nstraints of the unified statement form outlined in the preceding section.\\nHowever, this nested equivalent seems more obscure to some, and requires more code\\nthan the new merged form—though just one four-character line plus extra indentation.\\nMixing finally into the same statement makes your code arguably easier to write and\\nread, and is a generally preferred technique today.\\n\\nUnified try Example\\nHere’s a demonstration of the merged try statement form at work. The following file,\\nmergedexc.py, codes four common scenarios, with print statements that describe the\\nmeaning of each:\\n\\n# File mergedexc.py (Python 3.X + 2.X)\\nsep = \\'-\\' * 45 + \\'\\\\n\\'\\n\\nprint(sep + \\'EXCEPTION RAISED AND CAUGHT\\')\\ntry:\\n    x = \\'spam\\'[99]\\nexcept IndexError:\\n    print(\\'except run\\')\\nfinally:\\n    print(\\'finally run\\')\\nprint(\\'after run\\')\\n\\nprint(sep + \\'NO EXCEPTION RAISED\\')\\ntry:\\n    x = \\'spam\\'[3]\\nexcept IndexError:\\n    print(\\'except run\\')\\nfinally:\\n    print(\\'finally run\\')\\nprint(\\'after run\\')\\n\\nprint(sep + \\'NO EXCEPTION RAISED, WITH ELSE\\')\\ntry:\\n    x = \\'spam\\'[3]\\nexcept IndexError:\\n    print(\\'except run\\')\\nelse:\\n\\nUnified try/except/finally | 1105\\n\\n\\x0c    print(\\'else run\\')\\nfinally:\\n    print(\\'finally run\\')\\nprint(\\'after run\\')\\n\\nprint(sep + \\'EXCEPTION RAISED BUT NOT CAUGHT\\')\\ntry:\\n    x = 1 / 0\\nexcept IndexError:\\n    print(\\'except run\\')\\nfinally:\\n    print(\\'finally run\\')\\nprint(\\'after run\\')\\n\\nWhen this code is run, the following output is produced in Python 3.3; in 2.X, its\\nbehavior  and  output  are  the  same  because  the  print  calls  each  print  a  single  item,\\nthough the error message text varies slightly. Trace through the code to see how ex-\\nception handling produces the output of each of the four tests here:\\n\\nc:\\\\code> py −3 mergedexc.py\\n---------------------------------------------\\nEXCEPTION RAISED AND CAUGHT\\nexcept run\\nfinally run\\nafter run\\n---------------------------------------------\\nNO EXCEPTION RAISED\\nfinally run\\nafter run\\n---------------------------------------------\\nNO EXCEPTION RAISED, WITH ELSE\\nelse run\\nfinally run\\nafter run\\n---------------------------------------------\\nEXCEPTION RAISED BUT NOT CAUGHT\\nfinally run\\nTraceback (most recent call last):\\n  File \"mergedexc.py\", line 39, in <module>\\n    x = 1 / 0\\nZeroDivisionError: division by zero\\n\\nThis example uses built-in operations in the main action to trigger exceptions (or not),\\nand it relies on the fact that Python always checks for errors as code is running. The\\nnext section shows how to raise exceptions manually instead.\\n\\nThe raise Statement\\nTo trigger exceptions explicitly, you can code raise statements. Their general form is\\nsimple—a raise statement consists of the word raise, optionally followed by the class\\nto be raised or an instance of it:\\n\\n1106 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0craise instance               # Raise instance of class\\nraise class                  # Make and raise instance of class: makes an instance\\nraise                        # Reraise the most recent exception\\n\\nAs mentioned earlier, exceptions are always instances of classes in Python 2.6, 3.0, and\\nlater. Hence, the first raise form here is the most common—we provide an instance\\ndirectly, either created before the raise or within the raise statement itself. If we pass\\na class instead, Python calls the class with no constructor arguments, to create an in-\\nstance to be raised; this form is equivalent to adding parentheses after the class refer-\\nence. The last form reraises the most recently raised exception; it’s commonly used\\nin exception handlers to propagate exceptions that have been caught.\\n\\nVersion skew note: Python 3.X no longer supports the raise Exc, Args\\nform  that  is  still  available  in  Python  2.X.  In  3.X,  use  the  raise\\nExc(Args) instance-creation call form described in this book instead.\\nThe equivalent comma form in 2.X is legacy syntax provided for com-\\npatibility with the now-defunct string-based exceptions model, and it’s\\ndeprecated in 2.X. If used, it is converted to the 3.X call form.\\n\\nAs in earlier releases, a raise Exc form is also allowed to name a class—\\nit is converted to raise Exc() in both versions, calling the class con-\\nstructor with no arguments. Besides its defunct comma syntax, Python\\n2.X’s raise also allowed for either string or class exceptions, but the\\nformer is removed in 2.6, deprecated in 2.5, and not covered here except\\nfor a brief mention in the next chapter. Use classes for new exceptions\\ntoday.\\n\\nRaising Exceptions\\nTo make this clearer, let’s look at some examples. With built-in exceptions, the fol-\\nlowing two forms are equivalent—both raise an instance of the exception class named,\\nbut the first creates the instance implicitly:\\n\\nraise IndexError             # Class (instance created)\\nraise IndexError()           # Instance (created in statement)\\n\\nWe can also create the instance ahead of time—because the raise statement accepts\\nany kind of object reference, the following two examples raise IndexError just like the\\nprior two:\\n\\nexc = IndexError()           # Create instance ahead of time\\nraise exc\\n\\nexcs = [IndexError, TypeError]\\nraise excs[0]\\n\\nWhen an exception is raised, Python sends the raised instance along with the exception.\\nIf a try includes an except name as X: clause, the variable X will be assigned the instance\\nprovided in the raise:\\n\\nThe raise Statement\\n\\n| 1107\\n\\n\\x0ctry:\\n    ...\\nexcept IndexError as X:      # X assigned the raised instance object\\n    ...\\n\\nThe as is optional in a try handler (if it’s omitted, the instance is simply not assigned\\nto a name), but including it allows the handler to access both data in the instance and\\nmethods in the exception class.\\nThis  model  works  the  same  for  user-defined  exceptions  we  code  with  classes—the\\nfollowing, for example, passes to the exception class constructor arguments that be-\\ncome available in the handler through the assigned instance:\\n\\nclass MyExc(Exception): pass\\n...\\nraise MyExc(\\'spam\\')          # Exception class with constructor args\\n...\\ntry:\\n    ...\\nexcept MyExc as X:           # Instance attributes available in handler\\n    print(X.args)\\n\\nBecause this encroaches on the next chapter’s topic, though, I’ll defer further details\\nuntil then.\\nRegardless of how you name them, exceptions are always identified by class instance\\nobjects, and at most one is active at any given time. Once caught by an except clause\\nanywhere in the program, an exception dies (i.e., won’t propagate to another  try),\\nunless it’s reraised by another raise statement or error.\\n\\nScopes and try except Variables\\nWe’ll study exception objects in more detail in the next chapter. Now that we’ve seen\\nthe as variable in action, though, we can finally clarify the related version-specific scope\\nissue summarized in Chapter 17. In Python 2.X, the exception reference variable name\\nin an except clause is not localized to the clause itself, and is available after the associated\\nblock runs:\\n\\nc:\\\\code> py −2\\n>>> try:\\n...     1 / 0\\n... except Exception as X:               # 2.X does not localize X either way\\n...     print X\\n...\\ninteger division or modulo by zero\\n>>> X\\nZeroDivisionError(\\'integer division or modulo by zero\\',)\\n\\nThis is true in 2.X whether we use the 3.X-style as or the earlier comma syntax:\\n\\n>>> try:\\n...     1 / 0\\n... except Exception, X:\\n\\n1108 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0c...     print X\\n...\\ninteger division or modulo by zero\\n>>> X\\nZeroDivisionError(\\'integer division or modulo by zero\\',)\\n\\nBy contrast, Python 3.X localizes the exception reference name to the except block—\\nthe variable is not available after the block exits, much like a temporary loop variable\\nin 3.X comprehension expressions (3.X also doesn’t accept 2.X’s except comma syntax,\\nas noted earlier):\\nc:\\\\code> py −3\\n>>> try:\\n...     1 / 0\\n... except Exception, X:\\nSyntaxError: invalid syntax\\n\\n>>> try:\\n...     1 / 0\\n... except Exception as X:               # 3.X localizes \\'as\\' names to except block\\n...     print(X)\\n...\\ndivision by zero\\n>>> X\\nNameError: name \\'X\\' is not defined\\n\\nUnlike compression loop variables, though, this variable is removed after the except\\nblock exits in 3.X. It does so because it would otherwise retain a reference to the runtime\\ncall stack, which would defer garbage collection and thus retain excess memory space.\\nThis removal occurs, though, even if you’re using the name elsewhere, and is more\\nextreme policy than that used for comprehensions:\\n\\n>>> X = 99\\n>>> try:\\n...     1 / 0\\n... except Exception as X:               # 3.X localizes _and_ removes on exit!\\n...     print(X)\\n...\\ndivision by zero\\n>>> X\\nNameError: name \\'X\\' is not defined\\n\\n>>> X = 99\\n>>> {X for X in \\'spam\\'}                  # 2.X/3.X localizes only: not removed\\n{\\'s\\', \\'a\\', \\'p\\', \\'m\\'}\\n>>> X\\n99\\n\\nBecause of this, you should generally use unique variable names in your try statement’s\\nexcept  clauses,  even  if  they  are  localized  by  scope.  If  you  do  need  to  reference  the\\nexception instance after the try statement, simply assign it to another name that won’t\\nbe automatically removed:\\n\\nThe raise Statement\\n\\n| 1109\\n\\n\\x0c>>> try:\\n...     1 / 0\\n... except Exception as X:               # Python removes this reference\\n...     print(X)\\n...     Saveit = X                       # Assign exc to retain exc if needed\\n...\\ndivision by zero\\n>>> X\\nNameError: name \\'X\\' is not defined\\n>>> Saveit\\nZeroDivisionError(\\'division by zero\\',)\\n\\nPropagating Exceptions with raise\\nThe raise statement is a bit more feature-rich than we’ve seen thus far. For example,\\na raise that does not include an exception name or extra data value simply reraises the\\ncurrent exception. This form is typically used if you need to catch and handle an ex-\\nception but don’t want the exception to die in your code:\\n\\n>>> try:\\n...     raise IndexError(\\'spam\\')         # Exceptions remember arguments\\n... except IndexError:\\n...     print(\\'propagating\\')\\n...     raise                            # Reraise most recent exception\\n...\\npropagating\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 2, in <module>\\nIndexError: spam\\n\\nRunning a raise this way reraises the exception and propagates it to a higher handler\\n(or the default handler at the top, which stops the program with a standard error mes-\\nsage). Notice how the argument we passed to the exception class shows up in the error\\nmessages; you’ll learn why this happens in the next chapter.\\n\\nPython 3.X Exception Chaining: raise from\\nExceptions can sometimes be triggered in response to other exceptions—both delib-\\nerately and by new program errors. To support full disclosure in such cases, Python\\n3.X (but not 2.X) also allows raise statements to have an optional from clause:\\n\\nraise newexception from otherexception\\n\\nWhen the from is used in an explicit raise request, the expression following from speci-\\nfies another exception class or instance to attach to the __cause__ attribute of the new\\nexception being raised. If the raised exception is not caught, Python prints both ex-\\nceptions as part of the standard error message:\\n\\n>>> try:\\n...     1 / 0\\n... except Exception as E:\\n...     raise TypeError(\\'Bad\\') from E              # Explicitly chained exceptions\\n\\n1110 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0c...\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 2, in <module>\\nZeroDivisionError: division by zero\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 4, in <module>\\nTypeError: Bad\\n\\nWhen an exception is raised implicitly by a program error inside an exception handler,\\na similar procedure is followed automatically: the previous exception is attached to the\\nnew  exception’s  __context__  attribute  and  is  again  displayed  in  the  standard  error\\nmessage if the exception goes uncaught:\\n\\n>>> try:\\n...     1 / 0\\n... except:\\n...     badname                                    # Implicitly chained exceptions\\n...\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 2, in <module>\\nZeroDivisionError: division by zero\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 4, in <module>\\nNameError: name \\'badname\\' is not defined\\n\\nIn both cases, because the original exception objects thus attached to new exception\\nobjects  may  themselves  have  attached  causes,  the  causality  chain  can  be  arbitrary\\nlong, and is displayed in full in error messages. That is, error messages might give more\\nthan two exceptions. The net effect in both explicit and implicit contexts is to allow\\nprogrammers to know all exceptions involved, when one exception triggers another:\\n\\n>>> try:\\n...     try:\\n...         raise IndexError()\\n...     except Exception as E:\\n...         raise TypeError() from E\\n... except Exception as E:\\n...     raise SyntaxError() from E\\n...\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 3, in <module>\\nIndexError\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 5, in <module>\\nTypeError\\n\\nThe raise Statement\\n\\n| 1111\\n\\n\\x0cThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 7, in <module>\\nSyntaxError: None\\n\\nCode like the following would similarly display three exceptions, though implicitly\\ntriggered here:\\n\\ntry:\\n    try:\\n        1 / 0\\n    except:\\n        badname\\nexcept:\\n    open(\\'nonesuch\\')\\n\\nLike the unified try, chained exceptions are similar to utility in other languages (in-\\ncluding Java and C#) though it’s not clear which languages were borrowers. In Python,\\nit’s a still somewhat obscure extension, so we’ll defer to Python’s manuals for more\\ndetails. In fact, Python 3.3 adds a way to stop exceptions from chaining, per the fol-\\nlowing note.\\n\\nPython 3.3 chained exception suppression: raise from None. Python 3.3\\nintroduces a new syntax form—using None as the exception name in the\\nraise from statement:\\n\\nraise newexception from None\\n\\nThis allows the display of the chained exception context described in\\nthe preceding section to be disabled. This makes for less cluttered error\\nmessages in applications that convert between exception types while\\nprocessing exception chains.\\n\\nThe assert Statement\\nAs a somewhat special case for debugging purposes, Python includes the assert state-\\nment. It is mostly just syntactic shorthand for a common raise usage pattern, and an\\nassert can be thought of as a conditional raise statement. A statement of the form:\\n\\nassert test, data              # The data part is optional\\n\\nworks like the following code:\\n\\nif __debug__:\\n    if not test:\\n        raise AssertionError(data)\\n\\nIn other words, if the test evaluates to false, Python raises an exception: the data item\\n(if it’s provided) is used as the exception’s constructor argument. Like all exceptions, \\nthe AssertionError exception will kill your program if it’s not caught with a try, in\\nwhich case the data item shows up as part of the standard error message.\\n\\n1112 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0cAs an added feature, assert statements may be removed from a compiled program’s\\nbyte code if the -O Python command-line flag is used, thereby optimizing the program.\\nAssertionError is a built-in exception, and the __debug__ flag is a built-in name that is\\nautomatically set to True unless the -O flag is used. Use a command line like python –O\\nmain.py to run in optimized mode and disable (and hence skip) asserts.\\n\\nExample: Trapping Constraints (but Not Errors!)\\nAssertions are typically used to verify program conditions during development. When\\ndisplayed, their error message text automatically includes source code line information\\nand the value listed in the assert statement. Consider the file asserter.py:\\n\\ndef f(x):\\n    assert x < 0, \\'x must be negative\\'\\n    return x ** 2\\n\\n% python\\n>>> import asserter\\n>>> asserter.f(1)\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \".\\\\asserter.py\", line 2, in f\\n    assert x < 0, \\'x must be negative\\'\\nAssertionError: x must be negative\\n\\nIt’s important to keep in mind that assert is mostly intended for trapping user-defined\\nconstraints, not for catching genuine programming errors. Because Python traps pro-\\ngramming errors itself, there is usually no need to code assert to catch things like out-\\nof-bounds indexes, type mismatches, and zero divides:\\n\\ndef reciprocal(x):\\n    assert x != 0              # A generally useless assert!\\n    return 1 / x               # Python checks for zero automatically\\n\\nSuch assert use cases are usually superfluous—because Python raises exceptions on\\nerrors automatically, you might as well let it do the job for you. As a rule, you don’t\\nneed to do error checking explicitly in your own code.\\nOf course, there are exceptions for most rules—as suggested earlier in the book, if a\\nfunction has to perform long-running or unrecoverable actions before it reaches the\\nplace where an exception will be triggered, you still might want to test for errors. Even\\nin this case, though, be careful not to make your tests overly specific or restrictive, or\\nyou will limit your code’s utility.\\nFor another example of common assert usage, see the abstract superclass example in\\nChapter 29; there, we used assert to make calls to undefined methods fail with a mes-\\nsage. It’s a rare but useful tool.\\n\\nThe assert Statement\\n\\n| 1113\\n\\n\\x0cwith/as Context Managers\\nPython 2.6 and 3.0 introduced a new exception-related statement—the with, and its\\noptional as clause. This statement is designed to work with context manager objects,\\nwhich support a new method-based protocol, similar in spirit to the way that iteration\\ntools work with methods of the iteration protocol. This feature is also available as an\\noption in 2.5, but must be enabled there with an import of this form:\\n\\nfrom __future__ import with_statement\\n\\nThe with statement is also similar to a “using” statement in the C# language. Although\\na somewhat optional and advanced tools-oriented topic (and once a candidate for the\\nnext part of the book), context managers are lightweight and useful enough to group\\nwith the rest of the exception toolset here.\\nIn  short,  the  with/as  statement  is  designed  to  be  an  alternative  to  a  common  try/\\nfinally usage idiom; like that statement, with is in large part intended for specifying\\ntermination-time or “cleanup” activities that must run regardless of whether an excep-\\ntion occurs during a processing step.\\nUnlike try/finally, the with statement is based upon an object protocol for specifying\\nactions to be run around a block of code. This makes with less general, qualifies it as\\nredundant in termination roles, and requires coding classes for objects that do not\\nsupport its protocol. On the other hand, with also handles entry actions, can reduce\\ncode size, and allows code contexts to be managed with full OOP.\\nPython enhances some built-in tools with context managers, such as files that auto-\\nmatically close themselves and thread locks that automatically lock and unlock, but\\nprogrammers can code context managers of their own with classes, too. Let’s take a\\nbrief look at the statement and its implicit protocol.\\n\\nBasic Usage\\nThe basic format of the with statement looks like this, with an optional part in square\\nbrackets here:\\n\\nwith expression [as variable]:\\n    with-block\\n\\nThe expression here is assumed to return an object that supports the context manage-\\nment protocol (more on this protocol in a moment). This object may also return a value\\nthat will be assigned to the name variable if the optional as clause is present.\\nNote that the variable is not necessarily assigned the result of the expression; the result\\nof the expression is the object that supports the context protocol, and the variable may\\nbe assigned something else intended to be used inside the statement. The object re-\\nturned by the expression may then run startup code before the with-block is started,\\nas well as termination code after the block is done, regardless of whether the block\\nraised an exception or not.\\n\\n1114 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0cSome built-in Python objects have been augmented to support the context management\\nprotocol, and so can be used with the with statement. For example, file objects (covered\\nin Chapter 9) have a context manager that automatically closes the file after the with\\nblock regardless of whether an exception is raised, and regardless of if or when the\\nversion of Python running the code may close automatically:\\n\\nwith open(r\\'C:\\\\misc\\\\data\\') as myfile:\\n    for line in myfile:\\n        print(line)\\n        ...more code here...\\n\\nHere, the call to open returns a simple file object that is assigned to the name myfile.\\nWe can use myfile with the usual file tools—in this case, the file iterator reads line by\\nline in the for loop.\\nHowever,  this  object  also  supports  the  context  management  protocol  used  by  the\\nwith statement. After this with statement has run, the context management machinery\\nguarantees that the file object referenced by myfile is automatically closed, even if the\\nfor loop raised an exception while processing the file.\\nAlthough file objects may be automatically closed on garbage collection, it’s not always\\nstraightforward to know when that will occur, especially when using alternative Python\\nimplementations. The with statement in this role is an alternative that allows us to be\\nsure that the close will occur after execution of a specific block of code.\\nAs we saw earlier, we can achieve a similar effect with the more general and explicit\\ntry/finally statement, but it requires three more lines of administrative code in this\\ncase (four instead of just one):\\n\\nmyfile = open(r\\'C:\\\\misc\\\\data\\')\\ntry:\\n    for line in myfile:\\n        print(line)\\n        ...more code here...\\nfinally:\\n    myfile.close()\\n\\nWe won’t cover Python’s multithreading modules in this book (for more on that topic,\\nsee follow-up application-level texts such as Programming Python) but the lock and\\ncondition synchronization objects they define may also be used with the with statement,\\nbecause they support the context management protocol—in this case adding both entry\\nand exit actions around a block:\\n\\nlock = threading.Lock()                        # After: import threading\\nwith lock:\\n    # critical section of code\\n    ...access shared resources...\\n\\nHere, the context management machinery guarantees that the lock is automatically\\nacquired before the block is executed and released once the block is complete, regard-\\nless of exception outcomes.\\n\\nwith/as Context Managers\\n\\n| 1115\\n\\n\\x0cAs introduced in Chapter 5, the decimal module also uses context managers to simplify\\nsaving and restoring the current decimal context, which specifies the precision and\\nrounding characteristics for calculations:\\n\\nwith decimal.localcontext() as ctx:            # After: import decimal\\n    ctx.prec = 2\\n    x = decimal.Decimal(\\'1.00\\') / decimal.Decimal(\\'3.00\\')\\n\\nAfter this statement runs, the current thread’s context manager state is automatically\\nrestored  to  what  it  was  before  the  statement  began.  To  do  the  same  with  a  try/\\nfinally, we would need to save the context before and restore it manually after the\\nnested block.\\n\\nThe Context Management Protocol\\nAlthough some built-in types come with context managers, we can also write new ones\\nof our own. To implement context managers, classes use special methods that fall into\\nthe operator overloading category to tap into the with statement. The interface expected\\nof objects used in with statements is somewhat complex, and most programmers only\\nneed to know how to use existing context managers. For tool builders who might want\\nto write new application-specific context managers, though, let’s take a quick look at\\nwhat’s involved.\\nHere’s how the with statement actually works:\\n\\n1. The expression is evaluated, resulting in an object known as a context manager that\\n\\nmust have __enter__ and __exit__ methods.\\n\\n2. The context manager’s __enter__ method is called. The value it returns is assigned\\n\\nto the variable in the as clause if present, or simply discarded otherwise.\\n\\n3. The code in the nested with block is executed.\\n4. If the with block raises an exception, the __exit__(type, value, traceback) method\\nis called with the exception details. These are the same three values returned by\\nsys.exc_info, described in the Python manuals and later in this part of the book.\\nIf this method returns a false value, the exception is reraised; otherwise, the ex-\\nception  is  terminated.  The  exception  should  normally  be  reraised  so  that  it  is\\npropagated outside the with statement.\\n\\n5. If the with block does not raise an exception, the __exit__ method is still called,\\n\\nbut its type, value, and traceback arguments are all passed in as None.\\n\\nLet’s look at a quick demo of the protocol in action. The following, file  withas.py,\\ndefines a context manager object that traces the entry and exit of the with block in any\\nwith statement it is used for:\\n\\nclass TraceBlock:\\n    def message(self, arg):\\n        print(\\'running \\' + arg)\\n    def __enter__(self):\\n\\n1116 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0c        print(\\'starting with block\\')\\n        return self\\n    def __exit__(self, exc_type, exc_value, exc_tb):\\n        if exc_type is None:\\n            print(\\'exited normally\\\\n\\')\\n        else:\\n            print(\\'raise an exception! \\' + str(exc_type))\\n            return False    # Propagate\\n\\nif __name__ == \\'__main__\\':\\n    with TraceBlock() as action:\\n        action.message(\\'test 1\\')\\n        print(\\'reached\\')\\n\\n    with TraceBlock() as action:\\n        action.message(\\'test 2\\')\\n        raise TypeError\\n        print(\\'not reached\\')\\n\\nNotice  that  this  class’s  __exit__  method  returns  False  to  propagate  the  exception;\\ndeleting the return statement would have the same effect, as the default None return\\nvalue of functions is False by definition. Also notice that the __enter__ method returns\\nself as the object to assign to the as variable; in other use cases, this might return a\\ncompletely different object instead.\\nWhen run, the context manager traces the entry and exit of the with statement block\\nwith its __enter__ and __exit__ methods. Here’s the script in action being run under\\neither Python 3.X or 2.X (as usual, mileage varies slightly in some 2.X displays, and this\\nruns on 2.6, 2.7, and 2.5 if enabled):\\n\\nc:\\\\code> py −3 withas.py\\nstarting with block\\nrunning test 1\\nreached\\nexited normally\\n\\nstarting with block\\nrunning test 2\\nraise an exception! <class \\'TypeError\\'>\\nTraceback (most recent call last):\\n  File \"withas.py\", line 22, in <module>\\n    raise TypeError\\nTypeError\\n\\nContext  managers  can  also  utilize  OOP  state  information  and  inheritance,  but  are\\nsomewhat advanced devices for tool builders, so we’ll skip additional details here (see\\nPython’s standard manuals for the full story—for example, there’s a new contextlib\\nstandard module that provides additional tools for coding context managers). For sim-\\npler purposes, the try/finally statement provides sufficient support for termination-\\ntime activities without coding classes.\\n\\nwith/as Context Managers\\n\\n| 1117\\n\\n\\x0cMultiple Context Managers in 3.1, 2.7, and Later\\nPython 3.1 introduced a with extension that eventually appeared in Python 2.7 as well.\\nIn these and later Pythons, the with statement may also specify multiple (sometimes\\nreferred to as “nested”) context managers with new comma syntax. In the following,\\nfor example, both files’ exit actions are automatically run when the statement block\\nexits, regardless of exception outcomes:\\n\\nwith open(\\'data\\') as fin, open(\\'res\\', \\'w\\') as fout:\\n    for line in fin:\\n        if \\'some key\\' in line:\\n            fout.write(line)\\n\\nAny number of context manager items may be listed, and multiple items work the same\\nas nested with statements. In Pythons that support this, the following code:\\n\\nwith A() as a, B() as b:\\n    ...statements...\\n\\nis equivalent to the following, which also works in 3.0 and 2.6:\\n\\nwith A() as a:\\n    with B() as b:\\n        ...statements...\\n\\nPython 3.1’s release notes have additional details, but here’s a quick look at the exten-\\nsion  in  action—to  implement  a  parallel  lines  scan  of  two  files,  the  following  uses\\nwith to open two files at once and zip together their lines, without having to manually\\nclose when finished (assuming manual closes are required):\\n\\n>>> with open(\\'script1.py\\') as f1, open(\\'script2.py\\') as f2:\\n...     for pair in zip(f1, f2):\\n...         print(pair)\\n...\\n(\\'# A first Python script\\\\n\\', \\'import sys\\\\n\\')\\n(\\'import sys                  # Load a library module\\\\n\\', \\'print(sys.path)\\\\n\\')\\n(\\'print(sys.platform)\\\\n\\', \\'x = 2\\\\n\\')\\n(\\'print(2 ** 32)              # Raise 2 to a power\\\\n\\', \\'print(x ** 32)\\\\n\\')\\n\\nYou might use this coding structure to do a line-by-line comparison of two text files,\\nfor example—replace the print with an if for a simple file comparison operation, and\\nuse enumerate for line numbers:\\n\\nwith open(\\'script1.py\\') as f1, open(\\'script2.py\\') as f2:\\n    for (linenum, (line1, line2)) in enumerate(zip(f1, f2)):\\n        if line1 != line2:\\n            print(\\'%s\\\\n%r\\\\n%r\\' % (linenum, line1, line2))\\n\\nStill, the preceding technique isn’t all that useful in CPython, because input file objects\\ndon’t require a buffer flush, and file objects are closed automatically when reclaimed\\nif still open. In CPython, the files would be reclaimed immediately if the parallel scan\\nwere coded the following simpler way:\\n\\nfor pair in zip(open(\\'script1.py\\'), open(\\'script2.py\\')):   # Same effect, auto close\\n    print(pair)\\n\\n1118 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0cOn the other hand, alternative implementations such as PyPy and Jython may require\\nmore  direct  closure  inside  loops  to  avoid  taxing  system  resources,  due  to  differing\\ngarbage collectors. Even more usefully, the following automatically closes the output\\nfile on statement exit, to ensure that any buffered text is transferred to disk immediately:\\n\\n>>> with open(\\'script2.py\\') as fin, open(\\'upper.py\\', \\'w\\') as fout:\\n...     for line in fin:\\n...         fout.write(line.upper())\\n...\\n>>> print(open(\\'upper.py\\').read())\\nIMPORT SYS\\nPRINT(SYS.PATH)\\nX = 2\\nPRINT(X ** 32)\\n\\nIn both cases, we can instead simply open files in individual statements and close after\\nprocessing if needed, and in some scripts we probably should—there’s no point in using\\nstatements that catch an exception if it means your program is out of business anyhow!\\n\\nfin  = open(\\'script2.py\\')\\nfout = open(\\'upper.py\\', \\'w\\')\\nfor line in fin:                        # Same effect as preceding code, auto close\\n    fout.write(line.upper())\\n\\nHowever, in cases where programs must continue after exceptions, the with forms also\\nimplicitly catch exceptions, and thereby also avoid a try/finally in cases where close\\nis required. The equivalent without with is more explicit, but requires noticeably more\\ncode:\\n\\nfin  = open(\\'script2.py\\')\\nfout = open(\\'upper.py\\', \\'w\\')\\ntry:                                    # Same effect but explicit close on error\\n    for line in fin:\\n        fout.write(line.upper())\\nfinally:\\n    fin.close()\\n    fout.close()\\n\\nOn the other hand, the try/finally is a single tool that applies to all finalization cases,\\nwhereas the with adds a second tool that can be more concise, but applies to only certain\\nobjects types, and doubles the required knowledge base of programmers. As usual,\\nyou’ll have to weigh the tradeoffs for yourself.\\n\\nChapter Summary\\nIn this chapter, we took a more detailed look at exception processing by exploring the\\nstatements related to exceptions in Python: try to catch them, raise to trigger them,\\nassert to raise them conditionally, and with to wrap code blocks in context managers\\nthat specify entry and exit actions.\\n\\nChapter Summary | 1119\\n\\n\\x0cUp to this point, exceptions probably seem like a fairly lightweight tool, and in fact,\\nthey are; the only substantially complex thing about them is how they are identified.\\nThe next chapter continues our exploration by describing how to implement exception\\nobjects of your own; as you’ll see, classes allow you to code new exceptions specific to\\nyour programs. Before we move ahead, though, let’s work through the following short\\nquiz on the basics covered here.\\n\\nTest Your Knowledge: Quiz\\n1. What is the try statement for?\\n2. What are the two common variations of the try statement?\\n3. What is the raise statement for?\\n4. What is the assert statement designed to do, and what other statement is it like?\\n5. What is the with/as statement designed to do, and what other statement is it like?\\n\\nTest Your Knowledge: Answers\\n1. The try statement catches and recovers from exceptions—it specifies a block of\\ncode to run, and one or more handlers for exceptions that may be raised during\\nthe block’s execution.\\n\\n2. The two common variations on the try statement are try/except/else (for catching\\nexceptions)  and  try/finally  (for  specifying  cleanup  actions  that  must  occur\\nwhether an exception is raised or not). Through Python 2.4, these were separate\\nstatements that could be combined by syntactic nesting; in 2.5 and later, except\\nand finally blocks may be mixed in the same statement, so the two statement\\nforms are merged. In the merged form, the finally is still run on the way out of\\nthe try, regardless of what exceptions may have been raised or handled. In fact,\\nthe merged form is equivalent to nesting a try/except/else in a try/finally, and\\nthe two still have logically distinct roles.\\n\\n3. The raise statement raises (triggers) an exception. Python raises built-in excep-\\ntions on errors internally, but your scripts can trigger built-in or user-defined ex-\\nceptions with raise, too.\\n\\n4. The assert statement raises an AssertionError exception if a condition is false. It\\nworks like a conditional raise statement wrapped up in an if statement, and can\\nbe disabled with a –O switch.\\n\\n5. The with/as statement is designed to automate startup and termination activities\\nthat must occur around a block of code. It is roughly like a try/finally statement\\nin that its exit actions run whether an exception occurred or not, but it allows a\\nricher object-based protocol for specifying entry and exit actions, and may reduce\\n\\n1120 | Chapter 34:\\u2002Exception Coding Details\\n\\n\\x0ccode size. Still, it’s not quite as general, as it applies only to objects that support \\nits protocol; try handles many more use cases.\\n\\nTest Your Knowledge: Answers\\n\\n| 1121\\n\\n\\x0c\\x0cCHAPTER 35\\nException Objects\\n\\nSo far, I’ve been deliberately vague about what an exception actually is. As suggested\\nin the prior chapter, as of Python 2.6 and 3.0 both built-in and user-defined exceptions\\nare identified by class instance objects. This is what is raised and propagated along by\\nexception processing, and the source of the class matched against exceptions named\\nin try statements.\\nAlthough this means you must use object-oriented programming to define new excep-\\ntions in your programs—and introduces a knowledge dependency that deferred full\\nexception coverage to this part of the book—basing exceptions on classes and OOP\\noffers a number of benefits. Among them, class-based exceptions:\\n\\n• Can be organized into categories. Exceptions coded as classes support future\\nchanges by providing categories—adding new exceptions in the future won’t gen-\\nerally require changes in try statements.\\n\\n• Have state information and behavior. Exception classes provide a natural place\\nfor us to store context information and tools for use in the try handler—instances\\nhave access to both attached state information and callable methods.\\n\\n• Support inheritance. Class-based exceptions can participate in inheritance hier-\\narchies to obtain and customize common behavior—inherited display methods,\\nfor example, can provide a common look and feel for error messages.\\n\\nBecause of these advantages, class-based exceptions support program evolution and\\nlarger systems well. As we’ll find, all built-in exceptions are identified by classes and\\nare organized into an inheritance tree, for the reasons just listed. You can do the same\\nwith user-defined exceptions of your own.\\nIn fact, in Python 3.X the built-in exceptions we’ll study here turn out to be integral to\\nnew exceptions you define. Because 3.X requires user-defined exceptions to inherit\\nfrom built-in exception superclasses that provide useful defaults for printing and state\\nretention, the task of coding user-defined exceptions also involves understanding the\\nroles of these built-ins.\\n\\n1123\\n\\n\\x0cVersion skew note: Python 2.6, 3.0, and later require exceptions to be\\ndefined by classes. In addition, 3.X requires exception classes to be de-\\nrived from the BaseException built-in exception superclass, either di-\\nrectly or indirectly. As we’ll see, most programs inherit from this class’s\\nException subclass, to support catchall handlers for normal exception\\ntypes—naming it in a handler will thus catch everything most programs\\nshould. Python 2.X allows standalone classic classes to serve as excep-\\ntions, too, but it requires new-style classes to be derived from built-in\\nexception classes, the same as 3.X.\\n\\nExceptions: Back to the Future\\nOnce upon a time (well, prior to Python 2.6 and 3.0), it was possible to define excep-\\ntions in two different ways. This complicated try statements, raise statements, and\\nPython in general. Today, there is only one way to do it. This is a good thing: it removes\\nfrom the language substantial cruft accumulated for the sake of backward compatibil-\\nity. Because the old way helps explain why exceptions are as they are today, though,\\nand because it’s not really possible to completely erase the history of something that\\nhas been used by on the order of a million people over the course of nearly two decades,\\nlet’s begin our exploration of the present with a brief look at the past.\\n\\nString Exceptions Are Right Out!\\nPrior to Python 2.6 and 3.0, it was possible to define exceptions with both class in-\\nstances and string objects. String-based exceptions began issuing deprecation warnings\\nin 2.5 and were removed in 2.6 and 3.0, so today you should use class-based exceptions,\\nas shown in this book. If you work with legacy code, though, you might still come\\nacross string exceptions. They might also appear in books, tutorials, and web resources\\nwritten a few years ago (which qualifies as an eternity in Python years!).\\nString exceptions were straightforward to use—any string would do, and they matched\\nby object identity, not value (that is, using is, not ==):\\n\\nC:\\\\code> C:\\\\Python25\\\\python\\n>>> myexc = \"My exception string\"                 # Were we ever this young?...\\n>>> try:\\n...     raise myexc\\n... except myexc:\\n...     print(\\'caught\\')\\n...\\ncaught\\n\\nThis form of exception was removed because it was not as good as classes for larger\\nprograms and code maintenance. In modern Pythons, string exceptions trigger excep-\\ntions instead:\\n\\nC:\\\\code> py −3\\n>>> raise \\'spam\\'\\n\\n1124 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cTypeError: exceptions must derive from BaseException\\n\\nC:\\\\code> py −2\\n>>> raise \\'spam\\'\\nTypeError: exceptions must be old-style classes or derived from BaseException, ...etc\\n\\nAlthough you can’t use string exceptions today, they actually provide a natural vehicle\\nfor introducing the class-based exceptions model.\\n\\nClass-Based Exceptions\\nStrings were a simple way to define exceptions. As described earlier, however, classes\\nhave some added advantages that merit a quick look. Most prominently, they allow us\\nto identify exception categories that are more flexible to use and maintain than simple\\nstrings. Moreover, classes naturally allow for attached exception details and support\\ninheritance. Because they are seen by many as the better approach, they are now re-\\nquired.\\nCoding details aside, the chief difference between string and class exceptions has to do\\nwith the way that exceptions raised are matched against except clauses in try state-\\nments:\\n\\n• String exceptions were matched by simple object identity: the raised exception was\\n\\nmatched to except clauses by Python’s is test.\\n\\n• Class  exceptions  are  matched  by  superclass  relationships:  the  raised  exception\\nmatches an except clause if that except clause names the exception instance’s class\\nor any superclass of it.\\n\\nThat is, when a try statement’s except clause lists a superclass, it catches instances of\\nthat superclass, as well as instances of all its subclasses lower in the class tree. The net\\neffect is that class exceptions naturally support the construction of exception hierar-\\nchies: superclasses become category names, and subclasses become specific kinds of\\nexceptions  within  a  category.  By  naming  a  general  exception  superclass,  an  except\\nclause  can  catch  an  entire  category  of  exceptions—any  more  specific  subclass  will\\nmatch.\\nString exceptions had no such concept: because they were matched by simple object\\nidentity, there was no direct way to organize exceptions into more flexible categories\\nor groups. The net result was that exception handlers were coupled with exception sets\\nin a way that made changes difficult.\\nIn addition to this category idea, class-based exceptions better support exception state\\ninformation (attached to instances) and allow exceptions to participate in inheritance\\nhierarchies (to obtain common behaviors). Because they offer all the benefits of classes\\nand  OOP  in  general,  they  provide  a  more  powerful  alternative  to  the  now-defunct\\nstring-based exceptions model in exchange for a small amount of additional code.\\n\\nExceptions: Back to the Future | 1125\\n\\n\\x0cCoding Exceptions Classes\\nLet’s look at an example to see how class exceptions translate to code. In the following\\nfile, classexc.py, we define a superclass called General and two subclasses called Spe\\ncific1 and Specific2. This example illustrates the notion of exception categories—\\nGeneral is a category name, and its two subclasses are specific types of exceptions within\\nthe category. Handlers that catch General will also catch any subclasses of it, including\\nSpecific1 and Specific2:\\n\\nclass General(Exception): pass\\nclass Specific1(General): pass\\nclass Specific2(General): pass\\n\\ndef raiser0():\\n    X = General()          # Raise superclass instance\\n    raise X\\n\\ndef raiser1():\\n    X = Specific1()        # Raise subclass instance\\n    raise X\\n\\ndef raiser2():\\n    X = Specific2()        # Raise different subclass instance\\n    raise X\\n\\nfor func in (raiser0, raiser1, raiser2):\\n    try:\\n        func()\\n    except General:        # Match General or any subclass of it\\n        import sys\\n        print(\\'caught: %s\\' % sys.exc_info()[0])\\n\\nC:\\\\code> python classexc.py\\ncaught: <class \\'__main__.General\\'>\\ncaught: <class \\'__main__.Specific1\\'>\\ncaught: <class \\'__main__.Specific2\\'>\\n\\nThis code is mostly straightforward, but here are a few points to notice:\\n\\nException superclass\\n\\nClasses used to build exception category trees have very few requirements—in fact,\\nin this example they are mostly empty, with bodies that do nothing but pass. No-\\ntice, though, how the top-level class here inherits from the built-in Exception class.\\nThis is required in Python 3.X; Python 2.X allows standalone classic classes to serve\\nas exceptions too, but it requires new-style classes to be derived from built-in ex-\\nception classes just as in 3.X. Although we don’t employ it here, because Excep\\ntion provides some useful behavior we’ll meet later, it’s a good idea to inherit from\\nit in either Python.\\n\\nRaising instances\\n\\nIn this code, we call classes to make instances for the raise statements. In the class\\nexception model, we always raise and catch a class instance object. If we list a class\\n\\n1126 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cname without parentheses in a raise, Python calls the class with no constructor\\nargument to make an instance for us. Exception instances can be created before\\nthe raise, as done here, or within the raise statement itself.\\n\\nCatching categories\\n\\nThis code includes functions that raise instances of all three of our classes as ex-\\nceptions, as well as a top-level  try that calls the functions and catches  General\\nexceptions. The same try also catches the two specific exceptions, because they\\nare subclasses of General—members of its category.\\n\\nException details\\n\\nThe exception handler here uses the sys.exc_info call—as we’ll see in more detail\\nin the next chapter, it’s how we can grab hold of the most recently raised exception\\nin a generic fashion. Briefly, the first item in its result is the class of the exception\\nraised, and the second is the actual instance raised. In a general except clause like\\nthe one here that catches all classes in a category, sys.exc_info is one way to de-\\ntermine exactly what’s occurred. In this particular case, it’s equivalent to fetching\\nthe  instance’s  __class__  attribute.  As  we’ll  see  in  the  next  chapter,  the\\nsys.exc_info scheme is also commonly used with empty except clauses that catch\\neverything.\\n\\nThe last point merits further explanation. When an exception is caught, we can be sure\\nthat the instance raised is an instance of the class listed in the except, or one of its more\\nspecific subclasses. Because of this, the __class__ attribute of the instance also gives\\nthe exception type. The following variant in classexc2.py, for example, works the same\\nas the prior example—it uses the as extension in its except clause to assign a variable\\nto the instance actually raised:\\n\\nclass General(Exception): pass\\nclass Specific1(General): pass\\nclass Specific2(General): pass\\n\\ndef raiser0(): raise General()\\ndef raiser1(): raise Specific1()\\ndef raiser2(): raise Specific2()\\n\\nfor func in (raiser0, raiser1, raiser2):\\n    try:\\n        func()\\n    except General as X:                     # X is the raised instance\\n        print(\\'caught: %s\\' % X.__class__)    # Same as sys.exc_info()[0]\\n\\nBecause __class__ can be used like this to determine the specific type of exception\\nraised, sys.exc_info is more useful for empty except clauses that do not otherwise have\\na way to access the instance or its class. Furthermore, more realistic programs usually\\nshould not have to care about which specific exception was raised at all—by calling\\nmethods of the exception class instance generically, we automatically dispatch to be-\\nhavior tailored for the exception raised.\\n\\nExceptions: Back to the Future | 1127\\n\\n\\x0cMore on this and sys.exc_info in the next chapter; also see Chapter 29 and Part VI at\\nlarge if you’ve forgotten what __class__ means in an instance, and the prior chapter\\nfor a review of the as used here.\\n\\nWhy Exception Hierarchies?\\nBecause  there  are  only  three  possible  exceptions  in  the  prior  section’s  example,  it\\ndoesn’t really do justice to the utility of class exceptions. In fact, we could achieve the\\nsame effects by coding a list of exception names in parentheses within the except clause:\\n\\ntry:\\n    func()\\nexcept (General, Specific1, Specific2):     # Catch any of these\\n    ...\\n\\nThis approach worked for the defunct string exception model too. For large or high\\nexception hierarchies, however, it may be easier to catch categories using class-based\\ncategories than to list every member of a category in a single except clause. Perhaps\\nmore importantly, you can extend exception hierarchies as software needs evolve by\\nadding new subclasses without breaking existing code.\\nSuppose, for example, you code a numeric programming library in Python, to be used\\nby a large number of people. While you are writing your library, you identify two things\\nthat can go wrong with numbers in your code—division by zero, and numeric overflow.\\nYou document these as the two standalone exceptions that your library may raise:\\n\\n# mathlib.py\\n\\nclass Divzero(Exception): pass\\nclass Oflow(Exception): pass\\n\\ndef func():\\n    ...\\n    raise Divzero()\\n\\n...and so on...\\n\\nNow, when people use your library, they typically wrap calls to your functions or classes\\nin try statements that catch your two exceptions; after all, if they do not catch your\\nexceptions, exceptions from your library will kill their code:\\n\\n# client.py\\n\\nimport mathlib\\n\\ntry:\\n    mathlib.func(...)\\nexcept (mathlib.Divzero, mathlib.Oflow):\\n    ...handle and recover...\\n\\n1128 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cThis works fine, and lots of people start using your library. Six months down the road,\\nthough, you revise it (as programmers are prone to do!). Along the way, you identify a\\nnew thing that can go wrong—underflow, perhaps—and add that as a new exception:\\n\\n# mathlib.py\\n\\nclass Divzero(Exception): pass\\nclass Oflow(Exception): pass\\nclass Uflow(Exception): pass\\n\\nUnfortunately, when you re-release your code, you create a maintenance problem for\\nyour users. If they’ve listed your exceptions explicitly, they now have to go back and\\nchange every place they call your library to include the newly added exception name:\\n\\n# client.py\\n\\ntry:\\n    mathlib.func(...)\\nexcept (mathlib.Divzero, mathlib.Oflow, mathlib.Uflow):\\n    ...handle and recover...\\n\\nThis may not be the end of the world. If your library is used only in-house, you can\\nmake the changes yourself. You might also ship a Python script that tries to fix such\\ncode automatically (it would probably be only a few dozen lines, and it would guess\\nright at least some of the time). If many people have to change all their try statements\\neach time you alter your exception set, though, this is not exactly the most polite of\\nupgrade policies.\\nYour users might try to avoid this pitfall by coding empty except clauses to catch all\\npossible exceptions:\\n\\n# client.py\\n\\ntry:\\n    mathlib.func(...)\\nexcept:                           # Catch everything here (or catch Exception super)\\n    ...handle and recover...\\n\\nBut this workaround might catch more than they bargained for—things like running\\nout of memory, keyboard interrupts (Ctrl-C), system exits, and even typos in their own\\ntry block’s code will all trigger exceptions, and such things should pass, not be caught\\nand erroneously classified as library errors. Catching the Exception super class improves\\non this, but still intercepts—and thus may mask—program errors.\\nAnd really, in this scenario users want to catch and recover from only the specific ex-\\nceptions the library is defined and documented to raise. If any other exception occurs\\nduring a library call, it’s likely a genuine bug in the library (and probably time to contact\\nthe vendor!). As a rule of thumb, it’s usually better to be specific than general in ex-\\nception handlers—an idea we’ll revisit as a “gotcha” in the next chapter.1\\n\\nWhy Exception Hierarchies?\\n\\n| 1129\\n\\n\\x0cSo what to do, then? Class exception hierarchies fix this dilemma completely. Rather\\nthan defining your library’s exceptions as a set of autonomous classes, arrange them\\ninto a class tree with a common superclass to encompass the entire category:\\n\\n# mathlib.py\\n\\nclass NumErr(Exception): pass\\nclass Divzero(NumErr): pass\\nclass Oflow(NumErr): pass\\n\\ndef func():\\n    ...\\n    raise DivZero()\\n\\n...and so on...\\n\\nThis way, users of your library simply need to list the common superclass (i.e., category)\\nto catch all of your library’s exceptions, both now and in the future:\\n\\n# client.py\\n\\nimport mathlib\\n\\ntry:\\n    mathlib.func(...)\\nexcept mathlib.NumErr:\\n    ...report and recover...\\n\\nWhen you go back and hack (update) your code again, you can add new exceptions as\\nnew subclasses of the common superclass:\\n\\n# mathlib.py\\n\\n...\\nclass Uflow(NumErr): pass\\n\\nThe end result is that user code that catches your library’s exceptions will keep working,\\nunchanged. In fact, you are free to add, delete, and change exceptions arbitrarily in the\\nfuture—as long as clients name the superclass, and that superclass remains intact, they\\nare insulated from changes in your exceptions set. In other words, class exceptions\\nprovide a better answer to maintenance issues than strings could.\\nClass-based exception hierarchies also support state retention and inheritance in ways\\nthat make them ideal in larger programs. To understand these roles, though, we first\\n\\n1. As a clever student of mine suggested, the library module could also provide a tuple object that contains\\nall the exceptions the library can possibly raise—the client could then import the tuple and name it in an\\nexcept clause to catch all the library’s exceptions (recall that including a tuple in an except means catch\\nany of its exceptions). When new exceptions are added later, the library can just expand the exported\\ntuple. This would work, but you’d still need to keep the tuple up-to-date with raised exceptions inside\\nthe library module. Also, class hierarchies offer more benefits than just categories—they also support\\ninherited state and methods and a customization model that individual exceptions do not.\\n\\n1130 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cneed to see how user-defined exception classes relate to the built-in exceptions from\\nwhich they inherit.\\n\\nBuilt-in Exception Classes\\nI didn’t really pull the prior section’s examples out of thin air. All built-in exceptions\\nthat Python itself may raise are predefined class objects. Moreover, they are organized\\ninto a shallow hierarchy with general superclass categories and specific subclass types,\\nmuch like the prior section’s exceptions class tree.\\nIn Python 3.X, all the familiar exceptions you’ve seen (e.g., SyntaxError) are really just\\npredefined classes, available as built-in names in the module named builtins; in Python\\n2.X,  they  instead  live  in  __builtin__  and  are  also  attributes  of  the  standard  library\\nmodule exceptions. In addition, Python organizes the built-in exceptions into a hier-\\narchy, to support a variety of catching modes. For example:\\n\\nBaseException: topmost root, printing and constructor defaults\\n\\nThe top-level root superclass of exceptions. This class is not supposed to be directly\\ninherited by user-defined classes (use Exception instead). It provides default print-\\ning and state retention behavior inherited by subclasses. If the str built-in is called\\non an instance of this class (e.g., by print), the class returns the display strings of\\nthe constructor arguments passed when the instance was created (or an empty\\nstring if there were no arguments). In addition, unless subclasses replace this class’s\\nconstructor, all of the arguments passed to this class at instance construction time\\nare stored in its args attribute as a tuple.\\n\\nException: root of user-defined exceptions\\n\\nThe top-level root superclass of application-related exceptions. This is an imme-\\ndiate subclass of BaseException and is a superclass to every other built-in exception,\\nexcept the system exit event classes (SystemExit, KeyboardInterrupt, and Genera\\ntorExit). Nearly all user-defined classes should inherit from this class, not BaseEx\\nception. When this convention is followed, naming Exception in a try statement’s\\nhandler ensures that your program will catch everything but system exit events,\\nwhich should normally be allowed to pass. In effect, Exception becomes a catchall\\nin try statements and is more accurate than an empty except.\\n\\nArithmeticError: root of numeric errors\\n\\nA subclass of Exception, and the superclass of all numeric errors. Its subclasses\\nidentify specific numeric errors: OverflowError, ZeroDivisionError, and Floating\\nPointError.\\n\\nLookupError: root of indexing errors\\n\\nA subclass of Exception, and the superclass category for indexing errors for both\\nsequences  and  mappings—IndexError  and  KeyError—as  well  as  some  Unicode\\nlookup errors.\\n\\nBuilt-in Exception Classes\\n\\n| 1131\\n\\n\\x0cAnd so on—because the built-in exception set is prone to frequent changes, this book\\ndoesn’t document it exhaustively. You can read further about this structure in reference\\ntexts such as Python Pocket Reference or the Python library manual. In fact, the excep-\\ntions class tree differs slightly between Python 3.X and 2.X in ways we’ll omit here,\\nbecause they are not relevant to examples.\\nYou can also see the built-in exceptions class tree in the help text of the exceptions\\nmodule in Python 2.X only (see Chapter 4 and Chapter 15 for help on help):\\n\\n>>> import exceptions\\n>>> help(exceptions)\\n...lots of text omitted...\\n\\nThis module is removed in 3.X, where you’ll find up-to-date help in the other resources\\nmentioned.\\n\\nBuilt-in Exception Categories\\nThe built-in class tree allows you to choose how specific or general your handlers will\\nbe. For example, because the built-in exception  ArithmeticError is a superclass for\\nmore specific exceptions such as OverflowError and ZeroDivisionError:\\n\\n• By listing ArithmeticError in a try, you will catch any kind of numeric error raised.\\n• By listing ZeroDivisionError, you will intercept just that specific type of error, and\\n\\nno others.\\n\\nSimilarly,  because  Exception  is  the  superclass  of  all  application-level  exceptions  in\\nPython 3.X, you can generally use it as a catchall—the effect is much like an empty\\nexcept,  but  it  allows  system  exit  exceptions  to  pass  and  propagate  as  they  usually\\nshould:\\ntry:\\n    action()\\nexcept Exception:                                       # Exits not caught here\\n    ...handle all application exceptions...\\nelse:\\n    ...handle no-exception case...\\n\\nThis doesn’t quite work universally in Python 2.X, however, because standalone user-\\ndefined exceptions coded as classic classes are not required to be subclasses of the\\nException root class. This technique is more reliable in Python 3.X, since it requires all\\nclasses to derive from built-in exceptions. Even in Python 3.X, though, this scheme\\nsuffers most of the same potential pitfalls as the empty except, as described in the prior\\nchapter—it might intercept exceptions intended for elsewhere, and it might mask gen-\\nuine programming errors. Since this is such a common issue, we’ll revisit it as a “gotcha”\\nin the next chapter.\\n\\n1132 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cWhether or not you will leverage the categories in the built-in class tree, it serves as a\\ngood example; by using similar techniques for class exceptions in your own code, you\\ncan provide exception sets that are flexible and easily modified.\\n\\nPython 3.3 reworks the built-in IO and OS exception hierarchies. It adds\\nnew specific exception classes corresponding to common file and system\\nerror numbers, and groups these and others related to operating system\\ncalls under the OSError category superclass. Former exception names\\nare retained for backward compatibility.\\n\\nPrior to this, programs inspect the data attached to the exception in-\\nstance to see what specific error occurred, and possibly reraise others to\\nbe propagated (the errno module has names preset to the error codes\\nfor convenience, and the error number is available in both the generic\\ntuple as V.args[0] and attribute V.errno):\\n\\nc:\\\\temp> py −3.2\\n>>> try:\\n...     f = open(\\'nonesuch.txt\\')\\n... except IOError as V:\\n...     if V.errno == 2:                # Or errno.N, V.args[0]\\n...         print(\\'No such file\\')\\n...     else:\\n...         raise                       # Propagate others\\n...\\nNo such file\\n\\nThis code still works in 3.3, but with the new classes, programs in 3.3\\nand later can be more specific about the exceptions they mean to pro-\\ncess, and ignore others:\\n\\nc:\\\\temp> py −3.3\\n>>> try:\\n...     f = open(\\'nonesuch.txt\\')\\n... except FileNotFoundError:\\n...     print(\\'No such file\\')\\n...\\nNo such file\\n\\nFor full details on this extension and its classes, see the other resources\\nlisted earlier.\\n\\nDefault Printing and State\\nBuilt-in exceptions also provide default print displays and state retention, which is often\\nas much logic as user-defined classes require. Unless you redefine the constructors your\\nclasses  inherit  from  them,  any  constructor  arguments  you  pass  to  these  classes  are\\nautomatically saved in the instance’s args tuple attribute, and are automatically dis-\\nplayed when the instance is printed. An empty tuple and display string are used if no\\nconstructor arguments are passed, and a single argument displays as itself (not as a\\ntuple).\\n\\nBuilt-in Exception Classes\\n\\n| 1133\\n\\n\\x0cThis  explains  why  arguments  passed  to  built-in  exception  classes  show  up  in  error\\nmessages—any constructor arguments are attached to the instance and displayed when\\nthe instance is printed:\\n\\n>>> raise IndexError                    # Same as IndexError(): no arguments\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nIndexError\\n\\n>>> raise IndexError(\\'spam\\')            # Constructor argument attached, printed\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nIndexError: spam\\n\\n>>> I = IndexError(\\'spam\\')              # Available in object attribute\\n>>> I.args\\n(\\'spam\\',)\\n>>> print(I)                            # Displays args when printed manually\\nspam\\n\\nThe same holds true for user-defined exceptions in Python 3.X (and for new-style classes\\nin 2.X), because they inherit the constructor and display methods present in their built-\\nin superclasses:\\n\\n>>> class E(Exception): pass\\n...\\n>>> raise E\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.E\\n\\n>>> raise E(\\'spam\\')\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.E: spam\\n\\n>>> I = E(\\'spam\\')\\n>>> I.args\\n(\\'spam\\',)\\n>>> print(I)\\nspam\\n\\nWhen intercepted in a try statement, the exception instance object gives access to both\\nthe original constructor arguments and the display method:\\n\\n>>> try:\\n...     raise E(\\'spam\\')\\n... except E as X:\\n...     print(X)                        # Displays and saves constructor arguments\\n...     print(X.args)\\n...     print(repr(X))\\n...\\nspam\\n(\\'spam\\',)\\nE(\\'spam\\',)\\n\\n1134 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0c>>> try:                                # Multiple arguments save/display a tuple\\n...     raise E(\\'spam\\', \\'eggs\\', \\'ham\\')\\n... except E as X:\\n...     print(\\'%s %s\\' % (X, X.args))\\n...\\n(\\'spam\\', \\'eggs\\', \\'ham\\') (\\'spam\\', \\'eggs\\', \\'ham\\')\\n\\nNote that exception instance objects are not strings themselves, but use the __str__\\noperator overloading protocol we studied in Chapter 30 to provide display strings when\\nprinted; to concatenate with real strings, perform manual conversions: str(X) + \\'as\\ntr\\', \\'%s\\' % X, and the like.\\nAlthough this automatic state and display support is useful by itself, for more specific\\ndisplay and state retention needs you can always redefine inherited methods such as\\n__str__ and __init__ in Exception subclasses—as the next section shows.\\n\\nCustom Print Displays\\nAs we saw in the preceding section, by default, instances of class-based exceptions\\ndisplay whatever you passed to the class constructor when they are caught and printed:\\n\\n>>> class MyBad(Exception): pass\\n...\\n>>> try:\\n...     raise MyBad(\\'Sorry--my mistake!\\')\\n... except MyBad as X:\\n...     print(X)\\n...\\nSorry--my mistake!\\n\\nThis inherited default display model is also used if the exception is displayed as part of\\nan error message when the exception is not caught:\\n\\n>>> raise MyBad(\\'Sorry--my mistake!\\')\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.MyBad: Sorry--my mistake!\\n\\nFor many roles, this is sufficient. To provide a more custom display, though, you can\\ndefine one of two string-representation overloading methods in your class (__repr__ or\\n__str__) to return the string you want to display for your exception. The string the\\nmethod returns will be displayed if the exception either is caught and printed or reaches\\nthe default handler:\\n\\n>>> class MyBad(Exception):\\n...     def __str__(self):\\n...         return \\'Always look on the bright side of life...\\'\\n...\\n>>> try:\\n...     raise MyBad()\\n... except MyBad as X:\\n...     print(X)\\n\\nCustom Print Displays\\n\\n| 1135\\n\\n\\x0c...\\nAlways look on the bright side of life...\\n\\n>>> raise MyBad()\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n__main__.MyBad: Always look on the bright side of life...\\n\\nWhatever your method returns is included in error messages for uncaught exceptions\\nand  used  when  exceptions  are  printed  explicitly.  The  method  returns  a  hardcoded\\nstring here to illustrate, but it can also perform arbitrary text processing, possibly using\\nstate information attached to the instance object. The next section looks at state in-\\nformation options.\\n\\nA subtle point here: you generally must redefine __str__ for exception\\ndisplay purposes, because the built-in exception superclasses already\\nhave a __str__ method, and __str__ is preferred to __repr__ in some\\ncontexts—including error message displays. If you define a __repr__,\\nprinting will happily call the built-in superclass’s __str__ instead!\\n\\n>>> class E(Exception):\\n        def __repr__(self): return \\'Not called!\\'\\n>>> raise E(\\'spam\\')\\n...\\n__main__.E: spam\\n\\n>>> class E(Exception):\\n        def __str__(self): return \\'Called!\\'\\n>>> raise E(\\'spam\\')\\n...\\n__main__.E: Called!\\n\\nSee Chapter 30 for more details on these special operator overloading\\nmethods.\\n\\nCustom Data and Behavior\\nBesides supporting flexible hierarchies, exception classes also provide storage for extra\\nstate information as instance attributes. As we saw earlier, built-in exception super-\\nclasses provide a default constructor that automatically saves constructor arguments\\nin an instance tuple attribute named args. Although the default constructor is adequate\\nfor many cases, for more custom needs we can provide a constructor of our own. In\\naddition, classes may define methods for use in handlers that provide precoded excep-\\ntion processing logic.\\n\\nProviding Exception Details\\nWhen an exception is raised, it may cross arbitrary file boundaries—the raise state-\\nment that triggers an exception and the try statement that catches it may be in com-\\npletely different module files. It is not generally feasible to store extra details in global\\n\\n1136 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cvariables because the try statement might not know which file the globals reside in.\\nPassing extra state information along in the exception itself allows the try statement\\nto access it more reliably.\\nWith  classes,  this  is  nearly  automatic.  As  we’ve  seen,  when  an  exception  is  raised,\\nPython passes the class instance object along with the exception. Code in try statements\\ncan access the raised instance by listing an extra variable after the as keyword in an\\nexcept handler. This provides a natural hook for supplying data and behavior to the\\nhandler.\\nFor example, a program that parses data files might signal a formatting error by raising\\nan exception instance that is filled out with extra details about the error:\\n\\n>>> class FormatError(Exception):\\n        def __init__(self, line, file):\\n            self.line = line\\n            self.file = file\\n\\n>>> def parser():\\n        raise FormatError(42, file=\\'spam.txt\\')     # When error  found\\n\\n>>> try:\\n...     parser()\\n... except FormatError as X:\\n...     print(\\'Error at: %s %s\\' % (X.file, X.line))\\n...\\nError at: spam.txt 42\\n\\nIn the except clause here, the variable X is assigned a reference to the instance that was\\ngenerated when the exception was raised. This gives access to the attributes attached\\nto the instance by the custom constructor. Although we could rely on the default state\\nretention of built-in superclasses, it’s less relevant to our application (and doesn’t sup-\\nport the keyword arguments used in the prior example):\\n\\n>>> class FormatError(Exception): pass             # Inherited constructor\\n\\n>>> def parser():\\n        raise FormatError(42, \\'spam.txt\\')          # No keywords allowed!\\n\\n>>> try:\\n...     parser()\\n... except FormatError as X:\\n...     print(\\'Error at:\\', X.args[0], X.args[1])   # Not specific to this app\\n...\\nError at: 42 spam.txt\\n\\nProviding Exception Methods\\nBesides enabling application-specific state information, custom constructors also better\\nsupport extra behavior for exception objects. That is, the exception class can also define\\nmethods to be called in the handler. The following code in excparse.py, for example,\\nadds a method that uses exception state information to log errors to a file automatically:\\n\\nCustom Data and Behavior\\n\\n| 1137\\n\\n\\x0cfrom __future__ import print_function  # 2.X compatibility\\n\\nclass FormatError(Exception):\\n    logfile = \\'formaterror.txt\\'\\n    def __init__(self, line, file):\\n        self.line = line\\n        self.file = file\\n    def logerror(self):\\n        log = open(self.logfile, \\'a\\')\\n        print(\\'Error at:\\', self.file, self.line, file=log)\\n\\ndef parser():\\n    raise FormatError(40, \\'spam.txt\\')\\n\\nif __name__ == \\'__main__\\':\\n    try:\\n        parser()\\n    except FormatError as exc:\\n        exc.logerror()\\n\\nWhen run, this script writes its error message to a file in response to method calls in\\nthe exception handler:\\n\\nc:\\\\code> del formaterror.txt\\nc:\\\\code> py −3 excparse.py\\nc:\\\\code> py −2 excparse.py\\nc:\\\\code> type formaterror.txt\\nError at: spam.txt 40\\nError at: spam.txt 40\\n\\nIn such a class, methods (like logerror) may also be inherited from superclasses, and\\ninstance attributes (like line and file) provide a place to save state information that\\nprovides extra context for use in later method calls. Moreover, exception classes are\\nfree to customize and extend inherited behavior:\\n\\nclass CustomFormatError(FormatError):\\n    def logerror(self):\\n        ...something unique here...\\n\\nraise CustomFormatError(...)\\n\\nIn other words, because they are defined with classes, all the benefits of OOP that we\\nstudied in Part VI are available for use with exceptions in Python.\\nTwo final notes here: first, the raised instance object assigned to exc in this code is also\\navailable generically as the second item in the result tuple of the sys.exc_info() call—\\na tool that returns information about the most recently raised exception. This interface\\nmust be used if you do not list an exception name in an except clause but still need\\naccess to the exception that occurred, or to any of its attached state information or\\nmethods. Second, although our class’s logerror method appends a custom message to\\na logfile, it could also generate Python’s standard error message with stack trace using\\ntools in the traceback standard library module, which uses traceback objects.\\n\\n1138 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cTo learn more about sys.exc_info and tracebacks, though, we need to move ahead to\\nthe next chapter.\\n\\nChapter Summary\\nIn this chapter, we explored coding user-defined exceptions. As we learned, exceptions\\nare implemented as class instance objects as of Python 2.6 and 3.0 (an earlier string-\\nbased exception model alternative was available in earlier releases but has now been\\ndeprecated). Exception classes support the concept of exception hierarchies that ease\\nmaintenance,  allow  data  and  behavior  to  be  attached  to  exceptions  as  instance  at-\\ntributes and methods, and allow exceptions to inherit data and behavior from super-\\nclasses.\\nWe saw that in a try statement, catching a superclass catches that class as well as all\\nsubclasses below it in the class tree—superclasses become exception category names,\\nand subclasses become more specific exception types within those categories. We also\\nsaw that the built-in exception superclasses we must inherit from provide usable de-\\nfaults for printing and state retention, which we can override if desired.\\nThe next chapter wraps up this part of the book by exploring some common use cases\\nfor exceptions and surveying tools commonly used by Python programmers. Before we\\nget there, though, here’s this chapter’s quiz.\\n\\nTest Your Knowledge: Quiz\\n1. What are the two new constraints on user-defined exceptions in Python 3.X?\\n2. How are raised class-based exceptions matched to handlers?\\n3. Name two ways that you can attach context information to exception objects.\\n4. Name two ways that you can specify the error message text for exception objects.\\n5. Why should you not use string-based exceptions anymore today?\\n\\nTest Your Knowledge: Answers\\n1. In 3.X, exceptions must be defined by classes (that is, a class instance object is\\nraised and caught). In addition, exception classes must be derived from the built-\\nin class BaseException; most programs inherit from its Exception subclass, to sup-\\nport catchall handlers for normal kinds of exceptions.\\n\\n2. Class-based exceptions match by superclass relationships: naming a superclass in\\nan exception handler will catch instances of that class, as well as instances of any\\nof its subclasses lower in the class tree. Because of this, you can think of superclasses\\nas general exception categories and subclasses as more specific types of exceptions\\nwithin those categories.\\n\\nTest Your Knowledge: Answers\\n\\n| 1139\\n\\n\\x0c3. You can attach context information to class-based exceptions by filling out instance\\nattributes in the instance object raised, usually in a custom class constructor. For\\nsimpler needs, built-in exception superclasses provide a constructor that stores its\\narguments on the instance automatically (as a tuple in the attribute args). In ex-\\nception handlers, you list a variable to be assigned to the raised instance, then go\\nthrough this name to access attached state information and call any methods de-\\nfined in the class.\\n\\n4. The error message text in class-based exceptions can be specified with a custom\\n__str__ operator overloading method. For simpler needs, built-in exception su-\\nperclasses automatically display anything you pass to the class constructor. Oper-\\nations like print and str automatically fetch the display string of an exception\\nobject when it is printed either explicitly or as part of an error message.\\n\\n5. Because Guido said so—they have been removed as of both Python 2.6 and 3.0.\\nThere are arguably good reasons for this: string-based exceptions did not support\\ncategories, state information, or behavior inheritance in the way class-based ex-\\nceptions do. In practice, this made string-based exceptions easier to use at first\\nwhen programs were small, but more complex to use as programs grew larger.\\nThe downsides of requiring exceptions to be classes are to break existing code, and\\ncreate a forward  knowledge dependency—beginners must first learn classes and\\nOOP before they can code new exceptions, or even truly understand exceptions at\\nall. In fact, this is why this relatively straightforward topic was largely postponed\\nuntil this point in the book. For better or worse, such dependencies are not un-\\ncommon in Python today (see the preface and conclusion for more on such things).\\n\\n1140 | Chapter 35:\\u2002Exception Objects\\n\\n\\x0cCHAPTER 36\\nDesigning with Exceptions\\n\\nThis chapter rounds out this part of the book with a collection of exception design\\ntopics and common use case examples, followed by this part’s gotchas and exercises.\\nBecause this chapter also closes out the fundamentals portion of the book at large, it\\nincludes a brief overview of development tools as well to help you as you make the\\nmigration from Python beginner to Python application developer.\\n\\nNesting Exception Handlers\\nMost of our examples so far have used only a single try to catch exceptions, but what\\nhappens if one try is physically nested inside another? For that matter, what does it\\nmean if a try calls a function that runs another try? Technically, try statements can\\nnest, in terms of both syntax and the runtime control flow through your code. I’ve\\nmentioned this briefly, but let’s clarify the idea here.\\nBoth of these cases can be understood if you realize that Python stacks try statements\\nat runtime. When an exception is raised, Python returns to the most recently entered\\ntry  statement  with  a  matching  except  clause.  Because  each  try  statement  leaves  a\\nmarker, Python can jump back to earlier trys by inspecting the stacked markers. This\\nnesting of active handlers is what we mean when we talk about propagating exceptions\\nup to “higher” handlers—such handlers are simply try statements entered earlier in\\nthe program’s execution flow.\\nFigure 36-1 illustrates what occurs when try statements with except clauses nest at\\nruntime. The amount of code that goes into a try block can be substantial, and it may\\ncontain function calls that invoke other code watching for the same exceptions. When\\nan  exception  is  eventually  raised,  Python  jumps  back  to  the  most  recently  entered\\ntry statement that names that exception, runs that statement’s except clause, and then\\nresumes execution after that try.\\nOnce the exception is caught, its life is over—control does not jump back to all match-\\ning  trys  that  name  the  exception;  only  the  first  (i.e.,  most  recent)  one  is  given  the\\nopportunity to handle it. In Figure 36-1, for instance, the raise statement in the func-\\n\\n1141\\n\\n\\x0cFigure 36-1. Nested try/except statements: when an exception is raised (by you or by Python), control\\njumps back to the most recently entered try statement with a matching except clause, and the program\\nresumes after that try statement. except clauses intercept and stop the exception—they are where you\\nprocess and recover from exceptions.\\n\\nFigure 36-2. Nested try/finally statements: when an exception is raised here, control returns to the\\nmost recently entered try to run its finally statement, but then the exception keeps propagating to all\\nfinallys in all active try statements and eventually reaches the default top-level handler, where an\\nerror message is printed. finally clauses intercept (but do not stop) an exception—they are for actions\\nto be performed “on the way out.”\\n\\ntion func2 sends control back to the handler in func1, and then the program continues\\nwithin func1.\\nBy contrast, when try statements that contain only finally clauses are nested, each\\nfinally block is run in turn when an exception occurs—Python continues propagating\\nthe exception up to other trys, and eventually perhaps to the top-level default handler\\n(the standard error message printer). As Figure 36-2 illustrates, the finally clauses do\\nnot kill the exception—they just specify code to be run on the way out of each try\\nduring the exception propagation process. If there are many try/finally clauses active\\nwhen an exception occurs, they will all be run, unless a try/except catches the exception\\nsomewhere along the way.\\nIn other words, where the program goes when an exception is raised depends entirely\\nupon where it has been—it’s a function of the runtime flow of control through the script,\\nnot just its syntax. The propagation of an exception essentially proceeds backward\\nthrough time to try statements that have been entered but not yet exited. This propa-\\ngation stops as soon as control is unwound to a matching except clause, but not as it\\npasses through finally clauses on the way.\\n\\n1142 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cExample: Control-Flow Nesting\\nLet’s turn to an example to make this nesting concept more concrete. The following\\nmodule file, nestexc.py, defines two functions. action2 is coded to trigger an exception\\n(you can’t add numbers and sequences), and action1 wraps a call to action2 in a try\\nhandler, to catch the exception:\\n\\ndef action2():\\n    print(1 + [])            # Generate TypeError\\n\\ndef action1():\\n    try:\\n        action2()\\n    except TypeError:        # Most recent matching try\\n        print(\\'inner try\\')\\n\\ntry:\\n    action1()\\nexcept TypeError:            # Here, only if action1 re-raises\\n    print(\\'outer try\\')\\n\\n% python nestexc.py\\ninner try\\n\\nNotice, though, that the top-level module code at the bottom of the file wraps a call to\\naction1 in a try handler, too. When action2 triggers the TypeError exception, there will\\nbe two active try statements—the one in action1, and the one at the top level of the\\nmodule file. Python picks and runs just the most recent try with a matching except—\\nwhich in this case is the try inside action1.\\nAgain, the place where an exception winds up jumping to depends on the control flow\\nthrough the program at runtime. Because of this, to know where you will go, you need\\nto know where you’ve been. In this case, where exceptions are handled is more a func-\\ntion of control flow than of statement syntax. However, we can also nest exception\\nhandlers syntactically—an equivalent case we turn to next.\\n\\nExample: Syntactic Nesting\\nAs I mentioned when we looked at the new unified try/except/finally statement in\\nChapter 34, it is possible to nest try statements syntactically by their position in your\\nsource code:\\n\\ntry:\\n    try:\\n        action2()\\n    except TypeError:        # Most recent matching try\\n        print(\\'inner try\\')\\nexcept TypeError:            # Here, only if nested handler re-raises\\n    print(\\'outer try\\')\\n\\nNesting Exception Handlers\\n\\n| 1143\\n\\n\\x0cReally, though, this code just sets up the same handler-nesting structure as (and behaves\\nidentically to) the prior example. In fact, syntactic nesting works just like the cases\\nsketched in Figure 36-1 and Figure 36-2. The only difference is that the nested handlers\\nare physically embedded in a try block, not coded elsewhere in functions that are called\\nfrom  the  try  block.  For  example,  nested  finally  handlers  all  fire  on  an  exception,\\nwhether they are nested syntactically or by means of the runtime flow through physi-\\ncally separated parts of your code:\\n\\n>>> try:\\n...     try:\\n...         raise IndexError\\n...     finally:\\n...         print(\\'spam\\')\\n... finally:\\n...     print(\\'SPAM\\')\\n...\\nspam\\nSPAM\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 3, in <module>\\nIndexError\\n\\nSee Figure 36-2 for a graphic illustration of this code’s operation; the effect is the same,\\nbut the function logic has been inlined as nested statements here. For a more useful\\nexample of syntactic nesting at work, consider the following file, except-finally.py:\\n\\ndef raise1():  raise IndexError\\ndef noraise(): return\\ndef raise2():  raise SyntaxError\\n\\nfor func in (raise1, noraise, raise2):\\n    print(\\'<%s>\\' % func.__name__)\\n    try:\\n        try:\\n            func()\\n        except IndexError:\\n            print(\\'caught IndexError\\')\\n    finally:\\n        print(\\'finally run\\')\\n    print(\\'...\\')\\n\\nThis code catches an exception if one is raised and performs a finally termination-\\ntime action regardless of whether an exception occurs. This may take a few moments\\nto digest, but the effect is the same as combining an except and a finally clause in a\\nsingle try statement in Python 2.5 and later:\\n\\n% python except-finally.py\\n<raise1>\\ncaught IndexError\\nfinally run\\n...\\n<noraise>\\nfinally run\\n...\\n\\n1144 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0c<raise2>\\nfinally run\\nTraceback (most recent call last):\\n  File \"except-finally.py\", line 9, in <module>\\n    func()\\n  File \"except-finally.py\", line 3, in raise2\\n    def raise2():  raise SyntaxError\\nSyntaxError: None\\n\\nAs we saw in Chapter 34, as of Python 2.5, except and finally clauses can be mixed\\nin the same try statement. This, along with multiple except clause support, makes some\\nof the syntactic nesting described in this section unnecessary, though the equivalent\\nruntime nesting is common in larger Python programs. Moreover, syntactic nesting still\\nworks today, may still appear in code written prior to Python 2.5 that you may en-\\ncounter, can make the disjoint roles of except and finally more explicit, and can be\\nused as a technique for implementing alternative exception-handling behaviors in gen-\\neral.\\n\\nException Idioms\\nWe’ve seen the mechanics behind exceptions. Now let’s take a look at some of the other\\nways they are typically used.\\n\\nBreaking Out of Multiple Nested Loops: “go to”\\nAs mentioned at the start of this part of the book, exceptions can often be used to serve\\nthe same roles as other languages’ “go to” statements to implement more arbitrary\\ncontrol transfers. Exceptions, however, provide a more structured option that localizes\\nthe jump to a specific block of nested code.\\nIn this role, raise is like “go to,” and except clauses and exception names take the place\\nof program labels. You can jump only out of code wrapped in a try this way, but that’s\\na crucial feature—truly arbitrary “go to” statements can make code extraordinarily\\ndifficult to understand and maintain.\\nFor example, Python’s break statement exits just the single closest enclosing loop, but\\nwe can always use exceptions to break out of more than one loop level if needed:\\n\\n>>> class Exitloop(Exception): pass\\n...\\n>>> try:\\n...     while True:\\n...         while True:\\n...             for i in range(10):\\n...                  if i > 3: raise Exitloop          # break exits just one level\\n...                  print(\\'loop3: %s\\' % i)\\n...             print(\\'loop2\\')\\n...         print(\\'loop1\\')\\n... except Exitloop:\\n...     print(\\'continuing\\')                            # Or just pass, to move on \\n\\nException Idioms\\n\\n| 1145\\n\\n\\x0c...\\nloop3: 0\\nloop3: 1\\nloop3: 2\\nloop3: 3\\ncontinuing\\n>>> i\\n4\\n\\nIf you change the raise in this to break, you’ll get an infinite loop, because you’ll break\\nonly out of the most deeply nested for loop, and wind up in the second-level loop\\nnesting. The code would then print “loop2” and start the for again.\\nAlso notice that variable i is still what it was after the try statement exits. Variable\\nassignments made in a try are not undone in general, though as we’ve seen, exception\\ninstance variables listed in except clause headers are localized to that clause, and the\\nlocal variables of any functions that are exited as a result of a  raise are discarded.\\nTechnically, active functions’ local variables are popped off the call stack and the ob-\\njects they reference may be garbage-collected as a result, but this is an automatic step.\\n\\nExceptions Aren’t Always Errors\\nIn Python, all errors are exceptions, but not all exceptions are errors. For instance, we\\nsaw in Chapter 9 that file object read methods return an empty string at the end of a\\nfile. In contrast, the built-in input function—which we first met in Chapter 3, deployed\\nin an interactive loop in Chapter 10, and learned is named raw_input in 2.X—reads a\\nline of text from the standard input stream, sys.stdin, at each call and raises the built-\\nin EOFError at end-of-file.\\nUnlike file methods, this function does not return an empty string—an empty string\\nfrom input means an empty line. Despite its name, though, the EOFError exception is\\njust a signal in this context, not an error. Because of this behavior, unless the end-of-\\nfile should terminate a script, input often appears wrapped in a try handler and nested\\nin a loop, as in the following code:\\n\\nwhile True:\\n    try:\\n        line = input()           # Read line from stdin (raw_input in 2.X)\\n    except EOFError:\\n        break                    # Exit loop at end-of-file\\n    else:\\n        ...process next line here...\\n\\nSeveral other built-in exceptions are similarly signals, not errors—for example, calling\\nsys.exit() and pressing Ctrl-C on your keyboard raise SystemExit and KeyboardInter\\nrupt, respectively.\\nPython also has a set of built-in exceptions that represent warnings rather than errors;\\nsome of these are used to signal use of deprecated (phased out) language features. See\\nthe standard library manual’s description of built-in exceptions for more information,\\n\\n1146 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cand consult the warnings module’s documentation for more on exceptions raised as\\nwarnings.\\n\\nFunctions Can Signal Conditions with raise\\nUser-defined exceptions can also signal nonerror conditions. For instance, a search\\nroutine can be coded to raise an exception when a match is found instead of returning\\na status flag for the caller to interpret. In the following, the try/except/else exception\\nhandler does the work of an if/else return-value tester:\\n\\nclass Found(Exception): pass\\n\\ndef searcher():\\n    if ...success...:\\n        raise Found()            # Raise exceptions instead of returning flags\\n    else:\\n        return\\n\\ntry:\\n    searcher()\\nexcept Found:                    # Exception if item was found\\n    ...success...\\nelse:                            # else returned: not found\\n    ...failure...\\n\\nMore generally, such a coding structure may also be useful for any function that cannot \\nreturn a sentinel value to designate success or failure. In a widely applicable function,\\nfor instance, if all objects are potentially valid return values, it’s impossible for any\\nreturn value to signal a failure condition. Exceptions provide a way to signal results\\nwithout a return value:\\n\\nclass Failure(Exception): pass\\n\\ndef searcher():\\n    if ...success...:\\n        return ...founditem...\\n    else:\\n        raise Failure()\\n\\ntry:\\n    item = searcher()\\nexcept Failure:\\n    ...not found...\\nelse:\\n    ...use item here...\\n\\nBecause Python is dynamically typed and polymorphic to the core, exceptions, rather\\nthan sentinel return values, are the generally preferred way to signal such conditions.\\n\\nException Idioms\\n\\n| 1147\\n\\n\\x0cClosing Files and Server Connections\\nWe encountered examples in this category in Chapter 34. As a summary, though, ex-\\nception processing tools are also commonly used to ensure that system resources are\\nfinalized, regardless of whether an error occurs during processing or not.\\nFor example, some servers require connections to be closed in order to terminate a\\nsession. Similarly, output files may require close calls to flush their buffers to disk for\\nwaiting consumers, and input files may consume file descriptors if not closed; although\\nfile objects are automatically closed when garbage-collected if still open, in some Py-\\nthons it may be difficult to be sure when that will occur.\\nAs we saw in Chapter 34, the most general and explicit way to guarantee termination\\nactions for a specific block of code is the try/finally statement:\\n\\nmyfile = open(r\\'C:\\\\code\\\\textdata\\', \\'w\\')\\ntry:\\n    ...process myfile...\\nfinally:\\n    myfile.close()\\n\\nAs we also saw, some objects make this potentially easier in Python 2.6, 3.0, and later\\nby providing context managers that terminate or close the objects for us automatically\\nwhen run by the with/as statement:\\n\\nwith open(r\\'C:\\\\code\\\\textdata\\', \\'w\\') as myfile:\\n    ...process myfile...\\n\\nSo which option is better here? As usual, it depends on your programs. Compared to\\nthe traditional try/finally, context managers are more implicit, which runs contrary\\nto Python’s general design philosophy. Context managers are also arguably less general\\n—they are available only for select objects, and writing user-defined context managers\\nto handle general termination requirements is more complex than coding a try/finally.\\nOn the other hand, using existing context managers requires less code than using try/\\nfinally, as shown by the preceding examples. Moreover, the context manager protocol\\nsupports entry actions in addition to exit actions. In fact, it can save a line of code when\\nno exceptions are expected at all (albeit at the expense of further nesting and indenting\\nfile processing logic):\\n\\nmyfile = open(filename, \\'w\\')      # Traditional form\\n...process myfile...\\nmyfile.close()\\n\\nwith open(filename) as myfile:    # Context manager form\\n    ...process myfile...\\n\\nStill, the implicit exception processing of with makes it more directly comparable to\\nthe explicit exception handling of try/finally. Although try/finally is the more widely\\napplicable  technique,  context  managers  may  be  preferable  where  they  are  already\\navailable, or where their extra complexity is warranted.\\n\\n1148 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cDebugging with Outer try Statements\\nYou can also make use of exception handlers to replace Python’s default top-level ex-\\nception-handling behavior. By wrapping an entire program (or a call to it) in an outer\\ntry in your top-level code, you can catch any exception that may occur while your\\nprogram runs, thereby subverting the default program termination.\\nIn the following, the empty except clause catches any uncaught exception raised while\\nthe program runs. To get hold of the actual exception that occurred in this mode, fetch\\nthe sys.exc_info function call result from the built-in sys module; it returns a tuple\\nwhose first two items contain the current exception’s class and the instance object\\nraised (more on sys.exc_info in a moment):\\n\\ntry:\\n    ...run program...\\nexcept:                         # All uncaught exceptions come here\\n    import sys\\n    print(\\'uncaught!\\', sys.exc_info()[0], sys.exc_info()[1])\\n\\nThis structure is commonly used during development, to keep programs active even\\nafter errors occur—within a loop, it allows you to run additional tests without having\\nto restart. It’s also used when testing other program code, as described in the next\\nsection.\\n\\nOn  a  related  note,  for  more  about  handling  program  shutdowns\\nwithout recovery from them, see also Python’s atexit standard library\\nmodule.  It’s  also  possible  to  customize  what  the  top-level  exception\\nhandler  does  with  sys.excepthook.  These  and  other  related  tools  are\\ndescribed in Python’s library manual.\\n\\nRunning In-Process Tests\\nSome  of  the  coding  patterns  we’ve  just  looked  at  can  be  combined  in  a  test-driver\\napplication that tests other code within the same process. The following partial code\\nsketches the general model:\\n\\nimport sys\\nlog = open(\\'testlog\\', \\'a\\')\\nfrom testapi import moreTests, runNextTest, testName\\ndef testdriver():\\n    while moreTests():\\n        try:\\n            runNextTest()\\n        except:\\n            print(\\'FAILED\\', testName(), sys.exc_info()[:2], file=log)\\n        else:\\n            print(\\'PASSED\\', testName(), file=log)\\ntestdriver()\\n\\nException Idioms\\n\\n| 1149\\n\\n\\x0cThe testdriver function here cycles through a series of test calls (the module testapi\\nis left abstract in this example). Because an uncaught exception in a test case would\\nnormally kill this test driver, you need to wrap test case calls in a try if you want to\\ncontinue the testing process after a test fails. The empty except catches any uncaught\\nexception generated by a test case as usual, and it uses sys.exc_info to log the exception\\nto a file. The else clause is run when no exception occurs—the test success case.\\nSuch boilerplate code is typical of systems that test functions, modules, and classes by\\nrunning them in the same process as the test driver. In practice, however, testing can\\nbe much more sophisticated than this. For instance, to test external programs, you could\\ninstead check status codes or outputs generated by program-launching tools such as\\nos.system and os.popen, used earlier in this book and covered in the standard library\\nmanual. Such tools do not generally raise exceptions for errors in the external programs\\n—in fact, the test cases may run in parallel with the test driver.\\nAt the end of this chapter, we’ll also briefly meet more complete testing frameworks\\nprovided by Python, such as doctest and PyUnit, which provide tools for comparing\\nexpected outputs with actual results.\\n\\nMore on sys.exc_info\\nThe sys.exc_info result used in the last two sections allows an exception handler to\\ngain access to the most recently raised exception generically. This is especially useful\\nwhen using the empty except clause to catch everything blindly, to determine what was\\nraised:\\n\\ntry:\\n    ...\\nexcept:\\n    # sys.exc_info()[0:2] are the exception class and instance\\n\\nIf no exception is being handled, this call returns a tuple containing three None values.\\nOtherwise, the values returned are (type, value, traceback), where:\\n\\n• type is the exception class of the exception being handled.\\n• value is the exception class instance that was raised.\\n• traceback is a traceback object that represents the call stack at the point where the\\nexception originally occurred, and used by the traceback module to generate error\\nmessages.\\n\\nAs we saw in the prior chapter, sys.exc_info can also sometimes be useful to determine\\nthe specific exception type when catching exception category superclasses. As we’ve\\nalso learned, though, because in this case you can also get the exception type by fetching\\nthe __class__ attribute of the instance obtained with the as clause, sys.exc_info is often\\nredundant apart from the empty except:\\n\\ntry:\\n    ...\\n\\n1150 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cexcept General as instance:\\n    # instance.__class__ is the exception class\\n\\nAs we’ve seen, using Exception for the General exception name here would catch all\\nnonexit exceptions, similar to an empty except but less extreme, and still giving access\\nto the exception instance and its class. Even so, using the instance object’s interfaces\\nand polymorphism is often a better approach than testing exception types—exception\\nmethods can be defined per class and run generically:\\n\\ntry:\\n    ...\\nexcept General as instance:\\n    # instance.method() does the right thing for this instance\\n\\nAs usual, being too specific in Python can limit your code’s flexibility. A polymorphic\\napproach like the last example here generally supports future evolution better than\\nexplicitly type-specific tests or actions.\\n\\nDisplaying Errors and Tracebacks\\nFinally, the exception traceback object available in the prior section’s  sys.exc_info\\nresult is also used by the standard library’s traceback module to generate the standard\\nerror message and stack display manually. This file has a handful of interfaces that\\nsupport wide customization, which we don’t have space to cover usefully here, but the\\nbasics are simple. Consider the following aptly named file, badly.py:\\n\\nimport traceback\\n\\ndef inverse(x):\\n    return 1 / x\\n\\ntry:\\n    inverse(0)\\nexcept Exception:\\n    traceback.print_exc(file=open(\\'badly.exc\\', \\'w\\'))\\nprint(\\'Bye\\')\\n\\nThis code uses the print_exc convenience function in the traceback module, which\\nuses sys.exc_info data by default; when run, the script prints the error message to a\\nfile—handy in testing programs that need to catch errors but still record them in full:\\n\\nc:\\\\code> python badly.py\\nBye\\n\\nc:\\\\code> type badly.exc\\nTraceback (most recent call last):\\n  File \"badly.py\", line 7, in <module>\\n    inverse(0)\\n  File \"badly.py\", line 4, in inverse\\n    return 1 / x\\nZeroDivisionError: division by zero\\n\\nException Idioms\\n\\n| 1151\\n\\n\\x0cFor much more on traceback objects, the traceback module that uses them, and related\\ntopics, consult other reference resources and manuals.\\n\\nVersion  skew  note:  In  Python  2.X,  the  older  tools  sys.exc_type  and\\nsys.exc_value still work to fetch the most recent exception type and\\nvalue, but they can manage only a single, global exception for the entire\\nprocess. These two names have been removed in Python 3.X. The newer\\nand preferred sys.exc_info() call available in both 2.X and 3.X instead\\nkeeps track of each thread’s exception information, and so is thread-\\nspecific. Of course, this distinction matters only when using multiple\\nthreads in Python programs (a subject beyond this book’s scope), but\\n3.X forces the issue. See other resources for more details.\\n\\nException Design Tips and Gotchas\\nI’m lumping design tips and gotchas together in this chapter, because it turns out that\\nthe most common gotchas largely stem from design issues. By and large, exceptions\\nare easy to use in Python. The real art behind them is in deciding how specific or general\\nyour except clauses should be and how much code to wrap up in try statements. Let’s\\naddress the second of these concerns first.\\n\\nWhat Should Be Wrapped\\nIn principle, you could wrap every statement in your script in its own try, but that\\nwould just be silly (the try statements would then need to be wrapped in try state-\\nments!). What to wrap is really a design issue that goes beyond the language itself, and\\nit will become more apparent with use. But for now, here are a few rules of thumb:\\n\\n• Operations that commonly fail should generally be wrapped in try statements. For\\nexample, operations that interface with system state (file opens, socket calls, and\\nthe like) are prime candidates for try.\\n\\n• However,  there  are  exceptions  to  the  prior  rule—in  a  simple  script,  you  may\\nwant failures of such operations to kill your program instead of being caught and\\nignored. This is especially true if the failure is a showstopper. Failures in Python\\ntypically result in useful error messages (not hard crashes), and this is the best\\noutcome some programs could hope for.\\n\\n• You should implement termination actions in try/finally statements to guarantee\\ntheir execution, unless a context manager is available as a with/as option. The try/\\nfinally statement form allows you to run code whether exceptions occur or not\\nin arbitrary scenarios.\\n\\n• It is sometimes more convenient to wrap the call to a large function in a single\\ntry statement, rather than littering the function itself with many try statements.\\n\\n1152 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cThat way, all exceptions in the function percolate up to the try around the call,\\nand you reduce the amount of code within the function.\\n\\nThe types of programs you write will probably influence the amount of exception han-\\ndling you code as well. Servers, for instance, must generally keep running persistently\\nand  so  will  likely  require  try  statements  to  catch  and  recover  from  exceptions.  In-\\nprocess testing programs of the kind we saw in this chapter will probably handle ex-\\nceptions as well. Simpler one-shot scripts, though, will often ignore exception handling\\ncompletely because failure at any step requires script shutdown.\\n\\nCatching Too Much: Avoid Empty except and Exception\\nAs mentioned, exception handler generality is a key design choice. Python lets you pick\\nand choose which exceptions to catch, but you sometimes have to be careful to not be\\ntoo inclusive. For example, you’ve seen that an empty except clause catches every ex-\\nception that might be raised while the code in the try block runs.\\nThat’s easy to code, and sometimes desirable, but you may also wind up intercepting\\nan error that’s expected by a try handler higher up in the exception nesting structure.\\nFor example, an exception handler such as the following catches and stops every ex-\\nception that reaches it, regardless of whether another handler is waiting for it:\\n\\ndef func():\\n    try:\\n        ...                      # IndexError is raised in here\\n    except:\\n        ...                      # But everything comes here and dies!\\ntry:\\n    func()\\nexcept IndexError:               # Exception should be processed here\\n    ...\\n\\nPerhaps worse, such code might also catch unrelated system exceptions. Even things\\nlike memory errors, genuine programming mistakes, iteration stops, keyboard inter-\\nrupts, and system exits raise exceptions in Python. Unless you’re writing a debugger or\\nsimilar tool, such exceptions should not usually be intercepted in your code.\\nFor example, scripts normally exit when control falls off the end of the top-level file.\\nHowever, Python also provides a built-in sys.exit(statuscode) call to allow early ter-\\nminations. This actually works by raising a built-in SystemExit exception to end the\\nprogram, so that try/finally handlers run on the way out and special types of programs\\ncan intercept the event.1 Because of this, a try with an empty except might unknowingly\\nprevent a crucial exit, as in the following file (exiter.py):\\n\\n1. A related call, os._exit, also ends a program, but via an immediate termination—it skips cleanup actions,\\nincluding  any  registered  with  the  atexit  module  noted  earlier,  and  cannot  be  intercepted  with  try/\\nexcept or try/finally blocks. It is usually used only in spawned child processes, a topic beyond this book’s\\nscope. See the library manual or follow-up texts for details.\\n\\nException Design Tips and Gotchas\\n\\n| 1153\\n\\n\\x0cimport sys\\ndef bye():\\n    sys.exit(40)                 # Crucial error: abort now!\\ntry:\\n    bye()\\nexcept:\\n    print(\\'got it\\')              # Oops--we ignored the exit\\nprint(\\'continuing...\\')\\n\\n% python exiter.py\\ngot it\\ncontinuing...\\n\\nYou simply might not expect all the kinds of exceptions that could occur during an\\noperation. Using the built-in exception classes of the prior chapter can help in this\\nparticular case, because the Exception superclass is not a superclass of SystemExit:\\n\\ntry:\\n    bye()\\nexcept Exception:                # Won\\'t catch exits, but _will_ catch many others\\n    ...\\n\\nIn other cases, though, this scheme is no better than an empty except clause—because\\nException is a superclass above all built-in exceptions except system-exit events, it still\\nhas the potential to catch exceptions meant for elsewhere in the program.\\nProbably worst of all, both using an empty except and catching the Exception superclass\\nwill also catch genuine programming errors, which should be allowed to pass most of\\nthe time. In fact, these two techniques can effectively turn off Python’s error-reporting\\nmachinery, making it difficult to notice mistakes in your code. Consider this code, for\\nexample:\\n\\nmydictionary = {...}\\n...\\ntry:\\n    x = myditctionary[\\'spam\\']    # Oops: misspelled\\nexcept:\\n    x = None                     # Assume we got KeyError\\n...continue here with x...\\n\\nThe coder here assumes that the only sort of error that can happen when indexing a\\ndictionary is a missing key error. But because the name myditctionary is misspelled (it\\nshould say mydictionary), Python raises a NameError instead for the undefined name\\nreference, which the handler will silently catch and ignore. The event handler will in-\\ncorrectly fill in a None default for the dictionary access, masking the program error.\\nMoreover, catching Exception here will not help—it would have the exact same effect\\nas an empty except, happily and silently filling in a default and masking a genuine\\nprogram error you will probably want to know about. If this happens in code that is\\nfar removed from the place where the fetched values are used, it might make for a very\\ninteresting debugging task!\\n\\n1154 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cAs a rule of thumb, be as specific in your handlers as you can be—empty except clauses\\nand Exception catchers are handy, but potentially error-prone. In the last example, for\\ninstance, you would be better off saying except KeyError: to make your intentions\\nexplicit and avoid intercepting unrelated events. In simpler scripts, the potential for\\nproblems might not be significant enough to outweigh the convenience of a catchall,\\nbut in general, general handlers are generally trouble.\\n\\nCatching Too Little: Use Class-Based Categories\\nOn the other hand, neither should handlers be too specific. When you list specific\\nexceptions in a try, you catch only what you actually list. This isn’t necessarily a bad\\nthing, but if a system evolves to raise other exceptions in the future, you may need to\\ngo back and add them to exception lists elsewhere in your code.\\nWe saw this phenomenon at work in the prior chapter. For instance, the following\\nhandler is written to treat MyExcept1 and MyExcept2 as normal cases and everything else\\nas an error. If you add a MyExcept3 in the future, though, it will be processed as an error\\nunless you update the exception list:\\n\\ntry:\\n    ...\\nexcept (MyExcept1, MyExcept2):   # Breaks if you add a MyExcept3 later\\n    ...                          # Nonerrors\\nelse:\\n    ...                          # Assumed to be an error\\n\\nLuckily, careful use of the class-based exceptions we discussed in Chapter 34 can make\\nthis code maintenance trap go away completely. As we saw, if you catch a general\\nsuperclass, you can add and raise more specific subclasses in the future without having\\nto extend except clause lists manually—the superclass becomes an extendible excep-\\ntions category:\\n\\ntry:\\n    ...\\nexcept SuccessCategoryName:      # OK if you add a MyExcept3 subclass later\\n    ...                          # Nonerrors\\nelse:\\n    ...                          # Assumed to be an error\\n\\nIn other words, a little design goes a long way. The moral of the story is to be careful\\nto be neither too general nor too specific in exception handlers, and to pick the gran-\\nularity of your try statement wrappings wisely. Especially in larger systems, exception\\npolicies should be a part of the overall design.\\n\\nCore Language Summary\\nCongratulations! This concludes your look at the fundamentals of the Python pro-\\ngramming language. If you’ve gotten this far, you’ve become a fully operational Python\\n\\nCore Language Summary | 1155\\n\\n\\x0cprogrammer. There’s more optional reading in the advanced topics part ahead that I’ll\\ndescribe in a moment. In terms of the essentials, though, the Python story—and this\\nbook’s main journey—is now complete.\\nAlong the way, you’ve seen just about everything there is to see in the language itself,\\nand in enough depth to apply to most of the code you are likely to encounter in the\\nopen source “wild.” You’ve studied built-in types, statements, and exceptions, as well\\nas tools used to build up the larger program units of functions, modules, and classes.\\nYou’ve also explored important software design issues, the complete OOP paradigm,\\nfunctional programing tools, program architecture concepts, alternative tool tradeoffs,\\nand more—compiling a skill set now qualified to be turned loose on the task of devel-\\noping real applications.\\n\\nThe Python Toolset\\nFrom this point forward, your future Python career will largely consist of becoming\\nproficient with the toolset available for application-level Python programming. You’ll\\nfind this to be an ongoing task. The standard library, for example, contains hundreds\\nof modules, and the public domain offers still more tools. It’s possible to spend decades\\nseeking proficiency with all these tools, especially as new ones are constantly appearing\\nto address new technologies (trust me on this—I’m at 20 years and counting!).\\nSpeaking generally, Python provides a hierarchy of toolsets:\\n\\nBuilt-ins\\n\\nBuilt-in types like strings, lists, and dictionaries make it easy to write simple pro-\\ngrams fast.\\n\\nPython extensions\\n\\nFor more demanding tasks, you can extend Python by writing your own functions,\\nmodules, and classes.\\n\\nCompiled extensions\\n\\nAlthough we don’t cover this topic in this book, Python can also be extended with\\nmodules written in an external language like C or C++.\\n\\nBecause Python layers its toolsets, you can decide how deeply your programs need to\\ndelve into this hierarchy for any given task—you can use built-ins for simple scripts,\\nadd Python-coded extensions for larger systems, and code compiled extensions for\\nadvanced work. We’ve only covered the first two of these categories in this book, and\\nthat’s plenty to get you started doing substantial programming in Python.\\nBeyond this, there are tools, resources, or precedents for using Python in nearly any\\ncomputer domain you can imagine. For pointers on where to go next, see Chapter 1’s\\noverview of Python applications and users. You’ll likely find that with a powerful open\\nsource language like Python, common tasks are often much easier, and even enjoyable,\\nthan you might expect.\\n\\n1156 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cDevelopment Tools for Larger Projects\\nMost of the examples in this book have been fairly small and self-contained. They were\\nwritten that way on purpose, to help you master the basics. But now that you know all\\nabout the core language, it’s time to start learning how to use Python’s built-in and\\nthird-party interfaces to do real work.\\nIn practice, Python programs can become substantially larger than the examples you’ve\\nexperimented with so far in this book. Even in Python, thousands of lines of code are\\nnot uncommon for nontrivial and useful programs, once you add up all the individual\\nmodules in the system. Though Python basic program structuring tools such as mod-\\nules and classes help much to manage this complexity, other tools can sometimes offer\\nadditional support.\\nFor developing larger systems, you’ll find such support available in both Python and\\nthe public domain. You’ve seen some of these in action, and I’ve mentioned a few\\nothers. To help you on your next steps, here is a quick tour and summary of some of\\nthe most commonly used tools in this domain:\\n\\nPyDoc and docstrings\\n\\nPyDoc’s help function and HTML interfaces were introduced in Chapter 15. PyDoc\\nprovides a documentation system for your modules and objects, integrates with \\nPython’s docstrings syntax, and is a standard part of the Python system. See Chap-\\nter 15 and Chapter 4 for more documentation source hints.\\n\\nPyChecker and PyLint\\n\\nBecause Python is such a dynamic language, some programming errors are not\\nreported until your program runs (even syntax errors are not caught until a file is\\nrun or imported). This isn’t a big drawback—as with most languages, it just means\\nthat you have to test your Python code before shipping it. At worst, with Python\\nyou essentially trade a compile phase for an initial testing phase. Furthermore,\\nPython’s dynamic nature, automatic error messages, and exception model make it\\neasier and quicker to find and fix errors than it is in some other languages. Unlike\\nC, for example, Python does not crash completely on errors.\\nStill, tools can help here too. The PyChecker and PyLint systems provide support\\nfor catching common errors ahead of time, before your script runs. They serve\\nsimilar roles to the lint program in C development. Some Python developers run\\ntheir code through PyChecker prior to testing or delivery, to catch any lurking\\npotential problems. In fact, it’s not a bad idea to try this when you’re first starting\\nout—some of these tools’ warnings may help you learn to spot and avoid common\\nPython  mistakes.  PyChecker  and  PyLint  are  third-party  open  source  packages,\\navailable at the PyPI website or your friendly neighborhood web search engine.\\nThey may appear in IDE GUIs as well.\\n\\nPyUnit (a.k.a. unittest)\\n\\nIn Chapter 25, we learned how to add self-test code to a Python file by using the\\n__name__ == \\'__main__\\' trick at the bottom of the file—a simple unit-testing pro-\\n\\nCore Language Summary | 1157\\n\\n\\x0ctocol. For more advanced testing purposes, Python comes with two testing support\\ntools. The first, PyUnit (called unittest in the library manual), provides an object-\\noriented class framework for specifying and customizing test cases and expected\\nresults. It mimics the JUnit framework for Java. This is a sophisticated class-based\\nunit testing system; see the Python library manual for details.\\n\\ndoctest\\n\\nThe doctest standard library module provides a second and simpler approach to\\nregression testing, based upon Python’s docstrings feature. Roughly, to use doct\\nest, you cut and paste a log of an interactive testing session into the docstrings of\\nyour source files. doctest then extracts your docstrings, parses out the test cases\\nand results, and reruns the tests to verify the expected results. doctest’s operation\\ncan be tailored in a variety of ways; see the library manual for more details.\\n\\nIDEs\\n\\nWe discussed IDEs for Python in Chapter 3. IDEs such as IDLE provide a graphical\\nenvironment  for  editing,  running,  debugging,  and  browsing  your  Python  pro-\\ngrams. Some advanced IDEs—such as Eclipse, Komodo, NetBeans, and others\\nlisted in Chapter 3—may support additional development tasks, including source\\ncontrol integration, code refactoring, project management tools, and more. See\\nChapter 3, the text editors page at http://www.python.org, and your favorite web\\nsearch engine for more on available IDEs and GUI builders for Python.\\n\\nProfilers\\n\\nBecause  Python  is  so  high-level  and  dynamic,  intuitions  about  performance\\ngleaned from experience with other languages usually don’t apply to Python code.\\nTo truly isolate performance bottlenecks in your code, you need to add timing logic\\nwith clock tools in the time or timeit modules, or run your code under the pro\\nfile module. We saw an example of the timing modules at work when comparing\\nthe speed of iteration tools and Pythons in Chapter 21.\\nProfiling is usually your first optimization step—code for clarity, then profile to\\nisolate bottlenecks, and then time alternative codings of the slow parts of your\\nprogram. For the second of these steps, profile is a standard library module that\\nimplements a source code profiler for Python. It runs a string of code you provide\\n(e.g., a script file import, or a call to a function) and then, by default, prints a report\\nto the standard output stream that gives performance statistics—number of calls\\nto each function, time spent in each function, and more.\\nThe profile module can be run as a script or imported, and it may be customized\\nin various ways; for example, it can save run statistics to a file to be analyzed later \\nwith the pstats module. To profile interactively, import the profile module and\\ncall profile.run(\\'code\\'), passing in the code you wish to profile as a string (e.g.,\\na call to a function, an import of a file, or code read from a file). To profile from a\\nsystem  shell  command  line,  use  a  command  of  the  form  python  -m  profile\\nmain.py args (see Appendix A for more on this format). Also see Python’s standard\\nlibrary manuals for other profiling options; the cProfile module, for example, has\\n\\n1158 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cidentical interfaces to profile but runs with less overhead, so it may be better suited\\nto profiling long-running programs.\\n\\nDebuggers\\n\\nWe also discussed debugging options in Chapter 3 (see its sidebar “Debugging\\nPython Code” on page 83). As a review, most development IDEs for Python support\\nGUI-based debugging, and the Python standard library also includes a source code\\ndebugger module called pdb. This module provides a command-line interface and\\nworks much like common C language debuggers (e.g., dbx, gdb).\\nMuch like the profiler, the pdb debugger can be run either interactively or from a\\ncommand line and can be imported and called from a Python program. To use it\\ninteractively, import the module, start running code by calling a pdb function (e.g.,\\npdb.run(\\'main()\\')), and then type debugging commands from pdb’s interactive\\nprompt. To launch pdb from a system shell command line, use a command of the\\nform python -m pdb main.py args. pdb also includes a useful postmortem analysis\\ncall, pdb.pm(), which starts the debugger after an exception has been encountered,\\npossibly in conjunction with Python’s -i flag. See Appendix A for more on these\\ntools.\\nBecause  IDEs  such  as  IDLE  also  include  point-and-click  debugging  interfaces,\\npdb isn’t as critical a tool today, except when a GUI isn’t available or when more\\ncontrol is desired. See Chapter 3 for tips on using IDLE’s debugging GUI interfaces.\\nReally, neither pdb nor IDEs seem to be used much in practice—as noted in Chap-\\nter 3, most programmers either insert print statements or simply read Python’s\\nerror messages: perhaps not the most high-tech of approaches, but the practical\\ntends to win the day in the Python world!\\n\\nShipping options\\n\\nIn  Chapter  2,  we  introduced  common  tools  for  packaging  Python  programs.\\npy2exe, PyInstaller, and others listed in that chapter can package byte code and\\nthe Python Virtual Machine into “frozen binary” standalone executables, which\\ndon’t require that Python be installed on the target machine and hide your system’s\\ncode. In addition, we learned in Chapter 2 that Python programs may be shipped\\nin  their  source  (.py)  or  byte  code  (.pyc)  forms,  and  that  import  hooks  support\\nspecial packaging techniques such as automatic extraction of .zip files and byte\\ncode encryption.\\nWe also briefly met the standard library’s distutils modules, which provide pack-\\naging options for Python modules and packages, and C-coded extensions; see the\\nPython manuals for more details. The emerging Python “eggs” third-party pack-\\naging  system  provides  another  alternative  that  also  accounts  for  dependencies;\\nsearch the Web for more details.\\n\\nOptimization options\\n\\nWhen speed counts, there are a handful of options for optimizing your programs.\\nThe PyPy system described in Chapter 2 provides a just-in-time compiler for trans-\\nlating Python byte code to binary machine code, and Shed Skin offers a Python-to-\\n\\nCore Language Summary | 1159\\n\\n\\x0cC++ translator. You may also occasionally see .pyo optimized byte code files, gen-\\nerated and run with the -O Python command-line flag discussed in Chapter 22 and\\nChapter 34, and to be deployed in Chapter 39; because this provides a very modest\\nperformance boost, however, it is not commonly used except to remove debugging\\ncode.\\nAs a last resort, you can also move parts of your program to a compiled language\\nsuch as C to boost performance. See the book Programming Python and the Python\\nstandard manuals for more on C extensions. In general, Python’s speed tends to\\nalso improve over time, so upgrading to later releases may improve speed too—\\nonce you verify that they are faster for your code, that is (though largely repaired\\nsince, Python 3.0’s initial release was up to 1000X slower than 2.X on some IO\\noperations!).\\n\\nOther hints for larger projects\\n\\nWe’ve met a variety of core language features in this text that will also tend to\\nbecome more useful once you start coding larger projects. These include module\\npackages (Chapter 24), class-based exceptions (Chapter 34), class pseudoprivate\\nattributes (Chapter 31), documentation strings (Chapter 15), module path con-\\nfiguration files (Chapter 22), hiding names from from * with __all__ lists and _X-\\nstyle names (Chapter 25), adding self-test code with the __name__ == \\'__main__\\'\\ntrick (Chapter 25), using common design rules for functions and modules (Chap-\\nter 17, Chapter 19, and Chapter 25), using object-oriented design patterns (Chap-\\nter 31 and others), and so on.\\n\\nTo learn about other large-scale Python development tools available in the public do-\\nmain, be sure to browse the pages at the PyPI website at http://www.python.org, and\\nthe Web at large. Applying Python is actually a larger topic than learning Python, and\\none we’ll have to delegate to follow-up resources here.\\n\\nChapter Summary\\nThis chapter wrapped up the exceptions part of the book with a survey of design con-\\ncepts, a look at common exception use cases, and a brief summary of commonly used\\ndevelopment tools.\\nThis chapter also wrapped up the core material of this book. At this point, you’ve been\\nexposed to the full subset of Python that most programmers use—and probably more.\\nIn fact, if you have read this far, you should feel free to consider yourself an official\\nPython programmer. Be sure to pick up a t-shirt or laptop sticker the next time you’re\\nonline (and don’t forget to add Python to your résumé the next time you dig it out).\\nThe next and final part of this book is a collection of chapters dealing with topics that\\nare advanced, but still in the core language category. These chapters are all optional\\nreading, or at least deferrable reading, because not every Python programmer must delve\\ninto their subjects, and others can postpone these chapters’ topics until they are needed.\\n\\n1160 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cIndeed, many of you can stop here and begin exploring Python’s roles in your appli-\\ncation domains. Frankly, application libraries tend to be more important in practice\\nthan advanced—and to some, esoteric—language features.\\nOn the other hand, if you do need to care about things like Unicode or binary data,\\nhave to deal with API-building tools such as descriptors, decorators, and metaclasses,\\nor just want to dig a bit further in general, the next part of the book will help you get\\nstarted. The larger examples in the final part will also give you a chance to see the\\nconcepts you’ve already learned being applied in more realistic ways.\\nAs this is the end of the core material of this book, though, you get a break on the\\nchapter quiz—just one question this time. As always, be sure to work through this\\npart’s closing exercises to cement what you’ve learned in the past few chapters; because\\nthe next part is optional reading, this is the final end-of-part exercises session. If you\\nwant to see some examples of how what you’ve learned comes together in real scripts\\ndrawn from common applications, be sure to check out the “solution” to exercise 4 in\\nAppendix D.\\nAnd if this is the end of your journey in this book, be sure to also see the “Bonus” section\\nat the end of Chapter 41, the very last chapter in this book (for the sake of readers\\ncontinuing on to the Advanced Topics part, I won’t spill the beans here).\\n\\nTest Your Knowledge: Quiz\\n1. (This question is a repeat from the first quiz in Chapter 1—see, I told you it would\\nbe easy! :-) Why does “spam” show up in so many Python examples in books and\\non the Web?\\n\\nTest Your Knowledge: Answers\\n1. Because Python is named after the British comedy group Monty Python (based on\\nsurveys I’ve conducted in classes, this is a much-too-well-kept secret in the Python\\nworld!). The spam reference comes from a Monty Python skit, set in a cafeteria\\nwhose menu items all seem to come with Spam. A couple trying to order food there\\nkeeps getting drowned out by a chorus of Vikings singing a song about Spam. No,\\nreally. And if I could insert an audio clip of that song here, I would...\\n\\nTest Your Knowledge: Part VII Exercises\\nAs we’ve reached the end of this part of the book, it’s time for a few exception exercises\\nto give you a chance to practice the basics. Exceptions really are simple tools; if you get\\nthese, you’ve probably mastered the exceptions domain. See Part VII in Appendix D\\nfor the solutions.\\n\\nTest Your Knowledge: Part VII Exercises\\n\\n| 1161\\n\\n\\x0c1. try/except. Write a function called oops that explicitly raises an IndexError excep-\\ntion when called. Then write another function that calls oops inside a try/except\\nstatement  to  catch  the  error.  What  happens  if  you  change  oops  to  raise  a\\nKeyError instead of an IndexError? Where do the names KeyError and IndexError\\ncome from? (Hint: recall that all unqualified names generally come from one of\\nfour scopes.)\\n\\n2. Exception objects and lists. Change the oops function you just wrote to raise an\\nexception you define yourself, called MyError. Identify your exception with a class\\n(unless you’re using Python 2.5 or earlier, you must). Then, extend the try state-\\nment in the catcher function to catch this exception and its instance in addition to\\nIndexError, and print the instance you catch.\\n\\n3. Error handling. Write a function called safe(func, *pargs, **kargs) that runs any\\nfunction with any number of positional and/or keyword arguments by using the\\n* arbitrary arguments header and call syntax, catches any exception raised while\\nthe function runs, and prints the exception using the exc_info call in the sys mod-\\nule. Then use your safe function to run your oops function from exercise 1 or 2.\\nPut safe in a module file called exctools.py, and pass it the oops function interac-\\ntively. What kind of error messages do you get? Finally, expand safe to also print\\na Python stack trace when an error occurs by calling the built-in print_exc function\\nin  the  standard  traceback  module;  see  earlier  in  this  chapter,  and  consult  the\\nPython library reference manual for usage details. We could probably code safe as\\na function decorator using Chapter 32 techniques, but we’ll have to move on to the\\nnext part of the book to learn fully how (see the solutions for a preview).\\n\\n4. Self-study examples. At the end of Appendix D, I’ve included a handful of example\\nscripts developed as group exercises in live Python classes for you to study and run\\non your own in conjunction with Python’s standard manual set. These are not\\ndescribed, and they use tools in the Python standard library that you’ll have to\\nresearch on your own. Still, for many readers, it helps to see how the concepts\\nwe’ve discussed in this book come together in real programs. If these whet your\\nappetite for more, you can find a wealth of larger and more realistic application-\\nlevel Python program examples in follow-up books like Programming Python and\\non the Web.\\n\\n1162 | Chapter 36:\\u2002Designing with Exceptions\\n\\n\\x0cPART VIII\\nAdvanced Topics\\n\\n\\x0c\\x0cCHAPTER 37\\nUnicode and Byte Strings\\n\\nSo far, our exploration of strings in this book has been deliberately incomplete. Chap-\\nter  4’s  types  preview  briefly  introduced  Python’s  Unicode  strings  and  files  without\\ngiving many details, and the strings chapter in the core types part of this book (Chap-\\nter  7)  deliberately  limited  its  scope  to  the  subset  of  string  topics  that  most  Python\\nprogrammers need to know about.\\nThis was by design: because many programmers, including most beginners, deal with\\nsimple forms of text like ASCII, they can happily work with Python’s basic str string\\ntype and its associated operations and don’t need to come to grips with more advanced\\nstring concepts. In fact, such programmers can often ignore the string changes in Python\\n3.X and continue to use strings as they may have in the past.\\nOn the other hand, many other programmers deal with more specialized types of data:\\nnon-ASCII character sets, image file contents, and so on. For those programmers, and\\nothers who may someday join them, in this chapter we’re going to fill in the rest of the\\nPython string story and look at some more advanced concepts in Python’s string model.\\nSpecifically, we’ll explore the basics of Python’s support for Unicode text—rich char-\\nacter strings used in internationalized applications—as well as binary data—strings\\nthat represent absolute byte values. As we’ll see, the advanced string representation\\nstory has diverged in recent versions of Python:\\n\\n• Python 3.X provides an alternative string type for binary data, and supports Uni-\\n\\ncode text (including ASCII) in its normal string type.\\n\\n• Python 2.X provides an alternative string type for non-ASCII Unicode text, and\\n\\nsupports both simple text and binary data in its normal string type.\\n\\nIn addition, because Python’s string model has a direct impact on how you process\\nnon-ASCII files, we’ll explore the fundamentals of that related topic here as well. Fi-\\nnally, we’ll take a brief look at some advanced string and binary tools, such as pattern\\nmatching, object pickling, binary data packing, and XML parsing, and the ways in\\nwhich they are impacted by 3.X’s string changes.\\n\\n1165\\n\\n\\x0cThis is officially an advanced topics chapter, because not all programmers will need to\\ndelve into the worlds of Unicode encodings or binary data. For some readers, Chap-\\nter 4’s preview may suffice, and others may wish to file this chapter away for future\\nreference. If you ever need to care about processing either of these, though, you’ll find\\nthat Python’s string models provide the support you need.\\n\\nString Changes in 3.X\\nOne of the most noticeable changes in the Python 3.X line is the mutation of string\\nobject  types.  In  a  nutshell,  2.X’s  str  and  unicode  types  have  morphed  into  3.X’s\\nbytes and str types, and a new mutable bytearray type has been added. The bytear\\nray type is technically available in Python 2.6 and 2.7 too (though not earlier), but it’s\\na back-port from 3.X and does not as clearly distinguish between text and binary con-\\ntent in 2.X.\\nEspecially if you process data that is either Unicode or binary in nature, these changes\\ncan have substantial impacts on your code. As a general rule of thumb, how much you\\nneed to care about this topic depends in large part upon which of the following cate-\\ngories you fall into:\\n\\n• If you deal with non-ASCII Unicode text—for instance, in the context of interna-\\ntionalized domains like the Web, or the results of some XML and JSON parsers\\nand databases—you will find support for text encodings to be different in 3.X, but\\nalso probably more direct, accessible, and seamless than in 2.X.\\n\\n• If you deal with binary data—for example, in the form of image or audio files or\\npacked data processed with the struct module—you will need to understand 3.X’s\\nnew bytes object and 3.X’s different and sharper distinction between text and bi-\\nnary data and files.\\n\\n• If you fall into neither of the prior two categories, you can generally use strings in\\n3.X much as you would in 2.X, with the general str string type, text files, and all\\nthe familiar string operations we studied earlier. Your strings will be encoded and\\ndecoded by 3.X using your platform’s default encoding (e.g., ASCII, or UTF-8 on\\nWindows in the U.S.—sys.getdefaultencoding gives your default if you care to\\ncheck), but you probably won’t notice.\\n\\nIn other words, if your text is always ASCII, you can get by with normal string objects\\nand  text  files  and  can  avoid  most  of  the  following  story  for  now.  As  we’ll  see  in  a\\nmoment, ASCII is a simple kind of Unicode and a subset of other encodings, so string\\noperations and files generally “just work” if your programs process only ASCII text.\\nEven if you fall into the last of the three categories just mentioned, though, a basic\\nunderstanding of Unicode and 3.X’s string model can help both to demystify some of\\nthe underlying behavior now, and to make mastering Unicode or binary data issues\\neasier if they impact you later.\\n\\n1166 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cTo put that more strongly: like it or not, Unicode will be part of most software devel-\\nopment in the interconnected future we’ve sown, and will probably impact you even-\\ntually. Though applications are beyond our scope here, if you work with the Internet,\\nfiles, directories, network interfaces, databases, pipes, JSON, XML, and even GUIs,\\nUnicode may no longer be an optional topic for you in Python 3.X.\\nPython 3.X’s support for Unicode and binary data is also available in 2.X, albeit in\\ndifferent forms. Although our main focus in this chapter is on string types in 3.X, we’ll\\nalso explore how 2.X’s equivalent support differs along the way for readers using 2.X.\\nRegardless of which version you use, the tools we’ll explore here can become important\\nin many types of programs.\\n\\nString Basics\\nBefore we look at any code, let’s begin with a general overview of Python’s string model.\\nTo understand why 3.X changed the way it did on this front, we have to start with a\\nbrief look at how characters are actually represented in computers—both when enco-\\nded in files and when stored in memory.\\n\\nCharacter Encoding Schemes\\nMost programmers think of strings as series of characters used to represent textual data.\\nWhile that’s accurate, the way characters are stored can vary, depending on what sort\\nof character set must be recorded. When text is stored on files, for example, its character\\nset determines its format.\\nCharacter sets are standards that assign integer codes to individual characters so they\\ncan be represented in computer memory. The ASCII standard, for example, was created\\nin the U.S., and it defines many U.S. programmers’ notion of text strings. ASCII defines\\ncharacter codes from 0 through 127 and allows each character to be stored in one 8-\\nbit byte, only 7 bits of which are actually used.\\nFor example, the ASCII standard maps the character \\'a\\' to the integer value 97 (0x61\\nin hex), which can be stored in a single byte in memory and files. If you wish to see\\nhow this works, Python’s ord built-in function gives the binary identifying value for a\\ncharacter, and chr returns the character for a given integer code value:\\n\\n>>> ord(\\'a\\')         # \\'a\\' is a byte with binary value 97 in ASCII (and others)\\n97\\n>>> hex(97)\\n\\'0x61\\'\\n>>> chr(97)          # Binary value 97 stands for character \\'a\\'\\n\\'a\\'\\n\\nSometimes one byte per character isn’t enough, though. Various symbols and accented\\ncharacters,  for  instance,  do  not  fit  into  the  range  of  possible  characters  defined  by\\nASCII. To accommodate special characters, some standards use all the possible values\\n\\nString Basics\\n\\n| 1167\\n\\n\\x0cin  an  8-bit  byte,  0  through  255,  to  represent  characters,  and  assign  the  values  128\\nthrough 255 (outside ASCII’s range) to special characters.\\nOne  such  standard,  known  as  the  Latin-1  character  set,  is  widely  used  in  Western\\nEurope. In Latin-1, character codes above 127 are assigned to accented and otherwise\\nspecial characters. The character assigned to byte value 196, for example, is a specially\\nmarked non-ASCII character:\\n\\n>>> 0xC4\\n196\\n>>> chr(196)         # Python 3.X result form shown\\n\\'Ä\\'\\n\\nThis standard allows for a wide array of extra special characters, but still supports ASCII\\nas a 7-bit subset of its 8-bit representation.\\nStill, some alphabets define so many characters that it is impossible to represent each\\nof them as one byte. Unicode allows more flexibility. Unicode text is sometimes referred\\nto as “wide-character” strings, because characters may be represented with multiple\\nbytes if needed. Unicode is typically used in internationalized programs, to represent\\nEuropean, Asian, and other non-English character sets that have more characters than\\n8-bit bytes can represent.\\nTo store such rich text in computer memory, we say that characters are translated to\\nand from raw bytes using an encoding—the rules for translating a string of Unicode\\ncharacters to a sequence of bytes, and extracting a string from a sequence of bytes.\\nMore procedurally, this translation back and forth between bytes and strings is defined\\nby two terms:\\n\\n• Encoding is the process of translating a string of characters into its raw bytes form,\\n\\naccording to a desired encoding name.\\n\\n• Decoding is the process of translating a raw string of bytes into its character string\\n\\nform, according to its encoding name.\\n\\nThat is, we encode from string to raw bytes, and decode from raw bytes to string. To\\nscripts,  decoded  strings  are  just  characters  in  memory,  but  may  be  encoded  into  a\\nvariety of byte string representations when stored on files, transferred over networks,\\nembedded in documents and databases, and so on.\\nFor some encodings, the translation process is trivial—ASCII and Latin-1, for instance,\\nmap each character to a fixed-size single byte, so no translation work is required. For\\nother encodings, the mapping can be more complex and yield multiple bytes per char-\\nacter, even for simple 8-bit forms of text.\\nThe widely used UTF-8 encoding, for example, allows a wide range of characters to be\\nrepresented by employing a variable-sized number of bytes scheme. Character codes\\nless than 128 are represented as a single byte; codes between 128 and 0x7ff (2047) are\\nturned into 2 bytes, where each byte has a value between 128 and 255; and codes above\\n0x7ff are turned into 3- or 4-byte sequences having values between 128 and 255. This\\n\\n1168 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0ckeeps simple ASCII strings compact, sidesteps byte ordering issues, and avoids null\\n(zero value) bytes that can cause problems for C libraries and networking.\\nBecause their encodings’ character maps assign characters to the same codes for com-\\npatibility, ASCII is a subset of both Latin-1 and UTF-8. That is, a valid ASCII character\\nstring is also a valid Latin-1- and UTF-8-encoded string. For example, every ASCII file\\nis a valid UTF-8 file, because the ASCII character set is a 7-bit subset of UTF-8.\\nConversely, the UTF-8 encoding is binary compatible with ASCII, but only for character\\ncodes less than 128. Latin-1 and UTF-8 simply allow for additional characters: Latin-1\\nfor characters mapped to values 128 through 255 within a byte, and UTF-8 for char-\\nacters that may be represented with multiple bytes.\\nOther  encodings  allow  for  richer  character  sets  in  different  ways.  UTF-16  and\\nUTF-32, for example, format text with a fixed-size 2 and 4 bytes per each character\\nscheme, respectively, even for characters that could otherwise fit in a single byte. Some\\nencodings may also insert prefixes that identify byte ordering.\\nTo see this for yourself, run a string’s encode method, which gives its encoded byte-\\nstring format under a named scheme—a two-character ASCII string is 2 bytes in ASCII,\\nLatin-1, and UTF-8, but it’s much wider in UTF-16 and UTF-32, and includes header\\nbytes:\\n\\n>>> S = \\'ni\\'\\n>>> S.encode(\\'ascii\\'), S.encode(\\'latin1\\'), S.encode(\\'utf8\\')\\n(b\\'ni\\', b\\'ni\\', b\\'ni\\')\\n\\n>>> S.encode(\\'utf16\\'), len(S.encode(\\'utf16\\'))\\n(b\\'\\\\xff\\\\xfen\\\\x00i\\\\x00\\', 6)\\n\\n>>> S.encode(\\'utf32\\'), len(S.encode(\\'utf32\\'))\\n(b\\'\\\\xff\\\\xfe\\\\x00\\\\x00n\\\\x00\\\\x00\\\\x00i\\\\x00\\\\x00\\\\x00\\', 12)\\n\\nThese results differ slightly in Python 2.X (you won’t get the leading b for byte strings).\\nBut  all  of  these  encoding  schemes—ASCII,  Latin-1,  UTF-8,  and  many  others—are\\nconsidered to be Unicode.\\nTo Python programmers, encodings are specified as strings containing the encoding’s\\nname. Python comes with roughly 100 different encodings; see the Python library ref-\\nerence for a complete list. Importing the module encodings and running help(encod\\nings) shows you many encoding names as well; some are implemented in Python, and\\nsome  in  C.  Some  encodings  have  multiple  names,  too;  for  example,  latin-1,\\niso_8859_1, and 8859 are all synonyms for the same encoding, Latin-1. We’ll revisit\\nencodings later in this chapter, when we study techniques for writing Unicode strings\\nin a script.\\nFor more on the underlying Unicode story, see the Python standard manual set. It\\nincludes a “Unicode HOWTO” in its “Python HOWTOs” section, which provides\\nadditional background that we will skip here in the interest of space.\\n\\nString Basics\\n\\n| 1169\\n\\n\\x0cHow Python Stores Strings in Memory\\nThe prior section’s encodings really only apply when text is stored or transferred ex-\\nternally, in files and other mediums. In memory, Python always stores decoded text\\nstrings in an encoding-neutral format, which may or may not use multiple bytes for each\\ncharacter. All text processing occurs in this uniform internal format. Text is translated\\nto and from an encoding-specific format only when it is transferred to or from external\\ntext files, byte strings, or APIs with specific encoding requirements. Once in memory,\\nthough, strings have no encoding. They are just the string object presented in this book.\\nThough irrelevant to your code, it may help some readers to make this more tangible.\\nThe way Python actually stores text in memory is prone to change over time, and in\\nfact mutated substantially as of 3.3:\\n\\nPython 3.2 and earlier\\n\\nThrough Python 3.2, strings are stored internally in fixed-length UTF-16 (roughly,\\nUCS-2) format with 2 bytes per character, unless Python is configured to use 4\\nbytes per character (UCS-4).\\n\\nPython 3.3 and later\\n\\nPython 3.3 and later instead use a variable-length scheme with 1, 2, or 4 bytes per\\ncharacter,  depending  on  a  string’s  content.  The  size  is  chosen  based  upon  the\\ncharacter with the largest Unicode ordinal value in the represented string. This\\nscheme allows a space-efficient representation in common cases, but also allows\\nfor full UCS-4 on all platforms.\\n\\nPython 3.3’s new scheme is an optimization, especially compared to former wide Uni-\\ncode builds. Per Python documentation: memory footprint is divided by 2 to 4 de-\\npending on the text; encoding an ASCII string to UTF-8 doesn’t need to encode char-\\nacters anymore, because its ASCII and UTF-8 representations are the same; repeating\\na single ASCII letter and getting a substring of an ASCII strings is 4 times faster; UTF-8\\nis 2 to 4 times faster; and UTF-16 encoding is up to 10 times faster. On some bench-\\nmarks, Python 3.3’s overall memory usage is 2 to 3 times smaller than 3.2, and similar\\nto the less Unicode-centric 2.7.\\nRegardless of the storage scheme used, as noted in Chapter 6 Unicode clearly requires\\nus to think of strings in terms of characters, instead of bytes. This may be a bigger hurdle\\nfor programmers accustomed to the simpler ASCII-only world where each character\\nmapped to a single byte, but that idea no longer applies, in terms of both the results of\\ntext string tools and physical character size:\\n\\nText tools\\n\\nToday, both string content and length really correspond to Unicode code points—\\nidentifying ordinal numbers for characters. For instance, the built-in ord function\\nnow returns a character’s Unicode code point ordinal, which is not necessarily an\\nASCII code, and which may or may not fit in a single 8-bit byte’s value. Similarly,\\n\\n1170 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0clen returns the number of characters, not bytes; the string is probably larger in\\nmemory, and its characters may not fit in bytes anyhow.\\n\\nText size\\n\\nAs we saw by example in Chapter 4, under Unicode a single character does not\\nnecessarily map directly to a single byte, either when encoded in a file or when\\nstored in memory. Even characters in simple 7-bit ASCII text may not map to bytes\\n—UTF-16 uses multiple bytes per character in files, and Python may allocate 1, 2,\\nor 4 bytes per character in memory. Thinking in terms of characters allows us to\\nabstract away the details of external and internal storage.\\n\\nThe key point here, though, is that encoding pertains mostly to files and transfers. Once\\nloaded into a Python string, text in memory has no notion of an “encoding,” and is\\nsimply a sequence of Unicode characters (a.k.a. code points) stored generically. In your\\nscript, that string is accessed as a Python string object—the next section’s topic.\\n\\nPython’s String Types\\nAt a more concrete level, the Python language provides string data types to represent\\ncharacter text in your scripts. The string types you will use in your scripts depend upon\\nthe version of Python you’re using. Python 2.X has a general string type for representing\\nbinary data and simple 8-bit text like ASCII, along with a specific type for representing\\nricher Unicode text:\\n\\n• str for representing 8-bit text and binary data\\n• unicode for representing decoded Unicode text\\n\\nPython 2.X’s two string types are different (unicode allows for the extra size of some\\nUnicode characters and has extra support for encoding and decoding), but their oper-\\nation sets largely overlap. The str string type in 2.X is used for text that can be repre-\\nsented with 8-bit bytes (including ASCII and Latin-1), as well as binary data that rep-\\nresents absolute byte values.\\nBy contrast, Python 3.X comes with three string object types—one for textual data and\\ntwo for binary data:\\n\\n• str for representing decoded Unicode text (including ASCII)\\n• bytes for representing binary data (including encoded text)\\n• bytearray, a mutable flavor of the bytes type\\n\\nAs mentioned earlier, bytearray is also available in Python 2.6 and 2.7, but it’s simply\\na back-port from 3.X with less content-specific behavior and is generally considered a\\n3.X type.\\n\\nString Basics\\n\\n| 1171\\n\\n\\x0cWhy the different string types?\\nAll three string types in 3.X support similar operation sets, but they have different roles.\\nThe main goal behind this change in 3.X was to merge the normal and Unicode string\\ntypes of 2.X into a single string type that supports both simple and Unicode text: de-\\nvelopers wanted to remove the 2.X string dichotomy and make Unicode processing\\nmore natural. Given that ASCII and other 8-bit text is really a simple kind of Unicode,\\nthis convergence seems logically sound.\\nTo  achieve  this,  3.X  stores  text  in  a  redefined  str  type—an  immutable  sequence  of\\ncharacters (not necessarily bytes), which may contain either simple text such as ASCII\\nwhose character values fit in single bytes, or richer character set text such as UTF-8\\nwhose character values may require multiple bytes. Strings processed by your script\\nwith this type are stored generically in memory, and are encoded to and decoded from\\nbyte strings per either the platform Unicode default or an explicit encoding name. This\\nallows scripts to translate text to different encoding schemes, both in memory and when\\ntransferring to and from files.\\nWhile 3.X’s new str type does achieve the desired string/unicode merging, many pro-\\ngrams still need to process raw binary data that is not encoded per any text format.\\nImage and audio files, as well as packed data used to interface with devices or C pro-\\ngrams you might process with Python’s struct module, fall into this category. Because\\nUnicode strings are decoded from bytes, they cannot be used to represent bytes.\\nTo support processing of such truly binary data, a new string type, bytes, also was\\nintroduced—an immutable sequence of 8-bit integers representing absolute byte values,\\nwhich prints as ASCII characters when possible. Though a distinct object type, bytes\\nsupports almost all the same operations that the str type does; this includes string\\nmethods, sequence operations, and even re module pattern matching, but not string\\nformatting. In 2.X, the general str type fills this binary data role, because its strings are\\njust sequences of bytes; the separate unicode type handles richer text strings.\\nIn more detail, a 3.X bytes object really is a sequence of small integers, each of which\\nis  in  the  range  0  through  255;  indexing  a  bytes  returns  an  int,  slicing  one  returns\\nanother bytes, and running the list built-in on one returns a list of integers, not char-\\nacters. When processed with operations that assume characters, though, the contents\\nof  bytes  objects  are  assumed  to  be  ASCII-encoded  bytes  (e.g.,  the  isalpha  method\\nassumes each byte is an ASCII character code). Further, bytes objects are printed as\\ncharacter strings instead of integers for convenience.\\nWhile they were at it, Python developers also added a bytearray type in 3.X. bytear\\nray is a variant of bytes that is mutable and so supports in-place changes. It supports\\nthe usual string operations that str and bytes do, as well as many of the same in-place\\nchange operations as lists (e.g., the  append and extend methods, and assignment to\\nindexes). This can be useful both for truly binary data and simple types of text. As-\\nsuming your text strings can be treated as raw 8-bit bytes (e.g., ASCII or Latin-1 text),\\nbytearray finally adds direct in-place mutability for text data—something not possible\\n\\n1172 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cwithout conversion to a mutable type in Python 2.X, and not supported by Python 3.X’s\\nstr or bytes.\\nAlthough Python 2.X and 3.X offer much the same functionality, they package it dif-\\nferently. In fact, the mapping from 2.X to 3.X string types is not completely direct—\\n2.X’s str equates to both str and bytes in 3.X, and 3.X’s str equates to both str and\\nunicode in 2.X. Moreover, the mutability of 3.X’s bytearray is unique.\\nIn practice, though, this asymmetry is not as daunting as it might sound. It boils down\\nto the following: in 2.X, you will use str for simple text and binary data and unicode\\nfor advanced forms of text whose character sets don’t map to 8-bit bytes; in 3.X, you’ll\\nuse str for any kind of text (ASCII, Latin-1, and all other kinds of Unicode) and bytes or\\nbytearray for binary data. In practice, the choice is often made for you by the tools you\\nuse—especially in the case of file processing tools, the topic of the next section.\\n\\nText and Binary Files\\nFile I/O (input and output) was also revamped in 3.X to reflect the str/bytes distinction\\nand automatically support encoding Unicode text on transfers. Python now makes a\\nsharp platform-independent distinction between text files and binary files; in 3.X:\\n\\nText files\\n\\nWhen a file is opened in text mode, reading its data automatically decodes its con-\\ntent and returns it as a str; writing takes a str and automatically encodes it before\\ntransferring it to the file. Both reads and writes translate per a platform default or\\na  provided  encoding  name.  Text-mode  files  also  support  universal  end-of-line\\ntranslation and additional encoding specification arguments. Depending on the\\nencoding name, text files may also automatically process the byte order mark se-\\nquence at the start of a file (more on this momentarily).\\n\\nBinary files\\n\\nWhen a file is opened in binary mode by adding a b (lowercase only) to the mode-\\nstring argument in the built-in open call, reading its data does not decode it in any\\nway but simply returns its content raw and unchanged, as a bytes object; writing\\nsimilarly takes a bytes object and transfers it to the file unchanged. Binary-mode\\nfiles also accept a bytearray object for the content to be written to the file.\\n\\nBecause the language sharply differentiates between str and bytes, you must decide\\nwhether your data is text or binary in nature and use either str or bytes objects to\\nrepresent its content in your script, as appropriate. Ultimately, the mode in which you\\nopen a file will dictate which type of object your script will use to represent its content:\\n\\n• If you are processing image files, data transferred over networks, packed binary\\ndata whose content you must extract, or some device data streams, chances are\\ngood that you will want to deal with it using bytes and binary-mode files. You might\\nalso opt for bytearray if you wish to update the data without making copies of it\\nin memory.\\n\\nString Basics\\n\\n| 1173\\n\\n\\x0c• If instead you are processing something that is textual in nature, such as program\\noutput, HTML, email content, or CSV or XML files, you’ll probably want to use\\nstr and text-mode files.\\n\\nNotice that the mode string argument to built-in function open (its second argument)\\nbecomes fairly crucial in Python 3.X—its content not only specifies a file processing\\nmode, but also implies a Python object type. By adding a b to the mode string, you specify\\nbinary mode and will receive, or must provide, a bytes object to represent the file’s\\ncontent when reading or writing. Without the b, your file is processed in text mode,\\nand you’ll use str objects to represent its content in your script. For example, the modes\\nrb, wb, and rb+ imply bytes; r, w+, and rt (the default) imply str.\\nText-mode files also handle the byte order marker (BOM) sequence that may appear at\\nthe start of files under some encoding schemes. In the UTF-16 and UTF-32 encodings,\\nfor example, the BOM specifies big- or little-endian format (essentially, which end of\\na bit-string is most significant)—see the leading bytes in the results of the UTF-16 and\\nUTF-32 encoding calls we ran earlier for examples. A UTF-8 text file might also include\\na BOM to declare that it is UTF-8 in general. When reading and writing data using\\nthese encoding schemes, Python skips or writes the BOM according to rules we’ll study\\nlater in this chapter.\\nIn Python 2.X, the same behavior is supported, but normal files created by open are\\nused to access bytes-based data, and Unicode files opened with the codecs.open call are\\nused to process Unicode text data. The latter of these also encode and decode on trans-\\nfer, as we’ll see later in this chapter. First, let’s explore Python’s Unicode string model\\nlive.\\n\\nCoding Basic Strings\\nLet’s step through a few examples that demonstrate how the 3.X string types are used.\\nOne note up front: the code in this section was run with and applies to 3.X only. Still,\\nbasic string operations are generally portable across Python versions. Simple ASCII\\nstrings represented with the str type work the same in 2.X and 3.X (and exactly as we\\nsaw in Chapter 7 of this book).\\nMoreover, although there is no bytes type in Python 2.X (it has just the general str), it\\ncan usually run code that thinks there is—in 2.6 and 2.7, the call bytes(X) is present\\nas a synonym for str(X), and the new literal form b\\'...\\' is taken to be the same as the\\nnormal string literal \\'...\\'. You may still run into version skew in some isolated cases,\\nthough; the 2.6/2.7 bytes call, for instance, does not require or allow the second argu-\\nment (encoding name) that is required by 3.X’s bytes.\\n\\n1174 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cPython 3.X String Literals\\nPython 3.X string objects originate when you call a built-in function such as str or\\nbytes, read a file created by calling open (described in the next section), or code literal\\nsyntax  in  your  script.  For  the  latter,  a  new  literal  form,  b\\'xxx\\'  (and  equivalently,\\nB\\'xxx\\') is used to create bytes objects in 3.X, and you may create bytearray objects by\\ncalling the bytearray function, with a variety of possible arguments.\\nMore  formally,  in  3.X  all  the  current  string  literal  forms—\\'xxx\\',  \"xxx\",  and  triple-\\nquoted  blocks—generate  a  str;  adding  a  b  or  B  just  before  any  of  them  creates  a\\nbytes instead. This new b\\'...\\' bytes literal is similar in form to the r\\'...\\' raw string\\nused to suppress backslash escapes. Consider the following, run in 3.X:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> B = b\\'spam\\'               # 3.X bytes literal make a bytes object (8-bit bytes)\\n>>> S = \\'eggs\\'                # 3.X str literal makes a Unicode text string\\n\\n>>> type(B), type(S)\\n(<class \\'bytes\\'>, <class \\'str\\'>)\\n\\n>>> B                         # bytes: sequence of int, prints as character string\\nb\\'spam\\'\\n>>> S\\n\\'eggs\\'\\n\\nThe 3.X bytes object is actually a sequence of short integers, though it prints its content\\nas characters whenever possible:\\n\\n>>> B[0], S[0]                # Indexing returns an int for bytes, str for str\\n(115, \\'e\\')\\n>>> B[1:], S[1:]              # Slicing makes another bytes or str object\\n(b\\'pam\\', \\'ggs\\')\\n>>> list(B), list(S)\\n([115, 112, 97, 109], [\\'e\\', \\'g\\', \\'g\\', \\'s\\'])     # bytes is really 8-bit small ints\\n\\nThe bytes object is also immutable, just like str (though bytearray, described later, is\\nnot); you cannot assign a str, bytes, or integer to an offset of a bytes object.\\n\\n>>> B[0] = \\'x\\'                                  # Both are immutable\\nTypeError: \\'bytes\\' object does not support item assignment\\n>>> S[0] = \\'x\\'\\nTypeError: \\'str\\' object does not support item assignment\\n\\nFinally, note that the bytes literal’s b or B prefix also works for any string literal form,\\nincluding triple-quoted blocks, though you get back a string of raw bytes that may or\\nmay not map to characters:\\n\\n>>> # bytes prefix works on single, double, triple quotes, raw\\n>>> B = B\"\"\"\\n... xxxx\\n... yyyy\\n... \"\"\"\\n>>> B\\nb\\'\\\\nxxxx\\\\nyyyy\\\\n\\'\\n\\nCoding Basic Strings\\n\\n| 1175\\n\\n\\x0cPython 2.X Unicode literals in Python 3.3\\nPython 2.X’s u\\'xxx\\' and U\\'xxx\\' Unicode string literal forms were removed in Python\\n3.0 because they were deemed redundant—normal strings are Unicode in 3.X. To aid\\nboth forward and backward compatibility, though, they are available again as of 3.3,\\nwhere they are treated as normal str strings:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> U = u\\'spam\\'                   # 2.X Unicode literal accepted in 3.3+\\n>>> type(U)                       # It is just str, but is backward compatible\\n<class \\'str\\'>\\n>>> U\\n\\'spam\\'\\n>>> U[0]\\n\\'s\\'\\n>>> list(U)\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\']\\n\\nThese literals are gone in 3.0 through 3.2, where you must use \\'xxx\\' instead. You should\\ngenerally  use  3.X  \\'xxx\\'  text  literals  in  new  3.X-only  code,  because  the  2.X  form  is\\nsuperfluous. However, in 3.3 and later, using the 2.X literal form can ease the task of\\nporting 2.X code, and boost 2.X code compatibility (for a case in point, see Chap-\\nter 25’s currency example, described in an upcoming note). Regardless of how text\\nstrings are coded in 3.X, though, they are all Unicode, even if they contain only ASCII\\ncharacters (more on writing non-ASCII Unicode text in the section “Coding Non-ASCII\\nText” on page 1179).\\n\\nPython 2.X String Literals\\nAll three of the 3.X string forms of the prior section can be coded in 2.X, but their\\nmeaning differs. As mentioned earlier, in Python 2.6 and 2.7 the b\\'xxx\\' bytes literal is\\npresent for forward compatibility with 3.X, but is the same as \\'xxx\\' and makes a str\\n(the b is ignored), and bytes is just a synonym for str; as you’ve seen, in 3.X both of\\nthese address the distinct bytes type:\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> B = b\\'spam\\'                  # 3.X bytes literal is just str in 2.6/2.7\\n>>> S = \\'eggs\\'                   # str is a bytes/character sequence\\n\\n>>> type(B), type(S)\\n(<type \\'str\\'>, <type \\'str\\'>)\\n>>> B, S\\n(\\'spam\\', \\'eggs\\')\\n>>> B[0], S[0]\\n(\\'s\\', \\'e\\')\\n>>> list(B), list(S)\\n([\\'s\\', \\'p\\', \\'a\\', \\'m\\'], [\\'e\\', \\'g\\', \\'g\\', \\'s\\'])\\n\\nIn 2.X the special Unicode literal and type accommodates richer forms of text:\\n\\n>>> U = u\\'spam\\'                  # 2.X Unicode literal makes a distinct type\\n>>> type(U)                      # Works in 3.3 too, but is just a str there\\n\\n1176 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c<type \\'unicode\\'>\\n>>> U\\nu\\'spam\\'\\n>>> U[0]\\nu\\'s\\'\\n>>> list(U)\\n[u\\'s\\', u\\'p\\', u\\'a\\', u\\'m\\']\\n\\nAs we saw, for compatibility this form works in 3.3 and later too, but it simply makes\\na normal str there (the u is ignored).\\n\\nString Type Conversions\\nAlthough Python 2.X allowed str and unicode type objects to be mixed in expressions\\n(when the str contained only 7-bit ASCII text), 3.X draws a much sharper distinction\\n—str  and  bytes  type  objects  never  mix  automatically  in  expressions  and  never  are\\nconverted to one another automatically when passed to functions. A function that ex-\\npects an argument to be a str object won’t generally accept a bytes, and vice versa.\\nBecause of this, Python 3.X basically requires that you commit to one type or the other,\\nor perform manual, explicit conversions when needed:\\n\\n• str.encode() and bytes(S, encoding) translate a string to its raw bytes form and\\n\\ncreate an encoded bytes from a decoded str in the process.\\n\\n• bytes.decode() and str(B, encoding) translate raw bytes into its string form and\\n\\ncreate a decoded str from an encoded bytes in the process.\\n\\nThese encode and decode methods (as well as file objects, described in the next section)\\nuse either a default encoding for your platform or an explicitly passed-in encoding\\nname. For example, in Python 3.X:\\n\\n>>> S = \\'eggs\\'\\n>>> S.encode()                          # str->bytes: encode text into raw bytes\\nb\\'eggs\\'\\n>>> bytes(S, encoding=\\'ascii\\')          # str->bytes, alternative\\nb\\'eggs\\'\\n\\n>>> B = b\\'spam\\'\\n>>> B.decode()                          # bytes->str: decode raw bytes into text\\n\\'spam\\'\\n>>> str(B, encoding=\\'ascii\\')            # bytes->str, alternative\\n\\'spam\\'\\n\\nTwo cautions here. First of all, your platform’s default encoding is available in the\\nsys module, but the encoding argument to bytes is not optional, even though it is in\\nstr.encode (and bytes.decode).\\nSecond, although calls to str do not require the encoding argument like bytes does,\\nleaving it off in str calls does not mean that it defaults—instead, a str call without an\\nencoding returns the bytes object’s print string, not its str converted form (this is usu-\\nally not what you’ll want!). Assuming B and S are still as in the prior listing:\\n\\nCoding Basic Strings\\n\\n| 1177\\n\\n\\x0c>>> import sys\\n>>> sys.platform                        # Underlying platform\\n\\'win32\\'\\n>>> sys.getdefaultencoding()            # Default encoding for str here\\n\\'utf-8\\'\\n\\n>>> bytes(S)\\nTypeError: string argument without an encoding\\n\\n>>> str(B)                              # str without encoding\\n\"b\\'spam\\'\"                               # A print string, not conversion!\\n>>> len(str(B))\\n7\\n>>> len(str(B, encoding=\\'ascii\\'))       # Use encoding to convert to str\\n4\\n\\nWhen in doubt, pass in an encoding name argument in 3.X, even if it may have a default.\\nConversions are similar in Python 2.X, though 2.X’s support for mixing string types in\\nexpressions makes conversions optional for ASCII text, and the tool names differ for\\nthe different string type model—conversions in 2.X occur between encoded str and\\ndecoded unicode, rather than 3.X’s encoded bytes and decoded str:\\n>>> S = \\'spam\\'                          # 2.X type string conversion tools\\n>>> U = u\\'eggs\\'\\n>>> S, U\\n(\\'spam\\', u\\'eggs\\')\\n>>> unicode(S), str(U)                  # 2.X converts str->uni, uni->str\\n(u\\'spam\\', \\'eggs\\')\\n>>> S.decode(), U.encode()              # versus 3.X byte->str, str->bytes\\n(u\\'spam\\', \\'eggs\\')\\n\\nCoding Unicode Strings\\nEncoding and decoding become more meaningful when you start dealing with non-\\nASCII Unicode text. To code arbitrary Unicode characters in your strings, some of\\nwhich you might not even be able to type on your keyboard, Python string literals\\nsupport both \"\\\\xNN\" hex byte value escapes and \"\\\\uNNNN\" and \"\\\\UNNNNNNNN\" Unicode\\nescapes in string literals. In Unicode escapes, the first form gives four hex digits to\\nencode a 2-byte (16-bit) character code point, and the second gives eight hex digits for\\na 4-byte (32-bit) code point. Byte strings support only hex escapes for encoded text and\\nother forms of byte-based data.\\n\\nCoding ASCII Text\\nLet’s step through some examples that demonstrate text coding basics. As we’ve seen,\\nASCII text is a simple type of Unicode, stored as a sequence of byte values that represent\\ncharacters:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> ord(\\'X\\')             # \\'X\\' is binary code point value 88 in the default encoding\\n\\n1178 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c88\\n>>> chr(88)              # 88 stands for character \\'X\\'\\n\\'X\\'\\n\\n>>> S = \\'XYZ\\'            # A Unicode string of ASCII text\\n>>> S\\n\\'XYZ\\'\\n>>> len(S)               # Three characters long\\n3\\n>>> [ord(c) for c in S]  # Three characters with integer ordinal values\\n[88, 89, 90]\\n\\nNormal 7-bit ASCII text like this is represented with one character per byte under each\\nof the Unicode encoding schemes described earlier in this chapter:\\n\\n>>> S.encode(\\'ascii\\')    # Values 0..127 in 1 byte (7 bits) each\\nb\\'XYZ\\'\\n>>> S.encode(\\'latin-1\\')  # Values 0..255 in 1 byte (8 bits) each\\nb\\'XYZ\\'\\n>>> S.encode(\\'utf-8\\')    # Values 0..127 in 1 byte, 128..2047 in 2, others 3 or 4\\nb\\'XYZ\\'\\n\\nIn fact, the bytes objects returned by encoding ASCII text this way are really a sequence\\nof short integers, which just happen to print as ASCII characters when possible:\\n\\n>>> S.encode(\\'latin-1\\')\\nb\\'XYZ\\'\\n>>> S.encode(\\'latin-1\\')[0]\\n88\\n>>> list(S.encode(\\'latin-1\\'))\\n[88, 89, 90]\\n\\nCoding Non-ASCII Text\\nFormally, to code non-ASCII characters, we can use:\\n\\n• Hex or Unicode escapes to embed Unicode code point ordinal values in text strings\\n—normal string literals in 3.X, and Unicode string literals in 2.X (and in 3.3 for\\ncompatibility).\\n\\n• Hex escapes to embed the encoded representation of characters in byte strings—\\nnormal string literals in 2.X, and bytes string literals in 3.X (and in 2.X for com-\\npatibility).\\n\\nNote that text strings embed actual code point values, while byte strings embed their\\nencoded form. The value of a character’s encoded representation in a byte string is the\\nsame as its decoded Unicode code point value in a text string for only certain characters\\nand encodings. In any event, hex escapes are limited to coding a single byte’s value,\\nbut Unicode escapes can name characters with values 2 and 4 bytes wide. The chr\\nfunction can also be used to create a single non-ASCII character from its code point\\nvalue, and as we’ll see later, source code declarations apply to such characters embed-\\nded in your script.\\n\\nCoding Unicode Strings\\n\\n| 1179\\n\\n\\x0cFor instance, the hex values 0xCD and 0xE8 are codes for two special accented characters\\noutside the 7-bit range of ASCII, but we can embed them in 3.X str objects because\\nstr supports Unicode:\\n\\n>>> chr(0xc4)              # 0xC4, 0xE8: characters outside ASCII\\'s range\\n\\'Ä\\'\\n>>> chr(0xe8)\\n\\'è\\'\\n\\n>>> S = \\'\\\\xc4\\\\xe8\\'         # Single 8-bit value hex escapes: two digits\\n>>> S\\n\\'Äè\\'\\n\\n>>> S = \\'\\\\u00c4\\\\u00e8\\'     # 16-bit Unicode escapes: four digits each\\n>>> S\\n\\'Äè\\'\\n>>> len(S)                 # Two characters long (not number of bytes!)\\n2\\n\\nNote that in Unicode text string literals like these, hex and Unicode escapes denote a\\nUnicode code point value, not byte values. The x hex escapes require exactly two digits\\n(for 8-bit code point values), and u and U Unicode escapes require exactly four and eight\\nhexadecimal digits, respectively, for denoting code point values that can be as big as\\n16 and 32 bits will allow:\\n\\n>>> S = \\'\\\\U000000c4\\\\U000000e8\\'       # 32-bit Unicode escapes: eight digits each\\n>>> S\\n\\'Äè\\'\\n\\nAs shown later, Python 2.X works similarly in this regard, but Unicode escapes are\\nallowed only in its Unicode literal form. They work in normal string literals in 3.X here\\nsimply because its normal strings are always Unicode.\\n\\nEncoding and Decoding Non-ASCII text\\nNow, if we try to encode the prior section’s non-ASCII text string into raw bytes using\\nas ASCII, we’ll get an error, because its characters are outside ASCII’s 7-bit code point\\nvalue range:\\n\\n>>> S = \\'\\\\u00c4\\\\u00e8\\'               # Non-ASCII text string, two characters long\\n>>> S\\n\\'Äè\\'\\n>>> len(S)\\n2\\n\\n>>> S.encode(\\'ascii\\')\\nUnicodeEncodeError: \\'ascii\\' codec can\\'t encode characters in position 0-1:\\nordinal not in range(128)\\n\\nEncoding this as Latin-1 works, though, because each character falls into that encod-\\ning’s 8-bit range, and we get 1 byte per character allocated in the encoded byte string.\\nEncoding as UTF-8 also works: this encoding supports a wide range of Unicode code\\n\\n1180 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cpoints, but allocates 2 bytes per non-ASCII character instead. If these encoded strings\\nare written to a file, the raw bytes shown here for encoding results are what is actually\\nstored on the file for the encoding types given:\\n\\n>>> S.encode(\\'latin-1\\')              # 1 byte per character when encoded\\nb\\'\\\\xc4\\\\xe8\\'\\n\\n>>> S.encode(\\'utf-8\\')                # 2 bytes per character when encoded\\nb\\'\\\\xc3\\\\x84\\\\xc3\\\\xa8\\'\\n\\n>>> len(S.encode(\\'latin-1\\'))         # 2 bytes in latin-1, 4 in utf-8\\n2\\n>>> len(S.encode(\\'utf-8\\'))\\n4\\n\\nNote that you can also go the other way, reading raw bytes from a file and decoding\\nthem back to a Unicode string. However, as we’ll see later, the encoding mode you give\\nto the open call causes this decoding to be done for you automatically on input (and\\navoids issues that may arise from reading partial character sequences when reading by\\nblocks of bytes):\\n\\n>>> B = b\\'\\\\xc4\\\\xe8\\'                  # Text encoded per Latin-1\\n>>> B\\nb\\'\\\\xc4\\\\xe8\\'\\n>>> len(B)                           # 2 raw bytes, two encoded characters\\n2\\n>>> B.decode(\\'latin-1\\')              # Decode to text per Latin-1\\n\\'Äè\\'\\n\\n>>> B = b\\'\\\\xc3\\\\x84\\\\xc3\\\\xa8\\'          # Text encoded per UTF-8\\n>>> len(B)                           # 4 raw bytes, two encoded characters\\n4\\n>>> B.decode(\\'utf-8\\')                # Decode to text per UTF-8\\n\\'Äè\\'\\n>>> len(B.decode(\\'utf-8\\'))           # Two Unicode characters in memory\\n2\\n\\nOther Encoding Schemes\\nSome encodings use even larger byte sequences to represent characters. When needed,\\nyou can specify both 16- and 32-bit Unicode code point values for characters in your\\nstrings—as shown earlier, we can use \"\\\\u...\" with four hex digits for the former, and\\n\"\\\\U...\" with eight hex digits for the latter, and can mix these in literals with simpler\\nASCII characters freely:\\n\\n>>> S = \\'A\\\\u00c4B\\\\U000000e8C\\'\\n>>> S                                # A, B, C, and 2 non-ASCII characters\\n\\'AÄBèC\\'\\n>>> len(S)                           # Five characters long\\n5\\n\\n>>> S.encode(\\'latin-1\\')\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n\\nCoding Unicode Strings\\n\\n| 1181\\n\\n\\x0c>>> len(S.encode(\\'latin-1\\'))         # 5 bytes when encoded per latin-1\\n5\\n\\n>>> S.encode(\\'utf-8\\')\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n>>> len(S.encode(\\'utf-8\\'))           # 7 bytes when encoded per utf-8\\n7\\n\\nTechnically speaking, you can also build Unicode strings piecemeal using chr instead\\nof Unicode or hex escapes, but this might become tedious for large strings:\\n\\n>>> S = \\'A\\' + chr(0xC4) + \\'B\\' + chr(0xE8) + \\'C\\'\\n>>> S\\n\\'AÄBèC\\'\\n\\nSome other encodings may use very different byte formats, though. The cp500 EBCDIC\\nencoding, for example, doesn’t even encode ASCII the same way as the encodings we’ve\\nbeen using so far; since Python encodes and decodes for us, we only generally need to\\ncare about this when providing encoding names for data sources:\\n\\n>>> S\\n\\'AÄBèC\\'\\n>>> S.encode(\\'cp500\\')                # Two other Western European encodings\\nb\\'\\\\xc1c\\\\xc2T\\\\xc3\\'\\n>>> S.encode(\\'cp850\\')                # 5 bytes each, different encoded values\\nb\\'A\\\\x8eB\\\\x8aC\\'\\n\\n>>> S = \\'spam\\'                       # ASCII text is the same in most\\n>>> S.encode(\\'latin-1\\')\\nb\\'spam\\'\\n>>> S.encode(\\'utf-8\\')\\nb\\'spam\\'\\n>>> S.encode(\\'cp500\\')                # But not in cp500: IBM EBCDIC!\\nb\\'\\\\xa2\\\\x97\\\\x81\\\\x94\\'\\n>>> S.encode(\\'cp850\\')\\nb\\'spam\\'\\n\\nThe same holds true for the UTF-16 and UTF-32 encodings, which use fixed 2- and 4-\\nbyte-per-character schemes with same-sized headers—non-ASCII encodes differently,\\nand ASCII is not 1 byte per character:\\n\\n>>> S = \\'A\\\\u00c4B\\\\U000000e8C\\'\\n>>> S.encode(\\'utf-16\\')\\nb\\'\\\\xff\\\\xfeA\\\\x00\\\\xc4\\\\x00B\\\\x00\\\\xe8\\\\x00C\\\\x00\\'\\n\\n>>> S = \\'spam\\'\\n>>> S.encode(\\'utf-16\\')\\nb\\'\\\\xff\\\\xfes\\\\x00p\\\\x00a\\\\x00m\\\\x00\\'\\n>>> S.encode(\\'utf-32\\')\\nb\\'\\\\xff\\\\xfe\\\\x00\\\\x00s\\\\x00\\\\x00\\\\x00p\\\\x00\\\\x00\\\\x00a\\\\x00\\\\x00\\\\x00m\\\\x00\\\\x00\\\\x00\\'\\n\\n1182 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cByte String Literals: Encoded Text\\nTwo cautions here too. First, Python 3.X allows special characters to be coded with\\nboth hex and Unicode escapes in str strings, but only with hex escapes in bytes strings\\n—Unicode escape sequences are silently taken verbatim in bytes literals, not as escapes.\\nIn fact, bytes must be decoded to str strings to print their non-ASCII characters prop-\\nerly:\\n\\n>>> S = \\'A\\\\xC4B\\\\xE8C\\'                # 3.X: str recognizes hex and Unicode escapes\\n>>> S\\n\\'AÄBèC\\'\\n>>> S = \\'A\\\\u00C4B\\\\U000000E8C\\'\\n>>> S\\n\\'AÄBèC\\'\\n\\n>>> B = b\\'A\\\\xC4B\\\\xE8C\\'               # bytes recognizes hex but not Unicode\\n>>> B\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n>>> B = b\\'A\\\\u00C4B\\\\U000000E8C\\'       # Escape sequences taken literally!\\n>>> B\\nb\\'A\\\\\\\\u00C4B\\\\\\\\U000000E8C\\'\\n\\n>>> B = b\\'A\\\\xC4B\\\\xE8C\\'               # Use hex escapes for bytes\\n>>> B                                # Prints non-ASCII as hex\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print(B)\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n>>> B.decode(\\'latin-1\\')              # Decode as latin-1 to interpret as text\\n\\'AÄBèC\\'\\n\\nSecond, bytes literals require characters either to be ASCII characters or, if their values\\nare greater than 127, to be escaped; str stings, on the other hand, allow literals con-\\ntaining any character in the source character set—which, as discussed later, defaults\\nto UTF-8 unless an encoding declaration is given in the source file:\\n\\n>>> S = \\'AÄBèC\\'                      # Chars from UTF-8 if no encoding declaration\\n>>> S\\n\\'AÄBèC\\'\\n\\n>>> B = b\\'AÄBèC\\'\\nSyntaxError: bytes can only contain ASCII literal characters.\\n\\n>>> B = b\\'A\\\\xC4B\\\\xE8C\\'               # Chars must be ASCII, or escapes\\n>>> B\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n>>> B.decode(\\'latin-1\\')\\n\\'AÄBèC\\'\\n\\n>>> S.encode()                       # Source code encoded per UTF-8 by default\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'               # Uses system default to encode, unless passed\\n>>> S.encode(\\'utf-8\\')\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n\\nCoding Unicode Strings\\n\\n| 1183\\n\\n\\x0c>>> B.decode()                       # Raw bytes do not correspond to utf-8\\nUnicodeDecodeError: \\'utf8\\' codec can\\'t decode bytes in position 1-2: ...\\n\\nBoth these constraints make sense if you remember that byte strings hold bytes-based\\ndata, not decoded Unicode code point ordinals; while they may contain the encoded\\nform of text, decoded code point values don’t quite apply to byte strings unless the\\ncharacters are first encoded.\\n\\nConverting Encodings\\nSo far, we’ve been encoding and decoding strings to inspect their structure. It’s also\\npossible to convert a string to a different encoding than its original, but we must provide\\nan explicit encoding name to encode to and decode from. This is true whether the\\noriginal text string originated in a file or a literal.\\nThe term conversion may be a misnomer here—it really just means encoding a text\\nstring to raw bytes per a different encoding scheme than the one it was decoded from.\\nAs stressed earlier, decoded text in memory has no encoding type, and is simply a string\\nof Unicode code points (a.k.a. characters); there is no concept of changing its encoding\\nin this form. Still, this scheme allows scripts to read data in one encoding and store it\\nin another, to support multiple clients of the same data:\\n\\n>>> B = b\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'       # Text encoded in UTF-8 format originally\\n>>> S = B.decode(\\'utf-8\\')            # Decode to Unicode text per UTF-8\\n>>> S\\n\\'AÄBèC\\'\\n\\n>>> T = S.encode(\\'cp500\\')            # Convert to encoded bytes per EBCDIC\\n>>> T\\nb\\'\\\\xc1c\\\\xc2T\\\\xc3\\'\\n\\n>>> U = T.decode(\\'cp500\\')            # Convert back to Unicode per EBCDIC\\n>>> U\\n\\'AÄBèC\\'\\n\\n>>> U.encode()                       # Per default utf-8 encoding again\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n\\nKeep in mind that the special Unicode and hex character escapes are only necessary\\nwhen you code non-ASCII Unicode strings manually. In practice, you’ll often load such\\ntext from files instead. As we’ll see later in this chapter, 3.X’s file object (created with\\nthe open built-in function) automatically decodes text strings as they are read and enc-\\nodes them when they are written; because of this, your script can often deal with strings\\ngenerically, without having to code special characters directly.\\nLater in this chapter we’ll also see that it’s possible to convert between encodings when\\ntransferring strings to and from files, using a technique very similar to that in the last\\nexample; although you’ll still need to provide explicit encoding names when opening\\na file, the file interface does most of the conversion work for you automatically.\\n\\n1184 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cCoding Unicode Strings in Python 2.X\\nI stress Python 3.X Unicode support in this chapter because it’s new. But now that I’ve\\nshown you the basics of Unicode strings in 3.X, I need to explain more fully how you\\ncan do much the same in 2.X, though the tools differ. unicode is available in Python\\n2.X, but is a distinct type from str, supports most of the same operations, and allows\\nmixing of normal and Unicode strings when the str is all ASCII.\\nIn fact, you can essentially pretend 2.X’s str is 3.X’s bytes when it comes to decoding\\nraw bytes into a Unicode string, as long as it’s in the proper form. Here is 2.X in action;\\nUnicode characters display in hex in 2.X unless you explicitly print, and non-ASCII\\ndisplays can vary per shell (most of this section ran outside IDLE, which sometimes\\ndetects and prints Latin-1 characters in encoded byte strings—see ahead for more on\\nPYTHONIOENCODING and Windows Command Prompt display issues):\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> S = \\'A\\\\xC4B\\\\xE8C\\'                # String of 8-bit bytes\\n>>> S                                # Text encoded per Latin-1, some non-ASCII\\n\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print S                          # Nonprintable characters (IDLE may differ)\\nA─BΦC\\n\\n>>> U = S.decode(\\'latin1\\')           # Decode bytes to Unicode text per latin-1\\n>>> U\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print U\\nAÄBèC\\n\\n>>> S.decode(\\'utf-8\\')                # Encoded form not compatible with utf-8\\nUnicodeDecodeError: \\'utf8\\' codec can\\'t decode byte 0xc4 in position 1: invalid c\\nontinuation byte\\n\\n>>> S.decode(\\'ascii\\')                # Encoded bytes are also outside ASCII range\\nUnicodeDecodeError: \\'ascii\\' codec can\\'t decode byte 0xc4 in position 1: ordinal\\nnot in range(128)\\n\\nTo code Unicode text, make a unicode object with the u\\'xxx\\' literal form (as mentioned,\\nthis literal is available again in 3.3, but superfluous in 3.X in general, since its normal\\nstrings support Unicode):\\n\\n>>> U = u\\'A\\\\xC4B\\\\xE8C\\'               # Make Unicode string, hex escapes\\n>>> U\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print U\\nAÄBèC\\n\\nOnce you’ve created it, you can convert Unicode text to different raw byte encodings,\\nsimilar to encoding str objects into bytes objects in 3.X:\\n\\n>>> U.encode(\\'latin-1\\')              # Encode per latin-1: 8-bit bytes\\n\\'A\\\\xc4B\\\\xe8C\\'\\n\\nCoding Unicode Strings\\n\\n| 1185\\n\\n\\x0c>>> U.encode(\\'utf-8\\')                # Encode per utf-8: multibyte\\n\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n\\nNon-ASCII characters can be coded with hex or Unicode escapes in string literals in\\n2.X, just as in 3.X. However, as with bytes in 3.X, the \"\\\\u...\" and \"\\\\U...\" escapes are\\nrecognized only for unicode strings in 2.X, not 8-bit str strings—again, these are used\\nto give the values of decoded Unicode ordinal integers, which don’t make sense in a\\nraw byte string:\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> U = u\\'A\\\\xC4B\\\\xE8C\\'               # Hex escapes for non-ASCII\\n>>> U\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print U\\nAÄBèC\\n\\n>>> U = u\\'A\\\\u00C4B\\\\U000000E8C\\'       # Unicode escapes for non-ASCII\\n>>> U                                # u\\'\\' = 16 bits, U\\'\\' = 32 bits\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print U\\nAÄBèC\\n\\n>>> S = \\'A\\\\xC4B\\\\xE8C\\'                # Hex escapes work\\n>>> S\\n\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print S                          # But some may print oddly, unless decoded\\nA─BΦC\\n>>> print S.decode(\\'latin-1\\')\\nAÄBèC\\n\\n>>> S = \\'A\\\\u00C4B\\\\U000000E8C\\'        # Not Unicode escapes: taken literally!\\n>>> S\\n\\'A\\\\\\\\u00C4B\\\\\\\\U000000E8C\\'\\n>>> print S\\nA\\\\u00C4B\\\\U000000E8C\\n>>> len(S)\\n19\\n\\nMixing string types in 2.X\\nLike 3.X’s str and bytes, 2.X’s unicode and str share nearly identical operation sets,\\nso unless you need to convert to other encodings you can often treat unicode as though\\nit were str. One of the primary differences between 2.X and 3.X, though, is that uni\\ncode and non-Unicode str objects can be freely mixed in 2.X expressions—as long as\\nthe str is compatible with the unicode object, Python will automatically convert it up\\nto unicode:\\n\\n>>> u\\'ab\\' + \\'cd\\'                     # Can mix if compatible in 2.X\\nu\\'abcd\\'                              # But \\'ab\\' + b\\'cd\\' not allowed in 3.X\\n\\nHowever, this liberal approach to mixing string types in 2.X works only if the 8-bit\\nstring happens to contain only 7-bit (ASCII) bytes:\\n\\n1186 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c>>> S =  \\'A\\\\xC4B\\\\xE8C\\'               # Can\\'t mix in 2.X if str is non-ASCII!\\n>>> U = u\\'A\\\\xC4B\\\\xE8C\\'\\n>>> S + U\\nUnicodeDecodeError: \\'ascii\\' codec can\\'t decode byte 0xc4 in position 1: ordinal\\nnot in range(128)\\n\\n>>> \\'abc\\' + U                        # Can mix only if str is all 7-bit ASCII\\nu\\'abcA\\\\xc4B\\\\xe8C\\'\\n>>> print \\'abc\\' + U                  # Use print to display characters\\nabcAÄBèC\\n\\n>>> S.decode(\\'latin-1\\') + U          # Manual conversion may be required in 2.X too\\nu\\'A\\\\xc4B\\\\xe8CA\\\\xc4B\\\\xe8C\\'\\n>>> print S.decode(\\'latin-1\\') + U\\nAÄBèCAÄBèC\\n\\n>>> print u\\'\\\\xA3\\' + \\'999.99\\'         # Also see Chapter 25\\'s currency example\\n£999.99\\n\\nBy contrast, in 3.X, str and bytes never mix automatically and require manual con-\\nversions—the  preceding  code  actually  runs  in  3.3,  but  only  because  2.X’s  Unicode\\nliteral is taken to be the same as a normal string by 3.X (the  u is ignored); the 3.X\\nequivalent would be a str added to a bytes (i.e., \\'ab\\' + b\\'cd\\') which fails in 3.X, unless\\nobjects are converted to a common type.\\nIn 2.X, though, the difference in types is often trivial to your code. Like normal strings,\\nUnicode strings may be concatenated, indexed, sliced, matched with the re module,\\nand so on, and they cannot be changed in place. If you ever need to convert between\\nthe two types explicitly, you can use the built-in str and unicode functions as shown\\nearlier:\\n\\n>>> str(u\\'spam\\')                     # Unicode to normal\\n\\'spam\\'\\n>>> unicode(\\'spam\\')                  # Normal to Unicode\\nu\\'spam\\'\\n\\nIf you are using Python 2.X, also watch for an example of your different file interface\\nlater in this chapter. Your open call supports only files of 8-bit bytes, returning their\\ncontents as str strings, and it’s up to you to interpret the contents as text or binary data\\nand decode if needed. To read and write Unicode files and encode or decode their\\ncontent automatically, use 2.X’s codecs.open call we’ll see in action later in this chapter.\\nThis  call  provides  much  the  same  functionality  as  3.X’s  open  and  uses  2.X  unicode\\nobjects to represent file content—reading a file translates encoded bytes into decoded\\nUnicode characters, and writing translates strings to the desired encoding specified\\nwhen the file is opened.\\n\\nSource File Character Set Encoding Declarations\\nFinally, Unicode escape codes are fine for the occasional Unicode character in string\\nliterals, but they can become tedious if you need to embed non-ASCII text in your\\n\\nCoding Unicode Strings\\n\\n| 1187\\n\\n\\x0cstrings frequently. To interpret the content of strings you code and hence embed within\\nthe text of your script files, Python uses the UTF-8 encoding by default, but it allows\\nyou to change this to support arbitrary character sets by including a comment that\\nnames your desired encoding. The comment must be of this form and must appear as\\neither the first or second line in your script in either Python 2.X or 3.X:\\n\\n# -*- coding: latin-1 -*-\\n\\nWhen a comment of this form is present, Python will recognize strings represented\\nnatively in the given encoding. This means you can edit your script file in a text editor\\nthat  accepts  and  displays  accented  and  other  non-ASCII  characters  correctly,  and\\nPython will decode them correctly in your string literals. For example, notice how the\\ncomment at the top of the following file, text.py, allows Latin-1 characters to be em-\\nbedded in strings, which are themselves embedded in the script file’s text:\\n\\n# -*- coding: latin-1 -*-\\n# Any of the following string literal forms work in latin-1.\\n# Changing the encoding above to either ascii or utf-8 fails,\\n# because the 0xc4 and 0xe8 in myStr1 are not valid in either.\\n\\nmyStr1 = \\'aÄBèC\\'\\n\\nmyStr2 = \\'A\\\\u00c4B\\\\U000000e8C\\'\\n\\nmyStr3 = \\'A\\' + chr(0xC4) + \\'B\\' + chr(0xE8) + \\'C\\'\\n\\nimport sys\\nprint(\\'Default encoding:\\', sys.getdefaultencoding())\\n\\nfor aStr in myStr1, myStr2, myStr3:\\n    print(\\'{0}, strlen={1}, \\'.format(aStr, len(aStr)), end=\\'\\')\\n\\n    bytes1 = aStr.encode()              # Per default utf-8: 2 bytes for non-ASCII\\n    bytes2 = aStr.encode(\\'latin-1\\')     # One byte per char\\n   #bytes3 = aStr.encode(\\'ascii\\')       # ASCII fails: outside 0..127 range\\n\\n    print(\\'byteslen1={0}, byteslen2={1}\\'.format(len(bytes1), len(bytes2)))\\n\\nWhen run, this script produces the following output, giving, for each of three coding\\ntechniques, the string, its length, and the lengths of its UTF-8 and Latin-1 encoded byte\\nstring forms.\\n\\nC:\\\\code> C:\\\\python33\\\\python text.py\\nDefault encoding: utf-8\\naÄBèC, strlen=5, byteslen1=7, byteslen2=5\\nAÄBèC, strlen=5, byteslen1=7, byteslen2=5\\nAÄBèC, strlen=5, byteslen1=7, byteslen2=5\\n\\nSince many programmers are likely to fall back on the standard UTF-8 encoding, I’ll\\ndefer to Python’s standard manual set for more details on this option and other ad-\\nvanced  Unicode  support  topics,  such  as  properties  and  character  name  escapes  in\\nstrings I’m omitting here. For this chapter, let’s take a quick look at the new byte string\\nobject types in Python 3.X, before moving on to its file and tool changes.\\n\\n1188 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cFor an additional example of non-ASCII character coding and source\\nfile declarations, see the currency symbols used in the money formatting\\nexample of Chapter 25, as well as its associated file in this book’s ex-\\namples package, formats_currency2.py. The latter requires a source-file\\ndeclaration to be usable by Python, because it embeds non-ASCII cur-\\nrency symbol characters. This example also illustrates the portability\\ngains possible when using 2.X’s Unicode literal in 3.X code in 3.3 and\\nlater.\\n\\nUsing 3.X bytes Objects\\nWe studied a wide variety of operations available for Python 3.X’s general str string\\ntype in Chapter 7; the basic string type works identically in 2.X and 3.X, so we won’t\\nrehash this topic. Instead, let’s dig a bit deeper into the operation sets provided by the\\nnew bytes type in 3.X.\\nAs mentioned previously, the 3.X bytes object is a sequence of small integers, each of\\nwhich is in the range 0 through 255, that happens to print as ASCII characters when\\ndisplayed. It supports sequence operations and most of the same methods available on\\nstr objects (and present in 2.X’s str type). However, bytes does not support the for\\nmat method or the % formatting expression, and you cannot mix and match bytes and\\nstr type objects without explicit conversions—you generally will use all str type objects\\nand text files for text data, and all bytes type objects and binary files for binary data.\\n\\nMethod Calls\\nIf you really want to see what attributes str has that bytes doesn’t, you can always\\ncheck their dir built-in function results. The output can also tell you something about\\nthe  expression  operators  they  support  (e.g.,  __mod__  and  __rmod__  implement  the  %\\noperator):\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n\\n# Attributes in str but not bytes\\n>>> set(dir(\\'abc\\')) - set(dir(b\\'abc\\'))\\n{\\'isdecimal\\', \\'__mod__\\', \\'__rmod__\\', \\'format_map\\', \\'isprintable\\',\\n\\'casefold\\', \\'format\\', \\'isnumeric\\', \\'isidentifier\\', \\'encode\\'}\\n\\n# Attributes in bytes but not str\\n>>> set(dir(b\\'abc\\')) - set(dir(\\'abc\\'))\\n{\\'decode\\', \\'fromhex\\'}\\n\\nAs you can see, str and bytes have almost identical functionality. Their unique at-\\ntributes are generally methods that don’t apply to the other; for instance, decode trans-\\nlates a raw bytes into its str representation, and encode translates a string into its raw\\nbytes representation. Most of the methods are the same, though bytes methods require\\nbytes arguments (again, 3.X string types don’t mix). Also recall that bytes objects are\\n\\nUsing 3.X bytes Objects\\n\\n| 1189\\n\\n\\x0cimmutable, just like str objects in both 2.X and 3.X (error messages here have been\\nshortened for brevity):\\n\\n>>> B = b\\'spam\\'                    # b\\'...\\' bytes literal\\n>>> B.find(b\\'pa\\')\\n1\\n\\n>>> B.replace(b\\'pa\\', b\\'XY\\')        # bytes methods expect bytes arguments\\nb\\'sXYm\\'\\n\\n>>> B.split(b\\'pa\\')                 # bytes methods return bytes results\\n[b\\'s\\', b\\'m\\']\\n\\n>>> B\\nb\\'spam\\'\\n>>> B[0] = \\'x\\'\\nTypeError: \\'bytes\\' object does not support item assignment\\n\\nOne notable difference is that string formatting works only on str objects in 3.X, not\\non bytes objects (see Chapter 7 for more on string formatting expressions and meth-\\nods):\\n\\n>>> \\'%s\\' % 99\\n\\'99\\'\\n>>> b\\'%s\\' % 99\\nTypeError: unsupported operand type(s) for %: \\'bytes\\' and \\'int\\'\\n\\n>>> \\'{0}\\'.format(99)\\n\\'99\\'\\n>>> b\\'{0}\\'.format(99)\\nAttributeError: \\'bytes\\' object has no attribute \\'format\\'\\n\\nSequence Operations\\nBesides method calls, all the usual generic sequence operations you know (and possibly\\nlove) from Python 2.X strings and lists work as expected on both str and bytes in 3.X;\\nthis includes indexing, slicing, concatenation, and so on. Notice in the following that\\nindexing a bytes object returns an integer giving the byte’s binary value; bytes really is\\na sequence of 8-bit integers, but for convenience prints as a string of ASCII-coded char-\\nacters where possible when displayed as a whole. To check a given byte’s value, use\\nthe chr built-in to convert it back to its character, as in the following:\\n\\n>>> B = b\\'spam\\'                  # A sequence of small ints\\n>>> B                            # Prints as ASCII characters (and/or hex escapes)\\nb\\'spam\\'\\n\\n>>> B[0]                         # Indexing yields an int\\n115\\n>>> B[-1]\\n109\\n\\n>>> chr(B[0])                    # Show character for int\\n\\'s\\'\\n\\n1190 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c>>> list(B)                      # Show all the byte\\'s int values\\n[115, 112, 97, 109]\\n\\n>>> B[1:], B[:-1]\\n(b\\'pam\\', b\\'spa\\')\\n>>> len(B)\\n4\\n>>> B + b\\'lmn\\'\\nb\\'spamlmn\\'\\n>>> B * 4\\nb\\'spamspamspamspam\\'\\n\\nOther Ways to Make bytes Objects\\nSo far, we’ve been mostly making bytes objects with the b\\'...\\' literal syntax. We can\\nalso create them by calling the bytes constructor with a str and an encoding name,\\ncalling the bytes constructor with an iterable of integers representing byte values, or\\nencoding a str object per the default (or passed-in) encoding. As we’ve seen, encoding\\ntakes a text str and returns the raw encoded byte values of the string per the encoding\\nspecified; conversely, decoding takes a raw bytes sequence and translates it to its str\\ntext string representation—a series of Unicode characters. Both operations create new\\nstring objects:\\n\\n>>> B = b\\'abc\\'                   # Literal\\n>>> B\\nb\\'abc\\'\\n\\n>>> B = bytes(\\'abc\\', \\'ascii\\')    # Constructor with encoding name\\n>>> B\\nb\\'abc\\'\\n\\n>>> ord(\\'a\\')\\n97\\n>>> B = bytes([97, 98, 99])      # Integer iterable\\n>>> B\\nb\\'abc\\'\\n\\n>>> B = \\'spam\\'.encode()          # str.encode() (or bytes())\\n>>> B\\nb\\'spam\\'\\n>>>\\n>>> S = B.decode()               # bytes.decode() (or str())\\n>>> S\\n\\'spam\\'\\n\\nFrom  a  functional  perspective,  the  last  two  of  these  operations  are  really  tools  for\\nconverting between str and bytes, a topic introduced earlier and expanded upon in the\\nnext section.\\n\\nUsing 3.X bytes Objects\\n\\n| 1191\\n\\n\\x0cMixing String Types\\nIn the replace call of the section “Method Calls” on page 1189, we had to pass in two\\nbytes objects—str types won’t work there. Although Python 2.X automatically con-\\nverts str to and from unicode when possible (i.e., when the str is 7-bit ASCII text),\\nPython 3.X requires specific string types in some contexts and expects manual conver-\\nsions if needed:\\n\\n# Must pass expected types to function and method calls\\n\\n>>> B = b\\'spam\\'\\n\\n>>> B.replace(\\'pa\\', \\'XY\\')\\nTypeError: expected an object with the buffer interface\\n\\n>>> B.replace(b\\'pa\\', b\\'XY\\')\\nb\\'sXYm\\'\\n\\n>>> B = B\\'spam\\'\\n>>> B.replace(bytes(\\'pa\\'), bytes(\\'xy\\'))\\nTypeError: string argument without an encoding\\n\\n>>> B.replace(bytes(\\'pa\\', \\'ascii\\'), bytes(\\'xy\\', \\'utf-8\\'))\\nb\\'sxym\\'\\n\\n# Must convert manually in 3.X mixed-type expressions\\n\\n>>> b\\'ab\\' + \\'cd\\'\\nTypeError: can\\'t concat bytes to str\\n\\n>>> b\\'ab\\'.decode() + \\'cd\\'                   # bytes to str\\n\\'abcd\\'\\n>>> b\\'ab\\' + \\'cd\\'.encode()                   # str to bytes\\nb\\'abcd\\'\\n>>> b\\'ab\\' + bytes(\\'cd\\', \\'ascii\\')            # str to bytes\\nb\\'abcd\\'\\n\\nAlthough you can create bytes objects yourself to represent packed binary data, they\\ncan also be made automatically by reading files opened in binary mode, as we’ll see in\\nmore detail later in this chapter. First, though, let’s introduce bytes’s very close, and\\nmutable, cousin.\\n\\nUsing 3.X/2.6+ bytearray Objects\\nSo far we’ve focused on str and bytes, because they subsume Python 2’s unicode and\\nstr. Python 3.X grew a third string type, though—bytearray, a mutable sequence of\\nintegers in the range 0 through 255, which is a mutable variant of bytes. As such, it\\nsupports the same string methods and sequence operations as bytes, as well as many\\nof the mutable in-place-change operations supported by lists.\\n\\n1192 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cBytearrays support in-place changes to both truly binary data as well as simple forms\\nof text such as ASCII, which can be represented with 1 byte per character (richer Uni-\\ncode text generally requires Unicode strings, which are still immutable). The bytear\\nray type is also available in Python 2.6 and 2.7 as a back-port from 3.X, but it does not\\nenforce the strict text/binary distinction there that it does in 3.X.\\n\\nbytearrays in Action\\nLet’s take a quick tour. We can create bytearray objects by calling the bytearray built-\\nin. In Python 2.X, any string may be used to initialize:\\n# Creation in 2.6/2.7: a mutable sequence of small (0..255) ints\\n\\n>>> S = \\'spam\\'\\n>>> C = bytearray(S)                      # A back-port from 3.X in 2.6+\\n>>> C                                     # b\\'..\\' == \\'..\\' in 2.6+ (str)\\nbytearray(b\\'spam\\')\\n\\nIn Python 3.X, an encoding name or byte string is required, because text and binary\\nstrings do not mix (though byte strings may reflect encoded Unicode text):\\n\\n# Creation in 3.X: text/binary do not mix\\n\\n>>> S = \\'spam\\'\\n>>> C = bytearray(S)\\nTypeError: string argument without an encoding\\n\\n>>> C = bytearray(S, \\'latin1\\')            # A content-specific type in 3.X\\n>>> C\\nbytearray(b\\'spam\\')\\n\\n>>> B = b\\'spam\\'                           # b\\'..\\' != \\'..\\' in 3.X (bytes/str)\\n>>> C = bytearray(B)\\n>>> C\\nbytearray(b\\'spam\\')\\n\\nOnce created, bytearray objects are sequences of small integers like bytes and are mu-\\ntable like lists, though they require an integer for index assignments, not a string (all\\nof the following is a continuation of this session and is run under Python 3.X unless\\notherwise noted—see comments for 2.X usage notes):\\n\\n# Mutable, but must assign ints, not strings\\n\\n>>> C[0]\\n115\\n\\n>>> C[0] = \\'x\\'                            # This and the next work in 2.6/2.7\\nTypeError: an integer is required\\n>>> C[0] = b\\'x\\'\\nTypeError: an integer is required\\n\\n>>> C[0] = ord(\\'x\\')                       # Use ord() to get a character\\'s ordinal\\n>>> C\\n\\nUsing 3.X/2.6+ bytearray Objects\\n\\n| 1193\\n\\n\\x0cbytearray(b\\'xpam\\')\\n\\n>>> C[1] = b\\'Y\\'[0]                        # Or index a byte string\\n>>> C\\nbytearray(b\\'xYam\\')\\n\\nProcessing bytearray objects borrows from both strings and lists, since they are mutable\\nbyte strings. While the byterrray’s methods overlap with both str and bytes, it also\\nhas many of the list’s mutable methods. Besides named methods, the __iadd__ and\\n__setitem__ methods in bytearray implement += in-place concatenation and index as-\\nsignment, respectively:\\n\\n# in bytes but not bytearray\\n>>> set(dir(b\\'abc\\')) - set(dir(bytearray(b\\'abc\\')))\\n{\\'__getnewargs__\\'}\\n\\n# in bytearray but not bytes\\n>>> set(dir(bytearray(b\\'abc\\'))) - set(dir(b\\'abc\\'))\\n{\\'__iadd__\\', \\'reverse\\', \\'__setitem__\\', \\'extend\\', \\'copy\\', \\'__alloc__\\',\\n\\'__delitem__\\', \\'__imul__\\', \\'remove\\', \\'clear\\', \\'insert\\', \\'append\\', \\'pop\\'}\\n\\nYou can change a bytearray in place with both index assignment, as you’ve just seen,\\nand list-like methods like those shown here (to change text in place prior to 2.6, you\\nwould need to convert to and then from a list, with list(str) and \\'\\'.join(list)—see\\nChapter 4 and Chapter 6 for examples):\\n\\n# Mutable method calls\\n\\n>>> C\\nbytearray(b\\'xYam\\')\\n\\n>>> C.append(b\\'LMN\\')                      # 2.X requires string of size 1\\nTypeError: an integer is required\\n\\n>>> C.append(ord(\\'L\\'))\\n>>> C\\nbytearray(b\\'xYamL\\')\\n\\n>>> C.extend(b\\'MNO\\')\\n>>> C\\nbytearray(b\\'xYamLMNO\\')\\n\\nAll the usual sequence operations and string methods work on bytearrays, as you would\\nexpect (notice that like bytes objects, their expressions and methods expect bytes ar-\\nguments, not str arguments):\\n\\n# Sequence operations and string methods\\n\\n>>> C\\nbytearray(b\\'xYamLMNO\\')\\n\\n>>> C + b\\'!#\\'\\nbytearray(b\\'xYamLMNO!#\\')\\n>>> C[0]\\n120\\n\\n1194 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c>>> C[1:]\\nbytearray(b\\'YamLMNO\\')\\n>>> len(C)\\n8\\n\\n>>> C.replace(\\'xY\\', \\'sp\\')                 # This works in 2.X\\nTypeError: Type str doesn\\'t support the buffer API\\n>>> C.replace(b\\'xY\\', b\\'sp\\')\\nbytearray(b\\'spamLMNO\\')\\n\\n>>> C\\nbytearray(b\\'xYamLMNO\\')\\n>>> C * 4\\nbytearray(b\\'xYamLMNOxYamLMNOxYamLMNOxYamLMNO\\')\\n\\nPython 3.X String Types Summary\\nFinally, by way of summary, the following examples demonstrate how bytes and byte\\narray objects are sequences of ints, and str objects are sequences of characters:\\n\\n# Binary versus text\\n\\n>>> B                                     # B is same as S in 2.6/2.7\\nb\\'spam\\'\\n>>> list(B)\\n[115, 112, 97, 109]\\n\\n>>> C\\nbytearray(b\\'xYamLMNO\\')\\n>>> list(C)\\n[120, 89, 97, 109, 76, 77, 78, 79]\\n\\n>>> S\\n\\'spam\\'\\n>>> list(S)\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\']\\n\\nAlthough all three Python 3.X string types can contain character values and support\\nmany of the same operations, again, you should always:\\n\\n• Use str for textual data.\\n• Use bytes for binary data.\\n• Use bytearray for binary data you wish to change in place.\\n\\nRelated tools such as files, the next section’s topic, often make the choice for you.\\n\\nUsing Text and Binary Files\\nThis section expands on the impact of Python 3.X’s string model on the file processing\\nbasics introduced earlier in the book. As mentioned earlier, the mode in which you\\nopen a file is crucial—it determines which object type you will use to represent the file’s\\n\\nUsing Text and Binary Files\\n\\n| 1195\\n\\n\\x0ccontent in your script. Text mode implies str objects, and binary mode implies bytes\\nobjects:\\n\\n• Text-mode files interpret file contents according to a Unicode encoding—either the\\ndefault for your platform, or one whose name you pass in. By passing in an encoding\\nname to open, you can force conversions for various types of Unicode files. Text-\\nmode  files  also  perform  universal  line-end  translations:  by  default,  all  line-end\\nforms map to the single \\'\\\\n\\' character in your script, regardless of the platform on\\nwhich you run it. As described earlier, text files also handle reading and writing\\nthe byte order mark (BOM) stored at the start-of-file in some Unicode encoding\\nschemes.\\n\\n• Binary-mode files instead return file content to you raw, as a sequence of integers\\nrepresenting byte values, with no encoding or decoding and no line-end transla-\\ntions.\\n\\nThe second argument to open determines whether you want text or binary processing,\\njust  as  it  does  in  2.X  Python—adding  a  b  to  this  string  implies  binary  mode  (e.g.,\\n\"rb\" to read binary data files). The default mode is \"rt\"; this is the same as \"r\", which\\nmeans text input (just as in 2.X).\\nIn 3.X, though, this mode argument to open also implies an object type for file content\\nrepresentation, regardless of the underlying platform—text files return a str for reads\\nand expect one for writes, but binary files return a bytes for reads and expect one (or\\na bytearray) for writes.\\n\\nText File Basics\\nTo demonstrate, let’s begin with basic file I/O. As long as you’re processing basic text\\nfiles (e.g., ASCII) and don’t care about circumventing the platform-default encoding of\\nstrings, files in 3.X look and feel much as they do in 2.X (for that matter, so do strings\\nin general). The following, for instance, writes one line of text to a file and reads it back\\nin 3.X, exactly as it would in 2.X (note that file is no longer a built-in name in 3.X, so\\nit’s perfectly OK to use it as a variable here):\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n# Basic text files (and strings) work the same as in 2.X\\n\\n>>> file = open(\\'temp\\', \\'w\\')\\n>>> size = file.write(\\'abc\\\\n\\')       # Returns number of characters written\\n>>> file.close()                     # Manual close to flush output buffer\\n\\n>>> file = open(\\'temp\\')              # Default mode is \"r\" (== \"rt\"): text input\\n>>> text = file.read()\\n>>> text\\n\\'abc\\\\n\\'\\n>>> print(text)\\nabc\\n\\n1196 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cText and Binary Modes in 2.X and 3.X\\nIn Python 2.X, there is no major distinction between text and binary files—both accept\\nand return content as str strings. The only major difference is that text files automat-\\nically map \\\\n end-of-line characters to and from \\\\r\\\\n on Windows, while binary files\\ndo not (I’m stringing operations together into one-liners here just for brevity):\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> open(\\'temp\\', \\'w\\').write(\\'abd\\\\n\\')         # Write in text mode: adds \\\\r\\n>>> open(\\'temp\\', \\'r\\').read()                 # Read in text mode: drops \\\\r\\n\\'abd\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Read in binary mode: verbatim\\n\\'abd\\\\r\\\\n\\'\\n\\n>>> open(\\'temp\\', \\'wb\\').write(\\'abc\\\\n\\')        # Write in binary mode\\n>>> open(\\'temp\\', \\'r\\').read()                 # \\\\n not expanded to \\\\r\\\\n\\n\\'abc\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()\\n\\'abc\\\\n\\'\\n\\nIn Python 3.X, things are a bit more complex because of the distinction between str\\nfor text data and bytes for binary data. To demonstrate, let’s write a text file and read\\nit back in both modes in 3.X. Notice that we are required to provide a str for writing,\\nbut reading gives us a str or a bytes, depending on the open mode:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n# Write and read a text file\\n>>> open(\\'temp\\', \\'w\\').write(\\'abc\\\\n\\')         # Text mode output, provide a str\\n4\\n>>> open(\\'temp\\', \\'r\\').read()                 # Text mode input, returns a str\\n\\'abc\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Binary mode input, returns a bytes\\nb\\'abc\\\\r\\\\n\\'\\n\\nNotice how on Windows text-mode files translate the \\\\n end-of-line character to \\\\r\\\\n\\non output; on input, text mode translates the \\\\r\\\\n back to \\\\n, but binary-mode files do\\nnot. This is the same in 2.X, and it’s normally what we want—text files should for\\nportability map end-of-line markers to and from \\\\n (which is what is actually present\\nin files in Linux, where no mapping occurs), and such translations should never occur\\nfor binary data (where end-of-line bytes are irrelevant). Although you can control this\\nbehavior with extra open arguments in 3.X if desired, the default usually works well.\\nNow let’s do the same again, but with a binary file. We provide a bytes to write in this\\ncase, and we still get back a str or a bytes, depending on the input mode:\\n\\n# Write and read a binary file\\n>>> open(\\'temp\\', \\'wb\\').write(b\\'abc\\\\n\\')       # Binary mode output, provide a bytes\\n4\\n>>> open(\\'temp\\', \\'r\\').read()                 # Text mode input, returns a str\\n\\'abc\\\\n\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Binary mode input, returns a bytes\\nb\\'abc\\\\n\\'\\n\\nUsing Text and Binary Files\\n\\n| 1197\\n\\n\\x0cNote that the \\\\n end-of-line character is not expanded to \\\\r\\\\n in binary-mode output\\n—again, a desired result for binary data. Type requirements and file behavior are the\\nsame even if the data we’re writing to the binary file is truly binary in nature. In the\\nfollowing, for example, the \"\\\\x00\" is a binary zero byte and not a printable character:\\n\\n# Write and read truly binary data\\n>>> open(\\'temp\\', \\'wb\\').write(b\\'a\\\\x00c\\')      # Provide a bytes\\n3\\n>>> open(\\'temp\\', \\'r\\').read()                 # Receive a str\\n\\'a\\\\x00c\\'\\n>>> open(\\'temp\\', \\'rb\\').read()                # Receive a bytes\\nb\\'a\\\\x00c\\'\\n\\nBinary-mode files always return contents as a bytes object, but accept either a bytes or\\nbytearray object for writing; this naturally follows, given that bytearray is basically just\\na mutable variant of bytes. In fact, most APIs in Python 3.X that accept a bytes also\\nallow a bytearray:\\n\\n# bytearrays work too\\n>>> BA = bytearray(b\\'\\\\x01\\\\x02\\\\x03\\')\\n\\n>>> open(\\'temp\\', \\'wb\\').write(BA)\\n3\\n>>> open(\\'temp\\', \\'r\\').read()\\n\\'\\\\x01\\\\x02\\\\x03\\'\\n>>> open(\\'temp\\', \\'rb\\').read()\\nb\\'\\\\x01\\\\x02\\\\x03\\'\\n\\nType and Content Mismatches in 3.X\\nNotice that you cannot get away with violating Python’s str/bytes type distinction\\nwhen it comes to files. As the following examples illustrate, we get errors (shortened\\nhere) if we try to write a bytes to a text file or a str to a binary file (the exact text of the\\nerror messages here is prone to change):\\n\\n# Types are not flexible for file content\\n>>> open(\\'temp\\', \\'w\\').write(\\'abc\\\\n\\')         # Text mode makes and requires str\\n4\\n>>> open(\\'temp\\', \\'w\\').write(b\\'abc\\\\n\\')\\nTypeError: must be str, not bytes\\n\\n>>> open(\\'temp\\', \\'wb\\').write(b\\'abc\\\\n\\')       # Binary mode makes and requires bytes\\n4\\n>>> open(\\'temp\\', \\'wb\\').write(\\'abc\\\\n\\')\\nTypeError: \\'str\\' does not support the buffer interface\\n\\nThis makes sense: text has no meaning in binary terms, before it is encoded. Although\\nit is often possible to convert between the types by encoding str and decoding bytes,\\nas described earlier in this chapter, you will usually want to stick to either str for text\\ndata or bytes for binary data. Because the str and bytes operation sets largely intersect,\\nthe choice won’t be much of a dilemma for most programs (see the string tools coverage\\nin the final section of this chapter for some prime examples of this).\\n\\n1198 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cIn addition to type constraints, file content can matter in 3.X. Text-mode output files\\nrequire a str instead of a bytes for content, so there is no way in 3.X to write truly\\nbinary data to a text-mode file. Depending on the encoding rules, bytes outside the\\ndefault character set can sometimes be embedded in a normal string, and they can\\nalways be written in binary mode (some of the following raise errors when displaying\\ntheir string results in Pythons prior to 3.3, but the file operations work successfully):\\n\\n# Can\\'t read truly binary data in text mode\\n>>> chr(0xFF)                                   # FF is a valid char, FE is not\\n\\'ÿ\\'\\n>>> chr(0xFE)                                   # An error in some Pythons\\n\\'\\\\xfe\\'\\n\\n>>> open(\\'temp\\', \\'w\\').write(b\\'\\\\xFF\\\\xFE\\\\xFD\\')    # Can\\'t use arbitrary bytes!\\nTypeError: must be str, not bytes\\n\\n>>> open(\\'temp\\', \\'w\\').write(\\'\\\\xFF\\\\xFE\\\\xFD\\')     # Can write if embeddable in str\\n3\\n>>> open(\\'temp\\', \\'wb\\').write(b\\'\\\\xFF\\\\xFE\\\\xFD\\')   # Can also write in binary mode\\n3\\n\\n>>> open(\\'temp\\', \\'rb\\').read()                   # Can always read as binary bytes\\nb\\'\\\\xff\\\\xfe\\\\xfd\\'\\n\\n>>> open(\\'temp\\', \\'r\\').read()                    # Can\\'t read text unless decodable!\\n\\'ÿ\\\\xfe\\\\xfd\\'                                     # An error in some Pythons\\n\\nIn general, however, because text-mode input files in 3.X must be able to decode con-\\ntent per a Unicode encoding, there is no way to read truly binary data in text mode, as\\nthe next section explains.\\n\\nUsing Unicode Files\\nSo far, we’ve been reading and writing basic text and binary files. It turns out to be easy\\nto read and write Unicode text stored in files too, because the 3.X open call accepts an\\nencoding for text files, and arranges to run the required encoding and decoding for us\\nautomatically as data is transferred. This allows us to process a variety of Unicode text\\ncreated with different encodings than the default for the platform, and store the same\\ntext in different encodings for different purposes.\\n\\nReading and Writing Unicode in 3.X\\nIn fact, we can effectively convert a string to different encoded forms both manually\\nwith method calls as we did earlier, and automatically on file input and output. We’ll\\nuse the following Unicode string in this section to demonstrate:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> S = \\'A\\\\xc4B\\\\xe8C\\'           # Five-character decoded string, non-ASCII\\n>>> S\\n\\'AÄBèC\\'\\n\\nUsing Unicode Files\\n\\n| 1199\\n\\n\\x0c>>> len(S)\\n5\\n\\nManual encoding\\nAs we’ve already learned, we can always encode such a string to raw bytes according\\nto the target encoding name:\\n# Encode manually with methods\\n>>> L = S.encode(\\'latin-1\\')     # 5 bytes when encoded as latin-1\\n>>> L\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n>>> len(L)\\n5\\n\\n>>> U = S.encode(\\'utf-8\\')       # 7 bytes when encoded as utf-8\\n>>> U\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n>>> len(U)\\n7\\n\\nFile output encoding\\nNow, to write our string to a text file in a particular encoding, we can simply pass the\\ndesired encoding name to open—although we could manually encode first and write in\\nbinary mode, there’s no need to:\\n\\n# Encoding automatically when written\\n>>> open(\\'latindata\\', \\'w\\', encoding=\\'latin-1\\').write(S)    # Write as latin-1\\n5\\n>>> open(\\'utf8data\\', \\'w\\', encoding=\\'utf-8\\').write(S)       # Write as utf-8\\n5\\n\\n>>> open(\\'latindata\\', \\'rb\\').read()                         # Read raw bytes\\nb\\'A\\\\xc4B\\\\xe8C\\'\\n\\n>>> open(\\'utf8data\\', \\'rb\\').read()                          # Different in files\\nb\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n\\nFile input decoding\\nSimilarly, to read arbitrary Unicode data, we simply pass in the file’s encoding type\\nname to open, and it decodes from raw bytes to strings automatically; we could read\\nraw bytes and decode manually too, but that can be tricky when reading in blocks (we\\nmight read an incomplete character), and it isn’t necessary:\\n\\n# Decoding automatically when read\\n>>> open(\\'latindata\\', \\'r\\', encoding=\\'latin-1\\').read()      # Decoded on input\\n\\'AÄBèC\\'\\n>>> open(\\'utf8data\\', \\'r\\', encoding=\\'utf-8\\').read()         # Per encoding type\\n\\'AÄBèC\\'\\n\\n>>> X = open(\\'latindata\\', \\'rb\\').read()                     # Manual decoding:\\n>>> X.decode(\\'latin-1\\')                                    # Not necessary\\n\\n1200 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c\\'AÄBèC\\'\\n>>> X = open(\\'utf8data\\', \\'rb\\').read()\\n>>> X.decode()                                             # UTF-8 is default\\n\\'AÄBèC\\'\\n\\nDecoding mismatches\\nFinally, keep in mind that this behavior of files in 3.X limits the kind of content you\\ncan load as text. As suggested in the prior section, Python 3.X really must be able to\\ndecode the data in text files into a str string, according to either the default or a passed-\\nin Unicode encoding name. Trying to open a truly binary data file in text mode, for\\nexample, is unlikely to work in 3.X even if you use the correct object types:\\n\\n>>> file = open(r\\'C:\\\\Python33\\\\python.exe\\', \\'r\\')\\n>>> text = file.read()\\nUnicodeDecodeError: \\'charmap\\' codec can\\'t decode byte 0x90 in position 2: ...\\n\\n>>> file = open(r\\'C:\\\\Python33\\\\python.exe\\', \\'rb\\')\\n>>> data = file.read()\\n>>> data[:20]\\nb\\'MZ\\\\x90\\\\x00\\\\x03\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\xff\\\\xff\\\\x00\\\\x00\\\\xb8\\\\x00\\\\x00\\\\x00\\'\\n\\nThe first of these examples might not fail in Python 2.X (normal files do not decode\\ntext), even though it probably should: reading the file may return corrupted data in the\\nstring, due to automatic end-of-line translations in text mode (any embedded \\\\r\\\\n bytes\\nwill be translated to \\\\n on Windows when read). To treat file content as Unicode text\\nin 2.X, we need to use special tools instead of the general open built-in function, as we’ll\\nsee in a moment. First, though, let’s turn to a more explosive topic.\\n\\nHandling the BOM in 3.X\\nAs described earlier in this chapter, some encoding schemes store a special byte order\\nmarker (BOM) sequence at the start of files, to specify data endianness (which end of\\na string of bits is most significant to its value) or declare the encoding type. Python both\\nskips this marker on input and writes it on output if the encoding name implies it, but\\nwe sometimes must use a specific encoding name to force BOM processing explicitly.\\nFor example, in the UTF-16 and UTF-32 encodings, the BOM specifies big- or little-\\nendian format. A UTF-8 text file may also include a BOM, but this isn’t guaranteed,\\nand serves only to declare that it is UTF-8 in general. When reading and writing data\\nusing these encoding schemes, Python automatically skips or writes the BOM if it is\\neither implied by a general encoding name, or if you provide a more specific encoding\\nname to force the issue. For instance:\\n\\n• In UTF-16, the BOM is always processed for “utf-16,” and the more specific en-\\n\\ncoding name “utf-16-le” denotes little-endian format.\\n\\n• In UTF-8, the more specific encoding “utf-8-sig” forces Python to both skip and\\nwrite a BOM on input and output, respectively, but the general “utf-8” does not.\\n\\nUsing Unicode Files\\n\\n| 1201\\n\\n\\x0cDropping the BOM in Notepad\\nLet’s make some files with BOMs to see how this works in practice. When you save a\\ntext file in Windows Notepad, you can specify its encoding type in a drop-down list—\\nsimple ASCII text, UTF-8, or little- or big-endian UTF-16. If a two-line text file named\\nspam.txt is saved in Notepad as the encoding type ANSI, for instance, it’s written as\\nsimple ASCII text without a BOM. When this file is read in binary mode in Python, we\\ncan see the actual bytes stored in the file. When it’s read as text, Python performs end-\\nof-line translation by default; we can also decode it as explicit UTF-8 text since ASCII\\nis a subset of this scheme (and UTF-8 is Python 3.X’s default encoding):\\n\\nC:\\\\code> C:\\\\python33\\\\python               # File saved in Notepad\\n>>> import sys\\n>>> sys.getdefaultencoding()\\n\\'utf-8\\'\\n>>> open(\\'spam.txt\\', \\'rb\\').read()         # ASCII (UTF-8) text file\\nb\\'spam\\\\r\\\\nSPAM\\\\r\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\').read()          # Text mode translates line end\\n\\'spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\', encoding=\\'utf-8\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n\\nIf this file is instead saved as UTF-8 in Notepad, it is prepended with a 3-byte UTF-8\\nBOM sequence, and we need to give a more specific encoding name (“utf-8-sig”) to\\nforce Python to skip the marker:\\n\\n>>> open(\\'spam.txt\\', \\'rb\\').read()         # UTF-8 with 3-byte BOM\\nb\\'\\\\xef\\\\xbb\\\\xbfspam\\\\r\\\\nSPAM\\\\r\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\').read()\\n\\'ï»¿spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\', encoding=\\'utf-8\\').read()\\n\\'\\\\ufeffspam\\\\nSPAM\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\', encoding=\\'utf-8-sig\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n\\nIf the file is stored as Unicode big endian in Notepad, we get UTF-16-format data in the\\nfile, with 2-byte (16-bit) characters prepended with a 2-byte BOM sequence—the en-\\ncoding name “utf-16” in Python skips the BOM because it is implied (since all UTF-16\\nfiles have a BOM), and “utf-16-be” handles the big-endian format but does not skip\\nthe BOM (the second of the following fails to print on older Pythons):\\n\\n>>> open(\\'spam.txt\\', \\'rb\\').read()\\nb\\'\\\\xfe\\\\xff\\\\x00s\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\r\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\r\\\\x00\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\').read()\\n\\'\\\\xfeÿ\\\\x00s\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\n\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\n\\\\x00\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\', encoding=\\'utf-16\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'spam.txt\\', \\'r\\', encoding=\\'utf-16-be\\').read()\\n\\'\\\\ufeffspam\\\\nSPAM\\\\n\\'\\n\\nNotepad’s “Unicode,” by the way, is UTF-16 little endian (which, of course, is one of\\nvery many kinds of Unicode encoding!).\\n\\n1202 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cDropping the BOM in Python\\nThe same patterns generally hold true for output. When writing a Unicode file in Python\\ncode, we need a more explicit encoding name to force the BOM in UTF-8—“utf-8”\\ndoes not write (or skip) the BOM, but “utf-8-sig” does:\\n\\n>>> open(\\'temp.txt\\', \\'w\\', encoding=\\'utf-8\\').write(\\'spam\\\\nSPAM\\\\n\\')\\n10\\n>>> open(\\'temp.txt\\', \\'rb\\').read()                         # No BOM\\nb\\'spam\\\\r\\\\nSPAM\\\\r\\\\n\\'\\n\\n>>> open(\\'temp.txt\\', \\'w\\', encoding=\\'utf-8-sig\\').write(\\'spam\\\\nSPAM\\\\n\\')\\n10\\n>>> open(\\'temp.txt\\', \\'rb\\').read()                         # Wrote BOM\\nb\\'\\\\xef\\\\xbb\\\\xbfspam\\\\r\\\\nSPAM\\\\r\\\\n\\'\\n\\n>>> open(\\'temp.txt\\', \\'r\\').read()\\n\\'ï»¿spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-8\\').read()        # Keeps BOM\\n\\'\\\\ufeffspam\\\\nSPAM\\\\n\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-8-sig\\').read()    # Skips BOM\\n\\'spam\\\\nSPAM\\\\n\\'\\n\\nNotice that although “utf-8” does not drop the BOM, data without a BOM can be read\\nwith both “utf-8” and “utf-8-sig”—use the latter for input if you’re not sure whether a\\nBOM is present in a file (and don’t read this paragraph out loud in an airport security\\nline!):\\n\\n>>> open(\\'temp.txt\\', \\'w\\').write(\\'spam\\\\nSPAM\\\\n\\')\\n10\\n>>> open(\\'temp.txt\\', \\'rb\\').read()                         # Data without BOM\\nb\\'spam\\\\r\\\\nSPAM\\\\r\\\\n\\'\\n\\n>>> open(\\'temp.txt\\', \\'r\\').read()                          # Either utf-8 works\\n\\'spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-8\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-8-sig\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n\\nFinally, for the encoding name “utf-16,” the BOM is handled automatically: on out-\\nput, data is written in the platform’s native endianness, and the BOM is always written;\\non input, data is decoded per the BOM, and the BOM is always stripped because it’s\\nstandard in this scheme:\\n\\n>>> sys.byteorder\\n\\'little\\'\\n>>> open(\\'temp.txt\\', \\'w\\', encoding=\\'utf-16\\').write(\\'spam\\\\nSPAM\\\\n\\')\\n10\\n>>> open(\\'temp.txt\\', \\'rb\\').read()\\nb\\'\\\\xff\\\\xfes\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\r\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\r\\\\x00\\\\n\\\\x00\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-16\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n\\nUsing Unicode Files\\n\\n| 1203\\n\\n\\x0cMore specific UTF-16 encoding names can specify different endianness, though you\\nmay have to manually write and skip the BOM yourself in some scenarios if it is required\\nor present—study the following examples for more BOM-making instructions:\\n\\n>>> open(\\'temp.txt\\', \\'w\\', encoding=\\'utf-16-be\\').write(\\'\\\\ufeffspam\\\\nSPAM\\\\n\\')\\n11\\n>>> open(\\'spam.txt\\', \\'rb\\').read()\\nb\\'\\\\xfe\\\\xff\\\\x00s\\\\x00p\\\\x00a\\\\x00m\\\\x00\\\\r\\\\x00\\\\n\\\\x00S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\\\r\\\\x00\\\\n\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-16\\').read()\\n\\'spam\\\\nSPAM\\\\n\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-16-be\\').read()\\n\\'\\\\ufeffspam\\\\nSPAM\\\\n\\'\\n\\nThe  more  specific  UTF-16  encoding  names  work  fine  with  BOM-less  files,  though\\n“utf-16” requires one on input in order to determine byte order:\\n\\n>>> open(\\'temp.txt\\', \\'w\\', encoding=\\'utf-16-le\\').write(\\'SPAM\\')\\n4\\n>>> open(\\'temp.txt\\', \\'rb\\').read()             # OK if BOM not present or expected\\nb\\'S\\\\x00P\\\\x00A\\\\x00M\\\\x00\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-16-le\\').read()\\n\\'SPAM\\'\\n>>> open(\\'temp.txt\\', \\'r\\', encoding=\\'utf-16\\').read()\\nUnicodeError: UTF-16 stream does not start with BOM\\n\\nExperiment with these encodings yourself or see Python’s library manuals for more\\ndetails on the BOM.\\n\\nUnicode Files in 2.X\\nThe preceding discussion applies to Python 3.X’s string types and files. You can achieve\\nsimilar effects for Unicode files in 2.X, but the interface is different. However, if you \\nreplace str with unicode and open with codecs.open, the result is essentially the same\\nin 3.X:\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> S = u\\'A\\\\xc4B\\\\xe8C\\'                                               # 2.X type\\n>>> print S\\nAÄBèC\\n>>> len(S)\\n5\\n>>> S.encode(\\'latin-1\\')                                              # Manual calls\\n\\'A\\\\xc4B\\\\xe8C\\'\\n>>> S.encode(\\'utf-8\\')\\n\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n\\n>>> import codecs                                                    # 2.X files\\n>>> codecs.open(\\'latindata\\', \\'w\\', encoding=\\'latin-1\\').write(S)       # Writes encode\\n>>> codecs.open(\\'utfdata\\', \\'w\\', encoding=\\'utf-8\\').write(S)\\n\\n>>> open(\\'latindata\\', \\'rb\\').read()\\n\\'A\\\\xc4B\\\\xe8C\\'\\n>>> open(\\'utfdata\\', \\'rb\\').read()\\n\\'A\\\\xc3\\\\x84B\\\\xc3\\\\xa8C\\'\\n\\n1204 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c>>> codecs.open(\\'latindata\\', \\'r\\', encoding=\\'latin-1\\').read()         # Reads decode\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> codecs.open(\\'utfdata\\', \\'r\\', encoding=\\'utf-8\\').read()\\nu\\'A\\\\xc4B\\\\xe8C\\'\\n>>> print codecs.open(\\'utfdata\\', \\'r\\', encoding=\\'utf-8\\').read()       # Print to view\\nAÄBèC\\n\\nFor more 2.X Unicode details, see earlier sections of this chapter and Python 2.X man-\\nuals.\\n\\nUnicode Filenames and Streams\\nIn closing, this section has focused on the encoding and decoding of Unicode text file\\ncontent, but Python also supports the notion of non-ASCII file names. In fact, they are \\nindependent settings in sys, which can vary per Python version and platform (2.X re-\\nturns ASCII for the first of the following on Windows):\\n\\n>>> import sys\\n>>> sys.getdefaultencoding(), sys.getfilesystemencoding()   # File content, names\\n(\\'utf-8\\', \\'mbcs\\')\\n\\nFilenames: Text versus bytes\\nFilename encoding is often a nonissue. In short, for filenames given as Unicode text\\nstrings, the open call encodes automatically to and from the underlying platform’s file-\\nname conventions. Passing arbitrarily pre-encoded filenames as byte strings to file tools\\n(including open and directory walkers and listers) overrides automatic encodings, and\\nforces filename results to be returned in encoded byte string form too—useful if file-\\nnames are undecodable per the underlying platform’s conventions (I’m using Win-\\ndows, but some of the following may fail on other platforms):\\n>>> f = open(\\'xxx\\\\u00A5\\',  \\'w\\')          # Non-ASCII filename\\n>>> f.write(\\'\\\\xA5999\\\\n\\')                 # Writes five characters\\n>>> f.close()\\n>>> print(open(\\'xxx\\\\u00A5\\').read())      # Text: auto-encoded\\n¥999\\n>>> print(open(b\\'xxx\\\\xA5\\').read())       # Bytes: pre-encoded\\n¥999\\n\\n>>> import glob                          # Filename expansion tool\\n>>> glob.glob(\\'*\\\\u00A5*\\')                # Get decoded text for decoded text\\n[\\'xxx¥\\']\\n>>> glob.glob(b\\'*\\\\xA5*\\')                 # Get encoded bytes for encoded bytes\\n[b\\'xxx\\\\xa5\\']\\n\\nStream content: PYTHONIOENCODING\\nIn addition, the environment variable PYTHONIOENCODING can be used to set the encoding\\nused for text in the standard streams—input, output, and error. This setting overrides\\nPython’s default encoding for printed text, which on Windows currently uses a Win-\\n\\nUsing Unicode Files\\n\\n| 1205\\n\\n\\x0cdows format on 3.X and ASCII on 2.X. Setting this to a general Unicode format like\\nUTF-8 may sometimes be required to print non-ASCII text, and to display such text in\\nshell windows (possibly in conjunction with code page changes on some Windows\\nmachines). A script that prints non-ASCII filenames, for example, may fail unless this\\nsetting is made.\\nFor more background on this subject, see also “Currency Symbols: Unicode in Action”\\nin Chapter 25. There, we work through an example that demonstrates the essentials of\\nportable Unicode coding, as well as the roles and requirements of PYTHONIOENCODING\\nsettings, which we won’t rehash here.\\nFor more on these topics in general, see Python manuals or books such as Programming\\nPython, 4th Edition (or later, if later may be). The latter of these digs deeper into streams\\nand files from an applications-level perspective.\\n\\nOther String Tool Changes in 3.X\\nMany of the other popular string-processing tools in Python’s standard library have\\nalso been revamped for the new str/bytes type dichotomy. We won’t cover any of these\\napplication-focused tools in much detail in this core language book, but to wrap up\\nthis chapter, here’s a quick look at four of the major tools impacted: the re pattern-\\nmatching module, the struct binary data module, the pickle object serialization mod-\\nule, and the xml package for parsing XML text. As noted ahead, other Python tools,\\nsuch as its json module, differ in ways similar to those presented here.\\n\\nThe re Pattern-Matching Module\\nPython’s re pattern-matching module supports text processing that is more general\\nthan that afforded by simple string method calls such as find, split, and replace. With\\nre, strings that designate searching and splitting targets can be described by general\\npatterns, instead of absolute text. This module has been generalized to work on objects\\nof any string type in 3.X—str, bytes, and bytearray—and returns result substrings of\\nthe same type as the subject string. In 2.X it supports both unicode and str.\\nHere it is at work in 3.X, extracting substrings from a line of text—borrowed, of course,\\nfrom Monty Python’s The Meaning of Life. Within pattern strings,  (.*) means any\\ncharacter (the .), zero or more times (the *), saved away as a matched substring (the\\n()). Parts of the string matched by the parts of a pattern enclosed in parentheses are\\navailable after a successful match, via the group or groups method:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> import re\\n>>> S = \\'Bugger all down here on earth!\\'               # Line of text\\n>>> B = b\\'Bugger all down here on earth!\\'              # Usually from a file\\n\\n>>> re.match(\\'(.*) down (.*) on (.*)\\', S).groups()     # Match line to pattern\\n(\\'Bugger all\\', \\'here\\', \\'earth!\\')                       # Matched substrings\\n\\n1206 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c>>> re.match(b\\'(.*) down (.*) on (.*)\\', B).groups()    # bytes substrings\\n(b\\'Bugger all\\', b\\'here\\', b\\'earth!\\')\\n\\nIn Python 2.X results are similar, but the unicode type is used for non-ASCII text, and\\nstr handles both 8-bit and binary text:\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> import re\\n>>> S = \\'Bugger all down here on earth!\\'               # Simple text and binary\\n>>> U = u\\'Bugger all down here on earth!\\'              # Unicode text\\n\\n>>> re.match(\\'(.*) down (.*) on (.*)\\', S).groups()\\n(\\'Bugger all\\', \\'here\\', \\'earth!\\')\\n\\n>>> re.match(\\'(.*) down (.*) on (.*)\\', U).groups()\\n(u\\'Bugger all\\', u\\'here\\', u\\'earth!\\')\\n\\nSince bytes and str support essentially the same operation sets, this type distinction is\\nlargely transparent. But note that, like in other APIs, you can’t mix str and bytes types\\nin its calls’ arguments in 3.X (although if you don’t plan to do pattern matching on\\nbinary data, you probably don’t need to care):\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> import re\\n>>> S = \\'Bugger all down here on earth!\\'\\n>>> B = b\\'Bugger all down here on earth!\\'\\n\\n>>> re.match(\\'(.*) down (.*) on (.*)\\', B).groups()\\nTypeError: can\\'t use a string pattern on a bytes-like object\\n\\n>>> re.match(b\\'(.*) down (.*) on (.*)\\', S).groups()\\nTypeError: can\\'t use a bytes pattern on a string-like object\\n\\n>>> re.match(b\\'(.*) down (.*) on (.*)\\', bytearray(B)).groups()\\n(bytearray(b\\'Bugger all\\'), bytearray(b\\'here\\'), bytearray(b\\'earth!\\'))\\n\\n>>> re.match(\\'(.*) down (.*) on (.*)\\', bytearray(B)).groups()\\nTypeError: can\\'t use a string pattern on a bytes-like object\\n\\nThe struct Binary Data Module\\nThe Python struct module, used to create and extract packed binary data from strings,\\nalso works the same in 3.X as it does in 2.X, but in 3.X packed data is represented as\\nbytes and bytearray objects only, not str objects (which makes sense, given that it’s\\nintended for processing binary data, not decoded text); and “s” data code values must\\nbe bytes as of 3.2 (the former str UTF-8 auto-encode is dropped).\\nHere are both Pythons in action, packing three objects into a string according to a binary\\ntype specification (they create a 4-byte integer, a 4-byte string, and a 2-byte integer):\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> from struct import pack\\n>>> pack(\\'>i4sh\\', 7, b\\'spam\\', 8)        # bytes in 3.X (8-bit strings)\\n\\nOther String Tool Changes in 3.X | 1207\\n\\n\\x0cb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> from struct import pack\\n>>> pack(\\'>i4sh\\', 7, \\'spam\\', 8)         # str in 2.X (8-bit strings)\\n\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n\\nSince bytes has an almost identical interface to that of str in 3.X and 2.X, though, most\\nprogrammers probably won’t need to care—the change is irrelevant to most existing\\ncode, especially since reading from a binary file creates a bytes automatically. Although\\nthe last test in the following example fails on a type mismatch, most scripts will read\\nbinary data from a file, not create it as a string as we do here:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> import struct\\n>>> B = struct.pack(\\'>i4sh\\', 7, b\\'spam\\', 8)\\n>>> B\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n\\n>>> vals = struct.unpack(\\'>i4sh\\', B)\\n>>> vals\\n(7, b\\'spam\\', 8)\\n\\n>>> vals = struct.unpack(\\'>i4sh\\', B.decode())\\nTypeError: \\'str\\' does not support the buffer interface\\n\\nApart from the new syntax for bytes, creating and reading binary files works almost the\\nsame in 3.X as it does in 2.X. Still, code like this is one of the main places where pro-\\ngrammers will notice the bytes object type:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n# Write values to a packed binary file\\n>>> F = open(\\'data.bin\\', \\'wb\\')                  # Open binary output file\\n>>> import struct\\n>>> data = struct.pack(\\'>i4sh\\', 7, b\\'spam\\', 8)  # Create packed binary data\\n>>> data                                        # bytes in 3.X, not str\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>> F.write(data)                               # Write to the file\\n10\\n>>> F.close()\\n\\n# Read values from a packed binary file\\n>>> F = open(\\'data.bin\\', \\'rb\\')                  # Open binary input file\\n>>> data = F.read()                             # Read bytes\\n>>> data\\nb\\'\\\\x00\\\\x00\\\\x00\\\\x07spam\\\\x00\\\\x08\\'\\n>>> values = struct.unpack(\\'>i4sh\\', data)       # Extract packed binary data\\n>>> values                                      # Back to Python objects\\n(7, b\\'spam\\', 8)\\n\\nOnce you’ve extracted packed binary data into Python objects like this, you can dig\\neven further into the binary world if you have to—strings can be indexed and sliced to\\nget individual bytes’ values, individual bits can be extracted from integers with bitwise\\noperators, and so on (see earlier in this book for more on the operations applied here):\\n\\n1208 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c>>> values                                      # Result of struct.unpack\\n(7, b\\'spam\\', 8)\\n\\n# Accessing bits of parsed integers\\n>>> bin(values[0])                              # Can get to bits in ints\\n\\'0b111\\'\\n>>> values[0] & 0x01                            # Test first (lowest) bit in int\\n1\\n>>> values[0] | 0b1010                          # Bitwise or: turn bits on\\n15\\n>>> bin(values[0] | 0b1010)                     # 15 decimal is 1111 binary\\n\\'0b1111\\'\\n>>> bin(values[0] ^ 0b1010)                     # Bitwise xor: off if both true\\n\\'0b1101\\'\\n>>> bool(values[0] & 0b100)                     # Test if bit 3 is on\\nTrue\\n>>> bool(values[0] & 0b1000)                    # Test if bit 4 is set\\nFalse\\n\\nSince parsed bytes strings are sequences of small integers, we can do similar processing\\nwith their individual bytes:\\n\\n# Accessing bytes of parsed strings and bits within them\\n>>> values[1]\\nb\\'spam\\'\\n>>> values[1][0]                          # bytes string: sequence of ints\\n115\\n>>> values[1][1:]                         # Prints as ASCII characters\\nb\\'pam\\'\\n>>> bin(values[1][0])                     # Can get to bits of bytes in strings\\n\\'0b1110011\\'\\n>>> bin(values[1][0] | 0b1100)            # Turn bits on\\n\\'0b1111111\\'\\n>>> values[1][0] | 0b1100\\n127\\n\\nOf course, most Python programmers don’t deal with binary bits; Python has higher-\\nlevel object types, like lists and dictionaries that are generally a better choice for rep-\\nresenting information in Python scripts. However, if you must use or produce lower-\\nlevel data used by C programs, networking libraries, or other interfaces, Python has\\ntools to assist.\\n\\nThe pickle Object Serialization Module\\nWe met the pickle module briefly in Chapter 9, Chapter 28, and Chapter 31. In Chap-\\nter 28, we also used the shelve module, which uses pickle internally. For completeness\\nhere, keep in mind that the Python 3.X version of the pickle module always creates a\\nbytes object, regardless of the default or passed-in “protocol” (data format level). You\\ncan see this by using the module’s dumps call to return an object’s pickle string:\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> import pickle                          # dumps() returns pickle string\\n\\nOther String Tool Changes in 3.X | 1209\\n\\n\\x0c>>> pickle.dumps([1, 2, 3])                # Python 3.X default protocol=3=binary\\nb\\'\\\\x80\\\\x03]q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.\\'\\n\\n>>> pickle.dumps([1, 2, 3], protocol=0)    # ASCII protocol 0, but still bytes!\\nb\\'(lp0\\\\nL1L\\\\naL2L\\\\naL3L\\\\na.\\'\\n\\nThis implies that files used to store pickled objects must always be opened in binary\\nmode in Python 3.X, since text files use str strings to represent data, not bytes—the\\ndump call simply attempts to write the pickle string to an open output file:\\n\\n>>> pickle.dump([1, 2, 3], open(\\'temp\\', \\'w\\'))    # Text files fail on bytes!\\nTypeError: must be str, not bytes                # Despite protocol value\\n\\n>>> pickle.dump([1, 2, 3], open(\\'temp\\', \\'w\\'), protocol=0)\\nTypeError: must be str, not bytes\\n\\n>>> pickle.dump([1, 2, 3], open(\\'temp\\', \\'wb\\'))   # Always use binary in 3.X\\n\\n>>> open(\\'temp\\', \\'r\\').read()                     # This works, but just by luck\\n\\'\\\\u20ac\\\\x03]q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.\\'\\n\\nNotice the last result here didn’t issue an error in text mode only because the stored\\nbinary data was compatible with the Windows platform’s UTF-8 default decoder; this\\nwas really just luck (and in fact, this command failed when printing in older Pythons,\\nand may fail on other platforms). Because pickle data is not generally decodable Uni-\\ncode text, the same rule holds on input—correct usage in 3.X requires always both\\nwriting and reading pickle data in binary modes, whether unpickling or not:\\n\\n>>> pickle.dump([1, 2, 3], open(\\'temp\\', \\'wb\\'))\\n>>> pickle.load(open(\\'temp\\', \\'rb\\'))\\n[1, 2, 3]\\n>>> open(\\'temp\\', \\'rb\\').read()\\nb\\'\\\\x80\\\\x03]q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.\\'\\n\\nIn Python 2.X, we can get by with text-mode files for pickled data, as long as the pro-\\ntocol is level 0 (the default in 2.X) and we use text mode consistently to convert line\\nends:\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> import pickle\\n>>> pickle.dumps([1, 2, 3])                      # Python 2.X default=0=ASCII\\n\\'(lp0\\\\nI1\\\\naI2\\\\naI3\\\\na.\\'\\n\\n>>> pickle.dumps([1, 2, 3], protocol=1)\\n\\']q\\\\x00(K\\\\x01K\\\\x02K\\\\x03e.\\'\\n\\n>>> pickle.dump([1, 2, 3], open(\\'temp\\', \\'w\\'))    # Text mode works in 2.X\\n>>> pickle.load(open(\\'temp\\'))\\n[1, 2, 3]\\n>>> open(\\'temp\\').read()\\n\\'(lp0\\\\nI1\\\\naI2\\\\naI3\\\\na.\\'\\n\\n1210 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cIf you care about version neutrality, though, or don’t want to care about protocols or\\ntheir version-specific defaults, always use binary-mode files for pickled data—the fol-\\nlowing works the same in Python 3.X and 2.X:\\n\\n>>> import pickle\\n>>> pickle.dump([1, 2, 3], open(\\'temp\\', \\'wb\\'))     # Version neutral\\n>>> pickle.load(open(\\'temp\\', \\'rb\\'))                # And required in 3.X\\n[1, 2, 3]\\n\\nBecause almost all programs let Python pickle and unpickle objects automatically and\\ndo not deal with the content of pickled data itself, the requirement to always use binary\\nfile modes is the only significant incompatibility in Python 3.X’s newer pickling model.\\nSee reference books or Python’s manuals for more details on object pickling.\\n\\nXML Parsing Tools\\nXML is a tag-based language for defining structured information, commonly used to\\ndefine documents and data shipped over the Web. Although some information can be\\nextracted from XML text with basic string methods or the re pattern module, XML’s\\nnesting of constructs and arbitrary attribute text tend to make full parsing more accu-\\nrate.\\nBecause XML is such a pervasive format, Python itself comes with an entire package of\\nXML parsing tools that support the SAX and DOM parsing models, as well as a package \\nknown as ElementTree—a Python-specific API for parsing and constructing XML. Be-\\nyond basic parsing, the open source domain provides support for additional XML tools,\\nsuch as XPath, Xquery, XSLT, and more.\\nXML by definition represents text in Unicode form, to support internationalization.\\nAlthough most of Python’s XML parsing tools have always returned Unicode strings,\\nin Python 3.X their results have mutated from the 2.X unicode type to the 3.X general\\nstr string type—which makes sense, given that 3.X’s str string is Unicode, whether\\nthe encoding is ASCII or other.\\nWe can’t go into many details here, but to sample the flavor of this domain, suppose\\nwe have a simple XML text file, mybooks.xml:\\n\\n<books>\\n    <date>1995~2013</date>\\n    <title>Learning Python</title>\\n    <title>Programming Python</title>\\n    <title>Python Pocket Reference</title>\\n    <publisher>O\\'Reilly Media</publisher>\\n</books>\\n\\nand we want to run a script to extract and display the content of all the nested title\\ntags, as follows:\\n\\nLearning Python\\nProgramming Python\\nPython Pocket Reference\\n\\nOther String Tool Changes in 3.X | 1211\\n\\n\\x0cThere are at least four basic ways to accomplish this (not counting more advanced tools\\nlike XPath). First, we could run basic pattern matching on the file’s text, though this\\ntends to be inaccurate if the text is unpredictable. Where applicable, the re module we\\nmet earlier does the job—its match method looks for a match at the start of a string,\\nsearch scans ahead for a match, and the findall method used here locates all places\\nwhere the pattern matches in the string (the result comes back as a list of matched\\nsubstrings corresponding to parenthesized pattern groups, or tuples of such for mul-\\ntiple groups):\\n\\n# File patternparse.py\\n\\nimport re\\ntext  = open(\\'mybooks.xml\\').read()\\nfound = re.findall(\\'<title>(.*)</title>\\', text)\\nfor title in found: print(title)\\n\\nSecond, to be more robust, we could perform complete XML parsing with the standard\\nlibrary’s DOM parsing support. DOM parses XML text into a tree of objects and pro-\\nvides an interface for navigating the tree to extract tag attributes and values; the inter-\\nface is a formal specification, independent of Python:\\n\\n# File domparse.py\\n\\nfrom xml.dom.minidom import parse, Node\\nxmltree = parse(\\'mybooks.xml\\')\\nfor node1 in xmltree.getElementsByTagName(\\'title\\'):\\n    for node2 in node1.childNodes:\\n         if node2.nodeType == Node.TEXT_NODE:\\n             print(node2.data)\\n\\nAs a third option, Python’s standard library supports SAX parsing for XML. Under the\\nSAX model, a class’s methods receive callbacks as a parse progresses and use state\\ninformation to keep track of where they are in the document and collect its data:\\n\\n# File saxparse.py\\n\\nimport xml.sax.handler\\nclass BookHandler(xml.sax.handler.ContentHandler):\\n    def __init__(self):\\n        self.inTitle = False\\n    def startElement(self, name, attributes):\\n        if name == \\'title\\':\\n            self.inTitle = True\\n    def characters(self, data):\\n        if self.inTitle:\\n            print(data)\\n    def endElement(self, name):\\n        if name == \\'title\\':\\n            self.inTitle = False\\n\\nimport xml.sax\\nparser = xml.sax.make_parser()\\nhandler = BookHandler()\\n\\n1212 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cparser.setContentHandler(handler)\\nparser.parse(\\'mybooks.xml\\')\\n\\nFinally, the ElementTree system available in the etree package of the standard library\\ncan often achieve the same effects as XML DOM parsers, but with remarkably less code.\\nIt’s a Python-specific way to both parse and generate XML text; after a parse, its API\\ngives access to components of the document:\\n\\n# File etreeparse.py\\n\\nfrom xml.etree.ElementTree import parse\\ntree = parse(\\'mybooks.xml\\')\\nfor E in tree.findall(\\'title\\'):\\n    print(E.text)\\n\\nWhen run in either 2.X or 3.X, all four of these scripts display the same printed result:\\n\\nC:\\\\code> C:\\\\python27\\\\python domparse.py\\nLearning Python\\nProgramming Python\\nPython Pocket Reference\\n\\nC:\\\\code> C:\\\\python33\\\\python domparse.py\\nLearning Python\\nProgramming Python\\nPython Pocket Reference\\n\\nTechnically, though, in 2.X some of these scripts produce unicode string objects, while\\nin 3.X all produce str strings, since that type includes Unicode text (whether ASCII or\\nother):\\n\\nC:\\\\code> C:\\\\python33\\\\python\\n>>> from xml.dom.minidom import parse, Node\\n>>> xmltree = parse(\\'mybooks.xml\\')\\n>>> for node in xmltree.getElementsByTagName(\\'title\\'):\\n        for node2 in node.childNodes:\\n            if node2.nodeType == Node.TEXT_NODE:\\n                node2.data\\n\\n\\'Learning Python\\'\\n\\'Programming Python\\'\\n\\'Python Pocket Reference\\'\\n\\nC:\\\\code> C:\\\\python27\\\\python\\n>>> ...same code...\\n\\nu\\'Learning Python\\'\\nu\\'Programming Python\\'\\nu\\'Python Pocket Reference\\'\\n\\nPrograms that must deal with XML parsing results in nontrivial ways will need to ac-\\ncount for the different object type in 3.X. Again, though, because all strings have nearly\\nidentical interfaces in both 2.X and 3.X, most scripts won’t be affected by the change;\\ntools available on unicode in 2.X are generally available on str in 3.X. The major feat,\\n\\nOther String Tool Changes in 3.X | 1213\\n\\n\\x0cif there is one, is likely in getting the encoding names right when transferring the parsed-\\nout data to and from files, network connections, GUIs, and so on.\\nRegrettably, going into further XML parsing details is beyond this book’s scope. If you\\nare interested in text or XML parsing, it is covered in more detail in the applications-\\nfocused follow-up book Programming Python. For more details on re, struct, pickle,\\nand XML, as well as the additional impacts of Unicode on other library tools such as\\nfilename expansion and directory walkers, consult the Web, the aforementioned book\\nand others, and Python’s standard library manual.\\nFor a related topic, see also the JSON example in Chapter 9—a language-neutral data\\nexchange format, whose structure is very similar to Python dictionaries and lists, and\\nwhose strings are all Unicode that differs in type between Pythons 2.X and 3.X much\\nthe same as shown for XML here.\\n\\nWhy You Will Care: Inspecting Files, and Much More\\n\\nAs I was updating this chapter, I stumbled onto a use case for some of its tools. After\\nsaving a formerly ASCII HTML file in Notepad as “UTF8,” I found that it had grown\\na mystery non-ASCII character along the way due to an apparent keyboard operator\\nerror, and would no longer work as ASCII in text tools. To find the bad character, I\\nsimply  started  Python,  decoded  the  file’s  content  from  its  UTF-8  format  via  a  text\\nmode file, and scanned character by character looking for the first byte that was not a\\nvalid ASCII character too:\\n\\n>>> f = open(\\'py33-windows-launcher.html\\', encoding=\\'utf8\\')\\n>>> t = f.read()\\n>>> for (i, c) in enumerate(t):\\n        try:\\n            x = c.encode(encoding=\\'ascii\\')\\n        except:\\n            print(i, sys.exc_info()[0])\\n   9886 <class \\'UnicodeEncodeError\\'>\\n\\nWith the bad character’s index in hand, it’s easy to slice the Unicode string for more\\ndetails:\\n\\n>>> len(t)\\n31021\\n>>> t[9880:9890]\\n\\'ugh.  \\\\u206cThi\\'\\n>>> t[9870:9890]\\n\\'trace through.  \\\\u206cThi\\'\\n\\nAfter fixing, I could also open in binary mode to verify and explore actual undecoded\\nfile content further:\\n\\n>>> f = open(\\'py33-windows-launcher.html\\', \\'rb\\')\\n>>> b = f.read()\\n>>> b[0]\\n60\\n>>> b[:10]\\nb\\'<HTML>\\\\r\\\\n<T\\'\\n\\n1214 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0cNot rocket science, perhaps, and there are other approaches, but Python makes for a\\nconvenient tactical tool in such cases, and its file objects give you a tangible window\\non your data when needed, both in scripts and interactive mode.\\n\\nFor more realistically scaled examples of Unicode at work, I suggest my other book\\nProgramming Python, 4th Edition (or later). That book develops much larger programs\\nthan we can here, and has numerous up close and personal encounters with Unicode\\nalong the way, in the context of files, directory walkers, network sockets, GUIs, email\\ncontent and headers, web page content, databases, and more. Though clearly an im-\\nportant topic in today’s global software world, Unicode is more mandatory than you\\nmight expect, especially in a language like Python 3.X, which elevates it to its core string\\nand file types, thus bringing all its users into the Unicode fold—ready or not!\\n\\nChapter Summary\\nThis chapter explored in-depth the advanced string types available in Python 3.X and\\n2.X for processing Unicode text and binary data. As we saw, many programmers use\\nASCII text and can get by with the basic string type and its operations. For more ad-\\nvanced applications, Python’s string models fully support both richer Unicode text (via\\nthe normal string type in 3.X and a special type in 2.X) and byte-oriented data (repre-\\nsented with a bytes type in 3.X and normal strings in 2.X).\\nIn addition, we learned how Python’s file object has mutated in 3.X to automatically\\nencode and decode Unicode text and deal with byte strings for binary-mode files, and\\nsaw similar utility for 2.X. Finally, we briefly met some text and binary data tools in\\nPython’s library, and sampled their behavior in 3.X and 2.X.\\nIn the next chapter, we’ll shift our focus to tool-builder topics, with a look at ways to\\nmanage access to object attributes by inserting automatically run code. Before we move\\non, though, here’s a set of questions to review what we’ve learned here. This has been\\na substantial chapter, so be sure to read the quiz answers eventually for a more in-depth\\nsummary.\\n\\nTest Your Knowledge: Quiz\\n1. What are the names and roles of string object types in Python 3.X?\\n2. What are the names and roles of string object types in Python 2.X?\\n3. What is the mapping between 2.X and 3.X string types?\\n4. How do Python 3.X’s string types differ in terms of operations?\\n5. How can you code non-ASCII Unicode characters in a string in 3.X?\\n6. What are the main differences between text- and binary-mode files in Python 3.X?\\n7. How would you read a Unicode text file that contains text in a different encoding\\n\\nthan the default for your platform?\\n\\nTest Your Knowledge: Quiz | 1215\\n\\n\\x0c8. How can you create a Unicode text file in a specific encoding format?\\n9. Why is ASCII text considered to be a kind of Unicode text?\\n10. How large an impact does Python 3.X’s string types change have on your code?\\n\\nTest Your Knowledge: Answers\\n1. Python 3.X has three string types: str (for Unicode text, including ASCII), bytes\\n(for binary data with absolute byte values), and  bytearray (a mutable flavor of\\nbytes). The str type usually represents content stored on a text file, and the other\\ntwo types generally represent content stored on binary files.\\n\\n2. Python 2.X has two main string types:  str (for 8-bit text and binary data) and\\nunicode (for possibly wider character Unicode text). The str type is used for both\\ntext and binary file content; unicode is used for text file content that is generally\\nmore complex than 8-bit characters. Python 2.6 (but not earlier) also has 3.X’s\\nbytearray type, but it’s mostly a back-port and doesn’t exhibit the sharp text/binary\\ndistinction that it does in 3.X.\\n\\n3. The mapping from 2.X to 3.X string types is not direct, because 2.X’s str equates\\nto both str and bytes in 3.X, and 3.X’s str equates to both str and unicode in 2.X.\\nThe mutability of bytearray in 3.X is also unique. In general, though: Unicode text\\nis handled by 3.X str and 2.X unicode, byte-based data is handled by 3.X bytes\\nand 2.X str, and 3.X bytes and 2.X str can both handle some simpler types of text.\\n4. Python 3.X’s string types share almost all the same operations: method calls, se-\\nquence operations, and even larger tools like pattern matching work the same way.\\nOn the other hand, only str supports string formatting operations, and bytear\\nray has an additional set of operations that perform in-place changes. The str and\\nbytes types also have methods for encoding and decoding text, respectively.\\n\\n5. Non-ASCII Unicode characters can be coded in a string with both hex (\\\\xNN) and\\nUnicode (\\\\uNNNN, \\\\UNNNNNNNN) escapes. On some machines, some non-ASCII char-\\nacters—certain Latin-1 characters, for example—can also be typed or pasted di-\\nrectly into code, and are interpreted per the UTF-8 default or a source code en-\\ncoding directive comment.\\n\\n6. In 3.X, text-mode files assume their file content is Unicode text (even if it’s all\\nASCII) and automatically decode when reading and encode when writing. With\\nbinary-mode files, bytes are transferred to and from the file unchanged. The con-\\ntents of text-mode files are usually represented as str objects in your script, and\\nthe contents of binary files are represented as bytes (or bytearray) objects. Text-\\nmode  files  also  handle  the  BOM  for  certain  encoding  types  and  automatically\\ntranslate end-of-line sequences to and from the single \\\\n character on input and\\noutput unless this is explicitly disabled; binary-mode files do not perform either of\\nthese steps. Python 2.X uses codecs.open for Unicode files, which encodes and\\ndecodes similarly; 2.X’s open only translates line ends in text mode.\\n\\n1216 | Chapter 37:\\u2002Unicode and Byte Strings\\n\\n\\x0c7. To read files encoded in a different encoding than the default for your platform,\\nsimply  pass  the  name  of  the  file’s  encoding  to  the  open  built-in  in  3.X\\n(codecs.open() in 2.X); data will be decoded per the specified encoding when it is\\nread from the file. You can also read in binary mode and manually decode the bytes\\nto a string by giving an encoding name, but this involves extra work and is some-\\nwhat  error-prone  for  multibyte  characters  (you  may  accidentally  read  a  partial\\ncharacter sequence).\\n\\n8. To create a Unicode text file in a specific encoding format, pass the desired en-\\ncoding name to open in 3.X (codecs.open() in 2.X); strings will be encoded per the\\ndesired encoding when they are written to the file. You can also manually encode\\na string to bytes and write it in binary mode, but this is usually extra work.\\n\\n9. ASCII text is considered to be a kind of Unicode text, because its 7-bit range of\\nvalues is a subset of most Unicode encodings. For example, valid ASCII text is also\\nvalid Latin-1 text (Latin-1 simply assigns the remaining possible values in an 8-bit\\nbyte to additional characters) and valid UTF-8 text (UTF-8 defines a variable-byte\\nscheme for representing more characters, but ASCII characters are still represented\\nwith the same codes, in a single byte). This makes Unicode backward-compatible\\nwith the mass of ASCII text data in the world (though it also may have limited its\\noptions—self-identifying text, for instance, may have been difficult (though BOMs\\nserve much the same role).\\n\\n10. The impact of Python 3.X’s string types change depends upon the types of strings\\nyou use. For scripts that use simple ASCII text on platforms with ASCII-compatible\\ndefault encodings, the impact is probably minor: the str string type works the same\\nin 2.X and 3.X in this case. Moreover, although string-related tools in the standard\\nlibrary such as re, struct, pickle, and xml may technically use different types in\\n3.X than in 2.X, the changes are largely irrelevant to most programs because 3.X’s\\nstr and  bytes and 2.X’s  str support almost identical interfaces. If you process\\nUnicode  data,  the  toolset  you  need  has  simply  moved  from  2.X’s  unicode  and\\ncodecs.open() to 3.X’s str and open. If you deal with binary data files, you’ll need\\nto deal with content as bytes objects; since they have a similar interface to 2.X\\nstrings, though, the impact should again be minimal. That said, the update of the\\nbook Programming Python for 3.X ran across numerous cases where Unicode’s\\nmandatory status in 3.X implied changes in standard library APIs—from network-\\ning and GUIs, to databases and email. In general, Unicode will probably impact\\nmost 3.X users eventually.\\n\\nTest Your Knowledge: Answers\\n\\n| 1217\\n\\n\\x0c\\x0cCHAPTER 38\\nManaged Attributes\\n\\nThis chapter expands on the attribute interception techniques introduced earlier, in-\\ntroduces another, and employs them in a handful of larger examples. Like everything\\nin this part of the book, this chapter is classified as an advanced topic and optional\\nreading, because most applications programmers don’t need to care about the material\\ndiscussed here—they can fetch and set attributes on objects without concern for at-\\ntribute implementations.\\nEspecially for tools builders, though, managing attribute access can be an important\\npart of flexible APIs. Moreover, an understanding of the descriptor model covered here\\ncan make related tools such as slots and properties more tangible, and may even be\\nrequired reading if it appears in code you must use.\\n\\nWhy Manage Attributes?\\nObject attributes are central to most Python programs—they are where we often store\\ninformation  about  the  entities  our  scripts  process.  Normally,  attributes  are  simply\\nnames for objects; a person’s name attribute, for example, might be a simple string,\\nfetched and set with basic attribute syntax:\\n\\nperson.name                 # Fetch attribute value\\nperson.name = value         # Change attribute value\\n\\nIn most cases, the attribute lives in the object itself, or is inherited from a class from\\nwhich it derives. That basic model suffices for most programs you will write in your\\nPython career.\\nSometimes, though, more flexibility is required. Suppose you’ve written a program to\\nuse a name attribute directly, but then your requirements change—for example, you\\ndecide that names should be validated with logic when set or mutated in some way\\nwhen fetched. It’s straightforward to code methods to manage access to the attribute’s\\nvalue (valid and transform are abstract here):\\n\\nclass Person:\\n    def getName(self):\\n\\n1219\\n\\n\\x0c        if not valid():\\n            raise TypeError(\\'cannot fetch name\\')\\n        else:\\n            return self.name.transform()\\n\\n    def setName(self, value):\\n         if not valid(value):\\n            raise TypeError(\\'cannot change name\\')\\n        else:\\n            self.name = transform(value)\\n\\nperson = Person()\\nperson.getName()\\nperson.setName(\\'value\\')\\n\\nHowever, this also requires changing all the places where names are used in the entire\\nprogram—a possibly nontrivial task. Moreover, this approach requires the program to\\nbe aware of how values are exported: as simple names or called methods. If you begin\\nwith a method-based interface to data, clients are immune to changes; if you do not,\\nthey can become problematic.\\nThis issue can crop up more often than you might expect. The value of a cell in a\\nspreadsheet-like program, for instance, might begin its life as a simple discrete value,\\nbut later mutate into an arbitrary calculation. Since an object’s interface should be\\nflexible enough to support such future changes without breaking existing code, switch-\\ning to methods later is less than ideal.\\n\\nInserting Code to Run on Attribute Access\\nA better solution would allow you to run code automatically on attribute access, if\\nneeded. That’s one of the main roles of managed attributes—they provide ways to add\\nattribute accessor logic after the fact. More generally, they support arbitrary attribute\\nusage modes that go beyond simple data storage.\\nAt various points in this book, we’ve met Python tools that allow our scripts to dy-\\nnamically  compute  attribute  values  when  fetching  them  and  validate  or  change  at-\\ntribute values when storing them. In this chapter, we’re going to expand on the tools\\nalready introduced, explore other available tools, and study some larger use-case ex-\\namples in this domain. Specifically, this chapter presents four accessor techniques:\\n\\n• The __getattr__ and __setattr__ methods, for routing undefined attribute fetches\\n\\nand all attribute assignments to generic handler methods.\\n\\n• The __getattribute__ method, for routing all attribute fetches to a generic handler\\n\\nmethod.\\n\\n• The property built-in, for routing specific attribute access to get and set handler\\n\\nfunctions.\\n\\n1220 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0c• The descriptor protocol, for routing specific attribute accesses to instances of classes\\nwith arbitrary get and set handler methods, and the basis for other tools such as\\nproperties and slots.\\n\\nThe tools in the first of these bullets are available in all Pythons. The last three bullets’\\ntools are available in Python 3.X and new-style classes in 2.X—they first appeared in\\nPython 2.2, along with many of the other advanced tools of Chapter 32 such as slots\\nand super. We briefly met the first and third of these in Chapter 30 and Chapter 32,\\nrespectively; the second and fourth are largely new topics we’ll explore in full here.\\nAs we’ll see, all four techniques share goals to some degree, and it’s usually possible to\\ncode a given problem using any one of them. They do differ in some important ways,\\nthough. For example, the last two techniques listed here apply to specific attributes,\\nwhereas the first two are generic enough to be used by delegation-based proxy classes\\nthat must route arbitrary attributes to wrapped objects. As we’ll see, all four schemes\\nalso differ in both complexity and aesthetics, in ways you must see in action to judge\\nfor yourself.\\nBesides studying the specifics behind the four attribute interception techniques listed\\nin this section, this chapter also presents an opportunity to explore larger programs\\nthan we’ve seen elsewhere in this book. The CardHolder case study at the end, for ex-\\nample, should serve as a self-study example of larger classes in action. We’ll also be\\nusing some of the techniques outlined here in the next chapter to code decorators, so\\nbe sure you have at least a general understanding of these topics before you move on.\\n\\nProperties\\nThe property protocol allows us to route a specific attribute’s get, set, and delete op-\\nerations to functions or methods we provide, enabling us to insert code to be run au-\\ntomatically on attribute access, intercept attribute deletions, and provide documenta-\\ntion for the attributes if desired.\\nProperties are created with the property built-in and are assigned to class attributes,\\njust like method functions. Accordingly, they are inherited by subclasses and instances,\\nlike any other class attributes. Their access-interception functions are provided with\\nthe  self  instance  argument,  which  grants  access  to  state  information  and  class  at-\\ntributes available on the subject instance.\\nA property manages a single, specific attribute; although it can’t catch all attribute\\naccesses generically, it allows us to control both fetch and assignment accesses and\\nenables us to change an attribute from simple data to a computation freely, without\\nbreaking existing code. As we’ll see, properties are strongly related to descriptors; in\\nfact, they are essentially a restricted form of them.\\n\\nProperties\\n\\n| 1221\\n\\n\\x0cThe Basics\\nA property is created by assigning the result of a built-in function to a class attribute:\\n\\nattribute = property(fget, fset, fdel, doc)\\n\\nNone of this built-in’s arguments are required, and all default to None if not passed. For\\nthe first three, this None means that the corresponding operation is not supported, and\\nattempting it will raise an AttributeError exception automatically.\\nWhen these arguments are used, we pass  fget a function for intercepting attribute\\nfetches, fset a function for assignments, and fdel a function for attribute deletions.\\nTechnically, all three of these arguments accept any callable, including a class’s method,\\nhaving a first argument to receive the instance being qualified. When later invoked, the\\nfget  function  returns  the  computed  attribute  value,  fset  and  fdel  return  nothing\\n(really, None), and all three may raise exceptions to reject access requests.\\nThe doc argument receives a documentation string for the attribute, if desired; other-\\nwise, the property copies the docstring of the fget function, which as usual defaults to\\nNone.\\nThis built-in property call returns a property object, which we assign to the name of\\nthe attribute to be managed in the class scope, where it will be inherited by every in-\\nstance.\\n\\nA First Example\\nTo demonstrate how this translates to working code, the following class uses a property\\nto trace access to an attribute named name; the actual stored data is named _name so it\\ndoes  not  clash  with  the  property  (if  you’re  working  along  with  the  book  examples\\npackage, some filenames in this chapter are implied by the command-lines that run\\nthem following their listings):\\n\\nclass Person:                       # Add (object) in 2.X\\n    def __init__(self, name):\\n        self._name = name\\n    def getName(self):\\n        print(\\'fetch...\\')\\n        return self._name\\n    def setName(self, value):\\n        print(\\'change...\\')\\n        self._name = value\\n    def delName(self):\\n        print(\\'remove...\\')\\n        del self._name\\n    name = property(getName, setName, delName, \"name property docs\")\\n\\nbob = Person(\\'Bob Smith\\')           # bob has a managed attribute\\nprint(bob.name)                     # Runs getName\\nbob.name = \\'Robert Smith\\'           # Runs setName\\nprint(bob.name)\\n\\n1222 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cdel bob.name                        # Runs delName\\n\\nprint(\\'-\\'*20)\\nsue = Person(\\'Sue Jones\\')           # sue inherits property too\\nprint(sue.name)\\nprint(Person.name.__doc__)          # Or help(Person.name)\\n\\nProperties are available in both 2.X and 3.X, but they require new-style object deriva-\\ntion in 2.X to work correctly for assignments—add object as a superclass here to run\\nthis in 2.X. You can list the superclass in 3.X too, but it’s implied and not required, and\\nis sometimes omitted in this book to reduce clutter.\\nThis particular property doesn’t do much—it simply intercepts and traces an attribute\\n—but it serves to demonstrate the protocol. When this code is run, two instances inherit\\nthe property, just as they would any other attribute attached to their class. However,\\ntheir attribute accesses are caught:\\n\\nc:\\\\code> py −3 prop-person.py\\nfetch...\\nBob Smith\\nchange...\\nfetch...\\nRobert Smith\\nremove...\\n--------------------\\nfetch...\\nSue Jones\\nname property docs\\n\\nLike all class attributes, properties are inherited by both instances and lower subclasses.\\nIf we change our example as follows, for instance:\\n\\nclass Super:\\n    ...the original Person class code...\\n    name = property(getName, setName, delName, \\'name property docs\\')\\n\\nclass Person(Super):\\n    pass                            # Properties are inherited (class attrs)\\n\\nbob = Person(\\'Bob Smith\\')\\n...rest unchanged...\\n\\nthe output is the same—the Person subclass inherits the name property from Super, and\\nthe bob instance gets it from Person. In terms of inheritance, properties work the same\\nas normal methods; because they have access to the self instance argument, they can\\naccess instance state information and methods irrespective of subclass depth, as the\\nnext section further demonstrates.\\n\\nProperties\\n\\n| 1223\\n\\n\\x0cComputed Attributes\\nThe  example  in  the  prior  section  simply  traces  attribute  accesses.  Usually,  though,\\nproperties  do  much  more—computing  the  value  of  an  attribute  dynamically  when\\nfetched, for example. The following example illustrates:\\n\\nclass PropSquare:\\n    def __init__(self, start):\\n        self.value = start\\n    def getX(self):                         # On attr fetch\\n        return self.value ** 2\\n    def setX(self, value):                  # On attr assign\\n        self.value = value\\n    X = property(getX, setX)                # No delete or docs\\n\\nP = PropSquare(3)       # Two instances of class with property\\nQ = PropSquare(32)      # Each has different state information\\n\\nprint(P.X)              # 3 ** 2\\nP.X = 4\\nprint(P.X)              # 4 ** 2\\nprint(Q.X)              # 32 ** 2 (1024)\\n\\nThis class defines an attribute X that is accessed as though it were static data, but really\\nruns code to compute its value when fetched. The effect is much like an implicit method\\ncall. When the code is run, the value is stored in the instance as state information, but\\neach time we fetch it via the managed attribute, its value is automatically squared:\\n\\nc:\\\\code> py −3 prop-computed.py\\n9\\n16\\n1024\\n\\nNotice that we’ve made two different instances—because property methods automat-\\nically receive a self argument, they have access to the state information stored in in-\\nstances. In our case, this means the fetch computes the square of the subject instance’s\\nown data.\\n\\nCoding Properties with Decorators\\nAlthough we’re saving additional details until the next chapter, we introduced function\\ndecorator basics earlier, in Chapter 32. Recall that the function decorator syntax:\\n\\n@decorator\\ndef func(args): ...\\n\\nis automatically translated to this equivalent by Python, to rebind the function name\\nto the result of the decorator callable:\\n\\ndef func(args): ...\\nfunc = decorator(func)\\n\\n1224 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cBecause of this mapping, it turns out that the property built-in can serve as a decorator,\\nto define a function that will run automatically when an attribute is fetched:\\n\\nclass Person:\\n    @property\\n    def name(self): ...             # Rebinds: name = property(name)\\n\\nWhen run, the decorated method is automatically passed to the first argument of the\\nproperty built-in. This is really just alternative syntax for creating a property and re-\\nbinding the attribute name manually, but may be seen as more explicit in this role:\\n\\nclass Person:\\n    def name(self): ...\\n    name = property(name)\\n\\nSetter and deleter decorators\\nAs of Python 2.6 and 3.0, property objects also have getter, setter, and deleter meth-\\nods that assign the corresponding property accessor methods and return a copy of the\\nproperty itself. We can use these to specify components of properties by decorating\\nnormal methods too, though the getter component is usually filled in automatically\\nby the act of creating the property itself:\\n\\nclass Person:\\n    def __init__(self, name):\\n        self._name = name\\n\\n    @property\\n    def name(self):                 # name = property(name)\\n        \"name property docs\"\\n        print(\\'fetch...\\')\\n        return self._name\\n\\n    @name.setter\\n    def name(self, value):          # name = name.setter(name)\\n        print(\\'change...\\')\\n        self._name = value\\n\\n    @name.deleter\\n    def name(self):                 # name = name.deleter(name)\\n        print(\\'remove...\\')\\n        del self._name\\n\\nbob = Person(\\'Bob Smith\\')           # bob has a managed attribute\\nprint(bob.name)                     # Runs name getter (name 1)\\nbob.name = \\'Robert Smith\\'           # Runs name setter (name 2)\\nprint(bob.name)\\ndel bob.name                        # Runs name deleter (name 3)\\n\\nprint(\\'-\\'*20)\\nsue = Person(\\'Sue Jones\\')           # sue inherits property too\\nprint(sue.name)\\nprint(Person.name.__doc__)          # Or help(Person.name)\\n\\nProperties\\n\\n| 1225\\n\\n\\x0cIn fact, this code is equivalent to the first example in this section—decoration is just\\nan alternative way to code properties in this case. When it’s run, the results are the same:\\n\\nc:\\\\code> py −3 prop-person-deco.py\\nfetch...\\nBob Smith\\nchange...\\nfetch...\\nRobert Smith\\nremove...\\n--------------------\\nfetch...\\nSue Jones\\nname property docs\\n\\nCompared to manual assignment of property results, in this case using decorators to\\ncode properties requires just three extra lines of code—a seemingly negligible differ-\\nence. As is so often the case with alternative tools, though, the choice between the two\\ntechniques is largely subjective.\\n\\nDescriptors\\nDescriptors provide an alternative way to intercept attribute access; they are strongly\\nrelated to the properties discussed in the prior section. Really, a property is a kind of\\ndescriptor—technically speaking, the property built-in is just a simplified way to create\\na specific type of descriptor that runs method functions on attribute accesses. In fact,\\ndescriptors are the underlying implementation mechanism for a variety of class tools,\\nincluding both properties and slots.\\nFunctionally speaking, the descriptor protocol allows us to route a specific attribute’s\\nget, set, and delete operations to methods of a separate class’s instance object that we\\nprovide. This allows us to insert code to be run automatically on attribute fetches and\\nassignments,  intercept  attribute  deletions,  and  provide  documentation  for  the  at-\\ntributes if desired.\\nDescriptors are created as independent classes, and they are assigned to class attributes\\njust like method functions. Like any other class attribute, they are inherited by sub-\\nclasses  and  instances.  Their  access-interception  methods  are  provided  with  both  a\\nself for the descriptor instance itself, as well as the instance of the client class whose\\nattribute references the descriptor object. Because of this, they can retain and use state\\ninformation of their own, as well as state information of the subject instance. For ex-\\nample, a descriptor may call methods available in the client class, as well as descriptor-\\nspecific methods it defines.\\nLike a property, a descriptor manages a single, specific attribute; although it can’t catch\\nall attribute accesses generically, it provides control over both fetch and assignment\\naccesses and allows us to change an attribute name freely from simple data to a com-\\nputation without breaking existing code. Properties really are just a convenient way to\\n\\n1226 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0ccreate a specific kind of descriptor, and as we shall see, they can be coded as descriptors\\ndirectly.\\nUnlike properties, descriptors are broader in scope, and provide a more general tool.\\nFor instance, because they are coded as normal classes, descriptors have their own state,\\nmay participate in descriptor inheritance hierarchies, can use composition to aggregate\\nobjects, and provide a natural structure for coding internal methods and attribute doc-\\numentation strings.\\n\\nThe Basics\\nAs mentioned previously, descriptors are coded as separate classes and provide spe-\\ncially named accessor methods for the attribute access operations they wish to intercept\\n—get, set, and deletion methods in the descriptor class are automatically run when the\\nattribute assigned to the descriptor class instance is accessed in the corresponding way:\\n\\nclass Descriptor:\\n    \"docstring goes here\"\\n    def __get__(self, instance, owner): ...        # Return attr value\\n    def __set__(self, instance, value): ...        # Return nothing (None)\\n    def __delete__(self, instance): ...            # Return nothing (None)\\n\\nClasses with any of these methods are considered descriptors, and their methods are\\nspecial when one of their instances is assigned to another class’s attribute—when the\\nattribute is accessed, they are automatically invoked. If any of these methods are absent,\\nit generally means that the corresponding type of access is not supported. Unlike prop-\\nerties, however, omitting a __set__ allows the descriptor attribute’s name to be assigned\\nand thus redefined in an instance, thereby hiding the descriptor—to make an attribute\\nread-only, you must define __set__ to catch assignments and raise an exception.\\nDescriptors with __set__ methods also have some special-case implications for inher-\\nitance that we’ll largely defer until Chapter 40’s coverage of metaclasses and the com-\\nplete inheritance specification. In short, a descriptor with a __set__ is known formally\\nas data descriptor, and is given precedence over other names located by normal inher-\\nitance rules. The inherited descriptor for name __class__, for example, overrides the\\nsame name in an instance’s namespace dictionary. This also works to ensure that data\\ndescriptors you code in your own classes take precedence over others.\\n\\nDescriptor method arguments\\nBefore we code anything realistic, let’s take a brief look at some fundamentals. All three\\ndescriptor methods outlined in the prior section are passed both the descriptor class\\ninstance (self), and the instance of the client class to which the descriptor instance is\\nattached (instance).\\nThe __get__ access method additionally receives an owner argument, specifying the class\\nto which the descriptor instance is attached. Its instance argument is either the instance\\nthrough which the attribute was accessed (for instance.attr), or None when the at-\\n\\nDescriptors\\n\\n| 1227\\n\\n\\x0ctribute is accessed through the owner class directly (for class.attr). The former of\\nthese  generally  computes  a  value  for  instance  access,  and  the  latter  usually  returns\\nself if descriptor object access is supported.\\nFor example, in the following 3.X session, when X.attr is fetched, Python automatically\\nruns the __get__ method of the Descriptor class instance to which the Subject.attr\\nclass attribute is assigned. In 2.X, use the print statement equivalent, and derive both\\nclasses here from object, as descriptors are a new-style class tool; in 3.X this derivation\\nis implied and can be omitted, but doesn’t hurt:\\n\\n>>> class Descriptor:                        # Add \"(object)\" in 2.X\\n        def __get__(self, instance, owner):\\n            print(self, instance, owner, sep=\\'\\\\n\\')\\n\\n>>> class Subject:                           # Add \"(object)\" in 2.X\\n        attr = Descriptor()                  # Descriptor instance is class attr\\n\\n>>> X = Subject()\\n>>> X.attr\\n<__main__.Descriptor object at 0x0281E690>\\n<__main__.Subject object at 0x028289B0>\\n<class \\'__main__.Subject\\'>\\n\\n>>> Subject.attr\\n<__main__.Descriptor object at 0x0281E690>\\nNone\\n<class \\'__main__.Subject\\'>\\n\\nNotice the arguments automatically passed in to the __get__ method in the first at-\\ntribute fetch—when X.attr is fetched, it’s as though the following translation occurs\\n(though the Subject.attr here doesn’t invoke __get__ again):\\n\\nX.attr  ->  Descriptor.__get__(Subject.attr, X, Subject)\\n\\nThe descriptor knows it is being accessed directly when its instance argument is None.\\n\\nRead-only descriptors\\nAs mentioned earlier, unlike properties, simply omitting the __set__ method in a de-\\nscriptor isn’t enough to make an attribute read-only, because the descriptor name can\\nbe assigned to an instance. In the following, the attribute assignment to X.a stores a in\\nthe instance object X, thereby hiding the descriptor stored in class C:\\n\\n>>> class D:\\n        def __get__(*args): print(\\'get\\')\\n\\n>>> class C:\\n        a = D()                         # Attribute a is a descriptor instance\\n\\n>>> X = C()\\n>>> X.a                                 # Runs inherited descriptor __get__\\nget\\n>>> C.a\\n\\n1228 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cget\\n>>> X.a = 99                            # Stored on X, hiding C.a!\\n>>> X.a\\n99\\n>>> list(X.__dict__.keys())\\n[\\'a\\']\\n>>> Y = C()\\n>>> Y.a                                 # Y still inherits descriptor\\nget\\n>>> C.a\\nget\\n\\nThis is the way all instance attribute assignments work in Python, and it allows classes\\nto selectively override class-level defaults in their instances. To make a descriptor-based\\nattribute read-only, catch the assignment in the descriptor class and raise an exception\\nto  prevent  attribute  assignment—when  assigning  an  attribute  that  is  a  descriptor,\\nPython effectively bypasses the normal instance-level assignment behavior and routes\\nthe operation to the descriptor object:\\n\\n>>> class D:\\n        def __get__(*args): print(\\'get\\')\\n        def __set__(*args): raise AttributeError(\\'cannot set\\')\\n\\n>>> class C:\\n        a = D()\\n\\n>>> X = C()\\n>>> X.a                                 # Routed to C.a.__get__\\nget\\n>>> X.a = 99                            # Routed to C.a.__set__\\nAttributeError: cannot set\\n\\nAlso be careful not to confuse the descriptor __delete__ method with\\nthe general __del__ method. The former is called on attempts to delete\\nthe managed attribute name on an instance of the owner class; the latter\\nis the general instance destructor method, run when an instance of any\\nkind of class is about to be garbage-collected. __delete__ is more closely\\nrelated to the __delattr__ generic attribute deletion method we’ll meet\\nlater in this chapter. See Chapter 30 for more on operator overloading\\nmethods.\\n\\nA First Example\\nTo see how this all comes together in more realistic code, let’s get started with the same\\nfirst example we wrote for properties. The following defines a descriptor that intercepts\\naccess to an attribute named name in its clients. Its methods use their instance argument\\nto access state information in the subject instance, where the name string is actually\\nstored. Like properties, descriptors work properly only for new-style classes, so be sure\\nto derive both classes in the following from object if you’re using 2.X—it’s not enough\\nto derive just the descriptor, or just its client:\\n\\nDescriptors\\n\\n| 1229\\n\\n\\x0cclass Name:                             # Use (object) in 2.X\\n    \"name descriptor docs\"\\n    def __get__(self, instance, owner):\\n        print(\\'fetch...\\')\\n        return instance._name\\n    def __set__(self, instance, value):\\n        print(\\'change...\\')\\n        instance._name = value\\n    def __delete__(self, instance):\\n        print(\\'remove...\\')\\n        del instance._name\\n\\nclass Person:                           # Use (object) in 2.X\\n    def __init__(self, name):\\n        self._name = name\\n    name = Name()                       # Assign descriptor to attr\\n\\nbob = Person(\\'Bob Smith\\')               # bob has a managed attribute\\nprint(bob.name)                         # Runs Name.__get__\\nbob.name = \\'Robert Smith\\'               # Runs Name.__set__\\nprint(bob.name)\\ndel bob.name                            # Runs Name.__delete__\\n\\nprint(\\'-\\'*20)\\nsue = Person(\\'Sue Jones\\')               # sue inherits descriptor too\\nprint(sue.name)\\nprint(Name.__doc__)                     # Or help(Name)\\n\\nNotice in this code how we assign an instance of our descriptor class to a class at-\\ntribute in the client class; because of this, it is inherited by all instances of the class, just\\nlike a class’s methods. Really, we must assign the descriptor to a class attribute like this\\n—it won’t work if assigned to a self instance attribute instead. When the descriptor’s\\n__get__ method is run, it is passed three objects to define its context:\\n\\n• self is the Name class instance.\\n• instance is the Person class instance.\\n• owner is the Person class.\\n\\nWhen this code is run the descriptor’s methods intercept accesses to the attribute, much\\nlike the property version. In fact, the output is the same again:\\n\\nc:\\\\code> py −3 desc-person.py\\nfetch...\\nBob Smith\\nchange...\\nfetch...\\nRobert Smith\\nremove...\\n--------------------\\nfetch...\\nSue Jones\\nname descriptor docs\\n\\n1230 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cAlso like in the property example, our descriptor class instance is a class attribute and\\nthus is inherited by all instances of the client class and any subclasses. If we change the\\nPerson class in our example to the following, for instance, the output of our script is\\nthe same:\\n\\n...\\nclass Super:\\n    def __init__(self, name):\\n        self._name = name\\n    name = Name()\\n\\nclass Person(Super):                     # Descriptors are inherited (class attrs)\\n   pass\\n...\\n\\nAlso note that when a descriptor class is not useful outside the client class, it’s perfectly\\nreasonable to embed the descriptor’s definition inside its client syntactically. Here’s\\nwhat our example looks like if we use a nested class:\\n\\nclass Person:\\n    def __init__(self, name):\\n        self._name = name\\n\\n    class Name:                                 # Using a nested class\\n        \"name descriptor docs\"\\n        def __get__(self, instance, owner):\\n            print(\\'fetch...\\')\\n            return instance._name\\n        def __set__(self, instance, value):\\n            print(\\'change...\\')\\n            instance._name = value\\n        def __delete__(self, instance):\\n            print(\\'remove...\\')\\n            del instance._name\\n    name = Name()\\n\\nWhen coded this way, Name becomes a local variable in the scope of the Person class\\nstatement, such that it won’t clash with any names outside the class. This version works\\nthe same as the original—we’ve simply moved the descriptor class definition into the\\nclient class’s scope—but the last line of the testing code must change to fetch the doc-\\nstring from its new location (per the example file desc-person-nested.py):\\n\\n...\\nprint(Person.Name.__doc__)     # Differs: not Name.__doc__ outside class\\n\\nComputed Attributes\\nAs was the case when using properties, our first descriptor example of the prior section\\ndidn’t do much—it simply printed trace messages for attribute accesses. In practice,\\ndescriptors can also be used to compute attribute values each time they are fetched.\\nThe following illustrates—it’s a rehash of the same example we coded for properties,\\n\\nDescriptors\\n\\n| 1231\\n\\n\\x0cwhich  uses  a  descriptor  to  automatically  square  an  attribute’s  value  each  time  it  is\\nfetched:\\n\\nclass DescSquare:\\n    def __init__(self, start):                  # Each desc has own state\\n        self.value = start\\n    def __get__(self, instance, owner):         # On attr fetch\\n        return self.value ** 2\\n    def __set__(self, instance, value):         # On attr assign\\n        self.value = value                      # No delete or docs\\n\\nclass Client1:\\n    X = DescSquare(3)          # Assign descriptor instance to class attr\\n\\nclass Client2:\\n    X = DescSquare(32)         # Another instance in another client class\\n                               # Could also code two instances in same class\\nc1 = Client1()\\nc2 = Client2()\\n\\nprint(c1.X)                    # 3 ** 2\\nc1.X = 4\\nprint(c1.X)                    # 4 ** 2\\nprint(c2.X)                    # 32 ** 2 (1024)\\n\\nWhen run, the output of this example is the same as that of the original property-based\\nversion, but here a descriptor class object is intercepting the attribute accesses:\\n\\nc:\\\\code> py −3 desc-computed.py\\n9\\n16\\n1024\\n\\nUsing State Information in Descriptors\\nIf you study the two descriptor examples we’ve written so far, you might notice that\\nthey get their information from different places—the first (the name attribute example)\\nuses data stored on the client instance, and the second (the attribute squaring example)\\nuses data attached to the descriptor object itself (a.k.a. self). In fact, descriptors can\\nuse both instance state and descriptor state, or any combination thereof:\\n\\n• Descriptor state is used to manage either data internal to the workings of the de-\\nscriptor, or data that spans all instances. It can vary per attribute appearance (often,\\nper client class).\\n\\n• Instance state records information related to and possibly created by the client class.\\n\\nIt can vary per client class instance (that is, per application object).\\n\\nIn other words, descriptor state is per-descriptor data and instance state is per-client-\\ninstance data. As usual in OOP, you must choose state carefully. For instance, you\\nwould not normally use descriptor state to record employee names, since each client\\ninstance requires its own value—if stored in the descriptor, each client class instance\\n\\n1232 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cwill effectively share the same single copy. On the other hand, you would not usually\\nuse instance state to record data pertaining to descriptor implementation internals—if\\nstored in each instance, there would be multiple varying copies.\\nDescriptor methods may use either state form, but descriptor state often makes it un-\\nnecessary to use special naming conventions to avoid name collisions in the instance\\nfor data that is not instance-specific. For example, the following descriptor attaches\\ninformation to its own instance, so it doesn’t clash with that on the client class’s in-\\nstance—but also shares that information between two client instances:\\n\\nclass DescState:                           # Use descriptor state, (object) in 2.X\\n    def __init__(self, value):\\n        self.value = value\\n    def __get__(self, instance, owner):    # On attr fetch\\n        print(\\'DescState get\\')\\n        return self.value * 10\\n    def __set__(self, instance, value):    # On attr assign\\n        print(\\'DescState set\\')\\n        self.value = value\\n\\n# Client class\\nclass CalcAttrs:\\n    X = DescState(2)                       # Descriptor class attr\\n    Y = 3                                  # Class attr\\n    def __init__(self):\\n        self.Z = 4                         # Instance attr\\n\\nobj = CalcAttrs()\\nprint(obj.X, obj.Y, obj.Z)                 # X is computed, others are not\\nobj.X = 5                                  # X assignment is intercepted\\nCalcAttrs.Y = 6                            # Y reassigned in class\\nobj.Z = 7                                  # Z assigned in instance\\nprint(obj.X, obj.Y, obj.Z)\\n\\nobj2 = CalcAttrs()                         # But X uses shared data, like Y!\\nprint(obj2.X, obj2.Y, obj2.Z)\\n\\nThis code’s internal value information lives only in the descriptor, so there won’t be a\\ncollision if the same name is used in the client’s instance. Notice that only the descriptor\\nattribute is managed here—get and set accesses to X are intercepted, but accesses to Y\\nand Z are not (Y is attached to the client class and Z to the instance). When this code is\\nrun, X is computed when fetched, but its value is also the same for all client instances\\nbecause it uses descriptor-level state:\\nc:\\\\code> py −3 desc-state-desc.py\\nDescState get\\n20 3 4\\nDescState set\\nDescState get\\n50 6 7\\nDescState get\\n50 6 4\\n\\nDescriptors\\n\\n| 1233\\n\\n\\x0cIt’s also feasible for a descriptor to store or use an attribute attached to the client class’s\\ninstance, instead of itself. Crucially, unlike data stored in the descriptor itself, this allows\\nfor data that can vary per client class instance. The descriptor in the following example\\nassumes the instance has an attribute _X attached by the client class, and uses it to\\ncompute the value of the attribute it represents:\\n\\nclass InstState:                           # Using instance state, (object) in 2.X\\n    def __get__(self, instance, owner):\\n        print(\\'InstState get\\')             # Assume set by client class\\n        return instance._X * 10\\n    def __set__(self, instance, value):\\n        print(\\'InstState set\\')\\n        instance._X = value\\n\\n# Client class\\nclass CalcAttrs:\\n    X = InstState()                        # Descriptor class attr\\n    Y = 3                                  # Class attr\\n    def __init__(self):\\n        self._X = 2                        # Instance attr\\n        self.Z  = 4                        # Instance attr\\n\\nobj = CalcAttrs()\\nprint(obj.X, obj.Y, obj.Z)                 # X is computed, others are not\\nobj.X = 5                                  # X assignment is intercepted\\nCalcAttrs.Y = 6                            # Y reassigned in class\\nobj.Z = 7                                  # Z assigned in instance\\nprint(obj.X, obj.Y, obj.Z)\\n\\nobj2 = CalcAttrs()                         # But X differs now, like Z!\\nprint(obj2.X, obj2.Y, obj2.Z)\\n\\nHere, X is assigned to a descriptor as before that manages accesses. The new descriptor\\nhere, though, has no information itself, but it uses an attribute assumed to exist in the\\ninstance—that attribute is named _X, to avoid collisions with the name of the descriptor\\nitself. When this version is run the results are similar, but the value of the descriptor\\nattribute can vary per client instance due to the differing state policy:\\n\\nc:\\\\code> py −3 desc-state-inst.py\\nInstState get\\n20 3 4\\nInstState set\\nInstState get\\n50 6 7\\nInstState get\\n20 6 4\\n\\nBoth descriptor and instance state have roles. In fact, this is a general advantage that\\ndescriptors have over properties—because they have state of their own, they can easily\\nretain data internally, without adding it to the namespace of the client instance object.\\nAs a summary, the following uses both state sources—its self.data retains per-attribute\\ninformation, while its instance.data can vary per client instance:\\n\\n1234 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0c>>> class DescBoth:\\n        def __init__(self, data):\\n            self.data = data\\n        def __get__(self, instance, owner):\\n            return \\'%s, %s\\' % (self.data, instance.data)\\n        def __set__(self, instance, value):\\n            instance.data = value\\n\\n>>> class Client:\\n        def __init__(self, data):\\n            self.data = data\\n        managed = DescBoth(\\'spam\\')\\n\\n>>> I = Client(\\'eggs\\')\\n>>> I.managed                      # Show both data sources\\n\\'spam, eggs\\'\\n>>> I.managed = \\'SPAM\\'             # Change instance data\\n>>> I.managed\\n\\'spam, SPAM\\'\\n\\nWe’ll revisit the implications of this choice in a larger case study later in this chapter.\\nBefore we move on, recall from Chapter 32’s coverage of slots that we can access “vir-\\ntual” attributes like properties and descriptors with tools like dir and getattr, even\\nthough they don’t exist in the instance’s namespace dictionary. Whether you should\\naccess these this way probably varies per program—properties and descriptors may\\nrun arbitrary computation, and may be less obviously instance “data” than slots:\\n\\n>>> I.__dict__\\n{\\'data\\': \\'SPAM\\'}\\n>>> [x for x in dir(I) if not x.startswith(\\'__\\')]\\n[\\'data\\', \\'managed\\']\\n\\n>>> getattr(I, \\'data\\')\\n\\'SPAM\\'\\n>>> getattr(I, \\'managed\\')\\n\\'spam, SPAM\\'\\n\\n>>> for attr in (x for x in dir(I) if not x.startswith(\\'__\\')):\\n        print(\\'%s => %s\\' % (attr, getattr(I, attr)))\\n\\ndata => SPAM\\nmanaged => spam, SPAM\\n\\nThe more generic __getattr__ and __getattribute__ tools we’ll meet later are not de-\\nsigned to support this functionality—because they have no class-level attributes, their\\n“virtual” attribute names do not appear in dir results. In exchange, they are also not\\nlimited to specific attribute names coded as properties or descriptors: tools that share\\neven more than this behavior, as the next section explains.\\n\\nDescriptors\\n\\n| 1235\\n\\n\\x0cHow Properties and Descriptors Relate\\nAs mentioned earlier, properties and descriptors are strongly related—the  property\\nbuilt-in is just a convenient way to create a descriptor. Now that you know how both\\nwork, you should also be able to see that it’s possible to simulate the property built-in\\nwith a descriptor class like the following:\\n\\nclass Property:\\n    def __init__(self, fget=None, fset=None, fdel=None, doc=None):\\n        self.fget = fget\\n        self.fset = fset\\n        self.fdel = fdel                                  # Save unbound methods\\n        self.__doc__ = doc                                # or other callables\\n\\n    def __get__(self, instance, instancetype=None):\\n        if instance is None:\\n            return self\\n        if self.fget is None:\\n            raise AttributeError(\"can\\'t get attribute\")\\n        return self.fget(instance)                        # Pass instance to self\\n                                                          # in property accessors\\n    def __set__(self, instance, value):\\n        if self.fset is None:\\n            raise AttributeError(\"can\\'t set attribute\")\\n        self.fset(instance, value)\\n\\n    def __delete__(self, instance):\\n        if self.fdel is None:\\n            raise AttributeError(\"can\\'t delete attribute\")\\n        self.fdel(instance)\\n\\nclass Person:\\n    def getName(self): print(\\'getName...\\')\\n    def setName(self, value): print(\\'setName...\\')\\n    name = Property(getName, setName)                     # Use like property()\\n\\nx = Person()\\nx.name\\nx.name = \\'Bob\\'\\ndel x.name\\n\\nThis Property class catches attribute accesses with the descriptor protocol and routes\\nrequests to functions or methods passed in and saved in descriptor state when the class\\nis  created.  Attribute  fetches,  for  example,  are  routed  from  the  Person  class,  to  the\\nProperty class’s __get__ method, and back to the Person class’s getName. With descrip-\\ntors, this “just works”:\\n\\nc:\\\\code> py −3 prop-desc-equiv.py\\ngetName...\\nsetName...\\nAttributeError: can\\'t delete attribute\\n\\nNote that this descriptor class equivalent only handles basic property usage, though;\\nto use @ decorator syntax to also specify set and delete operations, we’d have to extend\\n\\n1236 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cour Property class with setter and deleter methods, which would save the decorated\\naccessor function and return the property object (self should suffice). Since the prop\\nerty built-in already does this, we’ll omit a formal coding of this extension here.\\n\\nDescriptors and slots and more\\nYou can also probably now at least in part imagine how descriptors are used to imple-\\nment Python’s slots extension: instance attribute dictionaries are avoided by creating\\nclass-level  descriptors  that  intercept  slot  name  access,  and  map  those  names  to  se-\\nquential storage space in the instance. Unlike the explicit property call, though, much\\nof the magic behind slots is orchestrated at class creation time both automatically and\\nimplicitly, when a __slots__ attribute is present in a class.\\nSee Chapter 32 for more on slots (and why they’re not recommended except in patho-\\nlogical use cases). Descriptors are also used for other class tools, but we’ll omit further\\ninternals details here; see Python’s manuals and source code for more details.\\n\\nIn Chapter 39, we’ll also make use of descriptors to implement function\\ndecorators that apply to both functions and methods. As you’ll see there,\\nbecause descriptors receive both descriptor and subject class instances\\nthey work well in this role, though nested functions are usually a con-\\nceptually much simpler solution. We’ll also deploy descriptors as one\\nway to intercept built-in operation method fetches in Chapter 39.\\n\\nBe sure to also see Chapter 40’s coverage of data descriptors’ precedence\\nin the full inheritance model mentioned earlier: with a __set__, descrip-\\ntors override other names, and are thus fairly binding—they cannot be\\nhidden by names in instance dictionaries.\\n\\n__getattr__ and __getattribute__\\nSo far, we’ve studied properties and descriptors—tools for managing specific attributes.\\nThe  __getattr__  and  __getattribute__  operator  overloading  methods  provide  still\\nother ways to intercept attribute fetches for class instances. Like properties and de-\\nscriptors, they allow us to insert code to be run automatically when attributes are ac-\\ncessed. As we’ll see, though, these two methods can also be used in more general ways.\\nBecause they intercept arbitrary names, they apply in broader roles such as delegation,\\nbut may also incur extra calls in some contexts, and are too dynamic to register in\\ndir results.\\nAttribute fetch interception comes in two flavors, coded with two different methods:\\n\\n• __getattr__ is run for undefined attributes—because it is run only for attributes\\nnot stored on an instance or inherited from one of its classes, its use is straightfor-\\nward.\\n\\n__getattr__ and __getattribute__ | 1237\\n\\n\\x0c• __getattribute__ is run for every attribute—because it is all-inclusive, you must\\nbe cautious when using this method to avoid recursive loops by passing attribute\\naccesses to a superclass.\\n\\nWe met the former of these in Chapter 30; it’s available for all Python versions. The\\nlatter of these is available for new-style classes in 2.X, and for all (implicitly new-style)\\nclasses in 3.X. These two methods are representatives of a set of attribute interception\\nmethods that also includes __setattr__ and __delattr_. Because these methods have\\nsimilar roles, though, we will generally treat them all as a single topic here.\\nUnlike properties and descriptors, these methods are part of Python’s general operator\\noverloading protocol—specially named methods of a class, inherited by subclasses, and\\nrun automatically when instances are used in the implied built-in operation. Like all\\nnormal methods of a class, they each receive a first self argument when called, giving\\naccess to any required instance state information as well as other methods of the class\\nin which they appear.\\nThe __getattr__ and __getattribute__ methods are also more generic than properties\\nand  descriptors—they  can  be  used  to  intercept  access  to  any  (or  even  all)  instance\\nattribute fetches, not just a single specific name. Because of this, these two methods\\nare well suited to general delegation-based coding patterns—they can be used to im-\\nplement wrapper (a.k.a. proxy) objects that manage all attribute accesses for an em-\\nbedded object. By contrast, we must define one property or descriptor for every at-\\ntribute we wish to intercept. As we’ll see ahead, this role is impaired somewhat in new-\\nstyle classes for built-in operations, but still applies to all named methods in a wrapped\\nobject’s interface.\\nFinally, these two methods are more narrowly focused than the alternatives we consid-\\nered earlier: they intercept attribute fetches only, not assignments. To also catch at-\\ntribute  changes  by  assignment,  we  must  code  a  __setattr__  method—an  operator\\noverloading method run for every attribute fetch, which must take care to avoid recur-\\nsive loops by routing attribute assignments through the instance namespace dictionary\\nor a superclass method. Although less common, we can also code a __delattr__ over-\\nloading method (which must avoid looping in the same way) to intercept attribute\\ndeletions. By contrast, properties and descriptors catch get, set, and delete operations\\nby design.\\nMost of these operator overloading methods were introduced earlier in the book; here,\\nwe’ll expand on their usage and study their roles in larger contexts.\\n\\nThe Basics\\n__getattr__  and  __setattr__  were  introduced  in  Chapter  30  and  Chapter  32,  and\\n__getattribute__ was mentioned briefly in Chapter 32. In short, if a class defines or\\ninherits the following methods, they will be run automatically when an instance is used\\nin the context described by the comments to the right:\\n\\n1238 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cdef __getattr__(self, name):        # On undefined attribute fetch [obj.name]\\ndef __getattribute__(self, name):   # On all attribute fetch [obj.name]\\ndef __setattr__(self, name, value): # On all attribute assignment [obj.name=value]\\ndef __delattr__(self, name):        # On all attribute deletion [del obj.name]\\n\\nIn all of these, self is the subject instance object as usual, name is the string name of the\\nattribute being accessed, and value is the object being assigned to the attribute. The\\ntwo get methods normally return an attribute’s value, and the other two return nothing\\n(None). All can raise exceptions to signal prohibited access.\\nFor example, to catch every attribute fetch, we can use either of the first two previous\\nmethods, and to catch every attribute assignment we can use the third. The following\\nuses __getattr__ and works portably on both Python 2.X and 3.X, not requiring new-\\nstyle object derivation in 2.X:\\n\\nclass Catcher:\\n    def __getattr__(self, name):\\n        print(\\'Get: %s\\' % name)\\n    def __setattr__(self, name, value):\\n        print(\\'Set: %s %s\\' % (name, value))\\n\\nX = Catcher()\\nX.job                               # Prints \"Get: job\"\\nX.pay                               # Prints \"Get: pay\"\\nX.pay = 99                          # Prints \"Set: pay 99\"\\n\\nUsing  __getattribute__  works  exactly  the  same  in  this  specific  case,  but  requires\\nobject derivation in 2.X (only), and has subtle looping potential, which we’ll take up\\nin the next section:\\n\\nclass Catcher(object):                           # Need (object) in 2.X only\\n    def __getattribute__(self, name):            # Works same as getattr here\\n        print(\\'Get: %s\\' % name)                  # But prone to loops on general\\n    ...rest unchanged...\\n\\nSuch a coding structure can be used to implement the delegation design pattern we met\\nearlier, in Chapter 31. Because all attributes are routed to our interception methods\\ngenerically, we can validate and pass them along to embedded, managed objects. The\\nfollowing class (borrowed from Chapter 31), for example, traces every attribute fetch\\nmade to another object passed to the wrapper (proxy) class:\\n\\nclass Wrapper:\\n    def __init__(self, object):\\n        self.wrapped = object                    # Save object\\n    def __getattr__(self, attrname):\\n        print(\\'Trace: \\' + attrname)              # Trace fetch\\n        return getattr(self.wrapped, attrname)   # Delegate fetch\\n\\nX = Wrapper([1, 2, 3])\\nX.append(4)                         # Prints \"Trace: append\"\\nprint(X.wrapped)                    # Prints \"[1, 2, 3, 4]\"\\n\\nThere is no such analog for properties and descriptors, short of coding accessors for\\nevery possible attribute in every possibly wrapped object. On the other hand, when\\n\\n__getattr__ and __getattribute__ | 1239\\n\\n\\x0csuch generality is not required, generic accessor methods may incur additional calls for\\nassignments in some contexts—a tradeoff described in Chapter 30 and mentioned in\\nthe context of the case study example we’ll explore at the end of this chapter.\\n\\nAvoiding loops in attribute interception methods\\nThese methods are generally straightforward to use; their only substantially complex\\naspect is the potential for looping (a.k.a. recursing). Because __getattr__ is called for\\nundefined attributes only, it can freely fetch other attributes within its own code. How-\\never, because __getattribute__ and __setattr__ are run for all attributes, their code\\nneeds to be careful when accessing other attributes to avoid calling themselves again\\nand triggering a recursive loop.\\nFor example, another attribute fetch run inside a __getattribute__ method’s code will\\ntrigger __getattribute__ again, and the code will usually loop until memory is exhaus-\\nted:\\n\\n    def __getattribute__(self, name):\\n        x = self.other                                # LOOPS!\\n\\nTechnically, this method is even more loop-prone than this may imply—a self attribute\\nreference  run  anywhere  in  a  class  that  defines  this  method  will  trigger  __getattri\\nbute__, and also has the potential to loop depending on the class’s logic. This is nor-\\nmally desired behavior—intercepting every attribute fetch is this method’s purpose,\\nafter all—but you should be aware that this method catches all attribute fetches wher-\\never they are coded. When coded within __getattribute__ itself, this almost always\\ncauses a loop. To avoid this loop, route the fetch through a higher superclass instead\\nto skip this level’s version—because the object class is always a new-style superclass,\\nit serves well in this role:\\n\\n    def __getattribute__(self, name):\\n        x = object.__getattribute__(self, \\'other\\')    # Force higher to avoid me\\n\\nFor  __setattr__,  the  situation  is  similar,  as  summarized  in  Chapter  30—assigning\\nany attribute inside this method triggers __setattr__ again and may create a similar\\nloop:\\n\\n    def __setattr__(self, name, value):\\n        self.other = value                            # Recurs (and might LOOP!)\\n\\nHere too, self attribute assignments anywhere in a class defining this method trigger\\n__setattr__ as well, though the potential for looping is much stronger when they show\\nup in __setattr__ itself. To work around this problem, you can assign the attribute as\\na key in the instance’s __dict__ namespace dictionary instead. This avoids direct at-\\ntribute assignment:\\n\\n    def __setattr__(self, name, value):\\n        self.__dict__[\\'other\\'] = value                # Use attr dict to avoid me\\n\\n1240 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cAlthough it’s a less traditional approach, __setattr__ can also pass its own attribute\\nassignments to a higher superclass to avoid looping, just like __getattribute__ (and\\nper the upcoming note, this scheme is sometimes preferred):\\n\\n    def __setattr__(self, name, value):\\n        object.__setattr__(self, \\'other\\', value)      # Force higher to avoid me\\n\\nBy contrast, though, we cannot use the __dict__ trick to avoid loops in __getattri\\nbute__:\\n\\n    def __getattribute__(self, name):\\n        x = self.__dict__[\\'other\\']                    # Loops!\\n\\nFetching the __dict__ attribute itself triggers __getattribute__ again, causing a recur-\\nsive loop. Strange but true!\\nThe __delattr__ method is less commonly used in practice, but when it is, it is called\\nfor every attribute deletion (just as __setattr__ is called for every attribute assignment).\\nWhen using this method, you must take care to avoid loops when deleting attributes,\\nby using the same techniques: namespace dictionaries operations or superclass method\\ncalls.\\n\\nAs noted in Chapter 30, attributes implemented with new-style class\\nfeatures such as slots and properties are not physically stored in the in-\\nstance’s __dict__ namespace dictionary (and slots may even preclude\\nits existence entirely). Because of this, code that wishes to support such\\nattributes \\nthe\\nobject.__setattr__ scheme shown here, not by self.__dict__ index-\\ning. Namespace __dict__ operations suffice for classes known to store\\ndata in instances, like this chapter’s self-contained examples; general\\ntools, though, should prefer object.\\n\\nassign  with \\n\\n__setattr__ \\n\\nshould \\n\\ncode \\n\\nto \\n\\nA First Example\\nGeneric attribute management is not nearly as complicated as the prior section may\\nhave implied. To see how to put these ideas to work, here is the same first example we\\nused for properties and descriptors in action again, this time implemented with at-\\ntribute operator overloading methods. Because these methods are so generic, we test\\nattribute names here to know when a managed attribute is being accessed; others are\\nallowed to pass normally:\\n\\nclass Person:                               # Portable: 2.X or 3.X\\n    def __init__(self, name):               # On [Person()]\\n        self._name = name                   # Triggers __setattr__!\\n\\n    def __getattr__(self, attr):            # On [obj.undefined]\\n        print(\\'get: \\' + attr)\\n        if attr == \\'name\\':                  # Intercept name: not stored\\n            return self._name               # Does not loop: real attr\\n        else:                               # Others are errors\\n\\n__getattr__ and __getattribute__ | 1241\\n\\n\\x0c            raise AttributeError(attr)\\n\\n    def __setattr__(self, attr, value):     # On [obj.any = value]\\n        print(\\'set: \\' + attr)\\n        if attr == \\'name\\':\\n            attr = \\'_name\\'                  # Set internal name\\n        self.__dict__[attr] = value         # Avoid looping here\\n\\n    def __delattr__(self, attr):            # On [del obj.any]\\n        print(\\'del: \\' + attr)\\n        if attr == \\'name\\':\\n            attr = \\'_name\\'                  # Avoid looping here too\\n        del self.__dict__[attr]             # but much less common\\n\\nbob = Person(\\'Bob Smith\\')           # bob has a managed attribute\\nprint(bob.name)                     # Runs __getattr__\\nbob.name = \\'Robert Smith\\'           # Runs __setattr__\\nprint(bob.name)\\ndel bob.name                        # Runs __delattr__\\n\\nprint(\\'-\\'*20)\\nsue = Person(\\'Sue Jones\\')           # sue inherits property too\\nprint(sue.name)\\n#print(Person.name.__doc__)         # No equivalent here\\n\\nNotice that the attribute assignment in the __init__ constructor triggers __setattr__\\ntoo—this method catches every attribute assignment, even those anywhere within the\\nclass itself. When this code is run, the same output is produced, but this time it’s the\\nresult of Python’s normal operator overloading mechanism and our attribute intercep-\\ntion methods:\\n\\nc:\\\\code> py −3 getattr-person.py\\nset: _name\\nget: name\\nBob Smith\\nset: name\\nget: name\\nRobert Smith\\ndel: name\\n--------------------\\nset: _name\\nget: name\\nSue Jones\\n\\nAlso note that, unlike with properties and descriptors, there’s no direct notion of spec-\\nifying documentation for our attribute here; managed attributes exist within the code\\nof our interception methods, not as distinct objects.\\n\\nUsing __getattribute__\\nTo achieve exactly the same results with __getattribute__, replace __getattr__ in the\\nexample with the following; because it catches all attribute fetches, this version must\\n\\n1242 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cbe careful to avoid looping by passing new fetches to a superclass, and it can’t generally\\nassume unknown names are errors:\\n\\n# Replace __getattr__ with this\\n\\n    def __getattribute__(self, attr):                 # On [obj.any]\\n        print(\\'get: \\' + attr)\\n        if attr == \\'name\\':                            # Intercept all names\\n            attr = \\'_name\\'                            # Map to internal name\\n        return object.__getattribute__(self, attr)    # Avoid looping here\\n\\nWhen  run  with  this  change,  the  output  is  similar,  but  we  get  an  extra  __getattri\\nbute__ call for the fetch in __setattr__ (the first time originating in __init__):\\n\\nc:\\\\code> py −3 getattribute-person.py\\nset: _name\\nget: __dict__\\nget: name\\nBob Smith\\nset: name\\nget: __dict__\\nget: name\\nRobert Smith\\ndel: name\\nget: __dict__\\n--------------------\\nset: _name\\nget: __dict__\\nget: name\\nSue Jones\\n\\nThis example is equivalent to that coded for properties and descriptors, but it’s a bit\\nartificial, and it doesn’t really highlight these tools’ assets. Because they are generic,\\n__getattr__ and __getattribute__ are probably more commonly used in delegation-\\nbase code (as sketched earlier), where attribute access is validated and routed to an\\nembedded object. Where just a single attribute must be managed, properties and de-\\nscriptors might do as well or better.\\n\\nComputed Attributes\\nAs before, our prior example doesn’t really do anything but trace attribute fetches; it’s\\nnot much more work to compute an attribute’s value when fetched. As for properties\\nand descriptors, the following creates a virtual attribute X that runs a calculation when\\nfetched:\\n\\nclass AttrSquare:\\n    def __init__(self, start):\\n        self.value = start                            # Triggers __setattr__!\\n\\n    def __getattr__(self, attr):                      # On undefined attr fetch\\n        if attr == \\'X\\':\\n            return self.value ** 2                    # value is not undefined\\n        else:\\n\\n__getattr__ and __getattribute__ | 1243\\n\\n\\x0c            raise AttributeError(attr)\\n\\n    def __setattr__(self, attr, value):               # On all attr assignments\\n        if attr == \\'X\\':\\n            attr = \\'value\\'\\n        self.__dict__[attr] = value\\n\\nA = AttrSquare(3)       # 2 instances of class with overloading\\nB = AttrSquare(32)      # Each has different state information\\n\\nprint(A.X)              # 3 ** 2\\nA.X = 4\\nprint(A.X)              # 4 ** 2\\nprint(B.X)              # 32 ** 2 (1024)\\n\\nRunning this code results in the same output that we got earlier when using properties\\nand descriptors, but this script’s mechanics are based on generic attribute interception\\nmethods:\\n\\nc:\\\\code> py −3 getattr-computed.py\\n9\\n16\\n1024\\n\\nUsing __getattribute__\\nAs  before,  we  can  achieve  the  same  effect  with  __getattribute__  instead  of  __get\\nattr__; the following replaces the fetch method with a __getattribute__ and changes\\nthe __setattr__ assignment method to avoid looping by using direct superclass method\\ncalls instead of __dict__ keys:\\n\\nclass AttrSquare:                           # Add (object) for 2.X\\n    def __init__(self, start):\\n        self.value = start                  # Triggers __setattr__!\\n\\n    def __getattribute__(self, attr):       # On all attr fetches\\n        if attr == \\'X\\':\\n            return self.value ** 2          # Triggers __getattribute__ again!\\n        else:\\n            return object.__getattribute__(self, attr)\\n\\n    def __setattr__(self, attr, value):     # On all attr assignments\\n        if attr == \\'X\\':\\n            attr = \\'value\\'\\n        object.__setattr__(self, attr, value)\\n\\nWhen this version, getattribute-computed.py, is run, the results are the same again.\\nNotice, though, the implicit routing going on inside this class’s methods:\\n\\n• self.value=start inside the constructor triggers __setattr__\\n• self.value inside __getattribute__ triggers __getattribute__ again\\n\\nIn fact, __getattribute__ is run twice each time we fetch attribute X. This doesn’t hap-\\npen in the __getattr__ version, because the value attribute is not undefined. If you care\\n\\n1244 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cabout speed and want to avoid this, change __getattribute__ to use the superclass to\\nfetch value as well:\\n\\n    def __getattribute__(self, attr):\\n        if attr == \\'X\\':\\n            return object.__getattribute__(self, \\'value\\') ** 2\\n\\nOf course, this still incurs a call to the superclass method, but not an additional recur-\\nsive call before we get there. Add print calls to these methods to trace how and when\\nthey run.\\n\\n__getattr__ and __getattribute__ Compared\\nTo summarize the coding differences between __getattr__ and __getattribute__, the\\nfollowing example uses both to implement three attributes—attr1 is a class attribute,\\nattr2 is an instance attribute, and attr3 is a virtual managed attribute computed when\\nfetched:\\n\\nclass GetAttr:\\n    attr1 = 1\\n    def __init__(self):\\n        self.attr2 = 2\\n    def __getattr__(self, attr):            # On undefined attrs only\\n        print(\\'get: \\' + attr)               # Not on attr1: inherited from class\\n        if attr == \\'attr3\\':                 # Not on attr2: stored on instance\\n            return 3\\n        else:\\n            raise AttributeError(attr)\\n\\nX = GetAttr()\\nprint(X.attr1)\\nprint(X.attr2)\\nprint(X.attr3)\\nprint(\\'-\\'*20)\\n\\nclass GetAttribute(object):                 # (object) needed in 2.X only\\n    attr1 = 1\\n    def __init__(self):\\n        self.attr2 = 2\\n    def __getattribute__(self, attr):       # On all attr fetches\\n        print(\\'get: \\' + attr)               # Use superclass to avoid looping here\\n        if attr == \\'attr3\\':\\n            return 3\\n        else:\\n            return object.__getattribute__(self, attr)\\n\\nX = GetAttribute()\\nprint(X.attr1)\\nprint(X.attr2)\\nprint(X.attr3)\\n\\n__getattr__ and __getattribute__ | 1245\\n\\n\\x0cWhen run, the __getattr__ version intercepts only attr3 accesses, because it is unde-\\nfined. The __getattribute__ version, on the other hand, intercepts all attribute fetches\\nand must route those it does not manage to the superclass fetcher to avoid loops:\\n\\nc:\\\\code> py −3 getattr-v-getattr.py\\n1\\n2\\nget: attr3\\n3\\n--------------------\\nget: attr1\\n1\\nget: attr2\\n2\\nget: attr3\\n3\\n\\nAlthough __getattribute__ can catch more attribute fetches than __getattr__, in prac-\\ntice they are often just variations on a theme—if attributes are not physically stored,\\nthe two have the same effect.\\n\\nManagement Techniques Compared\\nTo summarize the coding differences in all four attribute management schemes we’ve\\nseen in this chapter, let’s quickly step through a somewhat more comprehensive com-\\nputed-attribute example using each technique, coded to run in either Python 3.X or\\n2.X. The following first version uses properties to intercept and calculate attributes\\nnamed square and cube. Notice how their base values are stored in names that begin\\nwith an underscore, so they don’t clash with the names of the properties themselves:\\n\\n# Two dynamically computed attributes with properties\\n\\nclass Powers(object):                              # Need (object) in 2.X only\\n    def __init__(self, square, cube):\\n        self._square = square                      # _square is the base value\\n        self._cube   = cube                        # square is the property name\\n\\n    def getSquare(self):\\n        return self._square ** 2\\n    def setSquare(self, value):\\n        self._square = value\\n    square = property(getSquare, setSquare)\\n\\n    def getCube(self):\\n        return self._cube ** 3\\n    cube = property(getCube)\\n\\nX = Powers(3, 4)\\nprint(X.square)      # 3 ** 2 = 9\\nprint(X.cube)        # 4 ** 3 = 64\\nX.square = 5\\nprint(X.square)      # 5 ** 2 = 25\\n\\n1246 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cTo do the same with descriptors, we define the attributes with complete classes. Note\\nthat these descriptors store base values as instance state, so they must use leading un-\\nderscores again so as not to clash with the names of descriptors; as we’ll see in the final\\nexample of this chapter, we could avoid this renaming requirement by storing base\\nvalues as descriptor state instead, but that doesn’t as directly address data that must\\nvary per client class instance:\\n\\n# Same, but with descriptors (per-instance state)\\n\\nclass DescSquare(object):\\n    def __get__(self, instance, owner):\\n        return instance._square ** 2\\n    def __set__(self, instance, value):\\n        instance._square = value\\n\\nclass DescCube(object):\\n    def __get__(self, instance, owner):\\n        return instance._cube ** 3\\n\\nclass Powers(object):                          # Need all (object) in 2.X only\\n    square = DescSquare()\\n    cube   = DescCube()\\n    def __init__(self, square, cube):\\n        self._square = square                  # \"self.square = square\" works too,\\n        self._cube   = cube                    # because it triggers desc __set__!\\n\\nX = Powers(3, 4)\\nprint(X.square)      # 3 ** 2 = 9\\nprint(X.cube)        # 4 ** 3 = 64\\nX.square = 5\\nprint(X.square)      # 5 ** 2 = 25\\n\\nTo achieve the same result with __getattr__ fetch interception, we again store base\\nvalues with underscore-prefixed names so that accesses to managed names are unde-\\nfined and thus invoke our method; we also need to code a __setattr__ to intercept\\nassignments, and take care to avoid its potential for looping:\\n\\n# Same, but with generic __getattr__ undefined attribute interception\\n\\nclass Powers:\\n    def __init__(self, square, cube):\\n        self._square = square\\n        self._cube   = cube\\n\\n    def __getattr__(self, name):\\n        if name == \\'square\\':\\n            return self._square ** 2\\n        elif name == \\'cube\\':\\n            return self._cube ** 3\\n        else:\\n            raise TypeError(\\'unknown attr:\\' + name)\\n\\n    def __setattr__(self, name, value):\\n        if name == \\'square\\':\\n\\n__getattr__ and __getattribute__ | 1247\\n\\n\\x0c            self.__dict__[\\'_square\\'] = value             # Or use object\\n        else:\\n            self.__dict__[name] = value\\n\\nX = Powers(3, 4)\\nprint(X.square)      # 3 ** 2 = 9\\nprint(X.cube)        # 4 ** 3 = 64\\nX.square = 5\\nprint(X.square)      # 5 ** 2 = 25\\n\\nThe final option, coding this with __getattribute__, is similar to the prior version.\\nBecause we catch every attribute now, though, we must also route base value fetches\\nto a superclass to avoid looping or extra calls—fetching self._square directly works\\ntoo, but runs a second __getattribute__ call:\\n\\n# Same, but with generic __getattribute__ all attribute interception\\n\\nclass Powers(object):                                    # Need (object) in 2.X only\\n    def __init__(self, square, cube):\\n        self._square = square\\n        self._cube   = cube\\n\\n    def __getattribute__(self, name):\\n        if name == \\'square\\':\\n            return object.__getattribute__(self, \\'_square\\') ** 2\\n        elif name == \\'cube\\':\\n            return object.__getattribute__(self, \\'_cube\\') ** 3\\n        else:\\n            return object.__getattribute__(self, name)\\n\\n    def __setattr__(self, name, value):\\n        if name == \\'square\\':\\n            object.__setattr__(self, \\'_square\\', value)   # Or use __dict__\\n        else:\\n            object.__setattr__(self, name , value)\\n\\nX = Powers(3, 4)\\nprint(X.square)      # 3 ** 2 = 9\\nprint(X.cube)        # 4 ** 3 = 64\\nX.square = 5\\nprint(X.square)      # 5 ** 2 = 25\\n\\nAs you can see, each technique takes a different form in code, but all four produce the\\nsame result when run:\\n\\n9\\n64\\n25\\n\\nFor more on how these alternatives compare, and other coding options, stay tuned for\\na more realistic application of them in the attribute validation example in the section\\n“Example: Attribute Validations” on page 1256. First, though, we need to take a short\\nside trip to study a new-style-class pitfall associated with two of these tools—the generic\\nattribute interceptors presented in this section.\\n\\n1248 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cIntercepting Built-in Operation Attributes\\nIf you’ve been reading this book linearly, some of this section is review and elaboration\\non material covered earlier, especially in Chapter 32. For others, this topic is presented\\nin this chapter’s context here.\\nWhen I introduced __getattr__ and __getattribute__, I stated that they intercept un-\\ndefined and all attribute fetches, respectively, which makes them ideal for delegation-\\nbased  coding  patterns.  While  this  is  true  for  both  normally  named  and  explicitly\\ncalled attributes, their behavior needs some additional clarification: for method-name\\nattributes implicitly fetched by built-in operations, these methods may not be run at\\nall. This means that operator overloading method calls cannot be delegated to wrapped\\nobjects unless wrapper classes somehow redefine these methods themselves.\\nFor example, attribute fetches for the __str__, __add__, and __getitem__ methods run\\nimplicitly by printing, + expressions, and indexing, respectively, are not routed to the\\ngeneric attribute interception methods in 3.X. Specifically:\\n\\n• In Python 3.X, neither __getattr__ nor __getattribute__ is run for such attributes.\\n• In Python 2.X classic classes, __getattr__ is run for such attributes if they are un-\\n\\ndefined in the class.\\n\\n• In Python 2.X, __getattribute__ is available for new-style classes only and works\\n\\nas it does in 3.X.\\n\\nIn other words, in all Python 3.X classes (and 2.X new-style classes), there is no direct\\nway to generically intercept built-in operations like printing and addition. In Python\\n2.X’s default classic classes, the methods such operations invoke are looked up at run-\\ntime in instances, like all other attributes; in Python 3.X’s new-style classes such meth-\\nods are looked up in classes instead. Since 3.X mandates new-style classes and 2.X\\ndefaults to classic, this is understandably attributed to 3.X, but it can happen in 2.X\\nnew-style code too. In 2.X, though, you at least have a way to avoid this change; in 3.X,\\nyou do not.\\nPer Chapter 32, the official (though tersely documented) rationale for this change ap-\\npears to revolve around metaclassses and optimization of built-in operations. Regard-\\nless, given that all attributes—both normally named and others—still dispatch gener-\\nically through the instance and these methods when accessed explicitly by name, this\\ndoes not seem meant to preclude delegation in general; it seems more an optimization\\nstep for built-in operations’ implicit behavior. This does, however, make delegation-\\nbased coding patterns more complex in 3.X, because object interface proxies cannot\\ngenerically intercept operator overloading method calls and route them to an embedded\\nobject.\\nThis is an inconvenience, but is not necessarily a showstopper—wrapper classes can\\nwork around this constraint by redefining all relevant operator overloading methods\\nin the wrapper itself, in order to delegate calls. These extra methods can be added either\\n\\n__getattr__ and __getattribute__ | 1249\\n\\n\\x0cmanually, with tools, or by definition in and inheritance from common superclasses.\\nThis does, however, make object wrappers more work than they used to be when op-\\nerator overloading methods are a part of a wrapped object’s interface.\\nKeep in mind that this issue applies only to __getattr__ and __getattribute__. Because\\nproperties  and  descriptors  are  defined  for  specific  attributes  only,  they  don’t  really\\napply to delegation-based classes at all—a single property or descriptor cannot be used\\nto intercept arbitrary attributes. Moreover, a class that defines both operator overload-\\ning methods and attribute interception will work correctly, regardless of the type of\\nattribute interception defined. Our concern here is only with classes that do not have\\noperator overloading methods defined, but try to intercept them generically.\\nConsider the following example, the file getattr-bultins.py, which tests various attribute\\ntypes and built-in operations on instances of classes containing __getattr__ and __get\\nattribute__ methods:\\n\\nclass GetAttr:\\n    eggs = 88                    # eggs stored on class, spam on instance\\n    def __init__(self):\\n       self.spam = 77\\n    def __len__(self):           # len here, else __getattr__ called with __len__\\n        print(\\'__len__: 42\\')\\n        return 42\\n    def __getattr__(self, attr):     # Provide __str__ if asked, else dummy func\\n        print(\\'getattr: \\' + attr)\\n        if attr == \\'__str__\\':\\n            return lambda *args: \\'[Getattr str]\\'\\n        else:\\n            return lambda *args: None\\n\\nclass GetAttribute(object):          # object required in 2.X, implied in 3.X\\n    eggs = 88                        # In 2.X all are isinstance(object) auto\\n    def __init__(self):              # But must derive to get new-style tools,\\n        self.spam = 77               # incl __getattribute__, some __X__ defaults\\n    def __len__(self):\\n        print(\\'__len__: 42\\')\\n        return 42\\n    def __getattribute__(self, attr):\\n        print(\\'getattribute: \\' + attr)\\n        if attr == \\'__str__\\':\\n            return lambda *args: \\'[GetAttribute str]\\'\\n        else:\\n            return lambda *args: None\\n\\nfor Class in GetAttr, GetAttribute:\\n    print(\\'\\\\n\\' + Class.__name__.ljust(50, \\'=\\'))\\n\\n    X = Class()\\n    X.eggs                   # Class attr\\n    X.spam                   # Instance attr\\n    X.other                  # Missing attr\\n    len(X)                   # __len__ defined explicitly\\n\\n1250 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0c# New-styles must support [], +, call directly: redefine\\n\\n    try:    X[0]             # __getitem__?\\n    except: print(\\'fail []\\')\\n\\n    try:    X + 99           # __add__?\\n    except: print(\\'fail +\\')\\n\\n    try:    X()              # __call__?  (implicit via built-in)\\n    except: print(\\'fail ()\\')\\n\\n    X.__call__()             # __call__?  (explicit, not inherited)\\n    print(X.__str__())       # __str__?   (explicit, inherited from type)\\n    print(X)                 # __str__?   (implicit via built-in)\\n\\nWhen run under Python 2.X as coded, __getattr__ does receive a variety of implicit\\nattribute fetches for built-in operations, because Python looks up such attributes in\\ninstances normally. Conversely, __getattribute__ is not run for any of the operator\\noverloading names invoked by built-in operations, because such names are looked up\\nin classes only in the new-style class model:\\n\\nc:\\\\code> py −2 getattr-builtins.py\\n\\nGetAttr===========================================\\ngetattr: other\\n__len__: 42\\ngetattr: __getitem__\\ngetattr: __coerce__\\ngetattr: __add__\\ngetattr: __call__\\ngetattr: __call__\\ngetattr: __str__\\n[Getattr str]\\ngetattr: __str__\\n[Getattr str]\\n\\nGetAttribute======================================\\ngetattribute: eggs\\ngetattribute: spam\\ngetattribute: other\\n__len__: 42\\nfail []\\nfail +\\nfail ()\\ngetattribute: __call__\\ngetattribute: __str__\\n[GetAttribute str]\\n<__main__.GetAttribute object at 0x02287898>\\n\\nNote how __getattr__ intercepts both implicit and explicit fetches of __call__ and\\n__str__ in 2.X here. By contrast, __getattribute__ fails to catch implicit fetches of either\\nattribute name for built-in operations.\\n\\n__getattr__ and __getattribute__ | 1251\\n\\n\\x0cReally, the __getattribute__ case is the same in 2.X as it is in 3.X, because in 2.X classes\\nmust  be  made  new-style  by  deriving  from  object  to  use  this  method.  This  code’s\\nobject derivation is optional in 3.X because all classes are new-style.\\nWhen run under Python 3.X, though, results for __getattr__ differ—none of the im-\\nplicitly run operator overloading methods trigger either attribute interception method\\nwhen their attributes are fetched by built-in operations. Python 3.X (and new-style\\nclasses in general) skips the normal instance lookup mechanism when resolving such\\nnames, though normally named methods are still intercepted as before:\\n\\n c:\\\\code> py −3 getattr-builtins.py\\n\\nGetAttr===========================================\\ngetattr: other\\n__len__: 42\\nfail []\\nfail +\\nfail ()\\ngetattr: __call__\\n<__main__.GetAttr object at 0x02987CC0>\\n<__main__.GetAttr object at 0x02987CC0>\\n\\nGetAttribute======================================\\ngetattribute: eggs\\ngetattribute: spam\\ngetattribute: other\\n__len__: 42\\nfail []\\nfail +\\nfail ()\\ngetattribute: __call__\\ngetattribute: __str__\\n[GetAttribute str]\\n<__main__.GetAttribute object at 0x02987CF8>\\n\\nTrace these outputs back to prints in the script to see how this works. Some highlights:\\n\\n• __str__ access fails to be caught twice by __getattr__ in 3.X: once for the built-in\\nprint, and once for explicit fetches because a default is inherited from the class\\n(really, from the built-in object, which is an automatic superclass to every class in\\n3.X).\\n\\n• __str__ fails to be caught only once by the __getattribute__ catchall, during the\\n\\nbuilt-in print operation; explicit fetches bypass the inherited version.\\n\\n• __call__ fails to be caught in both schemes in 3.X for built-in call expressions, but\\nit is intercepted by both when fetched explicitly; unlike __str__, there is no inher-\\nited __call__ default for object instances to defeat __getattr__.\\n\\n• __len__ is caught by both classes, simply because it is an explicitly defined method\\nin the classes themselves—though its name it is not routed to either __getattr__\\nor __getattribute__ in 3.X if we delete the class’s __len__ methods.\\n\\n• All other built-in operations fail to be intercepted by both schemes in 3.X.\\n\\n1252 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cAgain, the net effect is that operator overloading methods implicitly run by built-in\\noperations are never routed through either attribute interception method in 3.X: Python\\n3.X’s new-style classes search for such attributes in classes and skip instance lookup\\nentirely. Normally named attributes do not.\\nThis makes delegation-based wrapper classes more difficult to code in 3.X’s new-style\\nclasses—if wrapped classes may contain operator overloading methods, those methods\\nmust be redefined redundantly in the wrapper class in order to delegate to the wrapped\\nobject. In general delegation tools, this can add dozens of extra methods.\\nOf course, the addition of such methods can be partly automated by tools that augment\\nclasses with new methods (the class decorators and metaclasses of the next two chapters\\nmight help here). Moreover, a superclass might be able to define all these extra methods\\nonce, for inheritance in delegation-based classes. Still, delegation coding patterns re-\\nquire extra work in 3.X’s classes.\\nFor a more realistic illustration of this phenomenon as well as its workaround, see the\\nPrivate decorator example in the following chapter. There, we’ll explore alternatives\\nfor coding the operator methods required of proxies in 3.X’s classes—including reus-\\nable mix-in superclass models. We’ll also see there that it’s possible to insert a __getat\\ntribute__ in the client class to retain its original type, although this method still won’t\\nbe called for operator overloading methods; printing still runs a __str__ defined in such\\na class directly, for example, instead of routing the request through __getattribute__.\\nAs a more realistic example of this, the next section resurrects our class tutorial exam-\\nple. Now that you understand how attribute interception works, I’ll be able to explain\\none of its stranger bits.\\n\\nDelegation-based managers revisited\\nThe object-oriented tutorial of Chapter 28 presented a Manager class that used object\\nembedding and method delegation to customize its superclass, rather than inheritance.\\nHere is the code again for reference, with some irrelevant testing removed:\\n\\nclass Person:\\n    def __init__(self, name, job=None, pay=0):\\n        self.name = name\\n        self.job  = job\\n        self.pay  = pay\\n    def lastName(self):\\n        return self.name.split()[-1]\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n    def __repr__(self):\\n        return \\'[Person: %s, %s]\\' % (self.name, self.pay)\\n\\nclass Manager:\\n    def __init__(self, name, pay):\\n        self.person = Person(name, \\'mgr\\', pay)      # Embed a Person object\\n    def giveRaise(self, percent, bonus=.10):\\n\\n__getattr__ and __getattribute__ | 1253\\n\\n\\x0c        self.person.giveRaise(percent + bonus)      # Intercept and delegate\\n    def __getattr__(self, attr):\\n        return getattr(self.person, attr)           # Delegate all other attrs\\n    def __repr__(self):\\n        return str(self.person)                     # Must overload again (in 3.X)\\n\\nif __name__ == \\'__main__\\':\\n    sue = Person(\\'Sue Jones\\', job=\\'dev\\', pay=100000)\\n    print(sue.lastName())\\n    sue.giveRaise(.10)\\n    print(sue)\\n    tom = Manager(\\'Tom Jones\\', 50000)    # Manager.__init__\\n    print(tom.lastName())                # Manager.__getattr__ -> Person.lastName\\n    tom.giveRaise(.10)                   # Manager.giveRaise -> Person.giveRaise\\n    print(tom)                           # Manager.__repr__ -> Person.__repr__\\n\\nComments at the end of this file show which methods are invoked for a line’s operation.\\nIn particular, notice how lastName calls are undefined in Manager, and thus are routed\\ninto the generic __getattr__ and from there on to the embedded Person object. Here\\nis the script’s output—Sue receives a 10% raise from Person, but Tom gets 20% because\\ngiveRaise is customized in Manager:\\nc:\\\\code> py −3 getattr-delegate.py\\nJones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\n\\nBy contrast, though, notice what occurs when we print a Manager at the end of the script:\\nthe wrapper class’s __repr__ is invoked, and it delegates to the embedded Person ob-\\nject’s  __repr__.  With  that  in  mind,  watch  what  happens  if  we  delete  the  Man\\nager.__repr__ method in this code:\\n\\n# Delete the Manager __str__ method\\n\\nclass Manager:\\n    def __init__(self, name, pay):\\n        self.person = Person(name, \\'mgr\\', pay)      # Embed a Person object\\n    def giveRaise(self, percent, bonus=.10):\\n        self.person.giveRaise(percent + bonus)      # Intercept and delegate\\n    def __getattr__(self, attr):\\n        return getattr(self.person, attr)           # Delegate all other attrs\\n\\nNow printing does not route its attribute fetch through the generic __getattr__ inter-\\nceptor  under  Python  3.X’s  new-style  classes  for  Manager  objects.  Instead,  a  default\\n__repr__ display method inherited from the class’s implicit object superclass is looked\\nup and run (sue still prints correctly, because Person has an explicit __repr__):\\n\\nc:\\\\code> py −3 getattr-delegate.py\\nJones\\n[Person: Sue Jones, 110000]\\nJones\\n<__main__.Manager object at 0x029E7B70>\\n\\n1254 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cAs coded, running without a __repr__ like this does trigger __getattr__ in Python 2.X’s\\ndefault classic classes, because operator overloading attributes are routed through this\\nmethod, and such classes do not inherit a default for __repr__:\\n\\nc:\\\\code> py −2 getattr-delegate.py\\nJones\\n[Person: Sue Jones, 110000]\\nJones\\n[Person: Tom Jones, 60000]\\n\\nSwitching to __getattribute__ won’t help 3.X here either—like __getattr__, it is not\\nrun for operator overloading attributes implied by built-in operations in either Python\\n2.X or 3.X:\\n\\n# Replace __getattr_ with __getattribute__\\n\\nclass Manager(object):                                   # Use \"(object)\" in 2.X\\n    def __init__(self, name, pay):\\n        self.person = Person(name, \\'mgr\\', pay)           # Embed a Person object\\n    def giveRaise(self, percent, bonus=.10):\\n        self.person.giveRaise(percent + bonus)           # Intercept and delegate\\n    def __getattribute__(self, attr):\\n        print(\\'**\\', attr)\\n        if attr in [\\'person\\', \\'giveRaise\\']:\\n            return object.__getattribute__(self, attr)   # Fetch my attrs\\n        else:\\n            return getattr(self.person, attr)            # Delegate all others\\n\\nRegardless of which attribute interception method is used in 3.X, we still must include\\na redefined __repr__ in Manager (as shown previously) in order to intercept printing\\noperations and route them to the embedded Person object:\\n\\nC:\\\\code> py −3 getattr-delegate.py\\nJones\\n[Person: Sue Jones, 110000]\\n** lastName\\n** person\\nJones\\n** giveRaise\\n** person\\n<__main__.Manager object at 0x028E0590>\\n\\nNotice that __getattribute__ gets called twice here for methods—once for the method\\nname, and again for the self.person embedded object fetch. We could avoid that with\\na different coding, but we would still have to redefine __repr__ to catch printing, albeit\\ndifferently here (self.person would cause this __getattribute__ to fail):\\n\\n# Code __getattribute__ differently to minimize extra calls\\n\\nclass Manager:\\n    def __init__(self, name, pay):\\n        self.person = Person(name, \\'mgr\\', pay)\\n    def __getattribute__(self, attr):\\n        print(\\'**\\', attr)\\n        person = object.__getattribute__(self, \\'person\\')\\n\\n__getattr__ and __getattribute__ | 1255\\n\\n\\x0c        if attr == \\'giveRaise\\':\\n            return lambda percent: person.giveRaise(percent+.10)\\n        else:\\n            return getattr(person, attr)\\n    def __repr__(self):\\n        person = object.__getattribute__(self, \\'person\\')\\n        return str(person)\\n\\nWhen this alternative runs, our object prints properly, but only because we’ve added\\nan explicit __repr__ in the wrapper—this attribute is still not routed to our generic\\nattribute interception method:\\n\\nJones\\n[Person: Sue Jones, 110000]\\n** lastName\\nJones\\n** giveRaise\\n[Person: Tom Jones, 60000]\\n\\nThat short story here is that delegation-based classes like Manager must redefine some\\noperator overloading methods (like __repr__ and __str__) to route them to embedded\\nobjects in Python 3.X, but not in Python 2.X unless new-style classes are used. Our\\nonly direct options seem to be using __getattr__ and Python 2.X, or redefining operator\\noverloading methods in wrapper classes redundantly in 3.X.\\nAgain, this isn’t an impossible task; many wrappers can predict the set of operator\\noverloading methods required, and tools and superclasses can automate part of this\\ntask—in fact, we’ll study coding patterns that can fill this need in the next chapter.\\nMoreover, not all classes use operator overloading methods (indeed, most application\\nclasses usually should not). It is, however, something to keep in mind for delegation\\ncoding models used in Python 3.X; when operator overloading methods are part of an\\nobject’s interface, wrappers must accommodate them portably by redefining them lo-\\ncally.\\n\\nExample: Attribute Validations\\nTo close out this chapter, let’s turn to a more realistic example, coded in all four of our\\nattribute management schemes. The example we will use defines a CardHolder object\\nwith four attributes, three of which are managed. The managed attributes validate or\\ntransform values when fetched or stored. All four versions produce the same results for\\nthe same test code, but they implement their attributes in very different ways. The\\nexamples are included largely for self-study; although I won’t go through their code in\\ndetail, they all use concepts we’ve already explored in this chapter.\\n\\nUsing Properties to Validate\\nOur first coding in the file that follows uses properties to manage three attributes. As\\nusual, we could use simple methods instead of managed attributes, but properties help\\n\\n1256 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cif we have been using attributes in existing code already. Properties run code automat-\\nically on attribute access, but are focused on a specific set of attributes; they cannot be\\nused to intercept all attributes generically.\\nTo understand this code, it’s crucial to notice that the attribute assignments inside the\\n__init__ constructor method trigger property setter methods too. When this method\\nassigns to self.name, for example, it automatically invokes the setName method, which\\ntransforms the value and assigns it to an instance attribute called __name so it won’t\\nclash with the property’s name.\\nThis renaming (sometimes called name mangling) is necessary because properties use\\ncommon instance state and have none of their own. Data is stored in an attribute called\\n__name,  and  the  attribute  called  name  is  always  a  property,  not  data.  As  we  saw  in\\nChapter 31, names like __name are known as pseudoprivate attributes, and are changed\\nby Python to include the enclosing class’s name when stored in the instance’s name-\\nspace; here, this helps keep the implementation-specific attributes distinct from others,\\nincluding that of the property that manages them.\\nIn the end, this class manages attributes called name, age, and acct; allows the attribute\\naddr to be accessed directly; and provides a read-only attribute called remain that is\\nentirely virtual and computed on demand. For comparison purposes, this property-\\nbased coding weighs in at 39 lines of code, not counting its two initial lines, and includes\\nthe object derivation required in 2.X but optional in 3.X:\\n\\n# File validate_properties.py\\n\\nclass CardHolder(object):                      # Need \"(object)\" for setter in 2.X\\n    acctlen = 8                                # Class data\\n    retireage = 59.5\\n\\n    def __init__(self, acct, name, age, addr):\\n        self.acct = acct                       # Instance data\\n        self.name = name                       # These trigger prop setters too!\\n        self.age  = age                        # __X mangled to have class name\\n        self.addr = addr                       # addr is not managed\\n                                               # remain has no data\\n    def getName(self):\\n        return self.__name\\n    def setName(self, value):\\n        value = value.lower().replace(\\' \\', \\'_\\')\\n        self.__name = value\\n    name = property(getName, setName)\\n\\n    def getAge(self):\\n        return self.__age\\n    def setAge(self, value):\\n        if value < 0 or value > 150:\\n            raise ValueError(\\'invalid age\\')\\n        else:\\n            self.__age = value\\n    age = property(getAge, setAge)\\n\\nExample: Attribute Validations\\n\\n| 1257\\n\\n\\x0c    def getAcct(self):\\n        return self.__acct[:-3] + \\'***\\'\\n    def setAcct(self, value):\\n        value = value.replace(\\'-\\', \\'\\')\\n        if len(value) != self.acctlen:\\n            raise TypeError(\\'invald acct number\\')\\n        else:\\n            self.__acct = value\\n    acct = property(getAcct, setAcct)\\n\\n    def remainGet(self):                       # Could be a method, not attr\\n        return self.retireage - self.age       # Unless already using as attr\\n    remain = property(remainGet)\\n\\nTesting code\\nThe following code, validate_tester.py, tests our class; run this script with the name of\\nthe class’s module (sans “.py”) as a single command-line argument (you could also add\\nmost of its test code to the bottom of each file, or interactively import it from a module\\nafter importing the class). We’ll use this same testing code for all four versions of this\\nexample. When it runs, it makes two instances of our managed-attribute class and\\nfetches and changes their various attributes. Operations expected to fail are wrapped\\nin  try  statements,  and  identical  behavior  on  2.X  is  supported  by  enabling  the  3.X\\nprint function:\\n\\n# File validate_tester.py\\nfrom __future__ import print_function # 2.X\\n\\ndef loadclass():\\n    import sys, importlib\\n    modulename = sys.argv[1]                          # Module name in command line\\n    module = importlib.import_module(modulename)      # Import module by name string\\n    print(\\'[Using: %s]\\' % module.CardHolder)          # No need for getattr() here\\n    return module.CardHolder\\n\\ndef printholder(who):\\n    print(who.acct, who.name, who.age, who.remain, who.addr, sep=\\' / \\')\\n\\nif __name__ == \\'__main__\\':\\n    CardHolder = loadclass()\\n    bob = CardHolder(\\'1234-5678\\', \\'Bob Smith\\', 40, \\'123 main st\\')\\n    printholder(bob)\\n    bob.name = \\'Bob Q. Smith\\'\\n    bob.age  = 50\\n    bob.acct = \\'23-45-67-89\\'\\n    printholder(bob)\\n\\n    sue = CardHolder(\\'5678-12-34\\', \\'Sue Jones\\', 35, \\'124 main st\\')\\n    printholder(sue)\\n    try:\\n        sue.age = 200\\n    except:\\n        print(\\'Bad age for Sue\\')\\n\\n1258 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0c    try:\\n        sue.remain = 5\\n    except:\\n        print(\"Can\\'t set sue.remain\")\\n\\n    try:\\n        sue.acct = \\'1234567\\'\\n    except:\\n        print(\\'Bad acct for Sue\\')\\n\\nHere is the output of our self-test code on both Python 3.X and 2.X; again, this is the\\nsame for all versions of this example, except for the tested class’s name. Trace through\\nthis code to see how the class’s methods are invoked; accounts are displayed with some\\ndigits hidden, names are converted to a standard format, and time remaining until\\nretirement is computed when fetched using a class attribute cutoff:\\n\\nc:\\\\code> py −3 validate_tester.py validate_properties\\n[Using: <class \\'validate_properties.CardHolder\\'>]\\n12345*** / bob_smith / 40 / 19.5 / 123 main st\\n23456*** / bob_q._smith / 50 / 9.5 / 123 main st\\n56781*** / sue_jones / 35 / 24.5 / 124 main st\\nBad age for Sue\\nCan\\'t set sue.remain\\nBad acct for Sue\\n\\nUsing Descriptors to Validate\\nNow, let’s recode our example using descriptors instead of properties. As we’ve seen,\\ndescriptors are very similar to properties in terms of functionality and roles; in fact,\\nproperties are basically a restricted form of descriptor. Like properties, descriptors are\\ndesigned to handle specific attributes, not generic attribute access. Unlike properties,\\ndescriptors can also have their own state, and are a more general scheme.\\n\\nOption 1: Validating with shared descriptor instance state\\nTo  understand  the  following  code,  it’s  again  important  to  notice  that  the  attribute\\nassignments inside the __init__ constructor method trigger descriptor __set__ meth-\\nods. When the constructor method assigns to self.name, for example, it automatically\\ninvokes the Name.__set__() method, which transforms the value and assigns it to a\\ndescriptor attribute called name.\\nIn the end, this class implements the same attributes as the prior version: it manages\\nattributes called name, age, and acct; allows the attribute addr to be accessed directly;\\nand provides a read-only attribute called remain that is entirely virtual and computed\\non demand. Notice how we must catch assignments to the remain name in its descriptor\\nand raise an exception; as we learned earlier, if we did not do this, assigning to this\\nattribute of an instance would silently create an instance attribute that hides the class\\nattribute descriptor.\\n\\nExample: Attribute Validations\\n\\n| 1259\\n\\n\\x0cFor  comparison  purposes,  this  descriptor-based  coding  takes  45  lines  of  code;  I’ve\\nadded the required object derivation to the main descriptor classes for 2.X compati-\\nbility (they can be omitted for code to be run in 3.X only, but don’t hurt in 3.X, and\\naid portability if present):\\n\\n# File validate_descriptors1.py: using shared descriptor state\\n\\nclass CardHolder(object):                        # Need all \"(object)\" in 2.X only\\n    acctlen = 8                                  # Class data\\n    retireage = 59.5\\n\\n    def __init__(self, acct, name, age, addr):\\n        self.acct = acct                         # Instance data\\n        self.name = name                         # These trigger __set__ calls too!\\n        self.age  = age                          # __X not needed: in descriptor\\n        self.addr = addr                         # addr is not managed\\n                                                 # remain has no data\\n    class Name(object):\\n        def __get__(self, instance, owner):      # Class names: CardHolder locals\\n            return self.name\\n        def __set__(self, instance, value):\\n            value = value.lower().replace(\\' \\', \\'_\\')\\n            self.name = value\\n    name = Name()\\n\\n    class Age(object):\\n        def __get__(self, instance, owner):\\n            return self.age                             # Use descriptor data\\n        def __set__(self, instance, value):\\n            if value < 0 or value > 150:\\n                raise ValueError(\\'invalid age\\')\\n            else:\\n                self.age = value\\n    age = Age()\\n\\n    class Acct(object):\\n        def __get__(self, instance, owner):\\n            return self.acct[:-3] + \\'***\\'\\n        def __set__(self, instance, value):\\n            value = value.replace(\\'-\\', \\'\\')\\n            if len(value) != instance.acctlen:          # Use instance class data\\n                raise TypeError(\\'invald acct number\\')\\n            else:\\n                self.acct = value\\n    acct = Acct()\\n\\n    class Remain(object):\\n        def __get__(self, instance, owner):\\n            return instance.retireage - instance.age    # Triggers Age.__get__\\n        def __set__(self, instance, value):\\n            raise TypeError(\\'cannot set remain\\')        # Else set allowed here\\n    remain = Remain()\\n\\n1260 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cWhen run with the prior testing script, all examples in this section produce the same\\noutput as shown for properties earlier, except that the name of the class in the first line\\nvaries:\\n\\nC:\\\\code> python validate_tester.py validate_descriptors1\\n...same output as properties, except class name...\\n\\nOption 2: Validating with per-client-instance state\\nUnlike in the prior property-based variant, though, in this case the actual name value is\\nattached to the descriptor object, not the client class instance. Although we could store\\nthis value in either instance or descriptor state, the latter avoids the need to mangle\\nnames with underscores to avoid collisions. In the CardHolder client class, the attribute\\ncalled name is always a descriptor object, not data.\\nImportantly, the downside of this scheme is that state stored inside a descriptor itself\\nis class-level data that is effectively shared by all client class instances, and so cannot\\nvary  between  them.  That  is,  storing  state  in  the  descriptor  instance  instead  of  the\\nowner (client) class instance means that the state will be the same in all owner class\\ninstances. Descriptor state can vary only per attribute appearance.\\nTo see this at work, in the preceding descriptor-based CardHolder example, try printing\\nattributes  of  the  bob  instance  after  creating  the  second  instance,  sue.  The  values  of\\nsue’s  managed  attributes  (name,  age,  and  acct)  overwrite  those  of  the  earlier  object\\nbob, because both share the same, single descriptor instance attached to their class:\\n\\n# File validate_tester2.py\\nfrom __future__ import print_function # 2.X\\n\\nfrom validate_tester import loadclass\\nCardHolder = loadclass()\\n\\nbob = CardHolder(\\'1234-5678\\',  \\'Bob Smith\\', 40, \\'123 main st\\')\\nprint(\\'bob:\\', bob.name, bob.acct, bob.age, bob.addr)\\n\\nsue = CardHolder(\\'5678-12-34\\', \\'Sue Jones\\', 35, \\'124 main st\\')\\nprint(\\'sue:\\', sue.name, sue.acct, sue.age, sue.addr)    # addr differs: client data\\nprint(\\'bob:\\', bob.name, bob.acct, bob.age, bob.addr)    # name,acct,age overwritten?\\n\\nThe results confirm the suspicion—in terms of managed attributes, bob has morphed\\ninto sue!\\n\\nc:\\\\code> py −3 validate_tester2.py validate_descriptors1\\n[Using: <class \\'validate_descriptors1.CardHolder\\'>]\\nbob: bob_smith 12345*** 40 123 main st\\nsue: sue_jones 56781*** 35 124 main st\\nbob: sue_jones 56781*** 35 123 main st\\n\\nThere are valid uses for descriptor state, of course—to manage descriptor implemen-\\ntation and data that spans all instance—and this code was implemented to illustrate\\nthe technique. Moreover, the state scope implications of class versus instance attributes\\nshould be more or less a given at this point in the book.\\n\\nExample: Attribute Validations\\n\\n| 1261\\n\\n\\x0cHowever, in this particular use case, attributes of CardHolder objects are probably better\\nstored as per-instance data instead of descriptor instance data, perhaps using the same\\n__X naming convention as the property-based equivalent to avoid name clashes in the\\ninstance—a more important factor this time, as the client is a different class with its\\nown state attributes. Here are the required coding changes; it doesn’t change line counts\\n(we’re still at 45):\\n\\n# File validate_descriptors2.py: using per-client-instance state\\n\\nclass CardHolder(object):                        # Need all \"(object)\" in 2.X only\\n    acctlen = 8                                  # Class data\\n    retireage = 59.5\\n\\n    def __init__(self, acct, name, age, addr):\\n        self.acct = acct                         # Client instance data\\n        self.name = name                         # These trigger __set__ calls too!\\n        self.age  = age                          # __X needed: in client instance\\n        self.addr = addr                         # addr is not managed\\n                                                 # remain managed but has no data\\n    class Name(object):\\n        def __get__(self, instance, owner):      # Class names: CardHolder locals\\n            return instance.__name\\n        def __set__(self, instance, value):\\n            value = value.lower().replace(\\' \\', \\'_\\')\\n            instance.__name = value\\n    name = Name()                                       # class.name vs mangled attr\\n\\n    class Age(object):\\n        def __get__(self, instance, owner):\\n            return instance.__age                       # Use descriptor data\\n        def __set__(self, instance, value):\\n            if value < 0 or value > 150:\\n                raise ValueError(\\'invalid age\\')\\n            else:\\n                instance.__age = value\\n    age = Age()                                         # class.age vs mangled attr\\n\\n    class Acct(object):\\n        def __get__(self, instance, owner):\\n            return instance.__acct[:-3] + \\'***\\'\\n        def __set__(self, instance, value):\\n            value = value.replace(\\'-\\', \\'\\')\\n            if len(value) != instance.acctlen:          # Use instance class data\\n                raise TypeError(\\'invald acct number\\')\\n            else:\\n                instance.__acct = value\\n    acct = Acct()                                       # class.acct vs mangled name\\n\\n    class Remain(object):\\n        def __get__(self, instance, owner):\\n            return instance.retireage - instance.age    # Triggers Age.__get__\\n        def __set__(self, instance, value):\\n            raise TypeError(\\'cannot set remain\\')        # Else set allowed here\\n    remain = Remain()\\n\\n1262 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cThis supports per-instance data for the name, age, and acct managed fields as expected\\n(bob remains bob), and other tests work as before:\\n\\nc:\\\\code> py −3 validate_tester2.py validate_descriptors2\\n[Using: <class \\'validate_descriptors2.CardHolder\\'>]\\nbob: bob_smith 12345*** 40 123 main st\\nsue: sue_jones 56781*** 35 124 main st\\nbob: bob_smith 12345*** 40 123 main st\\n\\nc:\\\\code> py −3 validate_tester.py validate_descriptors2\\n...same output as properties, except class name...\\n\\nOne small caveat here: as coded, this version doesn’t support through-class descriptor\\naccess, because such access passes a None to the instance argument (also notice the\\nattribute __X name mangling to _Name__name in the error message when the fetch attempt\\nis made):\\n\\n>>> from validate_descriptors1 import CardHolder\\n>>> bob = CardHolder(\\'1234-5678\\', \\'Bob Smith\\', 40, \\'123 main st\\')\\n>>> bob.name\\n\\'bob_smith\\'\\n>>> CardHolder.name\\n\\'bob_smith\\'\\n\\n>>> from validate_descriptors2 import CardHolder\\n>>> bob = CardHolder(\\'1234-5678\\', \\'Bob Smith\\', 40, \\'123 main st\\')\\n>>> bob.name\\n\\'bob_smith\\'\\n>>> CardHolder.name\\nAttributeError: \\'NoneType\\' object has no attribute \\'_Name__name\\'\\n\\nWe could detect this with a minor amount of additional code to trigger the error more\\nexplicitly, but there’s probably no point—because this version stores data in the client\\ninstance, there’s no meaning to its descriptors unless they’re accompanied by a client\\ninstance (much like a normal unbound instance method). In fact, that’s really the entire\\npoint of this version’s change!\\nBecause they are classes, descriptors are a useful and powerful tool, but they present\\nchoices that can deeply impact a program’s behavior. As always in OOP, choose your\\nstate retention policies carefully.\\n\\nUsing __getattr__ to Validate\\nAs we’ve seen, the __getattr__ method intercepts all undefined attributes, so it can be\\nmore generic than using properties or descriptors. For our example, we simply test the\\nattribute name to know when a managed attribute is being fetched; others are stored\\nphysically on the instance and so never reach __getattr__. Although this approach is\\nmore general than using properties or descriptors, extra work may be required to imitate\\nthe specific-attribute focus of other tools. We need to check names at runtime, and we\\nmust code a __setattr__ in order to intercept and validate attribute assignments.\\n\\nExample: Attribute Validations\\n\\n| 1263\\n\\n\\x0cAs for the property and descriptor versions of this example, it’s critical to notice that\\nthe attribute assignments inside the __init__ constructor method trigger the class’s\\n__setattr__ method too. When this method assigns to self.name, for example, it au-\\ntomatically invokes the __setattr__ method, which transforms the value and assigns\\nit to an instance attribute called name. By storing name on the instance, it ensures that\\nfuture accesses will not trigger __getattr__. In contrast, acct is stored as _acct, so that\\nlater accesses to acct do invoke __getattr__.\\nIn  the  end,  this  class,  like  the  prior  two,  manages  attributes  called  name,  age,  and\\nacct; allows the attribute addr to be accessed directly; and provides a read-only attribute\\ncalled remain that is entirely virtual and is computed on demand.\\nFor comparison purposes, this alternative comes in at 32 lines of code—7 fewer than\\nthe property-based version, and 13 fewer than the version using descriptors. Clarity\\nmatters  more  than  code  size,  of  course,  but  extra  code  can  sometimes  imply  extra\\ndevelopment and maintenance work. Probably more important here are roles: generic\\ntools like __getattr__ may be better suited to generic delegation, while properties and\\ndescriptors are more directly designed to manage specific attributes.\\nAlso note that the code here incurs extra calls when setting unmanaged attributes (e.g.,\\naddr), although no extra calls are incurred for fetching unmanaged attributes, since they\\nare defined. Though this will likely result in negligible overhead for most programs, the\\nmore narrowly focused properties and descriptors incur an extra call only when man-\\naged attributes are accessed, and also appear in dir results when needed by generic\\ntools.\\nHere’s the __getattr__ version of our validations code:\\n\\n# File validate_getattr.py\\n\\nclass CardHolder:\\n    acctlen = 8                                  # Class data\\n    retireage = 59.5\\n\\n    def __init__(self, acct, name, age, addr):\\n        self.acct = acct                         # Instance data\\n        self.name = name                         # These trigger __setattr__ too\\n        self.age  = age                          # _acct not mangled: name tested\\n        self.addr = addr                         # addr is not managed\\n                                                 # remain has no data\\n    def __getattr__(self, name):\\n        if name == \\'acct\\':                           # On undefined attr fetches\\n            return self._acct[:-3] + \\'***\\'           # name, age, addr are defined\\n        elif name == \\'remain\\':\\n            return self.retireage - self.age         # Doesn\\'t trigger __getattr__\\n        else:\\n            raise AttributeError(name)\\n\\n    def __setattr__(self, name, value):\\n        if name == \\'name\\':                           # On all attr assignments\\n            value = value.lower().replace(\\' \\', \\'_\\')  # addr stored directly\\n\\n1264 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0c        elif name == \\'age\\':                          # acct mangled to _acct\\n            if value < 0 or value > 150:\\n                raise ValueError(\\'invalid age\\')\\n        elif name == \\'acct\\':\\n            name  = \\'_acct\\'\\n            value = value.replace(\\'-\\', \\'\\')\\n            if len(value) != self.acctlen:\\n                raise TypeError(\\'invald acct number\\')\\n        elif name == \\'remain\\':\\n            raise TypeError(\\'cannot set remain\\')\\n        self.__dict__[name] = value                  # Avoid looping (or via object)\\n\\nWhen this code is run with either test script, it produces the same output (with a dif-\\nferent class name):\\n\\nc:\\\\code> py −3 validate_tester.py validate_getattr\\n...same output as properties, except class name...\\n\\nc:\\\\code> py −3 validate_tester2.py validate_getattr\\n...same output as instance-state descriptors, except class name...\\n\\nUsing __getattribute__ to Validate\\nOur final variant uses the __getattribute__ catchall to intercept attribute fetches and\\nmanage them as needed. Every attribute fetch is caught here, so we test the attribute\\nnames to detect managed attributes and route all others to the superclass for normal\\nfetch processing. This version uses the same __setattr__ to catch assignments as the\\nprior version.\\nThe  code  works  very  much  like  the  __getattr__  version,  so  I  won’t  repeat  the  full\\ndescription here. Note, though, that because every attribute fetch is routed to __getat\\ntribute__, we don’t need to mangle names to intercept them here (acct is stored as\\nacct). On the other hand, this code must take care to route nonmanaged attribute\\nfetches to a superclass to avoid looping or extra calls.\\nAlso notice that this version incurs extra calls for both setting and fetching unmanaged\\nattributes (e.g., addr); if speed is paramount, this alternative may be the slowest of the\\nbunch. For comparison purposes, this version amounts to 32 lines of code, just like the\\nprior version, and includes the requisite object derivation for 2.X compatibility; like\\nproperties and descriptors, __getattribute__ is a new-style class tool:\\n\\n# File validate_getattribute.py\\n\\nclass CardHolder(object):                        # Need \"(object)\" in 2.X only\\n    acctlen = 8                                  # Class data\\n    retireage = 59.5\\n\\n    def __init__(self, acct, name, age, addr):\\n        self.acct = acct                         # Instance data\\n        self.name = name                         # These trigger __setattr__ too\\n        self.age  = age                          # acct not mangled: name tested\\n        self.addr = addr                         # addr is not managed\\n\\nExample: Attribute Validations\\n\\n| 1265\\n\\n\\x0c                                                 # remain has no data\\n    def __getattribute__(self, name):\\n        superget = object.__getattribute__             # Don\\'t loop: one level up\\n        if name == \\'acct\\':                             # On all attr fetches\\n            return superget(self, \\'acct\\')[:-3] + \\'***\\'\\n        elif name == \\'remain\\':\\n            return superget(self, \\'retireage\\') - superget(self, \\'age\\')\\n        else:\\n            return superget(self, name)                # name, age, addr: stored\\n\\n    def __setattr__(self, name, value):\\n        if name == \\'name\\':                             # On all attr assignments\\n            value = value.lower().replace(\\' \\', \\'_\\')    # addr stored directly\\n        elif name == \\'age\\':\\n            if value < 0 or value > 150:\\n                raise ValueError(\\'invalid age\\')\\n        elif name == \\'acct\\':\\n            value = value.replace(\\'-\\', \\'\\')\\n            if len(value) != self.acctlen:\\n                raise TypeError(\\'invald acct number\\')\\n        elif name == \\'remain\\':\\n            raise TypeError(\\'cannot set remain\\')\\n        self.__dict__[name] = value                     # Avoid loops, orig names\\n\\nBoth the getattr and getattribute scripts work the same as the property and per-client-\\ninstance descriptor versions, when run by both tester scripts on either 2.X or 3.X.—\\nfour ways to achieve the same goal in Python, though they vary in structure, and are\\nperhaps less redundant in some other roles. Be sure to study and run this section’s code\\non your own for more pointers on managed attribute coding techniques.\\n\\nChapter Summary\\nThis  chapter  covered  the  various  techniques  for  managing  access  to  attributes  in\\nPython, including the __getattr__ and __getattribute__ operator overloading meth-\\nods, class properties, and class attribute descriptors. Along the way, it compared and\\ncontrasted these tools and presented a handful of use cases to demonstrate their be-\\nhavior.\\nChapter 39 continues our tool-building survey with a look at decorators—code run\\nautomatically at function and class creation time, rather than on attribute access. Before\\nwe continue, though, let’s work through a set of questions to review what we’ve covered\\nhere.\\n\\nTest Your Knowledge: Quiz\\n1. How do __getattr__ and __getattribute__ differ?\\n2. How do properties and descriptors differ?\\n3. How are properties and decorators related?\\n\\n1266 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0c4. What  are  the  main  functional  differences  between  __getattr__  and  __getattri\\n\\nbute__ and properties and descriptors?\\n\\n5. Isn’t all this feature comparison just a kind of argument?\\n\\nTest Your Knowledge: Answers\\n1. The __getattr__ method is run for fetches of undefined attributes only (i.e., those\\nnot present on an instance and not inherited from any of its classes). By contrast,\\nthe __getattribute__ method is called for every attribute fetch, whether the at-\\ntribute is defined or not. Because of this, code inside a __getattr__ can freely fetch\\nother attributes if they are defined, whereas __getattribute__ must use special code\\nfor all such attribute fetches to avoid looping or extra calls (it must route fetches\\nto a superclass to skip itself).\\n\\n2. Properties serve a specific role, while descriptors are more general. Properties define\\nget, set, and delete functions for a specific attribute; descriptors provide a class\\nwith methods for these actions, too, but they provide extra flexibility to support\\nmore arbitrary actions. In fact, properties are really a simple way to create a specific\\nkind of descriptor—one that runs functions on attribute accesses. Coding differs\\ntoo: a property is created with a built-in function, and a descriptor is coded with\\na class; thus, descriptors can leverage all the usual OOP features of classes, such\\nas inheritance. Moreover, in addition to the instance’s state information, descrip-\\ntors have local state of their own, so they can sometimes avoid name collisions in\\nthe instance.\\n\\n3. Properties can be coded with decorator syntax. Because the property built-in ac-\\ncepts a single function argument, it can be used directly as a function decorator to\\ndefine a fetch access property. Due to the name rebinding behavior of decorators,\\nthe name of the decorated function is assigned to a property whose get accessor is\\nset to the original function decorated (name = property(name)). Property setter\\nand deleter attributes allow us to further add set and delete accessors with deco-\\nration syntax—they set the accessor to the decorated function and return the aug-\\nmented property.\\n\\n4. The __getattr__ and __getattribute__ methods are more generic: they can be used\\nto catch arbitrarily many attributes. In contrast, each property or descriptor pro-\\nvides access interception for only one specific attribute—we can’t catch every at-\\ntribute fetch with a single property or descriptor. On the other hand, properties\\nand  descriptors  handle  both  attribute  fetch  and  assignment  by  design:  __get\\nattr__ and __getattribute__ handle fetches only; to intercept assignments as well,\\n__setattr__  must  also  be  coded.  The  implementation  is  also  different:  __get\\nattr__ and __getattribute__ are operator overloading methods, whereas proper-\\nties and descriptors are objects manually assigned to class attributes. Unlike the\\nothers, properties and descriptors can also sometimes avoid extra calls on assign-\\nment to unmanaged names, and show up in dir results automatically, but are also\\n\\nTest Your Knowledge: Quiz | 1267\\n\\n\\x0cnarrower in scope—they can’t address generic dispatch goals. In Python evolution,\\nnew features tend to offer alternatives, but do not fully subsume what came before.\\n\\n5. No it isn’t. To quote from Python namesake Monty Python’s Flying Circus:\\n\\nAn argument is a connected series of statements intended to establish a\\nproposition.\\nNo it isn\\'t.\\nYes it is! It\\'s not just contradiction.\\nLook, if I argue with you, I must take up a contrary position.\\nYes, but that\\'s not just saying \"No it isn\\'t.\"\\nYes it is!\\nNo it isn\\'t!\\nYes it is!\\nNo it isn\\'t. Argument is an intellectual process. Contradiction is just\\nthe automatic gainsaying of any statement the other person makes.\\n(short pause) No it isn\\'t.\\nIt is.\\nNot at all.\\nNow look...\\n\\n1268 | Chapter 38:\\u2002Managed Attributes\\n\\n\\x0cCHAPTER 39\\nDecorators\\n\\nIn the advanced class topics chapter of this book (Chapter 32), we met static and class\\nmethods, took a quick look at the @ decorator syntax Python offers for declaring them,\\nand previewed decorator coding techniques. We also met function decorators briefly\\nin Chapter 38, while exploring the property built-in’s ability to serve as one, and in\\nChapter 29 while studying the notion of abstract superclasses.\\nThis chapter picks up where this previous decorator coverage left off. Here, we’ll dig\\ndeeper into the inner workings of decorators and study more advanced ways to code\\nnew decorators ourselves. As we’ll see, many of the concepts we studied earlier—es-\\npecially state retention—show up regularly in decorators.\\nThis is a somewhat advanced topic, and decorator construction tends to be of more\\ninterest to tool builders than to application programmers. Still, given that decorators\\nare  becoming  increasingly  common  in  popular  Python  frameworks,  a  basic  under-\\nstanding can help demystify their role, even if you’re just a decorator user.\\nBesides covering decorator construction details, this chapter serves as a more realistic\\ncase study of Python in action. Because its examples grow somewhat larger than most\\nof the others we’ve seen in this book, they better illustrate how code comes together\\ninto more complete systems and tools. As an extra perk, some of the code we’ll write\\nhere may be used as general-purpose tools in your day-to-day programs.\\n\\nWhat’s a Decorator?\\nDecoration is a way to specify management or augmentation code for functions and\\nclasses. Decorators themselves take the form of callable objects (e.g., functions) that\\nprocess other callable objects. As we saw earlier in this book, Python decorators come\\nin two related flavors, neither of which requires 3.X or new-style classes:\\n\\n• Function decorators, added in Python 2.4, do name rebinding at function definition\\ntime, providing a layer of logic that can manage functions and methods, or later\\ncalls to them.\\n\\n1269\\n\\n\\x0c• Class decorators, added in Python 2.6 and 3.0, do name rebinding at class definition\\ntime, providing a layer of logic that can manage classes, or the instances created\\nby later calls to them.\\n\\nIn short, decorators provide a way to insert automatically run code at the end of function\\nand class definition statements—at the end of a def for function decorators, and at the\\nend of a class for class decorators. Such code can play a variety of roles, as described\\nin the following sections.\\n\\nManaging Calls and Instances\\nIn typical use, this automatically run code may be used to augment calls to functions\\nand classes. It arranges this by installing wrapper (a.k.a. proxy) objects to be invoked\\nlater:\\n\\nCall proxies\\n\\nFunction decorators install wrapper objects to intercept later function calls and\\nprocess them as needed, usually passing the call on to the original function to run\\nthe managed action.\\n\\nInterface proxies\\n\\nClass decorators install wrapper objects to intercept later instance creation calls\\nand process them as required, usually passing the call on to the original class to\\ncreate a managed instance.\\n\\nDecorators achieve these effects by automatically rebinding function and class names\\nto other callables, at the end of def and class statements. When later invoked, these\\ncallables can perform tasks such as tracing and timing function calls, managing access\\nto class instance attributes, and so on.\\n\\nManaging Functions and Classes\\nAlthough most examples in this chapter deal with using wrappers to intercept later\\ncalls to functions and classes, this is not the only way decorators can be used:\\n\\nFunction managers\\n\\nFunction decorators can also be used to manage function objects, instead of or in\\naddition to later calls to them—to register a function to an API, for instance. Our\\nprimary focus here, though, will be on their more commonly used call wrapper\\napplication.\\nClass managers\\n\\nClass decorators can also be used to manage class objects directly, instead of or in\\naddition  to  instance  creation  calls—to  augment  a  class  with  new  methods,  for\\nexample. Because this role intersects strongly with that of metaclasses, we’ll see\\nadditional use cases in the next chapter. As we’ll find, both tools run at the end of\\nthe class creation process, but class decorators often offer a lighter-weight solution.\\n\\n1270 | Chapter 39:\\u2002Decorators\\n\\n\\x0cIn other words, function decorators can be used to manage both function calls and\\nfunction objects, and class decorators can be used to manage both class instances and\\nclasses themselves. By returning the decorated object itself instead of a wrapper, dec-\\norators become a simple post-creation step for functions and classes.\\nRegardless of the role they play, decorators provide a convenient and explicit way to\\ncode tools useful both during program development and in live production systems.\\n\\nUsing and Defining Decorators\\nDepending on your job description, you might encounter decorators as a user or a\\nprovider (you might also be a maintainer, but that just means you straddle the fence).\\nAs we’ve seen, Python itself comes with built-in decorators that have specialized roles\\n—static and class method declaration, property creation, and more. In addition, many\\npopular Python toolkits include decorators to perform tasks such as managing database\\nor user-interface logic. In such cases, we can get by without knowing how the decorators\\nare coded.\\nFor more general tasks, programmers can code arbitrary decorators of their own. For\\nexample, function decorators may be used to augment functions with code that adds\\ncall tracing or logging, performs argument validity testing during debugging, automat-\\nically acquires and releases thread locks, times calls made to functions for optimization,\\nand  so  on.  Any  behavior  you  can  imagine  adding  to—really,  wrapping  around—a\\nfunction call is a candidate for custom function decorators.\\nOn the other hand, function decorators are designed to augment only a specific function\\nor method call, not an entire object interface. Class decorators fill the latter role better\\n—because they can intercept instance creation calls, they can be used to implement\\narbitrary object interface augmentation or management tasks. For example, custom\\nclass  decorators  can  trace,  validate,  or  otherwise  augment  every  attribute  reference\\nmade for an object. They can also be used to implement proxy objects, singleton classes,\\nand other common coding patterns. In fact, we’ll find that many class decorators bear\\na strong resemblance to—and in fact are a prime application of—the delegation coding\\npattern we met in Chapter 31.\\n\\nWhy Decorators?\\nLike many advanced Python tools, decorators are never strictly required from a purely\\ntechnical perspective: we can often implement their functionality instead using simple\\nhelper function calls or other techniques. And at a base level, we can always manually\\ncode the name rebinding that decorators perform automatically.\\nThat said, decorators provide an explicit syntax for such tasks, which makes intent\\nclearer, can minimize augmentation code redundancy, and may help ensure correct\\nAPI usage:\\n\\nWhat’s a Decorator?\\n\\n| 1271\\n\\n\\x0c• Decorators have a very explicit syntax, which makes them easier to spot than helper\\nfunction calls that may be arbitrarily far-removed from the subject functions or\\nclasses.\\n\\n• Decorators are applied once, when the subject function or class is defined; it’s not\\nnecessary to add extra code at every call to the class or function, which may have\\nto be changed in the future.\\n\\n• Because of both of the prior points, decorators make it less likely that a user of an\\n\\nAPI will forget to augment a function or class according to API requirements.\\n\\nIn other words, beyond their technical model, decorators offer some advantages in\\nterms of both code maintenance and consistency. Moreover, as structuring tools, dec-\\norators naturally foster encapsulation of code, which reduces redundancy and makes\\nfuture changes easier.\\nDecorators do have some potential drawbacks, too—when they insert wrapper logic,\\nthey can alter the types of the decorated objects, and they may incur extra calls when\\nused as call or interface proxies. On the other hand, the same considerations apply to\\nany technique that adds wrapping logic to objects.\\nWe’ll explore these tradeoffs in the context of real code later in this chapter. Although\\nthe choice to use decorators is still somewhat subjective, their advantages are compel-\\nling enough that they are quickly becoming best practice in the Python world. To help\\nyou decide for yourself, let’s turn to the details.\\n\\nDecorators versus macros: Python’s decorators bear similarities to what\\nsome call aspect-oriented programming in other languages—code inser-\\nted to run automatically before or after a function call runs. Their syntax\\nalso very closely resembles (and is likely borrowed from) Java’s anno-\\ntations, though Python’s model is usually considered more flexible and\\ngeneral.\\n\\nSome  liken  decorators  to  macros  too,  but  this  isn’t  entirely  apt,  and\\nmight even be misleading. Macros (e.g., C’s #define preprocessor di-\\nrective) are typically associated with textual replacement and expan-\\nsion, and designed for generating code. By contrast, Python’s decorators\\nare a runtime operation, based upon name rebinding, callable objects,\\nand often, proxies. While the two may have use cases that sometimes\\noverlap, decorators and macros are fundamentally different in scope,\\nimplementation, and coding patterns. Comparing the two seems akin\\nto comparing Python’s import with a C #include, which similarly con-\\nfuses a runtime object-based operation with text insertion.\\n\\nOf course, the term macro has been a bit diluted over time—to some,\\nit now can also refer to any canned series of steps or procedure—and\\nusers of other languages might find the analogy to descriptors useful\\nanyhow. But they should probably also keep in mind that decorators\\nare about callable objects managing callable objects, not text expansion.\\nPython tends to be best understood and used in terms of Python idioms.\\n\\n1272 | Chapter 39:\\u2002Decorators\\n\\n\\x0cThe Basics\\nLet’s get started with a first-pass look at decoration behavior from a symbolic perspec-\\ntive. We’ll write real and more substantial code soon, but since most of the magic of\\ndecorators boils down to an automatic rebinding operation, it’s important to under-\\nstand this mapping first.\\n\\nFunction Decorators\\nFunction decorators have been available in Python since version 2.4. As we saw earlier\\nin this book, they are largely just syntactic sugar that runs one function through another\\nat the end of a def statement, and rebinds the original function name to the result.\\n\\nUsage\\nA function decorator is a kind of runtime declaration about the function whose defini-\\ntion follows. The decorator is coded on a line just before the def statement that defines\\na  function  or  method,  and  it  consists  of  the  @  symbol  followed  by  a  reference  to  a\\nmetafunction—a function (or other callable object) that manages another function.\\nIn terms of code, function decorators automatically map the following syntax:\\n\\n@decorator              # Decorate function\\ndef F(arg):\\n    ...\\n\\nF(99)                   # Call function\\n\\ninto this equivalent form, where decorator is a one-argument callable object that re-\\nturns a callable object with the same number of arguments as F (in not F itself):\\n\\ndef F(arg):\\n    ...\\nF = decorator(F)        # Rebind function name to decorator result\\n\\nF(99)                   # Essentially calls decorator(F)(99)\\n\\nThis automatic name rebinding works on any def statement, whether it’s for a simple\\nfunction or a method within a class. When the function F is later called, it’s actually\\ncalling the object returned by the decorator, which may be either another object that\\nimplements required wrapping logic, or the original function itself.\\nIn other words, decoration essentially maps the first of the following into the second\\n—though the decorator is really run only once, at decoration time:\\n\\nfunc(6, 7)\\ndecorator(func)(6, 7)\\n\\nThis automatic name rebinding accounts for the static method and property decoration\\nsyntax we met earlier in the book:\\n\\nThe Basics\\n\\n| 1273\\n\\n\\x0cclass C:\\n    @staticmethod\\n    def meth(...): ...            # meth = staticmethod(meth)\\n\\nclass C:\\n    @property\\n    def name(self): ...           # name = property(name)\\n\\nIn both cases, the method name is rebound to the result of a built-in function decorator,\\nat the end of the def statement. Calling the original name later invokes whatever object\\nthe decorator returns. In these specific cases, the original names are rebound to a static\\nmethod router and property descriptor, but the process is much more general than this\\n—as the next section explains.\\n\\nImplementation\\nA decorator itself is a callable that returns a callable. That is, it returns the object to be\\ncalled later when the decorated function is invoked through its original name—either\\na wrapper object to intercept later calls, or the original function augmented in some\\nway. In fact, decorators can be any type of callable and return any type of callable: any\\ncombination of functions and classes may be used, though some are better suited to\\ncertain contexts.\\nFor example, to tap into the decoration protocol in order to manage a function just\\nafter it is created, we might code a decorator of this form:\\n\\ndef decorator(F):\\n    # Process function F\\n    return F\\n\\n@decorator\\ndef func(): ...                  # func = decorator(func)\\n\\nBecause the original decorated function is assigned back to its name, this simply adds\\na post-creation step to function definition. Such a structure might be used to register a\\nfunction to an API, assign function attributes, and so on.\\nIn more typical use, to insert logic that intercepts later calls to a function, we might\\ncode a decorator to return a different object than the original function—a proxy for\\nlater calls:\\n\\ndef decorator(F):\\n    # Save or use function F\\n    # Return a different callable: nested def, class with __call__, etc.\\n\\n@decorator\\ndef func(): ...                  # func = decorator(func)\\n\\nThis decorator is invoked at decoration time, and the callable it returns is invoked when\\nthe original function name is later called. The decorator itself receives the decorated\\nfunction;  the  callable  returned  receives  whatever  arguments  are  later  passed  to  the\\ndecorated function’s name. When coded properly, this works the same for class-level\\n\\n1274 | Chapter 39:\\u2002Decorators\\n\\n\\x0cmethods: the implied instance object simply shows up in the first argument of the re-\\nturned callable.\\nIn skeleton terms, here’s one common coding pattern that captures this idea—the dec-\\norator returns a wrapper that retains the original function in an enclosing scope:\\n\\ndef decorator(F):                     # On @ decoration\\n    def wrapper(*args):               # On wrapped function call\\n        # Use F and args\\n        # F(*args) calls original function\\n    return wrapper\\n\\n@decorator                            # func = decorator(func)\\ndef func(x, y):                       # func is passed to decorator\\'s F\\n    ...\\n\\nfunc(6, 7)                            # 6, 7 are passed to wrapper\\'s *args\\n\\nWhen the name func is later called, it really invokes the wrapper function returned by\\ndecorator; the wrapper function can then run the original func because it is still available\\nin an enclosing scope. When coded this way, each decorated function produces a new\\nscope to retain state.\\nTo do the same with classes, we can overload the call operation and use instance at-\\ntributes instead of enclosing scopes:\\n\\nclass decorator:\\n    def __init__(self, func):         # On @ decoration\\n        self.func = func\\n    def __call__(self, *args):        # On wrapped function call\\n        # Use self.func and args\\n        # self.func(*args) calls original function\\n\\n@decorator\\ndef func(x, y):                       # func = decorator(func)\\n    ...                               # func is passed to __init__\\n\\nfunc(6, 7)                            # 6, 7 are passed to __call__\\'s *args\\n\\nWhen the name func is later called now, it really invokes the __call__ operator over-\\nloading method of the instance created by decorator; the __call__ method can then\\nrun the original func because it is still available in an instance attribute. When coded\\nthis way, each decorated function produces a new instance to retain state.\\n\\nSupporting method decoration\\nOne subtle point about the prior class-based coding is that while it works to intercept\\nsimple function calls, it does not quite work when applied to class-level method func-\\ntions:\\n\\nclass decorator:\\n    def __init__(self, func):           # func is method without instance\\n        self.func = func\\n    def __call__(self, *args):          # self is decorator instance\\n\\nThe Basics\\n\\n| 1275\\n\\n\\x0c        # self.func(*args) fails!       # C instance not in args!\\n\\nclass C:\\n    @decorator\\n    def method(self, x, y):             # method = decorator(method)\\n        ...                             # Rebound to decorator instance\\n\\nWhen coded this way, the decorated method is rebound to an instance of the decorator\\nclass, instead of a simple function.\\nThe problem with this is that the self in the decorator’s __call__ receives the decora\\ntor class instance when the method is later run, and the instance of class C is never\\nincluded in *args. This makes it impossible to dispatch the call to the original method\\n—the decorator object retains the original method function, but it has no instance to\\npass to it.\\nTo support both functions and methods, the nested function alternative works better:\\n\\ndef decorator(F):                       # F is func or method without instance\\n    def wrapper(*args):                 # class instance in args[0] for method\\n                                        # F(*args) runs func or method\\n    return wrapper\\n\\n@decorator\\ndef func(x, y):                         # func = decorator(func)\\n    ...\\nfunc(6, 7)                              # Really calls wrapper(6, 7)\\n\\nclass C:\\n    @decorator\\n    def method(self, x, y):             # method = decorator(method)\\n        ...                             # Rebound to simple function\\n\\nX = C()\\nX.method(6, 7)                          # Really calls wrapper(X, 6, 7)\\n\\nWhen coded this way wrapper receives the C class instance in its first argument, so it\\ncan dispatch to the original method and access state information.\\nTechnically,  this  nested-function  version  works  because  Python  creates  a  bound\\nmethod object and thus passes the subject class instance to the self argument only\\nwhen a method attribute references a simple function; when it references an instance\\nof a callable class instead, the callable class’s instance is passed to  self to give the\\ncallable class access to its own state information. We’ll see how this subtle difference\\ncan matter in more realistic examples later in this chapter.\\nAlso note that nested functions are perhaps the most straightforward way to support\\ndecoration of both functions and methods, but not necessarily the only way. The prior\\nchapter’s descriptors, for example, receive both the descriptor and subject class instance\\nwhen called. Though more complex, later in this chapter we’ll see how this tool can be\\nleveraged in this context as well.\\n\\n1276 | Chapter 39:\\u2002Decorators\\n\\n\\x0cClass Decorators\\nFunction decorators proved so useful that the model was extended to allow class dec-\\noration as of Python 2.6 and 3.0. They were initially resisted because of role overlap\\nwith metaclasses; in the end, though, they were adopted because they provide a simpler\\nway to achieve many of the same goals.\\nClass decorators are strongly related to function decorators; in fact, they use the same\\nsyntax and very similar coding patterns. Rather than wrapping individual functions or\\nmethods, though, class decorators are a way to manage classes, or wrap up instance\\nconstruction calls with extra logic that manages or augments instances created from a\\nclass. In the latter role, they may manage full object interfaces.\\n\\nUsage\\nSyntactically, class decorators appear just before class statements, in the same way that\\nfunction decorators appear just before def statements. In symbolic terms, for a decora\\ntor that must be a one-argument callable that returns a callable, the class decorator\\nsyntax:\\n\\n@decorator                 # Decorate class\\nclass C:\\n    ...\\n\\nx = C(99)                  # Make an instance\\n\\nis equivalent to the following—the class is automatically passed to the decorator func-\\ntion, and the decorator’s result is assigned back to the class name:\\n\\nclass C:\\n    ...\\nC = decorator(C)           # Rebind class name to decorator result\\n\\nx = C(99)                  # Essentially calls decorator(C)(99)\\n\\nThe net effect is that calling the class name later to create an instance winds up triggering\\nthe callable returned by the decorator, which may or may not call the original class itself.\\n\\nImplementation\\nNew class decorators are coded with many of the same techniques used for function\\ndecorators, though some may involve two levels of augmentation—to manage both\\ninstance construction calls, as well as instance interface access. Because a class deco-\\nrator is also a callable that returns a callable, most combinations of functions and classes\\nsuffice.\\nHowever it’s coded, the decorator’s result is what runs when an instance is later created.\\nFor example, to simply manage a class just after it is created, return the original class\\nitself:\\n\\nThe Basics\\n\\n| 1277\\n\\n\\x0cdef decorator(C):\\n    # Process class C\\n    return C\\n\\n@decorator\\nclass C: ...                                    # C = decorator(C)\\n\\nTo instead insert a wrapper layer that intercepts later instance creation calls, return a\\ndifferent callable object:\\n\\ndef decorator(C):\\n    # Save or use class C\\n    # Return a different callable: nested def, class with __call__, etc.\\n\\n@decorator\\nclass C: ...                                    # C = decorator(C)\\n\\nThe callable returned by such a class decorator typically creates and returns a new\\ninstance  of  the  original  class,  augmented  in  some  way  to  manage  its  interface.  For\\nexample, the following inserts an object that intercepts undefined attributes of a class\\ninstance:\\n\\ndef decorator(cls):                             # On @ decoration\\n    class Wrapper:\\n        def __init__(self, *args):              # On instance creation\\n            self.wrapped = cls(*args)\\n        def __getattr__(self, name):            # On attribute fetch\\n            return getattr(self.wrapped, name)\\n    return Wrapper\\n\\n@decorator\\nclass C:                             # C = decorator(C)\\n    def __init__(self, x, y):        # Run by Wrapper.__init__\\n        self.attr = \\'spam\\'\\n\\nx = C(6, 7)                          # Really calls Wrapper(6, 7)\\nprint(x.attr)                        # Runs Wrapper.__getattr__, prints \"spam\"\\n\\nIn this example, the decorator rebinds the class name to another class, which retains\\nthe  original  class  in  an  enclosing  scope  and  creates  and  embeds  an  instance  of  the\\noriginal class when it’s called. When an attribute is later fetched from the instance, it\\nis intercepted by the wrapper’s __getattr__ and delegated to the embedded instance\\nof the original class. Moreover, each decorated class creates a new scope, which re-\\nmembers the original class. We’ll flesh out this example into some more useful code\\nlater in this chapter.\\nLike  function  decorators,  class  decorators  are  commonly  coded  as  either  “factory”\\nfunctions that create and return callables, classes that use __init__ or __call__ methods\\nto intercept call operations, or some combination thereof. Factory functions typically\\nretain state in enclosing scope references, and classes in attributes.\\n\\n1278 | Chapter 39:\\u2002Decorators\\n\\n\\x0cSupporting multiple instances\\nAs for function decorators, some callable type combinations work better for class dec-\\norators than others. Consider the following invalid alternative to the class decorator of\\nthe prior example:\\nclass Decorator:\\n    def __init__(self, C):                    # On @ decoration\\n        self.C = C\\n    def __call__(self, *args):                # On instance creation\\n        self.wrapped = self.C(*args)\\n        return self\\n    def __getattr__(self, attrname):          # On atrribute fetch\\n        return getattr(self.wrapped, attrname)\\n\\n@Decorator\\nclass C: ...                                  # C = Decorator(C)\\n\\nx = C()\\ny = C()                                       # Overwrites x!\\n\\nThis code handles multiple decorated classes (each makes a new Decorator instance)\\nand will intercept instance creation calls (each runs __call__). Unlike the prior version,\\nhowever, this version fails to handle multiple instances of a given class—each instance\\ncreation call overwrites the prior saved instance. The original version does support\\nmultiple instances, because each instance creation call makes a new independent wrap-\\nper object. More generally, either of the following patterns supports multiple wrapped\\ninstances:\\n\\ndef decorator(C):                             # On @ decoration\\n    class Wrapper:\\n        def __init__(self, *args):            # On instance creation: new Wrapper\\n            self.wrapped = C(*args)           # Embed instance in instance\\n    return Wrapper\\n\\nclass Wrapper: ...\\ndef decorator(C):                             # On @ decoration\\n    def onCall(*args):                        # On instance creation: new Wrapper\\n        return Wrapper(C(*args))              # Embed instance in instance\\n    return onCall\\n\\nWe’ll study this phenomenon in a more realistic context later in the chapter too; in\\npractice, though, we must be careful to combine callable types properly to support our\\nintent, and choose state policies wisely.\\n\\nDecorator Nesting\\nSometimes one decorator isn’t enough. For instance, suppose you’ve coded two func-\\ntion decorators to be used during development—one to test argument types before\\nfunction calls, and another to test return value types after function calls. You can use\\neither independently, but what to do if you want to employ both on a single function?\\nWhat you really need is a way to nest the two, such that the result of one decorator is\\n\\nThe Basics\\n\\n| 1279\\n\\n\\x0cthe function decorated by the other. It’s irrelevant which is nested, as long as both steps\\nrun on later calls.\\nTo support multiple nested steps of augmentation this way, decorator syntax allows\\nyou to add multiple layers of wrapper logic to a decorated function or method. When\\nthis feature is used, each decorator must appear on a line of its own. Decorator syntax\\nof this form:\\n\\n@A\\n@B\\n@C\\ndef f(...):\\n    ...\\n\\nruns the same as the following:\\n\\ndef f(...):\\n    ...\\nf = A(B(C(f)))\\n\\nHere, the original function is passed through three different decorators, and the re-\\nsulting callable object is assigned back to the original name. Each decorator processes\\nthe result of the prior, which may be the original function or an inserted wrapper.\\nIf all the decorators insert wrappers, the net effect is that when the original function\\nname is called, three different layers of wrapping object logic will be invoked, to aug-\\nment the original function in three different ways. The last decorator listed is the first\\napplied, and is the most deeply nested when the original function name is later called\\n(insert joke about Python “interior decorators” here).\\nJust as for functions, multiple class decorators result in multiple nested function calls,\\nand possibly multiple levels and steps of wrapper logic around instance creation calls.\\nFor example, the following code:\\n\\n@spam\\n@eggs\\nclass C:\\n    ...\\n\\nX = C()\\n\\nis equivalent to the following:\\n\\nclass C:\\n    ...\\nC = spam(eggs(C))\\n\\nX = C()\\n\\nAgain, each decorator is free to return either the original class or an inserted wrapper\\nobject. With wrappers, when an instance of the original C class is finally requested, the\\ncall is redirected to the wrapping layer objects provided by both the  spam and eggs\\ndecorators, which may have arbitrarily different roles—they might trace and validate\\nattribute access, for example, and both steps would be run on later requests.\\n\\n1280 | Chapter 39:\\u2002Decorators\\n\\n\\x0cFor instance, the following do-nothing decorators simply return the decorated func-\\ntion:\\n\\ndef d1(F): return F\\ndef d2(F): return F\\ndef d3(F): return F\\n\\n@d1\\n@d2\\n@d3\\ndef func():               # func = d1(d2(d3(func)))\\n    print(\\'spam\\')\\n\\nfunc()                    # Prints \"spam\"\\n\\nThe same syntax works on classes, as do these same do-nothing decorators.\\nWhen decorators insert wrapper function objects, though, they may augment the orig-\\ninal function when called—the following concatenates to its result in the decorator\\nlayers, as it runs the layers from inner to outer:\\n\\ndef d1(F): return lambda: \\'X\\' + F()\\ndef d2(F): return lambda: \\'Y\\' + F()\\ndef d3(F): return lambda: \\'Z\\' + F()\\n\\n@d1\\n@d2\\n@d3\\ndef func():               # func = d1(d2(d3(func)))\\n    return \\'spam\\'\\n\\nprint(func())             # Prints \"XYZspam\"\\n\\nWe use lambda functions to implement wrapper layers here (each retains the wrapped\\nfunction in an enclosing scope); in practice, wrappers can take the form of functions,\\ncallable classes, and more. When designed well, decorator nesting allows us to combine\\naugmentation steps in a wide variety of ways.\\n\\nDecorator Arguments\\nBoth function and class decorators can also seem to take arguments, although really\\nthese arguments are passed to a callable that in effect returns the decorator, which in\\nturn returns a callable. By nature, this usually sets up multiple levels of state retention.\\nThe following, for instance:\\n\\n@decorator(A, B)\\ndef F(arg):\\n    ...\\n\\nF(99)\\n\\nThe Basics\\n\\n| 1281\\n\\n\\x0cis automatically mapped into this equivalent form, where decorator is a callable that\\nreturns the actual decorator. The returned decorator in turn returns the callable run\\nlater for calls to the original function name:\\n\\ndef F(arg):\\n    ...\\nF = decorator(A, B)(F)    # Rebind F to result of decorator\\'s return value\\n\\nF(99)                     # Essentially calls decorator(A, B)(F)(99)\\n\\nDecorator arguments are resolved before decoration ever occurs, and they are usually\\nused to retain state information for use in later calls. The decorator function in this\\nexample, for instance, might take a form like the following:\\n\\ndef decorator(A, B):\\n    # Save or use A, B\\n    def actualDecorator(F):\\n        # Save or use function F\\n        # Return a callable: nested def, class with __call__, etc.\\n        return callable\\n    return actualDecorator\\n\\nThe outer function in this structure generally saves the decorator arguments away as\\nstate information, for use in the actual decorator, the callable it returns, or both. This\\ncode snippet retains the state information argument in enclosing function scope refer-\\nences, but class attributes are commonly used as well.\\nIn other words, decorator arguments often imply three levels of callables: a callable to\\naccept decorator arguments, which returns a callable to serve as decorator, which re-\\nturns a callable to handle calls to the original function or class. Each of the three levels\\nmay be a function or class and may retain state in the form of scopes or class attributes.\\nDecorator arguments can be used to provide attribute initialization values, call trace\\nmessage labels, attribute names to be validated, and much more—any sort of config-\\nuration parameter for objects or their proxies is a candidate. We’ll see concrete exam-\\nples of decorator arguments employed later in this chapter.\\n\\nDecorators Manage Functions and Classes, Too\\nAlthough much of the rest of this chapter focuses on wrapping later calls to functions\\nand classes, it’s important to remember that the decorator mechanism is more general\\nthan this—it is a protocol for passing functions and classes through any callable im-\\nmediately after they are created. As such, it can also be used to invoke arbitrary post-\\ncreation processing:\\ndef decorator(O):\\n    # Save or augment function or class O\\n    return O\\n\\n@decorator\\ndef F(): ...                 # F = decorator(F)\\n\\n1282 | Chapter 39:\\u2002Decorators\\n\\n\\x0c@decorator\\nclass C: ...                 # C = decorator(C)\\n\\nAs long as we return the original decorated object this way instead of a proxy, we can\\nmanage functions and classes themselves, not just later calls to them. We’ll see more\\nrealistic examples later in this chapter that use this idea to register callable objects to\\nan API with decoration and assign attributes to functions when they are created.\\n\\nCoding Function Decorators\\nOn to the code—in the rest of this chapter, we are going to study working examples\\nthat  demonstrate  the  decorator  concepts  we  just  explored.  This  section  presents  a\\nhandful of function decorators at work, and the next shows class decorators in action.\\nFollowing that, we’ll close out with some larger case studies of class and function dec-\\norator usage—complete implementations of class privacy and argument range tests.\\n\\nTracing Calls\\nTo get started, let’s revive the call tracer example we met in Chapter 32. The following\\ndefines and applies a function decorator that counts the number of calls made to the\\ndecorated function and prints a trace message for each call:\\n\\n# File decorator1.py\\n\\nclass tracer:\\n    def __init__(self, func):             # On @ decoration: save original func\\n        self.calls = 0\\n        self.func = func\\n    def __call__(self, *args):            # On later calls: run original func\\n        self.calls += 1\\n        print(\\'call %s to %s\\' % (self.calls, self.func.__name__))\\n        self.func(*args)\\n\\n@tracer\\ndef spam(a, b, c):           # spam = tracer(spam)\\n    print(a + b + c)         # Wraps spam in a decorator object\\n\\nNotice how each function decorated with this class will create a new instance, with its\\nown saved function object and calls counter. Also observe how the *args argument\\nsyntax is used to pack and unpack arbitrarily many passed-in arguments. This gener-\\nality enables this decorator to be used to wrap any function with any number of posi-\\ntional arguments; this version doesn’t yet work on keyword arguments or class-level\\nmethods, and doesn’t return results, but we’ll fix these shortcomings later in this sec-\\ntion.\\nNow, if we import this module’s function and test it interactively, we get the following\\nsort of behavior—each call generates a trace message initially, because the decorator\\nclass intercepts it. This code runs as is under both Python 2.X and 3.X, as does all code\\n\\nCoding Function Decorators\\n\\n| 1283\\n\\n\\x0cin this chapter unless otherwise noted (I’ve made prints version-neutral, and decorators\\ndo not require new-style classes; some hex addresses have also been shortened to pro-\\ntect the sighted):\\n\\n>>> from decorator1 import spam\\n\\n>>> spam(1, 2, 3)            # Really calls the tracer wrapper object\\ncall 1 to spam\\n6\\n\\n>>> spam(\\'a\\', \\'b\\', \\'c\\')      # Invokes __call__ in class\\ncall 2 to spam\\nabc\\n\\n>>> spam.calls               # Number calls in wrapper state information\\n2\\n>>> spam\\n<decorator1.tracer object at 0x02D9A730>\\n\\nWhen run, the tracer class saves away the decorated function, and intercepts later calls\\nto it, in order to add a layer of logic that counts and prints each call. Notice how the\\ntotal number of calls shows up as an attribute of the decorated function—spam is really\\nan instance of the tracer class when decorated, a finding that may have ramifications\\nfor programs that do type checking, but is generally benign (decorators might copy the\\noriginal function’s __name__, but such forgery is limited, and could lead to confusion).\\nFor function calls, the @ decoration syntax can be more convenient than modifying each\\ncall to account for the extra logic level, and it avoids accidentally calling the original\\nfunction directly. Consider a nondecorator equivalent such as the following:\\n\\ncalls = 0\\ndef tracer(func, *args):\\n    global calls\\n    calls += 1\\n    print(\\'call %s to %s\\' % (calls, func.__name__))\\n    func(*args)\\n\\ndef spam(a, b, c):\\n    print(a, b, c)\\n\\n>>> spam(1, 2, 3)            # Normal nontraced call: accidental?\\n1 2 3\\n\\n>>> tracer(spam, 1, 2, 3)    # Special traced call without decorators\\ncall 1 to spam\\n1 2 3\\n\\nThis alternative can be used on any function without the special @ syntax, but unlike\\nthe decorator version, it requires extra syntax at every place where the function is called\\nin your code. Furthermore, its intent may not be as obvious, and it does not ensure that\\nthe  extra  layer  will  be  invoked  for  normal  calls.  Although  decorators  are  never  re-\\nquired (we can always rebind names manually), they are often the most convenient and\\nuniform option.\\n\\n1284 | Chapter 39:\\u2002Decorators\\n\\n\\x0cDecorator State Retention Options\\nThe last example of the prior section raises an important issue. Function decorators\\nhave a variety of options for retaining state information provided at decoration time,\\nfor use during the actual function call. They generally need to support multiple deco-\\nrated objects and multiple calls, but there are a number of ways to implement these\\ngoals: instance attributes, global variables, nonlocal closure variables, and function\\nattributes can all be used for retaining state.\\n\\nClass instance attributes\\nFor example, here is an augmented version of the prior example, which adds support \\nfor keyword arguments with ** syntax, and returns the wrapped function’s result to\\nsupport more use cases (for nonlinear readers, we first studied keyword arguments in\\nChapter 18, and for readers working with the book examples package, some filenames\\nin this chapter are again implied by the command-lines that follow their listings):\\n\\nclass tracer:                                # State via instance attributes\\n    def __init__(self, func):                # On @ decorator\\n        self.calls = 0                       # Save func for later call\\n        self.func  = func\\n    def __call__(self, *args, **kwargs):     # On call to original function\\n        self.calls += 1\\n        print(\\'call %s to %s\\' % (self.calls, self.func.__name__))\\n        return self.func(*args, **kwargs)\\n\\n@tracer\\ndef spam(a, b, c):          # Same as: spam = tracer(spam)\\n    print(a + b + c)        # Triggers tracer.__init__\\n\\n@tracer\\ndef eggs(x, y):             # Same as: eggs = tracer(eggs)\\n    print(x ** y)           # Wraps eggs in a tracer object\\n\\nspam(1, 2, 3)               # Really calls tracer instance: runs tracer.__call__\\nspam(a=4, b=5, c=6)         # spam is an instance attribute\\n\\neggs(2, 16)                 # Really calls tracer instance, self.func is eggs\\neggs(4, y=4)                # self.calls is per-decoration here\\n\\nLike the original, this uses class instance attributes to save state explicitly. Both the\\nwrapped function and the calls counter are per-instance information—each decoration\\ngets its own copy. When run as a script under either 2.X or 3.X, the output of this\\nversion is as follows; notice how the spam and eggs functions each have their own calls\\ncounter, because each decoration creates a new class instance:\\n\\nc:\\\\code> python decorator2.py\\ncall 1 to spam\\n6\\ncall 2 to spam\\n15\\ncall 1 to eggs\\n\\nCoding Function Decorators\\n\\n| 1285\\n\\n\\x0c65536\\ncall 2 to eggs\\n256\\n\\nWhile useful for decorating functions, this coding scheme still has issues when applied\\nto methods—a shortcoming we’ll address in a later revision.\\n\\nEnclosing scopes and globals\\nClosure functions—with enclosing  def scope references and nested  defs—can often\\nachieve the same effect, especially for static data like the decorated original function.\\nIn this example, though, we would also need a counter in the enclosing scope that\\nchanges on each call, and that’s not possible in Python 2.X (recall from Chapter 17 that\\nthe nonlocal statement is 3.X-only).\\nIn  2.X,  we  can  still  use  either  classes  and  attributes  per  the  prior  section,  or  other\\noptions. Moving state variables out to the global scope with declarations is one candi-\\ndate, and works in both 2.X and 3.X:\\n\\ncalls = 0\\ndef tracer(func):                         # State via enclosing scope and global\\n    def wrapper(*args, **kwargs):         # Instead of class attributes\\n        global calls                      # calls is global, not per-function\\n        calls += 1\\n        print(\\'call %s to %s\\' % (calls, func.__name__))\\n        return func(*args, **kwargs)\\n    return wrapper\\n\\n@tracer\\ndef spam(a, b, c):        # Same as: spam = tracer(spam)\\n    print(a + b + c)\\n\\n@tracer\\ndef eggs(x, y):           # Same as: eggs = tracer(eggs)\\n    print(x ** y)\\n\\nspam(1, 2, 3)             # Really calls wrapper, assigned to spam\\nspam(a=4, b=5, c=6)       # wrapper calls spam\\n\\neggs(2, 16)               # Really calls wrapper, assigned to eggs\\neggs(4, y=4)              # Global calls is not per-decoration here!\\n\\nUnfortunately, moving the counter out to the common global scope to allow it to be\\nchanged like this also means that it will be shared by every wrapped function. Unlike\\nclass  instance  attributes,  global  counters  are  cross-program,  not  per-function—the\\ncounter is incremented for any traced function call. You can tell the difference if you\\ncompare this version’s output with the prior version’s—the single, shared global call\\ncounter is incorrectly updated by calls to every decorated function:\\n\\nc:\\\\code> python decorator3.py\\ncall 1 to spam\\n6\\ncall 2 to spam\\n\\n1286 | Chapter 39:\\u2002Decorators\\n\\n\\x0c15\\ncall 3 to eggs\\n65536\\ncall 4 to eggs\\n256\\n\\nEnclosing scopes and nonlocals\\nShared global state may be what we want in some cases. If we really want a per-func-\\ntion counter, though, we can either use classes as before, or make use of closure (a.k.a.\\nfactory)  functions  and  the  nonlocal  statement  in  Python  3.X,  described  in  Chap-\\nter  17.  Because  this  new  statement  allows  enclosing  function  scope  variables  to  be\\nchanged, they can serve as per-decoration and changeable data. In 3.X only:\\n\\ndef tracer(func):                        # State via enclosing scope and nonlocal\\n    calls = 0                            # Instead of class attrs or global\\n    def wrapper(*args, **kwargs):        # calls is per-function, not global\\n        nonlocal calls\\n        calls += 1\\n        print(\\'call %s to %s\\' % (calls, func.__name__))\\n        return func(*args, **kwargs)\\n    return wrapper\\n\\n@tracer\\ndef spam(a, b, c):        # Same as: spam = tracer(spam)\\n    print(a + b + c)\\n\\n@tracer\\ndef eggs(x, y):           # Same as: eggs = tracer(eggs)\\n    print(x ** y)\\n\\nspam(1, 2, 3)             # Really calls wrapper, bound to func\\nspam(a=4, b=5, c=6)       # wrapper calls spam\\n\\neggs(2, 16)               # Really calls wrapper, bound to eggs\\neggs(4, y=4)              # Nonlocal calls _is_ per-decoration here\\n\\nNow, because enclosing scope variables are not cross-program globals, each wrapped\\nfunction gets its own counter again, just as for classes and attributes. Here’s the new\\noutput when run under 3.X:\\n\\nc:\\\\code> py −3 decorator4.py\\ncall 1 to spam\\n6\\ncall 2 to spam\\n15\\ncall 1 to eggs\\n65536\\ncall 2 to eggs\\n256\\n\\nCoding Function Decorators\\n\\n| 1287\\n\\n\\x0cFunction attributes\\nFinally, if you are not using Python 3.X and don’t have a nonlocal statement—or you\\nwant your code to work portably on both 3.X and 2.X—you may still be able to avoid\\nglobals and classes by making use of function attributes for some changeable state in-\\nstead. In all Pythons since 2.1, we can assign arbitrary attributes to functions to attach\\nthem, with func.attr=value. Because a factory function makes a new function on each\\ncall, its attributes become per-call state. Moreover, you need to use this technique only\\nfor state variables that must change; enclosing scope references are still retained and\\nwork normally.\\nIn our example, we can simply use wrapper.calls for state. The following works the\\nsame as the preceding nonlocal version because the counter is again per-decorated-\\nfunction, but it also runs in Python 2.X:\\n\\ndef tracer(func):                        # State via enclosing scope and func attr\\n    def wrapper(*args, **kwargs):        # calls is per-function, not global\\n        wrapper.calls += 1\\n        print(\\'call %s to %s\\' % (wrapper.calls, func.__name__))\\n        return func(*args, **kwargs)\\n    wrapper.calls = 0\\n    return wrapper\\n\\n@tracer\\ndef spam(a, b, c):        # Same as: spam = tracer(spam)\\n    print(a + b + c)\\n\\n@tracer\\ndef eggs(x, y):           # Same as: eggs = tracer(eggs)\\n    print(x ** y)\\n\\nspam(1, 2, 3)             # Really calls wrapper, assigned to spam\\nspam(a=4, b=5, c=6)       # wrapper calls spam\\n\\neggs(2, 16)               # Really calls wrapper, assigned to eggs\\neggs(4, y=4)              # wrapper.calls _is_ per-decoration here\\n\\nAs we learned in Chapter 17, this works only because the name wrapper is retained in\\nthe enclosing tracer function’s scope. When we later increment wrapper.calls, we are\\nnot changing the name wrapper itself, so no nonlocal declaration is required. This ver-\\nsion runs in either Python line:\\nc:\\\\code> py −2 decorator5.py\\n...same output as prior version, but works on 2.X too...\\n\\nThis scheme was almost relegated to a footnote, because it may be more obscure than\\nnonlocal in 3.X and might be better saved for cases where other schemes don’t help.\\nHowever,  function  attributes  also  have  substantial  advantages.  For  one,  they  allow\\naccess to the saved state from outside the decorator’s code; nonlocals can only be seen\\ninside the nested function itself, but function attributes have wider visibility. For an-\\nother, they are far more portable; this scheme also works in 2.X, making it version-\\nneutral.\\n\\n1288 | Chapter 39:\\u2002Decorators\\n\\n\\x0cWe will employ function attributes again in an answer to one of the end-of-chapter\\nquestions, where their visibility outside callables becomes an asset. As changeable state\\nassociated with a context of use, they are equivalent to enclosing scope nonlocals. As\\nusual, choosing from multiple tools is an inherent part of the programming task.\\nBecause decorators often imply multiple levels of callables, you can combine functions\\nwith enclosing scopes, classes with attributes, and function attributes to achieve a va-\\nriety of coding structures. As we’ll see later, though, this sometimes may be subtler\\nthan you expect—each decorated function should have its own state, and each deco-\\nrated class may require state both for itself and for each generated instance.\\nIn fact, as the next section will explain in more detail, if we want to apply function\\ndecorators to class-level methods, too, we also have to be careful about the distinction\\nPython makes between decorators coded as callable class instance objects and deco-\\nrators coded as functions.\\n\\nClass Blunders I: Decorating Methods\\nWhen I wrote the first class-based tracer function decorator in decorator1.py earlier,\\nI naively assumed that it could also be applied to any method—decorated methods\\nshould work the same, I reasoned, but the automatic self instance argument would\\nsimply be included at the front of *args. The only real downside to this assumption is\\nthat it is completely wrong! When applied to a class’s method, the first version of the\\ntracer fails, because self is the instance of the decorator class and the instance of the\\ndecorated subject class is not included in *args at all. This is true in both Python 3.X\\nand 2.X.\\nI introduced this phenomenon earlier in this chapter, but now we can see it in the\\ncontext of realistic working code. Given the class-based tracing decorator:\\n\\nclass tracer:\\n    def __init__(self, func):                # On @ decorator\\n        self.calls = 0                       # Save func for later call\\n        self.func  = func\\n    def __call__(self, *args, **kwargs):     # On call to original function\\n        self.calls += 1\\n        print(\\'call %s to %s\\' % (self.calls, self.func.__name__))\\n        return self.func(*args, **kwargs)\\n\\ndecoration of simple functions works as advertised earlier:\\n\\n@tracer\\ndef spam(a, b, c):                           # spam = tracer(spam)\\n    print(a + b + c)                         # Triggers tracer.__init__\\n\\n>>> spam(1, 2, 3)                            # Runs tracer.__call__\\ncall 1 to spam\\n6\\n>>> spam(a=4, b=5, c=6)                      # spam saved in an instance attribute\\ncall 2 to spam\\n15\\n\\nCoding Function Decorators\\n\\n| 1289\\n\\n\\x0cHowever, decoration of class-level methods fails (more lucid sequential readers might\\nrecognize this as an adaptation of our Person class resurrected from the object-oriented\\ntutorial in Chapter 28):\\n\\nclass Person:\\n    def __init__(self, name, pay):\\n        self.name = name\\n        self.pay  = pay\\n\\n    @tracer\\n    def giveRaise(self, percent):            # giveRaise = tracer(giveRaise)\\n        self.pay *= (1.0 + percent)\\n\\n    @tracer\\n    def lastName(self):                      # lastName = tracer(lastName)\\n        return self.name.split()[-1]\\n\\n>>> bob = Person(\\'Bob Smith\\', 50000)         # tracer remembers method funcs\\n>>> bob.giveRaise(.25)                       # Runs tracer.__call__(???, .25)\\ncall 1 to giveRaise\\nTypeError: giveRaise() missing 1 required positional argument: \\'percent\\'\\n\\n>>> print(bob.lastName())                    # Runs tracer.__call__(???)\\ncall 1 to lastName\\nTypeError: lastName() missing 1 required positional argument: \\'self\\'\\n\\nThe root of the problem here is in the self argument of the tracer class’s __call__\\nmethod—is it a tracer instance or a Person instance? We really need both as it’s coded:\\nthe tracer for decorator state, and the Person for routing on to the original method.\\nReally, self must be the tracer object, to provide access to tracer’s state information\\n(its calls and func); this is true whether decorating a simple function or a method.\\nUnfortunately, when our decorated method name is rebound to a class instance object\\nwith a __call__, Python passes only the tracer instance to self; it doesn’t pass along\\nthe Person subject in the arguments list at all. Moreover, because the tracer knows\\nnothing about the Person instance we are trying to process with method calls, there’s\\nno way to create a bound method with an instance, and thus no way to correctly dis-\\npatch the call. This isn’t a bug, but it’s wildly subtle.\\nIn  the  end,  the  prior  listing  winds  up  passing  too  few  arguments  to  the  decorated\\nmethod, and results in an error. Add a line to the decorator’s __call__ to print all its\\narguments to verify this—as you can see, self is the tracer instance, and the Person\\ninstance is entirely absent:\\n>>> bob.giveRaise(.25)\\n<__main__.tracer object at 0x02A486D8> (0.25,) {}\\ncall 1 to giveRaise\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\n  File \"<stdin>\", line 9, in __call__\\nTypeError: giveRaise() missing 1 required positional argument: \\'percent\\'\\n\\n1290 | Chapter 39:\\u2002Decorators\\n\\n\\x0cAs mentioned earlier, this happens because Python passes the implied subject instance\\nto self when a method name is bound to a simple function only; when it is an instance\\nof a callable class, that class’s instance is passed instead. Technically, Python makes a\\nbound method object containing the subject instance only when the method is a simple\\nfunction, not when it is a callable instance of another class.\\n\\nUsing nested functions to decorate methods\\nIf you want your function decorators to work on both simple functions and class-level\\nmethods, the most straightforward solution lies in using one of the other state retention\\nsolutions described earlier—code your function decorator as nested defs, so that you\\ndon’t depend on a single self instance argument to be both the wrapper class instance\\nand the subject class instance.\\nThe following alternative applies this fix using Python 3.X nonlocals; recode this to use\\nfunction attributes for the changeable calls to use in 2.X. Because decorated methods\\nare rebound to simple functions instead of instance objects, Python correctly passes\\nthe Person object as the first argument, and the decorator propagates it on in the first\\nitem of *args to the self argument of the real, decorated methods:\\n\\n# A call tracer decorator for both functions and methods\\n\\ndef tracer(func):                        # Use function, not class with __call__\\n    calls = 0                            # Else \"self\" is decorator instance only!\\n    def onCall(*args, **kwargs):         # Or in 2.X+3.X: use [onCall.calls += 1]\\n        nonlocal calls\\n        calls += 1\\n        print(\\'call %s to %s\\' % (calls, func.__name__))\\n        return func(*args, **kwargs)\\n    return onCall\\n\\nif __name__ == \\'__main__\\':\\n\\n    # Applies to simple functions\\n    @tracer\\n    def spam(a, b, c):                       # spam = tracer(spam)\\n        print(a + b + c)                     # onCall remembers spam\\n\\n    @tracer\\n    def eggs(N):\\n        return 2 ** N\\n\\n    spam(1, 2, 3)                            # Runs onCall(1, 2, 3)\\n    spam(a=4, b=5, c=6)\\n    print(eggs(32))\\n\\n    # Applies to class-level method functions too!\\n    class Person:\\n        def __init__(self, name, pay):\\n            self.name = name\\n            self.pay  = pay\\n\\nCoding Function Decorators\\n\\n| 1291\\n\\n\\x0c        @tracer\\n        def giveRaise(self, percent):        # giveRaise = tracer(giveRaise)\\n            self.pay *= (1.0 + percent)      # onCall remembers giveRaise\\n\\n        @tracer\\n        def lastName(self):                  # lastName = tracer(lastName)\\n            return self.name.split()[-1]\\n\\n    print(\\'methods...\\')\\n    bob = Person(\\'Bob Smith\\', 50000)\\n    sue = Person(\\'Sue Jones\\', 100000)\\n    print(bob.name, sue.name)\\n    sue.giveRaise(.10)                       # Runs onCall(sue, .10)\\n    print(int(sue.pay))\\n    print(bob.lastName(), sue.lastName())    # Runs onCall(bob), lastName in scopes\\n\\nWe’ve also indented the file’s self-test code under a __name__ test so the decorator can\\nbe imported and used elsewhere. This version works the same on both functions and\\nmethods, but runs in 3.X only due to its nonlocal:\\n\\nc:\\\\code> py −3 calltracer.py\\ncall 1 to spam\\n6\\ncall 2 to spam\\n15\\ncall 1 to eggs\\n4294967296\\nmethods...\\nBob Smith Sue Jones\\ncall 1 to giveRaise\\n110000\\ncall 1 to lastName\\ncall 2 to lastName\\nSmith Jones\\n\\nTrace through these results to make sure you have a handle on this model; the next\\nsection provides an alternative to it that supports classes, but is also substantially more\\ncomplex.\\n\\nUsing descriptors to decorate methods\\nAlthough  the  nested  function  solution  illustrated  in  the  prior  section  is  the  most\\nstraightforward way to support decorators that apply to both functions and class-level\\nmethods, other schemes are possible. The descriptor feature we explored in the prior\\nchapter, for example, can help here as well.\\nRecall from our discussion in that chapter that a descriptor is normally a class attribute\\nassigned to an object with a __get__ method run automatically whenever that attribute\\nis referenced and fetched; new-style class object derivation is required for descriptors\\nin Python 2.X, but not 3.X:\\nclass Descriptor(object):\\n    def __get__(self, instance, owner): ...\\n\\n1292 | Chapter 39:\\u2002Decorators\\n\\n\\x0cclass Subject:\\n    attr = Descriptor()\\n\\nX = Subject()\\nX.attr         # Roughly runs Descriptor.__get__(Subject.attr, X, Subject)\\n\\nDescriptors may also have __set__ and __del__ access methods, but we don’t need\\nthem  here.  More  relevant  to  this  chapter’s  topic,  because  the  descriptor’s  __get__\\nmethod  receives  both  the  descriptor  class  instance  and  subject  class  instance  when\\ninvoked, it’s well suited to decorating methods when we need both the decorator’s state\\nand the original class instance for dispatching calls. Consider the following alternative\\ntracing decorator, which also happens to be a descriptor when used for a class-level\\nmethod:\\n\\nclass tracer(object):                        # A decorator+descriptor\\n    def __init__(self, func):                # On @ decorator\\n        self.calls = 0                       # Save func for later call\\n        self.func  = func\\n    def __call__(self, *args, **kwargs):     # On call to original func\\n        self.calls += 1\\n        print(\\'call %s to %s\\' % (self.calls, self.func.__name__))\\n        return self.func(*args, **kwargs)\\n    def __get__(self, instance, owner):      # On method attribute fetch\\n        return wrapper(self, instance)\\n\\nclass wrapper:\\n    def __init__(self, desc, subj):          # Save both instances\\n        self.desc = desc                     # Route calls back to deco/desc\\n        self.subj = subj\\n    def __call__(self, *args, **kwargs):\\n        return self.desc(self.subj, *args, **kwargs)  # Runs tracer.__call__\\n\\n@tracer\\ndef spam(a, b, c):                           # spam = tracer(spam)\\n    ...same as prior...                      # Uses __call__ only\\n\\nclass Person:\\n    @tracer\\n    def giveRaise(self, percent):            # giveRaise = tracer(giveRaise)\\n        ...same as prior...                  # Makes giveRaise a descriptor\\n\\nThis works the same as the preceding nested function coding. Its operation varies by\\nusage context:\\n\\n• Decorated functions invoke only its __call__, and never invoke its __get__.\\n• Decorated methods invoke its __get__ first to resolve the method name fetch (on\\nI.method); the object returned by __get__ retains the subject class instance and is\\nthen invoked to complete the call expression, thereby triggering the decorator’s\\n__call__ (on ()).\\n\\nFor example, the test code’s call to:\\n\\nCoding Function Decorators\\n\\n| 1293\\n\\n\\x0csue.giveRaise(.10)                           # Runs __get__ then __call__\\n\\nfollowed  by \\n\\nthree \\n\\ncall  operations— \\n\\nruns tracer.__get__ first, because the giveRaise attribute in the Person class has been\\nrebound to a descriptor by the method function decorator. The call expression then\\ntriggers the __call__ method of the returned wrapper object, which in turn invokes\\ntracer.__call__. In other words, decorated method calls trigger a four-step process:\\ntracer.__get__, \\nwrapper.__call__,\\ntracer.__call__, and finally the original wrapped method.\\nThe wrapper object retains both descriptor and subject instances, so it can route control\\nback to the original decorator/descriptor class instance. In effect, the wrapper object\\nsaves the subject class instance available during method attribute fetch and adds it to\\nthe later call’s arguments list, which is passed to the decorator__call__. Routing the\\ncall back to the descriptor class instance this way is required in this application so that\\nall  calls  to  a  wrapped  method  use  the  same  calls  counter  state  information  in  the\\ndescriptor instance object.\\nAlternatively, we could use a nested function and enclosing scope references to achieve\\nthe same effect—the following version works the same as the preceding one, by swap-\\nping a class and object attributes for a nested function and scope references. It requires\\nnoticeably less code, but follows the same four-step process on each decorated method\\ncall:\\n\\nclass tracer(object):\\n    def __init__(self, func):                # On @ decorator\\n        self.calls = 0                       # Save func for later call\\n        self.func  = func\\n    def __call__(self, *args, **kwargs):     # On call to original func\\n        self.calls += 1\\n        print(\\'call %s to %s\\' % (self.calls, self.func.__name__))\\n        return self.func(*args, **kwargs)\\n    def __get__(self, instance, owner):                # On method fetch\\n        def wrapper(*args, **kwargs):                  # Retain both inst\\n            return self(instance, *args, **kwargs)     # Runs __call__\\n        return wrapper\\n\\nAdd print statements to these alternatives’ methods to trace the multistep get/call pro-\\ncess on your own, and run them with the same test code as in the nested function\\nalternative shown earlier (see file calltracer-descr.py for their source). In either coding,\\nthis descriptor-based scheme is also substantially subtler than the nested function op-\\ntion, and so is probably a second choice here. To be more blunt, if its complexity doesn’t\\nsend you screaming into the night, its performance costs probably should! Still, this\\nmay be a useful coding pattern in other contexts.\\nIt’s also worth noting that we might code this descriptor-based decorator more simply\\nas follows, but it would then apply only to methods, not to simple functions—an in-\\ntrinsic limitation of attribute descriptors (and just the inverse of the problem we’re\\ntrying to solve: application to both functions and methods)\\n\\nclass tracer(object):                         # For methods, but not functions!\\n    def __init__(self, meth):                 # On @ decorator\\n\\n1294 | Chapter 39:\\u2002Decorators\\n\\n\\x0c        self.calls = 0                         \\n        self.meth  = meth\\n    def __get__(self, instance, owner):       # On method fetch\\n        def wrapper(*args, **kwargs):         # On method call: proxy with self+inst\\n            self.calls += 1\\n            print(\\'call %s to %s\\' % (self.calls, self.meth.__name__))\\n            return self.meth(instance, *args, **kwargs)\\n        return wrapper\\n\\nclass Person:                            \\n    @tracer                            # Applies to class methods\\n    def giveRaise(self, percent):      # giveRaise = tracer(giveRaise)\\n        ...                            # Makes giveRaise a descriptor\\n\\n@tracer                                # But fails for simple functions\\ndef spam(a, b, c):                     # spam = tracer(spam)\\n    ...                                # No attribute fetch occurs here\\n\\nIn the rest of this chapter we’re going to be fairly casual about using classes or functions\\nto code our function decorators, as long as they are applied only to functions. Some\\ndecorators may not require the instance of the original class, and will still work on both\\nfunctions  and  methods  if  coded  as  a  class—something  like  Python’s  own  staticme\\nthod decorator, for example, wouldn’t require an instance of the subject class (indeed,\\nits whole point is to remove the instance from the call).\\nThe moral of this story, though, is that if you want your decorators to work on both\\nsimple functions and methods, you’re probably better off using the nested-function-\\nbased coding pattern outlined here instead of a class with call interception.\\n\\nTiming Calls\\nTo sample the fuller flavor of what function decorators are capable of, let’s turn to a\\ndifferent use case. Our next decorator times calls made to a decorated function—both\\nthe time for one call, and the total time among all calls. The decorator is applied to two\\nfunctions, in order to compare the relative speed of list comprehensions and the map\\nbuilt-in call:\\n\\n# File timerdeco1.py\\n# Caveat: range still differs - a list in 2.X, an iterable in 3.X\\n# Caveat: timer won\\'t work on methods as coded (see quiz solution)\\n\\nimport time, sys\\nforce = list if sys.version_info[0] == 3 else (lambda X: X)\\n\\nclass timer:\\n    def __init__(self, func):\\n        self.func    = func\\n        self.alltime = 0\\n    def __call__(self, *args, **kargs):\\n        start   = time.clock()\\n        result  = self.func(*args, **kargs)\\n\\nCoding Function Decorators\\n\\n| 1295\\n\\n\\x0c        elapsed = time.clock() - start\\n        self.alltime += elapsed\\n        print(\\'%s: %.5f, %.5f\\' % (self.func.__name__, elapsed, self.alltime))\\n        return result\\n\\n@timer\\ndef listcomp(N):\\n    return [x * 2 for x in range(N)]\\n\\n@timer\\ndef mapcall(N):\\n    return force(map((lambda x: x * 2), range(N)))\\n\\nresult = listcomp(5)                # Time for this call, all calls, return value\\nlistcomp(50000)\\nlistcomp(500000)\\nlistcomp(1000000)\\nprint(result)\\nprint(\\'allTime = %s\\' % listcomp.alltime)      # Total time for all listcomp calls\\n\\nprint(\\'\\')\\nresult = mapcall(5)\\nmapcall(50000)\\nmapcall(500000)\\nmapcall(1000000)\\nprint(result)\\nprint(\\'allTime = %s\\' % mapcall.alltime)       # Total time for all mapcall calls\\n\\nprint(\\'\\\\n**map/comp = %s\\' % round(mapcall.alltime / listcomp.alltime, 3))\\n\\nWhen run in either Python 3.X or 2.X, the output of this file’s self-test code is as follows\\n—giving for each function call the function name, time for this call, and time for all\\ncalls so far, along with the first call’s return value, cumulative time for each function,\\nand the map-to-comprehension time ratio at the end:\\n\\nc:\\\\code> py −3 timerdeco1.py\\nlistcomp: 0.00001, 0.00001\\nlistcomp: 0.00499, 0.00499\\nlistcomp: 0.05716, 0.06215\\nlistcomp: 0.11565, 0.17781\\n[0, 2, 4, 6, 8]\\nallTime = 0.17780527629411225\\n\\nmapcall: 0.00002, 0.00002\\nmapcall: 0.00988, 0.00990\\nmapcall: 0.10601, 0.11591\\nmapcall: 0.21690, 0.33281\\n[0, 2, 4, 6, 8]\\nallTime = 0.3328064956447921\\n\\n**map/comp = 1.872\\n\\nTimes vary per Python line and test machine, of course, and cumulative time is available\\nas a class instance attribute here. As usual, map calls are almost twice as slow as list\\n\\n1296 | Chapter 39:\\u2002Decorators\\n\\n\\x0ccomprehensions when the latter can avoid a function call (or equivalently, its require-\\nment of function calls can make map slower).\\n\\nDecorators versus per-call timing\\nFor comparison, see Chapter 21 for a nondecorator approach to timing iteration alter-\\nnatives like these. As a review, we saw two per-call timing techniques there, homegrown\\nand library—here deployed to time the 1M list comprehension case of the decorator’s\\ntest code, though incurring extra costs for management code including an outer loop\\nand function calls:\\n\\n>>> def listcomp(N): [x * 2 for x in range(N)]\\n\\n>>> import timer                                             # Chapter 21 techniques\\n>>> timer.total(1, listcomp, 1000000)\\n(0.1461295268088542, None)\\n\\n>>> import timeit\\n>>> timeit.timeit(number=1, stmt=lambda: listcomp(1000000))\\n0.14964829430189397\\n\\nIn this specific case, a nondecorator approach would allow the subject functions to be\\nused with or without timing, but it would also complicate the call signature when timing\\nis desired—we’d need to add code at every call instead of once at the def. Moreover,\\nin the nondecorator scheme there would be no direct way to guarantee that all list\\nbuilder calls in a program are routed through timer logic, short of finding and poten-\\ntially changing them all. This may make it difficult to collect cumulative data for all calls.\\nIn general, decorators may be preferred when functions are already deployed as part of\\na larger system, and may not be easily passed to analysis functions at calls. On the other\\nhand, because decorators charge each call to a function with augmentation logic, a\\nnondecorator approach may be better if you wish to augment calls more selectively. As\\nusual, different tools serve different roles.\\n\\nTimer call portability and new options in 3.3: Also see Chapter 21’s more\\ncomplete handling and selection of time module functions, as well as its\\nsidebar concerning the new and improved timer functions in this mod-\\nule available as of Python 3.3 (e.g., perf_counter). We’re taking a sim-\\nplistic  approach  here  for  both  brevity  and  version  neutrality,  but\\ntime.clock may not be best on some platforms even prior to 3.3, and\\nplatform or version tests may be required outside Windows.\\n\\nTesting subtleties\\nNotice how this script uses its force setting to make it portable between 2.X and 3.X.\\nAs described in Chapter 14, the map built-in returns an iterable that generates results\\non demand in 3.X, but an actual list in 2.X. Hence, 3.X’s map by itself doesn’t compare\\ndirectly to a list comprehension’s work. In fact, without wrapping it in a list call to\\n\\nCoding Function Decorators\\n\\n| 1297\\n\\n\\x0cforce results production, the map test takes virtually no time at all in 3.X—it returns an\\niterable without iterating!\\nAt the same time, adding this list call in 2.X too charges map with an unfair penalty—\\nthe map test’s results would include the time required to build two lists, not one. To\\nwork around this, the script selects a map enclosing function per the Python version\\nnumber in sys: in 3.X, picking list, and in 2.X using a no-op function that simply\\nreturns its input argument unchanged. This adds a very minor constant time in 2.X,\\nwhich is probably fully overshadowed by the cost of the inner loop iterations in the\\ntimed function.\\nWhile this makes the comparison between list comprehensions and map more fair in\\neither 2.X or 3.X, because range is also an iterator in 3.X, the results for 2.X and 3.X\\nwon’t compare directly unless you also hoist this call out of the timed code. They’ll be\\nrelatively comparable—and will reflect best practice code in each line anyhow—but a\\nrange iteration adds extra time in 3.X only. For more on all such things, see Chap-\\nter 21’s benchmark recreations; producing comparable numbers is often a nontrivial\\ntask.\\nFinally, as we did for the tracer decorator earlier, we could make this timing decorator\\nreusable in other modules by indenting the self-test code at the bottom of the file under\\na __name__ test so it runs only when the file is run, not when it’s imported. We won’t\\ndo this here, though, because we’re about to add another feature to our code.\\n\\nAdding Decorator Arguments\\nThe timer decorator of the prior section works, but it would be nice if it were more\\nconfigurable—providing an output label and turning trace messages on and off, for\\ninstance, might be useful in a general-purpose tool like this. Decorator arguments come\\nin handy here: when they’re coded properly, we can use them to specify configuration\\noptions that can vary for each decorated function. A label, for instance, might be added\\nas follows:\\n\\ndef timer(label=\\'\\'):\\n    def decorator(func):\\n        def onCall(*args):          # Multilevel state retention:\\n            ...                     # args passed to function\\n            func(*args)             # func retained in enclosing scope\\n            print(label, ...        # label retained in enclosing scope\\n        return onCall\\n    return decorator                # Returns the actual decorator\\n\\n@timer(\\'==>\\')                       # Like listcomp = timer(\\'==>\\')(listcomp)\\ndef listcomp(N): ...                # listcomp is rebound to new onCall\\n\\nlistcomp(...)                       # Really calls onCall\\n\\nThis code adds an enclosing scope to retain a decorator argument for use on a later\\nactual call. When the listcomp function is defined, Python really invokes decorator—\\n\\n1298 | Chapter 39:\\u2002Decorators\\n\\n\\x0cthe result of timer, run before decoration actually occurs—with the label value avail-\\nable in its enclosing scope. That is, timer returns the decorator, which remembers both\\nthe  decorator  argument  and  the  original  function,  and  returns  the  callable  onCall,\\nwhich ultimately invokes the original function on later calls. Because this structure\\ncreates new decorator and onCall functions, their enclosing scopes are per-decoration\\nstate retention.\\nWe can put this structure to use in our timer to allow a label and a trace control flag to\\nbe  passed  in  at  decoration  time.  Here’s  an  example  that  does  just  that,  coded  in  a\\nmodule file named timerdeco2.py so it can be imported as a general tool; it uses a class\\nfor the second state retention level instead of a nested function, but the net result is\\nsimilar:\\n\\nimport time\\n\\ndef timer(label=\\'\\', trace=True):                  # On decorator args: retain args\\n    class Timer:\\n        def __init__(self, func):                 # On @: retain decorated func\\n            self.func    = func\\n            self.alltime = 0\\n        def __call__(self, *args, **kargs):       # On calls: call original\\n            start   = time.clock()\\n            result  = self.func(*args, **kargs)\\n            elapsed = time.clock() - start\\n            self.alltime += elapsed\\n            if trace:\\n                format = \\'%s %s: %.5f, %.5f\\'\\n                values = (label, self.func.__name__, elapsed, self.alltime)\\n                print(format % values)\\n            return result\\n    return Timer\\n\\nMostly all we’ve done here is embed the original Timer class in an enclosing function,\\nin order to create a scope that retains the decorator arguments per deployment. The\\nouter  timer  function  is  called  before  decoration  occurs,  and  it  simply  returns  the\\nTimer class to serve as the actual decorator. On decoration, an instance of Timer is made\\nthat remembers the decorated function itself, but also has access to the decorator ar-\\nguments in the enclosing function scope.\\n\\nTiming with decorator arguments\\nThis time, rather than embedding self-test code in this file, we’ll run the decorator in\\na different file. Here’s a client of our timer decorator, the module file testseqs.py, ap-\\nplying it to sequence iteration alternatives again:\\n\\nimport sys\\nfrom timerdeco2 import timer\\nforce = list if sys.version_info[0] == 3 else (lambda X: X)\\n\\n@timer(label=\\'[CCC]==>\\')\\ndef listcomp(N):                             # Like listcomp = timer(...)(listcomp)\\n    return [x * 2 for x in range(N)]         # listcomp(...) triggers Timer.__call__\\n\\nCoding Function Decorators\\n\\n| 1299\\n\\n\\x0c@timer(trace=True, label=\\'[MMM]==>\\')\\ndef mapcall(N):\\n    return force(map((lambda x: x * 2), range(N)))\\n\\nfor func in (listcomp, mapcall):\\n    result = func(5)        # Time for this call, all calls, return value\\n    func(50000)\\n    func(500000)\\n    func(1000000)\\n    print(result)\\n    print(\\'allTime = %s\\\\n\\' % func.alltime)   # Total time for all calls\\n\\nprint(\\'**map/comp = %s\\' % round(mapcall.alltime / listcomp.alltime, 3))\\n\\nAgain, to make this fair, map is wrapped in a list call in 3.X only. When run as is in 3.X\\nor 2.X, this file prints the following—each decorated function now has a label of its\\nown defined by decorator arguments, which will be more useful when we need to find\\ntrace displays mixed in with a larger program’s output:\\n\\nc:\\\\code> py −3 testseqs.py\\n[CCC]==> listcomp: 0.00001, 0.00001\\n[CCC]==> listcomp: 0.00504, 0.00505\\n[CCC]==> listcomp: 0.05839, 0.06344\\n[CCC]==> listcomp: 0.12001, 0.18344\\n[0, 2, 4, 6, 8]\\nallTime = 0.1834406801777564\\n\\n[MMM]==> mapcall: 0.00003, 0.00003\\n[MMM]==> mapcall: 0.00961, 0.00964\\n[MMM]==> mapcall: 0.10929, 0.11892\\n[MMM]==> mapcall: 0.22143, 0.34035\\n[0, 2, 4, 6, 8]\\nallTime = 0.3403542519173618\\n\\n**map/comp = 1.855\\n\\nAs usual, we can also test interactively to see how the decorator’s configuration argu-\\nments come into play:\\n\\n>>> from timerdeco2 import timer\\n>>> @timer(trace=False)                      # No tracing, collect total time\\n... def listcomp(N):\\n...     return [x * 2 for x in range(N)]\\n...\\n>>> x = listcomp(5000)\\n>>> x = listcomp(5000)\\n>>> x = listcomp(5000)\\n>>> listcomp.alltime\\n0.0037191417530599152\\n>>> listcomp\\n<timerdeco2.timer.<locals>.Timer object at 0x02957518>\\n\\n>>> @timer(trace=True, label=\\'\\\\t=>\\')         # Turn on tracing, custom label\\n... def listcomp(N):\\n\\n1300 | Chapter 39:\\u2002Decorators\\n\\n\\x0c...     return [x * 2 for x in range(N)]\\n...\\n>>> x = listcomp(5000)\\n        => listcomp: 0.00106, 0.00106\\n>>> x = listcomp(5000)\\n        => listcomp: 0.00108, 0.00214\\n>>> x = listcomp(5000)\\n        => listcomp: 0.00107, 0.00321\\n>>> listcomp.alltime\\n0.003208920466562404\\n\\nAs is, this timing function decorator can be used for any function, both in modules and\\ninteractively. In other words, it automatically qualifies as a general-purpose tool for\\ntiming code in our scripts. Watch for another example of decorator arguments in the\\nsection “Implementing Private Attributes” on page 1314, and again in “A Basic Range-\\nTesting Decorator for Positional Arguments”.\\n\\nSupporting methods: This section’s timer decorator works on any func-\\ntion, but a minor rewrite is required to be able to apply it to class-level\\nmethods too. In short, as our earlier section “Class Blunders I: Decorat-\\ning Methods” on page 1289 illustrated, it must avoid using a nested\\nclass. Because this mutation was deliberately reserved to be a subject of\\none of our end-of-chapter quiz questions, though, I’ll avoid giving away\\nthe answer completely here.\\n\\nCoding Class Decorators\\nSo far we’ve been coding function decorators to manage function calls, but as we’ve\\nseen, decorators have been extended to work on classes too as of Python 2.6 and 3.0.\\nAs described earlier, while similar in concept to function decorators, class decorators\\nare applied to classes instead—they may be used either to manage classes themselves,\\nor to intercept instance creation calls in order to manage instances. Also like function\\ndecorators, class decorators are really just optional syntactic sugar, though many be-\\nlieve that they make a programmer’s intent more obvious and minimize erroneous or\\nmissed calls.\\n\\nSingleton Classes\\nBecause class decorators may intercept instance creation calls, they can be used to either\\nmanage all the instances of a class, or augment the interfaces of those instances. To\\ndemonstrate, here’s a first class decorator example that does the former—managing all\\ninstances of a class. This code implements the classic singleton coding pattern, where\\nat most one instance of a class ever exists. Its singleton function defines and returns a\\nfunction for managing instances, and the @ syntax automatically wraps up a subject\\nclass in this function:\\n\\nCoding Class Decorators\\n\\n| 1301\\n\\n\\x0c# 3.X and 2.X: global table\\n\\ninstances = {}\\n\\ndef singleton(aClass):                          # On @ decoration\\n    def onCall(*args, **kwargs):                # On instance creation\\n        if aClass not in instances:             # One dict entry per class\\n            instances[aClass] = aClass(*args, **kwargs)\\n        return instances[aClass]\\n    return onCall\\n\\nTo use this, decorate the classes for which you want to enforce a single-instance model\\n(for reference, all the code in this section is in the file singletons.py):\\n\\n@singleton                                      # Person = singleton(Person)\\nclass Person:                                   # Rebinds Person to onCall\\n     def __init__(self, name, hours, rate):     # onCall remembers Person\\n        self.name = name\\n        self.hours = hours\\n        self.rate = rate\\n     def pay(self):\\n        return self.hours * self.rate\\n\\n@singleton                                      # Spam = singleton(Spam)\\nclass Spam:                                     # Rebinds Spam to onCall\\n    def __init__(self, val):                    # onCall remembers Spam\\n        self.attr = val\\n\\nbob = Person(\\'Bob\\', 40, 10)                     # Really calls onCall\\nprint(bob.name, bob.pay())\\n\\nsue = Person(\\'Sue\\', 50, 20)                     # Same, single object\\nprint(sue.name, sue.pay())\\n\\nX = Spam(val=42)                                # One Person, one Spam\\nY = Spam(99)\\nprint(X.attr, Y.attr)\\n\\nNow, when the Person or Spam class is later used to create an instance, the wrapping\\nlogic layer provided by the decorator routes instance construction calls to onCall, which\\nin turn ensures a single instance per class, regardless of how many construction calls\\nare made. Here’s this code’s output (2.X prints extra tuple parentheses):\\n\\nc:\\\\code> python singletons.py\\nBob 400\\nBob 400\\n42 42\\n\\nCoding alternatives\\nInterestingly, you can code a more self-contained solution here if you’re able to use the\\nnonlocal statement (available in Python 3.X only) to change enclosing scope names, as\\ndescribed earlier—the following alternative achieves an identical effect, by using one\\nenclosing scope per class, instead of one global table entry per class. It works the same,\\n\\n1302 | Chapter 39:\\u2002Decorators\\n\\n\\x0cbut it does not depend on names in the global scope outside the decorator (note that\\nthe None check could use is instead of == here, but it’s a trivial test either way):\\n\\n# 3.X only: nonlocal\\n\\ndef singleton(aClass):                                   # On @ decoration\\n    instance = None\\n    def onCall(*args, **kwargs):                         # On instance creation\\n        nonlocal instance                                # 3.X and later nonlocal\\n        if instance == None:\\n            instance = aClass(*args, **kwargs)           # One scope per class\\n        return instance\\n    return onCall\\n\\nIn either Python 3.X or 2.X (2.6 and later), you can also code a self-contained solution\\nwith either function attributes or a class instead. The first of the following codes the\\nformer, leveraging the fact that there will be one onCall function per decoration—the\\nobject namespace serves the same role as an enclosing scope. The second uses one\\ninstance per decoration, rather than an enclosing scope, function object, or global table.\\nIn fact, the second relies on the same coding pattern that we will later see is a common\\ndecorator class blunder—here we want just one instance, but that’s not usually the case:\\n\\n# 3.X and 2.X: func attrs, classes (alternative codings)\\n\\ndef singleton(aClass):                                   # On @ decoration\\n    def onCall(*args, **kwargs):                         # On instance creation\\n        if onCall.instance == None:\\n            onCall.instance = aClass(*args, **kwargs)    # One function per class\\n        return onCall.instance\\n    onCall.instance = None\\n    return onCall\\n\\nclass singleton:\\n    def __init__(self, aClass):                          # On @ decoration\\n        self.aClass = aClass\\n        self.instance = None\\n    def __call__(self, *args, **kwargs):                 # On instance creation\\n        if self.instance == None:\\n            self.instance = self.aClass(*args, **kwargs) # One instance per class\\n        return self.instance\\n\\nTo make this decorator a fully general-purpose tool, choose one, store it in an import-\\nable module file, and indent the self-test code under a __name__ check—steps we’ll leave\\nas  suggested  exercise.  The  final  class-based  version  offers  a  portability  and  explicit\\noption, with extra structure that may better support later evolution, but OOP might\\nnot be warranted in all contexts.\\n\\nTracing Object Interfaces\\nThe singleton example of the prior section illustrated using class decorators to manage\\nall the instances of a class. Another common use case for class decorators augments\\nthe interface of each generated instance. Class decorators can essentially install on in-\\n\\nCoding Class Decorators\\n\\n| 1303\\n\\n\\x0cstances a wrapper or “proxy” logic layer that manages access to their interfaces in some\\nway.\\nFor example, in Chapter 31, the __getattr__ operator overloading method is shown as\\na way to wrap up entire object interfaces of embedded instances, in order to implement\\nthe delegation coding pattern. We saw similar examples in the managed attribute cov-\\nerage of the prior chapter. Recall that __getattr__ is run when an undefined attribute\\nname is fetched; we can use this hook to intercept method calls in a controller class\\nand propagate them to an embedded object.\\nFor reference, here’s the original nondecorator delegation example, working on two\\nbuilt-in type objects:\\n\\nclass Wrapper:\\n    def __init__(self, object):\\n        self.wrapped = object                    # Save object\\n    def __getattr__(self, attrname):\\n        print(\\'Trace:\\', attrname)                # Trace fetch\\n        return getattr(self.wrapped, attrname)   # Delegate fetch\\n\\n>>> x = Wrapper([1,2,3])                         # Wrap a list\\n>>> x.append(4)                                  # Delegate to list method\\nTrace: append\\n>>> x.wrapped                                    # Print my member\\n[1, 2, 3, 4]\\n\\n>>> x = Wrapper({\"a\": 1, \"b\": 2})                # Wrap a dictionary\\n>>> list(x.keys())                               # Delegate to dictionary method\\nTrace: keys                                      # Use list() in 3.X\\n[\\'a\\', \\'b\\']\\n\\nIn this code, the Wrapper class intercepts access to any of the wrapped object’s named\\nattributes, prints a trace message, and uses the getattr built-in to pass off the request\\nto the wrapped object. Specifically, it traces attribute accesses made outside the wrap-\\nped object’s class; accesses inside the wrapped object’s methods are not caught and\\nrun normally by design. This whole-interface model differs from the behavior of func-\\ntion decorators, which wrap up just one specific method.\\n\\nTracing interfaces with class decorators\\nClass decorators provide an alternative and convenient way to code this __getattr__\\ntechnique to wrap an entire interface. As of both 2.6 and 3.0, for example, the prior\\nclass example can be coded as a class decorator that triggers wrapped instance creation,\\ninstead of passing a premade instance into the wrapper’s constructor (also augmented\\nhere to support keyword arguments with **kargs and to count the number of accesses\\nmade to illustrate changeable state):\\n\\ndef Tracer(aClass):                                   # On @ decorator\\n    class Wrapper:\\n        def __init__(self, *args, **kargs):           # On instance creation\\n            self.fetches = 0\\n\\n1304 | Chapter 39:\\u2002Decorators\\n\\n\\x0c            self.wrapped = aClass(*args, **kargs)     # Use enclosing scope name\\n        def __getattr__(self, attrname):\\n            print(\\'Trace: \\' + attrname)               # Catches all but own attrs\\n            self.fetches += 1\\n            return getattr(self.wrapped, attrname)    # Delegate to wrapped obj\\n    return Wrapper\\n\\nif __name__ == \\'__main__\\':\\n\\n    @Tracer\\n    class Spam:                                  # Spam = Tracer(Spam)\\n        def display(self):                       # Spam is rebound to Wrapper\\n            print(\\'Spam!\\' * 8)\\n\\n    @Tracer\\n    class Person:                                # Person = Tracer(Person)\\n        def __init__(self, name, hours, rate):   # Wrapper remembers Person\\n            self.name = name\\n            self.hours = hours\\n            self.rate = rate\\n        def pay(self):                           # Accesses outside class traced\\n            return self.hours * self.rate        # In-method accesses not traced\\n\\n    food = Spam()                                # Triggers Wrapper()\\n    food.display()                               # Triggers __getattr__\\n    print([food.fetches])\\n\\n    bob = Person(\\'Bob\\', 40, 50)                  # bob is really a Wrapper\\n    print(bob.name)                              # Wrapper embeds a Person\\n    print(bob.pay())\\n\\n    print(\\'\\')\\n    sue = Person(\\'Sue\\', rate=100, hours=60)      # sue is a different Wrapper\\n    print(sue.name)                              # with a different Person\\n    print(sue.pay())\\n\\n    print(bob.name)                              # bob has different state\\n    print(bob.pay())\\n    print([bob.fetches, sue.fetches])            # Wrapper attrs not traced\\n\\nIt’s important to note that this is very different from the tracer decorator we met earlier\\n(despite the name!). In “Coding Function Decorators”, we looked at decorators that\\nenabled us to trace and time calls to a given function or method. In contrast, by inter-\\ncepting instance creation calls, the class decorator here allows us to trace an entire\\nobject interface—that is, accesses to any of the instance’s attributes.\\nThe following is the output produced by this code under both 3.X and 2.X (2.6 and\\nlater): attribute fetches on instances of both the Spam and Person classes invoke the\\n__getattr__  logic  in  the  Wrapper  class,  because  food  and  bob  are  really  instances  of\\nWrapper, thanks to the decorator’s redirection of instance creation calls:\\n\\nc:\\\\code> python interfacetracer.py\\nTrace: display\\n\\nCoding Class Decorators\\n\\n| 1305\\n\\n\\x0cSpam!Spam!Spam!Spam!Spam!Spam!Spam!Spam!\\n[1]\\nTrace: name\\nBob\\nTrace: pay\\n2000\\n\\nTrace: name\\nSue\\nTrace: pay\\n6000\\nTrace: name\\nBob\\nTrace: pay\\n2000\\n[4, 2]\\n\\nNotice how there is one Wrapper class with state retention per decoration, generated by\\nthe nested class statement in the Tracer function, and how each instance gets its own\\nfetches counter by virtue of generating a new  Wrapper instance. As we’ll see ahead,\\norchestrating this is trickier than you may expect.\\n\\nApplying class decorators to built-in types\\nAlso notice that the preceding decorates a user-defined class. Just like in the original\\nexample in Chapter 31, we can also use the decorator to wrap up a built-in type such\\nas a list, as long as we either subclass to allow decoration syntax or perform the deco-\\nration manually—decorator syntax requires a class statement for the @ line. In the\\nfollowing, x is really a Wrapper again due to the indirection of decoration:\\n\\n>>> from interfacetracer import Tracer\\n\\n>>> @Tracer\\n... class MyList(list): pass      # MyList = Tracer(MyList)\\n\\n>>> x = MyList([1, 2, 3])         # Triggers Wrapper()\\n>>> x.append(4)                   # Triggers __getattr__, append\\nTrace: append\\n>>> x.wrapped\\n[1, 2, 3, 4]\\n\\n>>> WrapList = Tracer(list)       # Or perform decoration manually\\n>>> x = WrapList([4, 5, 6])       # Else subclass statement required\\n>>> x.append(7)\\nTrace: append\\n>>> x.wrapped\\n[4, 5, 6, 7]\\n\\nThe decorator approach allows us to move instance creation into the decorator itself,\\ninstead of requiring a premade object to be passed in. Although this seems like a minor\\ndifference, it lets us retain normal instance creation syntax and realize all the benefits\\nof decorators in general. Rather than requiring all instance creation calls to route objects\\n\\n1306 | Chapter 39:\\u2002Decorators\\n\\n\\x0cthrough a wrapper manually, we need only augment class definitions with decorator\\nsyntax:\\n\\n@Tracer                                          # Decorator approach\\nclass Person: ...\\nbob = Person(\\'Bob\\', 40, 50)\\nsue = Person(\\'Sue\\', rate=100, hours=60)\\n\\nclass Person: ...                                # Nondecorator approach\\nbob = Wrapper(Person(\\'Bob\\', 40, 50))\\nsue = Wrapper(Person(\\'Sue\\', rate=100, hours=60))\\n\\nAssuming you will make more than one instance of a class, and want to apply the\\naugmentation to every instance of a class, decorators will generally be a net win in terms\\nof both code size and code maintenance.\\n\\nAttribute version skew note: The preceding tracer decorator works for\\nexplicitly  accessed  attribute  names  on  all  Pythons.  As  we  learned  in\\nChapter 38, Chapter 32, and elsewhere, though, __getattr__ intercepts\\nbuilt-ins’  implicit  accesses  to  operator  overloading  methods  like\\n__str__ and __repr__ in Python 2.X’s default classic classes, but not in\\n3.X’s new-style classes.\\n\\nIn Python 3.X’s classes, instances inherit defaults for some, but not all\\nof these names from the class (really, from the object superclass). More-\\nover, in 3.X, implicitly invoked attributes for built-in operations like\\nprinting and + are not routed through __getattr__, or its cousin, __get\\nattribute__.  In  new-style  classes,  built-ins  start  such  searches  at\\nclasses and skip the normal instance lookup entirely.\\n\\nHere, this means that the __getattr__ based tracing wrapper will auto-\\nmatically trace and propagate operator overloading calls for built-ins in\\n2.X as coded, but not in 3.X. To see this, display “x” directly at the end\\nof the preceding interactive session—in 2.X the attribute  __repr__ is\\ntraced and the list prints as expected, but in 3.X no trace occurs and the\\nlist prints using a default display for the Wrapper class:\\n\\n>>> x                                   # 2.X\\nTrace: __repr__\\n[4, 5, 6, 7]\\n>>> x                                   # 3.X\\n<interfacetracer.Tracer.<locals>.Wrapper object at 0x02946358>\\n\\nTo work the same in 3.X, operator overloading methods generally must\\nbe redefined redundantly in the wrapper class, either by hand, by tools,\\nor by definition in superclasses. We’ll see this at work again in a Pri\\nvate decorator later in this chapter—where we’ll also study ways to add\\nthe methods required of such code in 3.X.\\n\\nCoding Class Decorators\\n\\n| 1307\\n\\n\\x0cClass Blunders II: Retaining Multiple Instances\\nCuriously, the decorator function in this example can almost be coded as a class instead\\nof a function, with the proper operator overloading protocol. The following slightly\\nsimplified alternative works similarly because its __init__ is triggered when the @ dec-\\norator is applied to the class, and its __call__ is triggered when a subject class instance\\nis created. Our objects are really instances of Tracer this time, and we essentially just\\ntrade an enclosing scope reference for an instance attribute here:\\n\\nclass Tracer:\\n    def __init__(self, aClass):               # On @decorator\\n        self.aClass = aClass                  # Use instance attribute\\n    def __call__(self, *args):                # On instance creation\\n        self.wrapped = self.aClass(*args)     # ONE (LAST) INSTANCE PER CLASS!\\n        return self\\n    def __getattr__(self, attrname):\\n        print(\\'Trace: \\' + attrname)\\n        return getattr(self.wrapped, attrname)\\n\\n@Tracer                                       # Triggers __init__\\nclass Spam:                                   # Like: Spam = Tracer(Spam)\\n    def display(self):\\n        print(\\'Spam!\\' * 8)\\n\\n...\\nfood = Spam()                                 # Triggers __call__\\nfood.display()                                # Triggers __getattr__\\n\\nAs we saw in the abstract earlier, though, this class-only alternative handles multiple\\nclasses as before, but it won’t quite work for multiple instances of a given class: each\\ninstance construction call triggers __call__, which overwrites the prior instance. The\\nnet effect is that Tracer saves just one instance—the last one created. Experiment with\\nthis yourself to see how, but here’s an example of the problem:\\n\\n@Tracer\\nclass Person:                                 # Person = Tracer(Person)\\n    def __init__(self, name):                 # Wrapper bound to Person\\n        self.name = name\\n\\nbob = Person(\\'Bob\\')                           # bob is really a Wrapper\\nprint(bob.name)                               # Wrapper embeds a Person\\nSue = Person(\\'Sue\\')\\nprint(sue.name)                               # sue overwrites bob\\nprint(bob.name)                               # OOPS: now bob\\'s name is \\'Sue\\'!\\n\\nThis code’s output follows—because this tracer only has a single shared instance, the\\nsecond overwrites the first:\\n\\nTrace: name\\nBob\\nTrace: name\\nSue\\nTrace: name\\nSue\\n\\n1308 | Chapter 39:\\u2002Decorators\\n\\n\\x0cThe problem here is bad state retention—we make one decorator instance per class,\\nbut not per class instance, such that only the last instance is retained. The solution, as\\nin our prior class blunder for decorating methods, lies in abandoning class-based dec-\\norators.\\nThe earlier function-based Tracer version does work for multiple instances, because\\neach instance construction call makes a new Wrapper instance, instead of overwriting\\nthe state of a single shared Tracer instance; the original nondecorator version handles\\nmultiple instances correctly for the same reason. The moral here: decorators are not\\nonly arguably magical, they can also be incredibly subtle!\\n\\nDecorators Versus Manager Functions\\nRegardless of such subtleties, the Tracer class decorator example ultimately still relies\\non __getattr__ to intercept fetches on a wrapped and embedded instance object. As\\nwe saw earlier, all we’ve really accomplished is moving the instance creation call inside\\na class, instead of passing the instance into a manager function. With the original non-\\ndecorator tracing example, we would simply code instance creation differently:\\n\\nclass Spam:                                   # Nondecorator version\\n    ...                                       # Any class will do\\nfood = Wrapper(Spam())                        # Special creation syntax\\n\\n@Tracer\\nclass Spam:                                   # Decorator version\\n    ...                                       # Requires @ syntax at class\\nfood = Spam()                                 # Normal creation syntax\\n\\nEssentially, class decorators shift special syntax requirements from the instance creation\\ncall to the class statement itself. This is also true for the singleton example earlier in\\nthis section—rather than decorating a class and using normal instance creation calls,\\nwe could simply pass the class and its construction arguments into a manager function:\\n\\ninstances = {}\\ndef getInstance(aClass, *args, **kwargs):\\n    if aClass not in instances:\\n        instances[aClass] = aClass(*args, **kwargs)\\n    return instances[aClass]\\n\\nbob = getInstance(Person, \\'Bob\\', 40, 10)    # Versus: bob = Person(\\'Bob\\', 40, 10)\\n\\nAlternatively, we could use Python’s introspection facilities to fetch the class from an\\nalready created instance (assuming creating an initial instance is acceptable):\\n\\ninstances = {}\\ndef getInstance(object):\\n    aClass = object.__class__\\n    if aClass not in instances:\\n        instances[aClass] = object\\n    return instances[aClass]\\n\\nbob = getInstance(Person(\\'Bob\\', 40, 10))    # Versus: bob = Person(\\'Bob\\', 40, 10)\\n\\nCoding Class Decorators\\n\\n| 1309\\n\\n\\x0cThe same holds true for function decorators like the tracer we wrote earlier: rather than\\ndecorating a function with logic that intercepts later calls, we could simply pass the\\nfunction and its arguments into a manager that dispatches the call:\\n\\ndef func(x, y):                   # Nondecorator version\\n    ...                           # def tracer(func, args): ... func(*args)\\nresult = tracer(func, (1, 2))     # Special call syntax\\n\\n@tracer\\ndef func(x, y):                   # Decorator version\\n    ...                           # Rebinds name: func = tracer(func)\\nresult = func(1, 2)               # Normal call syntax\\n\\nManager function approaches like this place the burden of using special syntax on\\ncalls, instead of expecting decoration syntax at function and class definitions, but also\\nallow you to selectively apply augmentation on a call-by-call basis.\\n\\nWhy Decorators? (Revisited)\\nSo why did I just show you ways to not use decorators to implement singletons? As I\\nmentioned at the start of this chapter, decorators present us with tradeoffs. Although\\nsyntax matters, we all too often forget to ask the “why” questions when confronted\\nwith new tools. Now that we’ve seen how decorators actually work, let’s step back for\\na minute to glimpse the big picture here before moving on to more code.\\nLike most language features, decorators have both pros and cons. For example, in the\\nnegatives column, decorators may suffer from three potential drawbacks, which can\\nvary per decorator type:\\n\\nType changes\\n\\nAs we’ve seen, when wrappers are inserted, a decorated function or class does not\\nretain its original type—it is rebound to a wrapper (proxy) object, which might\\nmatter in programs that use object names or test object types. In the singleton\\nexample, both the decorator and manager function approaches retain the original\\nclass type for instances; in the tracer code, neither approach does, because wrap-\\npers are required. Of course, you should avoid type checks in a polymorphic lan-\\nguage like Python anyhow, but there are exceptions to most rules.\\n\\nExtra calls\\n\\nA wrapping layer added by decoration incurs the additional performance cost of\\nan extra call each time the decorated object is invoked—calls are relatively time-\\nexpensive operations, so decoration wrappers can make a program slower. In the\\ntracer code, both approaches require each attribute to be routed through a wrapper\\nlayer; the singleton example avoids extra calls by retaining the original class type.\\n\\nAll or nothing\\n\\nBecause decorators augment a function or class, they generally apply to every later\\ncall to the decorated object. That ensures uniform deployment, but can also be a\\n\\n1310 | Chapter 39:\\u2002Decorators\\n\\n\\x0cnegative if you’d rather apply an augmentation more selectively on a call-by-call\\nbasis.\\n\\nThat said, none of these is a very serious issue. For most programs, decorations’ uni-\\nformity is an asset, the type difference is unlikely to matter, and the speed hit of the\\nextra  calls  will  be  insignificant.  Furthermore,  the  latter  of  these  occurs  only  when\\nwrappers are used, can often be negated if we simply remove the decorator when op-\\ntimal performance is required, and is also incurred by nondecorator solutions that add\\nwrapping logic (including metaclasses, as we’ll see in Chapter 40).\\nConversely, as we saw at the start of this chapter, decorators have three main advan-\\ntages. Compared to the manager (a.k.a. “helper”) function solutions of the prior sec-\\ntion, decorators offer:\\n\\nExplicit syntax\\n\\nDecorators make augmentation explicit and obvious. Their @ syntax is easier to\\nrecognize than special code in calls that may appear anywhere in a source file—in\\nour singleton and tracer examples, for instance, the decorator lines seem more\\nlikely to be noticed than extra code at calls would be. Moreover, decorators allow\\nfunction and instance creation calls to use normal syntax familiar to all Python\\nprogrammers.\\nCode maintenance\\n\\nDecorators avoid repeated augmentation code at each function or class call. Be-\\ncause they appear just once, at the definition of the class or function itself, they\\nobviate redundancy and simplify future code maintenance. For our singleton and\\ntracer cases, we need to use special code at each call to use a manager function\\napproach—extra work is required both initially and for any modifications that\\nmust be made in the future.\\n\\nConsistency\\n\\nDecorators make it less likely that a programmer will forget to use required wrap-\\nping logic. This derives mostly from the two prior advantages—because decoration\\nis explicit and appears only once, at the decorated objects themselves, decorators\\npromote more consistent and uniform API usage than special code that must be\\nincluded at each call. In the singleton example, for instance, it would be easy to\\nforget to route all class creation calls through special code, which would subvert\\nthe singleton management altogether.\\n\\nDecorators also promote code encapsulation to reduce redundancy and minimize future\\nmaintenance effort; although other code structuring tools do too, decorators add ex-\\nplicit structure that makes this natural for augmentation tasks.\\nNone of these benefits completely requires decorator syntax to be achieved, though,\\nand decorator usage is ultimately a stylistic choice. That said, most programmers find\\nthem to be a net win, especially as a tool for using libraries and APIs correctly.\\n\\nCoding Class Decorators\\n\\n| 1311\\n\\n\\x0cHistoric anecdote: I can recall similar arguments being made both for\\nand against constructor functions in classes—prior to the introduction\\nof __init__ methods, programmers achieved the same effect by running\\nan  instance  through  a  method  manually  when  creating  it  (e.g.,\\nX=Class().init()). Over time, though, despite being fundamentally a\\nstylistic choice, the  __init__ syntax came to be universally preferred\\nbecause it was more explicit, consistent, and maintainable. Although\\nyou should be the judge, decorators seem to bring many of the same\\nassets to the table.\\n\\nManaging Functions and Classes Directly\\nMost of our examples in this chapter have been designed to intercept function and\\ninstance creation calls. Although this is typical for decorators, they are not limited to\\nthis role. Because decorators work by running new functions and classes through dec-\\norator code, they can also be used to manage function and class objects themselves,\\nnot just later calls made to them.\\nImagine, for example, that you require methods or classes used by an application to be\\nregistered to an API for later processing (perhaps that API will call the objects later, in\\nresponse to events). Although you could provide a registration function to be called\\nmanually after the objects are defined, decorators make your intent more explicit.\\nThe following simple implementation of this idea defines a decorator that can be ap-\\nplied to both functions and classes, to add the object to a dictionary-based registry.\\nBecause it returns the object itself instead of a wrapper, it does not intercept later calls:\\n\\n# Registering decorated objects to an API\\nfrom __future__ import print_function # 2.X\\n\\nregistry = {}\\ndef register(obj):                          # Both class and func decorator\\n    registry[obj.__name__] = obj            # Add to registry\\n    return obj                              # Return obj itself, not a wrapper\\n\\n@register\\ndef spam(x):\\n    return(x ** 2)                          # spam = register(spam)\\n\\n@register\\ndef ham(x):\\n    return(x ** 3)\\n\\n@register\\nclass Eggs:                                 # Eggs = register(Eggs)\\n    def __init__(self, x):\\n        self.data = x ** 4\\n    def __str__(self):\\n        return str(self.data)\\n\\n1312 | Chapter 39:\\u2002Decorators\\n\\n\\x0cprint(\\'Registry:\\')\\nfor name in registry:\\n    print(name, \\'=>\\', registry[name], type(registry[name]))\\n\\nprint(\\'\\\\nManual calls:\\')\\nprint(spam(2))                              # Invoke objects manually\\nprint(ham(2))                               # Later calls not intercepted\\nX = Eggs(2)\\nprint(X)\\n\\nprint(\\'\\\\nRegistry calls:\\')\\nfor name in registry:\\n    print(name, \\'=>\\', registry[name](2))    # Invoke from registry\\n\\nWhen this code is run the decorated objects are added to the registry by name, but they\\nstill work as originally coded when they’re called later, without being routed through\\na wrapper layer. In fact, our objects can be run both manually and from inside the\\nregistry table:\\n\\nc:\\\\code> py −3 registry-deco.py\\nRegistry:\\nspam => <function spam at 0x02969158> <class \\'function\\'>\\nham => <function ham at 0x02969400> <class \\'function\\'>\\nEggs => <class \\'__main__.Eggs\\'> <class \\'type\\'>\\n\\nManual calls:\\n4\\n8\\n16\\n\\nRegistry calls:\\nspam => 4\\nham => 8\\nEggs => 16\\n\\nA user interface might use this technique, for example, to register callback handlers for\\nuser actions. Handlers might be registered by function or class name, as done here, or\\ndecorator arguments could be used to specify the subject event; an extra def statement\\nenclosing our decorator could be used to retain such arguments for use on decoration.\\nThis example is artificial, but its technique is very general. For example, function dec-\\norators might also be used to process function attributes, and class decorators might\\ninsert new class attributes, or even new methods, dynamically. Consider the following\\nfunction decorators—they assign function attributes to record information for later use\\nby an API, but they do not insert a wrapper layer to intercept later calls:\\n\\n# Augmenting decorated objects directly\\n\\n>>> def decorate(func):\\n        func.marked = True          # Assign function attribute for later use\\n        return func\\n\\n>>> @decorate\\n    def spam(a, b):\\n\\nManaging Functions and Classes Directly | 1313\\n\\n\\x0c        return a + b\\n\\n>>> spam.marked\\nTrue\\n\\n>>> def annotate(text):             # Same, but value is decorator argument\\n        def decorate(func):\\n            func.label = text\\n            return func\\n        return decorate\\n\\n>>> @annotate(\\'spam data\\')\\n    def spam(a, b):                 # spam = annotate(...)(spam)\\n        return a + b\\n\\n>>> spam(1, 2), spam.label\\n(3, \\'spam data\\')\\n\\nSuch decorators augment functions and classes directly, without catching later calls to\\nthem. We’ll see more examples of class decorations managing classes directly in the\\nnext chapter, because this turns out to encroach on the domain of metaclasses; for the\\nremainder of this chapter, let’s turn to two larger case studies of decorators at work.\\n\\nExample: “Private” and “Public” Attributes\\nThe final two sections of this chapter present larger examples of decorator use. Both\\nare  presented  with  minimal  description,  partly  because  this  chapter  has  hit  its  size\\nlimits, but mostly because you should already understand decorator basics well enough\\nto study these on your own. Being general-purpose tools, these examples give us a\\nchance to see how decorator concepts come together in more useful code.\\n\\nImplementing Private Attributes\\nThe following class decorator implements a Private declaration for class instance at-\\ntributes—that is, attributes stored on an instance, or inherited from one of its classes.\\nIt disallows fetch and change access to such attributes from outside the decorated class,\\nbut still allows the class itself to access those names freely within its own methods. It’s\\nnot exactly C++ or Java, but it provides similar access control as an option in Python.\\nWe  saw  an  incomplete  first-cut  implementation  of  instance  attribute  privacy  for\\nchanges only in Chapter 30. The version here extends this concept to validate attribute\\nfetches too, and it uses delegation instead of inheritance to implement the model. In\\nfact, in a sense this is just an extension to the attribute tracer class decorator we met\\nearlier.\\nAlthough this example utilizes the new syntactic sugar of class decorators to code at-\\ntribute  privacy,  its  attribute  interception  is  ultimately  still  based  upon  the  __get\\nattr__ and __setattr__ operator overloading methods we met in prior chapters. When\\n\\n1314 | Chapter 39:\\u2002Decorators\\n\\n\\x0ca private attribute access is detected, this version uses the raise statement to raise an\\nexception, along with an error message; the exception may be caught in a try or allowed\\nto terminate the script.\\nHere is the code, along with a self test at the bottom of the file. It will work under both\\nPython  3.X  and  2.X  (2.6  and  later)  because  it  employs  version-neutral  print  and\\nraise syntax, though as coded it catches built-ins’ dispatch to operator overloading\\nmethod attributes in 2.X only (more on this in a moment):\\n\\n\"\"\"\\nFile access1.py (3.X + 2.X)\\n\\nPrivacy for attributes fetched from class instances.\\nSee self-test code at end of file for a usage example.\\n\\nDecorator same as: Doubler = Private(\\'data\\', \\'size\\')(Doubler).\\nPrivate returns onDecorator, onDecorator returns onInstance,\\nand each onInstance instance embeds a Doubler instance.\\n\"\"\"\\n\\ntraceMe = False\\ndef trace(*args):\\n    if traceMe: print(\\'[\\' + \\' \\'.join(map(str, args)) + \\']\\')\\n\\ndef Private(*privates):                              # privates in enclosing scope\\n    def onDecorator(aClass):                         # aClass in enclosing scope\\n        class onInstance:                            # wrapped in instance attribute\\n            def __init__(self, *args, **kargs):\\n                self.wrapped = aClass(*args, **kargs)\\n\\n            def __getattr__(self, attr):             # My attrs don\\'t call getattr\\n                trace(\\'get:\\', attr)                  # Others assumed in wrapped\\n                if attr in privates:\\n                    raise TypeError(\\'private attribute fetch: \\' + attr)\\n                else:\\n                    return getattr(self.wrapped, attr)\\n\\n            def __setattr__(self, attr, value):             # Outside accesses\\n                trace(\\'set:\\', attr, value)                  # Others run normally\\n                if attr == \\'wrapped\\':                       # Allow my attrs\\n                    self.__dict__[attr] = value             # Avoid looping\\n                elif attr in privates:\\n                    raise TypeError(\\'private attribute change: \\' + attr)\\n                else:\\n                    setattr(self.wrapped, attr, value)      # Wrapped obj attrs\\n        return onInstance                                   # Or use __dict__\\n    return onDecorator\\n\\nif __name__ == \\'__main__\\':\\n    traceMe = True\\n\\n    @Private(\\'data\\', \\'size\\')                   # Doubler = Private(...)(Doubler)\\n    class Doubler:\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1315\\n\\n\\x0c        def __init__(self, label, start):\\n            self.label = label                 # Accesses inside the subject class\\n            self.data  = start                 # Not intercepted: run normally\\n        def size(self):\\n            return len(self.data)              # Methods run with no checking\\n        def double(self):                      # Because privacy not inherited\\n            for i in range(self.size()):\\n                self.data[i] = self.data[i] * 2\\n        def display(self):\\n            print(\\'%s => %s\\' % (self.label, self.data))\\n\\n    X = Doubler(\\'X is\\', [1, 2, 3])\\n    Y = Doubler(\\'Y is\\', [-10, −20, −30])\\n\\n    # The following all succeed\\n    print(X.label)                             # Accesses outside subject class\\n    X.display(); X.double(); X.display()       # Intercepted: validated, delegated\\n    print(Y.label)\\n    Y.display(); Y.double()\\n    Y.label = \\'Spam\\'\\n    Y.display()\\n\\n    # The following all fail properly\\n    \"\"\"\\n    print(X.size())          # prints \"TypeError: private attribute fetch: size\"\\n    print(X.data)\\n    X.data = [1, 1, 1]\\n    X.size = lambda S: 0\\n    print(Y.data)\\n    print(Y.size())\\n    \"\"\"\\n\\nWhen traceMe is True, the module file’s self-test code produces the following output.\\nNotice how the decorator catches and validates both attribute fetches and assignments\\nrun outside of the wrapped class, but does not catch attribute accesses inside the class\\nitself:\\n\\n c:\\\\code> py −3 access1.py\\n[set: wrapped <__main__.Doubler object at 0x00000000029769B0>]\\n[set: wrapped <__main__.Doubler object at 0x00000000029769E8>]\\n[get: label]\\nX is\\n[get: display]\\nX is => [1, 2, 3]\\n[get: double]\\n[get: display]\\nX is => [2, 4, 6]\\n[get: label]\\nY is\\n[get: display]\\nY is => [-10, −20, −30]\\n[get: double]\\n[set: label Spam]\\n[get: display]\\nSpam => [−20, −40, −60]\\n\\n1316 | Chapter 39:\\u2002Decorators\\n\\n\\x0cImplementation Details I\\nThis code is a bit complex, and you’re probably best off tracing through it on your own\\nto see how it works. To help you study, though, here are a few highlights worth men-\\ntioning.\\n\\nInheritance versus delegation\\nThe  first-cut  privacy  example  shown  in  Chapter  30  used  inheritance  to  mix  in  a\\n__setattr__ to catch accesses. Inheritance makes this difficult, however, because dif-\\nferentiating between accesses from inside or outside the class is not straightforward\\n(inside access should be allowed to run normally, and outside access should be restric-\\nted). To work around this, the Chapter 30 example requires inheriting classes to use\\n__dict__ assignments to set attributes—an incomplete solution at best.\\nThe version here uses delegation (embedding one object inside another) instead of in-\\nheritance; this pattern is better suited to our task, as it makes it much easier to distin-\\nguish between accesses inside and outside of the subject class. Attribute accesses from\\noutside the subject class are intercepted by the wrapper layer’s overloading methods\\nand delegated to the class if valid. Accesses inside the class itself (i.e., through self\\nwithin its methods’ code) are not intercepted and are allowed to run normally without\\nchecks, because privacy is not inherited in this version.\\n\\nDecorator arguments\\nThe class decorator used here accepts any number of arguments, to name private at-\\ntributes.  What  really  happens,  though,  is  that  the  arguments  are  passed  to  the  Pri\\nvate function, and Private returns the decorator function to be applied to the subject\\nclass. That is, the arguments are used before decoration ever occurs; Private returns\\nthe decorator, which in turn “remembers” the privates list as an enclosing scope ref-\\nerence.\\n\\nState retention and enclosing scopes\\nSpeaking of enclosing scopes, there are actually three levels of state retention at work\\nin this code:\\n\\n• The arguments to Private are used before decoration occurs and are retained as\\n\\nan enclosing scope reference for use in both onDecorator and onInstance.\\n\\n• The class argument to onDecorator is used at decoration time and is retained as an\\n\\nenclosing scope reference for use at instance construction time.\\n\\n• The  wrapped  instance  object  is  retained  as  an  instance  attribute  in  the  onIn\\nstance proxy object, for use when attributes are later accessed from outside the\\nclass.\\n\\nThis all works fairly naturally, given Python’s scope and namespace rules.\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1317\\n\\n\\x0cUsing __dict__ and __slots__ (and other virtual names)\\nThe __setattr__ method in this code relies on an instance object’s __dict__ attribute\\nnamespace dictionary in order to set onInstance’s own wrapped attribute. As we learned\\nin the prior chapter, this method cannot assign an attribute directly without looping.\\nHowever, it uses the setattr built-in instead of __dict__ to set attributes in the wrap-\\nped object itself. Moreover, getattr is used to fetch attributes in the wrapped object,\\nsince they may be stored in the object itself or inherited by it.\\nBecause of that, this code will work for most classes—including those with “virtual”\\nclass-level attributes based on slots, properties, descriptors, and even __getattr__ and\\nits ilk. By assuming a namespace dictionary for itself only and using storage-neutral\\ntools for the wrapped object, the wrapper class avoids limitations inherent in other\\ntools.\\nFor example, you may recall from Chapter 32 that new-style classes with __slots__\\nmay not store attributes in a __dict__ (and in fact may not even have one of these at\\nall). However, because we rely on a __dict__ only at the onInstance level here, and not\\nin the wrapped instance, this concern does not apply. In addition, because setattr and\\ngetattr apply to attributes based on both __dict__ and __slots__, our decorator applies\\nto classes using either storage scheme. By the same reasoning, the decorator also applies\\nto new-style properties and similar tools: delegated names will be looked up anew in\\nthe wrapped instance, irrespective of attributes of the decorator proxy object itself.\\n\\nGeneralizing for Public Declarations, Too\\nNow that we have a Private implementation, it’s straightforward to generalize the code\\nto allow for Public declarations too—they are essentially the inverse of Private decla-\\nrations, so we need only negate the inner test. The example listed in this section allows\\na class to use decorators to define a set of either Private or Public instance attributes\\n—attributes of any kind stored on an instance or inherited from its classes—with the\\nfollowing semantics:\\n\\n• Private declares attributes of a class’s instances that cannot be fetched or assigned,\\nexcept from within the code of the class’s methods. That is, any name declared\\nPrivate cannot be accessed from outside the class, while any name not declared\\nPrivate can be freely fetched or assigned from outside the class.\\n\\n• Public declares attributes of a class’s instances that can be fetched or assigned from\\nboth outside the class and within the class’s methods. That is, any name declared\\nPublic can be freely accessed anywhere, while any name not declared Public cannot\\nbe accessed from outside the class.\\n\\nPrivate and Public declarations are intended to be mutually exclusive: when using\\nPrivate, all undeclared names are considered Public, and when using Public, all un-\\ndeclared names are considered Private. They are essentially inverses, though unde-\\nclared names not created by a class’s methods behave slightly differently—new names\\n\\n1318 | Chapter 39:\\u2002Decorators\\n\\n\\x0ccan be assigned and thus created outside the class under Private (all undeclared names\\nare accessible), but not under Public (all undeclared names are inaccessible).\\nAgain, study this code on your own to get a feel for how this works. Notice that this\\nscheme adds an additional fourth level of state retention at the top, beyond that de-\\nscribed in the preceding section: the test functions used by the lambdas are saved in an\\nextra enclosing scope. This example is coded to run under either Python 3.X or 2.X\\n(2.6 or later), though it comes with a caveat when run under 3.X (explained briefly in\\nthe file’s docstring and expanded on after the code):\\n\\n\"\"\"\\nFile access2.py (3.X + 2.X)\\nClass decorator with Private and Public attribute declarations.\\n\\nControls external access to attributes stored on an instance, or\\nInherited by it from its classes. Private declares attribute names\\nthat cannot be fetched or assigned outside the decorated class,\\nand Public declares all the names that can.\\n\\nCaveat: this works in 3.X for explicitly named attributes only: __X__\\noperator overloading methods implicitly run for built-in operations\\ndo not trigger either __getattr__ or __getattribute__ in new-style\\nclasses.  Add __X__ methods here to intercept and delegate built-ins.\\n\"\"\"\\n\\ntraceMe = False\\ndef trace(*args):\\n    if traceMe: print(\\'[\\' + \\' \\'.join(map(str, args)) + \\']\\')\\n\\ndef accessControl(failIf):\\n    def onDecorator(aClass):\\n        class onInstance:\\n            def __init__(self, *args, **kargs):\\n                self.__wrapped = aClass(*args, **kargs)\\n\\n            def __getattr__(self, attr):\\n                trace(\\'get:\\', attr)\\n                if failIf(attr):\\n                    raise TypeError(\\'private attribute fetch: \\' + attr)\\n                else:\\n                    return getattr(self.__wrapped, attr)\\n\\n            def __setattr__(self, attr, value):\\n                trace(\\'set:\\', attr, value)\\n                if attr == \\'_onInstance__wrapped\\':\\n                    self.__dict__[attr] = value\\n                elif failIf(attr):\\n                    raise TypeError(\\'private attribute change: \\' + attr)\\n                else:\\n                    setattr(self.__wrapped, attr, value)\\n        return onInstance\\n    return onDecorator\\n\\ndef Private(*attributes):\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1319\\n\\n\\x0c    return accessControl(failIf=(lambda attr: attr in attributes))\\n\\ndef Public(*attributes):\\n    return accessControl(failIf=(lambda attr: attr not in attributes))\\n\\nSee the prior example’s self-test code for a usage example. Here’s a quick look at these\\nclass decorators in action at the interactive prompt; they work the same in 2.X and 3.X\\nfor attributes referenced by explicit name like those tested here. As advertised, non-\\nPrivate or Public names can be fetched and changed from outside the subject class,\\nbut Private or non-Public names cannot:\\n>>> from access2 import Private, Public\\n\\n>>> @Private(\\'age\\')                             # Person = Private(\\'age\\')(Person)\\n    class Person:                               # Person = onInstance with state\\n        def __init__(self, name, age):\\n            self.name = name\\n            self.age  = age                     # Inside accesses run normally\\n\\n>>> X = Person(\\'Bob\\', 40)\\n>>> X.name                                      # Outside accesses validated\\n\\'Bob\\'\\n>>> X.name = \\'Sue\\'\\n>>> X.name\\n\\'Sue\\'\\n>>> X.age\\nTypeError: private attribute fetch: age\\n>>> X.age = \\'Tom\\'\\nTypeError: private attribute change: age\\n\\n>>> @Public(\\'name\\')\\n    class Person:\\n        def __init__(self, name, age):\\n            self.name = name\\n            self.age  = age\\n\\n>>> X = Person(\\'bob\\', 40)                       # X is an onInstance\\n>>> X.name                                      # onInstance embeds Person\\n\\'bob\\'\\n>>> X.name = \\'Sue\\'\\n>>> X.name\\n\\'Sue\\'\\n>>> X.age\\nTypeError: private attribute fetch: age\\n>>> X.age = \\'Tom\\'\\nTypeError: private attribute change: age\\n\\nImplementation Details II\\nTo help you analyze the code, here are a few final notes on this version. Since this is\\njust a generalization of the preceding section’s version, the implementation notes there\\napply here as well.\\n\\n1320 | Chapter 39:\\u2002Decorators\\n\\n\\x0cUsing __X pseudoprivate names\\nBesides generalizing, this version also makes use of Python’s __X pseudoprivate name\\nmangling feature (which we met in Chapter 31) to localize the wrapped attribute to the\\nproxy control class, by automatically prefixing it with this class’s name. This avoids\\nthe prior version’s risk for collisions with a wrapped attribute that may be used by the\\nreal, wrapped class, and it’s useful in a general tool like this. It’s not quite “privacy,”\\nthough, because the mangled version of the name can be used freely outside the class.\\nNotice that we also have to use the fully expanded name string—\\'_onInstance__wrap\\nped\\'— as a test value in __setattr__, because that’s what Python changes it to.\\n\\nBreaking privacy\\nAlthough this example does implement access controls for attributes of an instance and\\nits classes, it is possible to subvert these controls in various ways—for instance, by\\ngoing through the expanded version of the wrapped attribute explicitly (bob.pay might\\nnot work, but the fully mangled bob._onInstance__wrapped.pay could!). If you have to\\nexplicitly try to do so, though, these controls are probably sufficient for normal in-\\ntended use. Of course, privacy controls can generally be subverted in other languages\\nif you try hard enough (#define private public may work in some C++ implementa-\\ntions, too). Although access controls can reduce accidental changes, much of this is up\\nto programmers in any language; whenever source code may be changed, airtight access\\ncontrol will always be a bit of a pipe dream.\\n\\nDecorator tradeoffs\\nWe could again achieve the same results without decorators, by using manager func-\\ntions or coding the name rebinding of decorators manually; the decorator syntax, how-\\never, makes this consistent and a bit more obvious in the code. The chief potential\\ndownsides of this and any other wrapper-based approach are that attribute access in-\\ncurs an extra call, and instances of decorated classes are not really instances of the\\noriginal decorated class—if you test their type with X.__class__ or isinstance(X, C),\\nfor example, you’ll find that they are instances of the wrapper class. Unless you plan\\nto do introspection on objects’ types, though, the type issue is probably irrelevant, and\\nthe extra call may apply mostly to development time; as we’ll see later, there are ways\\nto remove decorations automatically if desired.\\n\\nOpen Issues\\nAs is, this example works as planned under both Python 2.X and 3.X for methods called\\nexplicitly by name. As with most software, though, there is always room for improve-\\nment. Most notably, this tool turns in mixed performance on operator overloading\\nmethods if they are used by client classes.\\nAs coded, the proxy class is a classic class when run under 2.X, but a new-style class\\nwhen run by 3.X. As such, the code supports any client class in 2.X, but in 3.X fails to\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1321\\n\\n\\x0cvalidate or delegate operator overloading methods dispatched implicitly by built-in\\noperations, unless they are redefined in the proxy. Clients that do not use operator\\noverloading are fully supported, but others may require additional code in 3.X.\\nImportantly, this is not a new-style class issue here, it’s a Python version issue—the\\nsame code runs differently and fails in 3.X only. Because the nature of the wrapped\\nobject’s class is irrelevant to the proxy, we are concerned only with the proxy’s own\\ncode, which works under 2.X but not 3.X.\\nWe’ve met this issue a few times already in this book, but let’s take a quick look at its\\nimpact on the very realistic code we’ve written here, and explore a workaround to it.\\n\\nCaveat: Implicitly run operator overloading methods fail to delegate under 3.X\\nLike all delegation-based classes that use __getattr__, this decorator works cross-ver-\\nsion for normally named or explicitly called attributes only. When run implicitly by\\nbuilt-in operations, operator overloading methods like __str__ and __add__ work dif-\\nferently for new-style classes. Because this code is interpreted as a new-style class in\\n3.X only, such operations fail to reach an embedded object that defines them when run\\nunder this Python line as currently coded.\\nAs we learned in the prior chapter, built-in operations look for operator overloading\\nnames in instances for classic classes, but not for new-style classes—for the latter, they\\nskip the instance entirely and begin the search for such methods in classes (technically,\\nin the namespace dictionaries of all classes in the instance’s tree). Hence, the __X__\\noperator overloading methods implicitly run for built-in operations do not trigger either\\n__getattr__ or __getattribute__ in new-style classes; because such attribute fetches\\nskip our onInstance class’s __getattr__ altogether, they cannot be validated or dele-\\ngated.\\nOur decorator’s class is not coded as explicitly new-style (by deriving from object), so\\nit will catch operator overloading methods if run under 2.X as a default classic class.\\nIn 3.X, though, because all classes are new-style automatically (and by mandate), such\\nmethods will fail if they are implemented by the embedded object—because they are\\nnot caught by the proxy, they won’t be passed on.\\nThe most direct workaround in 3.X is to redefine redundantly in onInstance all the\\noperator overloading methods that can possibly be used in wrapped objects. Such extra\\nmethods can be added by hand, by tools that partly automate the task (e.g., with class\\ndecorators or the metaclasses discussed in the next chapter), or by definition in reusable\\nsuperclasses. Though tedious—and code-intensive enough to largely omit here—we’ll\\nexplore approaches to satisfying this 3.X-only requirement in a moment.\\nFirst, though, to see the difference for yourself, try applying the decorator to a class\\nthat uses operator overloading methods under 2.X; validations work as before, and\\nboth the __str__ method used by printing and the __add__ method run for + invoke the\\n\\n1322 | Chapter 39:\\u2002Decorators\\n\\n\\x0cdecorator’s __getattr__ and hence wind up being validated and delegated to the subject\\nPerson object correctly:\\n\\nC:\\\\code> c:\\\\python27\\\\python\\n>>> from access2 import Private\\n>>> @Private(\\'age\\')\\n    class Person:\\n        def __init__(self):\\n            self.age = 42\\n        def __str__(self):\\n            return \\'Person: \\' + str(self.age)\\n        def __add__(self, yrs):\\n            self.age += yrs\\n\\n>>> X = Person()\\n>>> X.age                                   # Name validations fail correctly\\nTypeError: private attribute fetch: age\\n>>> print(X)                                # __getattr__ => runs Person.__str__\\nPerson: 42\\n>>> X + 10                                  # __getattr__ => runs Person.__add__\\n>>> print(X)                                # __getattr__ => runs Person.__str__\\nPerson: 52\\n\\nWhen  the  same  code  is  run  under  Python  3.X,  though,  the  implicitly  invoked\\n__str__ and __add__ skip the decorator’s __getattr__ and look for definitions in or\\nabove the decorator class itself; print winds up finding the default display inherited\\nfrom the class type (technically, from the implied object superclass in 3.X), and + gen-\\nerates an error because no default is inherited:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>> from access2 import Private\\n>>> @Private(\\'age\\')\\n    class Person:\\n        def __init__(self):\\n            self.age = 42\\n        def __str__(self):\\n            return \\'Person: \\' + str(self.age)\\n        def __add__(self, yrs):\\n            self.age += yrs\\n\\n>>> X = Person()                            # Name validations still work\\n>>> X.age                                   # But 3.X fails to delegate built-ins!\\nTypeError: private attribute fetch: age\\n>>> print(X)\\n<access2.accessControl.<locals>.onDecorator.<locals>.onInstance object at ...etc>\\n>>> X + 10\\nTypeError: unsupported operand type(s) for +: \\'onInstance\\' and \\'int\\'\\n>>> print(X)\\n<access2.accessControl.<locals>.onDecorator.<locals>.onInstance object at ...etc>\\n\\nStrangely, this occurs only for dispatch from built-in operations; explicit direct calls to\\noverload methods are routed to __getattr__, though clients using operator overloading\\ncan’t be expected to do the same:\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1323\\n\\n\\x0c>>> X.__add__(10)                           # Though calls by name work normally\\n>>> X._onInstance__wrapped.age              # Break privacy to view result...\\n52\\n\\nIn other words, this is a matter of built-in operations versus explicit calls; it has little to\\ndo with the actual names of the methods involved. Just for built-in operations, Python\\nskips a step for 3.X’s new-style classes.\\nUsing the alternative __getattribute__ method won’t help here—although it is defined\\nto catch every attribute reference (not just undefined names), it is also not run by built-\\nin operations. Python’s property feature, which we met in Chapter 38, won’t help di-\\nrectly  here  either;  recall  that  properties  are  automatically  run  code  associated  with\\nspecific attributes defined when a class is written, and are not designed to handle arbi-\\ntrary attributes in wrapped objects.\\n\\nApproaches to redefining operator overloading methods for 3.X\\nAs mentioned earlier, the most straightforward solution under 3.X is to redundantly\\nredefine operator overloading names that may appear in embedded objects in delega-\\ntion-based classes like our decorator. This isn’t ideal because it creates some code re-\\ndundancy, especially compared to 2.X solutions. However, it isn’t an impossibly major\\ncoding effort; can be automated to some extent with tools or superclasses; suffices to\\nmake our decorator work in 3.X; and may allow operator overloading names to be\\ndeclared Private or Public too, assuming overloading methods trigger the failIf test\\ninternally.\\nInline definition.\\nFor  instance,  the  following  is  an  inline  redefinition  approach—add\\nmethod redefinitions to the proxy for every operator overloading method a wrapped\\nobject may define itself, to catch and delegate. We’re adding just four operation inter-\\nceptors to illustrate, but others are similar (new code is in bold font here):\\n\\ndef accessControl(failIf):\\n    def onDecorator(aClass):\\n        class onInstance:\\n            def __init__(self, *args, **kargs):\\n                self.__wrapped = aClass(*args, **kargs)\\n\\n            # Intercept and delegate built-in operations specifically\\n            def __str__(self):\\n                return str(self.__wrapped)\\n            def __add__(self, other):\\n                return self.__wrapped + other          # Or getattr(x, \\'__add__\\')(y)\\n            def __getitem__(self, index):\\n                return self.__wrapped[index]           # If needed\\n            def __call__(self, *args, **kargs):\\n                return self.__wrapped(*args, **kargs)  # If needed\\n            # plus any others needed\\n\\n            # Intercept and delegate by-name attribute access generically\\n            def __getattr__(self, attr): ...\\n            def __setattr__(self, attr, value): ...\\n\\n1324 | Chapter 39:\\u2002Decorators\\n\\n\\x0c        return onInstance\\n    return onDecorator\\n\\nMix-in superclasses.\\nAlternatively, these methods can be inserted by a common superclass\\n—given that there are dozens of such methods, an external class may be better suited\\nto the task, especially if it is general enough to be used in any such interface proxy class.\\nEither of the following mix-in class schemes (among likely others) suffice to catch and\\ndelegate built-ins operations:\\n\\n• The  first  catches  built-ins  and  forcibly  reroutes  down  to  the  subclass  __get\\nattr__. It requires that operator overloading names be public per the decorator’s\\nspecifications, but built-in operation calls will work the same as both explicit name\\ncalls and 2.X’s classic classes.\\n\\n• The second catches built-ins and reroutes to the wrapped object directly. It requires\\naccess to and assumes a proxy attribute named _wrapped giving access to the em-\\nbedded object—which is less than ideal because it precludes wrapped objects from\\nusing the same name and creates a subclass dependency, but better than using the\\nmangled and class-specific _onInstance__wrapped, and no worse than a similarly\\nnamed method.\\n\\nLike the inline approach, both of these mix-ins also require one method per built-in\\noperation in general tools that proxy arbitrary objects’ interfaces. Notice how these\\nclasses catch operation calls rather than operation attribute fetches, and thus must per-\\nform the actual operation by delegating a call or expression:\\n\\nclass BuiltinsMixin:\\n    def __add__(self, other):\\n        return self.__class__.__getattr__(self, \\'__add__\\')(other)\\n    def __str__(self):\\n        return self.__class__.__getattr__(self, \\'__str__\\')()\\n    def __getitem__(self, index):\\n        return self.__class__.__getattr__(self, \\'__getitem__\\')(index)\\n    def __call__(self, *args, **kargs):\\n        return self.__class__.__getattr__(self, \\'__call__\\')(*args, **kargs)\\n    # plus any others needed\\n\\ndef accessControl(failIf):\\n    def onDecorator(aClass):\\n        class onInstance(BuiltinsMixin):\\n            ...rest unchanged...\\n            def __getattr__(self, attr): ...\\n            def __setattr__(self, attr, value): ...\\n\\nclass BuiltinsMixin:\\n    def __add__(self, other):\\n        return self._wrapped + other                    # Assume a _wrapped\\n    def __str__(self):                                  # Bypass __getattr__\\n        return str(self._wrapped)\\n    def __getitem__(self, index):\\n        return self._wrapped[index]\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1325\\n\\n\\x0c    def __call__(self, *args, **kargs):\\n        return self._wrapped(*args, **kargs)\\n    # plus any others needed\\n\\ndef accessControl(failIf):\\n    def onDecorator(aClass):\\n        class onInstance(BuiltinsMixin):\\n            ...and use self._wrapped instead of self.__wrapped...\\n            def __getattr__(self, attr): ...\\n            def __setattr__(self, attr, value): ...\\n\\nEither one of these superclass mix-ins will be extraneous code, but must be imple-\\nmented only once, and seem much more straightforward than the various metaclass-\\nor decorator-based tool approaches you’ll find online that populate each proxy class\\nwith the requisite methods redundantly (see the class augmentation examples in Chap-\\nter 40 for the principles behind such tools).\\nCoding variations: Routers, descriptors, automation.\\nNaturally, both of the prior section’s mix-\\nin superclasses might be improved with additional code changes we’ll largely pass on\\nhere, except for two variations worth noting briefly. First, compare the following mu-\\ntation of the first mix-in—which uses a simpler coding structure but will incur an extra\\ncall per built-in operation, making it slower (though perhaps not significantly so in a\\nproxy context):\\n\\nclass BuiltinsMixin:\\n    def reroute(self, attr, *args, **kargs):\\n        return self.__class__.__getattr__(self, attr)(*args, **kargs)\\n\\n    def __add__(self, other):\\n        return self.reroute(\\'__add__\\', other)\\n    def __str__(self):\\n        return self.reroute(\\'__str__\\')\\n    def __getitem__(self, index):\\n        return self.reroute(\\'__getitem__\\', index)\\n    def __call__(self, *args, **kargs):\\n        return self.reroute(\\'__call__\\', *args, **kargs)\\n    # plus any others needed\\n\\nSecond,  all  the  preceding  built-in  mix-in  classes  code  each  operator  overloading\\nmethod explicitly, and intercept the call issued for the operation. With an alternative\\ncoding, we could instead generate methods from a list of names mechanically, and\\nintercept only the attribute fetch preceding the call by creating class-level descriptors of\\nthe prior chapter—as in the following, which, like the second mix-in alternative, as-\\nsumes the proxied object is named _wrapped in the proxy instance itself:\\n\\nclass BuiltinsMixin:\\n    class ProxyDesc(object):                                     # object for 2.X\\n        def __init__(self, attrname):\\n            self.attrname = attrname\\n        def __get__(self, instance, owner):\\n            return getattr(instance._wrapped, self.attrname)     # Assume a _wrapped\\n\\n    builtins = [\\'add\\', \\'str\\', \\'getitem\\', \\'call\\']                 # Plus any others\\n\\n1326 | Chapter 39:\\u2002Decorators\\n\\n\\x0c    for attr in builtins:\\n        exec(\\'__%s__ = ProxyDesc(\"__%s__\")\\' % (attr, attr))\\n\\nThis coding may be the most concise, but also the most implicit and complex, and is\\nfairly tightly coupled with its subclasses by the shared name. The loop at the end of\\nthis class is equivalent to the following, run in the mix-in class’s local scope—it creates\\ndescriptors that respond to initial name lookups by fetching from the wrapped object\\nin __get__, rather than catching the later operation call itself:\\n\\n    __add__ = ProxyDesc(\"__add__\")\\n    __str__ = ProxyDesc(\"__str__\")\\n    ...etc...\\n\\nWith such operator overloading methods added—either inline or by mix-in inheritance\\n—the  prior  Private  example  client  that  overloaded  +  and  print  with  __str__  and\\n__add__ works correctly under 2.X and 3.X, as do subclasses that overload indexing\\nand calls. If you care to experiment further, see files access2_builtins*.py in the book\\nexamples package for complete codings of these options; we’ll also employ that third\\nof the mix-in options in a solution to an end-of-chapter quiz.\\n\\nShould operator methods be validated?\\nAdding support for operator overloading methods is required of interface proxies in\\ngeneral, to delegate calls correctly. In our specific privacy application, though, it also\\nraises some additional design choices. In particular, privacy of operator overloading\\nmethods differs per implementation:\\n\\n• Because  they  invoke  __getattr__,  the  rerouter  mix-ins  require  either  that  all\\n__X__ names accessed be listed in Public decorations, or that Private be used in-\\nstead when operator overloading is present in clients. In classes that use overload-\\ning heavily, Public may be impractical.\\n\\n• Because they bypass __getattr__ entirely, as coded here both the inline scheme\\nand self._wrapped mix-ins do not have these constraints, but they preclude built-\\nin operations from being made private, and cause built-in operation dispatch to\\nwork  asymmetrically  from  both  explicit  __X__  calls  by-name  and  2.X’s  default\\nclassic classes.\\n\\n• Python 2.X classic classes have the first bullet’s constraints, simply because all\\n\\n__X__ names are routed through __getattr__ automatically.\\n\\n• Operator overloading names and protocols differ between 2.X and 3.X, making\\ntruly cross-version decoration less than trivial (e.g., Public decorators may need to\\nlist names from both lines).\\n\\nWe’ll leave final policy here a TBD, but some interface proxies might prefer to allow\\n__X__ operator names to always pass unchecked when delegated.\\nIn the general case, though, a substantial amount of extra code is required to accom-\\nmodate  3.X’s  new-style  classes  as  delegation  proxies—in  principle,  every  operator\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1327\\n\\n\\x0coverloading method that is no longer dispatched as a normal instance attribute auto-\\nmatically will need to be defined redundantly in a general tool class like this privacy\\ndecorator. This is why this extension is omitted in our code: there are potentially more\\nthan 50 such methods! Because all its classes are new-style, delegation-based code is\\nmore difficult—though not necessarily impossible—in Python 3.X.\\n\\nImplementation alternatives: __getattribute__ inserts, call stack inspection\\nAlthough redundantly defining operator overloading methods in wrappers is probably\\nthe most straightforward workaround to Python 3.X dilemma outlined in the prior\\nsection, it’s not necessarily the only one. We don’t have space to explore this issue\\nmuch further here, so deeper investigation will have to be relegated to suggested exer-\\ncise. Because one dead-end alternative illustrates class concepts well, though, it merits\\na brief mention.\\nOne downside of the privacy example is that instance objects are not truly instances of\\nthe original class—they are instances of the wrapper instead. In some programs that\\nrely on type testing, this might matter. To support such cases, we might try to achieve\\nsimilar effects by inserting a __getattribute__ and a __setattr__ method into the orig-\\ninal class, to catch every attribute reference and assignment made on its instances. These\\ninserted methods would pass valid requests up to their superclass to avoid loops, using\\nthe techniques we studied in the prior chapter. Here is the potential change to our class\\ndecorator’s code:\\n\\n# Method insertion: rest of access2.py code as before\\n\\ndef accessControl(failIf):\\n    def onDecorator(aClass):\\n        def getattributes(self, attr):\\n            trace(\\'get:\\', attr)\\n            if failIf(attr):\\n                raise TypeError(\\'private attribute fetch: \\' + attr)\\n            else:\\n                return object.__getattribute__(self, attr)\\n\\n        def setattributes(self, attr, value):\\n            trace(\\'set:\\', attr)\\n            if failIf(attr):\\n                raise TypeError(\\'private attribute change: \\' + attr)\\n            else:\\n                return object.__setattr__(self, attr, value)\\n\\n        aClass.__getattribute__ = getattributes\\n        aClass.__setattr__ = setattributes               # Insert accessors\\n        return aClass                                    # Return original class\\n    return onDecorator\\n\\nThis alternative addresses the type-testing issue but suffers from others. For one thing,\\nthis decorator can be used by new-style class clients only: because __getattribute__ is\\na new-style-only tool (as is this __setattr__ coding), decorated classes in 2.X must use\\n\\n1328 | Chapter 39:\\u2002Decorators\\n\\n\\x0cnew-style derivation, which may or may not be appropriate for their goals. In fact, the\\nset of classes supported is even further limited: inserting methods will break clients that\\nare already using a __setattr__ or __getattribute__ of their own.\\nWorse, this scheme does not address the built-in operation attributes issue described\\nin the prior section, because __getattribute__ is also not run in these contexts. In our\\ncase, if Person had a __str__ it would be run by print operations, but only because it\\nwas actually present in that class. As before, the __str__ attribute would not be routed\\nto  the  inserted  __getattribute__  method  generically—printing  would  bypass  this\\nmethod altogether and call the class’s __str__ directly.\\nAlthough this is probably better than not supporting operator overloading methods in\\na wrapped object at all (barring redefinition, at least), this scheme still cannot intercept\\nand  validate  __X__  methods,  making  it  impossible  for  any  of  them  to  be  private.\\nWhether operator overloading methods should be private is another matter, but this\\nstructure precludes the possibility.\\nMuch worse, because this nonwrapper approach works by adding a __getattribute__\\nand __setattr__ to the decorated class, it also intercepts attribute accesses made by the\\nclass itself and validates them the same as accesses made from outside. In other words,\\nthe class’s own method won’t be able to use its private names either! This is a show-\\nstopper for the insertion approach.\\nIn fact, inserting these methods this way is functionally equivalent to inheriting them,\\nand implies the same constraints as our original Chapter 30 privacy code. To know\\nwhether an attribute access originated inside or outside the class, our methods might\\nneed to inspect frame objects on the Python call stack. This might ultimately yield a\\nsolution—implementing private attributes as properties or descriptors that check the\\nstack and validate for outside accesses only, for example—but it would slow access\\nfurther, and is far too dark a magic for us to explore here. (Descriptors seem to make\\nall things possible, even when they shouldn’t!)\\nWhile interesting, and possibly relevant for some other use cases, this method insertion\\ntechnique doesn’t meet our goals. We won’t explore this option’s coding pattern fur-\\nther here because we will study class augmentation techniques in the next chapter, in\\nconjunction with metaclasses. As we’ll see there, metaclasses are not strictly required\\nfor changing classes this way, because class decorators can often serve the same role.\\n\\nPython Isn’t About Control\\nNow that I’ve gone to such great lengths to implement Private and Public attribute\\ndeclarations for Python code, I must again remind you that it is not entirely Pythonic\\nto add access controls to your classes like this. In fact, most Python programmers will\\nprobably find this example to be largely or totally irrelevant, apart from serving as a\\ndemonstration of decorators in action. Most large Python programs get by successfully\\nwithout any such controls at all.\\n\\nExample: “Private” and “Public” Attributes\\n\\n| 1329\\n\\n\\x0cThat said, you might find this tool useful in limited scopes during development. If you\\ndo wish to regulate attribute access in order to eliminate coding mistakes, or happen\\nto be a soon-to-be-ex-C++-or-Java programmer, most things are possible with Python’s\\noperator overloading and introspection tools.\\n\\nExample: Validating Function Arguments\\nAs a final example of the utility of decorators, this section develops a function decora-\\ntor that automatically tests whether arguments passed to a function or method are\\nwithin a valid numeric range. It’s designed to be used during either development or\\nproduction, and it can be used as a template for similar tasks (e.g., argument type\\ntesting, if you must). Because this chapter’s size limits have been broached, this exam-\\nple’s code is largely self-study material, with limited narrative; as usual, browse the\\ncode for more details.\\n\\nThe Goal\\nIn the object-oriented tutorial of Chapter 28, we wrote a class that gave a pay raise to\\nobjects representing people based upon a passed-in percentage:\\n\\nclass Person:\\n     ...\\n     def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n\\nThere, we noted that if we wanted the code to be robust it would be a good idea to\\ncheck the percentage to make sure it’s not too large or too small. We could implement\\nsuch a check with either if or assert statements in the method itself, using inline tests:\\n\\nclass Person:\\n    def giveRaise(self, percent):                # Validate with inline code\\n        if percent < 0.0 or percent > 1.0:\\n            raise TypeError, \\'percent invalid\\'\\n        self.pay = int(self.pay * (1 + percent))\\n\\nclass Person:                                    # Validate with asserts\\n    def giveRaise(self, percent):\\n        assert percent >= 0.0 and percent <= 1.0, \\'percent invalid\\'\\n        self.pay = int(self.pay * (1 + percent))\\n\\nHowever, this approach clutters up the method with inline tests that will probably be\\nuseful only during development. For more complex cases, this can become tedious\\n(imagine trying to inline the code needed to implement the attribute privacy provided\\nby the last section’s decorator). Perhaps worse, if the validation logic ever needs to\\nchange, there may be arbitrarily many inline copies to find and update.\\nA more useful and interesting alternative would be to develop a general tool that can\\nperform range tests for us automatically, for the arguments of any function or method\\n\\n1330 | Chapter 39:\\u2002Decorators\\n\\n\\x0cwe might code now or in the future. A decorator approach makes this explicit and\\nconvenient:\\n\\nclass Person:\\n    @rangetest(percent=(0.0, 1.0))               # Use decorator to validate\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n\\nIsolating validation logic in a decorator simplifies both clients and future maintenance.\\nNotice that our goal here is different than the attribute validations coded in the prior\\nchapter’s final example. Here, we mean to validate the values of function arguments\\nwhen passed, rather than attribute values when set. Python’s decorator and introspec-\\ntion tools allow us to code this new task just as easily.\\n\\nA Basic Range-Testing Decorator for Positional Arguments\\nLet’s start with a basic range test implementation. To keep things simple, we’ll begin\\nby coding a decorator that works only for positional arguments and assumes they al-\\nways appear at the same position in every call; they cannot be passed by keyword name,\\nand we don’t support additional **args keywords in calls because this can invalidate\\nthe positions declared in the decorator. Code the following in a file called rangetest1.py:\\n\\ndef rangetest(*argchecks):                  # Validate positional arg ranges\\n    def onDecorator(func):\\n        if not __debug__:                   # True if \"python -O main.py args...\"\\n            return func                     # No-op: call original directly\\n        else:                               # Else wrapper while debugging\\n            def onCall(*args):\\n                for (ix, low, high) in argchecks:\\n                    if args[ix] < low or args[ix] > high:\\n                        errmsg = \\'Argument %s not in %s..%s\\' % (ix, low, high)\\n                        raise TypeError(errmsg)\\n                return func(*args)\\n            return onCall\\n    return onDecorator\\n\\nAs is, this code is mostly a rehash of the coding patterns we explored earlier: we use\\ndecorator arguments, nested scopes for state retention, and so on.\\nWe also use nested def statements to ensure that this works for both simple functions\\nand methods, as we learned earlier. When used for a class’s method, onCall receives the\\nsubject class’s instance in the first item in *args and passes this along to self in the\\noriginal method function; argument numbers in range tests start at 1 in this case, not 0.\\nNew here, notice this code’s use of the __debug__ built-in variable—Python sets this to\\nTrue, unless it’s being run with the  –O optimize command-line flag (e.g.,  python –O\\nmain.py).  When  __debug__  is  False,  the  decorator  returns  the  origin  function  un-\\nchanged, to avoid extra later calls and their associated performance penalty. In other\\nwords, the decorator automatically removes its augmentation logic when –O is used,\\nwithout requiring you to physically remove the decoration lines in your code.\\n\\nExample: Validating Function Arguments\\n\\n| 1331\\n\\n\\x0cThis first iteration solution is used as follows:\\n\\n# File rangetest1_test.py\\nfrom __future__ import print_function # 2.X\\nfrom rangetest1 import rangetest\\nprint(__debug__)                           # False if \"python -O main.py\"\\n\\n@rangetest((1, 0, 120))                    # persinfo = rangetest(...)(persinfo)\\ndef persinfo(name, age):                   # age must be in 0..120\\n    print(\\'%s is %s years old\\' % (name, age))\\n\\n@rangetest([0, 1, 12], [1, 1, 31], [2, 0, 2009])\\ndef birthday(M, D, Y):\\n    print(\\'birthday = {0}/{1}/{2}\\'.format(M, D, Y))\\n\\nclass Person:\\n    def __init__(self, name, job, pay):\\n        self.job  = job\\n        self.pay  = pay\\n\\n    @rangetest([1, 0.0, 1.0])              # giveRaise = rangetest(...)(giveRaise)\\n    def giveRaise(self, percent):          # Arg 0 is the self instance here\\n        self.pay = int(self.pay * (1 + percent))\\n\\n# Comment lines raise TypeError unless \"python -O\" used on shell command line\\n\\npersinfo(\\'Bob Smith\\', 45)                  # Really runs onCall(...) with state\\n#persinfo(\\'Bob Smith\\', 200)                # Or person if -O cmd line argument\\n\\nbirthday(5, 31, 1963)\\n#birthday(5, 32, 1963)\\n\\nsue = Person(\\'Sue Jones\\', \\'dev\\', 100000)\\nsue.giveRaise(.10)                         # Really runs onCall(self, .10)\\nprint(sue.pay)                             # Or giveRaise(self, .10) if -O\\n#sue.giveRaise(1.10)\\n#print(sue.pay)\\n\\nWhen run, valid calls in this code produce the following output (all the code in this\\nsection works the same under Python 2.X and 3.X, because function decorators are\\nsupported in both, we’re not using attribute delegation, and we use version-neutral\\nexception construction and printing techniques):\\n\\nC:\\\\code> python rangetest1_test.py\\nTrue\\nBob Smith is 45 years old\\nbirthday = 5/31/1963\\n110000\\n\\nUncommenting any of the invalid calls causes a TypeError to be raised by the decorator.\\nHere’s the result when the last two lines are allowed to run (as usual, I’ve omitted some\\nof the error message text here to save space):\\n\\nC:\\\\code> python rangetest1_test.py\\nTrue\\n\\n1332 | Chapter 39:\\u2002Decorators\\n\\n\\x0cBob Smith is 45 years old\\nbirthday = 5/31/1963\\n110000\\nTypeError: Argument 1 not in 0.0..1.0\\n\\nRunning Python with its -O flag at a system command line will disable range testing,\\nbut also avoid the performance overhead of the wrapping layer—we wind up calling\\nthe original undecorated function directly. Assuming this is a debugging tool only, you\\ncan use this flag to optimize your program for production use:\\n\\nC:\\\\code> python -O rangetest1_test.py\\nFalse\\nBob Smith is 45 years old\\nbirthday = 5/31/1963\\n110000\\n231000\\n\\nGeneralizing for Keywords and Defaults, Too\\nThe prior version illustrates the basics we need to employ, but it’s fairly limited—it\\nsupports validating arguments passed by position only, and it does not validate key-\\nword arguments (in fact, it assumes that no keywords are passed in a way that makes\\nargument position numbers incorrect). Additionally, it does nothing about arguments\\nwith defaults that may be omitted in a given call. That’s fine if all your arguments are\\npassed by position and never defaulted, but less than ideal in a general tool. Python\\nsupports much more flexible argument-passing modes, which we’re not yet addressing.\\nThe mutation of our example shown next does better. By matching the wrapped func-\\ntion’s expected arguments against the actual arguments passed in a call, it supports\\nrange validations for arguments passed by either position or keyword name, and it skips\\ntesting for default arguments omitted in the call. In short, arguments to be validated\\nare specified by keyword arguments to the decorator, which later steps through both \\nthe *pargs positionals tuple and the **kargs keywords dictionary to validate.\\n\\n\"\"\"\\nFile rangetest.py: function decorator that performs range-test\\nvalidation for arguments passed to any function or method.\\n\\nArguments are specified by keyword to the decorator. In the actual\\ncall, arguments may be passed by position or keyword, and defaults\\nmay be omitted.  See rangetest_test.py for example use cases.\\n\"\"\"\\ntrace = True\\n\\ndef rangetest(**argchecks):                 # Validate ranges for both+defaults\\n    def onDecorator(func):                  # onCall remembers func and argchecks\\n        if not __debug__:                   # True if \"python -O main.py args...\"\\n            return func                     # Wrap if debugging; else use original\\n        else:\\n            code     = func.__code__\\n            allargs  = code.co_varnames[:code.co_argcount]\\n            funcname = func.__name__\\n\\nExample: Validating Function Arguments\\n\\n| 1333\\n\\n\\x0c            def onCall(*pargs, **kargs):\\n                # All pargs match first N expected args by position\\n                # The rest must be in kargs or be omitted defaults\\n                expected    = list(allargs)\\n                positionals = expected[:len(pargs)]\\n\\n                for (argname, (low, high)) in argchecks.items():\\n                    # For all args to be checked\\n                    if argname in kargs:\\n                        # Was passed by name\\n                        if kargs[argname] < low or kargs[argname] > high:\\n                            errmsg = \\'{0} argument \"{1}\" not in {2}..{3}\\'\\n                            errmsg = errmsg.format(funcname, argname, low, high)\\n                            raise TypeError(errmsg)\\n\\n                    elif argname in positionals:\\n                        # Was passed by position\\n                        position = positionals.index(argname)\\n                        if pargs[position] < low or pargs[position] > high:\\n                            errmsg = \\'{0} argument \"{1}\" not in {2}..{3}\\'\\n                            errmsg = errmsg.format(funcname, argname, low, high)\\n                            raise TypeError(errmsg)\\n                    else:\\n                        # Assume not passed: default\\n                        if trace:\\n                            print(\\'Argument \"{0}\" defaulted\\'.format(argname))\\n\\n                return func(*pargs, **kargs)    # OK: run original call\\n            return onCall\\n    return onDecorator\\n\\nThe following test script shows how the decorator is used—arguments to be validated\\nare given by keyword decorator arguments, and at actual calls we can pass by name or\\nposition and omit arguments with defaults even if they are to be validated otherwise:\\n\\n\"\"\"\\nFile rangetest_test.py (3.X + 2.X)\\nComment lines raise TypeError unless \"python -O\" used on shell command line\\n\"\"\"\\nfrom __future__ import print_function # 2.X\\nfrom rangetest import rangetest\\n\\n# Test functions, positional and keyword\\n\\n@rangetest(age=(0, 120))                  # persinfo = rangetest(...)(persinfo)\\ndef persinfo(name, age):\\n    print(\\'%s is %s years old\\' % (name, age))\\n\\n@rangetest(M=(1, 12), D=(1, 31), Y=(0, 2013))\\ndef birthday(M, D, Y):\\n    print(\\'birthday = {0}/{1}/{2}\\'.format(M, D, Y))\\n\\npersinfo(\\'Bob\\', 40)\\npersinfo(age=40, name=\\'Bob\\')\\n\\n1334 | Chapter 39:\\u2002Decorators\\n\\n\\x0cbirthday(5, D=1, Y=1963)\\n#persinfo(\\'Bob\\', 150)\\n#persinfo(age=150, name=\\'Bob\\')\\n#birthday(5, D=40, Y=1963)\\n\\n# Test methods, positional and keyword\\n\\nclass Person:\\n    def __init__(self, name, job, pay):\\n        self.job  = job\\n        self.pay  = pay\\n                                          # giveRaise = rangetest(...)(giveRaise)\\n    @rangetest(percent=(0.0, 1.0))        # percent passed by name or position\\n    def giveRaise(self, percent):\\n        self.pay = int(self.pay * (1 + percent))\\n\\nbob = Person(\\'Bob Smith\\', \\'dev\\', 100000)\\nsue = Person(\\'Sue Jones\\', \\'dev\\', 100000)\\nbob.giveRaise(.10)\\nsue.giveRaise(percent=.20)\\nprint(bob.pay, sue.pay)\\n#bob.giveRaise(1.10)\\n#bob.giveRaise(percent=1.20)\\n\\n# Test omitted defaults: skipped\\n\\n@rangetest(a=(1, 10), b=(1, 10), c=(1, 10), d=(1, 10))\\ndef omitargs(a, b=7, c=8, d=9):\\n    print(a, b, c, d)\\n\\nomitargs(1, 2, 3, 4)\\nomitargs(1, 2, 3)\\nomitargs(1, 2, 3, d=4)\\nomitargs(1, d=4)\\nomitargs(d=4, a=1)\\nomitargs(1, b=2, d=4)\\nomitargs(d=8, c=7, a=1)\\n\\n#omitargs(1, 2, 3, 11)         # Bad d\\n#omitargs(1, 2, 11)            # Bad c\\n#omitargs(1, 2, 3, d=11)       # Bad d\\n#omitargs(11, d=4)             # Bad a\\n#omitargs(d=4, a=11)           # Bad a\\n#omitargs(1, b=11, d=4)        # Bad b\\n#omitargs(d=8, c=7, a=11)      # Bad a\\n\\nWhen this script is run, out-of-range arguments raise an exception as before, but ar-\\nguments may be passed by either name or position, and omitted defaults are not vali-\\ndated. This code runs on both 2.X and 3.X. Trace its output and test this further on\\nyour own to experiment; it works as before, but its scope has been broadened:\\n\\nC:\\\\code> python rangetest_test.py\\nBob is 40 years old\\nBob is 40 years old\\nbirthday = 5/1/1963\\n\\nExample: Validating Function Arguments\\n\\n| 1335\\n\\n\\x0c110000 120000\\n1 2 3 4\\nArgument \"d\" defaulted\\n1 2 3 9\\n1 2 3 4\\nArgument \"c\" defaulted\\nArgument \"b\" defaulted\\n1 7 8 4\\nArgument \"c\" defaulted\\nArgument \"b\" defaulted\\n1 7 8 4\\nArgument \"c\" defaulted\\n1 2 8 4\\nArgument \"b\" defaulted\\n1 7 7 8\\n\\nOn validation errors, we get an exception as before when one of the method test lines\\nis uncommented, unless the -O command-line argument is passed to Python to disable\\nthe decorator’s logic:\\n\\nTypeError: giveRaise argument \"percent\" not in 0.0..1.0\\n\\nImplementation Details\\nThis decorator’s code relies on both introspection APIs and subtle constraints of ar-\\ngument passing. To be fully general we could in principle try to mimic Python’s argu-\\nment matching logic in its entirety to see which names have been passed in which\\nmodes, but that’s far too much complexity for our tool. It would be better if we could\\nsomehow match arguments passed by name against the set of all expected arguments’\\nnames, in order to determine which position arguments actually appear in during a\\ngiven call.\\n\\nFunction introspection\\nIt turns out that the introspection API available on function objects and their associated\\ncode objects has exactly the tool we need. This API was briefly introduced in Chap-\\nter 19, but we’ll actually put it to use here. The set of expected argument names is\\nsimply the first N variable names attached to a function’s code object:\\n\\n# In Python 3.X (and 2.6+ for compatibility)\\n>>> def func(a, b, c, e=True, f=None):       # Args: three required, two defaults\\n        x = 1                                # Plus two more local variables\\n        y = 2\\n\\n>>> code = func.__code__                     # Code object of function object\\n>>> code.co_nlocals\\n7\\n>>> code.co_varnames                         # All local variable names\\n(\\'a\\', \\'b\\', \\'c\\', \\'e\\', \\'f\\', \\'x\\', \\'y\\')\\n>>> code.co_varnames[:code.co_argcount]      # <== First N locals are expected args\\n(\\'a\\', \\'b\\', \\'c\\', \\'e\\', \\'f\\')\\n\\n1336 | Chapter 39:\\u2002Decorators\\n\\n\\x0cAnd as usual, starred-argument names in the call proxy allow it to collect arbitrarily\\nmany arguments to be matched against the expected arguments so obtained from the\\nfunction’s introspection API:\\n\\n>>> def catcher(*pargs, **kargs): print(\\'%s, %s\\' % (pargs, kargs))\\n\\n>>> catcher(1, 2, 3, 4, 5)\\n(1, 2, 3, 4, 5), {}\\n>>> catcher(1, 2, c=3, d=4, e=5)             # Arguments at calls\\n(1, 2), {\\'d\\': 4, \\'e\\': 5, \\'c\\': 3}\\n\\nThe function object’s API is available in older Pythons, but the func.__code__ attribute\\nis named func.func_code in 2.5 and earlier; the newer __code__ attribute is also redun-\\ndantly available in 2.6 and later for portability. Run a dir call on function and code\\nobjects for more details. Code like the following would support 2.5 and earlier, though\\nthe sys.version_info result itself is similarly nonportable—it’s a named tuple in recent\\nPythons, but we can use offsets on newer and older Pythons alike:\\n\\n>>> import sys                               # For backward compatibility\\n>>> tuple(sys.version_info)                  # [0] is major release number\\n(3, 3, 0, \\'final\\', 0)\\n>>> code = func.__code__ if sys.version_info[0] == 3 else func.func_code\\n\\nArgument assumptions\\nGiven the decorated function’s set of expected argument names, the solution relies\\nupon two constraints on argument passing order imposed by Python (these still hold\\ntrue in both 2.X and 3.X current releases):\\n\\n• At the call, all positional arguments appear before all keyword arguments.\\n• In the def, all nondefault arguments appear before all default arguments.\\n\\nThat is, a nonkeyword argument cannot generally follow a keyword argument at a\\ncall, and a nondefault argument cannot follow a default argument at a definition. All\\n“name=value” syntax must appear after any simple “name” in both places. As we’ve\\nalso learned, Python matches argument values passed by position to argument names\\nin function headers from left to right, such that these values always match the left-\\nmost names in headers. Keywords match by name instead, and a given argument can\\nreceive only one value.\\nTo simplify our work, we can also make the assumption that a call is valid in general\\n—that is, that all arguments either will receive values (by name or position), or will be\\nomitted intentionally to pick up defaults. This assumption won’t necessarily hold, be-\\ncause the function has not yet actually been called when the wrapper logic tests validity\\n—the call may still fail later when invoked by the wrapper layer, due to incorrect ar-\\ngument passing. As long as that doesn’t cause the wrapper to fail any more badly,\\nthough, we can finesse the validity of the call. This helps, because validating calls before\\nthey are actually made would require us to emulate Python’s argument-matching al-\\ngorithm in full—again, too complex a procedure for our tool.\\n\\nExample: Validating Function Arguments\\n\\n| 1337\\n\\n\\x0cMatching algorithm\\nNow, given these constraints and assumptions, we can allow for both keywords and\\nomitted default arguments in the call with this algorithm. When a call is intercepted,\\nwe can make the following assumptions and deductions:\\n\\n1. Let N be the number of passed positional arguments, obtained from the length of\\n\\nthe *pargs tuple.\\n\\n2. All N positional arguments in *pargs must match the first N expected arguments\\nobtained from the function’s code object. This is true per Python’s call ordering\\nrules, outlined earlier, since all positionals precede all keywords in a call.\\n\\n3. To obtain the names of arguments actually passed by position, we can slice the list\\nof all expected arguments up to the length N of the *pargs passed positionals tuple.\\n4. Any arguments after the first N expected arguments either were passed by keyword\\n\\nor were defaulted by omission at the call.\\n\\n5. For each argument name to be validated by the decorator:\\n\\na. If the name is in **kargs, it was passed by name—indexing **kargs gives its\\n\\npassed value.\\n\\nb. If the name is in the first N expected arguments, it was passed by position—\\n\\nits relative position in the expected list gives its relative position in *pargs.\\n\\nc. Otherwise, we can assume it was omitted in the call and defaulted, and need\\n\\nnot be checked.\\n\\nIn other words, we can skip tests for arguments that were omitted in a call by assuming\\nthat the first N actually passed positional arguments in *pargs must match the first N\\nargument names in the list of all expected arguments, and that any others must either\\nhave been passed by keyword and thus be in **kargs, or have been defaulted. Under\\nthis scheme, the decorator will simply skip any argument to be checked that was omit-\\nted between the rightmost positional argument and the leftmost keyword argument;\\nbetween  keyword  arguments;  or  after  the  rightmost  positional  in  general.  Trace\\nthrough the decorator and its test script to see how this is realized in code.\\n\\nOpen Issues\\nAlthough our range-testing tool works as planned, three caveats remain—it doesn’t\\ndetect invalid calls, doesn’t handle some arbitrary-argument signatures, and doesn’t\\nfully support nesting. Improvements may require extension or altogether different ap-\\nproaches. Here’s a quick rundown of the issues.\\n\\nInvalid calls\\nFirst, as mentioned earlier, calls to the original function that are not valid still fail in\\nour final decorator. The following both trigger exceptions, for example:\\n\\n1338 | Chapter 39:\\u2002Decorators\\n\\n\\x0comitargs()\\nomitargs(d=8, c=7, b=6)\\n\\nThese only fail, though, where we try to invoke the original function, at the end of the\\nwrapper. While we could try to imitate Python’s argument matching to avoid this,\\nthere’s not much reason to do so—since the call would fail at this point anyhow, we\\nmight as well let Python’s own argument-matching logic detect the problem for us.\\n\\nArbitrary arguments\\nSecond, although our final version handles positional arguments, keyword arguments,\\nand omitted defaults, it still doesn’t do anything explicit about  *pargs and **kargs\\nstarred-argument names that may be used in a decorated function that accepts arbi-\\ntrarily many arguments itself. We probably don’t need to care for our purposes, though:\\n\\n• If an extra keyword argument is passed, its name will show up in **kargs and can\\n\\nbe tested normally if mentioned to the decorator.\\n\\n• If an extra keyword argument is not passed, its name won’t be in either **kargs or\\nthe sliced expected positionals list, and it will thus not be checked—it is treated as\\nthough it were defaulted, even though it is really an optional extra argument.\\n\\n• If an extra positional argument is passed, there’s no way to reference it in the dec-\\norator anyhow—its name won’t be in either **kargs or the sliced expected argu-\\nments list, so it will simply be skipped. Because such arguments are not listed in\\nthe function’s definition, there’s no way to map a name given to the decorator back\\nto an expected relative position.\\n\\nIn other words, as it is the code supports testing arbitrary keyword arguments by name,\\nbut not arbitrary positionals that are unnamed and hence have no set position in the\\nfunction’s argument signature. In terms of the function object’s API, here’s the effect\\nof these tools in decorated functions:\\n>>> def func(*kargs, **pargs): pass\\n>>> code = func.__code__\\n>>> code.co_nlocals, code.co_varnames\\n(2, (\\'kargs\\', \\'pargs\\'))\\n>>> code.co_argcount, code.co_varnames[:code.co_argcount]\\n(0, ())\\n\\n>>> def func(a, b, *kargs, **pargs): pass\\n>>> code = func.__code__\\n>>> code.co_argcount, code.co_varnames[:code.co_argcount]\\n(2, (\\'a\\', \\'b\\'))\\n\\nBecause starred-argument names show up as locals but not as expected arguments, they\\nwon’t be a factor in our matching algorithm—names preceding them in function head-\\ners can be validated as usual, but not any extra positional arguments passed. In prin-\\nciple, we could extend the decorator’s interface to support  *pargs in the decorated\\nfunction, too, for the rare cases where this might be useful (e.g., a special argument\\n\\nExample: Validating Function Arguments\\n\\n| 1339\\n\\n\\x0cname with a test to apply to all arguments in the wrapper’s *pargs beyond the length\\nof the expected arguments list), but we’ll pass on such an extension here.\\n\\nDecorator nesting\\nFinally, and perhaps most subtly, this code’s approach does not fully support use of\\ndecorator nesting to combine steps. Because it analyzes arguments using names in func-\\ntion definitions, and the names of the call proxy function returned by a nested deco-\\nration won’t correspond to argument names in either the original function or decorator\\narguments, it does not fully support use in nested mode.\\nTechnically, when nested, only the most deeply nested appearance’s validations are\\nrun in full; all other nesting levels run tests on arguments passed by keyword only.\\nTrace the code to see why; because the onCall proxy’s call signature expects no named\\npositional arguments, any to-be-validated arguments passed to it by position are treated\\nas if they were omitted and hence defaulted, and are thus skipped.\\nThis may be inherent in this tool’s approach—proxies change the argument name sig-\\nnatures at their levels, making it impossible to directly map names in decorator argu-\\nments to positions in passed argument sequences. When proxies are present, argument\\nnames ultimately apply to keywords only; by contrast, the first-cut solution’s argument\\npositions may support proxies better, but do not fully support keywords.\\nIn lieu of this nesting capability, we’ll generalize this decorator to support multiple\\ntypes of validations in a single decoration in an end-of-chapter quiz solution, which\\nalso gives examples of the nesting limitation in action. Since we’ve already neared the\\nspace allocation for this example, though, if you care about these or any other further\\nimprovements, you’ve officially crossed over into the realm of suggested exercises.\\n\\nDecorator Arguments Versus Function Annotations\\nInterestingly, the function annotation feature introduced in Python 3.X (3.0 and later)\\ncould provide an alternative to the decorator arguments used by our example to specify\\nrange tests. As we learned in Chapter 19, annotations allow us to associate expressions\\nwith arguments and return values, by coding them in the def header line itself; Python\\ncollects annotations in a dictionary and attaches it to the annotated function.\\nWe could use this in our example to code range limits in the header line, instead of in\\ndecorator arguments. We would still need a function decorator to wrap the function\\nin order to intercept later calls, but we would essentially trade decorator argument\\nsyntax:\\n\\n@rangetest(a=(1, 5), c=(0.0, 1.0))\\ndef func(a, b, c):                         # func = rangetest(...)(func)\\n    print(a + b + c)\\n\\nfor annotation syntax like this:\\n\\n1340 | Chapter 39:\\u2002Decorators\\n\\n\\x0c@rangetest\\ndef func(a:(1, 5), b, c:(0.0, 1.0)):\\n    print(a + b + c)\\n\\nThat is, the range constraints would be moved into the function itself, instead of being\\ncoded externally. The following script illustrates the structure of the resulting decora-\\ntors under both schemes, in incomplete skeleton code for brevity. The decorator ar-\\nguments code pattern is that of our complete solution shown earlier; the annotation\\nalternative requires one less level of nesting, because it doesn’t need to retain decorator\\narguments as state:\\n\\n# Using decorator arguments (3.X + 2.X)\\n\\ndef rangetest(**argchecks):\\n    def onDecorator(func):\\n        def onCall(*pargs, **kargs):\\n            print(argchecks)\\n            for check in argchecks:\\n                pass                         # Add validation code here\\n            return func(*pargs, **kargs)\\n        return onCall\\n    return onDecorator\\n\\n@rangetest(a=(1, 5), c=(0.0, 1.0))\\ndef func(a, b, c):                           # func = rangetest(...)(func)\\n    print(a + b + c)\\n\\nfunc(1, 2, c=3)                              # Runs onCall, argchecks in scope\\n\\n# Using function annotations (3.X only)\\n\\ndef rangetest(func):\\n    def onCall(*pargs, **kargs):\\n        argchecks = func.__annotations__\\n        print(argchecks)\\n        for check in argchecks:\\n            pass                             # Add validation code here\\n        return func(*pargs, **kargs)\\n    return onCall\\n\\n@rangetest\\ndef func(a:(1, 5), b, c:(0.0, 1.0)):         # func = rangetest(func)\\n    print(a + b + c)\\n\\nfunc(1, 2, c=3)                              # Runs onCall, annotations on func\\n\\nWhen run, both schemes have access to the same validation test information, but in\\ndifferent forms—the decorator argument version’s information is retained in an argu-\\nment in an enclosing scope, and the annotation version’s information is retained in an\\nattribute of the function itself. In 3.X only, due to the use of function annotations:\\n\\nC:\\\\code> py −3 decoargs-vs-annotation.py\\n{\\'a\\': (1, 5), \\'c\\': (0.0, 1.0)}\\n6\\n\\nExample: Validating Function Arguments\\n\\n| 1341\\n\\n\\x0c{\\'a\\': (1, 5), \\'c\\': (0.0, 1.0)}\\n6\\n\\nI’ll leave fleshing out the rest of the annotation-based version as a suggested exercise;\\nits code would be identical to that of our complete solution shown earlier, because\\nrange-test information is simply on the function instead of in an enclosing scope. Really,\\nall this buys us is a different user interface for our tool—it will still need to match\\nargument names against expected argument names to obtain relative positions as be-\\nfore.\\nIn fact, using annotation instead of decorator arguments in this example actually limits\\nits utility. For one thing, annotation only works under Python 3.X, so 2.X is no longer\\nsupported; function decorators with arguments, on the other hand, work in both ver-\\nsions.\\nMore importantly, by moving the validation specifications into the def header, we es-\\nsentially commit the function to a single role—since annotation allows us to code only\\none expression per argument, it can have only one purpose. For instance, we cannot\\nuse range-test annotations for any other role.\\nBy contrast, because decorator arguments are coded outside the function itself, they\\nare both easier to remove and more general—the code of the function itself does not\\nimply a single decoration purpose. Crucially, by nesting decorators with arguments, we\\ncan apply multiple augmentation steps to the same function; annotation directly sup-\\nports only one. With decorator arguments, the function itself also retains a simpler,\\nnormal appearance.\\nStill, if you have a single purpose in mind, and you can commit to supporting 3.X only,\\nthe choice between annotation and decorator arguments is largely stylistic and subjec-\\ntive.  As  is  so  often  true  in  life,  one  person’s  decoration  or  annotation  may  well  be\\nanother’s syntactic clutter!\\n\\nOther Applications: Type Testing (If You Insist!)\\nThe coding pattern we’ve arrived at for processing arguments in decorators could be\\napplied in other contexts. Checking argument data types at development time, for ex-\\nample, is a straightforward extension:\\n\\ndef typetest(**argchecks):\\n    def onDecorator(func):\\n           ...\\n           def onCall(*pargs, **kargs):\\n                positionals = list(allargs)[:len(pargs)]\\n                for (argname, type) in argchecks.items():\\n                    if argname in kargs:\\n                        if not isinstance(kargs[argname], type):\\n                            ...\\n                            raise TypeError(errmsg)\\n                    elif argname in positionals:\\n                        position = positionals.index(argname)\\n\\n1342 | Chapter 39:\\u2002Decorators\\n\\n\\x0c                        if not isinstance(pargs[position], type):\\n                            ...\\n                            raise TypeError(errmsg)\\n                    else:\\n                        # Assume not passed: default\\n                return func(*pargs, **kargs)\\n            return onCall\\n    return onDecorator\\n\\n@typetest(a=int, c=float)\\ndef func(a, b, c, d):                    # func = typetest(...)(func)\\n    ...\\n\\nfunc(1, 2, 3.0, 4)                       # OK\\nfunc(\\'spam\\', 2, 99, 4)                   # Triggers exception correctly\\n\\nUsing function annotations instead of decorator arguments for such a decorator, as\\ndescribed in the prior section, would make this look even more like type declarations\\nin other languages:\\n\\n@typetest\\ndef func(a: int, b, c: float, d):        # func = typetest(func)\\n    ...                                  # Gasp!...\\n\\nBut we’re getting dangerously close to triggering a “flag on the play” here. As you should\\nhave learned in this book, this particular role is generally a bad idea in working code,\\nand, much like private declarations, is not at all Pythonic (and is often a symptom of\\nan ex-C++ programmer’s first attempts to use Python).\\nType testing restricts your function to work on specific types only, instead of allowing\\nit to operate on any types with compatible interfaces. In effect, it limits your code and\\nbreaks its flexibility. On the other hand, every rule has exceptions; type checking may\\ncome in handy in isolated cases while debugging and when interfacing with code writ-\\nten in more restrictive languages, such as C++.\\nStill, this general pattern of argument processing might also be applicable in a variety\\nof less controversial roles. We might even generalize further by passing in a test func-\\ntion, much as we did to add Public decorations earlier; a single copy of this sort of code\\nwould then suffice for both range and type testing, and perhaps other similar goals. In\\nfact, we will generalize this way in the end-of-chapter quiz coming up, so we’ll leave\\nthis extension as a cliffhanger here.\\n\\nChapter Summary\\nIn this chapter, we explored decorators—both the function and class varieties. As we\\nlearned, decorators are a way to insert code to be run automatically when a function\\nor class is defined. When a decorator is used, Python rebinds a function or class name\\nto the callable object it returns. This hook allows us to manage functions and classes\\nthemselves, or later calls to them—by adding a layer of wrapper logic to catch later\\ncalls,  we  can  augment  both  function  calls  and  instance  interfaces.  As  we  also  saw,\\n\\nChapter Summary | 1343\\n\\n\\x0cmanager functions and manual name rebinding can achieve the same effect, but dec-\\norators provide a more explicit and uniform solution.\\nAs we also learned, class decorators can be used to manage classes themselves, rather\\nthan  just  their  instances.  Because  this  functionality  overlaps  with  metaclasses—the\\ntopic of the next and final technical chapter— you’ll have to read ahead for the con-\\nclusion to this story, and that of this book at large. First, though, let’s work through\\nthe following quiz. Because this chapter was mostly focused on its examples, its quiz\\nwill ask you to modify some of its code in order to review. You can find the original\\nversions’ code in the book’s examples package (see the preface for access pointers). If\\nyou’re pressed for time, study the modifications listed in the answers instead—pro-\\ngramming is as much about reading code as writing it.\\n\\nTest Your Knowledge: Quiz\\n1. Method  decorators:  As  mentioned  in  one  of  this  chapter’s  notes,  the  time-\\nrdeco2.py module’s timer function decorator with decorator arguments that we\\nwrote in the section “Adding Decorator Arguments” on page 1298 can be applied\\nonly to simple functions, because it uses a nested class with a __call__ operator\\noverloading method to catch calls. This structure does not work for a class’s meth-\\nods because the decorator instance is passed to self, not the subject class instance.\\nRewrite this decorator so that it can be applied to both simple functions and meth-\\nods in classes, and test it on both functions and methods. (Hint: see the section\\n“Class Blunders I: Decorating Methods” on page 1289 for pointers.) Note that you\\nwill probably need to use function object attributes to keep track of total time, since\\nyou won’t have a nested class for state retention and can’t access nonlocals from\\noutside the decorator code. As an added bonus, this makes your decorator usable\\non both Python 3.X and 2.X.\\n\\n2. Class  decorators:  The  Public/Private  class  decorators  we  wrote  in  module  ac-\\ncess2.py in this chapter’s first case study example will add performance costs to\\nevery attribute fetch in a decorated class. Although we could simply delete the @\\ndecoration line to gain speed, we could also augment the decorator itself to check\\nthe __debug__ switch and perform no wrapping at all when the –O Python flag is\\npassed on the command line—just as we did for the argument range-test decora-\\ntors. That way, we can speed our program without changing its source, via com-\\nmand-line arguments (python –O main.py...). While we’re at it, we could also use\\none of the mix-in superclass techniques we studied to catch a few built-in opera-\\ntions in Python 3.X too. Code and test these two extensions.\\n\\n3. Generalized argument validations: The function and method decorator we wrote\\nin rangetest.py checks that passed arguments are in a valid range, but we also saw\\nthat the same pattern could apply to similar goals such as argument type testing,\\nand possibly more. Generalize the range tester so that its single code base can be\\nused for multiple argument validations. Passed-in functions may be the simplest\\n\\n1344 | Chapter 39:\\u2002Decorators\\n\\n\\x0csolution given the coding structure here, though in more OOP-based contexts,\\nsubclasses that provide expected methods can often provide similar generalization\\nroutes as well.\\n\\nTest Your Knowledge: Answers\\n1. Here’s one way to code the first question’s solution, and its output (though some\\nmethods may run too fast to register reported time). The trick lies in replacing\\nnested classes with nested functions, so the self argument is not the decorator’s\\ninstance, and assigning the total time to the decorator function itself so it can be\\nfetched later through the original rebound name (see the section “State Information\\nRetention  Options”  of  this  chapter  for  details—functions  support  arbitrary  at-\\ntribute attachment, and the function name is an enclosing scope reference in this\\ncontext). If you wish to expand this further, it might be useful to also record the\\nbest (minimum) call time in addition to the total time, as we did in Chapter 21’s\\ntimer examples.\\n\\n\"\"\"\\nFile timerdeco.py (3.X + 2.X)\\nCall timer decorator for both functions and methods.\\n\"\"\"\\nimport time\\n\\ndef timer(label=\\'\\', trace=True):             # On decorator args: retain args\\n    def onDecorator(func):                   # On @: retain decorated func\\n        def onCall(*args, **kargs):          # On calls: call original\\n            start   = time.clock()           # State is scopes + func attr\\n            result  = func(*args, **kargs)\\n            elapsed = time.clock() - start\\n            onCall.alltime += elapsed\\n            if trace:\\n                format = \\'%s%s: %.5f, %.5f\\'\\n                values = (label, func.__name__, elapsed, onCall.alltime)\\n                print(format % values)\\n            return result\\n        onCall.alltime = 0\\n        return onCall\\n    return onDecorator\\n\\nI’ve coded tests in a separate file here to allow the decorator to be easily reused:\\n\\n\"\"\"\\nFile timerdeco-test.py\\n\"\"\"\\nfrom __future__ import print_function # 2.X\\nfrom timerdeco import timer\\nimport sys\\nforce = list if sys.version_info[0] == 3 else (lambda X: X)\\n\\nprint(\\'---------------------------------------------------\\')\\n# Test on functions\\n\\nTest Your Knowledge: Answers\\n\\n| 1345\\n\\n\\x0c@timer(trace=True, label=\\'[CCC]==>\\')\\ndef listcomp(N):                             # Like listcomp = timer(...)(listcomp)\\n    return [x * 2 for x in range(N)]         # listcomp(...) triggers onCall\\n\\n@timer(\\'[MMM]==>\\')\\ndef mapcall(N):\\n    return force(map((lambda x: x * 2), range(N)))   # list() for 3.X views\\n\\nfor func in (listcomp, mapcall):\\n    result = func(5)                  # Time for this call, all calls, return value\\n    func(5000000)\\n    print(result)\\n    print(\\'allTime = %s\\\\n\\' % func.alltime)   # Total time for all calls\\n\\nprint(\\'---------------------------------------------------\\')\\n# Test on methods\\n\\nclass Person:\\n    def __init__(self, name, pay):\\n        self.name = name\\n        self.pay  = pay\\n\\n    @timer()\\n    def giveRaise(self, percent):            # giveRaise = timer()(giveRaise)\\n        self.pay *= (1.0 + percent)          # tracer remembers giveRaise\\n\\n    @timer(label=\\'**\\')\\n    def lastName(self):                      # lastName = timer(...)(lastName)\\n        return self.name.split()[-1]         # alltime per class, not instance\\n\\nbob = Person(\\'Bob Smith\\', 50000)\\nsue = Person(\\'Sue Jones\\', 100000)\\nbob.giveRaise(.10)\\nsue.giveRaise(.20)                           # runs onCall(sue, .10)\\nprint(int(bob.pay), int(sue.pay))\\nprint(bob.lastName(), sue.lastName())        # runs onCall(bob), remembers lastName\\nprint(\\'%.5f %.5f\\' % (Person.giveRaise.alltime, Person.lastName.alltime))\\n\\nIf all goes according to plan, you’ll see the following output in both Python 3.X\\nand 2.X, albeit with timing results that will vary per Python and machine:\\n\\nc:\\\\code> py −3 timerdeco-test.py\\n---------------------------------------------------\\n[CCC]==>listcomp: 0.00001, 0.00001\\n[CCC]==>listcomp: 0.57930, 0.57930\\n[0, 2, 4, 6, 8]\\nallTime = 0.5793010457092784\\n\\n[MMM]==>mapcall: 0.00002, 0.00002\\n[MMM]==>mapcall: 1.08609, 1.08611\\n[0, 2, 4, 6, 8]\\nallTime = 1.0861149923442373\\n\\n---------------------------------------------------\\ngiveRaise: 0.00001, 0.00001\\n\\n1346 | Chapter 39:\\u2002Decorators\\n\\n\\x0cgiveRaise: 0.00000, 0.00001\\n55000 120000\\n**lastName: 0.00001, 0.00001\\n**lastName: 0.00000, 0.00001\\nSmith Jones\\n0.00001 0.00001\\n\\n2. The following three files satisfy the second question. The first gives the decorator\\n—it’s been augmented to return the original class in optimized mode (–O), so at-\\ntribute accesses don’t incur a speed hit. Mostly, it just adds the debug mode test\\nstatements and indents the class further to the right:\\n\\n\"\"\"\\nFile access.py (3.X + 2.X)\\nClass decorator with Private and Public attribute declarations.\\nControls external access to attributes stored on an instance, or\\ninherited by it from its classes in any fashion.\\n\\nPrivate declares attribute names that cannot be fetched or assigned\\noutside the decorated class, and Public declares all the names that can.\\n\\nCaveats: in 3.X catches built-ins coded in BuiltinMixins only (expand me);\\nas coded, Public may be less useful than Private for operator overloading.\\n\"\"\"\\nfrom access_builtins import BuiltinsMixin    # A partial set!\\n\\ntraceMe = False\\ndef trace(*args):\\n    if traceMe: print(\\'[\\' + \\' \\'.join(map(str, args)) + \\']\\')\\n\\ndef accessControl(failIf):\\n    def onDecorator(aClass):\\n        if not __debug__:\\n            return aClass\\n        else:\\n            class onInstance(BuiltinsMixin):\\n                def __init__(self, *args, **kargs):\\n                    self.__wrapped = aClass(*args, **kargs)\\n\\n                def __getattr__(self, attr):\\n                    trace(\\'get:\\', attr)\\n                    if failIf(attr):\\n                        raise TypeError(\\'private attribute fetch: \\' + attr)\\n                    else:\\n                        return getattr(self.__wrapped, attr)\\n\\n                def __setattr__(self, attr, value):\\n                    trace(\\'set:\\', attr, value)\\n                    if attr == \\'_onInstance__wrapped\\':\\n                        self.__dict__[attr] = value\\n                    elif failIf(attr):\\n                        raise TypeError(\\'private attribute change: \\' + attr)\\n                    else:\\n                        setattr(self.__wrapped, attr, value)\\n            return onInstance\\n\\nTest Your Knowledge: Answers\\n\\n| 1347\\n\\n\\x0c    return onDecorator\\n\\ndef Private(*attributes):\\n    return accessControl(failIf=(lambda attr: attr in attributes))\\n\\ndef Public(*attributes):\\n    return accessControl(failIf=(lambda attr: attr not in attributes))\\n\\nI’ve  also  used  one  of  our  mix-in  techniques  to  add  some  operator  overloading\\nmethod redefinitions to the wrapper class, so that in 3.X it correctly delegates built-\\nin operations to subject classes that use these methods. As coded, the proxy is a\\ndefault classic class in 2.X that routes these through __getattr__ already, but in\\n3.X is a new-style class that does not. The mix-in used here requires listing such\\nmethods in Public decorators; see earlier for alternatives that do not (but that also\\ndo not allow built-ins to be made private), and expand this class as needed:\\n\\n\"\"\"\\nFile access_builtins.py (from access2_builtins2b.py)\\nRoute some built-in operations back to proxy class __getattr__, so they\\nwork the same in 3.X as direct by-name calls and 2.X\\'s default classic classes.\\nExpand me as needed to include other __X__ names used by proxied objects.\\n\"\"\"\\n\\nclass BuiltinsMixin:\\n    def reroute(self, attr, *args, **kargs):\\n        return self.__class__.__getattr__(self, attr)(*args, **kargs)\\n\\n    def __add__(self, other):\\n        return self.reroute(\\'__add__\\', other)\\n    def __str__(self):\\n        return self.reroute(\\'__str__\\')\\n    def __getitem__(self, index):\\n        return self.reroute(\\'__getitem__\\', index)\\n    def __call__(self, *args, **kargs):\\n        return self.reroute(\\'__call__\\', *args, **kargs)\\n\\n    # Plus any others used by wrapped objects in 3.X only\\n\\nHere too I split the self-test code off to a separate file, so the decorator could be\\nimported  elsewhere  without  triggering  the  tests,  and  without  requiring  a\\n__name__ test and indenting:\\n\\n\"\"\"\\nFile: access-test.py\\nTest code: separate file to allow decorator reuse.\\n\"\"\"\\nimport sys\\nfrom access import Private, Public\\n\\nprint(\\'---------------------------------------------------------\\')\\n# Test 1: names are public if not private\\n\\n@Private(\\'age\\')                             # Person = Private(\\'age\\')(Person)\\nclass Person:                               # Person = onInstance with state\\n\\n1348 | Chapter 39:\\u2002Decorators\\n\\n\\x0c    def __init__(self, name, age):\\n        self.name = name\\n        self.age  = age                     # Inside accesses run normally\\n    def __add__(self, N):\\n        self.age += N                       # Built-ins caught by mix-in in 3.X\\n    def __str__(self):\\n        return \\'%s: %s\\' % (self.name, self.age)\\n\\nX = Person(\\'Bob\\', 40)\\nprint(X.name)                               # Outside accesses validated\\nX.name = \\'Sue\\'\\nprint(X.name)\\nX + 10\\nprint(X)\\n\\ntry:    t = X.age                           # FAILS unless \"python -O\"\\nexcept: print(sys.exc_info()[1])\\ntry:    X.age = 999                         # ditto\\nexcept: print(sys.exc_info()[1])\\n\\nprint(\\'---------------------------------------------------------\\')\\n# Test 2: names are private if not public\\n# Operators must be non-Private or Public in BuiltinMixin used\\n\\n@Public(\\'name\\', \\'__add__\\', \\'__str__\\', \\'__coerce__\\')\\nclass Person:\\n    def __init__(self, name, age):\\n        self.name = name\\n        self.age  = age\\n    def __add__(self, N):\\n        self.age += N                       # Built-ins caught by mix-in in 3.X\\n    def __str__(self):\\n        return \\'%s: %s\\' % (self.name, self.age)\\n\\nX = Person(\\'bob\\', 40)                       # X is an onInstance\\nprint(X.name)                               # onInstance embeds Person\\nX.name = \\'sue\\'\\nprint(X.name)\\nX + 10\\nprint(X)\\n\\ntry:    t = X.age                           # FAILS unless \"python -O\"\\nexcept: print(sys.exc_info()[1])\\ntry:    X.age = 999                         # ditto\\nexcept: print(sys.exc_info()[1])\\n\\nFinally, if all works as expected, this test’s output is as follows in both Python 3.X\\nand 2.X—the same code applied to the same class decorated with Private and then\\nwith Public:\\n\\nc:\\\\code> py −3 access-test.py\\n---------------------------------------------------------\\nBob\\nSue\\nSue: 50\\n\\nTest Your Knowledge: Answers\\n\\n| 1349\\n\\n\\x0cprivate attribute fetch: age\\nprivate attribute change: age\\n---------------------------------------------------------\\nbob\\nsue\\nsue: 50\\nprivate attribute fetch: age\\nprivate attribute change: age\\n\\nc:\\\\code> py −3 -O access-test.py       # Suppresses the four access error messages\\n\\n3. Here’s a generalized argument validator for you to study on your own. It uses a\\npassed-in validation function, to which it passes the test’s criteria value coded for\\nthe argument in the decorator. This handles ranges, type tests, value testers, and\\nalmost anything else you can dream up in an expressive language like Python. I’ve\\nalso refactored the code a bit to remove some redundancy, and automated test\\nfailure  processing.  See  this  module’s  self-test  for  usage  examples  and  expected\\noutput. Per this example’s caveats described earlier, this decorator doesn’t fully\\nwork in nested mode as is—only the most deeply nested validation is run for po-\\nsitional arguments—but its arbitrary valuetest can be used to combine differing\\ntypes of tests in a single decoration (though the amount of code needed in this\\nmode may negate much of its benefits over a simple assert!).\\n\\n\"\"\"\\nFile argtest.py: (3.X + 2.X) function decorator that performs\\narbitrary passed-in validations for arguments passed to any\\nfunction method. Range and type tests are two example uses;\\nvaluetest handles more arbitrary tests on an argument\\'s value.\\n\\nArguments are specified by keyword to the decorator. In the actual\\ncall, arguments may be passed by position or keyword, and defaults\\nmay be omitted.  See self-test code below for example use cases.\\n\\nCaveats: doesn\\'t fully support nesting because call proxy args\\ndiffer; doesn\\'t validate extra args passed to a decoratee\\'s *args;\\nand may be no easier than an assert except for canned use cases.\\n\"\"\"\\ntrace = False\\n\\ndef rangetest(**argchecks):\\n    return argtest(argchecks, lambda arg, vals: arg < vals[0] or arg > vals[1])\\n\\ndef typetest(**argchecks):\\n    return argtest(argchecks, lambda arg, type: not isinstance(arg, type))\\n\\ndef valuetest(**argchecks):\\n    return argtest(argchecks, lambda arg, tester: not tester(arg))\\n\\ndef argtest(argchecks, failif):             # Validate args per failif + criteria\\n    def onDecorator(func):                  # onCall retains func, argchecks, failif\\n        if not __debug__:                   # No-op if \"python -O main.py args...\"\\n\\n1350 | Chapter 39:\\u2002Decorators\\n\\n\\x0c            return func\\n        else:\\n            code = func.__code__\\n            expected = list(code.co_varnames[:code.co_argcount])\\n            def onError(argname, criteria):\\n                 errfmt = \\'%s argument \"%s\" not %s\\'\\n                 raise TypeError(errfmt % (func.__name__, argname, criteria))\\n\\n            def onCall(*pargs, **kargs):\\n                positionals = expected[:len(pargs)]\\n                for (argname, criteria) in argchecks.items():      # For all to test\\n                    if argname in kargs:                           # Passed by name\\n                        if failif(kargs[argname], criteria):\\n                            onError(argname, criteria)\\n\\n                    elif argname in positionals:                   # Passed by posit\\n                        position = positionals.index(argname)\\n                        if failif(pargs[position], criteria):\\n                            onError(argname, criteria)\\n                    else:                                          # Not passed-dflt\\n                        if trace:\\n                            print(\\'Argument \"%s\" defaulted\\' % argname)\\n                return func(*pargs, **kargs)   # OK: run original call\\n            return onCall\\n    return onDecorator\\n\\nif __name__ == \\'__main__\\':\\n    import sys\\n    def fails(test):\\n        try:    result = test()\\n        except: print(\\'[%s]\\' % sys.exc_info()[1])\\n        else:   print(\\'?%s?\\' % result)\\n\\n    print(\\'--------------------------------------------------------------------\\')\\n    # Canned use cases: ranges, types\\n\\n    @rangetest(m=(1, 12), d=(1, 31), y=(1900, 2013))\\n    def date(m, d, y):\\n        print(\\'date = %s/%s/%s\\' % (m, d, y))\\n\\n    date(1, 2, 1960)\\n    fails(lambda: date(1, 2, 3))\\n\\n    @typetest(a=int, c=float)\\n    def sum(a, b, c, d):\\n        print(a + b + c + d)\\n\\n    sum(1, 2, 3.0, 4)\\n    sum(1, d=4, b=2, c=3.0)\\n    fails(lambda: sum(\\'spam\\', 2, 99, 4))\\n    fails(lambda: sum(1, d=4, b=2, c=99))\\n\\n    print(\\'--------------------------------------------------------------------\\')\\n    # Arbitrary/mixed tests\\n\\nTest Your Knowledge: Answers\\n\\n| 1351\\n\\n\\x0c    @valuetest(word1=str.islower, word2=(lambda x: x[0].isupper()))\\n    def msg(word1=\\'mighty\\', word2=\\'Larch\\', label=\\'The\\'):\\n        print(\\'%s %s %s\\' % (label, word1, word2))\\n\\n    msg()  # word1 and word2 defaulted\\n    msg(\\'majestic\\', \\'Moose\\')\\n    fails(lambda: msg(\\'Giant\\', \\'Redwood\\'))\\n    fails(lambda: msg(\\'great\\', word2=\\'elm\\'))\\n\\n    print(\\'--------------------------------------------------------------------\\')\\n    # Manual type and range tests\\n\\n    @valuetest(A=lambda x: isinstance(x, int), B=lambda x: x > 0 and x < 10)\\n    def manual(A, B):\\n        print(A + B)\\n\\n    manual(100, 2)\\n    fails(lambda: manual(1.99, 2))\\n    fails(lambda: manual(100, 20))\\n\\n    print(\\'--------------------------------------------------------------------\\')\\n    # Nesting: runs both, by nesting proxies on original.\\n    # Open issue: outer levels do not validate positionals due\\n    # to call proxy function\\'s differing argument signature;\\n    # when trace=True, in all but the last of these \"X\" is\\n    # classified as defaulted due to the proxy\\'s signature.\\n\\n    @rangetest(X=(1, 10))\\n    @typetest(Z=str)                      # Only innermost validates positional args\\n    def nester(X, Y, Z):\\n        return(\\'%s-%s-%s\\' % (X, Y, Z))\\n\\n    print(nester(1, 2, \\'spam\\'))                # Original function runs properly\\n    fails(lambda: nester(1, 2, 3))             # Nested typetest is run:  positional\\n    fails(lambda: nester(1, 2, Z=3))           # Nested typetest is run:  keyword\\n    fails(lambda: nester(0, 2, \\'spam\\'))        # <==Outer rangetest not run: posit.\\n    fails(lambda: nester(X=0, Y=2, Z=\\'spam\\'))  # Outer rangetest is run:  keyword\\n\\nThis module’s self-test output in both 3.X and 2.X follows (some 2.X object dis-\\nplays vary slightly): as usual, correlate with the source for more insights.\\n\\nc:\\\\code> py −3 argtest.py\\n--------------------------------------------------------------------\\ndate = 1/2/1960\\n[date argument \"y\" not (1900, 2013)]\\n10.0\\n10.0\\n[sum argument \"a\" not <class \\'int\\'>]\\n[sum argument \"c\" not <class \\'float\\'>]\\n--------------------------------------------------------------------\\nThe mighty Larch\\nThe majestic Moose\\n[msg argument \"word1\" not <method \\'islower\\' of \\'str\\' objects>]\\n[msg argument \"word2\" not <function <lambda> at 0x0000000002A096A8>]\\n--------------------------------------------------------------------\\n\\n1352 | Chapter 39:\\u2002Decorators\\n\\n\\x0c102\\n[manual argument \"A\" not <function <lambda> at 0x0000000002A09950>]\\n[manual argument \"B\" not <function <lambda> at 0x0000000002A09B70>]\\n--------------------------------------------------------------------\\n1-2-spam\\n[nester argument \"Z\" not <class \\'str\\'>]\\n[nester argument \"Z\" not <class \\'str\\'>]\\n?0-2-spam?\\n[onCall argument \"X\" not (1, 10)]\\n\\nFinally, as we’ve learned, this decorator’s coding structure works for both functions\\nand methods:\\n\\n# File argtest_testmeth.py\\nfrom argtest import rangetest, typetest\\n\\nclass C:\\n    @rangetest(a=(1, 10))\\n    def meth1(self, a):\\n        return a * 1000\\n\\n    @typetest(a=int)\\n    def meth2(self, a):\\n        return a * 1000\\n\\n>>> from argtest_testmeth import C\\n>>> X = C()\\n>>> X.meth1(5)\\n5000\\n>>> X.meth1(20)\\nTypeError: meth1 argument \"a\" not (1, 10)\\n>>> X.meth2(20)\\n20000\\n>>> X.meth2(20.9)\\nTypeError: meth2 argument \"a\" not <class \\'int\\'>\\n\\nTest Your Knowledge: Answers\\n\\n| 1353\\n\\n\\x0c\\x0cCHAPTER 40\\nMetaclasses\\n\\nIn the prior chapter, we explored decorators and studied various examples of their use.\\nIn this final technical chapter of the book, we’re going to continue our tool-builders\\nfocus and investigate another advanced topic: metaclasses.\\nIn a sense, metaclasses simply extend the code-insertion model of decorators. As we\\nlearned in the prior chapter, function and class decorators allow us to intercept and\\naugment function calls and class instance creation calls. In a similar spirit, metaclasses\\nallow us to intercept and augment class creation—they provide an API for inserting\\nextra logic to be run at the conclusion of a class statement, albeit in different ways than\\ndecorators. Accordingly, they provide a general protocol for managing class objects in\\na program.\\nLike all the subjects dealt with in this part of the book, this is an advanced topic that\\ncan be investigated on an as-needed basis. In practice, metaclasses allow us to gain a\\nhigh level of control over how a set of classes works. This is a powerful concept, and\\nmetaclasses are not intended for most application programmers. Nor, frankly, is this a\\ntopic for the faint of heart—some parts of this chapter may warrant extra focus (and\\nothers might even owe attribution to Dr. Seuss!).\\nOn the other hand, metaclasses open the door to a variety of coding patterns that may\\nbe difficult or impossible to achieve otherwise, and they are especially of interest to\\nprogrammers seeking to write flexible APIs or programming tools for others to use.\\nEven if you don’t fall into that category, though, metaclasses can teach you much about\\nPython’s class model in general (as we’ll see, they even impact inheritance), and are\\nprerequisite  to  understanding  code  that  employs  them.  Like  other  advanced  tools,\\nmetaclasses have begun appearing in Python programs more often than their creators\\nmay have intended.\\nAs in the prior chapter, part of our goal here is also to show more realistic code examples\\nthan we did earlier in this book. Although metaclasses are a core language topic and\\nnot themselves an application domain, part of this chapter’s agenda is to spark your\\ninterest  in  exploring  larger  application-programming  examples  after  you  finish  this\\nbook.\\n\\n1355\\n\\n\\x0cBecause this is the final technical chapter in this book, it also begins to wrap up some\\nthreads concerning Python itself that we’ve met often along the way and will finalize\\nin the conclusion that follows. Where you go after this book is up to you, of course,\\nbut  in  an  open  source  project  it’s  important  to  keep  the  big  picture  in  mind  while\\nhacking the small details.\\n\\nTo Metaclass or Not to Metaclass\\nMetaclasses are perhaps the most advanced topic in this book, if not the Python lan-\\nguage as a whole. To borrow a quote from the comp.lang.python newsgroup by veteran\\nPython core developer Tim Peters (who is also the author of the famous “import this”\\nPython motto):\\n\\n[Metaclasses] are deeper magic than 99% of users should ever worry about. If you wonder\\nwhether you need them, you don’t (the people who actually need them know with cer-\\ntainty that they need them, and don’t need an explanation about why).\\n\\nIn other words, metaclasses are primarily intended for a subset of programmers build-\\ning APIs and tools for others to use. In many (if not most) cases, they are probably not\\nthe best choice in applications work. This is especially true if you’re developing code\\nthat other people will use in the future. Coding something “because it seems cool” is\\nnot generally a reasonable justification, unless you are experimenting or learning.\\nStill, metaclasses have a wide variety of potential roles, and it’s important to know when\\nthey can be useful. For example, they can be used to enhance classes with features like\\ntracing, object persistence, exception logging, and more. They can also be used to con-\\nstruct portions of a class at runtime based upon configuration files, apply function\\ndecorators to every method of a class generically, verify conformance to expected in-\\nterfaces, and so on.\\nIn their more grandiose incarnations, metaclasses can even be used to implement al-\\nternative coding patterns such as aspect-oriented programming, object/relational map-\\npers (ORMs) for databases, and more. Although there are often alternative ways to\\nachieve such results—as we’ll see, the roles of class decorators and metaclasses often\\nintersect—metaclasses provide a formal model tailored to those tasks. We don’t have\\nspace to explore all such applications first-hand in this chapter, of course, but you\\nshould feel free to search the Web for additional use cases after studying the basics here.\\nProbably the reason for studying metaclasses most relevant to this book is that this\\ntopic can help demystify Python’s class mechanics in general. For instance, we’ll see\\nthat they are an intrinsic part of the language’s new-style inheritance model finally\\nformalized in full here. Although you may or may not code or reuse them in your work,\\na cursory understanding of metaclasses can impart a deeper understanding of Python\\nat large.1\\n\\n1356 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cIncreasing Levels of “Magic”\\nMost of this book has focused on straightforward application-coding techniques—the\\nmodules, functions, and classes that most programmers spend their time writing to\\nachieve real-world goals. The majority of Python’s users may use classes and make\\ninstances, and might even do a bit of operator overloading, but they probably won’t\\nget too deep into the details of how their classes actually work.\\nHowever, in this book we’ve also seen a variety of tools that allow us to control Python’s\\nbehavior in generic ways, and that often have more to do with Python internals or tool\\nbuilding than with application-programming domains. As a review, and to help us place\\nmetaclasses in the tools spectrum:\\n\\nIntrospection attributes and tools\\n\\nSpecial attributes like __class__ and __dict__ allow us to inspect internal imple-\\nmentation aspects of Python objects, in order to process them generically—to list\\nall attributes of an object, display a class’s name, and so on. As we’ve also seen,\\ntools such as dir and getattr can serve similar roles when “virtual” attributes such\\nas slots must be supported.\\n\\nOperator overloading methods\\n\\nSpecially named methods such as __str__ and __add__ coded in classes intercept\\nand provide behavior for built-in operations applied to class instances, such as\\nprinting, expression operators, and so on. They are run automatically in response\\nto built-in operations and allow classes to conform to expected interfaces.\\n\\nAttribute interception methods\\n\\nA special category of operator overloading methods provides a way to intercept\\nattribute  accesses  on \\ninstances  generically:  __getattr__,  __setattr__,\\n__delattr__, and __getattribute__ allow wrapper (a.k.a. proxy) classes to insert\\nautomatically run code that may validate attribute requests and delegate them to\\nembedded objects. They allow any number of attributes of an object to be com-\\nputed when accessed—either selected attributes, or all of them.\\n\\nClass properties\\n\\nThe property built-in allows us to associate code with a specific class attribute that\\nis automatically run when the attribute is fetched, assigned, or deleted. Though\\nnot as generic as the prior paragraph’s tools, properties allow for automatic code\\ninvocation on access to specific attributes.\\n\\nClass attribute descriptors\\n\\nReally, property is a succinct way to define an attribute descriptor that runs func-\\ntions  on  access  automatically.  Descriptors  allow  us  to  code  in  a  separate  class\\n\\n1. And to quote a Python 3.3 error message I just came across: “TypeError: metaclass conflict: the metaclass\\nof a derived class must be a (non-strict) subclass of the metaclasses of all its bases” (!). This reflects an\\nerroneous use of a module as a superclass, but metaclasses may not be as optional as developers imply\\n—a theme we’ll revisit in the next chapter’s conclusion to this book.\\n\\nTo Metaclass or Not to Metaclass\\n\\n| 1357\\n\\n\\x0c__get__, __set__, and __delete__ handler methods that are run automatically when\\nan attribute assigned to an instance of that class is accessed. They provide a general\\nway to insert arbitrary code that is run implicitly when a specific attribute is ac-\\ncessed as part of the normal attribute lookup procedure.\\n\\nFunction and class decorators\\n\\nAs we saw in Chapter 39, the special @callable syntax for decorators allows us to\\nadd logic to be automatically run when a function is called or a class instance is\\ncreated. This wrapper logic can trace or time calls, validate arguments, manage all\\ninstances of a class, augment instances with extra behavior such as attribute fetch\\nvalidation, and more. Decorator syntax inserts name-rebinding logic to be run at\\nthe end of function and class definition statements—decorated function and class\\nnames may be rebound to either augmented original objects, or to object proxies\\nthat intercept later calls.\\n\\nMetaclasses\\n\\nThe last topic of magic introduced in Chapter 32, which we take up here.\\n\\nAs mentioned in this chapter’s introduction, metaclasses are a continuation of this story\\n—they allow us to insert logic to be run automatically at the end of a class statement,\\nwhen a class object is being created. Though strongly reminiscent of class decorators,\\nthe metaclass mechanism doesn’t rebind the class name to a decorator callable’s result,\\nbut rather routes creation of the class itself to specialized logic.\\n\\nA Language of Hooks\\nIn other words, metaclasses are ultimately just another way to define automatically run\\ncode. With the tools listed in the prior section, Python provides ways for us to interject\\nlogic in a variety of contexts—at operator evaluation, attribute access, function calls,\\nclass instance creation, and now class object creation. It’s a language with hooks galore\\n—a feature open to abuse like any other, but one that also offers the flexibility that\\nsome programmers desire, and that some programs may require.\\nAs we’ve also seen, many of these advanced Python tools have intersecting roles. For\\nexample, attributes can often be managed with properties, descriptors, or attribute\\ninterception methods. As we’ll see in this chapter, class decorators and metaclasses can\\noften be used interchangeably as well. By way of preview:\\n\\n• Although class decorators are often used to manage instances, they can also be used\\n\\nto manage classes instead, much like metaclasses.\\n\\n• Similarly, while metaclasses are designed to augment class construction, they can\\n\\nalso insert proxies to manage instances instead, much like class decorators.\\n\\nIn fact, the main functional difference between these two tools is simply their place in\\nthe timing of class creation. As we saw in the prior chapter, class decorators run after\\nthe decorated class has already been created. Thus, they are often used to add logic to\\n\\n1358 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cbe run at instance creation time. When they do provide behavior for a class, it is typically\\nthrough changes or proxies, instead of a more direct relationship.\\nAs we’ll see here, metaclasses, by contrast, run during class creation to make and return\\nthe  new  client  class.  Therefore,  they  are  often  used  for  managing  or  augmenting\\nclasses themselves, and can even provide methods to process the classes that are created\\nfrom them, via a direct instance relationship.\\nFor example, metaclasses can be used to add decoration to all methods of classes au-\\ntomatically, register all classes in use to an API, add user-interface logic to classes au-\\ntomatically, create or extend classes from simplified specifications in text files, and so\\non. Because they can control how classes are made—and by proxy the behavior their\\ninstances acquire—metaclass applicability is potentially very wide.\\nAs we’ll also see here, though, these two tools are more similar than different in many\\ncommon roles. Since tool choices are sometimes partly subjective, knowledge of the\\nalternatives can help you pick the right tool for a given task. To understand the options\\nbetter, let’s see how metaclasses stack up.\\n\\nThe Downside of “Helper” Functions\\nAlso like the decorators of the prior chapter, metaclasses are often optional from a\\ntheoretical perspective. We can usually achieve the same effect by passing class objects\\nthrough manager functions—sometimes known as helper functions—much as we can\\nachieve the goals of decorators by passing functions and instances through manager\\ncode. Just like decorators, though, metaclasses:\\n\\n• Provide a more formal and explicit structure\\n• Help ensure that application programmers won’t forget to augment their classes\\n\\naccording to an API’s requirements\\n\\n• Avoid code redundancy and its associated maintenance costs by factoring class\\n\\ncustomization logic into a single location, the metaclass\\n\\nTo illustrate, suppose we want to automatically insert a method into a set of classes.\\nOf course, we could do this with simple inheritance, if the subject method is known\\nwhen we code the classes. In that case, we can simply code the method in a superclass\\nand have all the classes in question inherit from it:\\n\\nclass Extras:\\n    def extra(self, args):              # Normal inheritance: too static\\n        ...\\n\\nclass Client1(Extras): ...              # Clients inherit extra methods\\nclass Client2(Extras): ...\\nclass Client3(Extras): ...\\n\\nX = Client1()                           # Make an instance\\nX.extra()                               # Run the extra methods\\n\\nTo Metaclass or Not to Metaclass\\n\\n| 1359\\n\\n\\x0cSometimes, though, it’s impossible to predict such augmentation when classes are co-\\nded. Consider the case where classes are augmented in response to choices made in a\\nuser interface at runtime, or to specifications typed in a configuration file. Although\\nwe could code every class in our imaginary set to manually check these, too, it’s a lot\\nto ask of clients (required is abstract here—it’s something to be filled in):\\n\\ndef extra(self, arg): ...\\n\\nclass Client1: ...                      # Client augments: too distributed\\nif required():\\n    Client1.extra = extra\\n\\nclass Client2: ...\\nif required():\\n    Client2.extra = extra\\n\\nclass Client3: ...\\nif required():\\n    Client3.extra = extra\\n\\nX = Client1()\\nX.extra()\\n\\nWe can add methods to a class after the class statement like this because a class-level\\nmethod is just a function that is associated with a class and has a first argument to\\nreceive the self instance. Although this works, it might become untenable for larger\\nmethod sets, and puts all the burden of augmentation on client classes (and assumes\\nthey’ll remember to do this at all!).\\nIt would be better from a maintenance perspective to isolate the choice logic in a single\\nplace.  We  might  encapsulate  some  of  this  extra  work  by  routing  classes  through  a\\nmanager function—such a manager function would extend the class as required and\\nhandle all the work of runtime testing and configuration:\\n\\ndef extra(self, arg): ...\\n\\ndef extras(Class):                      # Manager function: too manual\\n    if required():\\n        Class.extra = extra\\n\\nclass Client1: ...\\nextras(Client1)\\n\\nclass Client2: ...\\nextras(Client2)\\n\\nclass Client3: ...\\nextras(Client3)\\n\\nX = Client1()\\nX.extra()\\n\\n1360 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cThis code runs the class through a manager function immediately after it is created.\\nAlthough manager functions like this one can achieve our goal here, they still put a\\nfairly heavy burden on class coders, who must understand the requirements and adhere\\nto them in their code. It would be better if there was a simple way to enforce the aug-\\nmentation in the subject classes, so that they don’t need to deal with the augmentation\\nso explicitly, and would be less likely to forget to use it altogether. In other words, we’d\\nlike to be able to insert some code to run automatically at the end of a class statement,\\nto augment the class.\\nThis is exactly what metaclasses do—by declaring a metaclass, we tell Python to route\\nthe creation of the class object to another class we provide:\\n\\ndef extra(self, arg): ...\\n\\nclass Extras(type):\\n    def __init__(Class, classname, superclasses, attributedict):\\n        if required():\\n            Class.extra = extra\\n\\nclass Client1(metaclass=Extras): ...    # Metaclass declaration only (3.X form)\\nclass Client2(metaclass=Extras): ...    # Client class is instance of meta\\nclass Client3(metaclass=Extras): ...\\n\\nX = Client1()                           # X is instance of Client1\\nX.extra()\\n\\nBecause Python invokes the metaclass automatically at the end of the class statement\\nwhen the new class is created, it can augment, register, or otherwise manage the class\\nas needed. Moreover, the only requirement for the client classes is that they declare the\\nmetaclass; every class that does so will automatically acquire whatever augmentation\\nthe metaclass provides, both now and in the future if the metaclass changes.\\nOf course, this is the standard rationale, which you’ll need to judge for yourself—in\\ntruth, clients might forget to list a metaclass just as easily as they could forget to call a\\nmanager function! Still, the explicit nature of metaclasses may make this less likely.\\nMoreover, metaclasses have additional potentials we haven’t yet seen. Although it may\\nbe difficult to glean from this small example, metaclasses generally handle such tasks\\nbetter than more manual approaches.\\n\\nMetaclasses Versus Class Decorators: Round 1\\nHaving said that, it’s also important to note that the class decorators described in the\\npreceding chapter sometimes overlap with metaclasses—in terms of both utility and\\nbenefit. Although they are often used for managing instances, class decorators can also\\naugment classes, independent of any created instances. Their syntax makes their usage\\nsimilarly explicit, and arguably more obvious than manager function calls.\\nFor example, suppose we coded our manager function to return the augmented class,\\ninstead of simply modifying it in place. This would allow a greater degree of flexibility,\\n\\nTo Metaclass or Not to Metaclass\\n\\n| 1361\\n\\n\\x0cbecause the manager would be free to return any type of object that implements the\\nclass’s expected interface:\\n\\ndef extra(self, arg): ...\\n\\ndef extras(Class):\\n    if required():\\n        Class.extra = extra\\n    return Class\\n\\nclass Client1: ...\\nClient1 = extras(Client1)\\n\\nclass Client2: ...\\nClient2 = extras(Client2)\\n\\nclass Client3: ...\\nClient3 = extras(Client3)\\n\\nX = Client1()\\nX.extra()\\n\\nIf you think this is starting to look reminiscent of class decorators, you’re right. In the\\nprior chapter we emphasized class decorators’ role in augmenting instance creation\\ncalls. Because they work by automatically rebinding a class name to the result of a\\nfunction, though, there’s no reason that we can’t use them to augment the class by\\nchanging it before any instances are ever created. That is, class decorators can apply\\nextra logic to classes, not just instances, at class creation time:\\n\\ndef extra(self, arg): ...\\n\\ndef extras(Class):\\n    if required():\\n        Class.extra = extra\\n    return Class\\n\\n@extras\\nclass Client1: ...             # Client1 = extras(Client1)\\n\\n@extras\\nclass Client2: ...             # Rebinds class independent of instances\\n\\n@extras\\nclass Client3: ...\\n\\nX = Client1()                  # Makes instance of augmented class\\nX.extra()                      # X is instance of original Client1\\n\\nDecorators essentially automate the prior example’s manual name rebinding here. Just\\nas for metaclasses, because this decorator returns the original class, instances are made\\nfrom it, not from a wrapper object. In fact, instance creation is not intercepted at all in\\nthis example.\\n\\n1362 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cIn this specific case—adding methods to a class when it’s created—the choice between\\nmetaclasses and decorators is somewhat arbitrary. Decorators can be used to manage\\nboth instances and classes, and intersect most strongly with metaclasses in the second\\nof these roles, but this discrimination is not absolute. In fact, the roles of each are\\ndetermined in part by their mechanics.\\nAs we’ll see ahead, decorators technically correspond to metaclass __init__ methods,\\nused  to  initialize  newly  created  classes.  Metaclasses  have  additional  customization\\nhooks beyond class initialization, though, and may perform arbitrary class construction\\ntasks that might be more difficult with decorators. This can make them more complex,\\nbut also better suited for augmenting classes as they are being formed.\\nFor example, metaclasses also have a __new__ method used to create a class, which has\\nno analogy in decorators; making a new class in a decorator would incur an extra step.\\nMoreover, metaclasses may also provide behavior acquired by classes in the form of\\nmethods, which have no direct counterpart in decorators either; decorators must pro-\\nvide class behavior is less direct ways.\\nConversely,  because  metaclasses  are  designed  to  manage  classes,  applying  them  to\\nmanaging instances alone is less optimal. Because they are also responsible for making\\nthe class itself, metaclasses incur this as an extra step in instance management roles.\\nWe’ll  explore  these  differences  in  code  later  in  this  chapter,  and  will  flesh  out  this\\nsection’s partial code into a real working example later in this chapter. To understand\\nhow metaclasses do their work, though, we first need to get a clearer picture of their\\nunderlying model.\\n\\nThere’s Magic, and Then There’s Magic\\n\\nThis chapter’s “Increasing Levels of Magic” list deals with types of magic beyond those\\nwidely seen as beneficial by programmers. Some might add Python’s functional tools\\nlike closures and generators, and even its basic OOP support, to this list—the former\\nrelying on scope retention and automatic generator object creation, and the latter on\\ninheritance attribute search and a special first function argument. Though based on\\nmagic too, these represent paradigms that ease the task of programming by providing\\nabstractions above and beyond the underlying hardware architecture.\\n\\nFor example, OOP—Python’s earlier paradigm—is broadly accepted in the software\\nworld. It provides a model for writing programs that is more complete, explicit, and\\nrichly structured than functional tools. That is, some levels of magic are considered\\nmore warranted than others; after all, if it were not for some magic, programs would\\nstill consist of machine code (or physical switches).\\n\\nIt’s usually the accumulation of new magic that puts systems at risk of breaching a\\ncomplexity threshold—such as adding a functional paradigm to what was always an\\nOO language, or adding redundant or advanced ways to achieve goals that are rarely\\npursued in the common practice of most users. Such magic can set the entry bar far too\\nhigh for a large part of your tool’s audience.\\n\\nTo Metaclass or Not to Metaclass\\n\\n| 1363\\n\\n\\x0cMoreover, some magic is imposed on its users more than others. The translation step\\nof a compiler, for instance, does not generally require its users to be compiler devel-\\nopers. By contrast, Python’s super assumes full mastery and deployment of the arguably\\nobscure and artificial MRO algorithm. The new-style inheritance algorithm presented\\nin this chapter similarly assumes descriptors, metaclasses, and the MRO as its prereq-\\nuisites—all advanced tools in their own right. Even implicit “hooks” like descriptors\\nremain implicit only until their first failure or maintenance cycle. Such magic exposed\\nescalates a tool’s prerequisites and downgrades its usability.\\n\\nIn open source systems, only time and downloads can determine where such thresholds\\nmay lie. Finding the proper balance of power and complexity depends as much on\\nshifting opinion as on technology. Subjective factors aside, though, new magic that\\nimposes itself on users inevitably skews a system’s learning curve higher—a topic we’ll\\nreturn to in the next chapter’s final words.\\n\\nThe Metaclass Model\\nTo understand metaclasses, you first need to understand a bit more about Python’s\\ntype model and what happens at the end of a class statement. As we’ll see here, the\\ntwo are intimately related.\\n\\nClasses Are Instances of type\\nSo far in this book, we’ve done most of our work by making instances of built-in types\\nlike lists and strings, as well as instances of classes we code ourselves. As we’ve seen,\\ninstances of classes have some state information attributes of their own, but they also\\ninherit behavioral attributes from the classes from which they are made. The same holds\\ntrue for built-in types; list instances, for example, have values of their own, but they\\ninherit methods from the list type.\\nWhile we can get a lot done with such instance objects, Python’s type model turns out\\nto be a bit richer than I’ve formally described. Really, there’s a hole in the model we’ve\\nseen thus far: if instances are created from classes, what is it that creates our classes? It\\nturns out that classes are instances of something, too:\\n\\n• In Python 3.X, user-defined class objects are instances of the object named type,\\n\\nwhich is itself a class.\\n\\n• In Python 2.X, new-style classes inherit from object, which is a subclass of type;\\n\\nclassic classes are instances of type and are not created from a class.\\n\\nWe explored the notion of types in Chapter 9 and the relationship of classes to types\\nin Chapter 32, but let’s review the basics here so we can see how they apply to meta-\\nclasses.\\nRecall that the type built-in returns the type of any object (which is itself an object)\\nwhen called with a single argument. For built-in types like lists, the type of the instance\\n\\n1364 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cis the built-in list type, but the type of the list type is the type type itself—the type object\\nat the top of the hierarchy creates specific types, and specific types create instances.\\nYou can see this for yourself at the interactive prompt. In Python 3.X, for example, the\\ntype of a list instance is the list class, and the type of the list class is the type class:\\n\\nC:\\\\code> py −3                        # In 3.X:\\n>>> type([]), type(type([]))          # List instance is created from list class\\n(<class \\'list\\'>, <class \\'type\\'>)      # List class is created from type class\\n>>> type(list), type(type)            # Same, but with type names\\n(<class \\'type\\'>, <class \\'type\\'>)      # Type of type is type: top of hierarchy\\n\\nAs we learned when studying new-style class changes in Chapter 32, the same is gen-\\nerally true in Python 2.X, but types are not quite the same as classes—type is a unique\\nkind of built-in object that caps the type hierarchy and is used to construct types:\\n\\nC:\\\\code> py −2\\n>>> type([]), type(type([]))          # In 2.X, type is a bit different\\n(<type \\'list\\'>, <type \\'type\\'>)\\n>>> type(list), type(type)\\n(<type \\'type\\'>, <type \\'type\\'>)\\n\\nAs it happens, the type/instance relationship holds true for user-defined classes as well:\\ninstances are created from classes, and classes are created from type. In Python 3.X,\\nthough, the notion of a “type” is merged with the notion of a “class.” In fact, the two\\nare essentially synonyms—classes are types, and types are classes. That is:\\n\\n• Types are defined by classes that derive from type.\\n• User-defined classes are instances of type classes.\\n• User-defined classes are types that generate instances of their own.\\n\\nAs we saw earlier, this equivalence affects code that tests the type of instances: the type\\nof an instance is the class from which it was generated. It also has implications for the\\nway that classes are created that turn out to be the key to this chapter’s subject. Because\\nclasses are normally created from a root type class by default, most programmers don’t\\nneed to think about this type/class equivalence. However, it opens up new possibilities\\nfor customizing both classes and their instances.\\nFor example, all user-defined classes in 3.X (and new-style classes in 2.X) are instances\\nof the type class, and instance objects are instances of their classes; in fact, classes now\\nhave a __class__ that links to type, just as an instance has a __class__ that links to the\\nclass from which it was made:\\n\\nC:\\\\code> py −3\\n>>> class C: pass                   # 3.X class object (new-style)\\n>>> X = C()                         # Class instance object\\n\\n>>> type(X)                         # Instance is instance of class\\n<class \\'__main__.C\\'>\\n>>> X.__class__                     # Instance\\'s class\\n<class \\'__main__.C\\'>\\n\\n>>> type(C)                         # Class is instance of type\\n\\nThe Metaclass Model\\n\\n| 1365\\n\\n\\x0c<class \\'type\\'>\\n>>> C.__class__                     # Class\\'s class is type\\n<class \\'type\\'>\\n\\nNotice especially the last two lines here—classes are instances of the type class, just as\\nnormal instances are instances of a user-defined class. This works the same for both\\nbuilt-ins and user-defined class types in 3.X. In fact, classes are not really a separate\\nconcept at all: they are simply user-defined types, and type itself is defined by a class.\\nIn Python 2.X, things work similarly for new-style classes derived from object, because\\nthis enables 3.X class behavior (as we’ve seen, 3.X adds object to the __bases__ super-\\nclass tuple of top-level root classes automatically to qualify them as new-style):\\n\\nC:\\\\code> py −2\\n>>> class C(object): pass           # In 2.X new-style classes,\\n>>> X = C()                         # classes have a class too\\n\\n>>> type(X)\\n<class \\'__main__.C\\'>\\n>>> X.__class__\\n<class \\'__main__.C\\'>\\n\\n>>> type(C)\\n<type \\'type\\'>\\n>>> C.__class__\\n<type \\'type\\'>\\n\\nClassic classes in 2.X are a bit different, though—because they reflect the original class\\nmodel in older Pythons, they do not have a __class__ link, and like built-in types in\\n2.X they are instances of type, not a type class (I’ve shortened some of the hex addresses\\nin object displays in this chapter for clarity):\\n\\nC:\\\\code> py −2\\n>>> class C: pass                   # In 2.X classic classes,\\n>>> X = C()                         # classes have no class themselves\\n\\n>>> type(X)\\n<type \\'instance\\'>\\n>>> X.__class__\\n<class __main__.C at 0x005F85A0>\\n\\n>>> type(C)\\n<type \\'classobj\\'>\\n>>> C.__class__\\nAttributeError: class C has no attribute \\'__class__\\'\\n\\nMetaclasses Are Subclasses of Type\\nWhy would we care that classes are instances of a type class in 3.X? It turns out that\\nthis is the hook that allows us to code metaclasses. Because the notion of type is the\\nsame as class today, we can subclass type with normal object-oriented techniques and\\nclass syntax to customize it. And because classes are really instances of the type class,\\n\\n1366 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0ccreating classes from customized subclasses of type allows us to implement custom\\nkinds of classes. In full detail, this all works out quite naturally—in 3.X, and in 2.X\\nnew-style classes:\\n\\n• type is a class that generates user-defined classes.\\n• Metaclasses are subclasses of the type class.\\n• Class objects are instances of the type class, or a subclass thereof.\\n• Instance objects are generated from a class.\\n\\nIn other words, to control the way classes are created and augment their behavior, all\\nwe need to do is specify that a user-defined class be created from a user-defined meta-\\nclass instead of the normal type class.\\nNotice that this type instance relationship is not quite the same as normal inheritance.\\nUser-defined classes may also have superclasses from which they and their instances\\ninherit attributes as usual. As we’ve seen, inheritance superclasses are listed in paren-\\ntheses in the class statement and show up in a class’s __bases__ tuple. The type from\\nwhich a class is created, though, and of which it is an instance, is a different relationship.\\nInheritance searches instance and class namespace dictionaries, but classes may also\\nacquire behavior from their type that is not exposed to the normal inheritance search.\\nTo lay the groundwork for understanding this distinction, the next section describes\\nthe procedure Python follows to implement this instance-of type relationship.\\n\\nClass Statement Protocol\\nSubclassing the type class to customize it is really only half of the magic behind meta-\\nclasses. We still need to somehow route a class’s creation to the metaclass, instead of\\nthe default type. To fully understand how this is arranged, we also need to know how\\nclass statements do their business.\\nWe’ve already learned that when Python reaches a class statement, it runs its nested\\nblock of code to create its attributes—all the names assigned at the top level of the\\nnested code block generate attributes in the resulting class object. These names are\\nusually method functions created by nested  defs, but they can also be arbitrary at-\\ntributes assigned to create class data shared by all instances.\\nTechnically speaking, Python follows a standard protocol to make this happen: at the\\nend of a class statement, and after running all its nested code in a namespace dictionary\\ncorresponding  to  the  class’s  local  scope,  Python  calls  the  type  object  to  create  the\\nclass object like this:\\n\\nclass = type(classname, superclasses, attributedict)\\n\\nThe type object in turn defines a __call__ operator overloading method that runs two\\nother methods when the type object is called:\\n\\nThe Metaclass Model\\n\\n| 1367\\n\\n\\x0ctype.__new__(typeclass, classname, superclasses, attributedict)\\ntype.__init__(class, classname, superclasses, attributedict)\\n\\nThe __new__ method creates and returns the new class object, and then the __init__\\nmethod initializes the newly created object. As we’ll see in a moment, these are the\\nhooks that metaclass subclasses of type generally use to customize classes.\\nFor example, given a class definition like the following for Spam:\\n\\nclass Eggs: ...                  # Inherited names here\\n\\nclass Spam(Eggs):                # Inherits from Eggs\\n    data = 1                     # Class data attribute\\n    def meth(self, arg):         # Class method attribute\\n        return self.data + arg\\n\\nPython will internally run the nested code block to create two attributes of the class\\n(data and meth), and then call the type object to generate the class object at the end of\\nthe class statement:\\n\\nSpam = type(\\'Spam\\', (Eggs,), {\\'data\\': 1, \\'meth\\': meth, \\'__module__\\': \\'__main__\\'})\\n\\nIn fact, you can call type this way yourself to create a class dynamically—albeit here\\nwith a fabricated method function and empty superclasses tuple (Python adds object\\nautomatically in both 3.X and 2.X):\\n\\n>>> x = type(\\'Spam\\', (), {\\'data\\': 1, \\'meth\\': (lambda x, y: x.data + y)})\\n>>> i = x()\\n>>> x, i\\n(<class \\'__main__.Spam\\'>, <__main__.Spam object at 0x029E7780>)\\n>>> i.data, i.meth(2)\\n(1, 3)\\n\\nThe class produced is exactly like that you’d get from running a class statement:\\n\\n>>> x.__bases__\\n(<class \\'object\\'>,)\\n>>> [(a, v) for (a, v) in x.__dict__.items() if not a.startswith(\\'__\\')]\\n[(\\'data\\', 1), (\\'meth\\', <function <lambda> at 0x0297A158>)]\\n\\nBecause this type call is made automatically at the end of the class statement, though,\\nit’s  an  ideal  hook  for  augmenting  or  otherwise  processing  a  class.  The  trick  lies  in\\nreplacing the default type with a custom subclass that will intercept this call. The next\\nsection shows how.\\n\\nDeclaring Metaclasses\\nAs we’ve just seen, classes are created by the type class by default. To tell Python to\\ncreate a class with a custom metaclass instead, you simply need to declare a metaclass\\nto intercept the normal instance creation call in a user-defined class. How you do so\\ndepends on which Python version you are using.\\n\\n1368 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cDeclaration in 3.X\\nIn Python 3.X, list the desired metaclass as a keyword argument in the class header:\\n\\nclass Spam(metaclass=Meta):                   # 3.X version (only)\\n\\nInheritance superclasses can be listed in the header as well. In the following, for ex-\\nample, the new class Spam inherits from superclass Eggs, but is also an instance of and\\nis created by metaclass Meta:\\n\\nclass Spam(Eggs, metaclass=Meta):             # Normal supers OK: must list first\\n\\nIn this form, superclasses must be listed before the metaclass; in effect, the ordering\\nrules used for keyword arguments in function calls apply here.\\n\\nDeclaration in 2.X\\nWe can get the same effect in Python 2.X, but we must specify the metaclass differently\\n—using a class attribute instead of a keyword argument:\\n\\nclass Spam(object):                           # 2.X version (only), object optional?\\n    __metaclass__ = Meta\\n\\nclass Spam(Eggs, object):                     # Normal supers OK: object suggested\\n    __metaclass__ = Meta\\n\\nTechnically, some classes in 2.X do not have to derive from object explicitly to make\\nuse of metaclasses. The generalized metaclass dispatch mechanism was added at the\\nsame  time  as  new-style  classes,  but  is  not  itself  bound  to  them.  It  does,  however,\\nproduce them—in the presence of a __metaclass__ declaration, 2.X makes the resulting\\nclass new-style automatically, adding object to its __bases__ sequence. In the absence\\nof this declaration, 2.X simply uses the classic class creator as the metaclass default.\\nBecause of this, some classes in 2.X require only the __metaclass__ attribute.\\nOn the other hand, notice that metaclasses imply that your class will be new-style in\\n2.X even without an explicit object. They’ll behave somewhat differently as outlined\\nin Chapter 32, and as we’ll see ahead 2.X may require that they or their superclasses\\nderive from object explicitly, because a new-style class cannot have only classic super-\\nclasses in this context. Given this, deriving from object doesn’t hurt as a sort of warning\\nabout the class’s nature, and may be required to avoid potential problems.\\nAlso in 2.X, a module level __metaclass__ global variable is available to link all classes\\nin the module to a metaclass. This is no longer supported in 3.X, as it was intended as\\na temporary measure to make it easier to default to new-style classes without deriving\\nevery class from object. Python 3.X also ignores the 2.X class attribute, and the 3.X\\nkeyword form is a syntax error in 2.X, so there is no simple portability route. Apart\\nfrom differing syntax, though, metaclass declaration in 2.X and 3.X has the same effect,\\nwhich we turn to next.\\n\\nDeclaring Metaclasses\\n\\n| 1369\\n\\n\\x0cMetaclass Dispatch in Both 3.X and 2.X\\nWhen a specific metaclass is declared per the prior sections’ syntax, the call to create\\nthe class object run at the end of the class statement is modified to invoke the meta-\\nclass instead of the type default:\\n\\nclass = Meta(classname, superclasses, attributedict)\\n\\nAnd because the metaclass is a subclass of type, the type class’s __call__ delegates the\\ncalls to create and initialize the new class object to the metaclass, if it defines custom\\nversions of these methods:\\n\\nMeta.__new__(Meta, classname, superclasses, attributedict)\\nMeta.__init__(class, classname, superclasses, attributedict)\\n\\nTo demonstrate, here’s the prior section’s example again, augmented with a 3.X met-\\naclass specification:\\n\\nclass Spam(Eggs, metaclass=Meta):      # Inherits from Eggs, instance of Meta\\n    data = 1                           # Class data attribute\\n    def meth(self, arg):               # Class method attribute\\n        return self.data + arg\\n\\nAt the end of this class statement, Python internally runs the following to create the\\nclass object—again, a call you could make manually too, but automatically run by\\nPython’s class machinery:\\n\\nSpam = Meta(\\'Spam\\', (Eggs,), {\\'data\\': 1, \\'meth\\': meth, \\'__module__\\': \\'__main__\\'})\\n\\nIf the metaclass defines its own versions of __new__ or __init__, they will be invoked\\nin turn during this call by the inherited type class’s __call__ method, to create and\\ninitialize the new class. The net effect is to automatically run methods the metaclass\\nprovides, as part of the class construction process. The next section shows how we\\nmight go about coding this final piece of the metaclass puzzle.\\n\\nThis chapter uses Python 3.X metaclass keyword argument syntax, not\\nthe 2.X class attribute. 2.X readers will need to translate, but version\\nneutrality  is  not  straightforward  here—3.X  doesn’t  recognize  the  at-\\ntribute and 2.X doesn’t allow keyword syntax—and listing examples\\ntwice doesn’t address portability (or chapter size!).\\n\\nCoding Metaclasses\\nSo far, we’ve seen how Python routes class creation calls to a metaclass, if one is speci-\\nfied and provided. How, though, do we actually code a metaclass that customizes type?\\nIt  turns  out  that  you  already  know  most  of  the  story—metaclasses  are  coded  with\\nnormal Python class statements and semantics. By definition, they are simply classes\\nthat inherit from type. Their only substantial distinctions are that Python calls them\\n\\n1370 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cautomatically at the end of a class statement, and that they must adhere to the inter-\\nface expected by the type superclass.\\n\\nA Basic Metaclass\\nPerhaps  the  simplest  metaclass  you  can  code  is  simply  a  subclass  of  type  with  a\\n__new__ method that creates the class object by running the default version in type. A\\nmetaclass __new__ like this is run by the __call__ method inherited from type; it typi-\\ncally  performs  whatever  customization  is  required  and  calls  the  type  superclass’s\\n__new__ method to create and return the new class object:\\n\\nclass Meta(type):\\n    def __new__(meta, classname, supers, classdict):\\n        # Run by inherited type.__call__\\n        return type.__new__(meta, classname, supers, classdict)\\n\\nThis metaclass doesn’t really do anything (we might as well let the default type class\\ncreate the class), but it demonstrates the way a metaclass taps into the metaclass hook\\nto customize—because the metaclass is called at the end of a  class statement, and\\nbecause the type object’s __call__ dispatches to the __new__ and __init__ methods, \\ncode we provide in these methods can manage all the classes created from the metaclass.\\nHere’s our example in action again, with prints added to the metaclass and the file at\\nlarge to trace (again, some filenames are implied by later command-lines in this chap-\\nter):\\n\\nclass MetaOne(type):\\n    def __new__(meta, classname, supers, classdict):\\n        print(\\'In MetaOne.new:\\', meta, classname, supers, classdict, sep=\\'\\\\n...\\')\\n        return type.__new__(meta, classname, supers, classdict)\\n\\nclass Eggs:\\n    pass\\n\\nprint(\\'making class\\')\\nclass Spam(Eggs, metaclass=MetaOne):      # Inherits from Eggs, instance of MetaOne\\n    data = 1                              # Class data attribute\\n    def meth(self, arg):                  # Class method attribute\\n        return self.data + arg\\n\\nprint(\\'making instance\\')\\nX = Spam()\\nprint(\\'data:\\', X.data, X.meth(2))\\n\\nHere, Spam inherits from Eggs and is an instance of MetaOne, but X is an instance of and\\ninherits from Spam. When this code is run with Python 3.X, notice how the metaclass\\nis invoked at the end of the class statement, before we ever make an instance—meta-\\nclasses are for processing classes, and classes are for processing normal instances:\\n\\nc:\\\\code> py −3 metaclass1.py\\nmaking class\\nIn MetaOne.new:\\n\\nCoding Metaclasses\\n\\n| 1371\\n\\n\\x0c...<class \\'__main__.MetaOne\\'>\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x02A191E0>, \\'__module__\\': \\'__main__\\'}\\nmaking instance\\ndata: 1 3\\n\\nPresentation  note:  I’m  truncating  addresses  and  omitting  some  irrelevant  built-in\\n__X__ names in namespace dictionaries in this chapter for brevity, and as noted earlier\\nam forgoing 2.X portability due to differing declaration syntax. To run in 2.X, use the\\nclass attribute form, and change print operations as desired. This example works in 2.X\\nwith the following modifications, in the file metaclass1-2x.py; notice that either Eggs\\nor Spam must be derived from object explicitly, or else 2.X issues a warning because\\nnew-style class can’t have only classic bases here—when in doubt, use object in 2.X\\nmetaclasses clients:\\n\\nfrom __future__ import print_function              # To run the same in 2.X (only)\\nclass Eggs(object):                                # One of the \"object\" optional\\nclass Spam(Eggs, object):\\n    __metaclass__ = MetaOne\\n\\nCustomizing Construction and Initialization\\nMetaclasses  can  also  tap  into  the  __init__  protocol  invoked  by  the  type  object’s\\n__call__. In general, __new__ creates and returns the class object, and __init__ initial-\\nizes the already created class passed in as an argument. Metaclasses can use either or\\nboth hooks to manage the class at creation time:\\n\\nclass MetaTwo(type):\\n    def __new__(meta, classname, supers, classdict):\\n        print(\\'In MetaTwo.new: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        return type.__new__(meta, classname, supers, classdict)\\n\\n    def __init__(Class, classname, supers, classdict):\\n        print(\\'In MetaTwo.init:\\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        print(\\'...init class object:\\', list(Class.__dict__.keys()))\\n\\nclass Eggs:\\n    pass\\n\\nprint(\\'making class\\')\\nclass Spam(Eggs, metaclass=MetaTwo):      # Inherits from Eggs, instance of MetaTwo\\n    data = 1                              # Class data attribute\\n    def meth(self, arg):                  # Class method attribute\\n       return self.data + arg\\n\\nprint(\\'making instance\\')\\nX = Spam()\\nprint(\\'data:\\', X.data, X.meth(2))\\n\\nIn this case, the class initialization method is run after the class construction method,\\nbut both run at the end of the class statement before any instances are made. Con-\\n\\n1372 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cversely, an __init__ in Spam would run at instance creation time, and is not affected or\\nrun by the metaclass’s __init__:\\nc:\\\\code> py −3 metaclass2.py\\nmaking class\\nIn MetaTwo.new:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x02967268>, \\'__module__\\': \\'__main__\\'}\\nIn MetaTwo.init:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x02967268>, \\'__module__\\': \\'__main__\\'}\\n...init class object: [\\'__qualname__\\', \\'data\\', \\'__module__\\', \\'meth\\', \\'__doc__\\']\\nmaking instance\\ndata: 1 3\\n\\nOther Metaclass Coding Techniques\\nAlthough redefining the type superclass’s __new__ and __init__ methods is the most\\ncommon way to insert logic into the class object creation process with the metaclass\\nhook, other schemes are possible.\\n\\nUsing simple factory functions\\nFor example, metaclasses need not really be classes at all. As we’ve learned, the class\\nstatement issues a simple call to create a class at the conclusion of its processing. Be-\\ncause of this, any callable object can in principle be used as a metaclass, provided it\\naccepts the arguments passed and returns an object compatible with the intended class.\\nIn fact, a simple object factory function may serve just as well as a type subclass:\\n\\n# A simple function can serve as a metaclass too\\n\\ndef MetaFunc(classname, supers, classdict):\\n    print(\\'In MetaFunc: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n    return type(classname, supers, classdict)\\n\\nclass Eggs:\\n    pass\\n\\nprint(\\'making class\\')\\nclass Spam(Eggs, metaclass=MetaFunc):            # Run simple function at end\\n    data = 1                                     # Function returns class\\n    def meth(self, arg):\\n        return self.data + arg\\n\\nprint(\\'making instance\\')\\nX = Spam()\\nprint(\\'data:\\', X.data, X.meth(2))\\n\\nCoding Metaclasses\\n\\n| 1373\\n\\n\\x0cWhen run, the function is called at the end of the declaring class statement, and it\\nreturns the expected new class object. The function is simply catching the call that the\\ntype object’s __call__ normally intercepts by default:\\n\\nc:\\\\code> py −3 metaclass3.py\\nmaking class\\nIn MetaFunc:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x029471E0>, \\'__module__\\': \\'__main__\\'}\\nmaking instance\\ndata: 1 3\\n\\nOverloading class creation calls with normal classes\\nBecause normal class instances can respond to call operations with operator overload-\\ning, they can serve in some metaclass roles too, much like the preceding function. The\\noutput of the following is similar to the prior class-based versions, but it’s based on a\\nsimple class—one that doesn’t inherit from type at all, and provides a __call__ for its\\ninstances that catches the metaclass call using normal operator overloading. Note that\\n__new__ and __init__ must have different names here, or else they will run when the\\nMeta instance is created, not when it is later called in the role of metaclass:\\n\\n# A normal class instance can serve as a metaclass too\\n\\nclass MetaObj:\\n    def __call__(self, classname, supers, classdict):\\n        print(\\'In MetaObj.call: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        Class = self.__New__(classname, supers, classdict)\\n        self.__Init__(Class, classname, supers, classdict)\\n        return Class\\n\\n    def __New__(self, classname, supers, classdict):\\n        print(\\'In MetaObj.new: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        return type(classname, supers, classdict)\\n\\n    def __Init__(self, Class, classname, supers, classdict):\\n        print(\\'In MetaObj.init:\\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        print(\\'...init class object:\\', list(Class.__dict__.keys()))\\n\\nclass Eggs:\\n    pass\\n\\nprint(\\'making class\\')\\nclass Spam(Eggs, metaclass=MetaObj()):          # MetaObj is normal class instance\\n    data = 1                                    # Called at end of statement\\n    def meth(self, arg):\\n        return self.data + arg\\n\\nprint(\\'making instance\\')\\nX = Spam()\\nprint(\\'data:\\', X.data, X.meth(2))\\n\\n1374 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cWhen run, the three methods are dispatched via the normal instance’s __call__ inher-\\nited from its normal class, but without any dependence on type dispatch mechanics or\\nsemantics:\\n\\nc:\\\\code> py −3 metaclass4.py\\nmaking class\\nIn MetaObj.call:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x029492F0>, \\'__module__\\': \\'__main__\\'}\\nIn MetaObj.new:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x029492F0>, \\'__module__\\': \\'__main__\\'}\\nIn MetaObj.init:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x029492F0>, \\'__module__\\': \\'__main__\\'}\\n...init class object: [\\'__module__\\', \\'__doc__\\', \\'data\\', \\'__qualname__\\', \\'meth\\']\\nmaking instance\\ndata: 1 3\\n\\nIn fact, we can use normal superclass inheritance to acquire the call interceptor in this\\ncoding model—the superclass here is serving essentially the same role as type, at least\\nin terms of metaclass dispatch:\\n\\n# Instances inherit from classes and their supers normally\\n\\nclass SuperMetaObj:\\n    def __call__(self, classname, supers, classdict):\\n        print(\\'In SuperMetaObj.call: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        Class = self.__New__(classname, supers, classdict)\\n        self.__Init__(Class, classname, supers, classdict)\\n        return Class\\n\\nclass SubMetaObj(SuperMetaObj):\\n    def __New__(self, classname, supers, classdict):\\n        print(\\'In SubMetaObj.new: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        return type(classname, supers, classdict)\\n\\n    def __Init__(self, Class, classname, supers, classdict):\\n        print(\\'In SubMetaObj.init:\\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        print(\\'...init class object:\\', list(Class.__dict__.keys()))\\n\\nclass Spam(Eggs, metaclass=SubMetaObj()):   # Invoke Sub instance via Super.__call__\\n   ...rest of file unchanged...\\n\\nc:\\\\code> py −3 metaclass4-super.py\\nmaking class\\nIn SuperMetaObj.call:\\n...as before...\\nIn SubMetaObj.new:\\n...as before...\\nIn SubMetaObj.init:\\n...as before...\\n\\nCoding Metaclasses\\n\\n| 1375\\n\\n\\x0cmaking instance\\ndata: 1 3\\n\\nAlthough such alternative forms work, most metaclasses get their work done by rede-\\nfining the type superclass’s __new__ and __init__; in practice, this is usually as much\\ncontrol as is required, and it’s often simpler than other schemes. Moreover, metaclasses\\nhave access to additional tools, such as class methods we’ll explore ahead, which can\\ninfluence class behavior more directly than some other schemes.\\nStill, we’ll see later that a simple callable-based metaclass can often work much like a\\nclass decorator, which allows the metaclasses to manage instances as well as classes.\\nFirst, though, the next section presents an example drawn from the Python “Twilight\\nZone” to introduce metaclass name resolution concepts.\\n\\nOverloading class creation calls with metaclasses\\nSince they participate in normal OOP mechanics, it’s also possible for metaclasses to\\ncatch the creation call at the end of a class statement directly, by redefining the type\\nobject’s __call__. The redefinitions of both __new__ and __call__ must be careful to\\ncall  back  to  their  defaults  in  type  if  they  mean  to  make  a  class  in  the  end,  and\\n__call__ must invoke type to kick off the other two here:\\n# Classes can catch calls too (but built-ins look in metas, not supers!)\\n\\nclass SuperMeta(type):\\n    def __call__(meta, classname, supers, classdict):\\n        print(\\'In SuperMeta.call: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        return type.__call__(meta, classname, supers, classdict)\\n\\n    def __init__(Class, classname, supers, classdict):\\n        print(\\'In SuperMeta init:\\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        print(\\'...init class object:\\', list(Class.__dict__.keys()))\\n\\nprint(\\'making metaclass\\')\\nclass SubMeta(type, metaclass=SuperMeta):\\n    def __new__(meta, classname, supers, classdict):\\n        print(\\'In SubMeta.new: \\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        return type.__new__(meta, classname, supers, classdict)\\n\\n    def __init__(Class, classname, supers, classdict):\\n        print(\\'In SubMeta init:\\', classname, supers, classdict, sep=\\'\\\\n...\\')\\n        print(\\'...init class object:\\', list(Class.__dict__.keys()))\\n\\nclass Eggs:\\n    pass\\n\\nprint(\\'making class\\')\\nclass Spam(Eggs, metaclass=SubMeta):        # Invoke SubMeta, via SuperMeta.__call__\\n    data = 1\\n    def meth(self, arg):\\n        return self.data + arg\\n\\nprint(\\'making instance\\')\\n\\n1376 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cX = Spam()\\nprint(\\'data:\\', X.data, X.meth(2))\\n\\nThis code has some oddities I’ll explain in a moment. When run, though, all three\\nredefined methods run in turn for Spam as in the prior section. This is again essentially\\nwhat the type object does by default, but there’s an additional metaclass call for the\\nmetaclass subclass (metasubclass?):\\n\\nc:\\\\code> py −3 metaclass5.py\\nmaking metaclass\\nIn SuperMeta init:\\n...SubMeta\\n...(<class \\'type\\'>,)\\n...{\\'__init__\\': <function SubMeta.__init__ at 0x028F92F0>, ...}\\n...init class object: [\\'__doc__\\', \\'__module__\\', \\'__new__\\', \\'__init__, ...]\\nmaking class\\nIn SuperMeta.call:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x028F9378>, \\'__module__\\': \\'__main__\\'}\\nIn SubMeta.new:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x028F9378>, \\'__module__\\': \\'__main__\\'}\\nIn SubMeta init:\\n...Spam\\n...(<class \\'__main__.Eggs\\'>,)\\n...{\\'data\\': 1, \\'meth\\': <function Spam.meth at 0x028F9378>, \\'__module__\\': \\'__main__\\'}\\n...init class object: [\\'__qualname__\\', \\'__module__\\', \\'__doc__\\', \\'data\\', \\'meth\\']\\nmaking instance\\ndata: 1 3\\n\\nThis example is complicated by the fact that it overrides a method invoked by a built-\\nin operation—in this case, the call run automatically to create a class. Metaclasses are\\nused to create class objects, but only generate instances of themselves when called in a\\nmetaclass role. Because of this, name lookup with metaclasses may be somewhat dif-\\nferent than what we are accustomed to. The __call__ method, for example, is looked\\nup by built-ins in the class (a.k.a. type) of an object; for metaclasses, this means the\\nmetaclass of a metaclass!\\nAs we’ll see ahead, metaclasses also inherit names from other metaclasses normally,\\nbut as for normal classes, this seems to apply to explicit name fetches only, not to the\\nimplicit lookup of names for built-in operations such as calls. The latter appears to look\\nin  the  metaclass’s  class,  available  in  its  __class__  link—which  is  either  the  default\\ntype or a metaclass. This is the same built-ins routing issue we’ve seen so often in this\\nbook for normal class instances. The metaclass in SubMeta is required to set this link,\\nthough this also kicks off a metaclass construction step for the metaclass itself.\\nTrace the invocations in the output. SuperMeta’s __call__ method is not run for the call\\nto SuperMeta when making SubMeta (this goes to type instead), but is run for the Sub\\nMeta call when making Spam. Inheriting normally from SuperMeta does not suffice to\\n\\nCoding Metaclasses\\n\\n| 1377\\n\\n\\x0ccatch SubMeta calls, and for reasons we’ll see later is actually the wrong thing to do for\\noperator overloading methods: SuperMeta’s __call__ is then acquired by Spam, causing\\nSpam instance creation calls to fail before any instance is ever created. Subtle but true!\\nHere’s an illustration of the issue in simpler terms—a normal superclass is skipped for\\nbuilt-ins, but not for explicit fetches and calls, the latter relying on normal attribute\\nname inheritance:\\n\\nclass SuperMeta(type):\\n    def __call__(meta, classname, supers, classdict):      # By name, not built-in\\n        print(\\'In SuperMeta.call:\\', classname)\\n        return type.__call__(meta, classname, supers, classdict)\\n\\nclass SubMeta(SuperMeta):                                  # Created by type default\\n    def __init__(Class, classname, supers, classdict):     # Overrides type.__init__\\n        print(\\'In SubMeta init:\\', classname)\\n\\nprint(SubMeta.__class__)\\nprint([n.__name__ for n in SubMeta.__mro__])\\nprint()\\nprint(SubMeta.__call__)                   # Not a data descriptor if found by name\\nprint()\\nSubMeta.__call__(SubMeta, \\'xxx\\', (), {})  # Explicit calls work: class inheritance\\nprint()\\nSubMeta(\\'yyy\\', (), {})                    # But implicit built-in calls do not: type\\n\\nc:\\\\code> py −3 metaclass5b.py\\n<class \\'type\\'>\\n[\\'SubMeta\\', \\'SuperMeta\\', \\'type\\', \\'object\\']\\n\\n<function SuperMeta.__call__ at 0x029B9158>\\n\\nIn SuperMeta.call: xxx\\nIn SubMeta init: xxx\\n\\nIn SubMeta init: yyy\\n\\nOf course, this specific example is a special case: catching a built-in run on a metaclass,\\na likely rare usage related to __call__ here. But it underscores a core asymmetry and\\napparent inconsistency: normal attribute inheritance is not fully used for built-in dispatch\\n—for both instances and classes.\\nTo truly understand this example’s subtleties, though, we need to get more formal\\nabout what metaclasses mean for Python name resolution in general.\\n\\nInheritance and Instance\\nBecause metaclasses are specified in similar ways to inheritance superclasses, they can\\nbe a bit confusing at first glance. A few key points should help summarize and clarify\\nthe model:\\n\\n1378 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cMetaclasses inherit from the type class (usually)\\n\\nAlthough they have a special role, metaclasses are coded with class statements and\\nfollow the usual OOP model in Python. For example, as subclasses of type, they\\ncan  redefine  the  type  object’s  methods,  overriding  and  customizing  them  as\\nneeded.  Metaclasses  typically  redefine  the  type  class’s  __new__  and  __init__  to\\ncustomize class creation and initialization. Although it’s less common, they can\\nalso redefine __call__ if they wish to catch the end-of-class creation call directly\\n(albeit with the complexities we saw in the prior section), and can even be simple\\nfunctions or other callables that return arbitrary objects, instead of type subclasses.\\n\\nMetaclass declarations are inherited by subclasses\\n\\nThe metaclass=M declaration in a user-defined class is inherited by the class’s normal\\nsubclasses, too, so the metaclass will run for the construction of each class that\\ninherits this specification in a superclass inheritance chain.\\n\\nMetaclass attributes are not inherited by class instances\\n\\nMetaclass declarations specify an instance relationship, which is not the same as\\nwhat we’ve called inheritance thus far. Because classes are instances of metaclasses,\\nthe behavior defined in a metaclass applies to the class, but not the class’s later\\ninstances. Instances obtain behavior from their classes and superclasses, but not\\nfrom any metaclasses. Technically, attribute inheritance for normal instances usu-\\nally searches only the __dict__ dictionaries of the instance, its class, and all its\\nsuperclasses; metaclasses are not included in inheritance lookup for normal in-\\nstances.\\n\\nMetaclass attributes are acquired by classes\\n\\nBy contrast, classes do acquire methods of their metaclasses by virtue of the in-\\nstance relationship. This is a source of class behavior that processes classes them-\\nselves.  Technically,  classes  acquire  metaclass  attributes  through  the  class’s\\n__class__ link just as normal instances acquire names from their class, but inher-\\nitance via __dict__ search is attempted first: when the same name is available to a\\nclass in both a metaclass and a superclass, the superclass (inheritance) version is\\nused instead of that on a metaclass (instance). The class’s __class__, however, is\\nnot followed for its own instances: metaclass attributes are made available to their\\ninstance classes, but not to instances of those instance classes (and see the earlier\\nreference to Dr. Seuss...).\\n\\nThis may be easier to understand in code than in prose. To illustrate all these points,\\nconsider the following example:\\n\\n# File metainstance.py\\n\\nclass MetaOne(type):\\n    def __new__(meta, classname, supers, classdict):        # Redefine type method\\n        print(\\'In MetaOne.new:\\', classname)\\n        return type.__new__(meta, classname, supers, classdict)\\n    def toast(self):\\n       return \\'toast\\'\\n\\nInheritance and Instance | 1379\\n\\n\\x0cclass Super(metaclass=MetaOne):        # Metaclass inherited by subs too\\n    def spam(self):                    # MetaOne run twice for two classes\\n        return \\'spam\\'\\n\\nclass Sub(Super):                      # Superclass: inheritance versus instance\\n    def eggs(self):                    # Classes inherit from superclasses\\n        return \\'eggs\\'                  # But not from metaclasses\\n\\nWhen this code is run (as a script or module), the metaclass handles construction of\\nboth client classes, and instances inherit class attributes but not metaclass attributes:\\n\\n>>> from metainstance import *         # Runs class statements: metaclass run twice\\nIn MetaOne.new: Super\\nIn MetaOne.new: Sub\\n\\n>>> X = Sub()             # Normal instance of user-defined class\\n>>> X.eggs()              # Inherited from Sub\\n\\'eggs\\'\\n>>> X.spam()              # Inherited from Super\\n\\'spam\\'\\n>>> X.toast()             # Not inherited from metaclass\\nAttributeError: \\'Sub\\' object has no attribute \\'toast\\'\\n\\nBy contrast, classes both inherit names from their superclasses, and acquire names from\\ntheir metaclass (which in this example is itself inherited from a superclass):\\n\\n>>> Sub.eggs(X)           # Own method\\n\\'eggs\\'\\n>>> Sub.spam(X)           # Inherited from Super\\n\\'spam\\'\\n>>> Sub.toast()           # Acquired from metaclass\\n\\'toast\\'\\n>>> Sub.toast(X)          # Not a normal class method\\nTypeError: toast() takes 1 positional argument but 2 were given\\n\\nNotice how the last of the preceding calls fails when we pass in an instance, because\\nthe name resolves to a metaclass method, not a normal class method. In fact, both the\\nobject you fetch a name from and its source become crucial here. Methods acquired\\nfrom metaclasses are bound to the subject class, while methods from normal classes\\nare unbound if fetched through the class but bound when fetched through the instance:\\n\\n>>> Sub.toast\\n<bound method MetaOne.toast of <class \\'metainstance.Sub\\'>>\\n>>> Sub.spam\\n<function Super.spam at 0x0298A2F0>\\n>>> X.spam\\n<bound method Sub.spam of <metainstance.Sub object at 0x02987438>>\\n\\nWe’ve studied the last two of these rules before in Chapter 31’s bound method cover-\\nage; the first is new, but reminiscent of class methods. To understand why this works\\nthe way it does, we need to explore the metaclass instance relationship further.\\n\\n1380 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cMetaclass Versus Superclass\\nIn even simpler terms, watch what happens in the following: as an instance of the A\\nmetaclass type, class B acquires A’s attribute, but this attribute is not made available for\\ninheritance by B’s own instances—the acquisition of names by metaclass instances is\\ndistinct from the normal inheritance used for class instances:\\n\\n>>> class A(type): attr = 1\\n>>> class B(metaclass=A): pass          # B is meta instance and acquires meta attr\\n>>> I = B()                             # I inherits from class but not meta!\\n>>> B.attr\\n1\\n>>> I.attr\\nAttributeError: \\'B\\' object has no attribute \\'attr\\'\\n>>> \\'attr\\' in B.__dict__, \\'attr\\' in A.__dict__\\n(False, True)\\n\\nBy contrast, if A morphs from metaclass to superclass, then names inherited from an A\\nsuperclass become available to later instances of B, and are located by searching name-\\nspace dictionaries in classes in the tree—that is, by checking the __dict__ of objects in\\nthe method resolution order (MRO), much like the mapattrs example we coded back\\nin Chapter 32:\\n\\n>>> class A: attr = 1\\n>>> class B(A): pass                    # I inherits from class and supers\\n>>> I = B()\\n>>> B.attr\\n1\\n>>> I.attr\\n1\\n>>> \\'attr\\' in B.__dict__, \\'attr\\' in A.__dict__\\n(False, True)\\n\\nThis is why metaclasses often do their work by manipulating a new class’s namespace\\ndictionary, if they wish to influence the behavior of later instance objects—instances\\nwill see names in a class, but not its metaclass. Watch what happens, though, if the\\nsame name is available in both attribute sources—the inheritance name is used instead\\nof instance acquisition:\\n\\n>>> class M(type): attr = 1\\n>>> class A: attr = 2\\n>>> class B(A, metaclass=M): pass       # Supers have precedence over metas\\n>>> I = B()\\n>>> B.attr, I.attr\\n(2, 2)\\n>>> \\'attr\\' in B.__dict__, \\'attr\\' in A.__dict__, \\'attr\\' in M.__dict__\\n(False, True, True)\\n\\nThis is true regardless of the relative height of the inheritance and instance sources—\\nPython checks the __dict__ of each class on the MRO (inheritance), before falling back\\non metaclass acquisition (instance):\\n\\n>>> class M(type): attr = 1\\n>>> class A: attr = 2\\n\\nInheritance and Instance | 1381\\n\\n\\x0c>>> class B(A): pass\\n>>> class C(B, metaclass=M): pass       # Super two levels above meta: still wins\\n>>> I = C()\\n>>> I.attr, C.attr\\n(2, 2)\\n>>> [x.__name__ for x in C.__mro__]     # See Chapter 32 for all things MRO\\n[\\'C\\', \\'B\\', \\'A\\', \\'object\\']\\n\\nIn fact, classes acquire metaclass attributes through their __class__ link, in the same\\nway that normal instances inherit from classes through their __class__, which makes\\nsense, given that classes are also instances of metaclasses. The chief distinction is that\\ninstance inheritance does not follow a class’s __class__, but instead restricts its scope\\nto the __dict__ of each class in a tree per the MRO—following __bases__ at each class\\nonly, and using only the instance’s __class__ link once:\\n\\n>>> I.__class__              # Followed by inheritance: instance\\'s class\\n<class \\'__main__.C\\'>\\n>>> C.__bases__              # Followed by inheritance: class\\'s supers\\n(<class \\'__main__.B\\'>,)\\n>>> C.__class__              # Followed by instance acquisition: metaclass\\n<class \\'__main__.M\\'>\\n>>> C.__class__.attr         # Another way to get to metaclass attributes\\n1\\n\\nIf you study this, you’ll probably notice a nearly glaring symmetry here, which leads us\\nto the next section.\\n\\nInheritance: The Full Story\\nAs it turns out, instance inheritance works in similar ways, whether the “instance” is\\ncreated from a normal class, or is a class created from a metaclass subclass of type—a\\nsingle attribute search rule, which fosters the grander and parallel notion of metaclass\\ninheritance hierarchies. To illustrate the basics of this conceptual merger, in the fol-\\nlowing, the instance inherits from all its classes; the class inherits from both classes and\\nmetaclasses; and metaclasses inherit from higher metaclasses (supermetaclasses?):\\n\\n>>> class M1(type): attr1 = 1                 # Metaclass inheritance tree\\n>>> class M2(M1):   attr2 = 2                 # Gets __bases__, __class__, __mro__\\n\\n>>> class C1: attr3 = 3                       # Superclass inheritance tree\\n>>> class C2(C1,metaclass=M2): attr4 = 4      # Gets __bases__, __class__, __mro__\\n\\n>>> I = C2()                                  # I gets __class__ but not others\\n>>> I.attr3, I.attr4                          # Instance inherits from super tree\\n(3, 4)\\n>>> C2.attr1, C2.attr2, C2.attr3, C2.attr4    # Class gets names from both trees!\\n(1, 2, 3, 4)\\n>>> M2.attr1, M2.attr2                        # Metaclass inherits names too!\\n(1, 2)\\n\\n1382 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cBoth inheritance paths—class and metaclass—employ the same links, though not re-\\ncursively: instances do not inherit their class’s metaclass names, but may request them\\nexplicitly:\\n\\n>>> I.__class__                # Links followed at instance with no __bases__\\n<class \\'__main__.C2\\'>\\n>>> C2.__bases__\\n(<class \\'__main__.C1\\'>,)\\n\\n>>> C2.__class__               # Links followed at class after __bases__\\n<class \\'__main__.M2\\'>\\n>>> M2.__bases__\\n(<class \\'__main__.M1\\'>,)\\n\\n>>> I.__class__.attr1          # Route inheritance to the class\\'s meta tree\\n1\\n>>> I.attr1                    # Though class\\'s __class__ not followed normally\\nAttributeError: \\'C2\\' object has no attribute \\'attr1\\'\\n\\n>>> M2.__class__                        # Both trees have MROs and instance links\\n<class \\'type\\'>\\n>>> [x.__name__ for x in C2.__mro__]    # __bases__ tree from I.__class__\\n[\\'C2\\', \\'C1\\', \\'object\\']\\n>>> [x.__name__ for x in M2.__mro__]    # __bases__ tree from C2.__class__\\n[\\'M2\\', \\'M1\\', \\'type\\', \\'object\\']\\n\\nIf you care about metaclasses, or must use code that does, study these examples, and\\nthen study them again. In effect, inheritance follows __bases__ before following a single\\n__class__; normal instances have no __bases__; and classes have both—whether nor-\\nmal or metaclass. In fact, understanding this example is important to Python name\\nresolution in general, as the next section explains.\\n\\nPython’s inheritance algorithm: The simple version\\nNow that we know about metaclass acquisition, we’re finally able to formalize the\\ninheritance rules that they augment. Technically, inheritance deploys two distinct but\\nsimilar lookup routines, and is based on MROs. Because __bases__ are used to con-\\nstruct the __mro__ ordering at class creation time, and because a class’s __mro__ includes \\nitself, the prior section’s generalization is the same as the following—a first-cut defi-\\nnition of Python’s new-style inheritance algorithm:\\nTo look up an explicit attribute name:\\n\\n1. From an instance I, search the instance, then its class, and then all its superclasses,\\n\\nusing:\\n\\na. The __dict__ of the instance I\\nb. The __dict__ of all classes on the __mro__ found at I’s __class__, from left to\\n\\nright\\n\\n2. From a class C, search the class, then all its superclasses, and then its metaclasses\\n\\ntree, using:\\n\\nInheritance and Instance | 1383\\n\\n\\x0ca. The __dict__ of all classes on the __mro__ found at C itself, from left to right\\nb. The __dict__ of all metaclasses on the __mro__ found at C’s __class__, from\\n\\nleft to right\\n\\n3. In both rule 1 and 2, give precedence to data descriptors located in step b sources\\n\\n(see ahead).\\n\\n4. In both rule 1 and 2, skip step a and begin the search at step b for built-in operations\\n\\n(see ahead).\\n\\nThe first two steps are followed for normal, explicit attribute fetch only. There are\\nexceptions for both built-ins and descriptors, both of which we’ll clarify in a moment.\\nIn addition, a  __getattr__ or  __getattribute__ may also be used for missing or all\\nnames, respectively, per Chapter 38.\\nMost programmers need only be aware of the first of these rules, and perhaps the first\\nstep of the second—which taken together correspond to 2.X classic class inheritance.\\nThere’s an extra acquisition step added for metaclasses (2b), but it’s essentially the\\nsame as others—a fairly subtle equivalence to be sure, but metaclass acquisition is not\\nas novel as it may seem. In fact, it’s just one component of the larger model.\\n\\nThe descriptors special case\\nAt least that’s the normal—and simplistic—case. I listed step 3 in the prior section\\nspecially, because it doesn’t apply to most code, and complicates the algorithm sub-\\nstantially. It turns out, though, that inheritance also has a special case interaction with\\nChapter 38’s attribute descriptors. In short, some descriptors known as data descriptors\\n—those that define __set__ methods to intercept assignments—are given precedence,\\nsuch that their names override other inheritance sources.\\nThis exception serves some practical roles. For example, it is used to ensure that the\\nspecial __class__ and __dict__ attributes cannot be redefined by the same names in an\\ninstance’s own __dict__:\\n\\n>>> class C: pass                          # Inheritance special case #1...\\n>>> I = C()                                # Class data descriptors have precedence\\n>>> I.__class__, I.__dict__\\n(<class \\'__main__.C\\'>, {})\\n\\n>>> I.__dict__[\\'name\\'] = \\'bob\\'             # Dynamic data in the instance\\n>>> I.__dict__[\\'__class__\\'] = \\'spam\\'       # Assign keys, not attributes\\n>>> I.__dict__[\\'__dict__\\']  = {}\\n\\n>>> I.name                                 # I.name comes from I.__dict__ as usual\\n\\'bob\\'                                      # But I.__class__ and I.__dict__ do not!\\n>>> I.__class__, I.__dict__\\n(<class \\'__main__.C\\'>, {\\'__class__\\': \\'spam\\', \\'__dict__\\': {}, \\'name\\': \\'bob\\'})\\n\\nThis data descriptor exception is tested before the preceding two inheritance rules as\\na preliminary step, may be more important to Python implementers than Python pro-\\ngrammers, and can be reasonably ignored by most application code in any event—that\\n\\n1384 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cis, unless you code data descriptors of your own, which follow the same inheritance\\nspecial case precedence rule:\\n\\n>>> class D:\\n        def __get__(self, instance, owner): print(\\'__get__\\')\\n        def __set__(self, instance, value): print(\\'__set__\\')\\n\\n>>> class C: d = D()            # Data descriptor attribute\\n>>> I = C()\\n>>> I.d                         # Inherited data descriptor access\\n__get__\\n>>> I.d = 1\\n__set__\\n>>> I.__dict__[\\'d\\'] = \\'spam\\'    # Define same name in instance namespace dict\\n>>> I.d                         # But doesn\\'t hide data descriptor in class!\\n__get__\\n\\nConversely, if this descriptor did not define a __set__, the name in the instance’s dic-\\ntionary would hide the name in its class instead, per normal inheritance:\\n\\n>>> class D:\\n        def __get__(self, instance, owner): print(\\'__get__\\')\\n\\n>>> class C: d = D()\\n>>> I = C()\\n>>> I.d                         # Inherited nondata descriptor access\\n__get__\\n>>> I.__dict__[\\'d\\'] = \\'spam\\'    # Hides class names per normal inheritance rules\\n>>> I.d\\n\\'spam\\'\\n\\nIn both cases, Python automatically runs the descriptor’s __get__ when it’s found by\\ninheritance,  rather  than  returning  the  descriptor  object  itself—part  of  the  attribute\\nmagic we met earlier in the book. The special status afforded to data descriptors, how-\\never, also modifies the meaning of attribute inheritance, and thus the meaning of names\\nin your code.\\n\\nPython’s inheritance algorithm: The somewhat-more-complete version\\nWith both the data descriptor special case and general descriptor invocation factored\\nin with class and metaclass trees, Python’s full new-style inheritance algorithm can be\\nstated as follows—a complex procedure, which assumes knowledge of descriptors,\\nmetaclasses, and MROs, but is the final arbiter of attribute names nonetheless (in the\\nfollowing, items are attempted in sequence either as numbered, or per their left-to-right\\norder in “or” conjunctions):\\nTo look up an explicit attribute name:\\n\\n1. From an instance I, search the instance, its class, and its superclasses, as follows:\\n\\na. Search the __dict__ of all classes on the __mro__ found at I’s __class__\\nb. If a data descriptor was found in step a, call it and exit\\n\\nInheritance and Instance | 1385\\n\\n\\x0cc. Else, return a value in the __dict__ of the instance I\\nd. Else, call a nondata descriptor or return a value found in step a\\n\\n2. From a class C, search the class, its superclasses, and its metaclasses tree, as follows:\\na. Search the __dict__ of all metaclasses on the __mro__ found at C’s __class__\\nb. If a data descriptor was found in step a, call it and exit\\nc. Else, call a descriptor or return a value in the __dict__ of a class on C’s own\\n\\n__mro__\\n\\nd. Else, call a nondata descriptor or return a value found in step a\\n\\n3. In both rule 1 and 2, built-in operations essentially use just step a sources (see\\n\\nahead)\\n\\nNote here again that this applies to normal, explicit attribute fetch only. The implicit\\nlookup of method names for built-ins doesn’t follow these rules, and essentially uses\\njust step a sources in both cases, as the next section will demonstrate.\\nOn top of all this, method __getattr__ may be run if defined when an attribute is not\\nfound, and method __getattribute__ may be run for every attribute fetch, though they\\nare special-case extensions to the name lookup model. See Chapter 38 for more on\\nthese tools and descriptors.\\n\\nAssignment inheritance\\nAlso  note  that  the  prior  section  defines  inheritance  in  terms  of  attribute  reference\\n(lookup), but parts of it apply to attribute assignment as well. As we’ve learned, as-\\nsignment normally changes attributes in the subject object itself, but inheritance is also\\ninvoked on assignment to test first for some of Chapter 38’s attribute management\\ntools,  including  descriptors  and  properties.  When  present,  such  tools  intercept  at-\\ntribute assignment, and may route it arbitrarily.\\nFor example, when an attribute assignment is run for new-style classes, a data descrip-\\ntor with a __set__ method is acquired from a class by inheritance using the MRO, and\\nhas precedence over the normal storage model. In terms of the prior section’s rules:\\n\\n• When applied to an instance, such assignments essentially follow steps a through\\nc of rule 1, searching the instance’s class tree, though step b calls __set__ instead\\nof __get__, and step c stops and stores in the instance instead of attempting a fetch.\\n• When applied to a class, such assignments run the same procedure on the class’s\\nmetaclass tree: roughly the same as rule 2, but step c stops and stores in the class.\\n\\nBecause descriptors are also the basis for other advanced attribute tools such as prop-\\nerties and slots, this inheritance pre-check on assignment is utilized in multiple con-\\ntexts. The net effect is that descriptors are treated as an inheritance special case in new-\\nstyle classes, for both reference and assignment. \\n\\n1386 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cThe built-ins special case\\nAt least that’s almost the full story. As we’ve seen, built-ins don’t follow these rules.\\nInstances and classes may both be skipped for built-in operations only, as a special case\\nthat differs from normal or explicit name inheritance. Because this is a context-spe-\\ncific divergence, it’s easier to demonstrate in code than to weave into a single algorithm.\\nIn the following, str is the built-in, __str__ is its explicit name equivalent, and the\\ninstance is skipped for the built-in only:\\n\\n>>> class C:                              # Inheritance special case #2...\\n        attr = 1                          # Built-ins skip a step\\n        def __str__(self): return(\\'class\\')\\n\\n>>> I = C()\\n>>> I.__str__(), str(I)                   # Both from class if not in instance\\n(\\'class\\', \\'class\\')\\n\\n>>> I.__str__ = lambda: \\'instance\\'\\n>>> I.__str__(), str(I)                   # Explicit=>instance, built-in=>class!\\n(\\'instance\\', \\'class\\')\\n\\n>>> I.attr                                # Asymmetric with normal or explicit names\\n1\\n>>> I.attr = 2; I.attr\\n2\\n\\nAs we saw in metaclass5.py earlier, the same holds true for classes: explicit names start\\nat the class, but built-ins start at the class’s class, which is its metaclass, and defaults\\nto type:\\n\\n>>> class D(type):\\n        def __str__(self): return(\\'D class\\')\\n\\n>>> class C(D):\\n        pass\\n>>> C.__str__(C), str(C)                  # Explicit=>super, built-in=>metaclass!\\n(\\'D class\\', \"<class \\'__main__.C\\'>\")\\n\\n>>> class C(D):\\n        def __str__(self): return(\\'C class\\')\\n>>> C.__str__(C), str(C)                  # Explicit=>class, built-in=>metaclass!\\n(\\'C class\\', \"<class \\'__main__.C\\'>\")\\n\\n>>> class C(metaclass=D):\\n        def __str__(self): return(\\'C class\\')\\n>>> C.__str__(C), str(C)                  # Built-in=>user-defined metaclass\\n(\\'C class\\', \\'D class\\')\\n\\nIn fact, it can sometimes be nontrivial to know where a name comes from in this model,\\nsince all classes also inherit from object—including the default type metaclass. In the\\nfollowing’s explicit call, C appears to get a default __str__ from object instead of the\\nmetaclass, per the first source of class inheritance (the class’s own MRO); by contrast,\\nthe built-in skips ahead to the metaclass as before:\\n\\nInheritance and Instance | 1387\\n\\n\\x0c>>> class C(metaclass=D):\\n        pass\\n>>> C.__str__(C), str(C)                  # Explicit=>object, built-in=>metaclass\\n(\"<class \\'__main__.C\\'>\", \\'D class\\')\\n\\n>>> C.__str__\\n<slot wrapper \\'__str__\\' of \\'object\\' objects>\\n\\n>>> for k in (C, C.__class__, type): print([x.__name__ for x in k.__mro__])\\n[\\'C\\', \\'object\\']\\n[\\'D\\', \\'type\\', \\'object\\']\\n[\\'type\\', \\'object\\']\\n\\nAll of which leads us to this book’s final import this quote—a tenet that seems to\\nconflict with the status given to descriptors and built-ins in the attribute inheritance\\nmechanism of new-style classes:\\n\\nSpecial cases aren’t special enough to break the rules.\\n\\nSome practical needs warrant exceptions, of course. We’ll forgo rationales here, but\\nyou should carefully consider the implications of an object-oriented language that ap-\\nplies  inheritance—its  foundational  operation—in  such  an  uneven  and  inconsistent\\nfashion. At a minimum, this should underscore the importance of keeping your code\\nsimple, to avoid making it dependent on such convoluted rules. As always, your code’s\\nusers and maintainers will be glad you did.\\nFor more fidelity on this story, see Python’s internal implementation of inheritance—\\na complete saga chronicled today in its object.c and typeobject.c, the former for normal\\ninstances, and the latter for classes. Delving into internals shouldn’t be required to use\\nPython, of course, but it’s the ultimate source of truth in a complex and evolving system,\\nand sometimes the best you’ll find. This is especially true in boundary cases born of\\naccrued exceptions. For our purposes here, let’s move on to the last bit of metaclass\\nmagic.\\n\\nMetaclass Methods\\nJust as important as the inheritance of names, methods in metaclasses process their\\ninstance classes—not the normal instance objects we’ve known as “self,” but classes\\nthemselves. This makes them similar in spirit and form to the class methods we studied\\nin Chapter 32, though they again are available in the metaclasses instance realm only,\\nnot to normal instance inheritance. The failure at the end of the following, for example,\\nstems from the explicit name inheritance rules of the prior section:\\n\\n>>> class A(type):\\n        def x(cls): print(\\'ax\\', cls)            # A metaclass (instances=classes)\\n        def y(cls): print(\\'ay\\', cls)            # y is overridden by instance B\\n\\n>>> class B(metaclass=A):\\n        def y(self): print(\\'by\\', self)          # A normal class (normal instances)\\n        def z(self): print(\\'bz\\', self)          # Namespace dict holds y and z\\n\\n1388 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0c>>> B.x                                         # x acquired from metaclass\\n<bound method A.x of <class \\'__main__.B\\'>>\\n>>> B.y                                         # y and z defined in class itself\\n<function B.y at 0x0295F1E0>\\n>>> B.z\\n<function B.z at 0x0295F378>\\n>>> B.x()                                       # Metaclass method call: gets cls\\nax <class \\'__main__.B\\'>\\n\\n>>> I = B()                                     # Instance method calls: get inst\\n>>> I.y()\\nby <__main__.B object at 0x02963BE0>\\n>>> I.z()\\nbz <__main__.B object at 0x02963BE0>\\n>>> I.x()                                       # Instance doesn\\'t see meta names\\nAttributeError: \\'B\\' object has no attribute \\'x\\'\\n\\nMetaclass Methods Versus Class Methods\\nThough they differ in inheritance visibility, much like class methods, metaclass meth-\\nods are designed to manage class-level data. In fact, their roles can overlap—much as\\nmetaclasses do in general with class decorators—but metaclass methods are not ac-\\ncessible except through the class, and do not require an explicit classmethod class-level\\ndata declaration in order to be bound with the class. In other words, metaclass methods\\ncan be thought of as implicit class methods, with limited visibility:\\n\\n>>> class A(type):\\n        def a(cls):                        # Metaclass method: gets class\\n            cls.x = cls.y + cls.z\\n\\n>>> class B(metaclass=A):\\n         y, z = 11, 22\\n         @classmethod                      # Class method: gets class\\n         def b(cls):\\n             return cls.x\\n\\n>>> B.a()            # Call metaclass method; visible to class only\\n>>> B.x              # Creates class data on B, accessible to normal instances\\n33\\n\\n>>> I = B()\\n>>> I.x, I.y, I.z\\n(33, 11, 22)\\n\\n>>> I.b()            # Class method: sends class, not instance; visible to instance\\n33\\n>>> I.a()            # Metaclass methods: accessible through class only\\nAttributeError: \\'B\\' object has no attribute \\'a\\'\\n\\nMetaclass Methods\\n\\n| 1389\\n\\n\\x0cOperator Overloading in Metaclass Methods\\nJust like normal classes, metaclasses may also employ operator overloading to make\\nbuilt-in  operations  applicable  to  their  instance  classes.  The  __getitem__  indexing\\nmethod in the following metaclass, for example, is a metaclass method designed to\\nprocess classes themselves—the classes that are instances of the metaclass, not those\\nclasses’ own later instances. In fact, per the inheritance algorithms sketched earlier,\\nnormal class instances don’t inherit names acquired via the metaclass instance rela-\\ntionship at all, though they can access names present on their own classes:\\n\\n>>> class A(type):\\n        def __getitem__(cls, i):         # Meta method for processing classes:\\n            return cls.data[i]           #  Built-ins skip class, use meta\\n                                         #  Explicit names search class + meta\\n>>> class B(metaclass=A):                #  Data descriptors in meta used first\\n        data = \\'spam\\'\\n\\n>>> B[0]                  # Metaclass instance names: visible to class only\\n\\'s\\'\\n>>> B.__getitem__\\n<bound method A.__getitem__ of <class \\'__main__.B\\'>>\\n\\n>>> I = B()\\n>>> I.data, B.data        # Normal inheritance names: visible to instance and class\\n(\\'spam\\', \\'spam\\')\\n>>> I[0]\\nTypeError: \\'B\\' object does not support indexing\\n\\nIt’s possible to define a __getattr__ on a metaclass too, but it can be used to process\\nits instance classes only, not their normal instances—as usual, it’s not even acquired\\nby a class’s instances:\\n>>> class A(type):\\n        def __getattr__(cls, name):                # Acquired by class B getitem\\n            return getattr(cls.data, name)         # But not run same by built-ins\\n\\n>>> class B(metaclass=A):\\n        data = \\'spam\\'\\n\\n>>> B.upper()\\n\\'SPAM\\'\\n>>> B.upper\\n<built-in method upper of str object at 0x029E7420>\\n>>> B.__getattr__\\n<bound method A.__getattr__ of <class \\'__main__.B\\'>>\\n\\n>>> I = B()\\n>>> I.upper\\nAttributeError: \\'B\\' object has no attribute \\'upper\\'\\n>>> I.__getattr__\\nAttributeError: \\'B\\' object has no attribute \\'__getattr__\\'\\n\\nMoving the __getattr__ to a metaclass doesn’t help with its built-in interception short-\\ncomings, though. In the following continuation, explicit attributes are routed to the\\n\\n1390 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cmetaclass’s __getattr__, but built-ins are not, despite that fact the indexing is routed\\nto a metaclass’s __getitem__ in the first example of the section—strongly suggesting\\nthat new-style __getattr__ is a special case of a special case, and further recommending\\ncode simplicity that avoids dependence on such boundary cases:\\n\\n>>> B.data = [1, 2, 3]\\n>>> B.append(4)           # Explicit normal names routed to meta\\'s getattr\\n>>> B.data\\n[1, 2, 3, 4]\\n>>> B.__getitem__(0)      # Explicit special names routed to meta\\'s gettarr\\n1\\n>>> B[0]                  # But built-ins skip meta\\'s gettatr too?!\\nTypeError: \\'A\\' object does not support indexing\\n\\nAs you can probably tell, metaclasses are interesting to explore, but it’s easy to lose\\ntrack of their big picture. In the interest of space, we’ll omit additional fine points here.\\nFor the purposes of this chapter, it’s more important to show why you’d care to use\\nsuch a tool in the first place. Let’s move on to some larger examples to sample the roles\\nof metaclasses in action. As we’ll find, like so many tools in Python, metaclasses are\\nfirst and foremost about easing maintenance work by eliminating redundancy.\\n\\nExample: Adding Methods to Classes\\nIn this and the following section, we’re going to study examples of two common use\\ncases for metaclasses: adding methods to a class, and decorating all methods automat-\\nically. These are just two of the many metaclass roles, which unfortunately will consume\\nthe space we have left for this chapter; again, you should consult the Web for more\\nadvanced  applications.  These  examples  are  representative  of  metaclasses  in  action,\\nthough, and they suffice to illustrate their application.\\nMoreover, both give us an opportunity to contrast class decorators and metaclasses—\\nour first example compares metaclass- and decorator-based implementations of class\\naugmentation and instance wrapping, and the second applies a decorator with a met-\\naclass first and then with another decorator. As you’ll see, the two tools are often in-\\nterchangeable, and even complementary.\\n\\nManual Augmentation\\nEarlier in this chapter, we looked at skeleton code that augmented classes by adding\\nmethods to them in various ways. As we saw, simple class-based inheritance suffices if\\nthe extra methods are statically known when the class is coded. Composition via object\\nembedding can often achieve the same effect too. For more dynamic scenarios, though,\\nother techniques are sometimes required—helper functions can usually suffice, but\\nmetaclasses  provide  an  explicit  structure  and  minimize  the  maintenance  costs  of\\nchanges in the future.\\n\\nExample: Adding Methods to Classes\\n\\n| 1391\\n\\n\\x0cLet’s put these ideas in action here with working code. Consider the following example\\nof manual class augmentation—it adds two methods to two classes, after they have\\nbeen created:\\n\\n# Extend manually - adding new methods to classes\\n\\nclass Client1:\\n    def __init__(self, value):\\n        self.value = value\\n    def spam(self):\\n        return self.value * 2\\n\\nclass Client2:\\n    value = \\'ni?\\'\\n\\ndef eggsfunc(obj):\\n    return obj.value * 4\\n\\ndef hamfunc(obj, value):\\n    return value + \\'ham\\'\\n\\nClient1.eggs = eggsfunc\\nClient1.ham  = hamfunc\\n\\nClient2.eggs = eggsfunc\\nClient2.ham  = hamfunc\\n\\nX = Client1(\\'Ni!\\')\\nprint(X.spam())\\nprint(X.eggs())\\nprint(X.ham(\\'bacon\\'))\\n\\nY = Client2()\\nprint(Y.eggs())\\nprint(Y.ham(\\'bacon\\'))\\n\\nThis works because methods can always be assigned to a class after it’s been created,\\nas long as the methods assigned are functions with an extra first argument to receive\\nthe subject self instance—this argument can be used to access state information ac-\\ncessible from the class instance, even though the function is defined independently of\\nthe class.\\nWhen this code runs, we receive the output of a method coded inside the first class, as\\nwell as the two methods added to the classes after the fact:\\n\\nc:\\\\code> py −3 extend-manual.py\\nNi!Ni!\\nNi!Ni!Ni!Ni!\\nbaconham\\nni?ni?ni?ni?\\nbaconham\\n\\nThis scheme works well in isolated cases and can be used to fill out a class arbitrarily\\nat runtime. It suffers from a potentially major downside, though: we have to repeat the\\n\\n1392 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0caugmentation code for every class that needs these methods. In our case, it wasn’t too\\nonerous to add the two methods to both classes, but in more complex scenarios this\\napproach can be time-consuming and error-prone. If we ever forget to do this consis-\\ntently, or we ever need to change the augmentation, we can run into problems.\\n\\nMetaclass-Based Augmentation\\nAlthough manual augmentation works, in larger programs it would be better if we could\\napply such changes to an entire set of classes automatically. That way, we’d avoid the\\nchance of the augmentation being botched for any given class. Moreover, coding the\\naugmentation in a single location better supports future changes—all classes in the set\\nwill pick up changes automatically.\\nOne way to meet this goal is to use metaclasses. If we code the augmentation in a\\nmetaclass, every class that declares that metaclass will be augmented uniformly and\\ncorrectly and will automatically pick up any changes made in the future. The following\\ncode demonstrates:\\n\\n# Extend with a metaclass - supports future changes better\\n\\ndef eggsfunc(obj):\\n    return obj.value * 4\\n\\ndef hamfunc(obj, value):\\n    return value + \\'ham\\'\\n\\nclass Extender(type):\\n    def __new__(meta, classname, supers, classdict):\\n        classdict[\\'eggs\\'] = eggsfunc\\n        classdict[\\'ham\\']  = hamfunc\\n        return type.__new__(meta, classname, supers, classdict)\\n\\nclass Client1(metaclass=Extender):\\n    def __init__(self, value):\\n        self.value = value\\n    def spam(self):\\n        return self.value * 2\\n\\nclass Client2(metaclass=Extender):\\n    value = \\'ni?\\'\\n\\nX = Client1(\\'Ni!\\')\\nprint(X.spam())\\nprint(X.eggs())\\nprint(X.ham(\\'bacon\\'))\\n\\nY = Client2()\\nprint(Y.eggs())\\nprint(Y.ham(\\'bacon\\'))\\n\\nThis time, both of the client classes are extended with the new methods because they\\nare instances of a metaclass that performs the augmentation. When run, this version’s\\n\\nExample: Adding Methods to Classes\\n\\n| 1393\\n\\n\\x0coutput is the same as before—we haven’t changed what the code does, we’ve just re-\\nfactored it to encapsulate the augmentation more cleanly:\\n\\nc:\\\\code> py −3 extend-meta.py\\nNi!Ni!\\nNi!Ni!Ni!Ni!\\nbaconham\\nni?ni?ni?ni?\\nbaconham\\n\\nNotice that the metaclass in this example still performs a fairly static task: adding two\\nknown methods to every class that declares it. In fact, if all we need to do is always add\\nthe same two methods to a set of classes, we might as well code them in a normal\\nsuperclass and inherit in subclasses. In practice, though, the metaclass structure sup-\\nports much more dynamic behavior. For instance, the subject class might also be con-\\nfigured based upon arbitrary logic at runtime:\\n\\n# Can also configure class based on runtime tests\\n\\nclass MetaExtend(type):\\n    def __new__(meta, classname, supers, classdict):\\n        if sometest():\\n            classdict[\\'eggs\\'] = eggsfunc1\\n        else:\\n            classdict[\\'eggs\\'] = eggsfunc2\\n        if someothertest():\\n            classdict[\\'ham\\']  = hamfunc\\n        else:\\n            classdict[\\'ham\\']  = lambda *args: \\'Not supported\\'\\n        return type.__new__(meta, classname, supers, classdict)\\n\\nMetaclasses Versus Class Decorators: Round 2\\nKeep in mind again that the prior chapter’s class decorators often overlap with this\\nchapter’s metaclasses in terms of functionality. This derives from the fact that:\\n\\n• Class  decorators  rebind  class  names  to  the  result  of  a  function  at  the  end  of  a\\n\\nclass statement, after the new class has been created.\\n\\n• Metaclasses work by routing class object creation through an object at the end of\\n\\na class statement, in order to create the new class.\\n\\nAlthough these are slightly different models, in practice they can often achieve the same\\ngoals, albeit in different ways. As you’ve now seen, class decorators correspond directly\\nto metaclass __init__ methods called to initialize newly created classes. Decorators\\nhave no direct analog to the metaclass __new__ (called to make classes in the first place)\\nor to metaclass methods (used to process instance classes), but many or most use cases\\nfor these tools do not require these extra steps.\\nBecause of this, both tools in principle can be used to manage both instances of a class\\nand the class itself. In practice, though, metaclasses incur extra steps to manage in-\\nstances, and decorators incur extra steps to create new classes. Hence, while their roles\\n\\n1394 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0coften overlap, metaclasses are probably best used for class object management. Let’s\\ntranslate these ideas to code.\\n\\nDecorator-based augmentation\\nIn pure augmentation cases, decorators can often stand in for metaclasses. For example,\\nthe prior section’s metaclass example, which adds methods to a class on creation, can\\nalso be coded as a class decorator; in this mode, decorators roughly correspond to the\\n__init__ method of metaclasses, since the class object has already been created by the\\ntime the decorator is invoked. Also as for metaclasses, the original class type is retained,\\nsince  no  wrapper  object  layer  is  inserted.  The  output  of  the  following,  file  extend-\\ndeco.py, is the same as that of the prior metaclass code:\\n\\n# Extend with a decorator: same as providing __init__ in a metaclass\\n\\ndef eggsfunc(obj):\\n    return obj.value * 4\\n\\ndef hamfunc(obj, value):\\n    return value + \\'ham\\'\\n\\ndef Extender(aClass):\\n    aClass.eggs = eggsfunc                   # Manages class, not instance\\n    aClass.ham  = hamfunc                    # Equiv to metaclass __init__\\n    return aClass\\n\\n@Extender\\nclass Client1:                               # Client1 = Extender(Client1)\\n    def __init__(self, value):               # Rebound at end of class stmt\\n        self.value = value\\n    def spam(self):\\n        return self.value * 2\\n\\n@Extender\\nclass Client2:\\n    value = \\'ni?\\'\\n\\nX = Client1(\\'Ni!\\')                           # X is a Client1 instance\\nprint(X.spam())\\nprint(X.eggs())\\nprint(X.ham(\\'bacon\\'))\\n\\nY = Client2()\\nprint(Y.eggs())\\nprint(Y.ham(\\'bacon\\'))\\n\\nIn other words, at least in certain cases, decorators can manage classes as easily as\\nmetaclasses. The converse isn’t quite so straightforward, though; metaclasses can be\\nused to manage instances, but only with a certain amount of extra magic. The next\\nsection demonstrates.\\n\\nExample: Adding Methods to Classes\\n\\n| 1395\\n\\n\\x0cManaging instances instead of classes\\nAs we’ve just seen, class decorators can often serve the same class-management role as\\nmetaclasses. Metaclasses can often serve the same instance-management role as deco-\\nrators, too, but this requires extra code and may seem less natural. That is:\\n\\n• Class decorators can manage both classes and instances, but don’t create classes\\n\\nnormally.\\n\\n• Metaclasses can manage both classes and instances, but instances require extra\\n\\nwork.\\n\\nThat said, certain applications may be better coded in one or the other. For example,\\nconsider the following class decorator example from the prior chapter; it’s used to print\\na trace message whenever any normally named attribute of a class instance is fetched:\\n\\n# Class decorator to trace external instance attribute fetches\\n\\ndef Tracer(aClass):                                   # On @ decorator\\n    class Wrapper:\\n        def __init__(self, *args, **kargs):           # On instance creation\\n            self.wrapped = aClass(*args, **kargs)     # Use enclosing scope name\\n        def __getattr__(self, attrname):\\n            print(\\'Trace:\\', attrname)                 # Catches all but .wrapped\\n            return getattr(self.wrapped, attrname)    # Delegate to wrapped object\\n    return Wrapper\\n\\n@Tracer\\nclass Person:                                         # Person = Tracer(Person)\\n    def __init__(self, name, hours, rate):            # Wrapper remembers Person\\n        self.name = name\\n        self.hours = hours\\n        self.rate = rate                              # In-method fetch not traced\\n    def pay(self):\\n        return self.hours * self.rate\\n\\nbob = Person(\\'Bob\\', 40, 50)                           # bob is really a Wrapper\\nprint(bob.name)                                       # Wrapper embeds a Person\\nprint(bob.pay())                                      # Triggers __getattr__\\n\\nWhen this code is run, the decorator uses class name rebinding to wrap instance objects\\nin an object that produces the trace lines in the following output:\\n\\nc:\\\\code> py −3 manage-inst-deco.py\\nTrace: name\\nBob\\nTrace: pay\\n2000\\n\\nAlthough it’s possible for a metaclass to achieve the same effect, it seems less straight-\\nforward conceptually. Metaclasses are designed explicitly to manage class object cre-\\nation, and they have an interface tailored for this purpose. To use a metaclass just to\\nmanage instances, we have to also take on responsibility for creating the class too—an\\n\\n1396 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cextra step if normal class creation would otherwise suffice. The following metaclass, in\\nfile manage-inst-meta.py, has the same effect as the prior decorator:\\n\\n# Manage instances like the prior example, but with a metaclass\\n\\ndef Tracer(classname, supers, classdict):             # On class creation call\\n    aClass = type(classname, supers, classdict)       # Make client class\\n    class Wrapper:\\n        def __init__(self, *args, **kargs):           # On instance creation\\n            self.wrapped = aClass(*args, **kargs)\\n        def __getattr__(self, attrname):\\n            print(\\'Trace:\\', attrname)                 # Catches all but .wrapped\\n            return getattr(self.wrapped, attrname)    # Delegate to wrapped object\\n    return Wrapper\\n\\nclass Person(metaclass=Tracer):                       # Make Person with Tracer\\n    def __init__(self, name, hours, rate):            # Wrapper remembers Person\\n        self.name = name\\n        self.hours = hours\\n        self.rate = rate                              # In-method fetch not traced\\n    def pay(self):\\n        return self.hours * self.rate\\n\\nbob = Person(\\'Bob\\', 40, 50)                           # bob is really a Wrapper\\nprint(bob.name)                                       # Wrapper embeds a Person\\nprint(bob.pay())                                      # Triggers __getattr__\\n\\nThis works, but it relies on two tricks. First, it must use a simple function instead of a\\nclass, because type subclasses must adhere to object creation protocols. Second, it must\\nmanually create the subject class by calling type manually; it needs to return an instance\\nwrapper, but metaclasses are also responsible for creating and returning the subject\\nclass. Really, we’re using the metaclass protocol to imitate decorators in this example,\\nrather than vice versa; because both run at the conclusion of a class statement, in many\\nroles they are just variations on a theme. This metaclass version produces the same\\noutput as the decorator when run live:\\n\\nc:\\\\code> py −3 manage-inst-meta.py\\nTrace: name\\nBob\\nTrace: pay\\n2000\\n\\nYou should study both versions of these examples for yourself to weigh their tradeoffs.\\nIn general, though, metaclasses are probably best suited to class management, due to\\ntheir design; class decorators can manage either instances or classes, though they may\\nnot be the best option for more advanced metaclass roles that we don’t have space to\\ncover in this book. See the Web for more metaclass examples, but keep in mind that\\nsome are more appropriate than others (and some of their authors may know less of \\nPython than you do!).\\n\\nExample: Adding Methods to Classes\\n\\n| 1397\\n\\n\\x0cMetaclass and class decorator equivalence?\\nThe preceding section illustrated that metaclasses incur an extra step to create the class\\nwhen used in instance management roles, and hence can’t quite subsume decorators\\nin all use cases. But what about the inverse—are decorators a replacement for meta-\\nclasses?\\nJust in case this chapter has not yet managed to make your head explode, consider the\\nfollowing metaclass coding alternative too—a class decorator that returns a metaclass\\ninstance:\\n\\n# A decorator can call a metaclass, though not vice versa without type()\\n\\n>>> class Metaclass(type):\\n        def __new__(meta, clsname, supers, attrdict):\\n            print(\\'In M.__new__:\\')\\n            print([clsname, supers, list(attrdict.keys())])\\n            return type.__new__(meta, clsname, supers, attrdict)\\n\\n>>> def decorator(cls):\\n        return Metaclass(cls.__name__, cls.__bases__, dict(cls.__dict__))\\n\\n>>> class A:\\n        x = 1\\n\\n>>> @decorator\\n    class B(A):\\n        y = 2\\n        def m(self): return self.x  + self.y\\n\\nIn M.__new__:\\n[\\'B\\', (<class \\'__main__.A\\'>,), [\\'__qualname__\\', \\'__doc__\\', \\'m\\', \\'y\\', \\'__module__\\']]\\n>>> B.x, B.y\\n(1, 2)\\n>>> I = B()\\n>>> I.x, I.y, I.m()\\n(1, 2, 3)\\n\\nThis nearly proves the equivalence of the two tools, but really just in terms of  dis-\\npatch at class construction time. Again, decorators essentially serve the same role as\\nmetaclass __init__ methods. Because this decorator returns a metaclass instance, met-\\naclasses—or at least their type superclass—are still assumed here. Moreover, this winds\\nup triggering an additional metaclass call after the class is created, and isn’t an ideal\\nscheme in real code—you might as well move this metaclass to the first creation step:\\n\\n>>> class B(A, metaclass=Metaclass): ...     # Same effect, but makes just one class\\n\\nStill, there is some tool redundancy here, and decorator and metaclass roles often over-\\nlap in practice. And although decorators don’t directly support the notion of class-level\\nmethods in metaclasses discussed earlier, methods and state in proxy objects created\\nby decorators can achieve similar effects, though for space we’ll leave this last obser-\\nvation in the suggested explorations column.\\n\\n1398 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cThe inverse may not seem applicable—a metaclass can’t generally defer to a nonme-\\ntaclass decorator, because the class doesn’t yet exist until the metaclass call completes\\n—although a metaclass can take the form of a simple callable that invokes type to create\\nthe class directly and passes it on to the decorator. In other words, the crucial hook in\\nthe model is the type call issued for class construction. Given that, metaclasses and\\nclass decorators are often functionally equivalent, with varying dispatch protocol mod-\\nels:\\n\\n>>> def Metaclass(clsname, supers, attrdict):\\n        return decorator(type(clsname, supers, attrdict))\\n\\n>>> def decorator(cls): ...\\n>>> class B(A, metaclass=Metaclass): ...     # Metas can call decos and vice versa\\n\\nIn  fact,  metaclasses  need  not  necessarily  return  a  type  instance  either—any  object\\ncompatible with the class coder’s expectations will do—and this further blurs the dec-\\norator/metaclass distinction:\\n\\n>>> def func(name, supers, attrs):\\n        return \\'spam\\'\\n\\n>>> class C(metaclass=func):           # A class whose metaclass makes it a string!\\n        attr = \\'huh?\\'\\n\\n>>> C, C.upper()\\n(\\'spam\\', \\'SPAM\\')\\n\\n>>> def func(cls):\\n        return \\'spam\\'\\n\\n>>> @func\\n    class C:                           # A class whose decorator makes it a string!\\n        attr = \\'huh?\\'\\n\\n>>> C, C.upper()\\n(\\'spam\\', \\'SPAM\\')\\n\\nOdd metaclass and decorator tricks like these aside, timing often determines roles in\\npractice, as stated earlier:\\n\\n• Because decorators run after a class is created, they incur an extra runtime step in\\n\\nclass creation roles.\\n\\n• Because metaclasses must create classes, they incur an extra coding step in instance\\n\\nmanagement roles.\\n\\nIn other words, neither completely subsumes the other. Strictly speaking, metaclasses\\nmight be a functional superset, as they can call decorators during class creation; but\\nmetaclasses can also be substantially heavier to understand and code, and many roles\\nintersect completely. In practice, the need to take over class creation entirely is probably\\nmuch less important than tapping into the process in general.\\n\\nExample: Adding Methods to Classes\\n\\n| 1399\\n\\n\\x0cRather than follow this rabbit hole further, though, let’s move on to explore metaclass\\nroles that may be a bit more typical and practical. The next section concludes this\\nchapter with one more common use case—applying operations to a class’s methods\\nautomatically at class creation time.\\n\\nExample: Applying Decorators to Methods\\nAs we saw in the prior section, because they are both run at the end of a class statement,\\nmetaclasses  and  decorators  can  often  be  used  interchangeably,  albeit  with  different\\nsyntax. The choice between the two is arbitrary in many contexts. It’s also possible to\\nuse  them  in  combination,  as  complementary  tools.  In  this  section,  we’ll  explore  an\\nexample of just such a combination—applying a function decorator to all the methods\\nof a class.\\n\\nTracing with Decoration Manually\\nIn the prior chapter we coded two function decorators, one that traced and counted all\\ncalls made to a decorated function and another that timed such calls. They took various\\nforms there, some of which were applicable to both functions and methods and some\\nof which were not. The following collects both decorators’ final forms into a module\\nfile for reuse and reference here:\\n\\n# File decotools.py: assorted decorator tools\\nimport time\\n\\ndef tracer(func):                         # Use function, not class with __call__\\n    calls = 0                             # Else self is decorator instance only\\n    def onCall(*args, **kwargs):\\n        nonlocal calls\\n        calls += 1\\n        print(\\'call %s to %s\\' % (calls, func.__name__))\\n        return func(*args, **kwargs)\\n    return onCall\\n\\ndef timer(label=\\'\\', trace=True):                # On decorator args: retain args\\n    def onDecorator(func):                      # On @: retain decorated func\\n        def onCall(*args, **kargs):             # On calls: call original\\n            start   = time.clock()              # State is scopes + func attr\\n            result  = func(*args, **kargs)\\n            elapsed = time.clock() - start\\n            onCall.alltime += elapsed\\n            if trace:\\n                format = \\'%s%s: %.5f, %.5f\\'\\n                values = (label, func.__name__, elapsed, onCall.alltime)\\n                print(format % values)\\n            return result\\n        onCall.alltime = 0\\n        return onCall\\n    return onDecorator\\n\\n1400 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cAs we learned in the prior chapter, to use these decorators manually, we simply import\\nthem from the module and code the decoration @ syntax before each method we wish\\nto trace or time:\\n\\nfrom decotools import tracer\\n\\nclass Person:\\n    @tracer\\n    def __init__(self, name, pay):\\n        self.name = name\\n        self.pay  = pay\\n\\n    @tracer\\n    def giveRaise(self, percent):         # giveRaise = tracer(giverRaise)\\n        self.pay *= (1.0 + percent)       # onCall remembers giveRaise\\n\\n    @tracer\\n    def lastName(self):                   # lastName = tracer(lastName)\\n        return self.name.split()[-1]\\n\\nbob = Person(\\'Bob Smith\\', 50000)\\nsue = Person(\\'Sue Jones\\', 100000)\\nprint(bob.name, sue.name)\\nsue.giveRaise(.10)                        # Runs onCall(sue, .10)\\nprint(\\'%.2f\\' % sue.pay)\\nprint(bob.lastName(), sue.lastName())     # Runs onCall(bob), remembers lastName\\n\\nWhen this code is run, we get the following output—calls to decorated methods are\\nrouted to logic that intercepts and then delegates the call, because the original method\\nnames have been bound to the decorator:\\n\\nc:\\\\code> py −3 decoall-manual.py\\ncall 1 to __init__\\ncall 2 to __init__\\nBob Smith Sue Jones\\ncall 1 to giveRaise\\n110000.00\\ncall 1 to lastName\\ncall 2 to lastName\\nSmith Jones\\n\\nTracing with Metaclasses and Decorators\\nThe manual decoration scheme of the prior section works, but it requires us to add\\ndecoration syntax before each method we wish to trace and to later remove that syntax\\nwhen we no longer desire tracing. If we want to trace every method of a class, this can\\nbecome tedious in larger programs. In more dynamic contexts where augmentations\\ndepend upon runtime parameters, it may not be possible at all. It would be better if we\\ncould somehow apply the tracer decorator to all of a class’s methods automatically.\\nWith metaclasses, we can do exactly that—because they are run when a class is con-\\nstructed, they are a natural place to add decoration wrappers to a class’s methods. By\\n\\nExample: Applying Decorators to Methods\\n\\n| 1401\\n\\n\\x0cscanning the class’s attribute dictionary and testing for function objects there, we can\\nautomatically run methods through the decorator and rebind the original names to the\\nresults. The effect is the same as the automatic method name rebinding of decorators,\\nbut we can apply it more globally:\\n\\n# Metaclass that adds tracing decorator to every method of a client class\\n\\nfrom types import FunctionType\\nfrom decotools import tracer\\n\\nclass MetaTrace(type):\\n    def __new__(meta, classname, supers, classdict):\\n        for attr, attrval in classdict.items():\\n            if type(attrval) is FunctionType:                      # Method?\\n                classdict[attr] = tracer(attrval)                  # Decorate it\\n        return type.__new__(meta, classname, supers, classdict)    # Make class\\n\\nclass Person(metaclass=MetaTrace):\\n    def __init__(self, name, pay):\\n        self.name = name\\n        self.pay  = pay\\n    def giveRaise(self, percent):\\n        self.pay *= (1.0 + percent)\\n    def lastName(self):\\n        return self.name.split()[-1]\\n\\nbob = Person(\\'Bob Smith\\', 50000)\\nsue = Person(\\'Sue Jones\\', 100000)\\nprint(bob.name, sue.name)\\nsue.giveRaise(.10)\\nprint(\\'%.2f\\' % sue.pay)\\nprint(bob.lastName(), sue.lastName())\\n\\nWhen this code is run, the results are the same as before—calls to methods are routed\\nto the tracing decorator first for tracing, and then propagated on to the original method:\\n\\nc:\\\\code> py −3 decoall-meta.py\\ncall 1 to __init__\\ncall 2 to __init__\\nBob Smith Sue Jones\\ncall 1 to giveRaise\\n110000.00\\ncall 1 to lastName\\ncall 2 to lastName\\nSmith Jones\\n\\nThe result you see here is a combination of decorator and metaclass work—the meta-\\nclass automatically applies the function decorator to every method at class creation\\ntime, and the function decorator automatically intercepts method calls in order to print\\nthe trace messages in this output. The combination “just works,” thanks to the gener-\\nality of both tools.\\n\\n1402 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cApplying Any Decorator to Methods\\nThe prior metaclass example works for just one specific function decorator—tracing.\\nHowever, it’s trivial to generalize this to apply any decorator to all the methods of a\\nclass. All we have to do is add an outer scope layer to retain the desired decorator, much\\nlike we did for decorators in the prior chapter. The following, for example, codes such\\na generalization and then uses it to apply the tracer decorator again:\\n\\n# Metaclass factory: apply any decorator to all methods of a class\\n\\nfrom types import FunctionType\\nfrom decotools import tracer, timer\\n\\ndef decorateAll(decorator):\\n    class MetaDecorate(type):\\n        def __new__(meta, classname, supers, classdict):\\n            for attr, attrval in classdict.items():\\n                if type(attrval) is FunctionType:\\n                    classdict[attr] = decorator(attrval)\\n            return type.__new__(meta, classname, supers, classdict)\\n    return MetaDecorate\\n\\nclass Person(metaclass=decorateAll(tracer)):       # Apply a decorator to all\\n    def __init__(self, name, pay):\\n        self.name = name\\n        self.pay  = pay\\n    def giveRaise(self, percent):\\n        self.pay *= (1.0 + percent)\\n    def lastName(self):\\n        return self.name.split()[-1]\\n\\nbob = Person(\\'Bob Smith\\', 50000)\\nsue = Person(\\'Sue Jones\\', 100000)\\nprint(bob.name, sue.name)\\nsue.giveRaise(.10)\\nprint(\\'%.2f\\' % sue.pay)\\nprint(bob.lastName(), sue.lastName())\\n\\nWhen this code is run as it is, the output is again the same as that of the previous\\nexamples—we’re  still  ultimately  decorating  every  method  in  a  client  class  with  the\\ntracer function decorator, but we’re doing so in a more generic fashion:\\n\\nc:\\\\code> py −3 decoall-meta-any.py\\ncall 1 to __init__\\ncall 2 to __init__\\nBob Smith Sue Jones\\ncall 1 to giveRaise\\n110000.00\\ncall 1 to lastName\\ncall 2 to lastName\\nSmith Jones\\n\\nNow, to apply a different decorator to the methods, we can simply replace the decorator\\nname in the class header line. To use the timer function decorator shown earlier, for\\n\\nExample: Applying Decorators to Methods\\n\\n| 1403\\n\\n\\x0cexample, we could use either of the last two header lines in the following when defining\\nour class—the first accepts the timer’s default arguments, and the second specifies label\\ntext:\\n\\nclass Person(metaclass=decorateAll(tracer)):               # Apply tracer\\n\\nclass Person(metaclass=decorateAll(timer())):              # Apply timer, defaults\\nclass Person(metaclass=decorateAll(timer(label=\\'**\\'))):    # Decorator arguments\\n\\nNotice that this scheme cannot support nondefault decorator arguments differing per\\nmethod in the client class, but it can pass in decorator arguments that apply to all such\\nmethods, as done here. To test, use the last of these metaclass declarations to apply the\\ntimer, and add the following lines at the end of the script to see the timer’s extra in-\\nformational attributes:\\n\\n# If using timer: total time per method\\n\\nprint(\\'-\\'*40)\\nprint(\\'%.5f\\' % Person.__init__.alltime)\\nprint(\\'%.5f\\' % Person.giveRaise.alltime)\\nprint(\\'%.5f\\' % Person.lastName.alltime)\\n\\nThe new output is as follows—the metaclass wraps methods in timer decorators now,\\nso we can tell how long each and every call takes, for every method of the class:\\n\\nc:\\\\code> py −3 decoall-meta-any2.py\\n**__init__: 0.00001, 0.00001\\n**__init__: 0.00001, 0.00001\\nBob Smith Sue Jones\\n**giveRaise: 0.00002, 0.00002\\n110000.00\\n**lastName: 0.00002, 0.00002\\n**lastName: 0.00002, 0.00004\\nSmith Jones\\n----------------------------------------\\n0.00001\\n0.00002\\n0.00004\\n\\nMetaclasses Versus Class Decorators: Round 3 (and Last)\\nAs you might expect, class decorators intersect with metaclasses here, too. The fol-\\nlowing version replaces the preceding example’s metaclass with a class decorator. That\\nis, it defines and uses a class decorator that applies a function decorator to all methods\\nof a class. Although the prior sentence may sound more like a Zen statement than a\\ntechnical description, this all works quite naturally—Python’s decorators support ar-\\nbitrary nesting and combinations:\\n\\n# Class decorator factory: apply any decorator to all methods of a class\\n\\nfrom types import FunctionType\\nfrom decotools import tracer, timer\\n\\n1404 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cdef decorateAll(decorator):\\n    def DecoDecorate(aClass):\\n        for attr, attrval in aClass.__dict__.items():\\n            if type(attrval) is FunctionType:\\n                setattr(aClass, attr, decorator(attrval))        # Not __dict__\\n        return aClass\\n    return DecoDecorate\\n\\n@decorateAll(tracer)                          # Use a class decorator\\nclass Person:                                 # Applies func decorator to methods\\n    def __init__(self, name, pay):            # Person = decorateAll(..)(Person)\\n        self.name = name                      # Person = DecoDecorate(Person)\\n        self.pay  = pay\\n    def giveRaise(self, percent):\\n        self.pay *= (1.0 + percent)\\n    def lastName(self):\\n        return self.name.split()[-1]\\n\\nbob = Person(\\'Bob Smith\\', 50000)\\nsue = Person(\\'Sue Jones\\', 100000)\\nprint(bob.name, sue.name)\\nsue.giveRaise(.10)\\nprint(\\'%.2f\\' % sue.pay)\\nprint(bob.lastName(), sue.lastName())\\n\\nWhen this code is run as it is, the class decorator applies the tracer function decorator\\nto every method and produces a trace message on calls (the output is the same as that\\nof the preceding metaclass version of this example):\\n\\nc:\\\\code> py −3 decoall-deco-any.py\\ncall 1 to __init__\\ncall 2 to __init__\\nBob Smith Sue Jones\\ncall 1 to giveRaise\\n110000.00\\ncall 1 to lastName\\ncall 2 to lastName\\nSmith Jones\\n\\nNotice that the class decorator returns the original, augmented class, not a wrapper\\nlayer for it (as is common when wrapping instance objects instead). As for the metaclass\\nversion, we retain the type of the original class—an instance of Person is an instance of\\nPerson, not of some wrapper class. In fact, this class decorator deals with class creation\\nonly; instance creation calls are not intercepted at all.\\nThis distinction can matter in programs that require type testing for instances to yield\\nthe original class, not a wrapper. When augmenting a class instead of an instance, class\\ndecorators can retain the original class type. The class’s methods are not their original\\nfunctions because they are rebound to decorators, but this is likely less important in\\npractice, and it’s true in the metaclass alternative as well.\\nAlso note that, like the metaclass version, this structure cannot support function dec-\\norator arguments that differ per method in the decorated class, but it can handle such\\n\\nExample: Applying Decorators to Methods\\n\\n| 1405\\n\\n\\x0carguments if they apply to all such methods. To use this scheme to apply the timer\\ndecorator, for example, either of the last two decoration lines in the following will\\nsuffice if coded just before our class definition—the first uses decorator argument de-\\nfaults, and the second provides one explicitly:\\n\\n@decorateAll(tracer)                 # Decorate all with tracer\\n\\n@decorateAll(timer())                # Decorate all with timer, defaults\\n@decorateAll(timer(label=\\'@@\\'))      # Same but pass a decorator argument\\n\\nAs before, let’s use the last of these decorator lines and add the following at the end of\\nthe script to test our example with a different decorator (better schemes are possible\\non both the testing and timing fronts here, of course, but we’re at chapter end; improve\\nas desired):\\n\\n# If using timer: total time per method\\n\\nprint(\\'-\\'*40)\\nprint(\\'%.5f\\' % Person.__init__.alltime)\\nprint(\\'%.5f\\' % Person.giveRaise.alltime)\\nprint(\\'%.5f\\' % Person.lastName.alltime)\\n\\nThe same sort of output appears—for every method we get timing data for each and\\nall calls, but we’ve passed a different label argument to the timer decorator:\\n\\nc:\\\\code> py −3 decoall-deco-any2.py\\n@@__init__: 0.00001, 0.00001\\n@@__init__: 0.00001, 0.00001\\nBob Smith Sue Jones\\n@@giveRaise: 0.00002, 0.00002\\n110000.00\\n@@lastName: 0.00002, 0.00002\\n@@lastName: 0.00002, 0.00004\\nSmith Jones\\n----------------------------------------\\n0.00001\\n0.00002\\n0.00004\\n\\nFinally, it’s possible to combine decorators such that each runs per method call, but it\\nwill likely require changes to those we’ve coded here. As is, nesting calls to them directly\\nwinds up tracing or timing the other’s creation-time application, listing the two on\\nseparate lines results in tracing or timing the other’s wrapper before running the original\\nmethod, and metaclasses seem to fare no better on this front:\\n\\n@decorateAll(tracer(timer(label=\\'@@\\')))    # Traces applying the timer\\nclass Person:\\n\\n@decorateAll(tracer)                       # Traces onCall wrapper, times methods\\n@decorateAll(timer(label=\\'@@\\'))\\nclass Person:\\n\\n@decorateAll(timer(label=\\'@@\\'))\\n\\n1406 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0c@decorateAll(tracer)                       # Times onCall wrapper, traces methods\\nclass Person:\\n\\nPondering this further will have to remain suggested study—both because we’re out of\\nspace and time, and because this may quite possibly be illegal in some states!\\nAs you can see, metaclasses and class decorators are not only often interchangeable,\\nbut also commonly complementary. Both provide advanced but powerful ways to cus-\\ntomize and manage both class and instance objects, because both ultimately allow you\\nto insert code into the class creation process. Although some more advanced applica-\\ntions may be better coded with one or the other, the way you choose or combine these\\ntwo tools in many cases is largely up to you.\\n\\nChapter Summary\\nIn  this  chapter,  we  studied  metaclasses  and  explored  examples  of  them  in  action.\\nMetaclasses allow us to tap into the class creation protocol of Python, in order to man-\\nage or augment user-defined classes. Because they automate this process, they may\\nprovide better solutions for API writers than manual code or helper functions; because\\nthey encapsulate such code, they may minimize maintenance costs better than some\\nother approaches.\\nAlong the way, we also saw how the roles of class decorators and metaclasses often\\nintersect: because both run at the conclusion of a class statement, they can sometimes\\nbe used interchangeably. Class decorators and metaclasses can both be used to manage\\nboth class and instance objects, though each tool may present tradeoffs in some use\\ncases.\\nSince this chapter covered an advanced topic, we’ll work through just a few quiz ques-\\ntions to review the basics (candidly, if you’ve made it this far in a chapter on metaclasses,\\nyou probably already deserve extra credit!). Because this is the last part of the book,\\nwe’ll  forgo  the  end-of-part  exercises.  Be  sure  to  see  the  appendixes  that  follow  for\\nPython changes, the solutions to the prior parts’ exercises, and more; the last of these\\nincludes a sampling of typical application-level programs for self-study.\\nOnce you finish the quiz, you’ve officially reached the end of this book’s technical\\nmaterial. The next and final chapter offers some brief closing thoughts to wrap up the\\nbook at large. I’ll see you there in the Python benediction after you work through this\\nfinal quiz.\\n\\nTest Your Knowledge: Quiz\\n1. What is a metaclass?\\n2. How do you declare the metaclass of a class?\\n3. How do class decorators overlap with metaclasses for managing classes?\\n\\nTest Your Knowledge: Quiz | 1407\\n\\n\\x0c4. How do class decorators overlap with metaclasses for managing instances?\\n5. Would you rather count decorators or metaclasses amongst your weaponry? (And\\n\\nplease phrase your answer in terms of a popular Monty Python skit.)\\n\\nTest Your Knowledge: Answers\\n1. A metaclass is a class used to create a class. Normal new-style classes are instances\\nof the type class by default. Metaclasses are usually subclasses of the type class,\\nwhich redefines class creation protocol methods in order to customize the class\\ncreation  call  issued  at  the  end  of  a  class  statement;  they  typically  redefine  the\\nmethods __new__ and __init__ to tap into the class creation protocol. Metaclasses\\ncan also be coded other ways—as simple functions, for example—but they are\\nalways responsible for making and returning an object for the new class. Meta-\\nclasses may have methods and data to provide behavior for their classes too—and\\nconstitute a secondary pathway for inheritance search—but their attributes are\\naccessible only to their class instances, not to their instance’s instances.\\n\\n2. In Python 3.X, use a keyword argument in the  class header line:  class  C(meta\\nclass=M). In Python 2.X, use a class attribute instead: __metaclass__ = M. In 3.X,\\nthe class header line can also name normal superclasses before the metaclass key-\\nword argument; in 2.X you generally should derive from object too, though this\\nis sometimes optional.\\n\\n3. Because both are automatically triggered at the end of a  class statement, class\\ndecorators and metaclasses can both be used to manage classes. Decorators rebind\\na class name to a callable’s result and metaclasses route class creation through a\\ncallable,  but  both  hooks  can  be  used  for  similar  purposes.  To  manage  classes,\\ndecorators simply augment and return the original class objects. Metaclasses aug-\\nment a class after they create it. Decorators may have a slight disadvantage in this\\nrole if a new class must be defined, because the original class has already been\\ncreated.\\n\\n4. Because both are automatically triggered at the end of a class statement, we can\\nuse both class decorators and metaclasses to manage class instances, by inserting\\na wrapper (proxy) object to catch instance creation calls. Decorators may rebind\\nthe class name to a callable run on instance creation that retains the original class\\nobject. Metaclasses can do the same, but may have a slight disadvantage in this\\nrole, because they must also create the class object.\\n\\n5. Our  chief  weapon  is  decorators...decorators  and  metaclasses...metaclasses  and\\ndecorators... Our two weapons are metaclasses and decorators...and ruthless effi-\\nciency...  Our  three  weapons  are  metaclasses,  decorators,  and  ruthless  effi-\\nciency...and an almost fanatical devotion to Python... Our four...no... Amongst our\\nweapons...  Amongst  our  weaponry...are  such  elements  as  metaclasses,  decora-\\ntors... I’ll come in again...\\n\\n1408 | Chapter 40:\\u2002Metaclasses\\n\\n\\x0cCHAPTER 41\\nAll Good Things\\n\\nWelcome to the end of the book! Now that you’ve made it this far, I want to say a few\\nwords in closing about Python’s evolution before turning you loose on the software\\nfield. This topic is subjective by nature, of course, but vital to all Python users none-\\ntheless.\\nYou’ve now had a chance to see the entire language yourself—including some advanced\\nfeatures that may seem at odds with its scripting paradigm. Though many will under-\\nstandably accept this as status quo, in an open source project it’s crucial that some ask\\nthe “why” questions too. Ultimately, the trajectory of the Python story—and its true\\nconclusion—is at least in part up to you.\\n\\nThe Python Paradox\\nIf you’ve read this book, or reasonable subsets of it, you should now be able to weigh\\nPython’s tradeoffs fairly. As you’ve seen, Python is a powerful, expressive, and even\\nfun programming language, which will serve as an enabling technology for wherever\\nyou choose to go next. At the same time, you’ve also seen that today’s Python is some-\\nthing of a paradox: it has expanded to incorporate tools that many consider both need-\\nlessly redundant and curiously advanced—and at a rate that appears to be only accel-\\nerating.\\nFor my part, as one of Python’s earliest advocates, I’ve watched it morph over the years\\nfrom simple to sophisticated tool, with a steadily shifting scope. By most measures, it\\nseems to have grown at least as complex as other languages that drove many of us to\\nPython in the first place. And just as in those other languages, this has inevitably fos-\\ntered a growing culture in which obscurity is a badge of honor.\\nThat’s as contrary to Python’s original goals as it could be. Run an import this in any\\nPython interactive session to see what I mean—the creed I’ve quoted from repeatedly\\nin this book in contexts where it was clearly violated. On many levels, its core ideals of\\nexplicitness, simplicity, and lack of redundancy have been either naively forgotten or\\ncarelessly abandoned.\\n\\n1409\\n\\n\\x0cThe end result is a language and community that could in part be described today in\\nsome of the same terms I used in the Perl sidebar of Chapter 1. While Python still has\\nmuch to offer, this trend threatens to negate much of its perceived advantage, as the\\nnext section explains.\\n\\nOn “Optional” Language Features\\nI included a quote near the start of the prior chapter about metaclasses not being of\\ninterest to 99% of Python programmers, to underscore their perceived obscurity. That\\nstatement is not quite accurate, though, and not just numerically so. The quote’s author\\nis a noted Python contributor and friend from the early days of Python, and I don’t\\nmean to pick on anyone unfairly. Moreover, I’ve often made such statements about\\nlanguage feature obscurity myself—in the various editions of this very book, in fact.\\nThe problem, though, is that such statements really apply only to people who work\\nalone and only ever use code that they’ve written themselves. As soon as an “optional”\\nadvanced language feature is used by anyone in an organization, it is no longer optional\\n—it is effectively imposed on everyone in the organization. The same holds true for\\nexternally developed software you use in your systems—if the software’s author uses\\nan advanced or extraneous language feature, it’s no longer entirely optional for you,\\nbecause you have to understand the feature to reuse or change the code.\\nThis observation applies to all the advanced topics covered in this book, including those\\nlisted as “magic” hooks near the beginning of the prior chapter, and many others:\\nGenerators,  decorators,  slots,  properties,  descriptors,  metaclasses,  context  managers,\\nclosures, super, namespace packages, Unicode, function annotations, relative imports,\\nkeyword-only arguments, class and static methods, and even obscure applications of\\ncomprehensions and operator overloading\\n\\nIf any person or program you need to work with uses such tools, they automatically\\nbecome part of your required knowledge base too.\\nTo see just how daunting this can be, one need only consider Chapter 40’s new-style\\ninheritance procedure—a horrifically convoluted model that can make descriptors and\\nmetaclasses prerequisite to understanding even basic name resolution. Chapter 32’s\\nsuper similarly ups the intellectual ante—imposing an obscenely implicit and artificial\\nMRO algorithm on readers of any code that uses this tool.\\nThe net effect of such over-engineering is to either escalate learning requirements rad-\\nically, or foster a user base that only partially understands the tools they employ. This\\nis obviously less than ideal for those hoping to use Python in simpler ways, and con-\\ntradictory to the scripting motif.\\n\\n1410 | Chapter 41:\\u2002All Good Things\\n\\n\\x0cAgainst Disquieting Improvements\\nThis  observation  also  applies  to  the  many  redundant  features  we’ve  seen,  such  as\\nChapter  7’s  str.format  method  and  Chapter  34’s  with  statement—tools  borrowed\\nfrom other languages, and overlapping with others long present in Python. When pro-\\ngrammers use multiple ways to achieve the same goal, all become required knowledge.\\nLet’s be honest: Python has grown rife with redundancy in recent years. As I suggested\\nin the preface—and as you’ve now seen first-hand—today’s Python world comes re-\\nplete with all the functional duplications and expansions chronicled in Table 41-1,\\namong others we’ve seen in this book.\\n\\nTable 41-1. A sampling of redundancy and feature explosion in Python\\n\\nCategory\\n3 major paradigms\\n2 incompatible lines\\n3 string formatting tools\\n4 attribute accessor tools\\n2 finalization statements\\n4 varieties of comprehension\\n3 class augmentation tools\\n4 kinds of methods\\n2 attribute storage systems\\n4 flavors of imports\\n2 superclass dispatch protocols\\n5 assignment statement forms\\n2 types of functions\\n5 function argument forms\\n2 class behavior sources\\n4 state retention options\\n2 class models\\n2 Unicode models\\n2 PyDoc modes\\n2 byte code storage schemes\\n\\nSpecifics\\nProcedural, functional, object-oriented\\n2.X and 3.X, with new-style classes in both\\n% expression, str.format, string.Template\\n__getattr__, __getattribute__, properties, descriptors\\ntry/finally, with\\nList, generator, set, dictionary\\nFunction calls, decorators, metaclasses\\nInstance, static, class, metaclass\\nDictionaries, slots\\nModule, package, package relative, namespace package\\nDirect calls, super + MRO\\nBasic, multiname, augmented, sequence, starred\\nNormal, generator\\nBasic, name=value, *pargs, **kargs, keyword-only\\nSuperclasses, metaclasses\\nClasses, closures, function attributes, mutables\\nClassic + new-style in 2.X, mandated new-style in 3.X\\nOptional in 2.X, mandated in 3.X\\nGUI client, required all-browser in recent 3.X\\nOriginal, __pycache__ only in recent 3.X\\n\\nIf you care about Python, you should take a moment to browse this table. It reflects a\\nvirtual explosion in functionality and toolbox size—59 concepts that are all fair game\\nfor newcomers. Most of its categories began with just one original member in Python;\\nmany were expanded in part to imitate other languages; and only the last few can be\\n\\nThe Python Paradox | 1411\\n\\n\\x0csimplified by pretending that the latest Python is the only Python that matters to its\\nprogrammers.\\nI’ve stressed avoiding unwarranted complexity in this book, but in practice, both ad-\\nvanced and new tools tend to encourage their own adoption—often for no better reason\\nthan a programmer’s personal desire to demonstrate prowess. The net result is that\\nmuch Python code today is littered with these complex and extraneous tools. That is,\\nnothing is truly “optional” if nothing is truly optional.\\n\\nComplexity Versus Power\\nThis is why some Python old-timers (myself included) sometimes worry that Python\\nseems to have grown larger and more complex over time. New features added by vet-\\nerans, converts, and even amateurs may have raised the intellectual bar for newcomers.\\nAlthough Python’s core ideas, like dynamic typing and built-in types, have remained\\nessentially  the  same,  its  advanced  additions  can  become  required  reading  for  any\\nPython programmer. I chose to cover these topics here for this reason, despite their\\nomission in early editions. It’s not possible to skip the advanced stuff if it’s in code you\\nhave to understand.\\nOn the other hand, as mentioned in Chapter 1, to most observers Python is still no-\\nticeably simpler than most of its contemporaries, and perhaps only as complex as its\\nmany roles require. Though it’s acquired many of the same tools as Java, C#, and\\nC++, they tend to be lighter weight in the context of a dynamically typed scripting\\nlanguage. For all its growth over the years, Python is still relatively easy to learn and\\nuse when compared to the alternatives, and new learners can often pick up advanced\\ntopics as needed.\\nAnd frankly, application programmers tend to spend most of their time dealing with\\nlibraries and extensions, not advanced and sometimes-arcane language features. For\\ninstance, the book Programming Python—a follow-up to this one—deals mostly with\\nthe marriage of Python to application libraries for tasks such as GUIs, databases, and\\nthe Web, not with esoteric language tools (though Unicode still forces itself onto many\\nstages, and the odd generator expression and yield crop up along the way).\\nMoreover, the flipside of this growth is that Python has become more powerful. When\\nused well, tools like decorators and metaclasses are not only arguably “cool,” but allow\\ncreative programmers to build more flexible and useful APIs for other programmers to\\nuse. As we’ve seen, they can also provide good solutions to problems of encapsulation\\nand maintenance.\\n\\nSimplicity Versus Elitism\\nWhether this justifies the potential expansion of required Python knowledge is up to\\nyou to decide. For better or worse, a person’s skill level often decides this issue by\\ndefault—more advanced programmers like more advanced tools and tend to forget\\n\\n1412 | Chapter 41:\\u2002All Good Things\\n\\n\\x0cabout their impact on other camps. Fortunately, though, this isn’t an absolute; good\\nprogrammers also understand that simplicity is good engineering, and advanced tools\\nshould be used only when warranted. This is true in any programming language, but\\nespecially in one like Python that is frequently exposed to new or novice programmers\\nas an extension tool.\\nAnd if you’re still not buying this, keep in mind that many people using Python are not\\ncomfortable with even basic OOP. Trust me on this; I’ve met thousands of them. Al-\\nthough Python was never a trivial subject, the reports from the software trenches are\\nvery clear on this point: unwarranted added complexity is never a welcome feature,\\nespecially when it is driven by the personal preferences of an unrepresentative few.\\nWhether intended or not, this is often understandably perceived as elitism—a mindset\\nthat is both unproductive and rude, and has no place in a tool as widely used as Python.\\nThis is also a social issue, of course, and pertains as much to individual programmers\\nas to language designers. In the “real world” where open source software is measured,\\nthough, Python-based systems that require their users to master the nuances of meta-\\nclasses, descriptors, and the like should probably scale their market expectations ac-\\ncordingly. Hopefully, if this book has done its job, you’ll find the importance of sim-\\nplicity in programming to be one of its most important and lasting takeaways.\\n\\nClosing Thoughts\\nSo there you have it—some observations from someone who has been using, teaching,\\nand advocating Python for two decades, and still wishes nothing but the best for its\\nfuture. None of these concerns are entirely new, of course. Indeed, the growth of this\\nvery book over the years seems testament to the effect of Python’s own growth—if not\\nan ironic eulogy to its original conception as a tool that would simplify programming\\nand be accessible to both experts and nonspecialists alike. Judging by language heft\\nalone, that dream seems to have been either neglected or abandoned entirely.\\nThat said, Python’s present rise in popularity seems to show no signs of abating—a\\npowerful counterargument to complexity concerns. Today’s Python world may be un-\\nderstandably less concerned with its original and perhaps idealistic goals than with\\napplying its present form in their work. Python gets many a job done in the practical\\nworld of complex programming requirements, and this is still ample cause to recom-\\nmend it for many tasks. Original goals aside, mass appeal does qualify as one form of\\nsuccess, though one whose significance will have to await the verdict of time.\\nIf you’re interested in musing further over Python’s evolution and learning curve, I\\nwrote  a  more  in-depth  article  in  2012  on  such  things:  Answer  Me  These  Questions\\nThree...,  available  online  at  http://learning-python.com/pyquestions3.html.  These  are\\nimportant pragmatic questions that are crucial to Python’s future, and deserve more\\nattention than I’ve given here. But these are highly subjective issues; this is not a phi-\\nlosophy text; and this book has already exceeded its page-count targets.\\n\\nThe Python Paradox | 1413\\n\\n\\x0cMore importantly, in an open source project like Python the answers to such questions\\nmust be formed anew by each wave of newcomers. I hope the wave you ride in will\\nhave as much common sense as fun while plotting Python’s future.\\n\\nWhere to Go From Here\\nAnd that’s a wrap, folks. You’ve officially reached the end of this book. Now that you\\nknow Python inside and out, your next step, should you choose to take it, is to explore\\nthe libraries, techniques, and tools available in the application domains in which you\\nwork.\\nBecause Python is so widely used, you’ll find ample resources for using it in almost any\\napplication you can think of—from GUIs, the Web, and databases to numeric pro-\\ngramming, robotics, and system administration. See Chapter 1 and your favorite web\\nbrowser for pointers to popular tools and topics.\\nThis is where Python starts to become truly fun, but this is also where this book’s story\\nends, and others’ begin. For pointers on where to turn after this book, see the recom-\\nmended follow-up texts mentioned in the preface. I hope to see you in an applications\\nprogramming domain soon.\\nGood luck with your journey. And of course, “Always look on the bright side of Life!”\\n\\nEncore: Print Your Own Completion Certificate!\\nAnd one last thing: in lieu of exercises for this part of the book, I’m going to post a\\nbonus script here for you to study and run on your own. I can’t provide completion\\ncertificates for readers of this book (and the certificates would be worthless if I could),\\nbut I can include an arguably cheesy Python script that does—the following file, cer-\\ntificate.py, is a Python 2.X and 3.X script that creates a simple book completion certif-\\nicate in both text and HTML file forms, and pops them up in a web browser on your\\nmachine by default.\\n#!/usr/bin/python\\n\"\"\"\\nFile certificate.py: a Python 2.X and 3.X script.\\nGenerate a bare-bones class completion certificate: printed,\\nand saved in text and html files displayed in a web browser.\\n\"\"\"\\nfrom __future__ import print_function             # 2.X compatibility\\nimport time, sys, webbrowser\\n\\nif sys.version_info[0] == 2:                      # 2.X compatibility\\n    input = raw_input\\n    import cgi\\n    htmlescape = cgi.escape\\nelse:\\n    import html\\n\\n1414 | Chapter 41:\\u2002All Good Things\\n\\n\\x0c    htmlescape = html.escape\\n\\nmaxline  = 60                         # For seperator lines\\nbrowser  = True                       # Display in a browser\\nsaveto   = \\'Certificate.txt\\'          # Output filenames\\ntemplate = \"\"\"\\n%s\\n\\n ===> Official Certificate <===\\n\\nDate: %s\\n\\nThis certifies that:\\n\\n\\\\t%s\\n\\nhas survived the massive tome:\\n\\n\\\\t%s\\n\\nand is now entitled to all privileges thereof, including\\nthe right to proceed on to learning how to develop Web\\nsites, desktop GUIs, scientific models, and assorted apps,\\nwith the possible assistance of follow-up applications\\nbooks such as Programming Python (shameless plug intended).\\n\\n--Mark Lutz, Instructor\\n\\n(Note: certificate void where obtained by skipping ahead.)\\n\\n%s\\n\"\"\"\\n\\n# Interact, setup\\nfor c in \\'Congratulations!\\'.upper():\\n    print(c, end=\\' \\')\\n    sys.stdout.flush()    # Else some shells wait for \\\\n\\n    time.sleep(0.25)\\nprint()\\n\\ndate = time.asctime()\\nname = input(\\'Enter your name: \\').strip() or \\'An unknown reader\\'\\nsept = \\'*\\' * maxline\\nbook = \\'Learning Python 5th Edition\\'\\n\\n# Make text file version\\nfile = open(saveto, \\'w\\')\\ntext = template % (sept, date, name, book, sept)\\nprint(text, file=file)\\nfile.close()\\n\\n# Make html file version\\nhtmlto = saveto.replace(\\'.txt\\', \\'.html\\')\\nfile = open(htmlto, \\'w\\')\\n\\nEncore: Print Your Own Completion Certificate!\\n\\n| 1415\\n\\n\\x0ctags = text.replace(sept,   \\'<hr>\\')                   # Insert a few tags\\ntags = tags.replace(\\'===>\\', \\'<h1 align=center>\\')\\ntags = tags.replace(\\'<===\\', \\'</h1>\\')\\n\\ntags = tags.split(\\'\\\\n\\')                               # Line-by-line mods\\ntags = [\\'<p>\\' if line == \\'\\'\\n            else line for line in tags]\\ntags = [\\'<i>%s</i>\\' % htmlescape(line) if line[:1] == \\'\\\\t\\'\\n            else line for line in tags]\\ntags = \\'\\\\n\\'.join(tags)\\n\\nlink = \\'<i><a href=\"http://www.rmi.net/~lutz\">Book support site</a></i>\\\\n\\'\\nfoot = \\'<table>\\\\n<td><img src=\"ora-lp.jpg\" hspace=5>\\\\n<td>%s</table>\\\\n\\' % link\\ntags = \\'<html><body bgcolor=beige>\\' + tags + foot + \\'</body></html>\\'\\n\\nprint(tags, file=file)\\nfile.close()\\n\\n# Display results\\nprint(\\'[File: %s]\\' % saveto, end=\\'\\')\\nprint(\\'\\\\n\\' * 2, open(saveto).read())\\n\\nif browser:\\n    webbrowser.open(saveto, new=True)\\n    webbrowser.open(htmlto, new=False)\\n\\nif sys.platform.startswith(\\'win\\'):\\n    input(\\'[Press Enter]\\')  # Keep window open if clicked on Windows\\n\\nRun this script on your own, and study its code for a summary of some of the ideas\\nwe’ve covered in this book. Fetch it from this book’s website described in the preface\\nif you wish. You won’t find any descriptors, decorators, metaclasses, or super calls in\\nthis code, but it’s typical Python nonetheless.\\nWhen run, it generates the web page captured in the fully gratuitous Figure 41-1. This\\ncould be much more grandiose, of course; see the Web for pointers to Python support\\nfor PDFs and other document tools such as Sphinx surveyed in Chapter 15. But hey: if\\nyou’ve made it to the end of this book, you deserve another joke or two...\\n\\n1416 | Chapter 41:\\u2002All Good Things\\n\\n\\x0cFigure 41-1. Web page created and opened by certificate.py.\\n\\nEncore: Print Your Own Completion Certificate!\\n\\n| 1417\\n\\n\\x0c\\x0cPART IX\\nAppendixes\\n\\n\\x0c\\x0cAPPENDIX A\\nInstallation and Configuration\\n\\nThis appendix provides additional installation and configuration details as a resource\\nfor people new to these topics. It’s located here because not all readers will need to deal\\nwith these subjects up front. Because it covers some peripheral topics such as environ-\\nment variables and command-line arguments, though, this material probably merits at\\nleast a quick scan for most readers.\\n\\nInstalling the Python Interpreter\\nBecause you need the Python interpreter to run Python scripts, the first step in using\\nPython is usually installing Python. Unless one is already available on your machine,\\nyou’ll need to fetch, install, and possibly configure a recent version of Python on your\\ncomputer. You’ll only need to do this once per machine, and if you will be running a\\nfrozen binary (described in Chapter 2) or self-installing system, your setup tasks may\\nbe trivial or null.\\n\\nIs Python Already Present?\\nBefore you do anything else, check whether you already have a recent Python on your\\nmachine. If you are working on Linux, Mac OS X, or some Unix systems, Python is\\nprobably already installed on your computer, though it may be one or two releases\\nbehind the cutting edge. Here’s how to check:\\n\\n• On Windows 7 and earlier, check whether there is a Python entry in the Start but-\\nton’s All Programs menu (at the bottom left of the screen). On Windows 8, look\\nfor Python in a Start screen tile, your Search tool, the “All apps” display on your\\nStart screen, or a File Explorer in desktop mode (more on Windows 8 in an up-\\ncoming sidebar).\\n\\n• On Mac OS X, open a Terminal window (Applications→Utilities→Terminal) and\\ntype python at the prompt. Python, IDLE, and its tkinter GUI toolkit are standard\\ncomponents of this system.\\n\\n1421\\n\\n\\x0c• On Linux and Unix, type python at a shell prompt (a.k.a. terminal window), and\\nsee what happens. Alternatively, try searching for “python” in the usual places\\n—/usr/bin, /usr/local/bin, etc. As on Macs, Python is a standard part of Linux sys-\\ntems.\\n\\nIf you find a Python, make sure it’s a recent version. Although any recent Python will\\ndo for most of this text, this edition focuses on Python 3.3 and 2.7 specifically, so you\\nmay want to install one of these to run some of the examples in this book.\\nSpeaking of versions, per the preface, I recommend starting out with Python 3.3 or later\\nif you’re learning Python anew and don’t need to deal with existing 2.X code; otherwise,\\nyou should generally use Python 2.7. Some popular Python-based systems still use older\\nreleases, though (2.6 and even 2.5 are still widespread), so if you’re working with ex-\\nisting systems be sure to use a version relevant to your needs; the next section describes\\nlocations where you can fetch a variety of Python versions.\\n\\nWhere to Get Python\\nIf there is no Python on your machine, you will need to install one yourself. The good\\nnews is that Python is an open source system that is freely available on the Web and\\nvery easy to install on most platforms.\\nYou can always fetch the latest and greatest standard Python release from http://www\\n.python.org, Python’s official website. Look for the Downloads link on that page, and\\nchoose a release for the platform on which you will be working. You’ll find prebuilt\\nself-installer  files  for  Windows  (run  to  install),  Installer  Disk  Images  for  Mac  OS  X\\n(installed per Mac conventions), the full source code distribution (typically compiled\\non Linux, Unix, or OS X machines to generate an interpreter), and more.\\nAlthough Python is standard on Linux these days, you can also find RPMs for Linux\\non the Web (unpack them with rpm). Python’s website also has links to pages where\\nversions for other platforms are maintained, either at Python.org (http://www.python\\n.org) itself or offsite. For example, you can find third-party Python installers for Goo-\\ngle’s Android, as well as apps to install Python on Apple’s iOS.\\nA Google web search is another great way to find Python installation packages. Among\\nother platforms, you can find Python prebuilt for iPods, Palm handhelds, Nokia cell\\nphones, PlayStation and PSP, Solaris, AS/400, and Windows Mobile, though some of\\nthese are typically a few releases behind the curve.\\nIf you find yourself pining for a Unix environment on a Windows machine, you might\\nalso be interested in installing Cygwin and its version of Python (see http://www.cygwin\\n.com). Cygwin is a GPL-licensed library and toolset that provides full Unix functionality\\non Windows machines, and it includes a prebuilt Python that makes use of all the Unix\\ntools provided.\\n\\n1422 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cYou can also find Python on CD-ROMs supplied with Linux distributions, included\\nwith  some  products  and  computer  systems,  and  enclosed  with  some  other  Python\\nbooks. These tend to lag behind the current release somewhat, but usually not seriously\\nso.\\nIn addition, you can find Python in some free and commercial development bundles.\\nAt this writing, this alternative distributions category includes:\\n\\nActiveState ActivePython\\n\\nA  package  that  combines  Python  with  extensions  for  scientific,  Windows,  and\\nother development needs, including PyWin32 and the PythonWin IDE\\n\\nEnthought Python Distribution\\n\\nA combination of Python and a host of additional libraries and tools oriented to-\\nward scientific computing needs\\n\\nPortable Python\\n\\nA blend of Python and add-on packages configured to run directly from a portable\\ndevice\\nPythonxy\\n\\nA scientific-oriented Python distribution based on Qt and Spyder\\n\\nConceptive Python SDK\\n\\nA bundle targeted at business, desktop, and database applications\\n\\nPyIMSL Studio\\n\\nA commercial distribution for numerical analysis\\n\\nAnaconda Python\\n\\nA distribution for analysis and visualization of large data sets\\n\\nThis set is prone to change, so search the Web for details on all of the above, and others.\\nSome of these are free, some are not, and some have both free and nonfree versions.\\nAll combine the standard Python freely available at http://www.python.org with addi-\\ntional tools, but can simplify install tasks for many.\\nFinally, if you are interested in alternative Python implementations, run a web search\\nto check out Jython (the Python port to the Java environment) and IronPython (Python\\nfor the C#/.NET world), both of which are described in Chapter 2. Installation of these\\nsystems is beyond the scope of this book.\\n\\nInstallation Steps\\nOnce  you’ve  downloaded  Python,  you  need  to  install  it.  Installation  steps  are  very\\nplatform-specific, but here are a few pointers for the major Python platforms (biased\\nin volume toward Windows, only because that is the platform where most Python\\nnewcomers are likely to encounter the language first):\\n\\nInstalling the Python Interpreter\\n\\n| 1423\\n\\n\\x0cWindows\\n\\nFor Windows (including XP, Vista, 7, and 8), Python comes as a self-installer MSI\\nprogram file—simply double-click on its file icon, and answer Yes or Next at every\\nprompt to perform a default install. The default install includes Python’s docu-\\nmentation set and support for tkinter (Tkinter in Python 2.X) GUIs, shelve data-\\nbases, and the IDLE development GUI. Python 3.3 and 2.7 are normally installed\\nin  the  directories  C:\\\\Python33  and  C:\\\\Python27  though  this  can  be  changed  at\\ninstall time.\\nFor convenience, on Windows 7 and earlier Python shows up after the install in\\nthe Start button’s All Programs menu (see ahead for Windows 8 notes). Python’s\\nmenu there has five entries that give quick access to common tasks: starting the\\nIDLE user interface, reading module documentation, starting an interactive ses-\\nsion, reading Python’s standard manuals, and uninstalling. Most of these options\\ninvolve concepts explored in detail elsewhere in this text.\\nWhen  installed  on  Windows,  Python  also  automatically  uses  filename  associa-\\ntions to register itself to be the program that opens Python files when their icons\\nare clicked (a program launch technique described in Chapter 3). It is also possible\\nto build Python from its source code on Windows, but this is not commonly done\\nso we’ll skip the details here (see python.org).\\nThree additional install-related notes for Windows users: first, be sure to see the\\nnext appendix for an introduction to the new Windows launcher shipped with 3.3;\\nit changes some of the rules for installation, file associations, and command lines,\\nbut can be an asset if you have multiple Python versions on your computer (e.g.,\\nboth 2.X and 3.X). Per Appendix B, Python 3.3’s MSI installer also has an option\\nto set your PATH variable to include Python’s directory.\\nSecond, Windows 8 users should see the sidebar in this appendix “Using Python\\non Windows 8” on page 1425. Standard Python installs and works the same on\\nWindows 8, where it runs in desktop mode, but you won’t get the Start button\\nmenu described earlier, and the tablet interface on top is not yet directly supported.\\nFinally, some Windows Vista users may run into install issues related to security\\nfeatures. This seems to have been resolved over time (and Vista is relatively rare\\nthese days), but if running the MSI installer file directly doesn’t work as expected,\\nit’s probably because MSI files are not true executables and do not correctly inherit\\nadministrator permissions (they run per the registry). To fix, run the installer from\\na command line with appropriate permissions: Select Command Prompt, choose\\n“Run as administrator,” cd to the directory where your Python MSI file resides,\\nand  run  the  MSI  installer  with  a  command  line  of  the  form:  msiexec  /i\\npython-2.5.1.msi.\\n\\nLinux\\n\\nFor Linux, if Python or your desired flavor of it is not already present, you can\\nprobably obtain it as one or more RPM files, which you unpack in the usual way\\n(consult the RPM manpage for details). Depending on which RPMs you download,\\n\\n1424 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cthere may be one for Python itself, and another that adds support for tkinter GUIs\\nand the IDLE environment. Because Linux is a Unix-like system, the next para-\\ngraph applies as well.\\n\\nUnix\\n\\nFor Unix systems, Python is usually compiled from its full C source code distri-\\nbution. This usually only requires you to unpack the file and run simple config\\nand make commands; Python configures its own build procedure automatically,\\naccording to the system on which it is being compiled. However, be sure to see the\\npackage’s README file for more details on this process. Because Python is open\\nsource, its source code may be used and distributed free of charge.\\n\\nOn other platforms the installation details can differ widely, but they generally follow\\nthe platform’s normal conventions. For example, installing the “Pippy” port of Python\\nfor PalmOS required a hotsync operation with your PDA, and Python for the Sharp\\nZaurus Linux-based PDA was one or more .ipk files, which you simply ran to install\\n(these likely still work, though finding the devices today may be a logistical challenge!).\\nMore recently, Python can be installed and used on Android and iOS platforms too,\\nbut installation and usage techniques are too platform-specific to cover here. For ad-\\nditional install procedures and the latest on available ports, try both Python’s website\\nand a web search.\\n\\nUsing Python on Windows 8\\n\\nWindows 8 was released as this edition was being written. As mentioned in the preface,\\nthis book was developed on both Windows 7 and 8, but mostly under Windows 7\\nbecause the choice is irrelevant to almost everything in this book—both Python 2.X\\nand 3.X presently work only in desktop mode on Windows 8, but install and run there\\nthe same as in Windows 7, Vista, XP, and others. Once you navigate past the tablet-\\nlike layer at the top, usage is almost entirely as before.\\n\\nThe only notable exception to this is Windows 8’s lack of a Start button menu in desktop\\nmode. You don’t get the nice menu of Python options automatically, though you can\\nsimulate it manually. Although this story is prone to change (and you should take this\\nsidebar as an early report), here are a few Windows 8 usage notes.\\n\\nAt this writing, the standard Python Windows MSI installer program installs Python\\non Windows 8 correctly, and exactly as in the past: you get the same filename associ-\\nations for icon clicks, access from command lines, and so on. The installer also creates\\na Start screen button on Windows 8, but Python itself runs in Windows 8’s desktop\\nmode, which is essentially the same as Windows 7 without a Start button menu. For\\nexample,  the  Windows  8  Start  screen  button  created  by  the  Python  install  simply\\nswitches control to desktop mode to open a Python interactive shell.\\n\\nThe upside to this is that all existing Python software works on Windows 8’s desktop\\njust as before. One downside is that you’ll need to create shortcuts for the user-friendly\\nStart button menu items created automatically on former Windows versions. This in-\\n\\nInstalling the Python Interpreter\\n\\n| 1425\\n\\n\\x0ccludes the former menu’s links to the IDLE GUI, PyDoc, Python’s command-line in-\\nterface, and Python’s manuals set.\\n\\nThis isn’t a showstopper—you can emulate the former Start button menu’s items with\\neither tiles on the Start screen or shortcuts on the desktop taskbar. To do so, you might\\nlook up these tools in a variety of ways:\\n\\n• By navigating to their corresponding filename in a File Explorer, opened by right-\\n\\nclicking the screen’s lower-left corner.\\n\\n• By searching for their name in the Search “charm,” opened by pulling down the\\n\\nscreen’s top-right corner.\\n\\n• By finding their entry after right-clicking on the Start screen to open the All apps\\n\\ndisplay, which is reminiscent of the former Start button menus.\\n\\n• By locating their tiles on your Start screen, if they have any.\\n\\nFor example, you can locate IDLE by navigating to the file idle.py in C:\\\\Python33\\\\Lib,\\nby searching on “idle,” by finding IDLE in “All apps,” or by clicking a Start screen tile\\nif one exists. You can find Python itself in the same ways (and probably others). This\\nisn’t quite as nice as the original Start button menus out of the box, but it suffices.\\n\\nProbably the bigger potential downside on Windows 8 is that while Python runs fine in\\ndesktop mode, it doesn’t yet have an official port to run as a Start screen style “app.”\\nThat is, standard Python does not yet run programs in the WinRT (formerly known as\\nMetro) environment—the tile-based media consumption layer that appears first when\\nyou start Windows 8, and before you can click your way to the desktop. This may be\\na temporary state, though, as a number of options either already exist or are being\\nactively explored.\\n\\nOn one front, it’s not impossible that Python’s installer may be enhanced for Windows\\n8’s nondesktop mode. There has already been work on porting Python to run as a Start\\nscreen “app,” though this may appear as a separate installer package due to differences\\nin  the  underlying  libraries  (in  short,  WinRT  runs  programs  in  a  classic  “sandbox”\\nmodel, with a restricted subset of the libraries available normally).\\n\\nOn other fronts, the C#/.NET-based IronPython system may offer additional Windows\\n8 “app” development options, and some of Python’s major GUI toolkits such as tkinter,\\nwxPython, and PyQt could eventually provide portability to the Windows 8 “apps”\\nenvironment as well. The Qt library underlying the latter of these seems to have already\\nshowed some progress in this department.\\n\\nFor now, existing Python software runs fine in Windows 8’s desktop mode unchanged.\\nDeveloping or running Python code in the Start screen “apps” environment will likely\\nrequire special handling and platform-specific APIs not unlike those required to run\\nPython on other tablet- and phone-oriented platforms based on Google’s Android and\\nApple’s iOS (iPhone and iPad) operating systems.\\n\\nAlso note that much of this sidebar applies to Window 8, but not Windows RT. The\\nlatter does not run third-party desktop mode applications directly, and may need to\\nawait a sanctioned Python installer that supports the WinRT “app” API in general.\\n\\n1426 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cThen again, the Windows 8 story remains to be told. Be sure to watch for developments\\nin both Windows and Python’s installer for it. For now, a simple tile click or Windows-\\nkey press to hop into desktop mode will allow most Python programmers on Windows\\nto safely ignore the tablet-like interface on top—at least until “apps” trounce “pro-\\ngrams” altogether.1\\n\\nConfiguring Python\\nAfter you’ve installed Python, you may want to configure some system settings that\\nimpact the way Python runs your code. (If you are just getting started with the language,\\nyou can probably skip this section completely; there is usually no need to specify any\\nsystem settings for basic programs.)\\nGenerally speaking, parts of the Python interpreter’s behavior can be configured with\\nenvironment variable settings and command-line options. In this section, we’ll take a\\nbrief look at both, but be sure to see other documentation sources for more details on\\nthe topics we introduce here.\\n\\nPython Environment Variables\\nEnvironment variables—known to some as shell variables, or DOS variables—are sys-\\ntem-wide settings that live outside Python and thus can be used to customize the in-\\nterpreter’s behavior each time it is run on a given computer. Python recognizes a handful\\nof environment variable settings, but only a few are used often enough to warrant ex-\\nplanation here. Table A-1 summarizes the main Python-related environment variable\\nsettings (you’ll find information on others in Python reference resources).\\n\\nTable A-1. Important environment variables\\n\\nVariable\\nPATH (or path)\\nPYTHONPATH\\n\\nPYTHONSTARTUP\\nTCL_LIBRARY, TK_LIBRARY\\nPY_PYTHON, PY_PYTHON3, PY_PYTHON2\\n\\nRole\\nSystem shell search path (for finding “python”)\\nPython module search path (for imports)\\nPath to Python interactive startup file\\nGUI extension variables (tkinter)\\nWindows launcher defaults (see Appendix B)\\n\\nThese variables are straightforward to use, but here are a few pointers:\\n\\n1. Lest that seem too sarcastic, I should note that Windows 8.1 may address some launch screen and\\nStart button (if not menu) concerns per late-breaking rumors, and this edition\\'s new Windows 8\\nsidebar replaces one in prior editions that discussed a Windows Vista issue. Any similarities you might\\ndeduce from that are officially coincidental.\\n\\nConfiguring Python | 1427\\n\\n\\x0cPATH\\n\\nThe PATH setting lists a set of directories that the operating system searches for\\nexecutable programs, when they are invoked without a full directory path. It should\\nnormally  include  the  directory  where  your  Python  interpreter  lives  (the  python\\nprogram on Unix, or the python.exe file on Windows).\\nYou don’t need to set this variable at all if you are willing to work in the directory\\nwhere Python resides, or type the full path to Python in command lines. On Win-\\ndows, for instance, the PATH is irrelevant if you run a cd C:\\\\Python33 before running\\nany code (to change to the directory where Python lives—though you shouldn’t\\ngenerally  store  your  own  code  in  this  directory  per  Chapter  3),  or  always  type\\nC:\\\\Python33\\\\python instead of just python (giving a full path).\\nAlso note that PATH settings are mostly for launching programs from command\\nlines; they are usually irrelevant when launching via icon clicks and IDEs—the\\nformer uses filename associations, and the latter uses built-in mechanisms, and\\ndoesn’t generally require this configuration step. See also Appendix B for details\\non 3.3’s automatic PATH setting option at install time.\\n\\nPYTHONPATH\\n\\nThe PYTHONPATH setting serves a role similar to PATH: the Python interpreter consults\\nthe PYTHONPATH variable to locate module files when you import them in a program.\\nIf used, this variable is set to a platform-dependent list of directory names, sepa-\\nrated by colons on Unix and semicolons on Windows. This list normally includes\\njust  your  own  source  code  directories.  Its  content  is  merged  into  the  sys.path\\nmodule import search path, along with the script’s container directory, any .pth\\npath file settings, and standard library directories.\\nYou don’t need to set this variable unless you will be performing cross-directory\\nimports—because Python always searches the home directory of the program’s top-\\nlevel file automatically, this setting is required only if a module needs to import\\nanother module that lives in a different directory. See also the discussion of .pth\\npath files later in this appendix for an alternative to PYTHONPATH. For more on the\\nmodule search path, refer to Chapter 22.\\n\\nPYTHONSTARTUP\\n\\nIf PYTHONSTARTUP is set to the pathname of a file of Python code, Python executes\\nthe  file’s  code  automatically  whenever  you  start  the  interactive  interpreter,  as\\nthough you had typed it at the interactive command line. This is a rarely used but\\nhandy way to make sure you always load certain utilities when working interac-\\ntively; it saves an import each time you start a Python session.\\n\\ntkinter settings\\n\\nIf you wish to use the tkinter GUI toolkit (named Tkinter in 2.X), you might have\\nto set the two GUI variables in the last line of Table A-1 to the names of the source\\nlibrary directories of the Tcl and Tk systems (much like PYTHONPATH). However,\\nthese settings are not required on Windows systems (where  tkinter support is\\ninstalled alongside Python), and are usually not required on Mac OS X and Linux\\n\\n1428 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0csystems, unless the underlying Tcl and Tk libraries are either invalid or reside in\\nnonstandard directories (see python.org’s Download page for more details).\\n\\nPY_PYTHON, PY_PYTHON3, PY_PYTHON2\\n\\nThese settings are used to specify default Pythons when you are using the new (at\\nthis writing) Windows launcher that ships with Python 3.3 and is available sepa-\\nrately for other versions. Since we’ll be exploring the launcher in Appendix B, I’ll\\npostpone further details here.\\n\\nNote that because these environment settings are external to Python itself, when you\\nset them is usually irrelevant: this can be done before or after Python is installed, as\\nlong as they are set the way you require before Python is actually run—be sure to restart\\nyour Python IDEs and interactive sessions after making such changes if you want them\\nto apply.\\n\\ntkinter and IDLE GUIs on Linux and Macs\\n\\nThe  IDLE  interface  described  in  Chapter  3  is  a  Python  tkinter  GUI  program.  The\\ntkinter module (named Tkinter in 2.X) is a GUI toolkit that is automatically installed\\nwith standard Python on Windows, and is an inherent part of Mac OS X and most\\nLinux installations.\\n\\nOn some Linux systems, though, the underlying GUI library may not be a standard\\ninstalled component. To add GUI support to your Python on Linux if needed, try run-\\nning a command line of the form yum tkinter to automatically install tkinter’s under-\\nlying libraries. This should work on Linux distributions (and some other systems) on\\nwhich the yum installation program is available; for others, see your platform’s instal-\\nlation documentation.\\n\\nAs also discussed in Chapter 3, on Mac OS X IDLE probably lives in the MacPython\\n(or Python N.M) folder of your Applications folder (along with PythonLauncher, used\\nfor starting programs with clicks in Finder), but be sure to see the Download page at\\npython.org if IDLE has problems; you may need to install an update on some OS X\\nversions (see Chapter 3).\\n\\nHow to Set Configuration Options\\nThe way to set Python-related environment variables, and what to set them to, depends\\non  the  type  of  computer  you’re  working  on.  And  again,  remember  that  you  won’t\\nnecessarily have to set these at all right away; especially if you’re working in IDLE\\n(described in Chapter 3) and save all your files in the same directory, configuration is\\nprobably not required up front.\\nBut suppose, for illustration, that you have generally useful module files in directories\\ncalled utilities and package1 somewhere on your machine, and you want to be able to\\nimport these modules from files located in other directories. That is, to load a file called\\n\\nConfiguring Python | 1429\\n\\n\\x0cspam.py in either the utilities or package1 directories, you want to be able to say this in\\nanother file in another directory:\\n\\nimport spam\\n\\nTo make this work, you’ll have to configure your module search path one way or an-\\nother to include the directory containing spam.py. Here are a few tips on this process\\nusing PYTHONPATH as an example; do the same for other settings like PATH as needed\\n(though 3.3 can set PATH automatically: see Appendix B).\\n\\nUnix/Linux shell variables\\nOn Unix systems, the way to set environment variables depends on the shell you use.\\nUnder the csh shell, you might add a line like the following in your .cshrc or .login file\\nto set the Python module search path:\\n\\nsetenv PYTHONPATH /usr/home/pycode/utilities:/usr/lib/pycode/package1\\n\\nThis tells Python to look for imported modules in two user-defined directories. Alter-\\nnatively, if you’re using the ksh shell, the setting might instead appear in your .kshrc\\nfile and look like this:\\n\\nexport PYTHONPATH=\"/usr/home/pycode/utilities:/usr/lib/pycode/package1\"\\n\\nOther shells may use different (but analogous) syntax.\\n\\nDOS variables (and older Windows)\\nIf you are using MS-DOS or some now fairly old flavors of Windows, you may need to\\nadd an environment variable configuration command to your C:\\\\autoexec.bat file, and\\nreboot your machine for the changes to take effect. The configuration command on\\nsuch machines has a syntax unique to DOS:\\n\\nset PYTHONPATH=c:\\\\pycode\\\\utilities;d:\\\\pycode\\\\package1\\n\\nYou can type such a command in a DOS console window, too, but the setting will then\\nbe active only for that one console window. Changing your .bat file makes the change\\npermanent and global to all programs, though this technique has been superseded in\\nrecent years by that described in the next section.\\n\\nWindows environment variable GUI\\nOn all recent versions of Windows (including XP, Vista, 7, and 8), you can instead set\\nPYTHONPATH and other variables via the system environment variable GUI without having\\nto edit files, type command lines, or reboot. Select the Control Panel (in your Start\\nbutton  in  Windows  7  and  earlier,  and  in  the  desktop  mode’s  Settings  “charm”  on\\nWindows 8), choose the System icon, pick the Advanced settings tab or link, and click\\nthe Environment Variables button at the bottom to edit or add new variables (PYTHON\\nPATH is usually a new user variable). Use the same variable name and values syntax\\n\\n1430 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cshown in the DOS set command in the preceding section. On Vista you may have to\\nverify operations along the way.\\nYou do not need to reboot your machine after this, but be sure to restart Python if it’s\\nopen so that it picks up your changes—it configures its import search path at startup\\ntime only. If you’re working in a Windows Command Prompt window, you’ll probably\\nneed to restart that to pick up your changes as well.\\n\\nWindows registry\\nIf you are an experienced Windows user, you may also be able to configure the module\\nsearch path by using the Windows Registry Editor. To open this tool, type regedit in\\nthe Start→Run... interface on some Windows, in the search field at the bottom of the\\nStart button display on Windows 7, and in a Command Prompt window on Windows\\n8 and others (among other routes). Assuming the typical registry tool is available on\\nyour machine, you can then navigate to Python’s entries and make your changes. This\\nis  a  delicate  and  error-prone  procedure,  though,  so  unless  you’re  familiar  with  the\\nregistry, I suggest using other options (indeed, this is akin to performing brain surgery\\non your computer, so be careful!).\\n\\nPath files\\nFinally, if you choose to extend the module search path with a .pth path file instead of\\nthe PYTHONPATH variable, you might instead code a text file that looks like the following\\non Windows (e.g., file C:\\\\Python33\\\\mypath.pth):\\n\\nc:\\\\pycode\\\\utilities\\nd:\\\\pycode\\\\package1\\n\\nIts contents will differ per platform, and its container directory may differ per both\\nplatform and Python release. Python locates this file automatically when it starts up.\\nDirectory names in path files may be absolute, or relative to the directory containing\\nthe path file; multiple .pth files can be used (all their directories are added), and .pth\\nfiles may appear in various automatically checked directories that are platform- and\\nversion-specific. In general, a Python release numbered Python N.M typically looks for\\npath files in C:\\\\PythonNM and C:\\\\PythonNM\\\\Lib\\\\site-packages on Windows, and in /\\nusr/local/lib/pythonN.M/site-packages and /usr/local/lib/site-python on Unix and Linux.\\nSee Chapter 22 for more on using path files to configure the sys.path import search\\npath.\\nBecause environment settings are often optional, and because this isn’t a book on op-\\nerating system shells, I’ll defer to other sources for further details. Consult your system\\nshell’s manpages or other documentation for more information, and if you have trouble\\nfiguring out what your settings should be, ask your system administrator or another\\nlocal expert for help.\\n\\nConfiguring Python | 1431\\n\\n\\x0cPython Command-Line Arguments\\nWhen you start Python from a system command line (a.k.a. a shell prompt, or Com-\\nmand Prompt window), you can pass in a variety of option flags to control how Python\\nruns your code. Unlike the system-wide environment variables of the prior section,\\ncommand-line arguments can be different each time you run a script. The complete\\nform of a Python command-line invocation in 3.3 looks like this (2.7 is roughly the\\nsame, with a few differences described ahead):\\n\\npython [-bBdEhiOqsSuvVWxX] [-c command | -m module-name | script | - ] [args]\\n\\nThe rest of this section briefly demonstrates some of Python’s most commonly used\\narguments. For more details on available command-line options not covered here, see\\nthe Python manuals or reference texts. Or better yet, ask Python itself—run a command\\nline form like this:\\n\\nC:\\\\code> python -h\\n\\nto request Python’s help display, which documents all available command-line options.\\nIf you deal with complex command lines, be sure to also check out the standard library\\nmodules in this domain: the original getop, the newer argparse, and the now-depre-\\ncated (since 3.2) optparse, which support more sophisticated command-line process-\\ning. Also see Python’s library manuals and other references for more on the pdb and\\nprofile modules the following tour deploys.\\n\\nRunning script files with arguments\\nMost command lines make use of only the script and args parts of the last section’s\\nPython command-line format, to run a program’s source file with arguments to be used\\nby the program itself. To illustrate, consider the following script—a text file named\\nshowargs.py, created in directory C:\\\\code or another of your choosing—which prints\\nthe command-line arguments made available to the script as sys.argv, a Python list of\\nPython strings (if you don’t yet know how to create or run Python script files, see the\\nfull coverage in Chapter 2 and Chapter 3; we’re interested only in command-line ar-\\nguments here):\\n\\n# File showargs.py\\nimport sys\\nprint(sys.argv)\\n\\nIn the following command line, both python and showargs.py can also be complete\\ndirectory paths—the former is assumed to be on your PATH here, and the latter is as-\\nsumed to be in the current directory. The three arguments (a b –c) meant for the script\\nshow up in the sys.argv list and can be inspected by your script’s code there; the first\\nitem in sys.argv is always the script file’s name, when it is known:\\n\\nC:\\\\code> python showargs.py a b -c            # Most common: run a script file\\n[\\'showargs.py\\', \\'a\\', \\'b\\', \\'-c\\']\\n\\n1432 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cAs covered elsewhere in this book, Python lists print in square brackets and strings\\ndisplay in quotes.\\n\\nRunning code given in arguments and standard input\\nOther code format specification options allow you to give Python code to be run on\\nthe command line itself (-c), and accept code to run from the standard input stream (a\\n– means read from a pipe or redirected input stream file, terms also defined in full\\nelsewhere in this text):\\n\\nC:\\\\code> python -c \"print(2 ** 100)\"          # Read code from command argument\\n1267650600228229401496703205376\\n\\nC:\\\\code> python -c \"import showargs\"          # Import a file to run its code\\n[\\'-c\\']\\n\\nC:\\\\code> python - < showargs.py a b -c        # Read code from standard input\\n[\\'-\\', \\'a\\', \\'b\\', \\'-c\\']\\n\\nC:\\\\code> python - a b -c < showargs.py        # Same effect as prior line\\n[\\'-\\', \\'a\\', \\'b\\', \\'-c\\']\\n\\nRunning modules on the search path\\nThe –m code specification locates a module on Python’s module search path and then\\nruns it as a top-level script (as module __main__). That is, it looks up a script the same\\nway import operations do, using the directory list normally known as sys.path, which\\nincludes the current directory, PYTHONPATH settings, and standard libraries. Leave off the\\n“.py” suffix here, as the filename is treated as a module.\\n\\nC:\\\\code> python -m showargs a b -c            # Locate/run module as script\\n[\\'c:\\\\\\\\code\\\\\\\\showargs.py\\', \\'a\\', \\'b\\', \\'-c\\']\\n\\nThe  –m  option  also  supports  running  tools,  modules  in  packages  with  and  without\\nrelative import syntax, and modules located in .zip archives. For instance, this switch\\nis commonly used to run the pdb debugger and profile profiler modules from a com-\\nmand line for a script invocation, rather than interactively:\\n\\nC:\\\\code> python                               # Interactve debugger session\\n>>> import pdb\\n>>> pdb.run(\\'import showargs\\')\\n...more omitted: see pdb docs\\n\\nC:\\\\code> python -m pdb showargs.py a b -c     # Debugging a script (c=continue)\\n> C:\\\\code\\\\showargs.py(2)<module>()\\n-> import sys\\n(Pdb) c\\n[\\'showargs.py\\', \\'a\\', \\'b\\', \\'-c\\']\\n...more omitted: q to exit\\n\\nThe profiler runs and times your code; its output can vary per Python, operating system,\\nand computer:\\n\\nConfiguring Python | 1433\\n\\n\\x0cC:\\\\code> python -m profile showargs.py a b -c     # Profiling a script\\n[\\'showargs.py\\', \\'a\\', \\'b\\', \\'-c\\']\\n         9 function calls in 0.016 seconds\\n\\n   Ordered by: standard name\\n\\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\\n        2    0.000    0.000    0.000    0.000 :0(charmap_encode)\\n        1    0.000    0.000    0.000    0.000 :0(exec)\\n...more omitted: see profile docs\\n\\nYou might also use the -m switch to spawn Chapter 3’s IDLE GUI program located in\\nthe standard library from any other directory, and to start the pydoc and timeit tools \\nmodules with command lines as we do in this book in Chapter 15 and Chapter 21 (see\\nthose chapters for more details on the tools launched here):\\n\\nc:\\\\code> python -m idlelib.idle -n           # Run IDLE in package, no subprocess\\n\\nc:\\\\code> python -m pydoc -b                  # Run pydoc and timeit tools modules\\n\\nc:\\\\code> python -m timeit -n 1000 -r 3 -s \"L = [1,2,3,4,5]\" \"M = [x + 1 for x in L]\"\\n\\nOptimized and unbuffered modes\\nImmediately after the “python” and before the designation of code to be run, Python\\naccepts additional arguments that control its own behavior. These arguments are con-\\nsumed by Python itself and are not meant for the script being run. For example, -O runs\\nPython in optimized mode and -u forces standard streams to be unbuffered—with the\\nlatter, any printed text will be finalized immediately, and won’t be delayed in a buffer:\\n\\nC:\\\\code> python -O showargs.py a b -c        # Optimized: make/run \".pyo\" byte code\\n\\nC:\\\\code> python -u showargs.py a b -c        # Unbuffered standard output stream\\n\\nPost-run interactive mode\\nFinally, the –i flag enters interactive mode after running a script—especially useful as\\na debugging tool, because you can print variables’ final values after a successful run to\\nget more details:\\n\\nC:\\\\code> python -i showargs.py a b -c        # Go to interactive mode on script exit\\n[\\'showargs.py\\', \\'a\\', \\'b\\', \\'-c\\']\\n>>> sys                                      # Final value of sys: imported module\\n<module \\'sys\\' (built-in)>\\n>>> ^Z\\n\\nYou can also print variables this way after an exception shuts down your script to see\\nwhat they looked like when the exception occurred, even if not running in debug mode\\n—though you can start the debugger’s postmortem tool here as well (type is the Win-\\ndows file display command; try a cat or other elsewhere):\\n\\nC:\\\\code> type divbad.py\\nX = 0\\n\\n1434 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cprint(1 / X)\\n\\nC:\\\\code> python divbad.py                  # Run the buggy script\\n...error text omitted\\nZeroDivisionError: division by zero\\n\\nC:\\\\code> python -i divbad.py               # Print variable values at error\\n...error text omitted\\nZeroDivisionError: division by zero\\n>>> X\\n0\\n>>> import pdb                             # Start full debugger session now\\n>>> pdb.pm()\\n> C:\\\\code\\\\divbad.py(2)<module>()\\n-> print(1 / X)\\n(Pdb) quit\\n\\nPython 2.X command-line arguments\\nBesides those just mentioned, Python 2.7 supports additional options that promote 3.X\\ncompatibility (−3 to warn about incompatibilities, and –Q to control division operator\\nmodels) and detecting inconsistent tab indentation usage, which is always detected and\\nreported in 3.X (-t; see Chapter 12). Again, you can always ask Python 2.X itself for\\nmore on the subject as needed:\\n\\nC:\\\\code> c:\\\\python27\\\\python -h\\n\\nPython 3.3 Windows Launcher Command Lines\\nTechnically, the preceding section described the arguments you can pass to the Python\\ninterpreter itself—the program usually named python.exe on Windows, and python on\\nLinux (the .exe is normally omitted on Windows). As we’ll see in the next appendix,\\nthe Windows launcher shipped with Python 3.3 augments this story for users of 3.3\\nand  later  or  the  standalone  launcher  package.  It  adds  new  executables  that  accept\\nPython version numbers as arguments in command lines used to start Python and your\\nscripts (file what.py is listed and described in the next appendix, and simply prints the\\nPython version number):\\n\\nC:\\\\code> py what.py                    # Windows launcher command lines\\n3.3.0\\n\\nC:\\\\code> py −2 what.py                 # Version number switch\\n2.7.3\\n\\nC:\\\\code> py −3.3 -i what.py -a -b -c   # Arguments for all 3: py, python, script\\n3.3.0\\n>>> ^Z\\n\\nIn  fact,  as  the  last  run  of  the  preceding  example  shows,  command  lines  using  the\\nlauncher can give arguments for the launcher itself (−3.3), Python itself (-i), and your\\nscript (-a, -b, and -c). The launcher can also parse version numbers out of #! Unix lines\\n\\nConfiguring Python | 1435\\n\\n\\x0cat the top of script files instead. Because the next appendix is devoted to this launcher\\nentirely, though, you’ll have to read on for the rest of this story.\\n\\nFor More Help\\nPython’s standard manual set today includes valuable pointers for usage on various\\nplatforms. The standard manual set is available in your Start button on Windows 7 and\\nearlier after Python is installed (option “Python Manuals”), and online at http://www\\n.python.org. Look for the manual set’s top-level section titled “Using Python” for more\\nplatform-specific pointers and hints, as well as up-to-date cross-platform environment\\nand command-line details.\\nAs always, the Web is your ally, too, especially in a field that often evolves faster than\\nbooks like this can be updated. Given Python’s widespread adoption, chances are good\\nthat answers to any high-level usage questions you may have can be found with a web\\nsearch.\\n\\n1436 | Appendix A:\\u2002Installation and Configuration\\n\\n\\x0cAPPENDIX B\\nThe Python 3.3 Windows Launcher\\n\\nThis appendix describes the new Windows launcher for Python, installed with Python\\n3.3 automatically, and available separately on the Web for use with older versions.\\nThough the new launcher comes with some pitfalls, it provides some much-needed\\ncoherence for program execution when multiple Pythons coexist on the same com-\\nputer.\\nI’ve written this page for programmers using Python on Windows. Though it is plat-\\nform-specific  by  nature,  it’s  targeted  at  both  Python  beginners  (most  of  whom  get\\nstarted on this platform), as well as Python developers who write code to work portably\\nbetween Windows and Unix. As we will see, the new launcher changes the rules on\\nWindows radically enough to impact everyone who uses Python on Windows, or may\\nin the future.\\n\\nThe Unix Legacy\\nTo fully understand the launcher’s protocols, we have to begin with a short history\\nlesson. Unix developers long ago devised a protocol for designating a program to run\\na script’s code. On Unix systems (including Linux and Mac OS X), the first line in a\\nscript’s text file is special if it begins with a two-character sequence:  #!, sometimes\\ncalled a shebang (an arguably silly phrase I promise not to repeat from here on).\\nChapter 3 gives a brief overview of this topic, but here’s another look. In Unix scripts,\\nsuch lines designate a program to run the rest of the script’s contents, by coding it after\\nthe #!—using either the directory path to the desired program itself, or an invocation\\nof the env Unix utility that looks up the target per your PATH setting, the customizable\\nsystem environment variable that lists directories to be searched for executables:\\n\\n#!/usr/local/bin/python\\n...script\\'s code              # Run under this specific program\\n\\n#!/usr/bin/env python\\n...script\\'s code              # Run under \"python\" found on PATH\\n\\n1437\\n\\n\\x0cBy making such a script executable (e.g., via chmod +x script.py), you can run it by\\ngiving just its filename in a command line; the #! line at the top then directs the Unix\\nshell to a program that will run the rest of the file’s code. Depending on the platform’s\\ninstall structure, the python that these #! lines name might be a real executable, or a\\nsymbolic link to a version-specific executable located elsewhere. These lines might also\\nname a more specific executable explicitly, such as python3. Either way, by changing\\n#!  lines,  symbolic  links,  or  PATH  settings,  Unix  developers  can  route  a  script  to  the\\nappropriate installed Python.\\nNone of this applies to Windows itself, of course, where  #! lines have no inherent\\nmeaning. Python itself has historically ignored such lines as comments if present on\\nWindows (“#” starts a comment in the language). Still, the idea of selecting Python\\nexecutables on a per-file basis is a compelling feature in a world where Python 2.X and\\n3.X often coexist on the same machine. Given that many programmers coded #! lines\\nfor portability to Unix anyhow, the idea seemed ripe for emulating.\\n\\nThe Windows Legacy\\nThe install model has been very different on the other side of the fence. In the past (well,\\nin every Python until 3.3), the Windows installer updated the global Windows registry\\nsuch that the latest Python version installed on your computer was the version that\\nopened Python files when they were clicked or run by direct filename in command lines.\\nSome Windows users may know this registry as filename associations, configurable in\\nControl Panel’s Default Programs dialog. You do not need to give files executable priv-\\nileges for this to work, as you do for Unix scripts. In fact, there’s no such concept on\\nWindows—filename associations and commands suffice to launch files as programs.\\nUnder this install model, if you wished to open a file with a different version than the\\nlatest install, you had to run a command line giving the full path to the Python you\\nwanted, or update your filename associations manually to use the desired version. You\\ncould also point generic python command lines to a specific Python by setting or chang-\\ning your PATH setting, but Python didn’t set this for you, and this wouldn’t apply to\\nscripts launched by icon clicks and other contexts.\\nThis reflects the natural order on Windows (when you click on a .doc file, Windows\\nusually opens it in the latest Word installed), and has been the state of things ever since\\nthere was a Python on Windows. It’s less ideal if you have Python scripts that require\\ndifferent versions on the same machine, though—a situation that has become increas-\\ningly common, and perhaps even normal in the dual Python 2.X/3.X era. Running\\nmultiple Pythons on Windows prior to 3.3 can be tedious for developers, and discour-\\naging for newcomers.\\n\\n1438 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0cIntroducing the New Windows Launcher\\nThe new Windows launcher, shipped and installed automatically with Python 3.3 (and\\npresumably later), and available as a standalone package for use with other versions,\\naddresses these deficits in the former install model by providing two new executables:\\n\\n• py.exe for console programs\\n• pyw.exe for nonconsole (typically GUI) programs\\n\\nThese two programs are registered to open .py and .pyw files, respectively, via Windows\\nfilename associations. Like Python’s original python.exe main program (which they do\\nnot deprecate but can largely subsume), these new executables are also registered to\\nopen byte code files launched directly. Amongst their weapons, these two new execut-\\nables:\\n\\n• Automatically open Python source and byte-code files launched by icon clicks or\\n\\nfilename commands, via Windows associations\\n\\n• Are normally installed on your system search path and do not require a directory\\n\\npath or PATH settings when used as command lines\\n\\n• Allow Python version numbers to be passed in easily as command-line arguments,\\n\\nwhen starting both scripts and interactive sessions\\n\\n• Attempt to parse Unix-style #! comment lines at the top of scripts to determine\\n\\nwhich Python version should be used to run a file’s code\\n\\nThe net effect is that under the new launcher, when multiple Pythons are installed on\\nWindows, you are no longer limited to either the latest version installed or explicit/full\\ncommand lines. Instead, you can now select versions explicitly on both a per-file and\\nper-command basis, and specify versions in either partial or full form in both contexts.\\nHere’s how this works:\\n\\n1. To select versions per file, use Unix-style top-of-script comments like these:\\n\\n#!python2\\n#!/usr/bin/python2.7\\n#!/usr/bin/env python3\\n\\n2. To select versions per command, use command lines of the following forms:\\n\\npy −2 m.py\\npy −2.7 m.py\\npy −3 m.py\\n\\nFor example, the first of these techniques can serve as a sort of directive to declare which\\nPython version the script depends upon, and will be applied by the launcher whenever\\nthe  script  is  run  by  command  line  or  icon  click  (these  are  variants  of  a  file  named\\nscript.py):\\n\\nIntroducing the New Windows Launcher\\n\\n| 1439\\n\\n\\x0c#!python3\\n...\\n...a 3.X script              # Runs under latest 3.X installed\\n...\\n\\n#!python2\\n...\\n...a 2.X script              # Runs under latest 2.X installed\\n...\\n\\n#!python2.6\\n...\\n...a 2.6 script              # Runs under 2.6 (only)\\n...\\n\\nOn Windows, command lines are typed in a Command Prompt window, designated\\nby its C:\\\\code> prompt in this appendix. The first of the following is the same as both\\nthe second and an icon click, because of filename associations:\\n\\nC:\\\\code> script.py           # Run per file\\'s #! line if present, else per default\\nC:\\\\code> py script.py        # Ditto, but py.exe is run explicitly\\n\\nAlternatively,  the  second  technique  just  listed  can  select  versions  with  argument\\nswitches in command lines instead:\\n\\nC:\\\\code> py −3 script.py     # Runs under latest 3.X\\nC:\\\\code> py −2 script.py     # Runs under latest 2.X\\nC:\\\\code> py −2.6 script.py   # Runs under 2.6 (only)\\n\\nThis works both when launching scripts and starting the interactive interpreter (when\\nno script is named):\\n\\nC:\\\\code> py −3               # Starts latest 3.X, interactive\\nC:\\\\code> py −2               # Starts latest 2.X, interactive\\nC:\\\\code> py −3.1             # Starts 3.1 (only), interactive\\nC:\\\\code> py                  # Starts default Python (initially 2.X: see ahead)\\n\\nIf there are both #! lines in the file and a version number switch in the command line\\nused to start it, the command line’s version overrides that in the file’s directive:\\n\\n#! python3.2\\n...\\n...a 3.X script\\n...\\n\\nC\\\\code> py script.py         # Runs under 3.2, per file directive\\nC\\\\code> py −3.1 script.py    # Runs under 3.1, even if 3.2 present\\n\\nThe launcher also applies heuristics to select a specific Python version when it is missing\\nor only partly described. For instance, the latest 2.X is run when only a 2 is specified,\\nand a 2.X is preferred for files that do not name a version in a #! line when launched\\nby icon click or generic command lines (e.g., py m.py, m.py), unless you configure the\\ndefault to use 3.X instead by setting PY_PYTHON or a configuration file entry (more on\\nthis ahead).\\n\\n1440 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0cEspecially in the current dual 2.X/3.X Python world, explicit version selection seems a\\nuseful addition for Windows, where many (and probably most) newcomers get their\\nfirst exposure to the language. Although it is not without potential pitfalls—including\\nfailures on unrecognized Unix #! lines and a puzzling 2.X default—it does allow for a\\nmore graceful coexistence of 2.X and 3.X files on the same machine, and provides a\\nrational approach to version control in command lines.\\nFor the complete story on the Windows launcher, including more advanced features\\nand use cases I’ll either condense or largely omit here, see Python’s release notes and\\ntry a web search to find the PEP (the proposal document). Among other things, the\\nlauncher also allows selecting between 32- and 64-bit installs, specifying defaults in\\nconfiguration files, and defining custom #! command string expansion.\\n\\nA Windows Launcher Tutorial\\nSome readers familiar with Unix scripting may find the prior section enough to get\\nstarted. For others, this section provides additional context in the form of a tutorial,\\nwhich gives concrete examples of the launcher in action for you to trace through. This\\nsection also discloses additional launcher details along the way, though, so even well-\\nseasoned Unix veterans may benefit from a quick scan here before FTPing all their\\nPython scripts to the local Windows box.\\nTo get started, we’ll be using the following simple script, what.py, which can be run\\nunder both 2.X and 3.X to echo the version number of the Python that runs its code.\\nIt uses sys.version—a string whose first component after splitting on whitespace is\\nPython’s version number:\\n\\n#!python3\\nimport sys\\nprint(sys.version.split()[0])     # First part of string\\n\\nIf you want to work along, type this script’s code in your favorite text file editor, open\\na Command Prompt window for typing the command lines we’ll be running, and cd to\\nthe directory where you’ve save the script (C:\\\\code is where I’m working, but feel free\\nto save this wherever you wish, and see Chapter 3 for more Windows usage pointers).\\nThis script’s first-line comment serves to designate the required Python version; it must\\nbegin with #! per Unix convention, and allows for a space before the python3 or not.\\nOn my machine I currently have Pythons 2.7, 3,1, 3.2, and 3.3 all installed; let’s watch\\nwhich version is invoked as the script’s first line is modified in the following sections,\\nexploring file directives, command lines, and defaults along the way.\\n\\nStep 1: Using Version Directives in Files\\nAs this script is coded, when run by icon click or command line, the first line directs\\nthe registered py.exe launcher to run using the latest 3.X installed:\\n\\nA Windows Launcher Tutorial\\n\\n| 1441\\n\\n\\x0c#! python3\\nimport sys\\nprint(sys.version.split()[0])\\n\\nC:\\\\code> what.py                  # Run per file directive\\n3.3.0\\n\\nC:\\\\code> py what.py               # Ditto: latest 3.X\\n3.3.0\\n\\nAgain, the space after #! is optional; I added a space to demonstrate the point here.\\nNote that the first what.py command here is equivalent to both an icon click and a full\\npy what.py, because the py.exe program is registered to open .py files automatically in\\nthe Windows filename associations registry when the launcher is installed.\\nAlso note that when launcher documentation (including this appendix) talks about the\\nlatest  version,  it  means  the  highest-numbered  version.  That  is,  it  refers  to  the  latest\\nreleased, not the latest installed on your computer (e.g., if you install 3.1 after 3.3, #!\\npython3 selects the latter). The launcher cycles through the Pythons on your computer\\nto find the highest-numbered version that matches your specification or defaults; this\\ndiffers from the former last-installed-wins model.\\nNow, changing the first line name to python2 triggers the latest (really, highest-num-\\nbered) 2.X installed instead. Here’s this change at work; I’ll omit the last two lines of\\nour script from this point on because they won’t be altered:\\n\\n#! python2\\n...rest of script unchanged\\n\\nC:\\\\code> what.py                  # Run with latest 2.X per #!\\n2.7.3\\n\\nAnd you can request a more specific version if needed—for example, if you don’t want\\nthe latest in a Python line:\\n\\n#! python3.1\\n...\\n\\nC:\\\\code> what.py                  # Run with 3.1 per #!\\n3.1.4\\n\\nThis is true even if the requested version is not installed—which is treated as an error\\ncase by the launcher:\\n\\n#! python2.6\\n...\\n\\nC:\\\\code> what.py\\nRequested Python version (2.6) is not installed\\n\\nUnrecognized Unix #! lines are also treated as errors, unless you give a version number\\nas a command-line switch to compensate, as the next section describes in more detail\\n(and as the section on launcher issues will revisit as a pitfall):\\n\\n1442 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0c#!/bin/python\\n...\\n\\nC:\\\\code> what.py\\nUnable to create process using \\'/bin/python \"C:\\\\code\\\\what.py\" \\'\\n\\nC:\\\\code> py what.py\\nUnable to create process using \\'/bin/python what.py\\'\\n\\nC:\\\\code> py −3 what.py\\n3.3.0\\n\\nTechnically, the launcher recognizes Unix-style #! lines at the top of script files that\\nfollow one of the following four patterns:\\n\\n#!/usr/bin/env python*\\n#!/usr/bin/python*\\n#!/usr/local/bin/python*\\n#!python*\\n\\nAny #! line that does not take one of these recognized and parseable forms is assumed\\nto be a fully specified command line to start a process to run the file, which is passed\\nto Windows as is, and generates the error message we saw previously if it is not a valid\\nWindows command. (The launcher also supports “customized” command expansions\\nvia its configuration files, which are attempted before passing unrecognized commands\\non to Windows, but we’ll gloss over these here.)\\nIn recognizable #! lines, directory paths are coded per Unix convention, for portability\\nto that platform. The * part at the end of the four preceding recognized patterns denotes\\nan optional Python version number, in one of three forms:\\n\\nPartial (e.g., python3)\\n\\nTo run the version installed with the highest minor release number among those\\nwith the major release number given\\n\\nFull (e.g., python3.1)\\n\\nTo run that specific version only, optionally suffixed by −32 to prefer a 32-bit ver-\\nsion (e.g., python3.1-32)\\n\\nOmitted (e.g., python)\\n\\nTo run the launcher’s default version, which is 2 unless changed (e.g., by setting\\nthe PY_PYTHON environment variable to 3), another pitfall described ahead\\n\\nFiles with no #! line at all behave the same as those that name just a generic python—\\nthe aforementioned omitted case—and are influenced by PY_PYTHON default settings.\\nThe first case, partials, may also be affected by version-specific environment settings\\n(e.g., set PY_PYTHON3 to 3.1 to select 3.1 for python3, and set PY_PYTHON2 to 2.6 to pick\\n2.6 for python2). We\\'ll revisit defaults later in this tutorial.\\nFirst, though, note that anything after the * part in a #! line’s format is assumed to be\\ncommand-line arguments to Python itself (i.e., program python.exe), unless you also\\n\\nA Windows Launcher Tutorial\\n\\n| 1443\\n\\n\\x0cgive arguments in a py command line that are deemed to supersede #! line arguments\\nby the launcher:\\n\\n#!python3 [any python.exe arguments go here]\\n...\\n\\nThese include all the Python command-line arguments we met in Appendix A. But this\\nleads us to launcher command lines in general, and will suffice as a natural segue to\\nthe next section.\\n\\nStep 2: Using Command-Line Version Switches\\nAs mentioned, version switches on command lines can be used to select a Python ver-\\nsion if one isn’t present in the file. You run a py or pyw command line to pass them a\\nswitch this way, instead of relying on filename associations in the registry, and instead\\nof (or in addition to) giving versions in #! lines in files. In the following, we modify our\\nscript so that it has no #! directive:\\n\\n# not a launcher directive\\n...\\n\\nC:\\\\code> py −3 what.py           # Run per command-line switch\\n3.3.0\\n\\nC:\\\\code> py −2 what.py           # Ditto: latest 2.X installed\\n2.7.3\\n\\nC:\\\\code> py −3.2 what.py         # Ditto: 3.2 specifically (and only)\\n3.2.3\\n\\nC:\\\\code> py what.py              # Run per launcher\\'s default (ahead)\\n2.7.3\\n\\nBut command-line switches also take precedence over a version designation in a file’s\\ndirective:\\n\\n#! python3.1\\n...\\n\\nC:\\\\code> what.py                 # Run per file directive\\n3.1.4\\n\\nC:\\\\code> py what.py              # Ditto\\n3.1.4\\n\\nC:\\\\code> py −3.2 what.py         # Switches override directives\\n3.2.3\\n\\nC:\\\\code> py −2 what.py           # Ditto\\n2.7.3\\n\\nFormally, the launcher accepts the following command-line argument types (which\\nexactly mirror the * part at the end of a file’s #! line described in the prior section):\\n\\n1444 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0c−2         Launch the latest Python 2.X version\\n-3         Launch the latest Python 3.X version\\n-X.Y       Launch the specified Python version (X is 2 or 3)\\n-X.Y−32    Launch the specified 32-bit Python version\\n\\nAnd the launcher’s command lines take the following general form:\\n\\npy [py.exe arg] [python.exe args] script.py [script.py args]\\n\\nAnything following the launcher’s own argument (if present) is treated as though it\\nwere passed to the  python.exe program—typically, this includes any arguments for\\nPython itself, followed by the script filename, followed by any arguments meant for the\\nscript.\\nThe usual -m mod, -c cmd, and - program specification forms work in a py command\\nline too, as do all the other Python command-line arguments covered in Appendix A.\\nAs mentioned earlier, arguments to python.exe can also appear at the end of the #!\\ndirective line in a file, if used, though arguments in py command lines override them.\\nTo see how this works, let’s write a new script that extends the prior to display com-\\nmand-line arguments; sys.argv is the script’s own arguments, and I’m using the Python\\n(python.exe) -i switch, which directs it to the interactive prompt (>>>) after a script\\nruns:\\n\\n# args.py, show my arguments too\\nimport sys\\nprint(sys.version.split()[0])\\nprint(sys.argv)\\n\\nC:\\\\code> py −3 -i args.py -a 1 -b -c     # −3: py, -i: python, rest: script\\n3.3.0\\n[\\'args.py\\', \\'-a\\', \\'1\\', \\'-b\\', \\'-c\\']\\n>>> ^Z\\n\\nC:\\\\code> py -i args.py -a 1 -b -c        # Args to python, script\\n2.7.3\\n[\\'args.py\\', \\'-a\\', \\'1\\', \\'-b\\', \\'-c\\']\\n>>> ^Z\\n\\nC:\\\\code> py −3 -c print(99)              # −3 to py, rest to python: \"-c cmd\"\\n99\\n\\nC:\\\\code> py −2 -c \"print 99\"\\n99\\n\\nNotice how the first two launches run the default Python unless a version is given in\\nthe command line, because no #! line appears in the script itself. Somewhat coinci-\\ndentally, that leads us to the last topic of this tutorial.\\n\\nStep 3: Using and Changing Defaults\\nAs also mentioned, the launcher defaults to 2.X for a generic python in a #! directive\\nwith no specific version number. This is true whether this generic form appears in a\\n\\nA Windows Launcher Tutorial\\n\\n| 1445\\n\\n\\x0cfull Unix path (e.g.,  #!/usr/bin/python) or not  (#!python). Here’s the latter case in\\naction, coded in our original what.py script:\\n\\n#!python\\n...                           # Same as #!/usr/bin/python\\n\\nC:\\\\code> what.py              # Run per launcher default\\n2.7.3\\n\\nThe default is also applied when no directive is present at all—perhaps the most com-\\nmon case for code written to be used on Windows primarily or exclusively:\\n\\n# not a launcher directive\\n...\\n\\nC:\\\\code> what.py              # Also run per default\\n2.7.3\\n\\nC:\\\\code> py what.py           # Ditto\\n2.7.3\\n\\nBut you can set the launcher’s default to 3.X with initialization file or environment\\nvariable settings, which will apply to both files run from command lines and by icon\\nclicks via their name’s association with py.exe or pyw.exe in the Windows registry:\\n\\n# not a launcher directive\\n...\\n\\nC:\\\\code> what.py               # Run per default\\n2.7.3\\n\\nC:\\\\code> set PY_PYTHON=3       # Or via Control Panel/System\\nC:\\\\code> what.py               # Run per changed default\\n3.3.0\\n\\nAs suggested earlier, for more fine-grained control you can also set version-specific\\nenvironment variables to direct partial selections to a specific release, instead of falling\\nback on the installed release with the highest minor number:\\n\\n#!python3\\n...\\n\\nC:\\\\code> py what.py             # Runs \"latest\" 3.X\\n3.3.0\\n\\nC:\\\\code> set PY_PYTHON3=3.1     # Use PY_PYTHON2 for 2.X\\nC:\\\\code> py what.py             # Override highest-minor choice\\n3.1.4\\n\\nThe set used in these interactions applies to its Command Prompt window only; mak-\\ning such settings in the Control Panel’s System window will make them apply globally\\nacross your machine (see Appendix A for help with these settings). You may or may\\nnot want to set defaults this way depending on the majority of the Python code you’ll\\n\\n1446 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0cbe  running.  Many  Python  2.X  users  can  probably  rely  on  defaults  unchanged,  and\\noverride them in #! lines or py command lines as needed.\\nHowever, the setting used for directive-less files, PY_PYTHON, seems fairly crucial. Most\\nprogrammers who have used Python on Windows in the past will probably expect 3.X\\nto be the default after installing 3.3, especially given that the launcher is installed by\\n3.3 in the first place—a seeming paradox, which leads us to the next section.\\n\\nPitfalls of the New Windows Launcher\\nThough the new Windows launcher in 3.3 is a nice addition, like much in 3.X it may\\nhave been nicer had it appeared years ago. Unfortunately, it comes with some backward\\nincompatibilities, which may be an inevitable byproduct of today’s multiversion Python\\nworld, but which may also break some existing programs. This includes examples in\\nbooks I’ve written, and probably many others. While porting code to 3.3, I’ve come\\nacross three launcher issues worth noting:\\n\\n• Unrecognized Unix !# lines now make scripts fail on Windows.\\n• The launcher defaults to using 2.X unless told otherwise.\\n• The new PATH extension is off by default and seems contradictory.\\n\\nThe rest of this section gives a rundown of each of these three issues in turn. In the\\nfollowing,  I  use  the  programs  in  my  book  Programming  Python,  4th  Edition,  as  an\\nexample to illustrate the impacts of launcher incompatibilities, because porting these\\n3.1/3.2 examples to 3.3 was my first exposure to the new launcher. In my specific case,\\ninstalling 3.3 broke numerous book examples that worked formerly under 3.2 and 3.1.\\nThe causes for these failures outlined here may break your code too.\\n\\nPitfall 1: Unrecognized Unix !# Lines Fail\\nThe new Windows launcher recognizes Unix #! lines that begin with #!/usr/bin/env\\npython  but  not  the  other  common  Unix  form  #!/bin/env  python  (which  is  actually\\nmandated on some Unixes). Scripts that use the latter of these, including some of my\\nbook examples, worked on Windows in the past because their #! lines coded for Unix\\ncompatibility have been ignored as comments by all Windows Pythons to date. These\\nscripts now fail to run in 3.3 because the new launcher doesn’t recognize their directive’s\\nformat and posts an error message.\\nMore generally, scripts with any #! Unix line not recognized will now fail to run on\\nWindows. This includes scripts having any first line that begins with a #! that is not\\nfollowed  by  one  of  the  four  recognized  patterns  described  earlier:  /usr/bin/env\\npython*, /usr/bin/python*, /usr/local/bin/python*, or python*. Anything else won’t\\nwork, and requires code changes. For instance, a somewhat common #!/bin/python\\nline also causes a script to now fail on Windows, unless a version number is given in\\ncommand-line switches.\\n\\nPitfalls of the New Windows Launcher\\n\\n| 1447\\n\\n\\x0cUnix-style  #!  lines  probably  aren’t  present  in  Windows-only  programs,  but  can  be\\ncommon in programs meant to be run on Unix too. Treating unrecognized Unix di-\\nrectives as errors on Windows seems a bit extreme, especially given that this is new\\nbehavior in 3.3, and will likely be unexpected. Why not just ignore unrecognized #!\\nlines and run the file with the default Python—like every Windows Python to date has?\\nIt’s possible that this might be improved in a future 3.X release (there may be some\\npushback on this), but today you must change any files using a #!/bin/env or other\\nunrecognized pattern, if you want them to run under the launcher installed with Python\\n3.3 on Windows.\\n\\nBook examples impact and fix\\nWith respect to the book examples I ported to 3.3, this broke roughly a dozen scripts\\nthat started with #!/bin/env python. Regrettably, this includes some of the book’s user-\\nfriendly  and  top-level  demo  launcher  scripts  (PyGadgets  and  PyDemos).  To  fix,  I\\nchanged these to use the accepted #!/usr/bin/env python form instead. Altering your\\nWindows file associations to omit the launcher altogether may be another option (e.g.,\\nassociating .py files with python.exe instead of py.exe), but this negates the launcher’s\\nbenefits, and seems a bit much to ask of users, especially newcomers.\\nOne open issue here: strangely, passing any command-line switch to the launcher, even\\na python.exe argument, seems to negate this effect and fall back on the default Python\\n—m.py and py m.py both issue errors on unrecognized #! lines, but py -i m.py runs\\nsuch a file with the default Python. This seems a possible launcher bug, but also relies\\non the default, the subject of the next issue.\\n\\nPitfall 2: The Launcher Defaults to 2.X\\nOddly, the Windows 3.3 launcher defaults to using an installed Python 2.X when run-\\nning scripts that don’t select 3.X explicitly. That is, scripts that either have no #! di-\\nrective or use one that names python generically will be run by a 2.X Python by default\\nwhen launched by icon clicks, direct filename command lines (m.py), or launcher com-\\nmand lines that give no version switch (py m.py). This is true even if 3.3 is installed after\\na 2.X on your machine, and has the potential to make many 3.X scripts fail initially.\\nThe implications of this are potentially broad. As one example, clicking the icon of a\\ndirective-less  3.X  file  just  after  installing  3.3  may  now  fail,  because  the  associated\\nlauncher assumes you mean to use 2.X by default. This probably won’t be a pleasant\\nfirst encounter for some Python newcomers! This assumes the 3.X file has no #! direc-\\ntive that provides an explicit python3 version number, but most scripts meant to run\\non Windows won’t have a #! line at all, and many files coded before the launcher came\\nonline won’t accommodate its version number expectations. Most 3.X users will be\\nbasically compelled to set PY_PYTHON after installing 3.3—hardly a usability win.\\nProgram launches that don’t give an explicit version number might be arguably am-\\nbiguous on Unix too, and often rely on symbolic links from python to a specific version\\n\\n1448 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0c(which is most likely 2.X today—a state the new Windows launcher seems to emulate).\\nBut as for the prior issue, this probably shouldn’t trigger a new error on Windows in\\n3.3 for scripts that worked there formerly. Most programmers wouldn’t expect Unix\\ncomment lines to matter on Windows, and wouldn’t expect 2.X to be used by default\\njust after installing 3.X.\\n\\nBook examples impact and fix\\nIn terms of my book examples port, this 2.X default caused multiple 3.X script failures\\nafter installing 3.3, for both scripts with no  #! line, as well as scripts with a Unix-\\ncompatible #!/usr/bin/python line. To fix just the latter, change all scripts in this cat-\\negory to name python3 explicitly instead of just python. To fix both the former and the\\nlatter in a single step, set the Windows launcher’s default to be 3.X globally with either\\na  py.ini  configuration  file  (see  the  launcher’s  documentation  for  details)  or  a\\nPY_PYTHON  environment  variable  setting  as  shown  in  the  earlier  examples  (e.g.,  set\\nPY_PYTHON=3). As mentioned in the prior point, manually changing your file associations\\nis another solution, but none of these options seem simpler than those imposed by prior\\ninstall schemes.\\n\\nPitfall 3: The New PATH Extension Option\\nBesides installing the new launcher, the Windows Python 3.3 installer can automati-\\ncally add the directory containing 3.3’s python.exe executable to your system PATH set-\\nting. The reasoning behind this is that it might make life easier for some Windows\\nbeginners—they can type just python instead of the full directory path to it. This isn’t\\na feature of the launcher per se, and shouldn’t cause scripts to fail in general. It had no\\nimpact on the book examples. But it seems to clash with the launcher’s operation and\\ngoals, and may be best avoided. This is a bit subtle, but I’ll explain why.\\nAs described, the new launcher’s py and pyw executables are by default installed on your\\nsystem search path, and running them requires neither directory paths nor PATH settings.\\nIf you start scripts with py instead of python command lines, the new PATH feature is\\nirrelevant.  In  fact,  py  completely  subsumes  python  in  most  contexts.  Given  that  file\\nassociations will launch py or pyw instead of python anyhow, you probably should too\\n—using python instead of py may prove redundant and inconsistent, and might even\\nlaunch a version different than that used in launcher contexts should the two schemes’\\nsettings grow out of sync. In short, adding python to PATH seems contradictory to the\\nnew launcher’s worldview, and potentially error-prone.\\nAlso note that updating your PATH assumes you want a python command to run 3.3\\nnormally, and this feature is disabled by default; be sure to select this in the install screen\\nif you want this to work (but not if you don’t!). Due to the second pitfall mentioned\\nearlier, many users may still need to set PY_PYTHON to 3 for programs run by icon clicks\\nthat invoke the new launcher, which seems no simpler than setting PATH, a step that the\\n\\nPitfalls of the New Windows Launcher\\n\\n| 1449\\n\\n\\x0clauncher was meant to remove. You may be better served by using just the launcher’s\\nexecutables, and changing just PY_PYTHON as needed.\\n\\nConclusions: A Net Win for Windows\\nTo be fair, some of the prior section’s pitfalls may be an inevitable consequence of trying\\nto simultaneously support a Unix feature on Windows and multiple installed versions.\\nIn exchange, it provides a coherent way to manage mixed-version scripts and installa-\\ntions. You’ll probably find the Windows launcher shipped with 3.3 and later to be a\\nmajor asset once you start using it, and get past any initial incompatibilities you may\\nencounter.\\nIn fact, you may also want to start getting into the habit of coding compatible Unix-\\nstyle #! lines in your Windows scripts, with explicit version numbers (e.g., #!/usr/bin/\\npython3). Not only does this declare your code’s requirements and arrange for its proper\\nexecution on Windows, it will also subvert the launcher’s defaults, and may also make\\nyour script usable as a Unix executable in the future.\\nBut you should be aware that the launcher may break some formerly valid scripts having\\n#! lines, may choose a default version that you don’t expect and your scripts can’t use,\\nand may require configuration and code changes on the order of those it was intended\\nto obviate. The new boss is better than the old boss, but seems to have gone to the same\\nschool.\\nFor more on Windows usage, see Appendix A for installation and configuration, Chap-\\nter 3 for general concepts, and platform-specific documents in Python’s manuals set.\\n\\n1450 | Appendix B:\\u2002The Python 3.3 Windows Launcher\\n\\n\\x0cAPPENDIX C\\nPython Changes and This Book\\n\\nThis appendix briefly summarizes changes made in recent releases of Python organized\\nby the book editions where they first appeared, and gives links to their coverage in this\\nbook. It is intended as a reference for both readers of prior editions, as well as developers\\nmigrating from prior Python releases.\\nHere’s how changes in Python relate to this book’s recent editions:\\n\\n• This fifth edition of 2013 covers Python 3.3 and 2.7.\\n• The fourth edition of 2009 covered Python 2.6 and 3.0 (with some 3.1 features).\\n• The third edition of 2007 covered Python 2.5.\\n• The first and second editions of 1999 and 2003 covered Pythons 2.0 and 2.2.\\n• The predecessor of this book, 1996’s Programming Python, covered Python 1.3.\\n\\nHence, to see changes made in just this fifth edition, see the Python 2.7, 3.2, and 3.3\\nchanges listed ahead. For changes incorporated into both the fourth and fifth editions\\n(that is, since the third), also see Python 2.6, 3.0, and 3.1 changes here. Third edition\\nlanguage changes are listed very briefly too, though this seems of only historical value\\ntoday.\\nAlso note that this appendix focuses on major changes and book impacts, and is not\\nintended as a complete guide to Python’s evolution. For the fuller story on changes\\napplied in each new Python release, consult the “What’s New” documents that are part\\nof  its  standard  documentation  set,  and  available  at  the  Documentation  page  of\\npython.org. Chapter 15 covers Python documentation and its manuals set.\\n\\nMajor 2.X/3.X Differences\\nMuch  of  this  appendix  relates  Python  changes  to  book  coverage.  If  you’re  instead\\nlooking for a quick summary of the most prominent 2.X/3.X distinctions, the following\\nmay suffice. Note that this section primarily compares the latest 3.X and 2.X releases\\n—3.3 and 2.7. Many 3.X features are not listed here because they were either also added\\n\\n1451\\n\\n\\x0cto 2.6 (e.g., the with statement and class decorators), or back-ported later to 2.7 (e.g.,\\nset and dictionary comprehensions), but are not available in earlier 2.X releases. See\\nlater sections for more fine-grained information about changes in earlier versions, and\\nsee Python’s “What’s New” documents for changes that may appear in future releases.\\n\\n3.X Differences\\nThe following summarizes tools that differ across Python lines.\\n\\n• Unicode string model: In 3.X, normal str strings support all Unicode text including\\nASCII, and the separate bytes type represents raw 8-bit byte sequences. In 2.X,\\nnormal  str strings support both 8-bit text including ASCII, and a separate  uni\\ncode type represents richer Unicode text as an option.\\n\\n• File model: In 3.X, files created by open are specialized by content—text files im-\\nplement Unicode encodings and represent content as str strings, and binary files\\nrepresent content as bytes strings. In 2.X, files use distinct interfaces—files created\\nby open represent content as str strings for content that is either 8-bit text or bytes-\\nbased data, and codecs.open implements Unicode text encodings.\\n\\n• Class model: In 3.X, all classes derive from object automatically and acquire the\\nnumerous changes and extensions of new-style classes, including their differing\\ninheritance  algorithm,  built-ins  dispatch,  and  MRO  search  order  for  diamond-\\npattern trees. In 2.X, normal classes follow the classic model, and explicit inheri-\\ntance from object or other built-in types enables the new-style model as an option.\\n• Built-in iterables: In 3.X, map, zip, range, filter, and dictionary keys, values, and\\nitems are all iterable objects that generate values on request. In 2.X, these calls\\ncreate physical lists.\\n\\n• Printing: 3.X provides a built-in function with keyword arguments for configura-\\n\\ntion, while 2.X provides a statement with special syntax for configuration.\\n\\n• Relative imports: Both 2.X and 3.X support from . relative import statements, but\\n3.X changes the search rule to skip a package’s own directory for normal imports.\\n• True division: Both 2.X and 3.X support the // floor division operator, but the / is\\ntrue division in 3.X and retains fractional remainders, while / is type-specific in 2.X.\\n• Integer types: 3.X has a single integer type that supports extended precision. 2.X\\n\\nhas both normal int and extended long, and automatic conversion to long.\\n\\n• Comprehension scopes: In 3.X, all comprehension forms—list, set, dictionary, gen-\\n\\nerator—localize variables to the expression. In 2.X, list comprehensions do not.\\n\\n• PyDoc: An all-browser pydoc –b interface is supported as of 3.2 and required as of\\n\\n3.3. In 2.X, the original pydoc –g GUI client interface may be used instead.\\n\\n• Byte code storage: As of 3.2, 3.X stores byte code files in a __pycache__ subdirectory\\nof the source directory, with version-identifying names. In 2.X, byte code is stored\\nin the source file directory with generic names.\\n\\n1452 | Appendix C:\\u2002Python Changes and This Book\\n\\n\\x0c• Built-in system exceptions: As of 3.3, 3.X has a reworked exception hierarchy for\\nOS and IO classes that includes additional categories and granularity. In 2.X, ex-\\nception attributes must sometimes be inspected on system errors.\\n\\n• Comparisons and sorts: In 3.X, relative magnitude comparisons of both mixed-\\ntypes and dictionaries are errors, and sorts do not support mixed types or general\\ncomparison functions (use key mappers instead). In 2.X all these forms work.\\n\\n• String exceptions and module functions: String-based exceptions are fully removed\\nin 3.X, though they are also gone in 2.X as of 2.6 (use classes instead).  string\\nmodule functions redundant with string object methods are also removed in 3.X.\\n• Language removals: Per Table C-2, 3.X removes, renames, or relocates many 2.X\\nlanguage items: reload, apply, `x`, <>, 0177, 999L, dict.has_key, raw_input, xrange,\\nfile, reduce, and file.xreadlines.\\n\\n3.X-Only Extensions\\nThe following summarizes tools available in 3.X only.\\n\\n• Extended sequence assignment: 3.X allows a * in sequence assignment targets to\\ncollect remaining unmatched iterable items in a list. 2.X can achieve similar effects\\nwith slicing.\\n\\n• Nonlocal:  3.X  provides  a  nonlocal  statement,  which  allows  names  in  enclosing\\nfunction scopes to be changed from within nested functions. 2.X can achieve sim-\\nilar effects with function attributes, mutable objects, and class state.\\n\\n• Function annotations: 3.X allows function arguments and return types to be anno-\\ntated with objects that are retained in the function but not otherwise used. 2.X may\\noften achieve similar effects with extra objects or decorator arguments.\\n\\n• Keyword-only arguments: 3.X allows specification of function arguments that must\\nbe passed as keywords, typically used for extra configuration options. 2.X may\\noften achieve similar effects with argument analysis and dictionary pops.\\n\\n• Chained exceptions: 3.X allows exceptions to be chained and thus appear in error\\n\\nmessages, with a raise from extension; 3.3 allows a None to cancel the chain.\\n\\n• Yield from: As of 3.3, the yield statement may delegate to a nested generator with\\n\\nfrom. 2.X can often achieve similar results with a for loop in simpler use cases.\\n\\n• Namespace packages: As of 3.3, the package model is extended to allow packages\\nthat span multiple directories with no initialization file, as a fallback option. 2.X\\nmight achieve similar effects with import extensions.\\n\\n• Windows launcher: As of 3.3, a launcher is shipped with Python for Windows,\\n\\nthough this is also available separately for use on other Pythons, including 2.X.\\n\\n• Internals: As of 3.2, threading is implemented with time slices instead of virtual\\nmachine  instruction  counts,  and  3.3  stores  Unicode  text  in  a  variable-length\\n\\nMajor 2.X/3.X Differences\\n\\n| 1453\\n\\n\\x0cscheme instead of fixed-size bytes. 2.X’s string model minimizes Unicode use in\\ngeneral.\\n\\nGeneral Remarks: 3.X Changes\\nAlthough the Python 3.X line covered in the two most recent editions of this book is\\nlargely the same language as its 2.X predecessor, it differs in some crucial ways. As\\ndiscussed in the preface and summarized in the preceding section, 3.X’s nonoptional\\nUnicode model, mandatory new-style classes, and broader emphasis on generators and\\nother functional tools alone can make it a materially different experience.\\nOn the whole, Python 3.X may be a cleaner language, but it is also in many ways a more\\nsophisticated language, relying upon concepts that are substantially more advanced. In\\nfact, some of its changes seem to assume you must already know Python in order to\\nlearn Python. The preface mentioned some of the more prominent circular knowledge\\ndependencies in 3.X that imply forward topic dependencies.\\nAs a random example, the rationale for wrapping dictionary views in a list call in 3.X\\nis incredibly subtle and requires substantial foreknowledge—of views, generators, and\\nthe iteration protocol, at the least. Keyword arguments are similarly required in simple\\ntools (e.g., printing, string formatting, dictionary creation, and sorting) that crop up\\nlong before a newcomer learns enough about functions to understand them fully. One\\nof this book’s goals is to help bridge this knowledge gap in today’s 2.X/3.X dual-version\\nworld.\\n\\nChanges in Libraries and Tools\\nThere are additional changes in Python 3.X not listed in this appendix, simply because\\nthey don’t affect this book. For example, some standard libraries and development\\ntools are outside this book’s core language scope, though some are mentioned along\\nthe way (e.g., timeit), and others have always been covered here (e.g., PyDoc).\\nFor completeness, the following sections note 3.X developments in these categories.\\nSome of the changes in these categories are also listed later in this appendix, in con-\\njunction with the book edition and Python version in which they were introduced.\\n\\nStandard library changes\\nFormally speaking, the Python standard library is not a part of this book’s core language\\nsubject, even though it’s always available with Python, and permeates realistic Python\\nprograms. In fact, the libraries were not subject to the temporary 3.X language changes\\nmoratorium enacted during 3.2’s development.\\nBecause of this, changes in the standard library have a larger impact on applications-\\nfocused books like Programming Python than they do here. Although most standard\\n\\n1454 | Appendix C:\\u2002Python Changes and This Book\\n\\n\\x0clibrary functionality is still present, Python 3.X takes further liberties with renaming\\nmodules, grouping them into packages, and changing API call patterns.\\nSome library changes are much broader, though. Python 3.X’s Unicode model, for ex-\\nample, creates widespread differences in 3.X’s standard library—it potentially impacts\\nany program that processes file content, filenames, directory walkers, pipes, descriptor\\nfiles, sockets, text in GUIs, Internet protocols such as FTP and email, CGI scripts, web\\ncontent of many kinds, and even some persistence tools such as DBM files, shelves,\\nand pickles.\\nFor a more comprehensive list of changes in 3.X’s standard libraries, see the “What’s\\nNew” documents for 3.X releases (especially 3.0) in Python’s standard manual set.\\nBecause it uses Python 3.X throughout, the aforementioned Programming Python can\\nalso serve as a guide to 3.X library changes.\\n\\nTools changes\\nThough most development tools are the same between 2.X and 3.X (e.g., for debugging,\\nprofiling, timing, and testing), a few have undergone changes in 3.X along with the\\nlanguage  and  library.  Among  these,  the  PyDoc  module  documentation  system  has\\nmoved away from its former GUI client model in 3.2 and earlier, replacing it with an\\nall web browser interface.\\nOther noteworthy changes in this category: the distutils package, used to distribute and\\ninstall third-party software, is to be subsumed by a new packaging system in 3.X; the\\nnew __pycache__ byte code storage scheme described in this book, though an improve-\\nment, potentially impacts many Python tools and programs; and the internal imple-\\nmentation of threading changed as of 3.2 to reduce contention by modifying the global\\ninterpreter lock (GIL) to use absolute time slices instead of a virtual machine instruction\\ncounter.\\n\\nMigrating to 3.X\\nIf you are migrating from Python 2.X to Python 3.X, be sure to also see the 2to3 auto-\\nmatic code conversion script that is shipped with Python 3.X. It’s currently available\\nin Python’s Tools\\\\Scripts install folder, or via a web search. This script cannot translate\\neverything, and attempts to translate core language code primarily—3.X standard li-\\nbrary APIs may differ further. Still, it does a reasonable job of converting much 2.X\\ncode to run under 3.X.\\nConversely, the 3to2 back-conversion program, currently available in the third-party\\ndomain, can also translate much Python 3.X code to run in 2.X environments. De-\\npending on your goals and constraints, either 2to3 or 3to2 may prove useful if you must\\nmaintain code for both Python lines; see the Web for details, and additional tools and\\ntechniques.\\n\\nGeneral Remarks: 3.X Changes\\n\\n| 1455\\n\\n\\x0cIt’s also possible to write code that runs portably on both 2.X and 3.X using techniques\\npresented  in  this  book—importing  3.X  features  from  __future__,  avoiding  version-\\nspecific tools, and so on. Many of the examples in this book are platform-neutral. For\\nexamples, see the benchmarking tools in Chapter 21, the module reloaders and comma\\nformatter in Chapter 25, the class tree listers in Chapter 31, most of the larger decorator\\nexamples in Chapter 38 and Chapter 39, the joke script at the end of Chapter 41, and\\nmore. As long as you understand 2.X/3.X core language differences, coding around\\nthem is often straightforward.\\nIf you’re interested in writing code for both 2.X and 3.X, see also six—a library of cross-\\nversion mapping and renaming tools, which currently lives at http://packages.python\\n.org/six. Naturally, this package can’t offset every difference in language semantics and\\nlibrary APIs, and in many cases you must use its library tools instead of straight Python\\nto realize its portability gains. In exchange, though, your programs become much more\\nversion-neutral when using this library’s tools.\\n\\nFifth Edition Python Changes: 2.7, 3.2, 3.3\\nThe following specific changes were made in the Python 2.X and 3.X lines after the\\nfourth edition was published, and have been incorporated into this edition. Specifically,\\nthis section documents Python book-related changes in Pythons 2.7, 3.2, and 3.3.\\n\\nChanges in Python 2.7\\nOn the technical front, Python 2.7 mostly incorporates as back-ports a handful of 3.X\\nfeatures that were covered in the prior edition of this book, but formerly as 3.X-only\\nfeatures. This new fifth edition presents these as 2.7 tools as well. Among these:\\n\\n• Set literals:\\n\\n{1, 4, 2, 3, 4}\\n\\n• Set and dictionary comprehensions:\\n\\n{c * 4 for c in \\'spam\\'}, {c: c * 4 for c in \\'spam\\'}\\n• Dictionary views, incorporated as optional methods:\\n\\ndict.viewkeys(), dict.viewvalues(), dict.viewitems()\\n\\n• Comma separators and field autonumbering in str.format (from 3.1):\\n\\n\\'{:,.2f} {}\\'.format(1234567.891, \\'spam\\')\\n\\n• Nested with statement context managers (from 3.1):\\n\\nwith X() as x, Y() as y: ...\\n\\n• Float object repr display improvements (back-ported from 3.1: see ahead)\\n\\n1456 | Appendix C:\\u2002Python Changes and This Book\\n\\n\\x0cTo see where these topics are covered in the book, look for their entries in the 3.0\\nchanges list of Table C-1, or the Python 3.1 changes section, both ahead. They were\\nalready present for 3.X, but have been updated to reflect their availability in 2.7 as well.\\nOn the logistical front, per current plans 2.7 will be the last major 2.X series release,\\nbut will have a long maintenance period in which it will continue to be used in pro-\\nduction work. After 2.7, new development is to shift to the Python 3.X line.\\nThat said, it’s impossible to foresee how this official posture will stand the test of time,\\ngiven 2.X’s still very wide user base. See the preface for more on this; the optimized\\nPyPy implementation, for example, is still Python 2.X only. Or, to borrow a Monty\\nPython line, “I’m not dead yet...”—stay tuned for developments on the Python 2.X\\nstory.\\n\\nChanges in Python 3.3\\nPython 3.3 includes a surprisingly large number of changes for a point release. Some\\nof these are not entirely compatible with code written for prior release in the 3.X line.\\nAmong these, the new Windows launcher, installed as a mandatory part of 3.3, has\\nbroad potential to break existing 3.X scripts run on Windows.\\nHere’s a brief rundown of noteworthy 3.3 changes, along with their location in this\\nbook where applicable. Python 3.3 comes with:\\n\\n• A reduced memory footprint that is more in line with 2.X, thanks mainly to its new\\nvariable-length string storage scheme, and also to its attribute name-sharing dic-\\ntionaries system (see Chapter 37 and Chapter 32)\\n\\n• A new namespace package model, where new-style packages may span multiple\\n\\ndirectories and require no __init__.py file (see Chapter 24)\\n\\n• New syntax for delegating to subgenerators: yield from ... (see Chapter 20)\\n• New syntax for suppressing exception context: raise ... from None (see Chap-\\n\\nter 34)\\n\\n• New syntax for accepting 2.X’s Unicode literal form to ease migration: 3.3 now\\ntreats 2.X’s Unicode literal u\\'xxxx\\' the same as its normal string \\'xxxx\\', similar to\\nthe  way  2.X  treats  3.X’s  bytes  literal  b\\'xxxx\\'  the  same  as  its  normal  string\\n\\'xxxx\\' (see Chapter 4, Chapter 7, and Chapter 37)\\n\\n• Reworked OS and IO exception hierarchies, which provide more inclusive general\\nsuperclasses, as well as new subclasses for common errors that can obviate the need\\nto inspect exception object attributes (see Chapter 35)\\n\\n• An all-web-browser-based interface to PyDoc documentation started via pydoc -b,\\nreplacing its former standalone GUI client search interface, which was in the Win-\\ndows 7 and earlier Start button and invoked by pydoc –g (see Chapter 15)\\n\\nFifth Edition Python Changes: 2.7, 3.2, 3.3 | 1457\\n\\n\\x0c• Changes to some longstanding standard library modules, including ftplib, time,\\nand email, and potentially distutils; impacts in this book: time has new portable\\ncalls in 3.X (see Chapter 21 and Chapter 39)\\n\\n• An implementation of the __import__ function in importlib.__import__, in part to\\nunify and more clearly expose its implementation (see Chapter 22 and Chapter 25)\\n• A new capability in the Windows 3.3 installer that extends the system PATH setting\\nto include 3.3’s directory as an install-time option to simplify some command lines\\n(see Appendixes A and B)\\n\\n• A new Windows launcher, which attempts to interpret Unix-style #! lines for dis-\\npatching Python scripts on Windows, and allows both #! lines and new py com-\\nmand lines to select between Python 2.X and 3.X versions explicitly on both a per-\\nfile and per-command basis (see the new Appendix B)\\n\\nChanges in Python 3.2\\nPython 3.2 continued the 3.X line’s evolution. It was developed during a moratorium\\non 3.X core language changes, so its relevant changes were minor. Here’s a quick review\\nof major 3.2 changes, and their location in this fifth edition where relevant:\\n\\n• Byte-code files storage model change: __pycache__ (see Chapter 2 and Chapter 22)\\n• The struct module’s autoencoding for strings is gone (see Chapter 9 and Chap-\\n\\nter 37)\\n\\n• 3.X str/bytes split supported better by Python itself (not relevant to this book)\\n• The cgi.escape call was to be moved in 3.2+ (not relevant to this book)\\n• Threading implementation change: time slices (not relevant to this book)\\n\\nFourth Edition Python Changes: 2.6, 3.0, 3.1\\nThe fourth edition was updated to cover Python 3.0 and 2.6, and incorporated a small\\nnumber of major changes made in 3.1. Its 3.0 and 3.1 changes apply to all future releases\\nin the 3.X line including this fifth edition’s Python 3.3, and its 2.6 changes are also part\\nof this edition’s 2.7. As noted earlier, some of the changes described here as 3.X changes\\nalso later found their way into Python 2.7 as back-ports (e.g., set literals, and set and\\ndictionary comprehensions).\\n\\nChanges in Python 3.1\\nIn addition to the 3.0 and 2.6 changes listed in upcoming sections, shortly before going\\nto press the fourth edition was also augmented with notes about prominent extensions\\nin the then upcoming Python 3.1 release, including:\\n\\n1458 | Appendix C:\\u2002Python Changes and This Book\\n\\n\\x0c• Comma separators and automatic field numbering in string format method calls\\n\\n(Chapter 7)\\n\\n• Multiple context manager syntax in with statements (Chapter 34)\\n• New methods for number objects (Chapter 5)\\n• (Not added until this fifth edition) Floating-point display changes (Chapter 4 and\\n\\nChapter 5)\\n\\nThis fifth edition covers these topics in the chapters just noted. Because Python 3.1 was\\ntargeted primarily at optimization and was released relatively soon after 3.0, the fourth\\nedition also applied directly to 3.1. In fact, because Python 3.1 superseded 3.0 entirely,\\nand  because  the  latest  Python  is  usually  the  best  Python  to  fetch  and  use  anyhow,\\nwhenever that edition used the term “Python 3.0” it generally referred to the language\\nvariations introduced by Python 3.0 but that are present in the entire 3.X line, including\\nthis edition’s Python 3.3.\\nOne notable exception: the fourth edition did not incorporate 3.1’s new repr display\\nscheme  for  floating-point  numbers.  The  new  display  algorithm  attempts  to  display\\nfloating-point numbers more intelligently when possible, usually with fewer (but oc-\\ncasionally with more) decimal digits—a change that is reflected in this fifth edition.\\n\\nChanges in Python 3.0 and 2.6\\nThe fourth edition’s language changes stem from Python 3.0 and 2.6. All of its 2.6 and\\nmany of its 3.0 changes are shared by Python 2.7 and 3.3 today. Python 2.7 was ex-\\ntended with some 3.0 features not present in 2.6 (see earlier in this appendix), and\\nPython 3.3 inherits all the features introduced by 3.0.\\nBecause there were so many changes in the initial 3.X release, they are noted only briefly\\nin tables here, with links to more details in this book. Table C-1 provides the first set\\nof 3.X changes, listing the most prominent new language features covered in the fourth\\nedition, along with the primary chapters in the current fifth edition in which they ap-\\npear.\\n\\nTable C-1. Extensions in Python 2.6 and 3.0\\n\\nExtension\\nThe print function in 3.0\\nThe nonlocal x,y statement in 3.0\\nThe str.format method in 2.6 and 3.0\\nString types in 3.0: str for Unicode text, bytes for binary data\\nText and binary file distinctions in 3.0\\nClass decorators in 2.6 and 3.0: @private(\\'age\\')\\nNew iterators in 3.0: range, map, zip\\nDictionary views in 3.0: D.keys, D.values, D.items\\n\\nCovered in chapter(s)\\n11\\n17\\n7\\n7, 37\\n9, 37\\n32, 39\\n14, 20\\n8, 14\\n\\nFourth Edition Python Changes: 2.6, 3.0, 3.1 | 1459\\n\\n\\x0cExtension\\nDivision operators in 3.0: remainders, / and //\\nSet literals in 3.0: {a, b, c}\\nSet comprehensions in 3.0: {x**2 for x in seq}\\nDictionary comprehensions in 3.0: {x: x**2 for x in seq}\\nBinary digit-string support in 2.6 and 3.0: 0b0101, bin(I)\\nThe fraction number type in 2.6 and 3.0: Fraction(1, 3)\\nFunction annotations in 3.0: def f(a:99, b:str)->int\\nKeyword-only arguments in 3.0: def f(a, *b, c, **d)\\nExtended sequence unpacking in 3.0: a, *b = seq\\nRelative import syntax for packages enabled in 3.0: from .\\nContext managers enabled in 2.6 and 3.0: with/as\\nException syntax changes in 3.0: raise, except/as, superclass\\nException chaining in 3.0: raise e2 from e1\\nReserved word changes in 2.6 and 3.0\\nNew-style class cutover in 3.0\\nProperty decorators in 2.6 and 3.0: @property\\nDescriptor use in 2.6 and 3.0\\nMetaclass use in 2.6 and 3.0\\nAbstract base classes support in 2.6 and 3.0\\n\\nCovered in chapter(s)\\n5\\n5\\n4, 5, 14, 20\\n4, 8, 14, 20\\n5\\n5\\n19\\n18, 20\\n11, 13\\n24\\n34, 36\\n34, 35\\n34\\n11\\n32\\n38\\n32, 38\\n32, 40\\n29\\n\\nSpecific Language Removals in 3.0\\nIn addition to extensions, a number of 2.X language tools have been removed in 3.X in\\nan effort to clean up its design. Table C-2 summarizes the 3.X removals that impact\\nthis book, covered in various chapters of this edition as noted. As also shown in this\\ntable,  many  of  the  3.X  removals  have  direct  replacements,  some  of  which  are  also\\navailable in 2.6 and 2.7 to support future migration to 3.X.\\n\\nTable C-2. Removals in Python 3.0 that impact this book\\n\\nRemoved\\nreload(M)\\n\\napply(f, ps, ks)\\n\\n`X`\\n\\nX <> Y\\n\\nlong\\n\\n9999L\\n\\nD.has_key(K)\\n\\nReplacement\\nimp.reload(M) (or exec)\\nf(*ps, **ks)\\n\\nrepr(X)\\n\\nX != Y\\n\\nint\\n\\n9999\\nK in D (or D.get(key) != None)\\n\\nCovered in chapter(s)\\n3, 23\\n18\\n5\\n5\\n5\\n5\\n8\\n\\n1460 | Appendix C:\\u2002Python Changes and This Book\\n\\n\\x0cRemoved\\nraw_input\\nold input\\nxrange\\n\\nfile\\n\\nX.next\\n\\nX.__getslice__\\n\\nX.__setslice__\\n\\nreduce\\n\\nexecfile(filename)\\n\\nexec open(filename)\\n\\n0777\\n\\nprint x, y\\n\\nprint >> F, x, y\\n\\nprint x, y,\\nu\\'ccc\\' (back in 3.3)\\n\\'bbb\\' for byte strings\\nraise E, V\\n\\nexcept E, X:\\n\\ndef f((a, b)):\\n\\nfile.xreadlines\\n\\nD.keys(), etc. as lists\\nmap(), range(), etc. as lists\\n\\nmap(None, ...)\\n\\nX=D.keys(); X.sort()\\n\\ncmp(x, y)\\n\\nX.__cmp__(y)\\n\\nX.__nonzero__\\n\\nX.__hex__, X.__oct__\\nSort comparison functions\\n\\nReplacement\\ninput\\n\\neval(input())\\n\\nrange\\nopen (and io module classes)\\nX.__next__, called by next(X)\\nX.__getitem__ passed a slice ob-\\nject\\nX.__setitem__ passed a slice ob-\\nject\\nfunctools.reduce (or loop code)\\nexec(open(file\\nname).read())\\n\\nexec(open(file\\nname).read())\\n\\n0o777\\n\\nprint(x, y)\\n\\nprint(x, y, file=F)\\n\\nprint(x, y, end=\\' \\')\\n\\n\\'ccc\\'\\n\\nb\\'bbb\\'\\n\\nraise E(V)\\n\\nexcept E as X:\\n\\ndef f(x): (a, b) = x\\nfor line in file: (or\\nX=iter(file))\\nlist(D.keys()) (dictionary views)\\nlist(map()), list(range())\\n(built-ins)\\nzip (or manual code to pad results)\\nsorted(D) (or list(D.keys()))\\n(x > y) - (x < y)\\n__lt__, __gt__, __eq__, etc.\\nX.__bool__\\n\\nX.__index__\\nUse key=transform or\\nreverse=True\\n\\nCovered in chapter(s)\\n3, 10\\n3\\n13, 14\\n9\\n14, 20, 30\\n7, 30\\n\\n7, 30\\n\\n14, 19\\n3\\n\\n3\\n\\n5\\n11\\n11\\n11\\n4, 7, 37\\n4, 7, 9, 37\\n33, 34, 35\\n33, 34, 35\\n11, 18, 20\\n13, 14\\n\\n8, 14\\n14\\n\\n13, 20\\n4, 8, 14\\n30\\n30\\n30\\n30\\n8\\n\\nFourth Edition Python Changes: 2.6, 3.0, 3.1 | 1461\\n\\n\\x0cRemoved\\nDictionary <, >, <=, >=\\n\\ntypes.ListType\\n\\n__metaclass__ = M\\n\\n__builtin__\\n\\nTkinter\\nsys.exc_type, exc_value\\nfunction.func_code\\n__getattr__ run by built-ins\\n\\n-t, –tt command-line switches\\n\\nfrom ... *, within a function\\nimport mod, in same package\\n\\nclass MyException:\\n\\nexceptions module\\nthread, Queue modules\\nanydbm module\\ncPickle module\\n\\nos.popen2/3/4\\n\\nString-based exceptions\\n\\nString module functions\\nUnbound methods\\n\\nMixed type comparisons, sorts\\n\\nReplacement\\nCompare sorted(D.items()) (or\\nloop code)\\nlist (types is for non-built-in names\\nonly)\\nclass C(metaclass=M):\\nbuiltins (renamed)\\ntkinter (renamed)\\nsys.exc_info()[0], [1]\\nfunction.__code__\\nRedefine __X__ methods in wrapper\\nclasses\\nInconsistent tabs/spaces use is always an\\nerror\\nMay only appear at the top level of a file\\nfrom . import mod, package-rel-\\native form\\nclass MyException(Excep\\ntion):\\nBuilt-in scope, library manual\\n_thread, queue (both renamed)\\ndbm (renamed)\\n_pickle (renamed, used automati-\\ncally)\\nsubprocess.Popen (os.popen re-\\ntained)\\nClass-based exceptions (also required in\\n2.6)\\nString object methods\\nFunctions (staticmethod to call via\\ninstance)\\nNonnumeric mixed type magnitude\\ncomparisons (and sorts) are errors\\n\\nCovered in chapter(s)\\n8, 9\\n\\n9\\n\\n29, 32, 40\\n17\\n18, 19, 25, 30, 31\\n35, 36\\n19, 39\\n31, 38, 39\\n\\n10, 12\\n\\n23\\n24\\n\\n35\\n\\n35\\n17\\n28\\n9\\n\\n14\\n\\n33, 34, 35\\n\\n7\\n31, 32\\n\\n5, 9\\n\\nThird Edition Python Changes: 2.3, 2.4, 2.5\\nThe third edition of this book was thoroughly updated to reflect Python 2.5 and all\\nchanges to the language made after the publication of the second edition in late 2003.\\n(The second edition was based largely on Python 2.2, with some 2.3 features grafted\\non at the end of the project.) In addition, brief discussions of anticipated changes in\\n\\n1462 | Appendix C:\\u2002Python Changes and This Book\\n\\n\\x0cthe upcoming Python 3.0 release were incorporated where appropriate. Here are some\\nof the major language topics for which new or expanded coverage was provided (chap-\\nter numbers here have been updated to reflect this fifth edition):\\n\\n• The new B if A else C conditional expression (Chapter 12, Chapter 19)\\n• with/as context managers (Chapter 34)\\n• try/except/finally unification (Chapter 34)\\n• Relative import syntax (Chapter 24)\\n• Generator expressions (Chapter 20)\\n• New generator function features (Chapter 20)\\n• Function decorators (Chapter 32, Chapter 39)\\n• The set object type (Chapter 5)\\n• New built-in functions: sorted, sum, any, all, enumerate (Chapter 13 and Chap-\\n\\nter 14)\\n\\n• The decimal fixed-precision object type (Chapter 5)\\n• Files, list comprehensions, and iterators (Chapter 14 and Chapter 20)\\n• New development tools: Eclipse, distutils, unittest and doctest, IDLE enhance-\\n\\nments, Shed Skin, and so on (Chapter 2 and Chapter 36)\\n\\nSmaller language changes (for instance, the widespread use of True and False; the new\\nsys.exc_info for fetching exception details; and the demise of string-based exceptions,\\nstring methods, and the apply and reduce built-ins) were incorporated throughout the\\nbook. The third edition also expanded coverage of some of the features that were new\\nin the second edition, including three-limit slices and the arbitrary arguments call syn-\\ntax that subsumed apply.\\n\\nEarlier and Later Python Changes\\nEach edition before the third also incorporated Python changes too—the first two ed-\\nitions from 1999 and 2003 covered Pythons 2.0 and 2.2, and their 1996 Programming\\nPython 1st Edition predecessor, from which my three later books were all derived, began\\nthe process with Python 1.3—but I’ve omitted these here because they are now ancient\\nhistory (well, in computer field terms, at least).\\nSee the first and second editions for more details, if you can manage to scare one up.\\nWhile it’s impossible to predict the future, given how much has stood the test of time,\\nit’s likely that the core ideas stressed in this book will likely apply to future Pythons as\\nwell.\\n\\nEarlier and Later Python Changes\\n\\n| 1463\\n\\n\\x0c\\x0cAPPENDIX D\\nSolutions to End-of-Part Exercises\\n\\nPart I, Getting Started\\nSee “Test Your Knowledge: Part I Exercises” on page 87 in Chapter 3 for the exercises.\\n\\n1. Interaction. Assuming Python is configured properly, the interaction should look\\nsomething like the following (you can run this any way you like (in IDLE, from a\\nshell prompt, and so on):\\n\\n% python\\n...copyright information lines...\\n>>> \"Hello World!\"\\n\\'Hello World!\\'\\n>>>                 # Use Ctrl-D or Ctrl-Z to exit, or close window\\n\\n2. Programs. Your code (i.e., module) file module1.py and the operating system shell\\n\\ninteractions should look like this:\\n\\nprint(\\'Hello module world!\\')\\n\\n% python module1.py\\nHello module world!\\n\\nAgain, feel free to run this other ways—by clicking the file’s icon, by using IDLE’s\\nRun→Run Module menu option, and so on.\\n\\n3. Modules. The following interaction listing illustrates running a module file by im-\\n\\nporting it:\\n\\n% python\\n>>> import module1\\nHello module world!\\n>>>\\n\\nRemember that you will need to reload the module to run it again without stopping\\nand restarting the interpreter. The question about moving the file to a different\\ndirectory and importing it again is a trick question: if Python generates a mod-\\nule1.pyc file in the original directory, it uses that when you import the module,\\neven if the source code (.py) file has been moved to a directory not in Python’s\\n\\n1465\\n\\n\\x0csearch path. The .pyc file is written automatically if Python has access to the source\\nfile’s directory; it contains the compiled byte code version of a module. See Chap-\\nter 3 for more on modules.\\n\\n4. Scripts. Assuming your platform supports the #! trick, your solution will look like\\nthe following (although your #! line may need to list another path on your ma-\\nchine). Note that these lines are significant under the Windows launcher shipped\\nand installed with Python 3.3, where they are parsed to select a version of Python\\nto run the script, along with a default setting; see Appendix B for details and ex-\\namples.\\n\\n#!/usr/local/bin/python          (or #!/usr/bin/env python)\\nprint(\\'Hello module world!\\')\\n% chmod +x module1.py\\n\\n% module1.py\\nHello module world!\\n\\n5. Errors. The following interaction (run in Python 3.X) demonstrates the sorts of\\nerror messages you’ll get when you complete this exercise. Really, you’re triggering\\nPython exceptions; the default exception-handling behavior terminates the run-\\nning Python program and prints an error message and stack trace on the screen.\\nThe stack trace shows where you were in a program when the exception occurred\\n(if function calls are active when the error happens, the “Traceback” section dis-\\nplays all active call levels). In Chapter 10 and Part VII, you will learn that you can\\ncatch exceptions using try statements and process them arbitrarily; you’ll also see\\nthere that Python includes a full-blown source code debugger for special error-\\ndetection requirements. For now, notice that Python gives meaningful messages\\nwhen programming errors occur, instead of crashing silently:\\n\\n% python\\n>>> 2 ** 500\\n32733906078961418700131896968275991522166420460430647894832913680961337964046745\\n54883270092325904157150886684127560071009217256545885393053328527589376\\n>>>\\n>>> 1 / 0\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nZeroDivisionError: int division or modulo by zero\\n>>>\\n>>> spam\\nTraceback (most recent call last):\\n  File \"<stdin>\", line 1, in <module>\\nNameError: name \\'spam\\' is not defined\\n\\n6. Breaks and cycles. When you type this code:\\n\\nL = [1, 2]\\nL.append(L)\\n\\nyou create a cyclic data structure in Python. In Python releases before 1.5.1, the\\nPython printer wasn’t smart enough to detect cycles in objects, and it would print\\n\\n1466 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cFigure D-1. A cyclic object, created by appending a list to itself. By default, Python appends a reference\\nto the original list, not a copy of the list.\\n\\nan unending stream of [1, 2, [1, 2, [1, 2, [1, 2, and so on, until you hit the\\nbreak-key combination on your machine (which, technically, raises a keyboard-\\ninterrupt exception that prints a default message). Beginning with Python 1.5.1,\\nthe printer is clever enough to detect cycles and prints [[...]] instead to let you\\nknow that it has detected a loop in the object’s structure and avoided getting stuck\\nprinting forever.\\nThe  reason  for  the  cycle  is  subtle  and  requires  information  you  will  glean  in\\nPart II, so this is something of a preview. But in short, assignments in Python always\\ngenerate  references  to  objects,  not  copies  of  them.  You  can  think  of  objects  as\\nchunks of memory and of references as implicitly followed pointers. When you run\\nthe first assignment above, the name L becomes a named reference to a two-item\\nlist object—a pointer to a piece of memory. Python lists are really arrays of object\\nreferences, with an append method that changes the array in place by tacking on\\nanother object reference at the end. Here, the append call adds a reference to the\\nfront of L at the end of L, which leads to the cycle illustrated in Figure D-1: a pointer\\nat the end of the list that points back to the front of the list.\\nBesides being printed specially, as you’ll learn in Chapter 6 cyclic objects must also\\nbe handled specially by Python’s garbage collector, or their space will remain un-\\nreclaimed even when they are no longer in use. Though rare in practice, in some\\nprograms that traverse arbitrary objects or structures you might have to detect such\\ncycles yourself by keeping track of where you’ve been to avoid looping. Believe it\\nor not, cyclic data structures can sometimes be useful, despite their special-case \\nprinting.\\n\\nPart II, Types and Operations\\nSee “Test Your Knowledge: Part II Exercises” on page 313 in Chapter 9 for the exercises.\\n\\nPart II, Types and Operations\\n\\n| 1467\\n\\n\\x0c1. The basics. Here are the sorts of results you should get, along with a few comments\\nabout their meaning. Again, note that ; is used in a few of these to squeeze more\\nthan one statement onto a single line (the ; is a statement separator), and commas\\nbuild up tuples displayed in parentheses. Also keep in mind that the / division\\nresult near the top differs in Python 2.X and 3.X (see Chapter 5 for details), and\\nthe list wrapper around dictionary method calls is needed to display results in\\n3.X, but not 2.X (see Chapter 8):\\n\\n# Numbers\\n\\n>>> 2 ** 16                           # 2 raised to the power 16\\n65536\\n>>> 2 / 5, 2 / 5.0                    # Integer / truncates in 2.X, but not 3.X\\n(0.40000000000000002, 0.40000000000000002)\\n\\n# Strings\\n\\n>>> \"spam\" + \"eggs\"                   # Concatenation\\n\\'spameggs\\'\\n>>> S = \"ham\"\\n>>> \"eggs \" + S\\n\\'eggs ham\\'\\n>>> S * 5                             # Repetition\\n\\'hamhamhamhamham\\'\\n>>> S[:0]                             # An empty slice at the front -- [0:0]\\n\\'\\'                                    # Empty of same type as object sliced\\n\\n>>> \"green %s and %s\" % (\"eggs\", S)   # Formatting\\n\\'green eggs and ham\\'\\n>>> \\'green {0} and {1}\\'.format(\\'eggs\\', S)\\n\\'green eggs and ham\\'\\n\\n# Tuples\\n\\n>>> (\\'x\\',)[0]                         # Indexing a single-item tuple\\n\\'x\\'\\n>>> (\\'x\\', \\'y\\')[1]                     # Indexing a two-item tuple\\n\\'y\\'\\n\\n# Lists\\n\\n>>> L = [1,2,3] + [4,5,6]             # List operations\\n>>> L, L[:], L[:0], L[-2], L[-2:]\\n([1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6], [], 5, [5, 6])\\n>>> ([1,2,3]+[4,5,6])[2:4]\\n[3, 4]\\n>>> [L[2], L[3]]                      # Fetch from offsets; store in a list\\n[3, 4]\\n>>> L.reverse(); L                    # Method: reverse list in place\\n[6, 5, 4, 3, 2, 1]\\n>>> L.sort(); L                       # Method: sort list in place\\n[1, 2, 3, 4, 5, 6]\\n>>> L.index(4)                        # Method: offset of first four (search)\\n3\\n\\n1468 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c# Dictionaries\\n\\n>>> {\\'a\\':1, \\'b\\':2}[\\'b\\']               # Index a dictionary by key\\n2\\n>>> D = {\\'x\\':1, \\'y\\':2, \\'z\\':3}\\n>>> D[\\'w\\'] = 0                        # Create a new entry\\n>>> D[\\'x\\'] + D[\\'w\\']\\n1\\n>>> D[(1,2,3)] = 4                    # A tuple used as a key (immutable)\\n\\n>>> D\\n{\\'w\\': 0, \\'z\\': 3, \\'y\\': 2, (1, 2, 3): 4, \\'x\\': 1}\\n\\n>>> list(D.keys()), list(D.values()), (1,2,3) in D         # Methods, key test\\n([\\'w\\', \\'z\\', \\'y\\', (1, 2, 3), \\'x\\'], [0, 3, 2, 4, 1], True)\\n\\n# Empties\\n\\n>>> [[]], [\"\",[],(),{},None]          # Lots of nothings: empty objects\\n([[]], [\\'\\', [], (), {}, None])\\n\\n2. Indexing and slicing. Indexing out of bounds (e.g., L[4]) raises an error; Python\\n\\nalways checks to make sure that all offsets are within the bounds of a sequence.\\nOn the other hand, slicing out of bounds (e.g., L[-1000:100]) works because Python\\nscales out-of-bounds slices so that they always fit (the limits are set to zero and the\\nsequence length, if required).\\nExtracting a sequence in reverse, with the lower bound greater than the higher\\nbound (e.g., L[3:1]), doesn’t really work. You get back an empty slice ([ ]) because\\nPython scales the slice limits to make sure that the lower bound is always less than\\nor equal to the upper bound (e.g., L[3:1] is scaled to L[3:3], the empty insertion\\npoint at offset 3). Python slices are always extracted from left to right, even if you\\nuse negative indexes (they are first converted to positive indexes by adding the\\nsequence length). Note that Python 2.3’s three-limit slices modify this behavior\\nsomewhat. For instance, L[3:1:-1] does extract from right to left:\\n\\n>>> L = [1, 2, 3, 4]\\n>>> L[4]\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nIndexError: list index out of range\\n>>> L[-1000:100]\\n[1, 2, 3, 4]\\n>>> L[3:1]\\n[]\\n>>> L\\n[1, 2, 3, 4]\\n>>> L[3:1] = [\\'?\\']\\n>>> L\\n[1, 2, 3, \\'?\\', 4]\\n\\nPart II, Types and Operations\\n\\n| 1469\\n\\n\\x0c3. Indexing, slicing, and del. Your interaction with the interpreter should look some-\\nthing like the following code. Note that assigning an empty list to an offset stores\\nan empty list object there, but assigning an empty list to a slice deletes the slice.\\nSlice assignment expects another sequence, or you’ll get a type error; it inserts items\\ninside the sequence assigned, not the sequence itself:\\n\\n>>> L = [1,2,3,4]\\n>>> L[2] = []\\n>>> L\\n[1, 2, [], 4]\\n>>> L[2:3] = []\\n>>> L\\n[1, 2, 4]\\n>>> del L[0]\\n>>> L\\n[2, 4]\\n>>> del L[1:]\\n>>> L\\n[2]\\n>>> L[1:2] = 1\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nTypeError: illegal argument type for built-in operation\\n\\n4. Tuple assignment. The values of X and Y are swapped. When tuples appear on the\\nleft and right of an assignment symbol (=), Python assigns objects on the right to\\ntargets on the left according to their positions. This is probably easiest to under-\\nstand by noting that the targets on the left aren’t a real tuple, even though they\\nlook like one; they are simply a set of independent assignment targets. The items\\non the right are a tuple, which gets unpacked during the assignment (the tuple\\nprovides the temporary assignment needed to achieve the swap effect):\\n\\n>>> X = \\'spam\\'\\n>>> Y = \\'eggs\\'\\n>>> X, Y = Y, X\\n>>> X\\n\\'eggs\\'\\n>>> Y\\n\\'spam\\'\\n\\n5. Dictionary keys. Any immutable object can be used as a dictionary key, including\\nintegers, tuples, strings, and so on. This really is a dictionary, even though some\\nof its keys look like integer offsets. Mixed-type keys work fine, too:\\n\\n>>> D = {}\\n>>> D[1] = \\'a\\'\\n>>> D[2] = \\'b\\'\\n>>> D[(1, 2, 3)] = \\'c\\'\\n>>> D\\n{1: \\'a\\', 2: \\'b\\', (1, 2, 3): \\'c\\'}\\n\\n6. Dictionary indexing. Indexing a nonexistent key (D[\\'d\\']) raises an error; assigning\\nto a nonexistent key (D[\\'d\\']=\\'spam\\') creates a new dictionary entry. On the other\\nhand, out-of-bounds indexing for lists raises an error too, but so do out-of-bounds\\n\\n1470 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cassignments. Variable names work like dictionary keys; they must have already\\nbeen assigned when referenced, but they are created when first assigned. In fact,\\nvariable names can be processed as dictionary keys if you wish (they’re made visible\\nin module namespace or stack-frame dictionaries):\\n\\n>>> D = {\\'a\\':1, \\'b\\':2, \\'c\\':3}\\n>>> D[\\'a\\']\\n1\\n>>> D[\\'d\\']\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nKeyError: d\\n>>> D[\\'d\\'] = 4\\n>>> D\\n{\\'b\\': 2, \\'d\\': 4, \\'a\\': 1, \\'c\\': 3}\\n>>>\\n>>> L = [0, 1]\\n>>> L[2]\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nIndexError: list index out of range\\n>>> L[2] = 3\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nIndexError: list assignment index out of range\\n\\n7. Generic operations. Question answers:\\n\\n• The + operator doesn’t work on different/mixed types (e.g., string + list, list\\n\\n+ tuple).\\n\\n• + doesn’t work for dictionaries, as they aren’t sequences.\\n• The append method works only for lists, not strings, and keys works only on\\ndictionaries. append assumes its target is mutable, since it’s an in-place exten-\\nsion; strings are immutable.\\n\\n• Slicing and concatenation always return a new object of the same type as the\\n\\nobjects processed:\\n\\n>>> \"x\" + 1\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nTypeError: illegal argument type for built-in operation\\n>>>\\n>>> {} + {}\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nTypeError: bad operand type(s) for +\\n>>>\\n>>> [].append(9)\\n>>> \"\".append(\\'s\\')\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nAttributeError: attribute-less object\\n>>>\\n\\nPart II, Types and Operations\\n\\n| 1471\\n\\n\\x0c>>> list({}.keys())                     # list() needed in 3.X, not 2.X\\n[]\\n>>> [].keys()\\nTraceback (innermost last):\\n  File \"<stdin>\", line 1, in ?\\nAttributeError: keys\\n>>>\\n>>> [][:]\\n[]\\n>>> \"\"[:]\\n\\'\\'\\n\\n8. String indexing. This is a bit of a trick question—because strings are collections of\\none-character strings, every time you index a string, you get back a string that can\\nbe indexed again. S[0][0][0][0][0] just keeps indexing the first character over and\\nover. This generally doesn’t work for lists (lists can hold arbitrary objects) unless\\nthe list contains strings:\\n\\n>>> S = \"spam\"\\n>>> S[0][0][0][0][0]\\n\\'s\\'\\n>>> L = [\\'s\\', \\'p\\']\\n>>> L[0][0][0]\\n\\'s\\'\\n\\n9. Immutable  types.  Either  of  the  following  solutions  works.  Index  assignment\\n\\ndoesn’t, because strings are immutable:\\n\\n>>> S = \"spam\"\\n>>> S = S[0] + \\'l\\' + S[2:]\\n>>> S\\n\\'slam\\'\\n>>> S = S[0] + \\'l\\' + S[2] + S[3]\\n>>> S\\n\\'slam\\'\\n\\n(See also the Python 3.X and 2.6+ bytearray string type in Chapter 37—it’s a mu-\\ntable sequence of small integers that is essentially processed the same as a string.)\\n\\n10. Nesting. Here is a sample:\\n\\n>>> me = {\\'name\\':(\\'John\\', \\'Q\\', \\'Doe\\'), \\'age\\':\\'?\\', \\'job\\':\\'engineer\\'}\\n>>> me[\\'job\\']\\n\\'engineer\\'\\n>>> me[\\'name\\'][2]\\n\\'Doe\\'\\n\\n11. Files. Here’s one way to create and read back a text file in Python (ls is a Unix\\n\\ncommand; use dir on Windows):\\n\\n# File: maker.py\\nfile = open(\\'myfile.txt\\', \\'w\\')\\nfile.write(\\'Hello file world!\\\\n\\')        # Or: open().write()\\nfile.close()                             # close not always needed\\n\\n# File: reader.py\\nfile = open(\\'myfile.txt\\')                # \\'r\\' is default open mode\\n\\n1472 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cprint(file.read())                       # Or print(open().read())\\n\\n% python maker.py\\n% python reader.py\\nHello file world!\\n\\n% ls -l myfile.txt\\n-rwxrwxrwa   1 0        0             19 Apr 13 16:33 myfile.txt\\n\\nPart III, Statements and Syntax\\nSee “Test Your Knowledge: Part III Exercises” on page 467 in Chapter 15 for the ex-\\nercises.\\n\\n1. Coding basic loops. As you work through this exercise, you’ll wind up with code\\n\\nthat looks like the following:\\n\\n>>> S = \\'spam\\'\\n>>> for c in S:\\n...     print(ord(c))\\n...\\n115\\n112\\n97\\n109\\n\\n>>> x = 0\\n>>> for c in S: x += ord(c)             # Or: x = x + ord(c)\\n...\\n>>> x\\n433\\n\\n>>> x = []\\n>>> for c in S: x.append(ord(c))\\n...\\n>>> x\\n[115, 112, 97, 109]\\n\\n>>> list(map(ord, S))                   # list() required in 3.X, not 2.X\\n[115, 112, 97, 109]\\n>>> [ord(c) for c in S]                 # map and listcomps automate list builders\\n[115, 112, 97, 109]\\n\\n2. Backslash characters. The example prints the bell character (\\\\a) 50 times; assuming\\nyour machine can handle it, and when it’s run outside of IDLE, you may get a series\\nof beeps (or one sustained tone, if your machine is fast enough). Hey—I warned\\nyou.\\n\\n3. Sorting dictionaries. Here’s one way to work through this exercise (see Chapter 8\\nor Chapter 14 if this doesn’t make sense). Remember, you really do have to split\\nup the keys and sort calls like this because sort returns None. In Python 2.2 and\\nlater, you can iterate through dictionary keys directly without calling keys (e.g.,\\n\\nPart III, Statements and Syntax | 1473\\n\\n\\x0cfor key in D:), but the keys list will not be sorted like it is by this code. In more\\nrecent Pythons, you can achieve the same effect with the sorted built-in, too:\\n\\n>>> D = {\\'a\\':1, \\'b\\':2, \\'c\\':3, \\'d\\':4, \\'e\\':5, \\'f\\':6, \\'g\\':7}\\n>>> D\\n{\\'f\\': 6, \\'c\\': 3, \\'a\\': 1, \\'g\\': 7, \\'e\\': 5, \\'d\\': 4, \\'b\\': 2}\\n>>>\\n>>> keys = list(D.keys())              # list() required in 3.X, not in 2.X\\n>>> keys.sort()\\n>>> for key in keys:\\n...     print(key, \\'=>\\', D[key])\\n...\\na => 1\\nb => 2\\nc => 3\\nd => 4\\ne => 5\\nf => 6\\ng => 7\\n\\n>>> for key in sorted(D):              # Better, in more recent Pythons\\n...     print(key, \\'=>\\', D[key])\\n\\n4. Program logic alternatives. Here’s some sample code for the solutions. For step e,\\nassign the result of 2 ** X to a variable outside the loops of steps a and b, and use\\nit inside the loop. Your results may vary a bit; this exercise is mostly designed to\\nget you playing with code alternatives, so anything reasonable gets full credit:\\n\\n# a\\n\\nL = [1, 2, 4, 8, 16, 32, 64]\\nX = 5\\n\\ni = 0\\nwhile i < len(L):\\n    if 2 ** X == L[i]:\\n        print(\\'at index\\', i)\\n        break\\n    i += 1\\nelse:\\n    print(X, \\'not found\\')\\n\\n# b\\n\\nL = [1, 2, 4, 8, 16, 32, 64]\\nX = 5\\n\\nfor p in L:\\n    if (2 ** X) == p:\\n        print((2 ** X), \\'was found at\\', L.index(p))\\n        break\\nelse:\\n    print(X, \\'not found\\')\\n\\n# c\\n\\n1474 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cL = [1, 2, 4, 8, 16, 32, 64]\\nX = 5\\n\\nif (2 ** X) in L:\\n    print((2 ** X), \\'was found at\\', L.index(2 ** X))\\nelse:\\n    print(X, \\'not found\\')\\n\\n# d\\n\\nX = 5\\nL = []\\nfor i in range(7): L.append(2 ** i)\\nprint(L)\\n\\nif (2 ** X) in L:\\n    print((2 ** X), \\'was found at\\', L.index(2 ** X))\\nelse:\\n    print(X, \\'not found\\')\\n\\n# f\\n\\nX = 5\\nL = list(map(lambda x: 2**x, range(7)))      # Or [2**x for x in range(7)]\\nprint(L)                                     # list() to print all in 3.X, not 2.X\\n\\nif (2 ** X) in L:\\n    print((2 ** X), \\'was found at\\', L.index(2 ** X))\\nelse:\\n    print(X, \\'not found\\')\\n\\n5. Code maintenance. There is no fixed solution to show here; see mypydoc.py in the\\n\\nbook’s examples package for my edits on this code as one example.\\n\\nPart IV, Functions and Generators\\nSee “Test Your Knowledge: Part IV Exercises” on page 663 in Chapter 21 for the ex-\\nercises.\\n\\n1. The basics. There’s not much to this one, but notice that using print (and hence\\nyour function) is technically a polymorphic operation, which does the right thing\\nfor each type of object:\\n\\n% python\\n>>> def func(x): print(x)\\n...\\n>>> func(\"spam\")\\nspam\\n>>> func(42)\\n42\\n>>> func([1, 2, 3])\\n[1, 2, 3]\\n\\nPart IV, Functions and Generators\\n\\n| 1475\\n\\n\\x0c>>> func({\\'food\\': \\'spam\\'})\\n{\\'food\\': \\'spam\\'}\\n\\n2. Arguments. Here’s a sample solution. Remember that you have to use print to see\\nresults in the test calls because a file isn’t the same as code typed interactively;\\nPython doesn’t normally echo the results of expression statements in files:\\n\\ndef adder(x, y):\\n    return x + y\\n\\nprint(adder(2, 3))\\nprint(adder(\\'spam\\', \\'eggs\\'))\\nprint(adder([\\'a\\', \\'b\\'], [\\'c\\', \\'d\\']))\\n\\n% python mod.py\\n5\\nspameggs\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\']\\n\\n3. varargs.  Two  alternative  adder  functions  are  shown  in  the  following  file,  add-\\ners.py. The hard part here is figuring out how to initialize an accumulator to an\\nempty value of whatever type is passed in. The first solution uses manual type\\ntesting to look for an integer, and an empty slice of the first argument (assumed to\\nbe a sequence) if the argument is determined not to be an integer. The second\\nsolution uses the first argument to initialize and scan items 2 and beyond, much\\nlike one of the min function variants shown in Chapter 18.\\nThe second solution is better. Both of these assume all arguments are of the same\\ntype, and neither works on dictionaries (as we saw in Part II, + doesn’t work on\\nmixed types or dictionaries). You could add a type test and special code to allow\\ndictionaries, too, but that’s extra credit.\\n\\ndef adder1(*args):\\n    print(\\'adder1\\', end=\\' \\')\\n    if type(args[0]) == type(0):              # Integer?\\n         sum = 0                              # Init to zero\\n    else:                                     # else sequence:\\n         sum = args[0][:0]                    # Use empty slice of arg1\\n    for arg in args:\\n        sum = sum + arg\\n    return sum\\n\\ndef adder2(*args):\\n    print(\\'adder2\\', end=\\' \\')\\n    sum = args[0]                             # Init to arg1\\n    for next in args[1:]:\\n        sum += next                           # Add items 2..N\\n    return sum\\n\\nfor func in (adder1, adder2):\\n    print(func(2, 3, 4))\\n    print(func(\\'spam\\', \\'eggs\\', \\'toast\\'))\\n    print(func([\\'a\\', \\'b\\'], [\\'c\\', \\'d\\'], [\\'e\\', \\'f\\']))\\n\\n1476 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c% python adders.py\\nadder1 9\\nadder1 spameggstoast\\nadder1 [\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\']\\nadder2 9\\nadder2 spameggstoast\\nadder2 [\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\']\\n\\n4. Keywords. Here is my solution to the first and second parts of this exercise (coded\\nin the file mod.py). To iterate over keyword arguments, use the **args form in the\\nfunction header and use a loop (e.g., for x in args.keys(): use args[x]), or use\\nargs.values() to make this the same as summing *args positionals:\\n\\ndef adder(good=1, bad=2, ugly=3):\\n    return good + bad + ugly\\n\\nprint(adder())\\nprint(adder(5))\\nprint(adder(5, 6))\\nprint(adder(5, 6, 7))\\nprint(adder(ugly=7, good=6, bad=5))\\n\\n% python mod.py\\n6\\n10\\n14\\n18\\n18\\n\\n# Second part solutions\\n\\ndef adder1(*args):                  # Sum any number of positional args\\n    tot = args[0]\\n    for arg in args[1:]:\\n        tot += arg\\n    return tot\\n\\ndef adder2(**args):                 # Sum any number of keyword args\\n    argskeys = list(args.keys())    # list needed in 3.X!\\n    tot = args[argskeys[0]]\\n    for key in argskeys[1:]:\\n        tot += args[key]\\n    return tot\\n\\ndef adder3(**args):                 # Same, but convert to list of values\\n    args = list(args.values())      # list needed to index in 3.X!\\n    tot = args[0]\\n    for arg in args[1:]:\\n        tot += arg\\n    return tot\\n\\ndef adder4(**args):                 # Same, but reuse positional version\\n    return adder1(*args.values())\\n\\nprint(adder1(1, 2, 3),       adder1(\\'aa\\', \\'bb\\', \\'cc\\'))\\n\\nPart IV, Functions and Generators\\n\\n| 1477\\n\\n\\x0cprint(adder2(a=1, b=2, c=3), adder2(a=\\'aa\\', b=\\'bb\\', c=\\'cc\\'))\\nprint(adder3(a=1, b=2, c=3), adder3(a=\\'aa\\', b=\\'bb\\', c=\\'cc\\'))\\nprint(adder4(a=1, b=2, c=3), adder4(a=\\'aa\\', b=\\'bb\\', c=\\'cc\\'))\\n\\n5. (and 6.) Dictionary tools. Here are my solutions to exercises 5 and 6 (file dicts.py).\\nThese are just coding exercises, though, because Python 1.5 added the dictionary\\nmethods  D.copy() and  D1.update(D2) to handle things like copying and adding\\n(merging) dictionaries. See Chapter 8 for dict.update examples, and Python’s li-\\nbrary manual or O’Reilly’s Python Pocket Reference for more details. X[:] doesn’t\\nwork for dictionaries, as they’re not sequences (see Chapter 8 for details). Also,\\nremember that if you assign (e = d) rather than copying, you generate a reference\\nto a shared dictionary object; changing d changes e, too:\\n\\ndef copyDict(old):\\n    new = {}\\n    for key in old.keys():\\n        new[key] = old[key]\\n    return new\\n\\ndef addDict(d1, d2):\\n    new = {}\\n    for key in d1.keys():\\n        new[key] = d1[key]\\n    for key in d2.keys():\\n        new[key] = d2[key]\\n    return new\\n\\n% python\\n>>> from dicts import *\\n>>> d = {1: 1, 2: 2}\\n>>> e = copyDict(d)\\n>>> d[2] = \\'?\\'\\n>>> d\\n{1: 1, 2: \\'?\\'}\\n>>> e\\n{1: 1, 2: 2}\\n\\n>>> x = {1: 1}\\n>>> y = {2: 2}\\n>>> z = addDict(x, y)\\n>>> z\\n{1: 1, 2: 2}\\n\\n6. See #5.\\n7. More argument-matching examples. Here is the sort of interaction you should get,\\n\\nalong with comments that explain the matching that goes on:\\n\\ndef f1(a, b): print(a, b)            # Normal args\\n\\ndef f2(a, *b): print(a, b)           # Positional varargs\\n\\ndef f3(a, **b): print(a, b)          # Keyword varargs\\n\\ndef f4(a, *b, **c): print(a, b, c)   # Mixed modes\\n\\n1478 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cdef f5(a, b=2, c=3): print(a, b, c)  # Defaults\\n\\ndef f6(a, b=2, *c): print(a, b, c)   # Defaults and positional varargs\\n\\n% python\\n>>> f1(1, 2)                         # Matched by position (order matters)\\n1 2\\n>>> f1(b=2, a=1)                     # Matched by name (order doesn\\'t matter)\\n1 2\\n\\n>>> f2(1, 2, 3)                      # Extra positionals collected in a tuple\\n1 (2, 3)\\n\\n>>> f3(1, x=2, y=3)                  # Extra keywords collected in a dictionary\\n1 {\\'x\\': 2, \\'y\\': 3}\\n\\n>>> f4(1, 2, 3, x=2, y=3)            # Extra of both kinds\\n1 (2, 3) {\\'x\\': 2, \\'y\\': 3}\\n\\n>>> f5(1)                            # Both defaults kick in\\n1 2 3\\n>>> f5(1, 4)                         # Only one default used\\n1 4 3\\n\\n>>> f6(1)                            # One argument: matches \"a\"\\n1 2 ()\\n>>> f6(1, 3, 4)                      # Extra positional collected\\n1 3 (4,)\\n\\n8. Primes revisited. Here is the primes example, wrapped up in a function and a mod-\\nule (file primes.py) so it can be run multiple times. I added an if test to trap neg-\\natives, 0, and 1. I also changed / to // in this edition to make this solution immune\\nto the Python 3.X / true division changes we studied in Chapter 5, and to enable\\nit  to  support  floating-point  numbers  (uncomment  the  from  statement  and\\nchange // to / to see the differences in 2.X):\\n\\n#from __future__ import division\\n\\ndef prime(y):\\n    if y <= 1:                                       # For some y > 1\\n        print(y, \\'not prime\\')\\n    else:\\n        x = y // 2                                   # 3.X / fails\\n        while x > 1:\\n            if y % x == 0:                           # No remainder?\\n                print(y, \\'has factor\\', x)\\n                break                                # Skip else\\n            x -= 1\\n        else:\\n            print(y, \\'is prime\\')\\n\\nprime(13); prime(13.0)\\nprime(15); prime(15.0)\\n\\nPart IV, Functions and Generators\\n\\n| 1479\\n\\n\\x0cprime(3);  prime(2)\\nprime(1);  prime(-3)\\n\\nHere is the module in action; the // operator allows it to work for floating-point\\nnumbers too, even though it perhaps should not:\\n\\n% python primes.py\\n13 is prime\\n13.0 is prime\\n15 has factor 5\\n15.0 has factor 5.0\\n3 is prime\\n2 is prime\\n1 not prime\\n-3 not prime\\n\\nThis function still isn’t very reusable—it could return values, instead of printing\\n—but it’s enough to run experiments. It’s also not a strict mathematical prime\\n(floating points work), and it’s still inefficient. Improvements are left as exercises\\nfor more mathematically minded readers. (Hint: a for loop over range(y, 1, −1)\\nmay be a bit quicker than the while, but the algorithm is the real bottleneck here.)\\nTo time alternatives, use the homegrown timer or standard library timeit modules\\nand coding patterns like those used in Chapter 21’s timing sections (and see Sol-\\nution 10).\\n\\n9. Iterations and comprehensions. Here is the sort of code you should write; I may\\n\\nhave a preference, but yours may vary:\\n\\n>>> values = [2, 4, 9, 16, 25]\\n>>> import math\\n\\n>>> res = []\\n>>> for x in values: res.append(math.sqrt(x))\\n...\\n>>> res\\n[1.4142135623730951, 2.0, 3.0, 4.0, 5.0]\\n\\n>>> list(map(math.sqrt, values))\\n[1.4142135623730951, 2.0, 3.0, 4.0, 5.0]\\n\\n>>> [math.sqrt(x) for x in values]\\n[1.4142135623730951, 2.0, 3.0, 4.0, 5.0]\\n\\n>>> list(math.sqrt(x) for x in values)\\n[1.4142135623730951, 2.0, 3.0, 4.0, 5.0]\\n\\n10. Timing tools. Here is some code I wrote to time the three square root options, along\\nwith the results in CPythons 3.3 and 2.7 and PyPy 1.9 (which implements Python\\n2.7). Each test takes the best of three runs; each run takes the total time required\\nto call the test function 1,000 times; and each test function iterates 1,000 times.\\nThe last result of each function is printed to verify that all three do the same work:\\n\\n# File timer2.py (2.X and 3.X)\\n...same as listed in Chapter 21...\\n\\n1480 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c# File timesqrt.py\\nimport sys, timer2\\nreps = 10000\\nrepslist = range(reps)              # Pull out range list time for 2.X\\n\\nfrom math import sqrt               # Not math.sqrt: adds attr fetch time\\ndef mathMod():\\n    for i in repslist:\\n        res = sqrt(i)\\n    return res\\n\\ndef powCall():\\n    for i in repslist:\\n        res = pow(i, .5)\\n    return res\\n\\ndef powExpr():\\n    for i in repslist:\\n        res = i ** .5\\n    return res\\n\\nprint(sys.version)\\nfor test in (mathMod, powCall, powExpr):\\n    elapsed, result = timer2.bestoftotal(test, _reps1=3, _reps=1000)\\n    print (\\'%s: %.5f => %s\\' % (test.__name__, elapsed, result))\\n\\nFollowing are the test results for the three Pythons. The 3.3 and 2.7 results are\\nroughly twice as fast as 3.0 and 2.6 in the prior edition, due largely to a faster test\\nmachine. For each Python tested, it looks like the math module is quicker than the\\n** expression, which is quicker than the pow call; however, you should try this with\\nyour code and on your own machine and version of Python. Also, note that Python\\n3.3 is essentially twice as slow as 2.7 on this test, and PyPy is a rough order of\\nmagnitude (10X) faster than both CPythons, despite the fact that this is running\\nfloating-point math and iterations. Later versions of any of these Pythons might\\ndiffer, so time this in the future to see for yourself:\\n\\nc:\\\\code> py −3 timesqrt.py\\n3.3.0 (v3.3.0:bd8afb90ebf2, Sep 29 2012, 10:57:17) [MSC v.1600 64 bit (AMD64)]\\nmathMod: 2.04481 => 99.99499987499375\\npowCall: 3.40973 => 99.99499987499375\\npowExpr: 2.56458 => 99.99499987499375\\n\\nc:\\\\code> py −2 timesqrt.py\\n2.7.3 (default, Apr 10 2012, 23:24:47) [MSC v.1500 64 bit (AMD64)]\\nmathMod: 1.04337 => 99.994999875\\npowCall: 2.57516 => 99.994999875\\npowExpr: 1.89560 => 99.994999875\\n\\nc:\\\\code> c:\\\\pypy\\\\pypy-1.9\\\\pypy timesqrt.py\\n2.7.2 (341e1e3821ff, Jun 07 2012, 15:43:00)\\n[PyPy 1.9.0 with MSC v.1500 32 bit]\\nmathMod: 0.07491 => 99.994999875\\n\\nPart IV, Functions and Generators\\n\\n| 1481\\n\\n\\x0cpowCall: 0.85678 => 99.994999875\\npowExpr: 0.85453 => 99.994999875\\n\\nTo time the relative speeds of Python 3.X and 2.7 dictionary comprehensions and\\nequivalent for loops interactively, you can run a session like the following. It ap-\\npears that the two are roughly the same in this regard under Python 3.3; unlike list\\ncomprehensions, though, manual loops are slightly faster than dictionary com-\\nprehensions today (though the difference isn’t exactly earth-shattering—at the end\\nwe save half a second when making 50 dictionaries of 1,000,000 items each). Again,\\nrather than taking these results as gospel you should investigate further on your\\nown, on your computer and with your Python:\\n\\nC:\\\\code> c:\\\\python33\\\\python\\n>>>\\n>>> def dictcomp(I):\\n        return {i: i for i in range(I)}\\n\\n>>> def dictloop(I):\\n        new = {}\\n        for i in range(I): new[i] = i\\n        return new\\n\\n>>> dictcomp(10)\\n{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\\n>>> dictloop(10)\\n{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\\n>>>\\n>>> from timer2 import total, bestof\\n>>> bestof(dictcomp, 10000)[0]               # 10,000-item dict\\n0.0017095345403959072\\n>>> bestof(dictloop, 10000)[0]\\n0.002097576400046819\\n>>>\\n>>> bestof(dictcomp, 100000)[0]              # 100,000-items: 10X slower\\n0.012716923463358398\\n>>> bestof(dictloop, 100000)[0]\\n0.014129806355413166\\n>>>\\n>>> bestof(dictcomp, 1000000)[0]             # 1 of 1M-items: 10X time\\n0.11614425187337929\\n>>> bestof(dictloop, 1000000)[0]\\n0.1331144855439561\\n>>>\\n>>> total(dictcomp, 1000000, _reps=50)[0]    # Total to make 50 1M-item dicts\\n5.8162020671780965\\n>>> total(dictloop, 1000000, _reps=50)[0]\\n6.626680761285343\\n\\n11. Recursive functions. I coded this function as follows; a simple range, comprehen-\\nsion, or map will do the job here as well, but recursion is useful enough to experiment\\nwith here (print is a function in 3.X only, unless you import it from __future__ or\\ncode your own equivalent):\\n\\n1482 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cdef countdown(N):\\n    if N == 0:\\n        print(\\'stop\\')                 # 2.X: print \\'stop\\'\\n    else:\\n        print(N, end=\\' \\')             # 2.X: print N,\\n        countdown(N-1)\\n\\n>>> countdown(5)\\n5 4 3 2 1 stop\\n>>> countdown(20)\\n20 19 18 17 16 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 stop\\n\\n# Nonrecursive options:\\n>>> list(range(5, 0, −1))\\n[5, 4, 3, 2, 1]\\n\\n# On 3.X only:\\n>>> t = [print(i, end=\\' \\') for i in range(5, 0, −1)]\\n5 4 3 2 1\\n>>> t = list(map(lambda x: print(x, end=\\' \\'), range(5, 0, −1)))\\n5 4 3 2 1\\n\\nI didn’t include a generator-based solution in this exercise on the grounds of merit\\n(and humanity!), but one is listed below; all the other techniques seem much sim-\\npler in this case—a good example of cases where generators should probably be\\navoided. Remember that generators produce no results until iterated, so we need\\na for or yield from here (yield from works in 3.3 and later only):\\n\\ndef countdown2(N):                          # Generator function, recursive\\n    if N == 0:\\n        yield \\'stop\\'\\n    else:\\n        yield N\\n        for x in countdown2(N-1): yield x   # 3.3+: yield from countdown2(N-1)\\n\\n>>> list(countdown2(5))\\n[5, 4, 3, 2, 1, \\'stop\\']\\n\\n# Nonrecursive options:\\n>>> def countdown3():                       # Generator function, simpler\\n        yield from range(5, 0, −1)          # Pre 3.3: for x in range(): yield x\\n\\n>>> list(countdown3())\\n[5, 4, 3, 2, 1]\\n\\n>>> list(x for x in range(5, 0, −1))        # Equivalent generator expression\\n[5, 4, 3, 2, 1]\\n\\n>>> list(range(5, 0, −1))                   # Equivalent nongenerator form\\n[5, 4, 3, 2, 1]\\n\\n12. Computing factorials. The following file shows how I coded this exercise; it runs\\non Python 3.X and 2.X, and its output on 3.3 is given in a string literal at the end\\nof the file. Naturally, there are many possible variations on its code; its ranges, for\\n\\nPart IV, Functions and Generators\\n\\n| 1483\\n\\n\\x0cinstance,  could  run  from  2..N+1  to  skip  an  iteration,  and  fact2  could  use\\nreduce(operator.mul, range(N, 1, −1)) to avoid a lambda.\\n\\n#!python\\nfrom __future__ import print_function                      # File factorials.py\\nfrom functools import reduce\\nfrom timeit import repeat\\nimport math\\n\\ndef fact0(N):                                              # Recursive\\n    if N == 1:                                             # Fails at 999 by default\\n        return N\\n    else:\\n        return N * fact0(N-1)\\n\\ndef fact1(N):\\n    return N if N == 1 else N * fact1(N-1)                 # Recursive, one-liner\\n\\ndef fact2(N):                                              # Functional\\n    return reduce(lambda x, y: x * y, range(1, N+1))\\n\\ndef fact3(N):\\n    res = 1\\n    for i in range(1, N+1): res *= i                       # Iterative\\n    return res\\n\\ndef fact4(N):\\n    return math.factorial(N)                               # Stdlib \"batteries\"\\n\\n# Tests\\nprint(fact0(6), fact1(6), fact2(6), fact3(6), fact4(6))    # 6*5*4*3*2*1: all 720\\nprint(fact0(500) == fact1(500) == fact2(500) == fact3(500) == fact4(500))  # True\\n\\nfor test in (fact0, fact1, fact2, fact3, fact4):\\n    print(test.__name__, min(repeat(stmt=lambda: test(500), number=20, repeat=3)))\\n\\nr\"\"\"\\nC:\\\\code> py −3 factorials.py\\n720 720 720 720 720\\nTrue\\nfact0 0.003990868798355564\\nfact1 0.003901433457907475\\nfact2 0.002732909419593966\\nfact3 0.002052614370939676\\nfact4 0.0003401475243271501\\n\"\"\"\\n\\nConclusions: recursion is slowest on my Python and machine, and fails once N\\nreaches 999 due to the default stack size setting in sys; per Chapter 19, this limit\\ncan be increased, but simple loops or the standard library tool seem the best route\\nhere in any event.\\nThis general finding holds true often. For instance, \\'\\'.join(reversed(S)) may be\\nthe preferred way to reverse a string, even though recursive solutions are possible.\\n\\n1484 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cTime the following to see how: as for factorials in 3.X, recursion is today an order\\nof magnitude slower in CPython, though these results vary in PyPy:\\n\\ndef rev1(S):\\n    if len(S) == 1:\\n        return S\\n    else:\\n        return S[-1] + rev1(S[:-1])        # Recursive: 10x slower in CPython today\\n\\ndef rev2(S):\\n    return \\'\\'.join(reversed(S))            # Nonrecursive iterable: simpler, faster\\n        \\ndef rev3(S):\\n    return S[::-1]                         # Even better?: sequence reversal by slice        \\n        \\n\\nPart V, Modules and Packages\\nSee “Test Your Knowledge: Part V Exercises” on page 778 in Chapter 25 for the exer-\\ncises.\\n\\n1. Import basics. When you’re done, your file (mymod.py) and interaction should look\\nsimilar to the following; remember that Python can read a whole file into a list of\\nline strings, and the len built-in returns the lengths of strings and lists:\\n\\ndef countLines(name):\\n    file = open(name)\\n    return len(file.readlines())\\n\\ndef countChars(name):\\n    return len(open(name).read())\\n\\ndef test(name):                                  # Or pass file object\\n    return countLines(name), countChars(name)    # Or return a dictionary\\n\\n% python\\n>>> import mymod\\n>>> mymod.test(\\'mymod.py\\')\\n(10, 291)\\n\\nYour counts may vary, as mine may or may not include comments and an extra\\nline at the end. Note that these functions load the entire file in memory all at once,\\nso they won’t work for pathologically large files too big for your machine’s memory.\\nTo be more robust, you could read line by line with iterators instead and count as\\nyou go:\\n\\ndef countLines(name):\\n    tot = 0\\n    for line in open(name): tot += 1\\n    return tot\\n\\ndef countChars(name):\\n    tot = 0\\n\\nPart V, Modules and Packages\\n\\n| 1485\\n\\n\\x0c    for line in open(name): tot += len(line)\\n    return tot\\n\\nA generator expression can have the same effect (though the instructor might take\\noff points for excessive magic!):\\n\\ndef countlines(name): return sum(+1 for line in open(name))\\ndef countchars(name): return sum(len(line) for line in open(name))\\n\\nOn Unix, you can verify your output with a wc command; on Windows, right-click\\non your file to view its properties. Note that your script may report fewer characters\\nthan  Windows  does—for  portability,  Python  converts  Windows  \\\\r\\\\n  line-end\\nmarkers to \\\\n, thereby dropping 1 byte (character) per line. To match byte counts\\nwith Windows exactly, you must open in binary mode (\\'rb\\'), or add the number\\nof bytes corresponding to the number of lines. See Chapter 9 and Chapter 37 for\\nmore on end-of-line translations in text files.\\nThe “ambitious” part of this exercise (passing in a file object so you only open the\\nfile once), will require you to use the seek method of the built-in file object. It works\\nlike C’s fseek call (and may call it behind the scenes): seek resets the current po-\\nsition in the file to a passed-in offset. After a seek, future input/output operations\\nare relative to the new position. To rewind to the start of a file without closing and\\nreopening it, call file.seek(0); the file read methods all pick up at the current\\nposition in the file, so you need to rewind to reread. Here’s what this tweak would\\nlook like:\\n\\ndef countLines(file):\\n    file.seek(0)                                 # Rewind to start of file\\n    return len(file.readlines())\\n\\ndef countChars(file):\\n    file.seek(0)                                 # Ditto (rewind if needed)\\n    return len(file.read())\\n\\ndef test(name):\\n    file = open(name)                            # Pass file object\\n    return countLines(file), countChars(file)    # Open file only once\\n\\n>>> import mymod2\\n>>> mymod2.test(\"mymod2.py\")\\n(11, 392)\\n\\n2. from/from *. Here’s the from * part; replace * with countChars to do the rest:\\n\\n% python\\n>>> from mymod import *\\n>>> countChars(\"mymod.py\")\\n291\\n\\n3. __main__. If you code it properly, this file works in either mode—program run or\\n\\nmodule import:\\n\\ndef countLines(name):\\n    file = open(name)\\n\\n1486 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c    return len(file.readlines())\\n\\ndef countChars(name):\\n    return len(open(name).read())\\n\\ndef test(name):                                  # Or pass file object\\n    return countLines(name), countChars(name)    # Or return a dictionary\\n\\nif __name__ == \\'__main__\\':\\n    print(test(\\'mymod.py\\'))\\n\\n% python mymod.py\\n(13, 346)\\n\\nThis is where I would probably begin to consider using command-line arguments\\nor user input to provide the filename to be counted, instead of hardcoding it in the\\nscript (see Chapter 25 for more on sys.argv, and Chapter 10 for more on input—\\nand use raw_input instead in 2.X):\\n\\nif __name__ == \\'__main__\\':\\n    print(test(input(\\'Enter file name:\\'))        # Console (raw_input in 2.X)\\n\\nif __name__ == \\'__main__\\':\\n    import sys                                   # Command line\\n    print(test(sys.argv[1]))\\n\\n4. Nested imports. Here is my solution (file myclient.py):\\n\\nfrom mymod import countLines, countChars\\nprint(countLines(\\'mymod.py\\'), countChars(\\'mymod.py\\'))\\n\\n% python myclient.py\\n13 346\\n\\nAs for the rest of this one, mymod’s functions are accessible (that is, importable) from\\nthe top level of myclient, since from simply assigns to names in the importer (it\\nworks as if mymod’s defs appeared in myclient). For example, another file can say:\\n\\nimport myclient\\nmyclient.countLines(...)\\n\\nfrom myclient import countChars\\ncountChars(...)\\n\\nIf  myclient used  import instead of  from, you’d need to use a path to get to the\\nfunctions in mymod through myclient:\\n\\nimport myclient\\nmyclient.mymod.countLines(...)\\n\\nfrom myclient import mymod\\nmymod.countChars(...)\\n\\nIn general, you can define collector modules that import all the names from other\\nmodules so they’re available in a single convenience module. The following partial\\n\\nPart V, Modules and Packages\\n\\n| 1487\\n\\n\\x0ccode, for example, creates three different copies of the name somename—mod1.some\\nname, collector.somename, and __main__.somename; all three share the same integer\\nobject initially, and only the name somename exists at the interactive prompt as is:\\n\\n# File mod1.py\\nsomename = 42\\n\\n# File collector.py\\nfrom mod1 import *                               # Collect lots of names here\\nfrom mod2 import *                               # from assigns to my names\\nfrom mod3 import *\\n\\n>>> from collector import somename\\n\\n5. Package imports. For this, I put the mymod.py solution file listed for exercise 3 into\\na directory package. The following is what I did in a Windows console interface to\\nset up the directory and the __init__.py file that it’s required to have until Python\\n3.3; you’ll need to interpolate for other platforms (e.g., use cp and vi instead of\\ncopy and notepad). This works in any directory (I’m using my own code directory\\nhere), and you can do some of this from a file explorer GUI, too.\\nWhen  I  was  done,  I  had  a  mypkg  subdirectory  that  contained  the  files\\n__init__.py and mymod.py. Until Python 3.3’s namespace package extension, you\\nneed  an  __init__.py  in  the  mypkg  directory,  but  not  in  its  parent;  technically,\\nmypkg is located in the home directory component of the module search path.\\nNotice how a print statement coded in the directory’s initialization file fires only\\nthe first time it is imported, not the second; raw strings are also used here to avoid\\nescape issues in the file paths:\\n\\nC:\\\\code> mkdir mypkg\\nC:\\\\code> copy mymod.py mypkg\\\\mymod.py\\nC:\\\\code> notepad mypkg\\\\__init__.py\\n...coded a print statement...\\n\\nC:\\\\code> python\\n>>> import mypkg.mymod\\ninitializing mypkg\\n>>> mypkg.mymod.countLines(r\\'mypkg\\\\mymod.py\\')\\n13\\n>>> from mypkg.mymod import countChars\\n>>> countChars(r\\'mypkg\\\\mymod.py\\')\\n346\\n\\n6. Reloads. This exercise just asks you to experiment with changing the changer.py\\n\\nexample in the book, so there’s nothing to show here.\\n\\n7. Circular imports. The short story is that importing recur2 first works because the\\n\\nrecursive import then happens at the import in recur1, not at a from in recur2.\\nThe long story goes like this: importing recur2 first works because the recursive\\nimport from recur1 to recur2 fetches recur2 as a whole, instead of getting specific\\nnames. recur2 is incomplete when it’s imported from recur1, but because it uses\\nimport instead of from, you’re safe: Python finds and returns the already created\\n\\n1488 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0crecur2 module object and continues to run the rest of  recur1 without a glitch.\\nWhen the recur2 import resumes, the second from finds the name Y in recur1 (it’s\\nbeen run completely), so no error is reported.\\nRunning a file as a script is not the same as importing it as a module; these cases\\nare  the  same  as  running  the  first  import  or  from  in  the  script  interactively.  For\\ninstance, running recur1 as a script works, because it is the same as importing\\nrecur2  interactively,  as  recur2  is  the  first  module  imported  in  recur1.  Running\\nrecur2 as a script fails for the same reason—it’s the same as running its first import\\ninteractively.\\n\\nPart VI, Classes and OOP\\nSee “Test Your Knowledge: Part VI Exercises” on page 1072 in Chapter 32 for the\\nexercises.\\n\\n1. Inheritance. Here’s the solution code for this exercise (file adder.py), along with\\nsome interactive tests. The __add__ overload has to appear only once, in the su-\\nperclass, as it invokes type-specific add methods in subclasses:\\n\\nclass Adder:\\n    def add(self, x, y):\\n        print(\\'not implemented!\\')\\n    def __init__(self, start=[]):\\n        self.data = start\\n    def __add__(self, other):                    # Or in subclasses?\\n        return self.add(self.data, other)        # Or return type?\\n\\nclass ListAdder(Adder):\\n    def add(self, x, y):\\n        return x + y\\n\\nclass DictAdder(Adder):\\n    def add(self, x, y):\\n        new = {}\\n        for k in x.keys(): new[k] = x[k]\\n        for k in y.keys(): new[k] = y[k]\\n        return new\\n\\n% python\\n>>> from adder import *\\n>>> x = Adder()\\n>>> x.add(1, 2)\\nnot implemented!\\n>>> x = ListAdder()\\n>>> x.add([1], [2])\\n[1, 2]\\n>>> x = DictAdder()\\n>>> x.add({1:1}, {2:2})\\n{1: 1, 2: 2}\\n\\n>>> x = Adder([1])\\n\\nPart VI, Classes and OOP | 1489\\n\\n\\x0c>>> x + [2]\\nnot implemented!\\n>>>\\n>>> x = ListAdder([1])\\n>>> x + [2]\\n[1, 2]\\n>>> [2] + x\\nIn 3.3:  TypeError: can only concatenate list (not \"ListAdder\") to list\\nEarlier: TypeError: __add__ nor __radd__ defined for these operands\\n\\nNotice in the last test that you get an error for expressions where a class instance\\nappears on the right of a +; if you want to fix this, use __radd__ methods, as de-\\nscribed in “Operator Overloading” in Chapter 30.\\nIf you are saving a value in the instance anyhow, you might as well rewrite the\\nadd method to take just one argument, in the spirit of other examples in this part\\nof the book (this is adder2.py):\\n\\nclass Adder:\\n    def __init__(self, start=[]):\\n        self.data = start\\n    def __add__(self, other):              # Pass a single argument\\n        return self.add(other)             # The left side is in self\\n    def add(self, y):\\n        print(\\'not implemented!\\')\\n\\nclass ListAdder(Adder):\\n    def add(self, y):\\n        return self.data + y\\n\\nclass DictAdder(Adder):\\n    def add(self, y):\\n        d = self.data.copy()               # Change to use self.data instead of x\\n        d.update(y)                        # Or \"cheat\" by using quicker built-ins\\n        return d\\n\\nx = ListAdder([1, 2, 3])\\ny = x + [4, 5, 6]\\nprint(y)                                   # Prints [1, 2, 3, 4, 5, 6]\\n\\nz = DictAdder(dict(name=\\'Bob\\')) + {\\'a\\':1}\\nprint(z)                                   # Prints {\\'name\\': \\'Bob\\', \\'a\\': 1}\\n\\nBecause values are attached to objects rather than passed around, this version is\\narguably more object-oriented. And, once you’ve gotten to this point, you’ll prob-\\nably  find  that  you  can  get  rid  of  add  altogether  and  simply  define  type-specific\\n__add__ methods in the two subclasses.\\n\\n2. Operator overloading. The solution code (file mylist.py) uses a handful of operator\\noverloading methods we explored in Chapter 30. Copying the initial value in the\\nconstructor is important because it may be mutable; you don’t want to change or\\nhave a reference to an object that’s possibly shared somewhere outside the class.\\nThe __getattr__ method routes calls to the wrapped list. For hints on an easier\\n\\n1490 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cway  to  code  this  in  Python  2.2  and  later,  see  “Extending  Types  by  Subclass-\\ning” on page 981 in Chapter 32:\\n\\nclass MyList:\\n    def __init__(self, start):\\n        #self.wrapped = start[:]                  # Copy start: no side effects\\n        self.wrapped = list(start)                # Make sure it\\'s a list here\\n    def __add__(self, other):\\n        return MyList(self.wrapped + other)\\n    def __mul__(self, time):\\n        return MyList(self.wrapped * time)\\n    def __getitem__(self, offset):                # Also passed a slice in 3.X\\n        return self.wrapped[offset]               # For iteration if no __iter__\\n    def __len__(self):\\n        return len(self.wrapped)\\n    def __getslice__(self, low, high):            # Ignored in 3.X: uses __getitem__\\n        return MyList(self.wrapped[low:high])\\n    def append(self, node):\\n        self.wrapped.append(node)\\n    def __getattr__(self, name):                  # Other methods: sort/reverse/etc\\n        return getattr(self.wrapped, name)\\n    def __repr__(self):                           # Catchall display method\\n        return repr(self.wrapped)\\n\\nif __name__ == \\'__main__\\':\\n    x = MyList(\\'spam\\')\\n    print(x)\\n    print(x[2])\\n    print(x[1:])\\n    print(x + [\\'eggs\\'])\\n    print(x * 3)\\n    x.append(\\'a\\')\\n    x.sort()\\n    print(\\' \\'.join(c for c in x))\\n\\nc:\\\\code> python mylist.py\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\']\\na\\n[\\'p\\', \\'a\\', \\'m\\']\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\', \\'eggs\\']\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\', \\'s\\', \\'p\\', \\'a\\', \\'m\\', \\'s\\', \\'p\\', \\'a\\', \\'m\\']\\na a m p s\\n\\nNote that it’s important to copy the start value by calling list instead of slicing\\nhere, because otherwise the result may not be a true list and so will not respond to\\nexpected list methods, such as append (e.g., slicing a string returns another string,\\nnot a list). You would be able to copy a MyList start value by slicing because its\\nclass overloads the slicing operation and provides the expected list interface; how-\\never, you need to avoid slice-based copying for objects such as strings.\\n\\n3. Subclassing. My solution (mysub.py) appears as follows. Your solution should be\\n\\nsimilar:\\n\\nPart VI, Classes and OOP | 1491\\n\\n\\x0cfrom mylist import MyList\\n\\nclass MyListSub(MyList):\\n    calls = 0                                      # Shared by instances\\n    def __init__(self, start):\\n        self.adds = 0                              # Varies in each instance\\n        MyList.__init__(self, start)\\n\\n    def __add__(self, other):\\n        print(\\'add: \\' + str(other))\\n        MyListSub.calls += 1                       # Class-wide counter\\n        self.adds += 1                             # Per-instance counts\\n        return MyList.__add__(self, other)\\n\\n    def stats(self):\\n        return self.calls, self.adds               # All adds, my adds\\n\\nif __name__ == \\'__main__\\':\\n    x = MyListSub(\\'spam\\')\\n    y = MyListSub(\\'foo\\')\\n    print(x[2])\\n    print(x[1:])\\n    print(x + [\\'eggs\\'])\\n    print(x + [\\'toast\\'])\\n    print(y + [\\'bar\\'])\\n    print(x.stats())\\n\\nc:\\\\code> python mysub.py\\na\\n[\\'p\\', \\'a\\', \\'m\\']\\nadd: [\\'eggs\\']\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\', \\'eggs\\']\\nadd: [\\'toast\\']\\n[\\'s\\', \\'p\\', \\'a\\', \\'m\\', \\'toast\\']\\nadd: [\\'bar\\']\\n[\\'f\\', \\'o\\', \\'o\\', \\'bar\\']\\n(3, 2)\\n\\n4. Attribute methods. I worked through this exercise as follows. Notice that in Python\\n2.X’s classic classes, operators try to fetch attributes through __getattr__, too; you\\nneed to return a value to make them work. As noted in Chapter 32 and elsewhere,\\n__getattr__ is not called for built-in operations in Python 3.X (and in 2.X if new-\\nstyle classes are used), so the expressions aren’t intercepted at all here; in new-style\\nclasses, a class like this must redefine __X__ operator overloading methods explic-\\nitly. More on this in Chapter 28, Chapter 31, Chapter 32, Chapter 38, and Chap-\\nter 39: it can impact much code!\\n\\nc:\\\\code> py −2\\n>>> class Attrs:\\n        def __getattr__(self, name):\\n            print(\\'get %s\\' % name)\\n        def __setattr__(self, name, value):\\n            print(\\'set %s %s\\' % (name, value))\\n\\n1492 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c>>> x = Attrs()\\n>>> x.append\\nget append\\n>>> x.spam = \\'pork\\'\\nset spam pork\\n>>> x + 2\\nget __coerce__\\nTypeError: \\'NoneType\\' object is not callable\\n>>> x[1]\\nget __getitem__\\nTypeError: \\'NoneType\\' object is not callable\\n>>> x[1:5]\\nget __getslice__\\nTypeError: \\'NoneType\\' object is not callable\\n\\nc:\\\\code> py −3\\n>>> ...same startup code...\\n>>> x + 2\\nTypeError: unsupported operand type(s) for +: \\'Attrs\\' and \\'int\\'\\n>>> x[1]\\nTypeError: \\'Attrs\\' object does not support indexing\\n>>> x[1:5]\\nTypeError: \\'Attrs\\' object is not subscriptable\\n\\n5. Set objects. Here’s the sort of interaction you should get. Comments explain which\\nmethods are called. Also, note that sets are a built-in type in Python today, so this\\nis largely just a coding exercise (see Chapter 5 for more on sets).\\n\\n% python\\n>>> from setwrapper import Set\\n>>> x = Set([1, 2, 3, 4])          # Runs __init__\\n>>> y = Set([3, 4, 5])\\n\\n>>> x & y                          # __and__, intersect, then __repr__\\nSet:[3, 4]\\n>>> x | y                          # __or__, union, then __repr__\\nSet:[1, 2, 3, 4, 5]\\n\\n>>> z = Set(\"hello\")               # __init__ removes duplicates\\n>>> z[0], z[-1], z[2:]             # __getitem__\\n(\\'h\\', \\'o\\', [\\'l\\', \\'o\\'])\\n\\n>>> for c in z: print(c, end=\\' \\')  # __iter__ (else __getitem__)   [3.X print]\\n...\\nh e l o\\n>>> \\'\\'.join(c.upper() for c in z)  # __iter__ (else __getitem__)\\n\\'HELO\\'\\n>>> len(z), z                      # __len__, __repr__\\n(4, Set:[\\'h\\', \\'e\\', \\'l\\', \\'o\\'])\\n\\n>>> z & \"mello\", z | \"mello\"\\n(Set:[\\'e\\', \\'l\\', \\'o\\'], Set:[\\'h\\', \\'e\\', \\'l\\', \\'o\\', \\'m\\'])\\n\\nPart VI, Classes and OOP | 1493\\n\\n\\x0cMy solution to the multiple-operand extension subclass looks like the following\\nclass (file multiset.py). It needs to replace only two methods in the original set. The\\nclass’s documentation string explains how it works:\\n\\nfrom setwrapper import Set\\n\\nclass MultiSet(Set):\\n    \"\"\"\\n    Inherits all Set names, but extends intersect and union to support\\n    multiple operands; note that \"self\" is still the first argument\\n    (stored in the *args argument now); also note that the inherited\\n    & and | operators call the new methods here with 2 arguments, but\\n    processing more than 2 requires a method call, not an expression;\\n    intersect doesn\\'t remove duplicates here: the Set constructor does;\\n    \"\"\"\\n    def intersect(self, *others):\\n        res = []\\n        for x in self:                         # Scan first sequence\\n            for other in others:               # For all other args\\n                if x not in other: break       # Item in each one?\\n            else:                              # No: break out of loop\\n                res.append(x)                  # Yes: add item to end\\n        return Set(res)\\n\\n    def union(*args):                          # self is args[0]\\n        res = []\\n        for seq in args:                       # For all args\\n            for x in seq:                      # For all nodes\\n                if not x in res:\\n                    res.append(x)              # Add new items to result\\n        return Set(res)\\n\\nYour interaction with the extension will look something like the following. Note\\nthat you can intersect by using  & or calling  intersect, but you must call  inter\\nsect for three or more operands; & is a binary (two-sided) operator. Also, note that\\nwe could have called MultiSet simply Set to make this change more transparent if\\nwe used setwrapper.Set to refer to the original within multiset (the as clause in an\\nimport could rename the class too if desired):\\n\\n>>> from multiset import *\\n>>> x = MultiSet([1, 2, 3, 4])\\n>>> y = MultiSet([3, 4, 5])\\n>>> z = MultiSet([0, 1, 2])\\n\\n>>> x & y, x | y                               # Two operands\\n(Set:[3, 4], Set:[1, 2, 3, 4, 5])\\n\\n>>> x.intersect(y, z)                          # Three operands\\nSet:[]\\n>>> x.union(y, z)\\nSet:[1, 2, 3, 4, 5, 0]\\n>>> x.intersect([1,2,3], [2,3,4], [1,2,3])     # Four operands\\nSet:[2, 3]\\n>>> x.union(range(10))                         # Non-MultiSets work, too\\n\\n1494 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cSet:[1, 2, 3, 4, 0, 5, 6, 7, 8, 9]\\n\\n>>> w = MultiSet(\\'spam\\')                       # String sets\\n>>> w\\nSet:[\\'s\\', \\'p\\', \\'a\\', \\'m\\']\\n>>> \\'\\'.join(w | \\'super\\')\\n\\'spamuer\\'\\n>>> (w | \\'super\\') & MultiSet(\\'slots\\')\\nSet:[\\'s\\']\\n\\n6. Class tree links. Here is the way I changed the lister classes, and a rerun of the test\\nto show its format. Do the same for the dir-based version, and also do this when\\nformatting class objects in the tree climber variant:\\n\\nclass ListInstance:\\n    def __attrnames(self):\\n        ...unchanged...\\n\\n    def __str__(self):\\n        return \\'<Instance of %s(%s), address %s:\\\\n%s>\\' % (\\n                           self.__class__.__name__,       # My class\\'s name\\n                           self.__supers(),               # My class\\'s own supers\\n                           id(self),                      # My address\\n                           self.__attrnames())            # name=value list\\n\\n    def __supers(self):\\n        names = []\\n        for super in self.__class__.__bases__:            # One level up from class\\n            names.append(super.__name__)                  # name, not str(super)\\n        return \\', \\'.join(names)\\n\\n    # Or: \\', \\'.join(super.__name__ for super in self.__class__.__bases__)\\n\\nc:\\\\code> py listinstance-exercise.py\\n<Instance of Sub(Super, ListInstance), address 43671000:\\n        data1=spam\\n        data2=eggs\\n        data3=42\\n>\\n\\n7. Composition. My solution is as follows (file lunch.py), with comments from the\\ndescription mixed in with the code. This is one case where it’s probably easier to\\nexpress a problem in Python than it is in English:\\n\\nclass Lunch:\\n    def __init__(self):                          # Make/embed Customer, Employee\\n        self.cust = Customer()\\n        self.empl = Employee()\\n    def order(self, foodName):                   # Start Customer order simulation\\n        self.cust.placeOrder(foodName, self.empl)\\n    def result(self):                            # Ask the Customer about its Food\\n        self.cust.printFood()\\n\\nclass Customer:\\n    def __init__(self):                          # Initialize my food to None\\n        self.food = None\\n\\nPart VI, Classes and OOP | 1495\\n\\n\\x0c    def placeOrder(self, foodName, employee):    # Place order with Employee\\n        self.food = employee.takeOrder(foodName)\\n    def printFood(self):                         # Print the name of my food\\n        print(self.food.name)\\n\\nclass Employee:\\n    def takeOrder(self, foodName):               # Return Food, with desired name\\n        return Food(foodName)\\n\\nclass Food:\\n    def __init__(self, name):                    # Store food name\\n        self.name = name\\n\\nif __name__ == \\'__main__\\':\\n    x = Lunch()                                  # Self-test code\\n    x.order(\\'burritos\\')                          # If run, not imported\\n    x.result()\\n    x.order(\\'pizza\\')\\n    x.result()\\n\\n% python lunch.py\\nburritos\\npizza\\n\\n8. Zoo  animal  hierarchy.  Here  is  the  way  I  coded  the  taxonomy  in  Python  (file\\nzoo.py); it’s artificial, but the general coding pattern applies to many real structures,\\nfrom GUIs to employee databases to spacecraft. Notice that the self.speak refer-\\nence in Animal triggers an independent inheritance search, which finds speak in a\\nsubclass. Test this interactively per the exercise description. Try extending this\\nhierarchy with new classes, and making instances of various classes in the tree:\\n\\nclass Animal:\\n    def reply(self):   self.speak()              # Back to subclass\\n    def speak(self):   print(\\'spam\\')             # Custom message\\n\\nclass Mammal(Animal):\\n    def speak(self):   print(\\'huh?\\')\\n\\nclass Cat(Mammal):\\n    def speak(self):   print(\\'meow\\')\\n\\nclass Dog(Mammal):\\n    def speak(self):   print(\\'bark\\')\\n\\nclass Primate(Mammal):\\n    def speak(self):   print(\\'Hello world!\\')\\n\\nclass Hacker(Primate): pass                      # Inherit from Primate\\n\\n9. The Dead Parrot Sketch. Here’s how I implemented this one (file parrot.py). Notice\\nhow the line method in the Actor superclass works: by accessing self attributes\\ntwice, it sends Python back to the instance twice, and hence invokes two inheritance\\nsearches—self.name and self.says() find information in the specific subclasses:\\n\\n1496 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cclass Actor:\\n    def line(self): print(self.name + \\':\\', repr(self.says()))\\n\\nclass Customer(Actor):\\n    name = \\'customer\\'\\n    def says(self): return \"that\\'s one ex-bird!\"\\n\\nclass Clerk(Actor):\\n    name = \\'clerk\\'\\n    def says(self): return \"no it isn\\'t...\"\\n\\nclass Parrot(Actor):\\n    name = \\'parrot\\'\\n    def says(self): return None\\n\\nclass Scene:\\n    def __init__(self):\\n        self.clerk    = Clerk()                  # Embed some instances\\n        self.customer = Customer()               # Scene is a composite\\n        self.subject  = Parrot()\\n\\n    def action(self):\\n        self.customer.line()                     # Delegate to embedded\\n        self.clerk.line()\\n        self.subject.line()\\n\\nPart VII, Exceptions and Tools\\nSee “Test Your Knowledge: Part VII Exercises” on page 1161 in Chapter 36 for the\\nexercises.\\n\\n1. try/except. My version of the oops function (file oops.py) follows. As for the non-\\ncoding questions, changing oops to raise a KeyError instead of an IndexError means\\nthat the try handler won’t catch the exception—it “percolates” to the top level and\\ntriggers Python’s default error message. The names KeyError and IndexError come\\nfrom the outermost built-in names scope (the B in “LEGB”). Import builtins in\\n3.X (and __builtin__ in Python 2.X) and pass it as an argument to the dir function\\nto see this for yourself.\\n\\ndef oops():\\n    raise IndexError()\\n\\ndef doomed():\\n    try:\\n        oops()\\n    except IndexError:\\n        print(\\'caught an index error!\\')\\n    else:\\n        print(\\'no error caught...\\')\\n\\nif __name__ == \\'__main__\\': doomed()\\n\\nPart VII, Exceptions and Tools\\n\\n| 1497\\n\\n\\x0c% python oops.py\\ncaught an index error!\\n\\n2. Exception objects and lists. Here’s the way I extended this module for an exception\\n\\nof my own, file oops2.py:\\n\\nfrom __future__ import print_function  # 2.X\\n\\nclass MyError(Exception): pass\\n\\ndef oops():\\n    raise MyError(\\'Spam!\\')\\n\\ndef doomed():\\n    try:\\n        oops()\\n    except IndexError:\\n        print(\\'caught an index error!\\')\\n    except MyError as data:\\n        print(\\'caught error:\\', MyError, data)\\n    else:\\n        print(\\'no error caught...\\')\\n\\nif __name__ == \\'__main__\\':\\n    doomed()\\n\\n% python oops2.py\\ncaught error: <class \\'__main__.MyError\\'> Spam!\\n\\nLike all class exceptions, the instance is accessible via the as variable data; the error\\nmessage shows both the class (<...>) and its instance (Spam!). The instance must\\nbe  inheriting  both  an  __init__  and  a  __repr__  or  __str__  from  Python’s  Excep\\ntion class, or it would print much like the class does. See Chapter 35 for details on\\nhow this works in built-in exception classes.\\n\\n3. Error handling. Here’s one way to solve this one (file exctools.py). I did my tests in\\na file, rather than interactively, but the results are similar enough for full credit.\\nNotice that the empty except and sys.exc_info approach used here will catch exit-\\nrelated exceptions that listing Exception with an as variable won’t; that’s probably\\nnot ideal in most applications code, but might be useful in a tool like this designed\\nto work as a sort of exceptions firewall.\\n\\nimport sys, traceback\\n\\ndef safe(callee, *pargs, **kargs):\\n    try:\\n        callee(*pargs, **kargs)            # Catch everything else\\n    except:                                # Or \"except Exception as E:\"\\n        traceback.print_exc()\\n        print(\\'Got %s %s\\' % (sys.exc_info()[0], sys.exc_info()[1]))\\n\\nif __name__ == \\'__main__\\':\\n    import oops2\\n    safe(oops2.oops)\\n\\n1498 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cc:\\\\code> py −3 exctools.py\\nTraceback (most recent call last):\\n  File \"C:\\\\code\\\\exctools.py\", line 5, in safe\\n    callee(*pargs, **kargs)            # Catch everything else\\n  File \"C:\\\\code\\\\oops2.py\", line 6, in oops\\n    raise MyError(\\'Spam!\\')\\noops2.MyError: Spam!\\nGot <class \\'oops2.MyError\\'> Spam!\\n\\nThe following sort of code could turn this into a function decorator that could wrap\\nand  catch  exceptions  raised  by  any  function,  using  techniques  introduced  in\\nChapter 32, but covered more fully in Chapter 39 in the next part of the book—it\\naugments a function, rather than expecting it to be passed in explicitly:\\n\\nimport sys, traceback\\n\\ndef safe(callee):\\n    def callproxy(*pargs, **kargs):\\n        try:\\n            return callee(*pargs, **kargs)\\n        except:\\n            traceback.print_exc()\\n            print(\\'Got %s %s\\' % (sys.exc_info()[0], sys.exc_info()[1]))\\n            raise\\n    return callproxy\\n\\nif __name__ == \\'__main__\\':\\n    import oops2\\n\\n    @safe\\n    def test():\\n        oops2.oops()\\n\\n    test()\\n\\n4. Self-study examples. Here are a few examples for you to study as time allows; for\\nmore, see follow-up books—such as Programming Python, from which these ex-\\namples were borrowed or derived—and the Web:\\n\\n# Find the largest Python source file in a single directory\\n\\nimport os, glob\\ndirname = r\\'C:\\\\Python33\\\\Lib\\'\\n\\nallsizes = []\\nallpy = glob.glob(dirname + os.sep + \\'*.py\\')\\nfor filename in allpy:\\n    filesize = os.path.getsize(filename)\\n    allsizes.append((filesize, filename))\\n\\nallsizes.sort()\\nprint(allsizes[:2])\\nprint(allsizes[-2:])\\n\\nPart VII, Exceptions and Tools\\n\\n| 1499\\n\\n\\x0c# Find the largest Python source file in an entire directory tree\\n\\nimport sys, os, pprint\\nif sys.platform[:3] == \\'win\\':\\n    dirname = r\\'C:\\\\Python33\\\\Lib\\'\\nelse:\\n    dirname = \\'/usr/lib/python\\'\\n\\nallsizes = []\\nfor (thisDir, subsHere, filesHere) in os.walk(dirname):\\n    for filename in filesHere:\\n        if filename.endswith(\\'.py\\'):\\n            fullname = os.path.join(thisDir, filename)\\n            fullsize = os.path.getsize(fullname)\\n            allsizes.append((fullsize, fullname))\\n\\nallsizes.sort()\\npprint.pprint(allsizes[:2])\\npprint.pprint(allsizes[-2:])\\n\\n# Find the largest Python source file on the module import search path\\n\\nimport sys, os, pprint\\nvisited  = {}\\nallsizes = []\\nfor srcdir in sys.path:\\n    for (thisDir, subsHere, filesHere) in os.walk(srcdir):\\n        thisDir = os.path.normpath(thisDir)\\n        if thisDir.upper() in visited:\\n            continue\\n        else:\\n            visited[thisDir.upper()] = True\\n        for filename in filesHere:\\n            if filename.endswith(\\'.py\\'):\\n                pypath  = os.path.join(thisDir, filename)\\n                try:\\n                    pysize = os.path.getsize(pypath)\\n                except:\\n                    print(\\'skipping\\', pypath)\\n                allsizes.append((pysize, pypath))\\n\\nallsizes.sort()\\npprint.pprint(allsizes[:3])\\npprint.pprint(allsizes[-3:])\\n\\n# Sum columns in a text file separated by commas\\n\\nfilename = \\'data.txt\\'\\nsums = {}\\n\\nfor line in open(filename):\\n    cols = line.split(\\',\\')\\n\\n1500 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c    nums = [int(col) for col in cols]\\n    for (ix, num) in enumerate(nums):\\n        sums[ix] = sums.get(ix, 0) + num\\n\\nfor key in sorted(sums):\\n    print(key, \\'=\\', sums[key])\\n\\n# Similar to prior, but using lists instead of dictionaries for sums\\n\\nimport sys\\nfilename = sys.argv[1]\\nnumcols  = int(sys.argv[2])\\ntotals   = [0] * numcols\\n\\nfor line in open(filename):\\n    cols = line.split(\\',\\')\\n    nums = [int(x) for x in cols]\\n    totals = [(x + y) for (x, y) in zip(totals, nums)]\\n\\nprint(totals)\\n\\n# Test for regressions in the output of a set of scripts\\n\\nimport os\\ntestscripts = [dict(script=\\'test1.py\\', args=\\'\\'),       # Or glob script/args dir\\n               dict(script=\\'test2.py\\', args=\\'spam\\')]\\n\\nfor testcase in testscripts:\\n    commandline = \\'%(script)s %(args)s\\' % testcase\\n    output = os.popen(commandline).read()\\n    result = testcase[\\'script\\'] + \\'.result\\'\\n    if not os.path.exists(result):\\n        open(result, \\'w\\').write(output)\\n        print(\\'Created:\\', result)\\n    else:\\n        priorresult = open(result).read()\\n        if output != priorresult:\\n            print(\\'FAILED:\\', testcase[\\'script\\'])\\n            print(output)\\n        else:\\n            print(\\'Passed:\\', testcase[\\'script\\'])\\n\\n# Build GUI with tkinter (Tkinter in 2.X) with buttons that change color and grow\\n\\nfrom tkinter import *                                  # Use Tkinter in 2.X\\nimport random\\nfontsize = 25\\ncolors = [\\'red\\', \\'green\\', \\'blue\\', \\'yellow\\', \\'orange\\', \\'white\\', \\'cyan\\', \\'purple\\']\\n\\ndef reply(text):\\n    print(text)\\n    popup = Toplevel()\\n\\nPart VII, Exceptions and Tools\\n\\n| 1501\\n\\n\\x0c    color = random.choice(colors)\\n    Label(popup, text=\\'Popup\\', bg=\\'black\\', fg=color).pack()\\n    L.config(fg=color)\\n\\ndef timer():\\n    L.config(fg=random.choice(colors))\\n    win.after(250, timer)\\n\\ndef grow():\\n    global fontsize\\n    fontsize += 5\\n    L.config(font=(\\'arial\\', fontsize, \\'italic\\'))\\n    win.after(100, grow)\\n\\nwin = Tk()\\nL = Label(win, text=\\'Spam\\',\\n          font=(\\'arial\\', fontsize, \\'italic\\'), fg=\\'yellow\\', bg=\\'navy\\',\\n          relief=RAISED)\\nL.pack(side=TOP, expand=YES, fill=BOTH)\\nButton(win, text=\\'press\\', command=(lambda: reply(\\'red\\'))).pack(side=BOTTOM, fill=X)\\nButton(win, text=\\'timer\\', command=timer).pack(side=BOTTOM, fill=X)\\nButton(win, text=\\'grow\\', command=grow).pack(side=BOTTOM, fill=X)\\nwin.mainloop()\\n\\n# Similar to prior, but use classes so each window has own state information\\n\\nfrom tkinter import *\\nimport random\\n\\nclass MyGui:\\n    \"\"\"\\n    A GUI with buttons that change color and make the label grow\\n    \"\"\"\\n    colors = [\\'blue\\', \\'green\\', \\'orange\\', \\'red\\', \\'brown\\', \\'yellow\\']\\n\\n    def __init__(self, parent, title=\\'popup\\'):\\n        parent.title(title)\\n        self.growing = False\\n        self.fontsize = 10\\n        self.lab = Label(parent, text=\\'Gui1\\', fg=\\'white\\', bg=\\'navy\\')\\n        self.lab.pack(expand=YES, fill=BOTH)\\n        Button(parent, text=\\'Spam\\', command=self.reply).pack(side=LEFT)\\n        Button(parent, text=\\'Grow\\', command=self.grow).pack(side=LEFT)\\n        Button(parent, text=\\'Stop\\', command=self.stop).pack(side=LEFT)\\n\\n    def reply(self):\\n        \"change the button\\'s color at random on Spam presses\"\\n        self.fontsize += 5\\n        color = random.choice(self.colors)\\n        self.lab.config(bg=color,\\n                font=(\\'courier\\', self.fontsize, \\'bold italic\\'))\\n\\n    def grow(self):\\n        \"start making the label grow on Grow presses\"\\n\\n1502 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0c        self.growing = True\\n        self.grower()\\n\\n    def grower(self):\\n        if self.growing:\\n            self.fontsize += 5\\n            self.lab.config(font=(\\'courier\\', self.fontsize, \\'bold\\'))\\n            self.lab.after(500, self.grower)\\n\\n    def stop(self):\\n        \"stop the button growing on Stop presses\"\\n        self.growing = False\\n\\nclass MySubGui(MyGui):\\n    colors = [\\'black\\', \\'purple\\']           # Customize to change color choices\\n\\nMyGui(Tk(), \\'main\\')\\nMyGui(Toplevel())\\nMySubGui(Toplevel())\\nmainloop()\\n\\n# Email inbox scanning and maintenance utility\\n\\n\"\"\"\\nscan pop email box, fetching just headers, allowing\\ndeletions without downloading the complete message\\n\"\"\"\\n\\nimport poplib, getpass, sys\\n\\nmailserver = \\'your pop email server name here\\'                 # pop.server.net\\nmailuser   = \\'your pop email user name here\\'\\nmailpasswd = getpass.getpass(\\'Password for %s?\\' % mailserver)\\n\\nprint(\\'Connecting...\\')\\nserver = poplib.POP3(mailserver)\\nserver.user(mailuser)\\nserver.pass_(mailpasswd)\\n\\ntry:\\n    print(server.getwelcome())\\n    msgCount, mboxSize = server.stat()\\n    print(\\'There are\\', msgCount, \\'mail messages, size \\', mboxSize)\\n    msginfo = server.list()\\n    print(msginfo)\\n    for i in range(msgCount):\\n        msgnum  = i+1\\n        msgsize = msginfo[1][i].split()[1]\\n        resp, hdrlines, octets = server.top(msgnum, 0)         # Get hdrs only\\n        print(\\'-\\'*80)\\n        print(\\'[%d: octets=%d, size=%s]\\' % (msgnum, octets, msgsize))\\n        for line in hdrlines: print(line)\\n\\n        if input(\\'Print?\\') in [\\'y\\', \\'Y\\']:\\n\\nPart VII, Exceptions and Tools\\n\\n| 1503\\n\\n\\x0c            for line in server.retr(msgnum)[1]: print(line)    # Get whole msg\\n        if input(\\'Delete?\\') in [\\'y\\', \\'Y\\']:\\n            print(\\'deleting\\')\\n            server.dele(msgnum)                                # Delete on srvr\\n        else:\\n            print(\\'skipping\\')\\nfinally:\\n    server.quit()                                  # Make sure we unlock mbox\\ninput(\\'Bye.\\')                                      # Keep window up on Windows\\n\\n# CGI server-side script to interact with a web browser\\n\\n#!/usr/bin/python\\nimport cgi\\nform = cgi.FieldStorage()                          # Parse form data\\nprint(\"Content-type: text/html\\\\n\")                 # hdr plus blank line\\nprint(\"<HTML>\")\\nprint(\"<title>Reply Page</title>\")                 # HTML reply page\\nprint(\"<BODY>\")\\nif not \\'user\\' in form:\\n    print(\"<h1>Who are you?</h1>\")\\nelse:\\n    print(\"<h1>Hello <i>%s</i>!</h1>\" % cgi.escape(form[\\'user\\'].value))\\nprint(\"</BODY></HTML>\")\\n\\n# Database script to populate a shelve with Python objects\\n\\n# see also Chapter 28 shelve and Chapter 31 pickle examples\\n\\nrec1 = {\\'name\\': {\\'first\\': \\'Bob\\', \\'last\\': \\'Smith\\'},\\n        \\'job\\':  [\\'dev\\', \\'mgr\\'],\\n        \\'age\\':  40.5}\\n\\nrec2 = {\\'name\\': {\\'first\\': \\'Sue\\', \\'last\\': \\'Jones\\'},\\n        \\'job\\':  [\\'mgr\\'],\\n        \\'age\\':  35.0}\\n\\nimport shelve\\ndb = shelve.open(\\'dbfile\\')\\ndb[\\'bob\\'] = rec1\\ndb[\\'sue\\'] = rec2\\ndb.close()\\n\\n# Database script to print and update shelve created in prior script\\n\\nimport shelve\\ndb = shelve.open(\\'dbfile\\')\\nfor key in db:\\n    print(key, \\'=>\\', db[key])\\n\\nbob = db[\\'bob\\']\\nbob[\\'age\\'] += 1\\n\\n1504 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cdb[\\'bob\\'] = bob\\ndb.close()\\n\\n# Database script to populate and query a MySql database\\n\\nfrom MySQLdb import Connect\\nconn = Connect(host=\\'localhost\\', user=\\'root\\', passwd=\\'XXXXXXX\\')\\ncurs = conn.cursor()\\ntry:\\n    curs.execute(\\'drop database testpeopledb\\')\\nexcept:\\n    pass                                           # Did not exist\\n\\ncurs.execute(\\'create database testpeopledb\\')\\ncurs.execute(\\'use testpeopledb\\')\\ncurs.execute(\\'create table people (name char(30), job char(10), pay int(4))\\')\\n\\ncurs.execute(\\'insert people values (%s, %s, %s)\\', (\\'Bob\\', \\'dev\\', 50000))\\ncurs.execute(\\'insert people values (%s, %s, %s)\\', (\\'Sue\\', \\'dev\\', 60000))\\ncurs.execute(\\'insert people values (%s, %s, %s)\\', (\\'Ann\\', \\'mgr\\', 40000))\\n\\ncurs.execute(\\'select * from people\\')\\nfor row in curs.fetchall():\\n    print(row)\\n\\ncurs.execute(\\'select * from people where name = %s\\', (\\'Bob\\',))\\nprint(curs.description)\\ncolnames = [desc[0] for desc in curs.description]\\nwhile True:\\n    print(\\'-\\' * 30)\\n    row = curs.fetchone()\\n    if not row: break\\n    for (name, value) in zip(colnames, row):\\n        print(\\'%s => %s\\' % (name, value))\\n\\nconn.commit()                                      # Save inserted records\\n\\n# Fetch and open/play a file by FTP\\n\\nimport webbrowser, sys\\nfrom ftplib import FTP                       # Socket-based FTP tools\\nfrom getpass import getpass                  # Hidden password input\\nif sys.version[0] == \\'2\\': input = raw_input  # 2.X compatibility\\n\\nnonpassive = False                           # Force active mode FTP for server?\\nfilename   = input(\\'File?\\')                  # File to be downloaded\\ndirname    = input(\\'Dir? \\') or \\'.\\'           # Remote directory to fetch from\\nsitename   = input(\\'Site?\\')                  # FTP site to contact\\nuser       = input(\\'User?\\')                  # Use () for anonymous\\nif not user:\\n    userinofo = ()\\nelse:\\n    from getpass import getpass              # Hidden password input\\n\\nPart VII, Exceptions and Tools\\n\\n| 1505\\n\\n\\x0c    userinfo = (user, getpass(\\'Pswd?\\'))\\n\\nprint(\\'Connecting...\\')\\nconnection = FTP(sitename)                   # Connect to FTP site\\nconnection.login(*userinfo)                  # Default is anonymous login\\nconnection.cwd(dirname)                      # Xfer 1k at a time to localfile\\nif nonpassive:                               # Force active FTP if server requires\\n    connection.set_pasv(False)\\n\\nprint(\\'Downloading...\\')\\nlocalfile = open(filename, \\'wb\\')             # Local file to store download\\nconnection.retrbinary(\\'RETR \\' + filename, localfile.write, 1024)\\nconnection.quit()\\nlocalfile.close()\\n\\nprint(\\'Playing...\\')\\nwebbrowser.open(filename)\\n\\n1506 | Appendix D:\\u2002Solutions to End-of-Part Exercises\\n\\n\\x0cIndex\\n\\nSymbols\\n# character\\n\\ncomments, 48, 55, 141, 444\\ndirectives, 48\\n\\n#! characters, 59, 60–62, 1441–1444\\n% (percent sign)\\n\\nformatting expression operator, 217, 227–\\n\\n229, 1189\\n\\nsystem shell prompt, 44, 48, 56\\n\\n( ) (parentheses)\\n\\ncomprehensions and, 112\\nexpression operators and, 139\\nstatements and, 323, 328\\nsuperclasses and, 801\\ntuples and, 277\\n\\n* (multiplication) operator\\n\\nmultiplying numbers, 97\\nrepeating lists, 242\\nrepeating strings, 100, 200\\n\\n+ (plus) operator\\n\\nadding numbers, 97\\nconcatenating lists, 242, 1100\\nconcatenating strings, 100, 200, 1100\\n\\n+= in-place addition, 920, 1194\\n, (comma), 277\\n/ / operator, 146–150\\n/ operator, 146–150\\n: (colon), 322\\n; (semicolon), 323, 327\\n<< (left-shift) operator, 207\\n== (equivalence) operator, 301\\n>>> prompt\\n\\nabout, 45, 49\\ncommon usage mistakes, 52\\n\\n@ symbol\\n\\nabout, 1029, 1035\\nfunction decorators and, 1022, 1035, 1273\\n\\n[ ] (square brackets), 96, 224, 328\\n\\\\ (backslash)\\n\\nescape sequences and, 105, 193–197\\nmultiline statements and, 328, 378\\n\\n_ (underscore)\\n\\nclass names, 845\\nmodule names, 70, 747\\nname mangling and, 945\\noperator overloading, 104, 805\\nshowing name values, 971\\n\\n{ } (curly braces), 114, 328\\n\\nA\\nabs built-in function, 155\\nabsolute imports, 718, 722, 726, 731\\nabstract superclasses, 869–871, 939\\naccess-by-key databases and filesystems\\n\\ndictionary interfaces, 848\\nexploring interactively, 849–851\\niterations and, 423\\nobject persistence and, 116, 847\\npickle module, 290\\nstoring objects on, 271, 848\\nupdating objects, 851\\n\\naccessor functions, 498, 554\\n__add__ method, 104, 808, 889, 918\\naddition operation, 97\\nall built-in function, 432\\n__all__ variable, 711, 747\\nAndroid platform, 1425\\nannotations, 565–567, 1340–1342\\n__annotations__ attribute, 565\\n\\nWe’d like to hear your suggestions for improving our indexes. Send email to index@oreilly.com.\\n\\n1507\\n\\n\\x0canonymous functions (see lambda expressions)\\nany built-in function, 432\\nanydbm module, 847\\napply built-in function, 538, 954\\narbitrary arguments, 534–538, 1339\\narbitrary expressions, 100\\narbitrary structures, 558–561\\nargparse module, 754\\narguments, 529\\n\\naugmented assignments, 341, 350–352\\nextended sequence unpacking, 341, 344–\\n\\n348, 398\\n\\nlist-unpacking assignments, 340\\nmultiple-target assignments, 341, 348–349\\nquiz questions and answers, 370\\nsequence assignments, 340–344\\nsyntax patterns, 340–341\\ntuple-unpacking assignments, 340, 396–\\n\\n(see also keyword arguments)\\nabout, 523\\narbitrary, 534–538, 1339\\navoiding changes, 526\\ncalculating lengths of, 620\\ncall expressions and, 209\\ncoding functions, 476\\ndecorator, 1281, 1298–1301, 1330–1343,\\n\\n1340–1342\\n\\ndefault values, 529, 532–534, 658–660\\nintersecting sequences example, 545–547\\nmatching, 528–531, 547–549\\npositional, 529, 534, 1331–1343\\nquiz questions and answers, 551\\nrunning script files with, 1432\\nself, 554, 573, 811, 818, 1025\\nshared references and, 524–526\\nsimulating multiple results, 527\\nsimulating output parameters, 527\\nunpacking, 528, 535\\nusage example, 542–545\\n\\nArithmeticError class, 1131, 1132\\narrays, lists and, 109\\nas extension for import/from statements, 758\\nascii built-in function, 224\\nASCII character set\\n\\nabout, 1167\\ncharacter code conversions, 207\\nencoding, 1178\\nencoding and decoding, 194\\nusage example, 582\\n\\naspect-oriented programming, 1272\\nassert statement\\n\\nabout, 321, 1081, 1112\\nspecial-case handling, 1083\\ntriggering exceptions, 1086\\nusage example, 1113\\n\\nAssertionError exception, 1112\\nassignment statements\\n\\nabout, 320, 339, 500\\n\\n1508 |\\n\\nIndex\\n\\n398, 591\\n\\nvariable name rules, 352–355\\n\\nasterisk (*), 97, 100, 200, 242\\natexit module, 1149\\nattribute fetches\\n\\nabout, 209, 839\\nattribute name qualification and, 697\\nbuilt-in types and, 985, 987–992\\nAttributeError exception, 910, 1222\\nattributes, 910\\n\\n(see also specific types of attributes)\\nabout, 68, 798\\naccessing, 1220\\nassigning and deleting, 910\\nattribute tools, 1023\\nbuilt-in, 839, 1249–1256\\ndata, 860\\ndescriptors and, 1226–1237\\nhandling generically, 1014–1016\\ninheritance and, 785–787, 802, 963–966\\nlisting per object, 966–971\\nmanaging, 912, 1219–1221\\nmapping to inheritance sources, 1004–\\n\\n1009\\n\\nmodules and, 68–71, 671–673, 804\\nname qualification for, 697\\nnamespaces and, 872\\noperator overloading and, 909–913, 1237–\\n\\n1256\\n\\nprivacy considerations, 913\\nproperties for, 1221–1226\\nquiz questions and answers, 1266–1268\\nreferencing, 909\\nspecial class, 840–842\\nstring method calls and, 231\\nvalidating, 1256–1266\\n\\naugmented assignments, 341, 350–352\\naugmented classes, 1391–1394, 1395\\nautomatic memory management, 18\\nawk utility, 413\\n\\n\\x0cB\\nbackslash (\\\\)\\n\\nescape sequences and, 105, 193–197\\nmultiline statements and, 328, 378\\n\\nbacktracking, exception handlers and, 1083\\nbase classes, 787\\nBaseException class, 1123, 1131\\n__bases__ attribute\\nabout, 811, 878\\ninheritance and, 843, 967, 1383\\n\\nBDFL (Benevolent Dictator for Life), 17\\nbenchmarking\\n\\npystone.py program, 656\\nquiz questions and answers, 662\\ntimeit module, 647–655\\ntiming iteration, 629–655\\nusage examples, 651\\n\\nBenevolent Dictator for Life (BDFL), 17\\nbig-endian format, 1201–1204\\nbin built-in function, 135, 207\\nbinary files\\n\\nabout, 107, 123, 1173–1174, 1196\\nescape sequences and, 196\\nfrozen executables, 39, 82\\nstoring data, 293\\nstruct module and, 1207–1209\\ntext files and, 123\\nversion considerations, 287, 1197\\n\\nbinary formatting, 231\\nbinary notation, 135, 151–153\\nbinary operator methods, 917–921\\nbitwise operations, 137, 153–155\\nblank lines\\n\\ncommon usage mistakes, 53\\nstatements and, 53, 375\\n\\nblock strings, 198–199\\nblocks of code\\n\\ndelimiting, 376–378\\nindenting, 376–378\\nloop coding techniques, 402–411\\nnesting, 335, 376–378\\nspecial case rules, 329\\n\\nBOM (byte order marker), 1174, 1201–1204\\n__bool__ method, 889, 927–929\\nBooleans (bool type)\\n\\nabout, 127, 384\\noperator overloading and, 927–929\\ntruth test and, 171, 305, 380–382\\nversion considerations, 928\\n\\nbound methods, 573, 948–953, 1025\\nbounds checking for lists, 110\\nbranching in if statements, 372–374\\nbreak statement\\n\\nabout, 320, 389\\nnested loops and, 391, 1145\\n\\nbsddb extension module, 850\\nbuilt-in attributes, 839, 1249–1256\\nbuilt-in exception classes\\n\\nabout, 1131\\nbuilt-in categories, 1132\\ndefault printing and state, 1133–1135\\n\\nbuilt-in exceptions, 1086, 1100\\nbuilt-in object types\\n\\nabout, 19, 94, 295\\nattribute fetches for, 985, 987–992\\nclass decorators and, 1306\\ncommon usage mistakes, 308–311\\ncomparison operations, 300–303\\ncore data types, 95, 295\\ndictionaries (see dictionaries)\\nequality and, 300–303\\nextending, 980–983\\nfiles (see files)\\ngeneral type categories, 235–236\\ngeneration in, 606–609\\niteration and, 422–424\\nlists (see lists)\\nmetaclasses and, 1387–1388\\nnumbers (see numbers)\\nobject flexibility, 297\\nreferences versus copies, 297–300, 308\\nstrings (see strings)\\ntuples (see tuples)\\ntype hierarchies, 306–308\\n\\nbuilt-in scope\\n\\nabout, 487, 491–493\\nLEGB rule and, 488\\n\\n__builtin__ module, 156, 493\\nbuiltins module, 156, 491–493\\nbyte code\\n\\nabout, 30–31\\nmodules and, 676–678\\noptimizing, 684\\nPVM and, 31\\nPython versions and, 31\\nsource changes and, 31\\n\\nbyte order marker (BOM), 1174, 1201–1204\\nbytearray string type\\n\\nIndex | 1509\\n\\n\\x0cabout, 107, 190, 1166, 1171–1173, 1192–\\n\\n1195\\n\\nchanging strings, 102, 209, 211\\n\\nbytes built-in function, 306\\nbytes string type\\n\\ncoding exception classes, 1127\\ncomparing class instances, 306\\nexception type and, 1150\\ninheritance and, 843\\nlisting attributes in class trees, 967\\n\\nabout, 106, 287, 1171–1173, 1189\\nbytearray string type and, 190\\nencoded text, 1183\\nmaking bytes objects, 1191\\nmethod calls, 1189\\nmixing string types, 1192\\npickle module and, 290\\nquiz questions and answers, 1215–1217\\nsequence operations, 1190\\ntype and content mismatches, 1198\\n\\nC\\nC language\\n\\nargument-passing model, 524\\n#define directive, 1272\\nerror checks, 1088\\n#include directive, 1272\\nmemory address pointers, 177\\nwhile loops, 394\\n\\nC++ language, 861, 863, 944\\ncall expressions, 209, 921–925\\n__call__ method\\n\\nabout, 889, 921–925\\nbound methods and, 952–953\\nclass decorators and, 1278, 1308\\nclass objects and, 573\\nfunction decorators and, 1037, 1275, 1293\\n\\ncase considerations\\n\\ncase conversion for strings, 192\\nvariable name rules, 352\\n\\ncertificate, completion, 1414–1416\\ncgi.FieldStorage class, 271\\nchaining\\n\\nexceptions, 1110–1112\\nmethods, 427\\nnumeric comparisons, 144–146\\n\\ncharacter code conversions, 206\\ncharacter sets, 1167\\n\\n(see also ASCII character set; Unicode\\ncharacter set)\\n\\nchr built-in function, 206, 582, 1167, 1179\\ncircular references, 179\\n__class__ attribute\\n\\nabout, 840, 878, 993\\n\\n1510 |\\n\\nIndex\\n\\nclass attributes\\nabout, 843\\nabstract superclasses and, 870\\nclass gotchas, 1064–1066\\ncreating, 865\\nfunction decorators and, 1285\\ninstance attributes versus, 843\\npseudoprivate, 845, 944–947, 1160, 1321\\nspecial, 840\\nusage examples, 878\\n\\nclass decorators\\n\\nabout, 943, 1034, 1270, 1277\\nbuilt-in types and, 1306\\ncoding, 1301–1311\\nimplementing, 1277–1278\\nmanager functions versus, 1309\\nmetaclasses and, 1034, 1038–1040, 1361–\\n\\n1363, 1394–1400, 1404–1407\\n\\nmultiple instances and, 1279, 1308\\nsingleton classes, 1301–1303\\nstate retention options, 1317\\ntracing object interfaces, 1303–1307\\nusage considerations, 1277, 1310\\n\\nclass methods\\nabout, 1024\\ncounting instances, 1031–1034\\nmetaclass methods versus, 1389\\nusage considerations, 1028–1030\\n\\nclass statement\\n\\nabout, 321, 789–791, 798, 859\\ndecorators and, 1270, 1277, 1306\\ngeneral form, 860\\ninheritance and, 865–871\\nlocal scope and, 489\\nmetaclasses and, 1367\\nmethods and, 862–865\\nmodules and, 804\\nobjects and, 130\\nproperties for, 798, 861, 1020\\nusage examples, 799–801, 802, 860\\n\\nclasses\\n\\nabout, 96, 784, 809–812\\naugmented, 1391–1394, 1395\\nclass instances, 306\\n\\n\\x0cclosures versus, 503\\ncoding class trees, 789–791\\ncoding gotchas, 1064–1070\\ncombining, 836–839\\ncustomizing behavior, 828–834\\ncustomizing constructors, 834–839\\ndecorators and, 1270, 1282, 1312–1314\\ndescriptors and, 1226\\ndictionaries versus, 812–814\\ndocstrings and, 882\\nexception, 1123–1140\\nexplicit attributes and, 513\\nextending built-in types, 980–983\\nfunctions and, 788, 860\\ngenerators and, 606–609, 898\\ninheritance and, 789, 801–805, 802, 865–\\n\\n871, 956–977\\ninstances (see instances)\\nintercepting operators, 805–809, 826–828\\nintrospection tools, 840–847\\nlisting attributes in class trees, 966–971\\nmethods and, 788, 822–826, 862–865\\nmix-in, 956–977, 1057–1060\\nmodules and, 788, 804, 860, 884\\nMRO ordering, 831, 957\\nname considerations, 844\\nnamespaces and, 860, 872–882\\nnesting, 875–877\\nnew-style (see new-style classes)\\nobjects and, 954–956, 983\\noperator overloading, 104\\npersistence and, 941\\npolymorphism and, 792–794, 832\\nproxy (see proxy classes)\\nquiz questions and answers, 815, 855–857,\\n\\n884, 978, 1071\\n\\nscopes in, 1068\\nsingleton, 1301–1303\\nstoring objects in databases, 847–853\\nsubclasses (see subclasses)\\nsuperclasses (see superclasses)\\ntype object and, 1364–1366\\nusage examples, 799–801, 802, 806–808,\\n\\n845–847\\nuser-defined, 129\\nversion considerations, 983\\n\\nclassmethod built-in function, 1024, 1029–\\n\\n1030\\n\\nclient module, 717\\n\\nclosures (see factory functions)\\n__cmp__ method, 925–927\\ncode points, 106, 194, 206, 1170\\ncodecs module\\nabout, 108\\nopen method, 125, 283, 287, 1204\\n\\ncoding (see development considerations)\\ncohesion\\n\\nin functions, 553\\nin modules, 746\\ncollections module\\n\\nnamedtuple function, 256, 281\\nOrderedDict subclass, 256\\n\\ncolon (:), 322\\ncomma (,), 277\\ncommand lines and files (see system command\\n\\nlines and files)\\n\\ncommand-line arguments, 204, 751, 1432–\\n\\n1435\\n\\ncomments\\n\\n# character, 48, 55, 141, 444\\n#! characters, 60–62\\nstatements and, 375\\ncomparison operations\\n\\nbuilt-in object types, 300–303\\ndictionaries, 270, 302\\nlists, 302\\nnumbers, 144–146, 302\\noperator overloading and, 925–927\\nrecursive, 300\\nsets, 302\\nstrings, 302\\ntesting truth values, 380–382\\ntuples, 302\\nversion considerations, 247, 302\\n\\ncompile built-in function, 762\\ncompiled extensions, 7\\ncompletion certificate, 1414–1416\\ncomplex built-in function, 135, 306\\ncomplex numbers, 97, 151\\ncomponent coupling, 1060\\ncomponent integration, 12\\ncomposition\\n\\nabout, 784\\ncombining classes, 836–839\\nOOP considerations, 937–941\\n\\ncompound object types, 297\\ncompound statements, 371\\n\\n(see also specific statements)\\n\\nIndex | 1511\\n\\n\\x0cabout, 371, 375\\ncolon character, 322\\ncommon usage mistakes, 52, 53\\nspecial case rules, 327–328, 379–380\\nterminating, 375\\ntiming, 645\\n\\ncomprehension variables, 490, 623\\ncomprehensions, 441\\n\\n(see also list comprehensions)\\ndictionary, 263, 265–266, 432, 624–626\\niterables versus, 597–602\\nquiz questions and answers, 441, 626\\nset, 166, 168, 432, 624–626\\nsyntax summary, 622–626\\n\\nconcatenating\\n\\nlists, 242, 1100\\nstrings, 100, 104, 200, 1100\\ntuples, 277\\nvirtual concatenation, 737\\n\\nconflict resolution, diamond inheritance trees,\\n\\n999–1000\\n\\nconstants, 95\\nconstructors\\n\\nclass gotchas, 1069\\ncoding, 818\\ncustomizing, 834–839\\n__init__ method and, 818, 864\\noperator overloading and, 888\\nsuperclass, 864\\n\\n__contains__ method, 482, 889, 906–909\\n__context__ attribute, 1111\\ncontext managers\\n\\nabout, 1114–1117\\nclosing files and server connections, 1148\\ndecimals, 159\\nfiles, 285, 294\\nimplementing, 1081, 1088\\nmultiple, 1118–1119\\nversion considerations, 1118–1119\\n\\ncontextlib module, 1117\\ncontinuation lines in statements, 328, 378\\ncontinue statement, 320, 389, 391\\ncontrol flows\\n\\nexceptions and, 1083\\nnesting, 1143\\n\\ncontrol languages, 6, 7, 12\\ncontrol-flow statements, 375\\nconversions\\ncase, 192\\n\\n1512 |\\n\\nIndex\\n\\nfor encodings, 1184\\nfraction, 162\\nhex, octal, binary notation, 151–153\\ninteger, 152\\nmixed types, 139, 162\\nstoring objects in files, 288–290\\nstring, 152, 205–207\\nstring types, 1192\\n3to2 converter, 367\\ntuple, 278–279\\n2to3 converter, 366\\n\\ncopy module, 299\\ncore data types (see built-in object types)\\ncoupling\\n\\ncomponent, 1060\\nfunctions, 553\\nmodules, 745\\nsuper built-in function, 1057–1060\\n\\ncPickle module, 290\\nCPython system\\nabout, 33, 34\\ntimeit module and, 643–645\\n\\nCSV file format, 214, 292\\ncsv module, 214, 292\\ncurly braces { }, 114, 328\\ncurrency symbols, 754–756\\ncurrent working directory (CWD), 724, 726,\\n\\n727\\n\\nCWD (current working directory), 724, 726,\\n\\n727\\n\\ncx_freeze tool, 39\\ncycles, recursive calls and, 560\\ncyclic data structures, 310\\ncyclic references, 179\\nCygwin system, 45\\nCython system, 33, 37\\n\\nD\\ndata attributes, 860\\ndata structures\\n\\nabout, 94\\narbitrary, 558–561\\nbuilt-in object types and, 95\\ncyclic, 310\\ndictionaries and, 259\\nempty, 304\\n\\ndata types (see object types)\\ndatabase programming, 12\\n\\n\\x0cdatabases, access-by-key (see access-by-key\\n\\ndatabases and filesystems)\\n\\ndbm module, 847\\n__debug__ built-in variable, 1113, 1331\\ndebugging Python code\\n\\nabout, 83–85\\nIDLE debugger, 77\\nstring issues, 972\\ntools supporting, 1159\\nwith try statement, 1149\\n\\ndecimal module, 158\\ndecimals (decimal object)\\n\\nabout, 97, 127, 157–158\\ncontext manager, 159\\nfrom_float method, 158\\ngetcontext method, 159\\nlocalcontext method, 159\\nnumeric accuracy in, 161\\nresetting precision temporarily, 159\\nsetting precision globally, 158\\n\\ndecoding (see encoding and decoding)\\ndecorators, 1034\\n\\n(see also class decorators; function\\ndecorators)\\nabout, 1034, 1269\\nabstract superclasses and, 870\\narguments and, 1281, 1298–1301, 1330–\\n\\n1343, 1340–1342\\n\\ncoding properties, 1224–1226\\ndefining, 1271\\nencapsulation and, 1311\\nmacros versus, 1272\\nmanager functions versus, 1309\\nmanaging calls and instances, 1270\\nmanaging functions and classes, 1270, 1282,\\n\\n1312–1314\\n\\nmethods and, 1289–1295, 1400–1407\\nnesting, 1279–1281, 1340\\nprivate and public attributes, 1314–1330\\nquiz questions and answers, 1344–1353\\nrange-testing for positional arguments,\\n\\n1331–1343\\n\\ntiming alternatives, 635\\nusage considerations, 1271–1272, 1310\\n\\ndef statement\\n\\nabout, 320, 476\\nclass statement and, 859\\ncoding functions, 475\\ndecorators and, 1270, 1273\\n\\nlambda expressions and, 505\\nname resolution and, 488\\nnesting, 477, 506, 790\\nruntime execution, 477\\nscope and, 486, 487, 488\\n\\ndefault exception handler, 1083\\n__del__ method\\n\\nabout, 889\\ndescriptors and, 1293\\nmanaging attributes, 1229\\nobject destruction and, 929–931\\n\\ndel statement, 249, 321\\n__delattr__ method, 889, 1238\\ndelegation\\n\\nabout, 942\\nclass gotchas, 1069\\nfunction decorators and, 1035\\ninheritance versus, 1317\\nOOP considerations, 942–943\\noperator overloading and, 1322–1329\\nproxy classes and, 988\\n\\n__delete__ method, 889, 1229\\ndeleting\\n\\ndictionary items, 252\\nlist items, 249\\n\\ndelimiters\\n\\nblocks of code, 376–378\\nstatement, 378\\n\\n__delitem__ method, 889\\ndeprecation protocol for Python, 354\\ndepth-first, left-to-right (DFLR) path, 956, 997\\nderived classes, 787, 995–997\\ndescriptors\\n\\nabout, 861, 1023, 1226–1237\\nattribute access and, 1221\\nbuiltins routing mixin, 1326\\ndecorating methods with, 1292–1295\\ninheritance and, 866, 1384–1386\\nmanagement techniques compared, 1246–\\n\\n1248\\n\\nmanaging attributes, 912\\nmetaclasses and, 1384\\nproperties and, 1236–1237\\nread-only, 1228\\nslots and, 1237\\nstate information in, 1232–1235\\nvalidating with, 1259–1263\\n\\ndesign patterns, 501–503\\ndestructor method, 929–931\\n\\nIndex | 1513\\n\\n\\x0cdevelopment considerations\\n\\nbuilt-in type gotchas, 308–311\\nclass gotchas, 1064–1070\\ncode reuse, 792–795\\ncoding class decorators, 1301–1311\\ncoding class trees, 789–791\\ncoding constructors, 818\\ncoding exception classes, 1126–1128\\ncoding exception details, 1093–1121, 1141–\\n\\n1162\\n\\ncoding function decorators, 1283–1301\\ncoding functions, 475–478, 556, 571–572\\ncoding metaclasses, 1370–1378\\ncoding methods, 824–826\\ncoding strings, 1174–1178\\ncoding subclasses, 828\\ncommon coding gotchas, 463–465\\ndatabase programming, 12\\ndevelopment community, 15\\nEIBTI acronym, 614–616\\nfunction gotchas, 656–661\\nimprovement suggestions, 975–977\\nfor larger projects, 1157–1160\\nminimizing cross-file changes, 497–498\\nminimizing global variables, 495\\nmodule coding, 687–705\\nprogram execution, 32\\nrapid development cycle, 6, 33\\nrapid prototyping, 13\\n\\nDFLR (depth-first, left-to-right) path, 956, 997\\ndiamond patterns\\n\\nabout, 957\\nattribute searches, 956\\ninheritance search order, 986, 997–1009\\n\\n__dict__ attribute\\nabout, 841, 843\\nlisting attributes in class trees, 967\\nlisting instance attributes, 959–963\\nmetaprogram example, 761\\nnamespace dictionaries and, 696\\nnamespaces and, 572, 695\\nprivate attributes and, 1318\\nslots and, 1011–1013\\nusage example, 759, 810\\nwrapper classes and, 943\\n\\ndict built-in function, 306, 432\\ndictionaries (dict object)\\n\\nabout, 96, 113, 250–251\\nadding keys, 223\\n\\n1514 |\\n\\nIndex\\n\\nalternate ways to make, 262\\nchanging in place, 254\\nclasses versus, 812–814\\nclear method, 252\\ncommon operations, 251, 253\\ncomparison operations, 270, 302\\ncopy method, 252, 299\\ndata structures and, 259\\ndeleting items, 252\\ndictionary views, 266–269, 439–440\\nempty dictionaries, 252\\nfromkeys method, 266\\nget method, 118, 252, 255, 260\\nhas_key method, 118, 264, 270\\nindexing, 114, 252, 258\\ninterface considerations, 271\\nitems method, 138, 252, 254, 264, 266, 303,\\n\\n397, 434\\n\\niteration in, 120, 253, 422, 439–440\\nkeys method, 118, 252, 253, 254, 264, 266,\\n\\n269, 422, 434\\n\\nkeyword arguments, 114\\nlists versus, 259, 263\\nliterals, 96, 251\\nmapping operations, 114, 116–118, 257\\nmissing keys, 116–118\\nmovie database example, 256–258\\nmutable nature of, 113\\nnesting, 115, 252, 254, 260\\noptimization in, 120\\nOrderedDict subclass, 256\\npop method, 252, 255, 549\\npopitem method, 252\\nquiz questions and answers, 272\\nsequence operations and, 258\\nsetdefault method, 252\\nsorting keys, 118–119, 269\\nstring formatting expressions, 221\\ntype-specific methods, 252, 254–256\\nupdate method, 252, 255\\nusage considerations, 258–262\\nvalues method, 252, 254, 264, 266, 434,\\n\\n608\\n\\nversion considerations, 264–271, 303\\nviewitems method, 264\\nviewkeys method, 252, 264\\nviewvalues method, 264\\nzip built-in function and, 409\\n\\n\\x0cdictionary comprehensions, 263, 265–266,\\n\\n432, 624–626\\n\\ndir built-in function\\n\\nabout, 104\\ncustomizing version of, 759\\nas documentation source, 444–446\\ninheritance and, 843, 963–966\\ninspecting namespaces, 695\\n\\ndirectives, 48\\ndirectories, file precedence over, 740–741\\ndiretory walkers, 607\\ndisplay formats\\n\\ngeneric display tool, 842\\nneutralizing difference with code, 367–368\\nnumeric, 143\\nprint operations, 826–828, 1135\\n\\ndistutils modules, 684, 731, 1159\\ndivision operations\\n\\nabout, 146\\nfloor division, 146–150\\ntruncating division, 146–150\\nversion considerations, 146–148\\n\\n__ doc__ attribute, 444, 446–449, 879, 882\\ndoctest module, 750, 1158\\ndocumentation\\n\\n# comments, 48, 55, 141, 444\\nabout, 443\\nadditional resources, 444, 461–463, 673\\ndir built-in function, 104, 444–446\\ndocstrings, 199, 375, 444, 446–449\\nhelp built-in function, 104, 215, 444, 449–\\n\\n451\\n\\nPyDoc system, 105, 444, 449–460\\nquiz questions and answers, 466\\nSphinx tool, 444, 461\\n\\ndocumentation strings\\n\\nabout, 444, 446–449, 882, 1157\\nmodules and, 756\\ntriple-quoted strings, 199\\nusage considerations, 375\\n\\nDOM parsing, 1212\\ndot path syntax, 709\\nduck typing, 480\\ndynamic typing\\n\\nabout, 18, 97, 175, 185\\nobjects and, 176–179\\nquiz questions and answers, 186\\nreferences and, 176, 180–185\\nvariables and, 176–178\\n\\nE\\nEaster eggs, 5\\nEBCDIC encoding, 1182\\nEclipse IDE, 80\\nEIBTI acronym, 614–616\\nElementTree package, 1211, 1213\\nelse clause (loop blocks), 389, 392–394\\nembedded programs, 81\\nempty data structures, 304\\nempty dictionaries, 252\\nempty lists, 240\\nempty strings, 191\\nempty tuples, 276\\nencapsulation\\nabout, 933\\ndecorators and, 1311\\npolymorphism and, 793\\n\\nenclosing scope\\n\\nabout, 487\\nfunction-related gotchas, 661\\nLEGB rule and, 488\\nnonlocal statement and, 924, 1286–1287,\\n\\n1302\\n\\nretaining state with defaults, 504–508\\nstate retention and, 1317\\n\\nencoding and decoding\\n\\nabout, 1167–1169\\nadditional schemes, 1181\\nASCII, 194, 1178\\nbyte string literals, 1183\\ncharacter set declarations, 1187–1188\\nconverting, 1184\\nEBCDIC, 1182\\nfilenames, 1205\\nnon-ASCII text, 1179–1181\\nUnicode, 123, 190, 192, 1178–1188, 1199–\\n\\n1206\\n\\nencodings module, 1169\\nendianness, 1201–1204\\n__enter__ method, 889, 1116\\nenumerate built-in function\\n\\nabout, 402, 410\\niteration and, 430\\nusage example, 424\\n\\nenv program, 60\\nenvironment variables\\nabout, 1427–1429\\nPATH, 45, 46, 57, 60, 1427, 1428\\nPYTHONIOENCODING, 1205\\n\\nIndex | 1515\\n\\n\\x0cPYTHONPATH, 72, 458, 679, 708, 756,\\n\\n1427, 1428, 1430\\n\\nPYTHONSTARTUP, 1427, 1428\\nPY_PYTHON, 61, 1427, 1429\\nPY_PYTHON2, 1427, 1429\\nPY_PYTHON3, 1427, 1429\\nTCL_LIBRARY, 1427\\nTK_LIBRARY, 1427\\n\\nEOFError exception, 1146\\n__eq__ method, 889, 925\\nequality\\n\\nbuilt-in object types, 300–303\\nshared references and, 183–185\\ntesting truth values, 380–382\\nvalue equality operators, 137\\nequivalence (==) operator, 301\\nerrno module, 1133\\nerror handling\\n\\ndisplaying errors and tracebacks, 1151\\nexceptions and, 1082, 1088\\nmissing keys, 116–118, 260\\nscripts and, 66\\ntesting inputs, 332\\nwith try statements, 333–334\\n\\nescape sequences, 105, 191, 193–197\\netree package, 1213\\neval built-in function\\n\\njump tables and, 571\\nstrings and, 152, 206, 289\\n\\nevent notification, 1082\\nException class\\n\\nabout, 1126, 1131\\nas catchall, 1097, 1132, 1151\\nuser-defined exceptions and, 1086\\n\\nexception classes\\n\\nabout, 1123–1125\\nbuilt-in, 1131–1135\\ncoding, 1126–1128\\ncustom data and behavior, 1136–1139\\ncustom print displays, 1135\\nhierarchies in, 1128–1131\\nquiz questions and answers, 1139\\nversion considerations, 1123\\n\\nexception handlers, 1082\\n\\n(see also specific statements)\\nabout, 1082\\nbacktracking and, 1083\\ndefault, 1083\\ndefining methods for, 1137–1139\\n\\n1516 |\\n\\nIndex\\n\\ninteractive prompt and, 1085\\nnesting, 1141–1145\\ntermination actions and, 1084, 1088\\n\\nexception variables, 490\\nexceptions, 1081\\n\\n(see also specific exceptions and specific\\nstatements)\\nabout, 1081\\nbuilt-in, 1086, 1100\\ncatching, 1084, 1088, 1096–1097, 1100\\ncatching too little, 1155\\ncatching too much, 1153–1155\\nchaining, 1110–1112\\nclass-based, 1123–1140\\ncoding details, 1093–1121\\ncommon roles, 1082\\ndesign tips and gotchas, 1152–1155\\nerrors versus, 1146\\npropagating, 1110\\nquiz questions and answers, 1090, 1120,\\n\\n1161\\n\\nraising, 549, 896, 1085, 1107\\nstring-based, 1124\\nusage considerations, 1081, 1145–1152\\nuser-defined, 1086, 1134, 1147\\n\\nexceptions module, 1132\\nexec built-in function, 72–73\\nexecfile built-in function, 73\\nexecutable scripts\\n\\n#! comment in Windows, 60–62\\nabout, 59\\nenv program, 60\\n\\nexecuting programs (see program execution)\\nexercises\\n\\npart I, 87–89, 1465–1467\\npart II, 313–315, 1468–1472\\npart III, 467–469, 1473–1475\\npart IV, 663–665, 1475–1485\\npart V, 778–779, 1485–1489\\npart VI, 1072–1076, 1489–1496\\npart VII, 1161, 1497–1499\\n\\n__exit__ method, 889, 1116\\nexplicit attributes, 513\\nexponentiation operation, 97\\nexpression operators\\n\\nconverting mixed types, 139\\ngrouping with parentheses, 139\\nlisted, 136\\noperator overloading, 141\\n\\n\\x0coperator precedence, 139\\npolymorphism and, 141\\nset operations and, 164\\nversion considerations, 138\\n\\nexpressions, 136\\n\\n(see also lambda expressions)\\nabout, 136\\narbitrary, 100\\ncall, 209, 921–925\\ncode examples, 50\\nexpression operators, 136–141\\nfunctions versus, 234, 356\\ngenerator, 439, 440, 591, 597–604\\nindexing, 99\\nnumbers in, 141–143\\nobjects and, 93\\noperator overloading and, 888\\nquiz questions and answers, 370\\nslice, 891\\nstatements and, 93, 356–357\\nstring formatting, 216–222\\nvariables and, 176\\n\\nextended sequence unpacking\\n\\nabout, 341, 344–348\\nfor loops and, 398\\n\\nextending built-in types\\n\\nabout, 980\\nby embedding, 980\\nby subclassing, 981–983\\n\\nextension modules, 688\\n\\nF\\nfactorials, 615, 665, 1483\\nfactory functions\\n\\nabout, 501–503\\ngeneric, 954–956\\ngotchas, 661\\nmetaclasses and, 1373\\n\\nfalse value in Python\\n\\nBooleans and, 171, 304–305, 380–382\\nbuilt-in scope and, 494\\noperator overloading and, 927–929\\n\\nFieldStorage class, 271\\nFIFO (first-in-first-out), 559\\n__file__ attribute, 761\\nfiles (file object), 286\\n\\n(see also binary files; text files)\\nabout, 122, 282\\nclose method, 283, 285\\n\\nclosing, 1148\\ncommon operations, 282, 285\\ncontext manager, 285\\ncontext managers, 294\\nflush method, 283, 294\\ngenerating namespaces, 695\\n__init__.py files, 709–711\\ninspecting, 1214\\niteration in, 286, 416–419, 590\\nlist comprehensions and, 426\\nliterals, 96\\nminimizing cross-file changes, 497–498\\nmodule filenames, 687\\n__next__ method, 417, 419, 426\\nopen built-in function and, 122, 126, 283\\nprecedence over directories, 740–741\\nprint operations and, 358\\nquiz questions and answers, 311\\nread method, 123, 283, 286, 400\\nreadline method, 123, 283, 285, 417\\nreadlines method, 283, 401, 418, 426, 482\\nseek method, 123, 283, 482\\nstoring objects in files, 288–290\\ntools supporting, 294\\ntype-specific methods, 123, 285\\nusage considerations, 58, 284–285\\nwrite method, 283, 288\\nwritelines method, 283\\nxreadlines method, 401\\n\\nfilesystems, access-by-key (see access-by-key\\n\\ndatabases and filesystems)\\n\\nfilter built-in function\\n\\ngenerator expressions versus, 601\\niteration and, 430, 434, 437, 576\\nlist comprehensions and, 112, 583–586\\n\\nfiltering test results, 427\\nfirst-class object model, 562, 574\\nfirst-in-first-out (FIFO), 559\\nfloat built-in function, 206, 306\\nfloating-point numbers (float type)\\n\\nabout, 97, 127, 134\\nas_integer_ratio method, 136\\nis_integer method, 136\\ntry statements and, 334\\n\\nFloatingPointError exception, 1131\\nfloor division, 146–150\\nfor statement\\n\\nabout, 320, 395\\nextended sequence unpacking, 348\\n\\nIndex | 1517\\n\\n\\x0cfilter clauses, 427\\ngeneral format, 395\\niteration and, 416, 418, 420, 422\\nlist comprehensions and, 400, 415, 425\\nnested loops, 428\\nnesting, 399–400\\nparallel traversals, 407–410\\nquiz questions and answers, 414\\nrange built-in function and, 344\\nrecursion versus, 558\\nsequence scans, 403\\nsorting keys, 118–119\\nterminating, 53\\nusage examples, 395–400\\n\\nformat built-in function, 225, 227\\n__format__ method, 225\\nformatting strings (see string formatting)\\nfractions (fraction object)\\n\\nabout, 127, 160\\nconversions and mixed types, 162\\nfrom_float method, 162\\nnumeric accuracy in, 161\\n\\nfractions module, 160\\nfreeze tool, 39\\nfrom * statement\\n\\nabout, 689\\nmodules and, 689\\nnamespace pollution and, 747\\npackage imports and, 710\\nvariables and, 773\\n\\nfrom statement\\n\\nabout, 69, 321, 669, 689, 691–694\\nas extension, 758\\ncopying names, 772\\nexec built-in function and, 73\\nimport statement versus, 692, 713, 775\\npackage imports and, 708\\npotential pitfalls, 693–694\\nrelative imports model and, 707\\nreload built-in function and, 773–775\\ntesting and, 774\\n\\nfrozen binaries, 39, 82\\nfrozenset built-in function, 168, 296\\nfunction attributes, 515–517, 564–565, 1288\\nfunction decorators\\n\\nabout, 943, 1034–1037, 1269\\nadding arguments, 1298–1301\\ncoding, 1283–1301\\nimplementing, 1274\\n\\n1518 |\\n\\nIndex\\n\\nmanager functions versus, 1310\\nmethod blunders, 1289–1295\\nmethod declaration and, 1275\\nproperties and, 1022\\nstate retention options, 1285–1289\\ntiming calls, 1295–1301\\ntracing calls, 1283–1284\\nusage considerations, 1273\\nuser-defined, 1037\\nvalidating arguments, 1330–1343\\n\\nfunctional programming\\n\\nbuilt-in functions for, 574–577\\nclasses, 798\\nclosures, 501–503\\nlist comprehensions, 581–589\\n\\nfunctions, 96\\n\\n(see also specific functions)\\nabout, 96, 473–475\\naccessor, 498, 554\\nannotations and, 565–567, 1340–1342\\nanonymous, 567–573\\napplying generically, 536–537\\n*arg form, 433, 534–538, 541\\n**args form, 531, 534–538, 541\\ncalling, 478\\nclasses and, 788, 860\\ncoding, 475–478, 556, 571–572\\ncohesion in, 553\\ncommon pitfalls, 656–661\\ncoupling, 553\\ndecorators and, 1270, 1282, 1312–1314\\ndefining, 478\\ndesign concepts, 553–554\\nexpressions versus, 234, 356\\nfactory, 501–503, 661, 954–956, 1373\\nfirst-class object model, 562, 574\\ngenerator, 439, 440, 591–597, 602–604\\nhelper, 1309, 1359–1361\\nintersecting sequences, 480–483, 545–547\\nintrospection tools, 563, 1336\\n**kargs form, 620, 1304, 1333, 1338\\nkeyword arguments, 114\\nmanager, 1309, 1359–1361\\nmapping operations, 574–576\\nmetafunctions, 1034–1037, 1273\\nmethods and, 799\\nnesting, 499–508, 572, 1291\\n*pargs form, 1333, 1338\\npolymorphism in, 479, 482\\n\\n\\x0cprogramming tools, 574–577\\nquiz questions and answers, 483, 578\\nrecursive, 487, 555–561, 764–767, 775,\\n\\n880\\n\\nscope considerations, 486\\nsignaling conditions with, 1147\\nunbound methods as, 950\\n\\nfunctools module, 576\\n__future__ module, 148, 367, 748\\n\\nmetaclasses and, 1390\\nnew-style classes and, 987\\nvalidating with, 1263–1265\\nwrapper classes and, 942\\n\\n__getattribute__ method\\n\\nabout, 889, 912, 1023, 1220\\nattribute fetches and, 839\\n__getattr__ method comparison, 1245\\nintercepting built-in operation attributes,\\n\\nG\\ngarbage collection\\nabout, 116, 208\\nexception variables and, 490\\nobjects and, 178, 929–931\\n\\ngc module, 179\\n__ge__ method, 889\\ngenerators\\n\\nabout, 112, 591\\nclasses and, 606–609, 898\\nEIBTI acronym, 614–616\\nfunctions versus expressions, 602–604\\ngenerating scrambled sequences, 609–614\\niterables versus comprehensions, 597–602\\niteration and, 120, 439, 440, 592, 604–605,\\n\\n617–621\\n\\nmultithreading and, 595\\n__next__ method, 593\\nquiz questions and answers, 626\\nrecursive calls, 968\\nsend method, 596\\nyield versus return statement, 592–597\\n\\n__get__ method\\n\\nabout, 889\\ndescriptors and, 912, 1292\\nmanaging attributes, 1228\\n\\ngetattr built-in function, 836, 942\\n__getattr__ method\\n\\nabout, 889, 909–913, 1220\\nattribute fetches and, 836\\nattribute interception and, 988\\nclass decorators and, 1278, 1304–1307\\nemulating privacy, 944\\n__getattribute__ method comparison,\\n\\n1245\\n\\n1249–1256\\n\\nmanaging attributes, 1237–1256\\nnew-style classes and, 987\\nrecursive looping and, 561\\nvalidating with, 1265\\n\\n__getitem__ method\\n\\nabout, 889, 890–894\\nindex iteration and, 894–895\\nmembership and, 906–909\\nuser defined class and, 441\\nuser defined iterables and, 609\\n\\ngetopt module, 754\\n__getslice__ method, 893, 927\\nglobal scope\\n\\nabout, 487\\nLEGB rule and, 488, 872\\nstate retention and, 513\\n\\nglobal statement\\n\\nabout, 320, 487, 494, 509\\ncoding functions, 476\\n\\nglobal variables\\n\\nalternatives for accessing, 498\\nminimizing, 495\\nmodules and, 745\\n\\ngo to statements, 1145\\nGraphical User Interface (GUI), 11, 853\\n__gt__ method, 889, 925\\nGUI (Graphical User Interface), 11, 853\\n\\nH\\nhash character (#)\\n\\ncomments, 48, 55, 141, 444\\ndirectives, 48\\n\\nhelp built-in function\\n\\nabout, 104, 215, 444\\nPyDoc system and, 449–451, 883, 1157\\n\\nimplementation alternatives, 1328–1329\\nintercepting built-in operation attributes,\\n\\n1249–1256\\n\\nmanaging attributes, 1237–1256\\n\\nhelper functions, 1309, 1359–1361\\nhex built-in function, 135\\n__hex__ method, 894\\nhexadecimal notation\\n\\nIndex | 1519\\n\\n\\x0cintegers, 135, 151–153\\nstring escape sequences, 105\\n\\nHTML reports, 452–460\\n\\nI\\n-i command-line argument, 84\\n__iadd__ method, 889, 917–921, 1194\\nicon clicks\\n\\nabout, 62\\nlimitations, 63–66\\nWindows platform, 63–65\\n\\nid built-in function, 960\\nIDEs (integrated development environments)\\n\\nabout, 74, 1158\\nalternative, 79–81\\n\\nIDLE user interface\\n\\nabout, 73, 446, 1429\\nadvanced tools, 77\\nbasic usage, 75–76\\ncommon usage mistakes, 58, 78–79\\nmultiline block strings, 198\\nstartup details, 74\\nusability features, 76\\n\\nif (elif/else) statement\\n\\nabout, 320, 322, 371\\nbasic examples, 372\\nfilter clauses, 427\\ngeneral format, 371\\ninteractive loops example, 330, 333\\nmissing keys tests, 116–118\\nmultiway branching, 372–374, 570\\nquiz questions and answers, 385\\nterminating, 53\\n\\nif/else ternary expression, 137, 382–384\\nimmutable objects\\nabout, 101, 208\\nchanging in place, 297, 311\\nconstraints with, 167\\nimmutable sequences, 191\\n\\nimp.reload function, 66–71, 78, 669\\nimplementation-related object types, 96\\nimplicit assignments, 691\\n__import__ built-in function, 684, 762\\nimport statement, 708\\n\\n(see also package imports)\\nabout, 66–71, 321, 669, 671–673, 689\\nas extension, 758\\nas one-time occurrence, 690\\ncommon usage mistakes, 71, 78\\n\\n1520 |\\n\\nIndex\\n\\ndot path syntax, 709\\nenabling context managers, 1114\\nas executable statement, 691\\nfrom statement versus, 692, 713, 775\\nimporting modules by name string, 761–\\n\\n763\\n\\npackages and, 708\\npotential pitfalls, 693–694\\nprocess overview, 674–676\\nscopes versus, 698\\n\\nimport this command, 5, 589\\nimportlib.import_module function, 684, 763\\nin operator\\n\\ndictionaries and, 117, 253\\nsets and, 127\\nstrings and, 214\\n\\nin-place change operations\\n\\navoiding mutable argument changes, 526\\ndictionaries and, 254\\nexpression statements and, 357\\nimmutable objects and, 297, 311\\nlists and, 244–250, 357\\nscope and, 488\\nshared references and, 181–183\\n\\nindenting\\n\\nblocks of code, 376–378\\ncommon usage mistakes, 52\\nstatements, 324–327\\n\\n__index__ method, 889, 894\\nIndexError exception, 896, 1084, 1086\\nindexing\\n\\ndictionaries, 114, 252, 258\\nlists, 243, 244–246\\noperator overloading and, 890–894\\nstrings, 99, 201–204\\ntuples, 277\\n\\nindirect function calls, 562\\ninheritance, 956\\n\\n(see also multiple inheritance)\\nabout, 783–785, 865, 933\\nabstract superclasses, 869–871\\nassignment and, 1386\\nattribute tree construction, 865\\nattributes and, 785–787, 802, 963–966\\nbuilt-ins and, 1387\\nclass interface techniques, 867–868\\nclasses and, 801–805, 802, 956–977\\ndelegation versus, 1317\\ndescriptors and, 866, 1384–1386\\n\\n\\x0cformal definition and algorithm, 1382–\\n\\n1388\\n\\ninstances and, 799\\nmapping attributes to sources, 1004–1009\\nmetaclasses and, 866, 1378–1388\\nmultiple, 789\\nnamespaces and, 865\\nOOP considerations, 935–937\\nspecializing inherited methods, 866\\nsubclasses and, 808\\ntype object and, 1379\\nusage examples, 802\\n\\n__init__ method\\n\\nabout, 791, 889\\nattribute validation and, 1257\\nclass decorators and, 1278, 1308\\ncoding multiple, 864\\nconstructors and, 818, 864, 888\\ninheritance and, 808\\nmetaclasses and, 1371\\n\\n__init__.py files, 709–711, 735–737\\ninput built-in function\\n\\ninput trick on Windows, 64, 65\\nprompting for test inputs, 754\\nusage example, 330\\n\\ninstalling Python, 28, 1421–1425\\ninstance attributes, 843\\n\\nclass attributes versus, 843\\ncreating, 865\\nemulating privacy for, 912\\nfunction decorators and, 1285\\nlisting with __dict__, 959–963\\nusage examples, 878\\ninstance methods, 864\\ninstances\\n\\nabout, 784, 798\\nabout and, 788\\ncounting with class methods, 1031–1034\\ncounting with static methods, 1030\\ncreating, 798, 818–821\\ndecorators managing, 1270\\ninheritance and, 799\\nmetaclasses and, 1378–1388, 1396–1397\\nmultiple, 797–801, 1279, 1308\\nnamespaces and, 799\\nraising with raise statement, 1126\\ntype object and, 1364–1366\\nusage examples, 799–801\\n\\nabout, 152, 205, 306\\nalternatives to, 207\\ninteractive loops example, 332\\n\\nintegers (int type)\\nabout, 97, 134\\nbit_length method, 154\\nconverting to strings, 152\\nhex, octal, binary notation, 135, 151–153\\ninteger keys, 259\\nprecision in, 150\\n\\nintegrated development environments (IDEs)\\n\\nabout, 74, 1158\\nalternative, 79–81\\n\\ninteractive loops, 329–336\\ninteractive prompt\\n\\nabout, 31, 43\\ncode directories, 47\\ncommon usage mistakes, 52–54\\nexception handling and, 1085\\nas experimenting tool, 50\\nnew Windows options, 46\\nprinting values at, 356\\nprompts and comments and, 48\\nrecursive reload example, 766\\nrunning code interactively, 49\\nscope and, 487\\nstarting interactive sessions, 44\\nsystem path, 45\\nterminating compound statements, 53\\nas testing tool, 51\\nInternet scripting, 11\\ninterpreters (see Python interpreter)\\nintrospection tools\\nclasses, 840–847\\nfunctions, 563, 1336\\n\\niOS platform, 1425\\nIronPython system, 34, 35\\nis operator, 136, 301\\nisinstance built-in function, 306, 919, 966\\niter built-in function\\n\\nabout, 120, 419–422, 438\\nuser defined iterables and, 608\\n\\n__iter__ method\\n\\nabout, 608, 889\\ncoding example, 902–906\\niterable objects and, 895–906\\nmembership and, 906–909\\nuser defined classes and, 441\\n\\nint built-in function\\n\\niteration\\n\\nIndex | 1521\\n\\n\\x0cabout, 120, 416\\nadditional contexts, 429–434\\nadditional information, 440\\nbuilt-in functions and, 430, 434, 436, 574–\\n\\n576, 617–621\\n\\nbuilt-in types supported, 422–424\\ncomprehensions versus, 597–602\\nin dictionaries, 120, 253, 422, 439–440\\nin files, 286, 416–419, 590\\ngenerators and, 120, 439, 440, 592, 604–\\n\\n605, 617–621\\n\\nin lists, 242\\nloop coding techniques, 402–411, 416–424\\nmanual, 419–422\\nmultiple versus single pass, 438\\none-shot, 621\\noperator overloading and, 894–906\\nquiz questions and answers, 441\\ntiming iteration alternatives, 629–655\\nin tuples, 277\\nversion considerations, 419, 434–440\\n\\nJ\\nJIT (just-in-time) compiler, 36, 38\\nJSON format\\n\\nabout, 116, 271\\nstoring objects in, 291–292\\njson module, 13, 116, 271, 291\\njump tables, 569, 571\\njust-in-time (JIT) compiler, 36, 38\\nJython system, 34\\n\\nK\\nKeyboardInterrupt exception, 1146\\nkeys, 269\\n\\n(see also access-by-key databases and\\nfilesystems)\\naccess-by-key databases and filesystems,\\n\\n116\\n\\ndictionary, 118, 223, 252, 253, 258, 269\\ninteger-based, 259\\nmapping values to, 257\\nmissing, 116–118, 260\\nsorting, 118–119, 256, 269\\nstring method calls and, 231\\ntuple-based, 259\\nusage notes, 258\\nkeyword arguments\\n\\n1522 |\\n\\nIndex\\n\\nabout, 529, 532–534\\nabstract superclasses and, 870\\ndecorators and, 1285\\nhomegrown timing module, 641\\nmapping operations and, 114\\nmodifying sort behavior, 247\\nprinting example, 548\\nusage examples, 820\\nversion considerations, 539–542\\n\\nKISS principle, 588–589, 1070\\nKomodo IDE, 80\\n\\nL\\nlambda expressions\\n\\nabout, 505, 567–572\\ncallbacks and, 924\\ncoding functions, 475, 571–572\\ndef statement and, 505\\ninline callbacks, 573\\nmultiway branching and, 374, 570\\nnesting, 506, 572\\nscope and, 487, 488, 572\\nunpacking arguments, 528\\nusage example, 137\\n\\nlanguage features, enabling in modules, 748\\nlast-in-first-out (LIFO), 249, 559\\nLatin-1 character set, 1168\\n__le__ method, 889\\nleft-shift (<<) operator, 207\\nLEGB rule\\n\\nbuilt-in scope and, 492\\nname resolution, 488–490\\nnamespaces and, 872\\nnested classes, 875–877\\n\\nlen built-in function\\n\\ndictionaries and, 253\\nsequence shufflers, 404\\nstrings, 98\\nstrings and, 194, 197, 200, 1171\\n\\n__len__ method, 889, 927–929\\nlexical scoping, 486\\nLIFO (last-in-first-out), 249, 559\\nLinux platform\\n\\nconfiguring Python, 1430\\nfrozen binaries and, 39\\nGUI support, 11\\nicon clicks, 62\\nIDLE startup details, 75\\ninstalling Python, 28, 1424\\n\\n\\x0csystem shell prompt, 44\\nworking directory, 48\\n\\nlist built-in function\\n\\nabout, 212\\nconverting objects to lists, 279\\niteration protocol and, 267, 423, 430, 431,\\n\\n434, 439\\n\\ntype customization and, 306\\n\\nlist comprehensions\\n\\nabout, 111–113, 424–425, 581\\nextended syntax, 427–429\\nfiles and, 426\\nfilter built-in function and, 112, 583–586\\nfor statement and, 400, 415, 425\\nfunctional tools, 581–589\\ngenerator expressions and, 440\\nmap built-in function versus, 112, 243, 582,\\n\\n590\\n\\nmatrixes and, 586–588\\nrange built-in function and, 112, 242, 406\\nusage considerations, 588–589\\n\\nlist-unpacking assignments, 340\\nlists (list object)\\n\\nabout, 96, 109, 239–242\\nappend method, 110, 246, 248, 344, 432\\nbounds checking, 110\\nchanging in place, 244–250, 357\\ncommon operations, 240, 242, 249\\ncomparison operations, 302\\nconcatenating, 242, 1100\\ncopy method, 250, 299\\ncount method, 249\\ndeleting items, 249\\ndictionaries versus, 259, 263\\nempty lists, 240\\nextend method, 110, 246, 248, 431\\nindex method, 249\\nindexing, 243, 244–246\\ninsert method, 110, 245, 249\\niteration in, 242\\nliterals, 96, 240\\nmatrixes and, 243\\nmutable nature of, 109, 239\\nnesting, 110, 243\\npop method, 110, 245, 249, 344\\nquiz questions and answers, 272\\nremove method, 110, 245, 249\\nrepeating, 242\\nreverse method, 110, 247, 248\\n\\nsequence operations, 109, 243\\nslicing, 243, 244–246\\nsort method, 110, 118, 246–248\\ntuples versus, 279\\ntype-specific methods, 246–249\\ntype-specific operations, 109\\n\\nliterals\\n\\nabout, 95\\nbuilt-in object type examples, 95\\nbyte string, 1183\\ndictionary, 96, 251\\nfile, 96\\nhex, octal, binary notation, 151–153\\ninteger objects, 134, 151–153\\nlist, 96, 240\\nnumeric, 96, 134–136\\nset, 96, 166\\nstring, 96, 190–199, 378, 1175–1177\\ntuple, 96, 276\\nUnicode, 106, 190, 1176\\n\\nlittle-endian format, 1201–1204\\nlocal scope\\n\\nabout, 487\\nclass statement and, 489\\nLEGB rule and, 488, 872\\n\\nlocal variables, 483\\nlogical operations, 137\\nLookupError class, 1131\\nloops, 329\\n\\n(see also specific statements)\\nattribute interception methods and, 1240\\nbreaking out of, 1145\\ncoding techniques for, 402–411\\nelse clause, 389, 392–394\\nfunction-related gotchas, 661\\ninteractive, 329–336\\niterations and, 402–411, 416–424\\nnesting, 427–429, 506, 583–586, 1145\\nquiz questions and answers, 414\\nrecursion versus, 557\\n__lt__ method, 889, 925\\n\\nM\\nMac OS X platform\\n\\nfrozen binaries and, 39\\nGUI support, 11\\nicon clicks, 62\\nIDLE startup details, 74\\ninstalling Python, 28\\n\\nIndex | 1523\\n\\n\\x0claunch options, 82\\nsystem shell prompt, 44\\nworking directory, 48\\n\\nmacros, decorators versus, 1272\\n__main__ module, 749–751, 851\\nmanager functions, 1309, 1359–1361\\nmap built-in function\\nbenchmarking, 652\\ngenerator expressions versus, 599–601\\nhomegrown timing module and, 635–638\\niteration and, 430, 434, 436, 574–576, 617–\\n\\n621\\n\\nlist comprehensions versus, 112, 243, 582,\\n\\n590\\n\\nloop coding techniques and, 402, 407–410\\nparallel traversals, 407–410\\ntiming calls example, 1295\\nversion considerations, 408\\n\\nmapattrs module, 975\\nmapping operations\\n\\nabout, 113\\ndictionaries and, 114, 116–118, 257\\nfunctions and, 574–576\\nmapping attributes to inheritance sources,\\n\\n1004–1009\\n\\nmapping values to keys, 257\\nmissing keys, 116–118\\n\\nmath module\\nabout, 98\\nbuilt-in numeric tools, 155\\nfloor function, 148\\ntrunc function, 149\\n\\nmathematical operations\\n\\nabout, 97\\ndivision, 146–150\\nexpression operators, 137\\nnesting, 98\\n\\nMatlab numeric programming system, 4, 111\\nmatrixes\\n\\nlist comprehensions and, 586–588\\nnested lists and, 243\\n\\nmax built-in function, 155, 433\\nmembership\\n\\nin operator and, 117, 127, 214, 253\\noperator overloading and, 906–909\\n\\nmemory management\\n\\nautomatic, 18\\ngarbage collection, 116, 178, 208\\ngenerator expressions and, 599\\n\\n1524 |\\n\\nIndex\\n\\nstoring strings, 1170\\n\\nmetaclasses\\n\\nabout, 1355\\nbuilt-in object types and, 1387–1388\\ncall pattern issues and, 988\\nclass decorators and, 1034, 1038–1040,\\n1361–1363, 1394–1400, 1404–\\n1407\\n\\nclass statement and, 1367\\ncoding, 1370–1378\\ncustomizing construction and initialization,\\n\\n1372\\n\\ndeclaring, 1368–1370\\ndescriptors and, 1384\\nfactory functions and, 1373\\ninheritance and, 866, 1378–1388\\ninstances and, 1378–1388, 1396–1397\\nmethods in, 1388–1407\\nmodel overview, 1364–1368\\noperator overloading and, 1374–1378,\\n\\n1390\\n\\nsuperclasses versus, 1381\\ntype object and, 1366\\nusage considerations, 1356–1363\\nusage examples, 1391–1407\\nversion considerations, 1369–1370\\n\\nmetafunctions, 1034–1037, 1273\\nmetaprograms, 759–761\\nmethod resolution order (see MRO)\\nmethods, 822\\n\\n(see also operator overloading)\\nabout, 788, 862\\nadding, 822–826, 1391–1400\\nattribute fetches, 209\\naugmenting, 829–831\\nbinary operator, 917–921\\nbound, 573, 948–953, 1025\\nchaining, 427\\ncoding, 824–826\\ndecorators and, 1289–1295, 1400–1407\\ndictionary, 252, 254–256\\nexception handler, 1137–1139\\nexpressions and, 356\\nfile, 123, 285\\nfunctions and, 799\\ninstance, 864\\nlist, 110, 246–249\\nmetaclass, 1388–1407\\nnumber-specific, 136\\n\\n\\x0cas objects, 948–953\\nscopes in, 1068\\nstatic, 865\\nstring, 102, 191, 209–216, 215–216\\nstring formatting, 222–234\\nsuperclass constructors, 864\\ntuple, 278–279\\nunbound, 948–953, 1025\\nunderscores in, 805\\nusage examples, 863\\n\\nmicrothreads, 35\\nmin built-in function, 155, 433, 633\\nmissing keys, 116–118, 260\\nmix-in classes, 956–977, 1057–1060\\n__mod__ method, 1189\\nmodule search path\\n\\nabout, 72, 678–684, 1431\\nchanging, 756–758\\nlookup rules summary, 723\\nrunning modules, 1433\\n\\nmodules, 707\\n\\n(see also from statement; import statement;\\npackages)\\nabout, 54, 96, 98, 669–670\\nas extension for import/from statements,\\n\\n758\\n\\nattributes and, 68–71, 671–673, 804\\nbyte code files, 676–678\\nclasses and, 788, 804, 860, 884\\ncommon usage mistakes, 71, 78\\ncopying names, 689, 691–694, 772\\ncreating, 687–688\\ndata hiding in, 747\\ndesign concepts, 745–746\\ndual mode code example, 751–756\\nembedding calls, 81\\nenabling future language features, 748\\nexec built-in function and, 72\\nextension, 688\\nimporting, 707\\nmixed usage modes, 749–751\\nmodule search path, 72, 678–684, 723, 756–\\n\\n758, 1431, 1433\\n\\nname clashes, 771\\nnamespaces and, 71, 669, 694–700\\nas objects, 759–761\\npotential gotchas, 770–776\\nprograms and, 54, 93\\nPython program architecture and, 670–673\\n\\nquiz questions and answers, 685, 704, 777\\nreloading, 66–71, 78, 700–703, 763–770\\nscope considerations, 486\\nstatements and, 54, 93, 771\\nusage considerations, 688–694, 973\\n\\nmodulus operator, 217\\nmod_python package, 12\\nMongoDB database, 116\\nmovie database example, 256–258\\nMRO (method resolution order)\\n\\nabout, 986, 997–1009\\nnew-style classes and, 957, 975\\nsuper built-in function and, 831, 1050–\\n\\n1058\\n__mro__ attribute\\n\\nabout, 975, 986, 1001–1004\\ninheritance and, 1383\\n\\nmultiline block strings, 198–199\\nmultiline statements (see compound\\n\\nstatements)\\n\\nmultiple context managers, 1118–1119\\nmultiple inheritance\\n\\nabout, 789\\nclass gotchas, 1066–1068\\ndiamond patterns of, 986, 997–1009\\nmix-in classes and, 956–977\\nsuper built-in function and, 1043–1046,\\n\\n1050–1062\\n\\nmultiple instances, 797–801, 1279, 1308\\nmultiple-target assignments, 341, 348–349\\nmultiplication (*) operator\\n\\nmultiplying numbers, 97\\nrepeating lists, 242\\nrepeating strings, 100, 200\\n\\nmultithreading, 496, 595\\nmultiway branching in if statements, 372–374,\\n\\n570\\n\\nmutable objects\\n\\navoiding argument changes, 526\\nchanging in modules, 691\\ndefault values for arguments, 534\\ndictionaries as, 113\\nfunction gotchas, 658–660\\nlists as, 109, 239\\n\\nN\\n__name__ attribute\\n\\nabout, 959\\nfunctions and, 537\\n\\nIndex | 1525\\n\\n\\x0cinspecting inheritance hierarchies, 880\\nmetaprogram example, 761\\nmixed usage modes, 749–751\\nmodules and, 732, 759, 821\\npreset value, 868\\nname collisions, 71\\nname mangling, 944, 1321\\nname resolution, 488–490\\nnamed tuples, 122, 256, 277, 280–282\\nnamespace declarations, 494\\nnamespace dictionaries\\n\\nabout, 878–880\\n__dict__ attribute, 696\\nslots and, 1011–1013\\n\\nnamespace package model\\n\\nabout, 707, 723, 734\\nfile precedence in, 740–741\\nnesting, 738\\nsemantics, 735–737\\nusage examples, 737–738\\n\\nnamespaces\\n\\nabout, 68, 71, 485, 788, 872\\nassigning names, 873–875\\nattribute names and, 872\\nclasses and, 860\\n__dict__ attribute, 572, 695, 810\\nfiles generating, 695\\ninheritance and, 865\\ninstances and, 799\\nLEGB rule and, 872, 875–877\\nminimizing namespace pollution, 747\\nmodules and, 71, 669, 694–700\\nnested classes and, 875–877\\nnesting, 699\\nscope and, 485\\n\\nnaming conventions and rules\\n\\nclasses, 844\\nLEGB rule, 488–490, 492, 872, 875–877\\nscope and, 485\\nfor variables, 352–355\\n_x name prefix, 747\\n\\n__ne__ method, 889, 925\\nnesting\\n\\nblocks of code, 335, 376–378\\nclasses, 875–877\\ncontrol flows, 1143\\ndecorators, 1279–1281, 1340\\ndef statement, 477, 506, 790\\ndictionaries, 115, 252, 254, 260\\n\\n1526 |\\n\\nIndex\\n\\nexception handlers, 1141–1145\\nfor statement, 399–400\\nfunctions, 499–508, 572, 1291\\nlambda expressions, 506, 572\\nlists, 110, 243\\nloops, 427–429, 506, 583–586, 1145\\nmathematical operations, 98\\nnamespace packages, 738\\nnamespaces, 699\\nstring formatting, 225\\ntry/except/finally statement, 1104, 1143–\\n\\n1145\\n\\ntuples, 277\\n\\nNetBeans IDE, 80\\n__new__ method, 889, 929, 1371\\nnew-style classes\\n\\nabout, 839, 983–985\\nattribute tools, 1023\\nchanges in, 985–1009, 1023\\nclass tools, 986, 1004–1009\\nextensions to, 1010–1024\\nMRO and, 957, 975\\nmultiple inheritance in, 956\\nproperties, 1020–1023\\nslots, 1008, 1010–1019\\n\\nnext built-in function, 120, 419–422, 608\\n__next__ method\\nabout, 419, 889\\nfile iterators and, 417\\ngenerator functions and, 593\\niterable objects and, 895–906\\nuser defined iterables and, 608\\n\\nNone object, 127, 304\\nnonlocal statement\\n\\nabout, 320, 487, 494, 508–512\\nboundary cases, 511\\ncoding functions, 476\\nenclosing scope and, 924, 1286–1287,\\n\\n1302\\n\\nstate retention options, 512–517\\nversion considerations, 508–512\\n\\nnormal versus chained comparisons, 144–146\\nNotImplemented object, 920\\nNotImplementedError exception, 869\\nnumbers\\n\\nabout, 97–99, 133\\nbitwise operations, 153–155\\nBooleans (see Booleans)\\nbuilt-in tools, 136, 155–157\\n\\n\\x0ccomparison operations, 144–146, 302\\ncomplex, 97, 151\\ndecimals (see decimals)\\ndivision operation, 146–150\\nexpression operators, 136–141\\nin expressions, 141–143\\nfloating-point (see floating-point numbers)\\nfractions (see fractions)\\nintegers (see integers)\\nnumeric display formats, 143\\nnumeric extensions, 172\\nnumeric literals, 96, 134–136\\nquiz questions and answers, 173\\nrational, 97, 127\\nsequence operations, 98\\nsets (see sets)\\nin variables, 141–143\\n\\nnumeric programming, 13\\nNumPy numeric programming extension\\n\\nabout, 4, 7, 13\\ncustomer base, 172\\nmatrix support, 111\\n\\nO\\nobject persistence, 116\\n\\n(see also specific modules)\\nabout, 116, 847\\nclasses and, 941\\ndatabase programming and, 13\\nimplementing, 847\\n\\nobject relational mappers (ORMs), 13, 854\\nobject serialization, 1209–1211\\nobject superclass, 881, 986, 995–997\\nobject types\\n\\nbuilt-in (see built-in object types)\\ncompound, 297\\ndictionaries (see dictionaries)\\ndynamic typing, 18, 97, 175–187\\nfiles (see files)\\ngeneral type categories, 235–236\\nimplementation-related, 96\\nlists (see lists)\\nnumbers (see numbers)\\nquiz questions and answers, 131\\nstrings (see strings)\\nstrong typing, 97\\ntesting, 986, 992–995, 1342\\ntuples (see tuples)\\n\\nobject-oriented programming (see OOP)\\n\\nobjects, 93\\n\\n(see also immutable objects; mutable\\nobjects)\\nabout, 93, 94, 177\\nattributes for, 785–787\\nclasses and, 954–956, 983\\ndynamic typing, 18, 97, 175–187\\nexpressions and, 93\\ngarbage collection, 116, 178\\niterable, 120, 416, 420, 423, 895–906\\nlisting attributes per, 966–971\\nmethods as, 948–953\\nmodules as, 759–761\\noptimizing, 120\\nreference counters, 177, 179\\nshared references and, 180–185\\nslice, 891\\nstrong typing, 97\\ntype designators, 177\\nupdating on shelves, 851\\nvariables and, 176\\n\\noct built-in function, 135, 152\\n__oct__ method, 894\\noctal notation, 135, 151–153\\nOOP (object-oriented programming)\\n\\nabout, 833\\nattribute inheritance, 785–787\\nbound and unbound methods, 948–953\\nclass gotchas, 1064–1070\\nclasses and instances, 784, 788\\ncode reuse, 792–795\\ncoding class trees, 789–791\\ncoding classes, 797–816, 859–885\\ncomposition and, 937–941\\nby customization, 794\\ndecorators and metaclasses, 1034–1041\\ndelegation and, 942–943\\nexception classes, 1123–1140\\nextending built-in types, 980–983\\ngeneric object factories, 954–956\\nimportant concepts in, 836\\ninheritance and, 935–937\\nKISS principle, 1070\\nmetaclasses, 1376\\nmethod calls, 788\\nmix-in classes, 956–977\\nnew-style classes, 983–1024\\noperator overloading, 791, 887–932\\npolymorphism and, 934\\n\\nIndex | 1527\\n\\n\\x0cpseudoprivate class attributes, 944–947\\nPython and, 16, 129, 554, 933\\nquiz questions and answers, 795\\nrealistic example of classes, 817–857\\nstate information, 1232\\nstatic and class methods, 1024–1034\\nsuper built-in function, 1041–1064\\n\\nopen built-in function\\n\\ncustomizing, 517–519\\nfile processing and, 122, 126, 283\\nversion considerations, 287\\nWindows platform and, 286\\n\\noperations (see specific operations)\\noperator module, 577\\noperator overloading\\n\\nabout, 296, 785, 791, 805, 887, 1238\\nattributes and, 909–913, 1237–1256\\nbinary operator methods, 917–921\\nBoolean tests and, 927–929\\ncall expressions and, 921–925\\ncommon methods, 888–890\\ncomparisons and, 925–927\\nconstructors and expressions, 888\\ndelegation and, 1322\\ndisplay formats and, 368\\ndouble underscores and, 104\\nindexing and slicing, 890–894\\niteration and, 894–906\\nmembership and, 906–909\\nmetaclasses and, 1374–1378, 1390\\nobject destruction, 929–931\\npolymorphism and, 141\\nquiz questions and answers, 931\\nstring representation and, 913–917\\nsuper built-in function and, 1047\\nusage considerations, 808\\nusage examples, 806–808, 826–828\\nvalidating methods, 1327\\n\\noperator precedence, 139\\noptimizing objects\\n\\nabout, 120, 1159\\nbyte code files, 684\\nexecution optimization tools, 37–38\\n\\noptparse module, 754\\n__or__ method, 889\\nor operator, 384\\nord built-in function, 206, 582, 1167\\nOrderedDict subclass, 256\\nordering (see sorting)\\n\\n1528 |\\n\\nIndex\\n\\nORMs (object relational mappers), 13, 854\\nos module\\n\\ndescriptor files, 295\\n_exit function, 1153\\npopen function, 295, 402, 411, 423, 607,\\n\\n650, 1150\\n\\nsystem function, 412, 1150\\nwalk function, 423, 607\\n\\nOSError class, 1133\\nOverflowError exception, 1131, 1132\\n\\nP\\npackage imports\\n\\nabout, 707–711\\n__all__ variable, 711\\nfrom versus import statement, 713\\n__init__.py files, 709–711\\nrelative imports model, 707, 717–733\\nsearch path settings, 708, 719\\nusage considerations, 713–716\\nusage example, 711–713\\nversion considerations, 718\\n\\npackages\\n\\nabout, 707, 716\\n__all__ variable, 711\\nnamespace package model, 707, 723, 734–\\n\\n741\\n\\npackage imports, 708–716\\nquiz questions and answers, 742\\nrelative imports model, 707, 717–733\\nsearch path settings, 708, 719\\n\\nparameters (see arguments)\\nparentheses ( )\\n\\ncomprehensions and, 112\\nexpression operators and, 139\\nstatements and, 323, 328\\nsuperclasses and, 801\\ntuples and, 277\\nParrot project, 40\\nparsing text in strings, 213\\npass statement, 320, 389–390\\npassing-arguments-by-pointer, 524\\npassing-arguments-by-value, 524\\nPATH environment variable\\n\\nabout, 1427, 1428\\nenv program and, 60\\nnew Windows options, 46\\nsetting, 45, 57\\n\\npaths\\n\\n\\x0cmodule search paths, 72, 678–684, 723,\\n\\n756–758, 1431, 1433\\n\\npackage imports, 708\\npackage search paths, 708, 719\\nrecording for recursive calls, 561\\n\\npattern matching in strings\\n\\nabout, 108\\nre module and, 108, 215, 1206\\n\\npdb command-line debugger, 84, 1159\\nPEP (Python Enhancement Proposal), 15\\npercent sign (%)\\n\\nformatting expression operator, 217, 227–\\n\\n229, 1189\\n\\nsystem shell prompt, 44, 48, 56\\n\\nperformance considerations, 589\\n\\n(see also benchmarking)\\nlist comprehensions, 589\\nMRO and, 1001\\nprogram execution, 32\\nPython alternatives, 35\\nslots, 1019\\n\\nPerl programming language, 24\\npermutations, 612–614\\npersistence (see object persistence)\\nPeters, Tim, 543\\npexpect system, 295\\npickle module\\nabout, 847\\nobject persistence and, 13, 116\\nobject serialization and, 1209–1211\\npersistence and, 941\\nstoring objects, 290, 295\\n\\nplus (+) operator\\n\\nadding numbers, 97\\nconcatenating lists, 242, 1100\\nconcatenating strings, 100, 200, 1100\\n\\nPMW extension package, 11\\npolymorphism\\n\\nabout, 101, 129, 933\\nclasses and, 792–794, 832\\nin functions, 479, 482\\nOOP considerations, 934\\noperator overloading and, 141\\ntesting exception types, 1151\\n\\nportability, 17\\npositional arguments, 529, 534, 1331–1343\\npow built-in function, 155\\npprint module\\n\\npformat function, 1006\\n\\npprint function, 1006\\nusage considerations, 1009\\n\\nprecedence rules, 139\\nprint built-in function, 49, 359–361, 547–549\\nprint operations, 49\\n\\n(see also print statement)\\nabout, 358\\nbuilt-in exception classes and, 1133–1135\\ncompletion certificate, 1414–1416\\ncustom displays, 1135\\ndisplay formats, 826–828\\nexpression statements and, 356\\nfile object methods and, 358\\nprint built-in function, 49, 359–361, 547–\\n\\n549\\n\\nprint stream redirection, 363–366\\nquiz questions and answers, 370\\nstandard output stream, 295, 358, 368\\nversion considerations, 359–363, 547–549,\\n\\n821\\n\\nversion-neutral, 366–368\\n\\nprint statement\\n\\nabout, 49, 361–363\\ncommon usage mistakes, 52, 59\\ndebugging code and, 84\\nnumeric display formats and, 143\\n\\nprivate attributes, 1314–1318\\nprocedures (see functions)\\nprofile module, 121, 642, 1158\\nprogram architecture\\n\\nabout, 67\\nconceptual hierarchy, 93, 319\\nmodules and, 670–673\\n\\nprogram execution\\n\\nabout, 27\\nalternative IDEs, 79–81\\nalternative launch options, 81–83\\nbyte code compilation and, 30–31\\nclicking file icons, 62–66\\ndebugging code, 83–85\\ndevelopment considerations, 32\\nembedding calls, 81\\nexec built-in function and, 72–73\\nfrozen binaries, 39, 82\\nfuture possibilities, 40, 83\\nIDLE user interface, 73–79\\ninteractive prompt, 31, 43–54\\ninterpreters and, 27–28, 30\\nmodel variations in, 33–40\\n\\nIndex | 1529\\n\\n\\x0cmodule imports and reloads, 66–72\\noptimization tools, 37–38\\nperformance considerations, 32\\nprogrammer\\'s perspective, 28–30\\nPVM and, 31\\nquiz questions and answers, 41, 85–87\\nselecting from options, 83\\nsystem command lines and files, 54–59\\ntext editor launch options, 82\\nUnix-style scripts, 59–62\\n\\nprogram units, 96\\n\\n(see also classes; functions; modules)\\n\\nProgramming Python (Lutz), 985\\nprograms\\n\\nabout, 54\\nmetaprograms, 759–761\\nmodules and, 54, 93\\n\\nprompts (see interactive prompt; system\\n\\nprompt)\\n\\nproperties\\n\\nabout, 1020–1023\\nattribute, 1221–1226\\nclass statement, 798, 861, 1020\\ncoding with decorators, 1224–1226\\ndescriptors and, 1236–1237\\nvalidating with, 1256–1259\\n\\nproperty built-in function, 1020, 1036, 1220,\\n\\n1236\\n\\nprototyping systems, 13\\nproxy classes (wrappers)\\n\\nabout, 942–943\\ndecorators installing, 1270\\ndelegation and, 988\\n\\npseudoprivate class attributes\\n\\nabout, 845, 944–947\\nlarger projects and, 1160\\npublic attributes and, 1321\\n\\nPSF (Python Software Foundation), 15\\npstats module, 1158\\nPsyco system, 36, 38\\n.pth file extension, 708\\npublic attributes, 1318–1321\\nPVM (Python Virtual Machine), 31\\n.py file extension\\n\\nabout, 29, 675, 687\\ncommon usage mistakes, 78\\nimported files and, 55\\n\\npy2app tool, 39\\npy2exe tool, 39\\n\\n1530 |\\n\\nIndex\\n\\n.pyc file extension, 30, 675, 676\\n__pycache__ subdirectory, 31, 63, 675, 676–\\n\\n678\\n\\nPyChecker tool, 661, 1157\\nPyDev IDE, 80\\nPyDoc system\\n\\nabout, 105, 444\\nchanging colors in, 456\\nhelp function, 449–451, 883, 1157\\nHTML reports, 452–460\\nversion considerations, 452–460\\n\\npydoc.py script, 458\\npygame toolkit, 39\\nPyInstaller tool, 39, 1159\\nPyLint system, 1157\\nPyMongo interface, 116\\n.pyo file extension, 684\\nPyPy system\\n\\nabout, 7, 34\\nbenchmarking, 652\\nperformance considerations, 35\\ntimeit module and, 643–645\\n\\nPyrolog interpreter, 36\\nPySerial extension, 295\\nPySolFC program, 15\\npystone.py program, 656\\nPython Enhancement Proposal (PEP), 15\\nPython interpreter\\n\\nabout, 27, 30\\nadditional information, 1436\\nalternatives to, 36\\nbyte code and, 30–31\\nconfiguring, 1427–1436\\ndevelopment considerations, 32\\ninstalling, 28, 1421–1425\\nlocating with env program, 60\\nperformance considerations, 32\\nPVM and, 31\\n\\nPython programming language\\nadditional information, 1436\\nadvantages of, 3–5\\ncommon applications of, 10–15\\ncompared to other languages, 21–22\\ncompared to Perl, 24\\ndevelopment community, 15\\nexecution speed, 7\\nfuture directions, 853–855\\nimplementation alternatives, 33–36\\nnew Windows options, 46\\n\\n\\x0cparadox of, 1409–1414\\npillars of programming, 94\\nportability, 17\\nquiz questions and answers, 23–24\\nscripting and, 5\\ntechnical strengths, 16–21\\ntools supporting, 10–15, 19, 1156\\ntradeoffs using, 8, 15\\nuser base, 9–10, 35\\nversion considerations (see version\\n\\nconsiderations for Python)\\nPython Software Foundation (PSF), 15\\nPython Virtual Machine (PVM), 31\\nPYTHONIOENCODING environment\\n\\nvariable, 1205\\n\\nPythonLauncher, 62\\nPYTHONPATH environment variable\\n\\nabout, 1427, 1428\\nmodule search paths, 72, 679, 756\\npackage search paths, 708\\nPyDoc HTML reports, 458\\nWindows platform and, 1430\\n\\nPYTHONSTARTUP environment variable,\\n\\n1427, 1428\\nPythonWin IDE, 80\\nPyUnit tool, 1157\\n.pyw file extension, 46\\nPY_PYTHON environment variable, 61, 1427,\\n\\n1429\\n\\nPY_PYTHON2 environment variable, 1427,\\n\\n1429\\n\\nPY_PYTHON3 environment variable, 1427,\\n\\n1429\\n\\nQ\\nqueue module, 496\\nqueues\\n\\nbest-first searches, 560\\nFIFO, 559\\nrecursion versus, 559, 768\\n\\nquiz questions and answers\\n\\nchapter 1: Python Q&A session, 23–24\\nchapter 2: program execution, 41\\nchapter 3: program execution, 85–87\\nchapter 4: object types, 131\\nchapter 5: numbers, 173\\nchapter 6: dynamic typing, 186\\nchapter 7: strings, 237\\nchapter 8: lists and dictionaries, 272\\n\\nchapter 9: tuples, files, and everything else,\\n\\n311\\n\\nchapter 10: statements, 336\\nchapter 11: assignments, expressions, and\\n\\nprints, 370\\n\\nchapter 12: if tests and syntax rules, 385\\nchapter 13: while and for loops, 414\\nchapter 14: iterations and comprehensions,\\n\\n441\\n\\nchapter 15: documentation, 466\\nchapter 16: functions, 483\\nchapter 17: scopes, 519–521\\nchapter 18: arguments, 551\\nchapter 19: functions, 578\\nchapter 20: comprehensions and generators,\\n\\n626\\n\\nchapter 21: benchmarking, 662\\nchapter 22: modules, 685\\nchapter 23: modules, 704\\nchapter 24: module packages, 742\\nchapter 25: modules, 777\\nchapter 26: OOP, 795\\nchapter 27: classes, 815\\nchapter 28: classes, 855–857\\nchapter 29: classes, 884\\nchapter 30: operator overloading, 931\\nchapter 31: classes, 978\\nchapter 32: classes, 1071\\nchapter 33: exceptions, 1090\\nchapter 34: exceptions, 1120\\nchapter 35: exception classes, 1139\\nchapter 36: exceptions, 1161\\nchapter 37: Unicode and byte strings, 1215–\\n\\n1217\\n\\nchapter 38: attributes, 1266–1268\\nchapter 39: decorators, 1344–1353\\n\\nquotation marks\\n\\ninterchangeable, 193\\nmultiline block strings, 198–199\\nstrings in, 105, 191\\n\\nR\\nr file processing mode, 122, 283\\n__radd__ method, 889, 917–921\\nraise statement\\n\\nabout, 321, 1081, 1106\\nbuilt-in exceptions and, 1086\\nchaining exceptions, 1110–1112\\nfrom clause, 1110–1112\\n\\nIndex | 1531\\n\\n\\x0cpropagating exceptions, 1110\\nraising exceptions, 549, 896, 1086, 1107\\nraising instances, 1126\\nsignaling conditions with, 1147\\nversion considerations, 1107\\n\\nrandom module\\n\\nabout, 98, 156\\ngenerator example, 616\\n\\nrange built-in function\\ncounter loops, 402\\niteration and, 434, 435\\nlist comprehensions and, 112, 242, 406\\nloop coding techniques and, 344, 402–407\\nnonexhaustive traversals, 405\\nsequence scans, 403\\nsequence shufflers, 404\\ntiming calls example, 1298\\nrapid development cycle, 6, 33\\nrational numbers, 97, 127\\nraw_input built-in function, 64, 65, 330\\nre module\\n\\nabout, 96\\nfindall function, 1212\\nmatch function, 192, 1212\\npattern matching and, 108, 215, 1206\\nsearch function, 1212\\n\\nread-only descriptors, 1228\\nrecursive comparisons, 300\\nrecursive functions\\n\\nabout, 487, 555, 880\\ncoding alternatives, 556\\nfrom statement and, 775\\ngenerators and, 968\\nhandling arbitrary structures, 558–561\\nloops versus, 557\\nreloaders, 764–767\\nsummation with, 555\\nusage examples, 561\\n\\nreduce built-in function, 430, 576\\nreference counters, 177, 179\\nreferences, 180\\n\\n(see also shared references)\\nabout, 177, 500\\nassignments and, 339\\nattribute, 909\\ncircular, 179\\ncopies versus, 297–300, 308\\ncyclic, 179\\ndynamic typing and, 176, 180–185\\n\\n1532 |\\n\\nIndex\\n\\nstring method calls, 231\\nweak, 185\\n\\nrelative imports model\\n\\nabout, 707, 717–720\\nabsolute imports versus, 722\\nlookup rules summary, 723\\npitfalls of, 729–733\\nscope of, 722\\nusage considerations, 720–722\\nusage examples, 723–728\\nversion considerations, 721\\n\\nreload built-in function\\n\\nabout, 66–71, 700–703\\ncommon usage mistakes, 71, 78\\nfrom statement and, 773–775\\nusage examples, 763–770\\n\\nrepetition\\n\\nas programming pillar, 94\\nin strings, 100, 200, 242\\nin tuples, 277\\nusage considerations, 309\\n\\nrepr built-in function\\n\\nabout, 205\\ndisplay formats, 144\\nstring formatting method calls and, 224\\nversion considerations, 138\\n\\n__repr__ method\\n\\nabout, 889, 913–917\\ncustom print displays, 1135\\ninheritance and, 842, 966\\nprint display example, 826–828\\nrecursive looping and, 561\\n\\nreserved words, 352\\nreStructuredText markup language, 461\\nreturn statement\\n\\nabout, 320, 477\\ncoding functions, 475\\nfunction gotchas, 660\\nreturning multiple values, 527\\nyield statement versus, 592–597\\nreversed built-in function, 248, 401\\nRIAs (rich Internet applications), 12\\nrich Internet applications (RIAs), 12\\n__rmod__ method, 1189\\nround built-in function, 149, 156\\nrunning programs (see program execution)\\n\\nS\\nSAX parsing, 1212\\n\\n\\x0cScientificPython programming extension, 14\\nSciPy programming extension, 14, 111\\nscopes\\n\\nsemicolon (;), 323, 327\\nsentinel value, 1147\\nsequence assignments\\n\\nabout, 485–488\\naccessing global variables, 498\\nbuiltins module, 491–493\\ncomprehension variables and, 623\\nfunction-related gotchas, 661\\nglobal statement, 320, 476, 487, 494, 509\\nimports versus, 698\\nLEGB rule and, 488, 492, 872, 875–877\\nin methods and classes, 1068\\nminimizing cross-file changes, 497–498\\nminimizing global variables, 495\\nmodules and, 695\\nname resolution and, 488–490\\nnested functions and, 499–508, 572\\nnonlocal statement, 320, 476, 487, 494,\\n\\n508–517\\n\\nquiz questions and answers, 519–521\\nrelative imports model, 722\\ntry/except statement and, 1108\\nusage example, 490\\n\\nscreen scraping technique, 854\\nscripts and scripting\\n\\nabout, 5\\ncommon usage mistakes, 78\\nerror handling, 66\\nexecutable, 59–62\\nInternet, 11\\nlaunching scripts with icon clicks, 62–66\\nmodules and, 54\\nPython support, 16\\nrunning with arguments, 1432\\nterminating compound statements, 53\\ntimeit module and, 644, 647–651\\ntiming script, 634\\nwriting scripts, 55\\n\\nsearch path\\n\\nmodules, 72, 678–684, 756–758, 1431,\\n\\n1433\\n\\npackages, 708, 719\\n\\nselection as programming pillar, 94\\nself argument\\n\\nabout, 554, 863\\ncoding constructors, 818\\nlambda callbacks and, 573\\nstatic methods and, 1025\\nusage considerations, 811\\n\\nabout, 340–342\\nadvanced patterns, 342–344\\n\\nsequence operations\\n\\nbytes string type, 1190\\ndictionaries and, 258\\ngenerating scrambled sequences, 609–614\\niteration and, 434\\nlists, 109\\nloop coding techniques, 403–405\\nnumbers, 98\\nstatement execution, 375\\nstrings, 99–101\\n\\nsequences\\n\\nabout, 99\\nescape, 105, 191, 193–197\\nintersecting, 480–483, 545–547\\nlist, 109, 243\\nas programming pillar, 94\\nrepeating, 309\\nstring, 99\\ntuple, 121\\n\\nserver connections, closing, 1148\\nset built-in function, 126, 167, 306\\nset comprehensions, 166, 168, 432, 624–626\\n__set__ method\\n\\nabout, 889\\ndescriptors and, 912, 1293\\nmanaging attributes, 1227\\n\\nset notation, 111\\nsetattr built-in function, 572\\n__setattr__ method\\n\\nabout, 889, 909–913, 1220, 1238\\nattribute assignments and, 861\\nemulating privacy, 944\\nprivate attributes and, 1318\\nrecursive looping and, 561\\n\\n__setitem__ method, 889, 890–894, 1194\\nsets\\n\\nabout, 97, 126, 163, 169–171, 547\\ncomparison operations, 302\\ncopy method, 299\\ncreating, 126\\ndictionary views and, 268\\nfrozen, 167\\nimmutable constraints, 167\\nliterals, 96, 166\\n\\nIndex | 1533\\n\\n\\x0cversion considerations, 164–169\\n\\n__setslice__ method, 893\\nshadowing, 661\\nshared references\\n\\nabout, 180–181\\narguments and, 524–526\\naugmented assignments and, 352\\nequality and, 183–185\\nin-place changes and, 181–183\\nmultiple-target assignments and, 349\\n\\nShed Skin system, 33, 37\\nshell tools and commands, 6, 11, 411–413\\n\\n(see also system command lines and files)\\n\\nshelve module\\n\\nabout, 793, 847, 848\\ndictionary interfaces and, 271\\nexploring shelves interactively, 849–851\\nobject persistence and, 116, 941\\nopen function, 849\\npickle module and, 1209–1211\\nstoring objects on database, 848\\nupdating objects, 851\\n\\nshelves (see access-by-key databases and\\n\\nfilesystems)\\n\\nsingleton classes, 1301–1303\\nslice expressions, 891\\nslice objects, 891\\nslicing\\n\\nlists, 243, 244–246\\nnonexhaustive traversals, 405\\noperator overloading and, 890–893\\nstrings, 100, 201–204\\ntuples, 277\\n\\nslots\\n\\nabout, 1008, 1010\\ndescriptors and, 1237\\nexample impacts of, 1017\\nhandling generically, 1014–1016\\nmanaging attributes, 912\\nnamespace dictionaries and, 1011–1013\\nprivate attributes and, 1318\\nspeed considerations, 1019\\nsuperclasses and, 1013\\nusage rules, 1016\\n\\nsocket module, 96\\nsorted built-in function\\n\\nabout, 118\\ndictionaries and, 269, 303\\niteration and, 430\\n\\n1534 |\\n\\nIndex\\n\\nlists and, 248\\ntuples and, 278\\n\\nsorting\\n\\nkeys, 118–119, 256, 269\\nlists, 246–248\\nversion considerations, 247, 302\\n\\nsource code\\nabout, 30\\ntimestamps in, 31\\n\\nspaces versus tabs, 378\\nSphinx tool, 444, 461\\nSQL database API, 590\\nsquare brackets [ ], 96, 224, 328\\nsquare roots, 156\\nstack traces, 1084, 1099\\nStackless Python, 11, 35\\nstacks\\n\\ninspecting, 1328–1329\\nLIFO, 249, 559\\nlimiting depth of, 561\\nrecursion versus, 559, 768\\n\\nstandard error stream (stderr), 366, 930\\nstandard input stream (stdin), 369\\nstandard library\\n\\nabout, 4\\nlaunch options, 82\\n\\nstandard output stream (stdout), 295, 358,\\n\\n368\\n\\nstate information\\n\\nabout, 129\\nbuilt-in exception classes and, 1133–1135\\nclass decorators and, 1317\\nin descriptors, 1232–1235\\nfactory functions and, 501\\nfunction attributes and, 565\\nfunction decorators and, 1285–1289\\ngenerator functions, 592\\nnonlocal statement and, 512–517\\nrecursive functions and, 560\\nvalidating with descriptors and, 1259–1263\\n\\nstatements\\n\\nabout, 319\\nassignment, 320, 339–370\\ncolon character and, 322\\ncommon usage mistakes, 53\\ncompound (see compound statements)\\ncontinuation lines in, 328, 378\\ncontrol-flow, 375\\ndelimiting, 378\\n\\n\\x0cexpressions and, 93, 356–357\\nindenting, 324–327\\ninteractive loops example, 329–336\\nlisted, 320–322\\nmodules and, 54, 93, 771\\nparentheses and, 323, 328\\nPython syntax model, 322–329\\nquiz questions and answers, 336\\nsemicolon and, 323\\nspecial case rules, 327–329, 379–380\\nsyntax rules, 375–380\\nterminating, 323\\nversion considerations, 321\\n\\ntext files and, 287\\nUnicode literals, 106, 190, 1176\\nversion considerations, 194\\n\\nstream redirection, 57\\nstrides in slicing, 203\\nstring formatting\\n\\nabout, 103, 144, 1190\\nconverting integers to strings, 152\\nexpressions technique, 216–222\\nliterals, 191\\nmethod calls technique, 222–234\\nnesting, 225\\ntype codes, 218–220\\n\\nstatic methods\\n\\nstring module\\n\\nabout, 865, 1024\\nalternatives for, 1027\\ncounting instances, 1030\\nusage considerations, 1028–1030\\nversion considerations, 1025–1027\\n\\nstaticmethod built-in function, 951, 1024,\\n\\n1029–1030\\nsteps in slicing, 203\\nStopIteration exception, 417, 420, 593\\nstoring objects and data\\n\\nbinary data, 293\\nclass building example, 847–853\\nclass gotchas, 1069\\nin files, 288–290\\nin JSON format, 291–292\\npickle module, 290, 295\\non shelve database, 848\\nstrings, 1170\\nstruct module, 293\\n\\nstr built-in function\\nabout, 205, 306\\ndisplay formats, 144\\nstring formatting method calls and, 224\\nusage example, 98\\nversion considerations, 138\\n\\n__str__ method\\n\\nabout, 889, 913–917\\ncustom print displays, 1135\\ninheritance and, 808, 966\\nprint display example, 826–828, 843\\n\\nstr string type\\n\\nabout, 1171–1173\\nconverting, 1192\\nencoded text, 1183\\nre module and, 1206\\n\\nabout, 215–216\\nrelative imports examples, 719–722, 724–\\n\\n728\\n\\nstrings (str object)\\n\\nabout, 96, 99, 189, 1167–1174\\n__add__ method, 104\\nalternate ways to code, 105\\nbackslash characters, 193–197\\ncasefold method, 247\\nchanging, 102, 208, 211–213\\ncoding, 1174–1178\\ncommon operations, 190–201\\ncomparison operations, 302\\nconcatenating, 100, 104, 200, 1100\\nconverting, 152, 192, 205–207\\ndebugging, 972\\ndecode method, 192, 1177\\ndocumentation, 199, 375, 444, 446–449\\nempty strings, 191\\nencode method, 192, 1169, 1177\\nendswith method, 192, 214\\nexceptions based on, 1124\\nfind method, 102, 191, 200, 212\\nformat method, 222, 225, 227–234, 968\\nformatting (see string formatting)\\ngarbage collection and, 208\\nimmutable, 101, 191, 208\\nimporting modules by name string, 761–\\n\\n763\\n\\nindexing, 99, 201–204\\nisdigit method, 192, 332\\njoin method, 192, 213, 431, 598\\nliterals, 96, 190–199, 378, 1175–1177\\nlower method, 192, 247\\nmultiline block strings, 198–199\\n\\nIndex | 1535\\n\\n\\x0cnonexhaustive traversals, 405\\noperator overloading and, 913–917\\nparsing text, 213\\npattern matching, 108, 215\\nquiz questions and answers, 237, 1215–\\n\\n1217\\n\\nrepeating, 100, 200\\nreplace method, 102, 191, 208, 211\\nrstrip method, 191, 205, 289, 426\\nsequence operations, 99–101\\nslicing, 100, 201–204\\nsplit method, 191, 213, 289\\ntool changes, 1206–1214\\ntype and content mismatches, 1198\\ntype-specific methods, 102, 191, 209–216\\nUnicode, 106–108, 189, 754–756, 1178–\\n\\n1188\\n\\nupper method, 103, 632\\nversion considerations, 190, 194, 215–216,\\n\\n229, 968, 1165–1167, 1204\\n\\nstrong typing, 97\\nstruct module, 124, 293, 1172, 1207–1209\\n__sub__ method, 888\\nsubclasses\\n\\nabout, 787\\nclass interface techniques, 867–868\\ncoding, 828\\ncustomizing behavior, 802, 828–834\\nextending built-in types, 981–983\\ninheritance and, 808, 866\\ntype object and, 1366\\n\\nsubprocess module, 295, 413\\nsubstitution operations in string formatting,\\n\\n103\\n\\nsum built-in function, 112, 155, 555\\nsuper built-in function\\n\\nabout, 831, 865, 1041\\nbasic usage and tradeoffs, 1043–1049\\ndebates about, 1041–1042\\nmultiple inheritance and, 1043–1046,\\n\\n1050–1062\\n\\noperator overloading and, 1047\\nruntime class changes, 1049\\nsummary of, 1062\\nversion considerations, 1048\\n\\nsuperclasses\\n\\nabout, 787\\nabstract, 869–871, 939\\nclass gotchas, 1069\\n\\n1536 |\\n\\nIndex\\n\\nclass interface techniques, 867–868\\nconstructor methods, 864\\ncustomizing, 833\\ninheritance and, 866\\nmetaclasses versus, 1381\\nmultiple inheritance and, 956\\noperator overloading methods and, 1325\\nparentheses and, 801\\nslots and, 1013\\ntraditional forms, 1042\\n\\nsys module\\n\\nargv attribute, 204, 650, 751\\nexcepthook function, 1149\\nexc_info function, 1138, 1149, 1150–1152\\nexit function, 1146, 1153\\nfile name settings, 1205\\ngetrecursionlimit function, 561\\nmodules dictionary, 498, 676, 759\\npath list, 72, 682, 719, 723, 756\\nplatform attribute, 55, 223, 631\\nsetrecursionlimit function, 561\\nstderr attribute, 366, 930\\nstdin attribute, 369\\nstdout attribute, 295, 358, 363–366, 368\\n\\nsystem command lines and files\\n\\nabout, 54, 1432–1436\\ncommon usage mistakes, 58\\nrunning files with command lines, 56\\nrunning in Python, 294, 411–413, 423, 650,\\n\\n770\\n\\nstarting interactive sessions, 44\\nsystem shell prompt, 44, 48\\ntimeit module and, 644\\nusage variations, 57\\nwriting scripts, 55\\nsystem shell prompt\\n\\nabout, 44, 48\\nrunning files, 56\\n\\nSystemExit exception, 1146, 1153\\nsysteminfo command, 412\\nsystems programming, 11\\n\\nT\\n-t command-line flag, 378\\ntabs versus spaces, 378\\nTCL_LIBRARY environment variable, 1427\\ntermination actions\\n\\nabout, 1083, 1087–1088\\ndefault exception handler and, 1084\\n\\n\\x0ctry/finally statement and, 1083, 1087–1088,\\n\\n1100–1102, 1152\\n\\nwith/as statement and, 1083, 1088, 1152\\n\\ntesting\\n\\nerror handling, 332–334\\nfiltering results, 427\\nfrom statement and, 774\\ninteractive prompt and, 51\\nlist comprehensions and, 583–586\\nfor missing keys, 117\\nwith __name__ attribute, 750\\nfor positional arguments, 1331–1343\\nprocesses, 819–820, 1149\\nreloading variants, 769\\ntiming calls example, 1297\\ntruth values, 171, 305, 380–382, 927–929\\ntype, 986, 992–995, 1342\\ntext editor launch options, 82\\ntext files\\n\\nabout, 107, 1173–1174, 1196\\nbinary files and, 123\\ncreating, 122\\nUnicode, 124–126, 190, 754–756\\nversion considerations, 287, 1197\\n\\n_thread module, 496\\nthreading module, 496\\n3to2 converter, 367\\ntime module\\n\\nabout, 121, 543\\nclock function, 631, 633, 644, 1297\\nhomegrown timing module and, 630\\nperf_counter function, 633, 1297\\nprocess_time function, 633\\ntime function, 631, 633\\n\\ntimeit module\\n\\nabout, 121, 543, 642–647\\nbenchmark and script, 647–651\\nother examples, 890, 1019, 1297, 1434,\\n\\n1484\\n\\nrepeat function, 643\\nsetup code, 646, 654\\n\\ntimestamps in source code, 31\\ntiming calls with function decorators, 1295–\\n\\n1301\\n\\ntiming iterations\\n\\nalternatives for, 629–642\\ntimeit module, 642–655\\n\\ntimsort algorithm, 543\\ntkinter GUI toolkit\\n\\nabout, 11\\ncallbacks and, 923, 953\\ncommon usage mistakes, 79\\nconfiguring Python and, 1428\\nIDLE and, 74\\nkeyword arguments and, 550\\nlambda callbacks, 573\\nquit function, 79\\ntesting reloading variants, 769\\n\\nTK_LIBRARY environment variable, 1427\\ntraceback module, 1151\\ntraceback objects, 1150, 1151\\ntranslation (see encoding and decoding)\\ntriple quotes, 198–199\\ntrue value in Python\\n\\nBooleans and, 171, 304–305, 380–382\\nbuilt-in scope and, 494\\noperator overloading and, 927–929\\n\\ntruncating division, 146–150\\ntry statement\\n\\nabout, 1094–1095\\ncatching built-in exceptions, 1100\\nclauses supported, 1095–1098\\ndebugging with, 1149\\ndefault behavior, 1098\\nwrapping statements with, 1152\\n\\ntry/except statement\\nabout, 321, 1081\\ncatching exceptions, 1084, 1088, 1096–\\n\\n1097, 1100\\n\\nerror handling, 333–334\\nnesting, 1141–1145\\nscopes and, 1108\\n\\ntry/except/else statement, 1093–1100, 1147,\\n\\n1150\\n\\ntry/except/finally statement, 1102–1106,\\n\\n1143–1145\\ntry/finally statement\\nabout, 321, 1081\\nclosing files and server connections, 1148\\nclosing files example, 294\\ntermination actions, 1083, 1087–1088,\\n\\n1100–1102, 1152\\n\\n-tt command-line flag, 378\\ntuple built-in function, 279, 306, 431\\ntuple-unpacking assignments, 340, 396–398\\ntuples\\n\\nabout, 70, 121–122, 276\\nassignments and, 591\\n\\nIndex | 1537\\n\\n\\x0ccommon operations, 276, 277–279\\ncomparison operations, 302\\nconcatenating, 277\\nconverting, 278–279\\ncount method, 277, 279\\nempty, 276\\nexception hierarchies and, 1129\\nimmutable, 121, 278–279\\nindex method, 277, 279\\nindexing, 277\\niteration in, 277\\nlists versus, 279\\nliterals, 96, 276\\nnamed, 122, 256, 277, 280–282\\nnesting, 277\\nquiz questions and answers, 311\\nrepeating, 277\\nslicing, 277\\ntuple keys, 259\\ntype-specific methods, 278–279\\n\\n2to3 converter, 366\\ntype built-in function, 128, 306, 986, 992–995\\ntype designators, 177\\ntype object\\n\\nclasses as instances of, 1364–1366\\ninheritance and, 1379\\nmetaclasses as subclasses of, 1366\\n\\nTypeError exception, 1100, 1356\\ntypes module, 306, 764\\n\\nU\\nunbound methods, 948–953, 1025\\nunderscore (_)\\n\\nclass names, 845\\nmodule names, 70, 747\\nname mangling and, 945\\noperator overloading, 104, 805\\nshowing name values, 971\\n\\nUnicode character set\\n\\ncharacter code conversions, 207\\ncode points, 106, 194, 206, 1170\\ncurrency symbols, 754–756\\nencoding and decoding, 123, 190, 192,\\n\\n1178–1188, 1199–1206\\n\\nJSON format and, 292\\nliterals and, 106, 190, 1176\\nquiz questions and answers, 1215–1217\\nstrings and, 106–108, 189, 754–756, 1178–\\n\\n1188\\n\\n1538 |\\n\\nIndex\\n\\ntext files and, 124–126, 190, 754–756\\n\\nunicode string type\\n\\nabout, 106, 190, 287, 1171–1173\\ncoding strings with, 1185–1187\\nconverting, 1192\\nre module and, 1206\\n\\nunittest module, 750, 1158\\nUnix platform\\n\\nawk utility, 413\\nconfiguring Python, 1430\\nenv program, 60\\nexecutable scripts, 59–62\\nfrozen binaries, 39\\nGUI support, 11\\nicon clicks, 62\\nIDLE startup details, 75\\ninstalling Python, 28, 1425\\nsystem shell prompt, 44\\nWindows launcher and, 1437\\nworking directory, 48\\n\\nUnladen Swallow project, 40\\nunpacking arguments, 528, 535\\nuser-defined classes, 129\\nuser-defined exceptions, 1086, 1134, 1147\\nUTF-16 encoding, 1170\\nUTF-8 encoding, 1168\\n\\nV\\nvalidating\\n\\nattributes, 1256–1266\\nfunction arguments, 1330–1343\\noperator overloading methods, 1327\\n\\nvalue equality operators, 137\\nvan Rossum, Guido, 17\\nvarargs, 529, 536–537\\nvariables\\n\\nabout, 177\\nassigning values to, 50, 99, 176, 177\\nattributes and, 68\\ncomprehension, 490, 623\\ncreating, 99, 176\\ndynamic typing and, 176–178\\nexception, 490\\nexpressions and, 176\\nfrom * statement and, 773\\nfunction-related gotchas, 661\\nglobal, 495, 498, 745\\nlocal, 483\\nname collisions and, 71\\n\\n\\x0cname rules for, 352–355\\nnumbers in, 141–143\\nobjects and, 176\\nscope of, 486\\nshared references and, 180–185\\ntry/except statement and, 1108\\nversion considerations for Python\\n\\nabout, xxxvi–xxxix\\nabstract superclasses, 870\\nBooleans, 928\\nbuiltins module, 156, 493\\nclasses, 983\\ncomparisons and sorts, 247, 302\\ncontext managers, 1118–1119\\ndictionaries, 264–271, 303\\ndivision operations, 146–148\\nexception classes, 1123\\nexpression operators, 138\\nfiles, 287, 1197\\nfunction attributes, 515–517\\niteration, 419, 434–440, 896\\nkeyword arguments, 539–542\\nmap built-in function, 408\\nmetaclasses, 1369–1370\\nnext method, 593\\nnonlocal statement, 508–512\\npackage imports, 718\\nprinting, 359–363, 547–549, 821\\nPyDoc system, 452–460\\nraise statement, 1107\\nrelative imports model, 721\\nsets, 164–169\\nstatements, 321\\nstatic methods, 1025–1027\\nstoring strings in memory, 1170\\nstrings, 190, 194, 215–216, 229, 968, 1165–\\n\\n1167, 1204\\n\\nsummarized, 1451–1463\\nsuper built-in function, 1048\\nthreading, 496\\nunbound methods, 950\\nwrapper classes, 943\\n\\nview objects, 266–269, 439–440\\nvirtual attributes, 1014–1016\\nvirtual concatenation, 737\\n\\nW\\nw file processing mode, 122, 283\\nwarnings module, 1147\\n\\nweak references, 185\\nweakref module, 185\\nwebsites, 462, 853\\nwhile statement\\n\\nabout, 119, 320, 387\\nC language, 394\\ngeneral format, 388\\ninteractive loops example, 330\\niteration and, 418\\nquiz questions and answers, 414\\nrecursion versus, 557\\nsequence scans, 403\\nusage examples, 388\\n\\nwhitespace, 191\\nwin32all package, 716\\nWindows launcher\\n\\n#! comment support, 60–62\\nabout, 46, 57, 1439–1441, 1450\\ncommand lines, 1435\\nicon clicks, 62\\npitfalls, 1447–1450\\ntutorial on, 1441–1447\\nUnix legacy, 1437\\nWindows legacy, 1438\\n\\nWindows platform\\n\\n#! comment support, 60–62\\ncommand-line interface, 45, 57\\ncommon usage mistakes, 58\\nconfiguring Python, 1430\\nfrozen binaries and, 39\\nGUI support, 11\\nicon clicks, 62, 63–65\\nIDLE startup details, 74\\ninstalling Python, 28, 1424, 1425–1427\\nnew options, 46\\nopen built-in function, 286\\nPython documentation, 461\\nsystem shell prompt, 44\\nsysteminfo command, 412\\nwin32all package, 716\\nworking directory, 47\\n\\nWindows Registry Editor, 1431\\nWing IDE, 80\\nWinpdb system, 85\\nwith/as statement\\n\\nabout, 321, 1081, 1114–1117\\nclosing files and server connections, 1148\\nfile objects and, 285, 294\\nresetting precision, 159\\n\\nIndex | 1539\\n\\n\\x0ctermination actions, 1083, 1088, 1152\\nversion considerations, 1118–1119\\n\\nworking directory, 47\\nwrappers (proxy classes)\\n\\nabout, 942–943\\ndecorators installing, 1270\\ndelegation and, 988\\n\\nwriting scripts, 55\\nwxPython GUI API, 11\\n\\nX\\n_x naming convention, 747, 1321\\nXML parsing tools, 1211–1214\\nxrange built-in function, 403, 435\\n\\nY\\nyield operator, 137\\nyield statement\\nabout, 320\\ncoding example, 902–906\\ncoding functions, 475\\nextended syntax, 605\\nfunction gotchas, 660\\ngenerator functions and, 591\\niteration and, 423, 440\\nreturn statement versus, 592–597\\n\\nZ\\nZeroDivisionError exception, 1131, 1132\\nzip built-in function\\n\\ndictionary keys and, 262, 265\\niteration and, 430, 433, 434, 437, 617–621\\nloop coding techniques and, 402, 407–410\\nparallel traversals, 407–410\\n\\n.zip file extension, 684\\nZODB object-oriented database system, 854\\n\\n1540 |\\n\\nIndex\\n\\n\\x0cAbout the Author\\nMark Lutz is a leading Python trainer, the author of Python’s earliest and best-selling\\ntexts, and a pioneering figure in the Python world.\\nMark  is  the  author  of  the  three  O’Reilly  books  Learning  Python,  Programming\\nPython, and Python Pocket Reference, all currently in fourth or fifth editions. He has\\nbeen using and promoting Python since 1992, started writing Python books in 1995,\\nand began teaching Python classes in 1997. As of Spring 2013, Mark has instructed 260\\nPython training sessions, taught roughly 4,000 students in live classes, and written\\nPython books that have sold 400,000 units and been translated to at least a dozen\\nlanguages.\\nTogether, his two decades of Python efforts have helped to establish it as one of the\\nmost widely used programming languages in the world today. In addition, Mark has\\nbeen in the software field for 30 years. He holds BS and MS degrees in computer science\\nfrom the University of Wisconsin where he explored implementations of the Prolog\\nlanguage, and over his career has worked as a professional software developer on com-\\npilers, programming tools, scripting applications, and assorted client/server systems.\\nMark maintains a training website and an additional book support site on the Web.\\n\\nColophon\\nThe animal on the cover of Learning Python, Fifth Edition, is a wood rat (Neotoma\\nMuridae). The wood rat lives in a wide range of conditions (mostly rocky, scrub, and\\ndesert areas) over much of North and Central America, generally at some distance from\\nhumans. Wood rats are good climbers, nesting in trees or bushes up to six meters off\\nthe ground; some species burrow underground or in rock crevices or inhabit other\\nspecies’ abandoned holes.\\nThese grayish-beige, medium-size rodents are the original pack rats: they carry anything\\nand everything into their homes, whether or not it’s needed, and are especially attracted\\nto shiny objects such as tin cans, glass, and silverware.\\nThe cover image is a 19th-century engraving from Cuvier’s Animals. The cover font is\\nAdobe  ITC  Garamond.  The  text  font  is  Linotype  Birka;  the  heading  font  is  Adobe\\nMyriad Condensed; and the code font is LucasFont’s TheSansMonoCondensed.\\n\\n\\x0c\\x0c'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571459\n"
     ]
    }
   ],
   "source": [
    "print(len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wand.image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\srivutta\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\srivutta\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pdf2image) (6.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\LearningPython.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from PIL import Image as img1\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd=\"C:\\\\Sridhar\\\\AI_ML\\\\downloads\\\\programFiles\\\\Tesseract-OCR\\\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The below logic will help to convert pdf pages to images using PDFToImage package\n",
    "### Also, below logic will convert images into text using pytesseract packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-f3e8266e4759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_data_pdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "with(Image(filename=base_data_pdf[1], resolution=120)) as source: \n",
    "    images = source.sequence\n",
    "    pages = len(images)\n",
    "    print(pages)\n",
    "    for i in range(pages):\n",
    "        newfilename = base_data_pdf[1][:-4] +str(i) + '.jpeg'\n",
    "        Image(images[i]).save(filename=newfilename)\n",
    "        img=img1.open(newfilename)\n",
    "        print(pytesseract.image_to_string(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "base_dataset_pdf= glob.glob(\"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\*.pdf\")\n",
    "print(len(base_dataset_pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_1MB.pdf']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset_pdf[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Image' has no attribute 'open'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-568661d10808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_500_kB0.jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Simple image to string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Image' has no attribute 'open'"
     ]
    }
   ],
   "source": [
    "img=Image.open(\"C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_500_kB0.jpeg\")\n",
    "\n",
    "# Simple image to string\n",
    "print(pytesseract.image_to_string(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_1MB.pdf'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset_pdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saving images as files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytesseract.pytesseract.tesseract_cmd=\"C:\\\\Sridhar\\\\AI_ML\\\\downloads\\\\programFiles\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "\n",
    "# try:\n",
    "#     from PIL import Image as img1\n",
    "# except ImportError:\n",
    "#     import Image\n",
    "# import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_1MB.pdf',\n",
       " 'C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-example_PDF_500_kB.pdf',\n",
       " 'C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\file-sample_150kB.pdf',\n",
       " 'C:\\\\Sridhar\\\\AI_ML\\\\Python\\\\Pandas\\\\Nov_11\\\\pdf\\\\LearningPython.pdf']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "30\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "1 30\n",
      "test\n",
      "5\n",
      "2 31\n",
      "2 32\n",
      "2 33\n",
      "2 34\n",
      "2 35\n",
      "test\n",
      "4\n",
      "3 36\n",
      "3 37\n",
      "3 38\n",
      "3 39\n",
      "test\n",
      "1594\n",
      "4 40\n",
      "4 41\n",
      "4 42\n",
      "4 43\n",
      "4 44\n",
      "4 45\n",
      "4 46\n",
      "4 47\n",
      "4 48\n",
      "4 49\n",
      "4 50\n",
      "4 51\n",
      "4 52\n",
      "4 53\n",
      "4 54\n",
      "4 55\n",
      "4 56\n",
      "4 57\n",
      "4 58\n",
      "4 59\n",
      "4 60\n",
      "4 61\n",
      "4 62\n",
      "4 63\n",
      "4 64\n",
      "4 65\n",
      "4 66\n",
      "4 67\n",
      "4 68\n",
      "4 69\n",
      "4 70\n",
      "4 71\n",
      "4 72\n",
      "4 73\n",
      "4 74\n",
      "4 75\n",
      "4 76\n",
      "4 77\n",
      "4 78\n",
      "4 79\n",
      "4 80\n",
      "4 81\n",
      "4 82\n",
      "4 83\n",
      "4 84\n",
      "4 85\n",
      "4 86\n",
      "4 87\n",
      "4 88\n",
      "4 89\n",
      "4 90\n",
      "4 91\n",
      "4 92\n",
      "4 93\n",
      "4 94\n",
      "4 95\n",
      "4 96\n",
      "4 97\n",
      "4 98\n",
      "4 99\n",
      "4 100\n",
      "4 101\n",
      "4 102\n",
      "4 103\n",
      "4 104\n",
      "4 105\n",
      "4 106\n",
      "4 107\n",
      "4 108\n",
      "4 109\n",
      "4 110\n",
      "4 111\n",
      "4 112\n",
      "4 113\n",
      "4 114\n",
      "4 115\n",
      "4 116\n",
      "4 117\n",
      "4 118\n",
      "4 119\n",
      "4 120\n",
      "4 121\n",
      "4 122\n",
      "4 123\n",
      "4 124\n",
      "4 125\n",
      "4 126\n",
      "4 127\n",
      "4 128\n",
      "4 129\n",
      "4 130\n",
      "4 131\n",
      "4 132\n",
      "4 133\n",
      "4 134\n",
      "4 135\n",
      "4 136\n",
      "4 137\n",
      "4 138\n",
      "4 139\n",
      "4 140\n",
      "4 141\n",
      "4 142\n",
      "4 143\n",
      "4 144\n",
      "4 145\n",
      "4 146\n",
      "4 147\n",
      "4 148\n",
      "4 149\n",
      "4 150\n",
      "4 151\n",
      "4 152\n",
      "4 153\n",
      "4 154\n",
      "4 155\n",
      "4 156\n",
      "4 157\n",
      "4 158\n",
      "4 159\n",
      "4 160\n",
      "4 161\n",
      "4 162\n",
      "4 163\n",
      "4 164\n",
      "4 165\n",
      "4 166\n",
      "4 167\n",
      "4 168\n",
      "4 169\n",
      "4 170\n",
      "4 171\n",
      "4 172\n",
      "4 173\n",
      "4 174\n",
      "4 175\n",
      "4 176\n",
      "4 177\n",
      "4 178\n",
      "4 179\n",
      "4 180\n",
      "4 181\n",
      "4 182\n",
      "4 183\n",
      "4 184\n",
      "4 185\n",
      "4 186\n",
      "4 187\n",
      "4 188\n",
      "4 189\n",
      "4 190\n",
      "4 191\n",
      "4 192\n",
      "4 193\n",
      "4 194\n",
      "4 195\n",
      "4 196\n",
      "4 197\n",
      "4 198\n",
      "4 199\n",
      "4 200\n",
      "4 201\n",
      "4 202\n",
      "4 203\n",
      "4 204\n",
      "4 205\n",
      "4 206\n",
      "4 207\n",
      "4 208\n",
      "4 209\n",
      "4 210\n",
      "4 211\n",
      "4 212\n",
      "4 213\n",
      "4 214\n",
      "4 215\n",
      "4 216\n",
      "4 217\n",
      "4 218\n",
      "4 219\n",
      "4 220\n",
      "4 221\n",
      "4 222\n",
      "4 223\n",
      "4 224\n",
      "4 225\n",
      "4 226\n",
      "4 227\n",
      "4 228\n",
      "4 229\n",
      "4 230\n",
      "4 231\n",
      "4 232\n",
      "4 233\n",
      "4 234\n",
      "4 235\n",
      "4 236\n",
      "4 237\n",
      "4 238\n",
      "4 239\n",
      "4 240\n",
      "4 241\n",
      "4 242\n",
      "4 243\n",
      "4 244\n",
      "4 245\n",
      "4 246\n",
      "4 247\n",
      "4 248\n",
      "4 249\n",
      "4 250\n",
      "4 251\n",
      "4 252\n",
      "4 253\n",
      "4 254\n",
      "4 255\n",
      "4 256\n",
      "4 257\n",
      "4 258\n",
      "4 259\n",
      "4 260\n",
      "4 261\n",
      "4 262\n",
      "4 263\n",
      "4 264\n",
      "4 265\n",
      "4 266\n",
      "4 267\n",
      "4 268\n",
      "4 269\n",
      "4 270\n",
      "4 271\n",
      "4 272\n",
      "4 273\n",
      "4 274\n",
      "4 275\n",
      "4 276\n",
      "4 277\n",
      "4 278\n",
      "4 279\n",
      "4 280\n",
      "4 281\n",
      "4 282\n",
      "4 283\n",
      "4 284\n",
      "4 285\n",
      "4 286\n",
      "4 287\n",
      "4 288\n",
      "4 289\n",
      "4 290\n",
      "4 291\n",
      "4 292\n",
      "4 293\n",
      "4 294\n",
      "4 295\n",
      "4 296\n",
      "4 297\n",
      "4 298\n",
      "4 299\n",
      "4 300\n",
      "4 301\n",
      "4 302\n",
      "4 303\n",
      "4 304\n",
      "4 305\n",
      "4 306\n",
      "4 307\n",
      "4 308\n",
      "4 309\n",
      "4 310\n",
      "4 311\n",
      "4 312\n",
      "4 313\n",
      "4 314\n",
      "4 315\n",
      "4 316\n",
      "4 317\n",
      "4 318\n",
      "4 319\n",
      "4 320\n",
      "4 321\n",
      "4 322\n",
      "4 323\n",
      "4 324\n",
      "4 325\n",
      "4 326\n",
      "4 327\n",
      "4 328\n",
      "4 329\n",
      "4 330\n",
      "4 331\n",
      "4 332\n",
      "4 333\n",
      "4 334\n",
      "4 335\n",
      "4 336\n",
      "4 337\n",
      "4 338\n",
      "4 339\n",
      "4 340\n",
      "4 341\n",
      "4 342\n",
      "4 343\n",
      "4 344\n",
      "4 345\n",
      "4 346\n",
      "4 347\n",
      "4 348\n",
      "4 349\n",
      "4 350\n",
      "4 351\n",
      "4 352\n",
      "4 353\n",
      "4 354\n",
      "4 355\n",
      "4 356\n",
      "4 357\n",
      "4 358\n",
      "4 359\n",
      "4 360\n",
      "4 361\n",
      "4 362\n",
      "4 363\n",
      "4 364\n",
      "4 365\n",
      "4 366\n",
      "4 367\n",
      "4 368\n",
      "4 369\n",
      "4 370\n",
      "4 371\n",
      "4 372\n",
      "4 373\n",
      "4 374\n",
      "4 375\n",
      "4 376\n",
      "4 377\n",
      "4 378\n",
      "4 379\n",
      "4 380\n",
      "4 381\n",
      "4 382\n",
      "4 383\n",
      "4 384\n",
      "4 385\n",
      "4 386\n",
      "4 387\n",
      "4 388\n",
      "4 389\n",
      "4 390\n",
      "4 391\n",
      "4 392\n",
      "4 393\n",
      "4 394\n",
      "4 395\n",
      "4 396\n",
      "4 397\n",
      "4 398\n",
      "4 399\n",
      "4 400\n",
      "4 401\n",
      "4 402\n",
      "4 403\n",
      "4 404\n",
      "4 405\n",
      "4 406\n",
      "4 407\n",
      "4 408\n",
      "4 409\n",
      "4 410\n",
      "4 411\n",
      "4 412\n",
      "4 413\n",
      "4 414\n",
      "4 415\n",
      "4 416\n",
      "4 417\n",
      "4 418\n",
      "4 419\n",
      "4 420\n",
      "4 421\n",
      "4 422\n",
      "4 423\n",
      "4 424\n",
      "4 425\n",
      "4 426\n",
      "4 427\n",
      "4 428\n",
      "4 429\n",
      "4 430\n",
      "4 431\n",
      "4 432\n",
      "4 433\n",
      "4 434\n",
      "4 435\n",
      "4 436\n",
      "4 437\n",
      "4 438\n",
      "4 439\n",
      "4 440\n",
      "4 441\n",
      "4 442\n",
      "4 443\n",
      "4 444\n",
      "4 445\n",
      "4 446\n",
      "4 447\n",
      "4 448\n",
      "4 449\n",
      "4 450\n",
      "4 451\n",
      "4 452\n",
      "4 453\n",
      "4 454\n",
      "4 455\n",
      "4 456\n",
      "4 457\n",
      "4 458\n",
      "4 459\n",
      "4 460\n",
      "4 461\n",
      "4 462\n",
      "4 463\n",
      "4 464\n",
      "4 465\n",
      "4 466\n",
      "4 467\n",
      "4 468\n",
      "4 469\n",
      "4 470\n",
      "4 471\n",
      "4 472\n",
      "4 473\n",
      "4 474\n",
      "4 475\n",
      "4 476\n",
      "4 477\n",
      "4 478\n",
      "4 479\n",
      "4 480\n",
      "4 481\n",
      "4 482\n",
      "4 483\n",
      "4 484\n",
      "4 485\n",
      "4 486\n",
      "4 487\n",
      "4 488\n",
      "4 489\n",
      "4 490\n",
      "4 491\n",
      "4 492\n",
      "4 493\n",
      "4 494\n",
      "4 495\n",
      "4 496\n",
      "4 497\n",
      "4 498\n",
      "4 499\n",
      "4 500\n",
      "4 501\n",
      "4 502\n",
      "4 503\n",
      "4 504\n",
      "4 505\n",
      "4 506\n",
      "4 507\n",
      "4 508\n",
      "4 509\n",
      "4 510\n",
      "4 511\n",
      "4 512\n",
      "4 513\n",
      "4 514\n",
      "4 515\n",
      "4 516\n",
      "4 517\n",
      "4 518\n",
      "4 519\n",
      "4 520\n",
      "4 521\n",
      "4 522\n",
      "4 523\n",
      "4 524\n",
      "4 525\n",
      "4 526\n",
      "4 527\n",
      "4 528\n",
      "4 529\n",
      "4 530\n",
      "4 531\n",
      "4 532\n",
      "4 533\n",
      "4 534\n",
      "4 535\n",
      "4 536\n",
      "4 537\n",
      "4 538\n",
      "4 539\n",
      "4 540\n",
      "4 541\n",
      "4 542\n",
      "4 543\n",
      "4 544\n",
      "4 545\n",
      "4 546\n",
      "4 547\n",
      "4 548\n",
      "4 549\n",
      "4 550\n",
      "4 551\n",
      "4 552\n",
      "4 553\n",
      "4 554\n",
      "4 555\n",
      "4 556\n",
      "4 557\n",
      "4 558\n",
      "4 559\n",
      "4 560\n",
      "4 561\n",
      "4 562\n",
      "4 563\n",
      "4 564\n",
      "4 565\n",
      "4 566\n",
      "4 567\n",
      "4 568\n",
      "4 569\n",
      "4 570\n",
      "4 571\n",
      "4 572\n",
      "4 573\n",
      "4 574\n",
      "4 575\n",
      "4 576\n",
      "4 577\n",
      "4 578\n",
      "4 579\n",
      "4 580\n",
      "4 581\n",
      "4 582\n",
      "4 583\n",
      "4 584\n",
      "4 585\n",
      "4 586\n",
      "4 587\n",
      "4 588\n",
      "4 589\n",
      "4 590\n",
      "4 591\n",
      "4 592\n",
      "4 593\n",
      "4 594\n",
      "4 595\n",
      "4 596\n",
      "4 597\n",
      "4 598\n",
      "4 599\n",
      "4 600\n",
      "4 601\n",
      "4 602\n",
      "4 603\n",
      "4 604\n",
      "4 605\n",
      "4 606\n",
      "4 607\n",
      "4 608\n",
      "4 609\n",
      "4 610\n",
      "4 611\n",
      "4 612\n",
      "4 613\n",
      "4 614\n",
      "4 615\n",
      "4 616\n",
      "4 617\n",
      "4 618\n",
      "4 619\n",
      "4 620\n",
      "4 621\n",
      "4 622\n",
      "4 623\n",
      "4 624\n",
      "4 625\n",
      "4 626\n",
      "4 627\n",
      "4 628\n",
      "4 629\n",
      "4 630\n",
      "4 631\n",
      "4 632\n",
      "4 633\n",
      "4 634\n",
      "4 635\n",
      "4 636\n",
      "4 637\n",
      "4 638\n",
      "4 639\n",
      "4 640\n",
      "4 641\n",
      "4 642\n",
      "4 643\n",
      "4 644\n",
      "4 645\n",
      "4 646\n",
      "4 647\n",
      "4 648\n",
      "4 649\n",
      "4 650\n",
      "4 651\n",
      "4 652\n",
      "4 653\n",
      "4 654\n",
      "4 655\n",
      "4 656\n",
      "4 657\n",
      "4 658\n",
      "4 659\n",
      "4 660\n",
      "4 661\n",
      "4 662\n",
      "4 663\n",
      "4 664\n",
      "4 665\n",
      "4 666\n",
      "4 667\n",
      "4 668\n",
      "4 669\n",
      "4 670\n",
      "4 671\n",
      "4 672\n",
      "4 673\n",
      "4 674\n",
      "4 675\n",
      "4 676\n",
      "4 677\n",
      "4 678\n",
      "4 679\n",
      "4 680\n",
      "4 681\n",
      "4 682\n",
      "4 683\n",
      "4 684\n",
      "4 685\n",
      "4 686\n",
      "4 687\n",
      "4 688\n",
      "4 689\n",
      "4 690\n",
      "4 691\n",
      "4 692\n",
      "4 693\n",
      "4 694\n",
      "4 695\n",
      "4 696\n",
      "4 697\n",
      "4 698\n",
      "4 699\n",
      "4 700\n",
      "4 701\n",
      "4 702\n",
      "4 703\n",
      "4 704\n",
      "4 705\n",
      "4 706\n",
      "4 707\n",
      "4 708\n",
      "4 709\n",
      "4 710\n",
      "4 711\n",
      "4 712\n",
      "4 713\n",
      "4 714\n",
      "4 715\n",
      "4 716\n",
      "4 717\n",
      "4 718\n",
      "4 719\n",
      "4 720\n",
      "4 721\n",
      "4 722\n",
      "4 723\n",
      "4 724\n",
      "4 725\n",
      "4 726\n",
      "4 727\n",
      "4 728\n",
      "4 729\n",
      "4 730\n",
      "4 731\n",
      "4 732\n",
      "4 733\n",
      "4 734\n",
      "4 735\n",
      "4 736\n",
      "4 737\n",
      "4 738\n",
      "4 739\n",
      "4 740\n",
      "4 741\n",
      "4 742\n",
      "4 743\n",
      "4 744\n",
      "4 745\n",
      "4 746\n",
      "4 747\n",
      "4 748\n",
      "4 749\n",
      "4 750\n",
      "4 751\n",
      "4 752\n",
      "4 753\n",
      "4 754\n",
      "4 755\n",
      "4 756\n",
      "4 757\n",
      "4 758\n",
      "4 759\n",
      "4 760\n",
      "4 761\n",
      "4 762\n",
      "4 763\n",
      "4 764\n",
      "4 765\n",
      "4 766\n",
      "4 767\n",
      "4 768\n",
      "4 769\n",
      "4 770\n",
      "4 771\n",
      "4 772\n",
      "4 773\n",
      "4 774\n",
      "4 775\n",
      "4 776\n",
      "4 777\n",
      "4 778\n",
      "4 779\n",
      "4 780\n",
      "4 781\n",
      "4 782\n",
      "4 783\n",
      "4 784\n",
      "4 785\n",
      "4 786\n",
      "4 787\n",
      "4 788\n",
      "4 789\n",
      "4 790\n",
      "4 791\n",
      "4 792\n",
      "4 793\n",
      "4 794\n",
      "4 795\n",
      "4 796\n",
      "4 797\n",
      "4 798\n",
      "4 799\n",
      "4 800\n",
      "4 801\n",
      "4 802\n",
      "4 803\n",
      "4 804\n",
      "4 805\n",
      "4 806\n",
      "4 807\n",
      "4 808\n",
      "4 809\n",
      "4 810\n",
      "4 811\n",
      "4 812\n",
      "4 813\n",
      "4 814\n",
      "4 815\n",
      "4 816\n",
      "4 817\n",
      "4 818\n",
      "4 819\n",
      "4 820\n",
      "4 821\n",
      "4 822\n",
      "4 823\n",
      "4 824\n",
      "4 825\n",
      "4 826\n",
      "4 827\n",
      "4 828\n",
      "4 829\n",
      "4 830\n",
      "4 831\n",
      "4 832\n",
      "4 833\n",
      "4 834\n",
      "4 835\n",
      "4 836\n",
      "4 837\n",
      "4 838\n",
      "4 839\n",
      "4 840\n",
      "4 841\n",
      "4 842\n",
      "4 843\n",
      "4 844\n",
      "4 845\n",
      "4 846\n",
      "4 847\n",
      "4 848\n",
      "4 849\n",
      "4 850\n",
      "4 851\n",
      "4 852\n",
      "4 853\n",
      "4 854\n",
      "4 855\n",
      "4 856\n",
      "4 857\n",
      "4 858\n",
      "4 859\n",
      "4 860\n",
      "4 861\n",
      "4 862\n",
      "4 863\n",
      "4 864\n",
      "4 865\n",
      "4 866\n",
      "4 867\n",
      "4 868\n",
      "4 869\n",
      "4 870\n",
      "4 871\n",
      "4 872\n",
      "4 873\n",
      "4 874\n",
      "4 875\n",
      "4 876\n",
      "4 877\n",
      "4 878\n",
      "4 879\n",
      "4 880\n",
      "4 881\n",
      "4 882\n",
      "4 883\n",
      "4 884\n",
      "4 885\n",
      "4 886\n",
      "4 887\n",
      "4 888\n",
      "4 889\n",
      "4 890\n",
      "4 891\n",
      "4 892\n",
      "4 893\n",
      "4 894\n",
      "4 895\n",
      "4 896\n",
      "4 897\n",
      "4 898\n",
      "4 899\n",
      "4 900\n",
      "4 901\n",
      "4 902\n",
      "4 903\n",
      "4 904\n",
      "4 905\n",
      "4 906\n",
      "4 907\n",
      "4 908\n",
      "4 909\n",
      "4 910\n",
      "4 911\n",
      "4 912\n",
      "4 913\n",
      "4 914\n",
      "4 915\n",
      "4 916\n",
      "4 917\n",
      "4 918\n",
      "4 919\n",
      "4 920\n",
      "4 921\n",
      "4 922\n",
      "4 923\n",
      "4 924\n",
      "4 925\n",
      "4 926\n",
      "4 927\n",
      "4 928\n",
      "4 929\n",
      "4 930\n",
      "4 931\n",
      "4 932\n",
      "4 933\n",
      "4 934\n",
      "4 935\n",
      "4 936\n",
      "4 937\n",
      "4 938\n",
      "4 939\n",
      "4 940\n",
      "4 941\n",
      "4 942\n",
      "4 943\n",
      "4 944\n",
      "4 945\n",
      "4 946\n",
      "4 947\n",
      "4 948\n",
      "4 949\n",
      "4 950\n",
      "4 951\n",
      "4 952\n",
      "4 953\n",
      "4 954\n",
      "4 955\n",
      "4 956\n",
      "4 957\n",
      "4 958\n",
      "4 959\n",
      "4 960\n",
      "4 961\n",
      "4 962\n",
      "4 963\n",
      "4 964\n",
      "4 965\n",
      "4 966\n",
      "4 967\n",
      "4 968\n",
      "4 969\n",
      "4 970\n",
      "4 971\n",
      "4 972\n",
      "4 973\n",
      "4 974\n",
      "4 975\n",
      "4 976\n",
      "4 977\n",
      "4 978\n",
      "4 979\n",
      "4 980\n",
      "4 981\n",
      "4 982\n",
      "4 983\n",
      "4 984\n",
      "4 985\n",
      "4 986\n",
      "4 987\n",
      "4 988\n",
      "4 989\n",
      "4 990\n",
      "4 991\n",
      "4 992\n",
      "4 993\n",
      "4 994\n",
      "4 995\n",
      "4 996\n",
      "4 997\n",
      "4 998\n",
      "4 999\n",
      "4 1000\n",
      "4 1001\n",
      "4 1002\n",
      "4 1003\n",
      "4 1004\n",
      "4 1005\n",
      "4 1006\n",
      "4 1007\n",
      "4 1008\n",
      "4 1009\n",
      "4 1010\n",
      "4 1011\n",
      "4 1012\n",
      "4 1013\n",
      "4 1014\n",
      "4 1015\n",
      "4 1016\n",
      "4 1017\n",
      "4 1018\n",
      "4 1019\n",
      "4 1020\n",
      "4 1021\n",
      "4 1022\n",
      "4 1023\n",
      "4 1024\n",
      "4 1025\n",
      "4 1026\n",
      "4 1027\n",
      "4 1028\n",
      "4 1029\n",
      "4 1030\n",
      "4 1031\n",
      "4 1032\n",
      "4 1033\n",
      "4 1034\n",
      "4 1035\n",
      "4 1036\n",
      "4 1037\n",
      "4 1038\n",
      "4 1039\n",
      "4 1040\n",
      "4 1041\n",
      "4 1042\n",
      "4 1043\n",
      "4 1044\n",
      "4 1045\n",
      "4 1046\n",
      "4 1047\n",
      "4 1048\n",
      "4 1049\n",
      "4 1050\n",
      "4 1051\n",
      "4 1052\n",
      "4 1053\n",
      "4 1054\n",
      "4 1055\n",
      "4 1056\n",
      "4 1057\n",
      "4 1058\n",
      "4 1059\n",
      "4 1060\n",
      "4 1061\n",
      "4 1062\n",
      "4 1063\n",
      "4 1064\n",
      "4 1065\n",
      "4 1066\n",
      "4 1067\n",
      "4 1068\n",
      "4 1069\n",
      "4 1070\n",
      "4 1071\n",
      "4 1072\n",
      "4 1073\n",
      "4 1074\n",
      "4 1075\n",
      "4 1076\n",
      "4 1077\n",
      "4 1078\n",
      "4 1079\n",
      "4 1080\n",
      "4 1081\n",
      "4 1082\n",
      "4 1083\n",
      "4 1084\n",
      "4 1085\n",
      "4 1086\n",
      "4 1087\n",
      "4 1088\n",
      "4 1089\n",
      "4 1090\n",
      "4 1091\n",
      "4 1092\n",
      "4 1093\n",
      "4 1094\n",
      "4 1095\n",
      "4 1096\n",
      "4 1097\n",
      "4 1098\n",
      "4 1099\n",
      "4 1100\n",
      "4 1101\n",
      "4 1102\n",
      "4 1103\n",
      "4 1104\n",
      "4 1105\n",
      "4 1106\n",
      "4 1107\n",
      "4 1108\n",
      "4 1109\n",
      "4 1110\n",
      "4 1111\n",
      "4 1112\n",
      "4 1113\n",
      "4 1114\n",
      "4 1115\n",
      "4 1116\n",
      "4 1117\n",
      "4 1118\n",
      "4 1119\n",
      "4 1120\n",
      "4 1121\n",
      "4 1122\n",
      "4 1123\n",
      "4 1124\n",
      "4 1125\n",
      "4 1126\n",
      "4 1127\n",
      "4 1128\n",
      "4 1129\n",
      "4 1130\n",
      "4 1131\n",
      "4 1132\n",
      "4 1133\n",
      "4 1134\n",
      "4 1135\n",
      "4 1136\n",
      "4 1137\n",
      "4 1138\n",
      "4 1139\n",
      "4 1140\n",
      "4 1141\n",
      "4 1142\n",
      "4 1143\n",
      "4 1144\n",
      "4 1145\n",
      "4 1146\n",
      "4 1147\n",
      "4 1148\n",
      "4 1149\n",
      "4 1150\n",
      "4 1151\n",
      "4 1152\n",
      "4 1153\n",
      "4 1154\n",
      "4 1155\n",
      "4 1156\n",
      "4 1157\n",
      "4 1158\n",
      "4 1159\n",
      "4 1160\n",
      "4 1161\n",
      "4 1162\n",
      "4 1163\n",
      "4 1164\n",
      "4 1165\n",
      "4 1166\n",
      "4 1167\n",
      "4 1168\n",
      "4 1169\n",
      "4 1170\n",
      "4 1171\n",
      "4 1172\n",
      "4 1173\n",
      "4 1174\n",
      "4 1175\n",
      "4 1176\n",
      "4 1177\n",
      "4 1178\n",
      "4 1179\n",
      "4 1180\n",
      "4 1181\n",
      "4 1182\n",
      "4 1183\n",
      "4 1184\n",
      "4 1185\n",
      "4 1186\n",
      "4 1187\n",
      "4 1188\n",
      "4 1189\n",
      "4 1190\n",
      "4 1191\n",
      "4 1192\n",
      "4 1193\n",
      "4 1194\n",
      "4 1195\n",
      "4 1196\n",
      "4 1197\n",
      "4 1198\n",
      "4 1199\n",
      "4 1200\n",
      "4 1201\n",
      "4 1202\n",
      "4 1203\n",
      "4 1204\n",
      "4 1205\n",
      "4 1206\n",
      "4 1207\n",
      "4 1208\n",
      "4 1209\n",
      "4 1210\n",
      "4 1211\n",
      "4 1212\n",
      "4 1213\n",
      "4 1214\n",
      "4 1215\n",
      "4 1216\n",
      "4 1217\n",
      "4 1218\n",
      "4 1219\n",
      "4 1220\n",
      "4 1221\n",
      "4 1222\n",
      "4 1223\n",
      "4 1224\n",
      "4 1225\n",
      "4 1226\n",
      "4 1227\n",
      "4 1228\n",
      "4 1229\n",
      "4 1230\n",
      "4 1231\n",
      "4 1232\n",
      "4 1233\n",
      "4 1234\n",
      "4 1235\n",
      "4 1236\n",
      "4 1237\n",
      "4 1238\n",
      "4 1239\n",
      "4 1240\n",
      "4 1241\n",
      "4 1242\n",
      "4 1243\n",
      "4 1244\n",
      "4 1245\n",
      "4 1246\n",
      "4 1247\n",
      "4 1248\n",
      "4 1249\n",
      "4 1250\n",
      "4 1251\n",
      "4 1252\n",
      "4 1253\n",
      "4 1254\n",
      "4 1255\n",
      "4 1256\n",
      "4 1257\n",
      "4 1258\n",
      "4 1259\n",
      "4 1260\n",
      "4 1261\n",
      "4 1262\n",
      "4 1263\n",
      "4 1264\n",
      "4 1265\n",
      "4 1266\n",
      "4 1267\n",
      "4 1268\n",
      "4 1269\n",
      "4 1270\n",
      "4 1271\n",
      "4 1272\n",
      "4 1273\n",
      "4 1274\n",
      "4 1275\n",
      "4 1276\n",
      "4 1277\n",
      "4 1278\n",
      "4 1279\n",
      "4 1280\n",
      "4 1281\n",
      "4 1282\n",
      "4 1283\n",
      "4 1284\n",
      "4 1285\n",
      "4 1286\n",
      "4 1287\n",
      "4 1288\n",
      "4 1289\n",
      "4 1290\n",
      "4 1291\n",
      "4 1292\n",
      "4 1293\n",
      "4 1294\n",
      "4 1295\n",
      "4 1296\n",
      "4 1297\n",
      "4 1298\n",
      "4 1299\n",
      "4 1300\n",
      "4 1301\n",
      "4 1302\n",
      "4 1303\n",
      "4 1304\n",
      "4 1305\n",
      "4 1306\n",
      "4 1307\n",
      "4 1308\n",
      "4 1309\n",
      "4 1310\n",
      "4 1311\n",
      "4 1312\n",
      "4 1313\n",
      "4 1314\n",
      "4 1315\n",
      "4 1316\n",
      "4 1317\n",
      "4 1318\n",
      "4 1319\n",
      "4 1320\n",
      "4 1321\n",
      "4 1322\n",
      "4 1323\n",
      "4 1324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1325\n",
      "4 1326\n",
      "4 1327\n",
      "4 1328\n",
      "4 1329\n",
      "4 1330\n",
      "4 1331\n",
      "4 1332\n",
      "4 1333\n",
      "4 1334\n",
      "4 1335\n",
      "4 1336\n",
      "4 1337\n",
      "4 1338\n",
      "4 1339\n",
      "4 1340\n",
      "4 1341\n",
      "4 1342\n",
      "4 1343\n",
      "4 1344\n",
      "4 1345\n",
      "4 1346\n",
      "4 1347\n",
      "4 1348\n",
      "4 1349\n",
      "4 1350\n",
      "4 1351\n",
      "4 1352\n",
      "4 1353\n",
      "4 1354\n",
      "4 1355\n",
      "4 1356\n",
      "4 1357\n",
      "4 1358\n",
      "4 1359\n",
      "4 1360\n",
      "4 1361\n",
      "4 1362\n",
      "4 1363\n",
      "4 1364\n",
      "4 1365\n",
      "4 1366\n",
      "4 1367\n",
      "4 1368\n",
      "4 1369\n",
      "4 1370\n",
      "4 1371\n",
      "4 1372\n",
      "4 1373\n",
      "4 1374\n",
      "4 1375\n",
      "4 1376\n",
      "4 1377\n",
      "4 1378\n",
      "4 1379\n",
      "4 1380\n",
      "4 1381\n",
      "4 1382\n",
      "4 1383\n",
      "4 1384\n",
      "4 1385\n",
      "4 1386\n",
      "4 1387\n",
      "4 1388\n",
      "4 1389\n",
      "4 1390\n",
      "4 1391\n",
      "4 1392\n",
      "4 1393\n",
      "4 1394\n",
      "4 1395\n",
      "4 1396\n",
      "4 1397\n",
      "4 1398\n",
      "4 1399\n",
      "4 1400\n",
      "4 1401\n",
      "4 1402\n",
      "4 1403\n",
      "4 1404\n",
      "4 1405\n",
      "4 1406\n",
      "4 1407\n",
      "4 1408\n",
      "4 1409\n",
      "4 1410\n",
      "4 1411\n",
      "4 1412\n",
      "4 1413\n",
      "4 1414\n",
      "4 1415\n",
      "4 1416\n",
      "4 1417\n",
      "4 1418\n",
      "4 1419\n",
      "4 1420\n",
      "4 1421\n",
      "4 1422\n",
      "4 1423\n",
      "4 1424\n",
      "4 1425\n",
      "4 1426\n",
      "4 1427\n",
      "4 1428\n",
      "4 1429\n",
      "4 1430\n",
      "4 1431\n",
      "4 1432\n",
      "4 1433\n",
      "4 1434\n",
      "4 1435\n",
      "4 1436\n",
      "4 1437\n",
      "4 1438\n",
      "4 1439\n",
      "4 1440\n",
      "4 1441\n",
      "4 1442\n",
      "4 1443\n",
      "4 1444\n",
      "4 1445\n",
      "4 1446\n",
      "4 1447\n",
      "4 1448\n",
      "4 1449\n",
      "4 1450\n",
      "4 1451\n",
      "4 1452\n",
      "4 1453\n",
      "4 1454\n",
      "4 1455\n",
      "4 1456\n",
      "4 1457\n",
      "4 1458\n",
      "4 1459\n",
      "4 1460\n",
      "4 1461\n",
      "4 1462\n",
      "4 1463\n",
      "4 1464\n",
      "4 1465\n",
      "4 1466\n",
      "4 1467\n",
      "4 1468\n",
      "4 1469\n",
      "4 1470\n",
      "4 1471\n",
      "4 1472\n",
      "4 1473\n",
      "4 1474\n",
      "4 1475\n",
      "4 1476\n",
      "4 1477\n",
      "4 1478\n",
      "4 1479\n",
      "4 1480\n",
      "4 1481\n",
      "4 1482\n",
      "4 1483\n",
      "4 1484\n",
      "4 1485\n",
      "4 1486\n",
      "4 1487\n",
      "4 1488\n",
      "4 1489\n",
      "4 1490\n",
      "4 1491\n",
      "4 1492\n",
      "4 1493\n",
      "4 1494\n",
      "4 1495\n",
      "4 1496\n",
      "4 1497\n",
      "4 1498\n",
      "4 1499\n",
      "4 1500\n",
      "4 1501\n",
      "4 1502\n",
      "4 1503\n",
      "4 1504\n",
      "4 1505\n",
      "4 1506\n",
      "4 1507\n",
      "4 1508\n",
      "4 1509\n",
      "4 1510\n",
      "4 1511\n",
      "4 1512\n",
      "4 1513\n",
      "4 1514\n",
      "4 1515\n",
      "4 1516\n",
      "4 1517\n",
      "4 1518\n",
      "4 1519\n",
      "4 1520\n",
      "4 1521\n",
      "4 1522\n",
      "4 1523\n",
      "4 1524\n",
      "4 1525\n",
      "4 1526\n",
      "4 1527\n",
      "4 1528\n",
      "4 1529\n",
      "4 1530\n",
      "4 1531\n",
      "4 1532\n",
      "4 1533\n",
      "4 1534\n",
      "4 1535\n",
      "4 1536\n",
      "4 1537\n",
      "4 1538\n",
      "4 1539\n",
      "4 1540\n",
      "4 1541\n",
      "4 1542\n",
      "4 1543\n",
      "4 1544\n",
      "4 1545\n",
      "4 1546\n",
      "4 1547\n",
      "4 1548\n",
      "4 1549\n",
      "4 1550\n",
      "4 1551\n",
      "4 1552\n",
      "4 1553\n",
      "4 1554\n",
      "4 1555\n",
      "4 1556\n",
      "4 1557\n",
      "4 1558\n",
      "4 1559\n",
      "4 1560\n",
      "4 1561\n",
      "4 1562\n",
      "4 1563\n",
      "4 1564\n",
      "4 1565\n",
      "4 1566\n",
      "4 1567\n",
      "4 1568\n",
      "4 1569\n",
      "4 1570\n",
      "4 1571\n",
      "4 1572\n",
      "4 1573\n",
      "4 1574\n",
      "4 1575\n",
      "4 1576\n",
      "4 1577\n",
      "4 1578\n",
      "4 1579\n",
      "4 1580\n",
      "4 1581\n",
      "4 1582\n",
      "4 1583\n",
      "4 1584\n",
      "4 1585\n",
      "4 1586\n",
      "4 1587\n",
      "4 1588\n",
      "4 1589\n",
      "4 1590\n",
      "4 1591\n",
      "4 1592\n",
      "4 1593\n",
      "4 1594\n",
      "4 1595\n",
      "4 1596\n",
      "4 1597\n",
      "4 1598\n",
      "4 1599\n",
      "4 1600\n",
      "4 1601\n",
      "4 1602\n",
      "4 1603\n",
      "4 1604\n",
      "4 1605\n",
      "4 1606\n",
      "4 1607\n",
      "4 1608\n",
      "4 1609\n",
      "4 1610\n",
      "4 1611\n",
      "4 1612\n",
      "4 1613\n",
      "4 1614\n",
      "4 1615\n",
      "4 1616\n",
      "4 1617\n",
      "4 1618\n",
      "4 1619\n",
      "4 1620\n",
      "4 1621\n",
      "4 1622\n",
      "4 1623\n",
      "4 1624\n",
      "4 1625\n",
      "4 1626\n",
      "4 1627\n",
      "4 1628\n",
      "4 1629\n",
      "4 1630\n",
      "4 1631\n",
      "4 1632\n",
      "4 1633\n"
     ]
    }
   ],
   "source": [
    "final_dataset=[]\n",
    "file_number=0\n",
    "page_number=0\n",
    "for f in base_dataset_pdf:\n",
    "    try :\n",
    "        with(Image(filename=f, resolution=120)) as source: \n",
    "            print(\"test\")\n",
    "            file_number=file_number+1\n",
    "            images = source.sequence\n",
    "            pages = len(images)\n",
    "            print(pages)\n",
    "            for i in range(pages):\n",
    "                n = i + 1\n",
    "                newfilename = f[:-4] + str(n) + '.jpeg'\n",
    "                Image(images[i]).save(filename=newfilename)\n",
    "                img=img1.open(newfilename)\n",
    "                page_number=page_number+1\n",
    "                # Simple image to string\n",
    "                final_dataset.append([f,newfilename,pytesseract.image_to_string(img)])\n",
    "                print(file_number,page_number)\n",
    "    except ImportError:\n",
    "            final_dataset.append([\"text not appended\",\"text not appended\",\"text not appended\"])\n",
    "            print(file_number,page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-aadd469e1370>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-aadd469e1370>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    graphs:\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "graphs:\n",
    "    pandas\n",
    "    matplotlib\n",
    "    seaborn\n",
    "    plotly\n",
    "    dash\n",
    "    bokeh\n",
    "    ggplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finds the insights : Insights are hypothetical scenarios which are true or false\n",
    "#Following graphs are for single continuous variables\n",
    "#Histogram\n",
    "#Rug plots\n",
    "#Heatmap\n",
    "#choropleth map - ex: Geographical maps\n",
    "\n",
    "#Following graphs are for two continuous variables\n",
    "#Linear plots (regression plots)\n",
    "#non linear plot\n",
    "#SCATTER PLOT\n",
    "\n",
    "#Following graphs are for three continuous variables\n",
    "# planes -- Linear plots\n",
    "# hyberplanes -- linear plots\n",
    "# surface plots -- Non linear plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
